/gpfs/home2/nreints/MScThesis/code/lstm.py:270: DeprecationWarning: Sampling from a set deprecated
since Python 3.9 and will be removed in a subsequent version.
  train_sims = set(random.sample(sims_train, int(0.8 * n_sims_train)))
wandb: Currently logged in as: nreints. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.13.9 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.8
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230127_042418-q7827ncf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run legendary-lantern-1519
wandb: â­ï¸ View project at https://wandb.ai/nreints/thesis
wandb: ğŸš€ View run at https://wandb.ai/nreints/thesis/runs/q7827ncf
/home/nreints/.conda/envs/thesis/lib/python3.10/site-packages/torch/nn/modules/rnn.py:67: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  warnings.warn("dropout option adds dropout after all but last "
BEFORE ['data_t(-10,', '10)_r(0,', '0)_none']
----- ITERATION 0/10 ------
[<torch.utils.data.dataloader.DataLoader object at 0x14de66aee8c0>, <torch.utils.data.dataloader.DataLoader object at 0x14de47d08eb0>, <torch.utils.data.dataloader.DataLoader object at 0x14de47d08fa0>, <torch.utils.data.dataloader.DataLoader object at 0x14de47d090f0>]
LSTM(
  (lstm): LSTM(24, 96, batch_first=True, dropout=0.2)
  (layers): Sequential(
    (0): Linear(in_features=96, out_features=24, bias=True)
  )
)
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.017062893137335777
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0524354986846447
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 1.7757784128189087
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 2.2833468914031982
0 1.9694870423 	 2.2833469541
epoch_time;  35.75206208229065
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.07000797241926193
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.17841395735740662
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 4.643931865692139
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 5.054288387298584
1 0.0997276566 	 5.0542884665
epoch_time;  35.69568753242493
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.011511126533150673
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.02447829581797123
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 1.369779348373413
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 1.6467393636703491
2 0.0453659884 	 1.646739395
epoch_time;  34.87450075149536
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.011945709586143494
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.02064063772559166
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.960566520690918
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 1.1884210109710693
3 0.0182076612 	 1.1884210592
epoch_time;  35.48560667037964
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.004614175762981176
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.01342839002609253
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 1.29241144657135
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 1.5117987394332886
4 0.0435595718 	 1.5117986858
epoch_time;  38.9017550945282
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0026433344464749098
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0084381690248847
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.8533822894096375
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 1.0278936624526978
5 0.0138083479 	 1.0278936196
epoch_time;  36.50234842300415
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0037335525266826153
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.008135800249874592
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.6855376958847046
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.841011643409729
6 0.0105768488 	 0.8410116236
epoch_time;  36.39280843734741
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0028366227634251118
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.00819957535713911
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.7854973077774048
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.9581278562545776
7 0.0184334171 	 0.9581278545
epoch_time;  35.49103093147278
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0020039724186062813
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.005477909464389086
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.6116180419921875
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.7558271884918213
8 0.0086633067 	 0.7558271979
epoch_time;  35.63417053222656
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0026629718486219645
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.005288011860102415
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.5576252341270447
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.6731783151626587
9 0.0078853258 	 0.6731783126
epoch_time;  35.3372540473938
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.004039693623781204
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.010284721851348877
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.885099470615387
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 1.0896726846694946
10 0.0207605412 	 1.0896727225
epoch_time;  35.316673278808594
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.00542807299643755
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.008871366269886494
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.5382518172264099
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.6670793890953064
11 0.0071326334 	 0.6670793608
epoch_time;  35.68667197227478
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0025613997131586075
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.005019630305469036
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.4546123445034027
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.5702422261238098
12 0.0070570376 	 0.5702421989
epoch_time;  35.272053480148315
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0331733264029026
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.040527623146772385
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.45748692750930786
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.5627192258834839
13 0.0067337824 	 0.562719201
epoch_time;  35.344223976135254
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.003648775164037943
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.005668296944350004
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.3735407888889313
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.4639583230018616
14 0.0069779801 	 0.4639583253
epoch_time;  35.250035524368286
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.001297183334827423
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.003095670836046338
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.4801839590072632
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.5652481317520142
15 0.0103178551 	 0.5652481494
epoch_time;  35.456677198410034
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.002987680723890662
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.005193511955440044
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.3939630389213562
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.4693674147129059
16 0.0048544311 	 0.4693674047
epoch_time;  35.67654252052307
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.002672515343874693
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.005952487699687481
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.3496720790863037
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.43074914813041687
17 0.0050772953 	 0.4307491614
epoch_time;  35.49672484397888
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.008381335064768791
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.02091241255402565
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 1.3345160484313965
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 1.5587910413742065
18 0.0432020154 	 1.558791054
epoch_time;  35.624300956726074
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.005754795856773853
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.009949088096618652
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.8054956793785095
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.9439297914505005
19 0.0122334179 	 0.9439298048
epoch_time;  35.188286542892456
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.007451727520674467
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.011384681798517704
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.6549988985061646
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.7629859447479248
20 0.0073879785 	 0.762985921
epoch_time;  35.3331937789917
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0019482970237731934
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.005048420280218124
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.6650149822235107
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.7913687229156494
21 0.0146598672 	 0.7913687438
epoch_time;  35.33089876174927
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.002083439379930496
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.00472266273573041
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.5015493631362915
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.607046902179718
22 0.0061374725 	 0.6070469052
epoch_time;  35.2760112285614
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.021750962361693382
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.04272088780999184
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                              Epoch â–â–â–â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–…â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb: Test loss t(-10, 10)_r(-5, 5)_none â–„â–ˆâ–ƒâ–‚â–ƒâ–‚â–‚â–‚â–‚â–â–‚â–â–â–â–â–â–â–â–ƒâ–‚â–‚â–‚â–â–‚â–â–â–‚â–â–â–‚â–‚
wandb:  Test loss t(-10, 10)_r(0, 0)_none â–ƒâ–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–ƒâ–â–â–â–â–‚â–â–â–â–â–ƒâ–â–â–â–â–â–‚â–‚
wandb:    Test loss t(0, 0)_r(-5, 5)_none â–ƒâ–ˆâ–ƒâ–‚â–ƒâ–‚â–‚â–‚â–â–â–‚â–â–â–â–â–â–â–â–ƒâ–‚â–‚â–‚â–â–‚â–â–â–‚â–â–â–‚â–‚
wandb:     Test loss t(0, 0)_r(0, 0)_none â–ƒâ–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–„â–â–â–â–â–‚â–â–‚â–â–â–ƒâ–â–â–â–â–â–‚â–‚
wandb:                         Train loss â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                              Epoch 29
wandb: Test loss t(-10, 10)_r(-5, 5)_none 1.10591
wandb:  Test loss t(-10, 10)_r(0, 0)_none 0.01552
wandb:    Test loss t(0, 0)_r(-5, 5)_none 0.91935
wandb:     Test loss t(0, 0)_r(0, 0)_none 0.0079
wandb:                         Train loss 0.03369
wandb: 
wandb: ğŸš€ View run legendary-lantern-1519 at: https://wandb.ai/nreints/thesis/runs/q7827ncf
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230127_042418-q7827ncf/logs
/gpfs/home2/nreints/MScThesis/code/lstm.py:270: DeprecationWarning: Sampling from a set deprecated
since Python 3.9 and will be removed in a subsequent version.
  train_sims = set(random.sample(sims_train, int(0.8 * n_sims_train)))
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.13.9 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.8
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230127_044355-f88amau1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run alight-monkey-1526
wandb: â­ï¸ View project at https://wandb.ai/nreints/thesis
wandb: ğŸš€ View run at https://wandb.ai/nreints/thesis/runs/f88amau1
/home/nreints/.conda/envs/thesis/lib/python3.10/site-packages/torch/nn/modules/rnn.py:67: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  warnings.warn("dropout option adds dropout after all but last "
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.6940457224845886
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.8323768973350525
23 0.0067595418 	 0.8323769008
epoch_time;  35.280372858047485
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.005051989573985338
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.011308581568300724
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.40147146582603455
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.48971331119537354
24 0.0061082927 	 0.4897133173
epoch_time;  35.05067157745361
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0010622938862070441
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0024821499828249216
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.3389682471752167
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.4092838764190674
25 0.0048424748 	 0.4092838714
epoch_time;  35.22116804122925
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.00455230288207531
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.009779626503586769
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.8047119379043579
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.9038537740707397
26 0.032883216 	 0.9038537708
epoch_time;  35.277159452438354
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0017882391111925244
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.004393185954540968
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.5534459352493286
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.6489791870117188
27 0.0076176667 	 0.6489792101
epoch_time;  35.277130126953125
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0020413463935256004
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.00423961877822876
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.4565480053424835
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.544125497341156
28 0.0057164412 	 0.5441255137
epoch_time;  35.69720983505249
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.007895604707300663
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.01551573071628809
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.9185647368431091
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 1.1064521074295044
29 0.0336873028 	 1.1064521352
epoch_time;  35.36064600944519
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.007896480150520802
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.015516165643930435
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.9193465709686279
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 1.1059072017669678
It took  1177.6052594184875  seconds.
----- ITERATION 1/10 ------
[<torch.utils.data.dataloader.DataLoader object at 0x14de47d08ac0>, <torch.utils.data.dataloader.DataLoader object at 0x14de47d8bf70>, <torch.utils.data.dataloader.DataLoader object at 0x14de30440100>, <torch.utils.data.dataloader.DataLoader object at 0x14de304401c0>]
LSTM(
  (lstm): LSTM(24, 96, batch_first=True, dropout=0.2)
  (layers): Sequential(
    (0): Linear(in_features=96, out_features=24, bias=True)
  )
)
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.011347129940986633
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.05934413895010948
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 1.7662973403930664
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 2.044952392578125
0 2.0221681905 	 2.0449523004
epoch_time;  35.2401762008667
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0401393361389637
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.11180833727121353
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 3.3807425498962402
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 3.663876533508301
1 0.1023922385 	 3.6638766286
epoch_time;  35.52499318122864
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.007534798700362444
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.025463242083787918
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 1.620025873184204
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 1.7355259656906128
2 0.0397059912 	 1.7355260013
epoch_time;  35.24650549888611
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.005186120048165321
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.015421406365931034
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 1.1686623096466064
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 1.2477906942367554
3 0.0192035817 	 1.2477906564
epoch_time;  35.79982137680054
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.006193618290126324
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.014014258049428463
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.9108306765556335
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.9770690202713013
4 0.014033724 	 0.9770690365
epoch_time;  35.80655002593994
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.003867474850267172
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.010314805433154106
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.7347097992897034
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.7858561277389526
5 0.0101393744 	 0.7858561259
epoch_time;  35.50787830352783
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.009821783751249313
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.02373260259628296
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 1.6109344959259033
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 1.7014952898025513
6 0.0790027962 	 1.701495306
epoch_time;  35.67090177536011
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.003333890112116933
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.010938040912151337
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 1.167426586151123
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 1.2348753213882446
7 0.0154705899 	 1.234875267
epoch_time;  34.729777097702026
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.01921023800969124
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.025760697200894356
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.917086124420166
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.9809669852256775
8 0.0107174266 	 0.9809669886
epoch_time;  35.23328351974487
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.003831910202279687
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.008315475657582283
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.7351006269454956
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.7899653315544128
9 0.0088438674 	 0.789965304
epoch_time;  35.38535404205322
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.004063621163368225
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.007979714311659336
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.6523439884185791
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.6978066563606262
10 0.0079776113 	 0.6978066436
epoch_time;  35.61166310310364
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0063271671533584595
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.01916465535759926
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 1.258636236190796
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 1.3380703926086426
11 0.0213548096 	 1.3380704113
epoch_time;  35.51777935028076
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0063909078016877174
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.01037019956856966
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.7500705718994141
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.791035532951355
12 0.009333059 	 0.7910355398
epoch_time;  35.43406414985657
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.008685553446412086
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.012142416089773178
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.6263514161109924
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.6598660945892334
13 0.0065405887 	 0.6598661025
epoch_time;  35.711241006851196
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.004087079782038927
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.008005582727491856
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.5763545632362366
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.6081818342208862
14 0.0063193456 	 0.608181818
epoch_time;  33.8062961101532
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0017024307744577527
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.004171377047896385
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.502016007900238
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.5299912095069885
15 0.0056310819 	 0.5299912191
epoch_time;  33.79592990875244
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                              Epoch â–â–â–â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–…â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb: Test loss t(-10, 10)_r(-5, 5)_none â–…â–ˆâ–„â–ƒâ–‚â–‚â–„â–ƒâ–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–â–‚â–â–â–â–â–â–â–‚â–‚â–â–â–â–‚â–â–
wandb:  Test loss t(-10, 10)_r(0, 0)_none â–…â–ˆâ–‚â–‚â–‚â–â–‚â–‚â–‚â–â–â–‚â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    Test loss t(0, 0)_r(-5, 5)_none â–„â–ˆâ–„â–ƒâ–‚â–‚â–„â–ƒâ–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–â–‚â–â–â–â–â–â–â–‚â–‚â–â–â–â–‚â–â–
wandb:     Test loss t(0, 0)_r(0, 0)_none â–ƒâ–ˆâ–‚â–‚â–‚â–‚â–ƒâ–â–„â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–‚â–â–â–‚â–â–â–â–â–â–â–â–â–â–
wandb:                         Train loss â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                              Epoch 29
wandb: Test loss t(-10, 10)_r(-5, 5)_none 0.52617
wandb:  Test loss t(-10, 10)_r(0, 0)_none 0.00477
wandb:    Test loss t(0, 0)_r(-5, 5)_none 0.50655
wandb:     Test loss t(0, 0)_r(0, 0)_none 0.00201
wandb:                         Train loss 0.00557
wandb: 
wandb: ğŸš€ View run alight-monkey-1526 at: https://wandb.ai/nreints/thesis/runs/f88amau1
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230127_044355-f88amau1/logs
/gpfs/home2/nreints/MScThesis/code/lstm.py:270: DeprecationWarning: Sampling from a set deprecated
since Python 3.9 and will be removed in a subsequent version.
  train_sims = set(random.sample(sims_train, int(0.8 * n_sims_train)))
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.13.9 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.8
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230127_050237-zr2kgtyn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run incandescent-wonton-1532
wandb: â­ï¸ View project at https://wandb.ai/nreints/thesis
wandb: ğŸš€ View run at https://wandb.ai/nreints/thesis/runs/zr2kgtyn
/home/nreints/.conda/envs/thesis/lib/python3.10/site-packages/torch/nn/modules/rnn.py:67: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  warnings.warn("dropout option adds dropout after all but last "
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.001457683276385069
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.004580617882311344
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.5340691804885864
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.5777120590209961
16 0.0136174556 	 0.5777120446
epoch_time;  34.01175618171692
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.00372412521392107
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.007557254750281572
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.48281699419021606
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.5210682153701782
17 0.0055454068 	 0.5210682388
epoch_time;  34.116148710250854
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0031595074106007814
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0055897291749715805
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.43096014857292175
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.4609226584434509
18 0.0053626287 	 0.4609226561
epoch_time;  33.75361895561218
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0013414670247584581
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0033907738979905844
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.376636266708374
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.4011991024017334
19 0.0050401735 	 0.4011991103
epoch_time;  33.6217155456543
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.004338900092989206
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.00633738050237298
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.38630419969558716
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.4233663082122803
20 0.0093651872 	 0.4233663046
epoch_time;  33.955997943878174
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0014262717450037599
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0038316012360155582
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.32926416397094727
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.3570781350135803
21 0.0042946979 	 0.3570781374
epoch_time;  33.851008892059326
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0009151704143732786
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0026440361980348825
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.29095789790153503
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.31208810210227966
22 0.0043266164 	 0.3120881049
epoch_time;  33.641783237457275
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.003246556967496872
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0095333531498909
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.7944568991661072
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.8331961631774902
23 0.0199020337 	 0.8331961733
epoch_time;  35.37599754333496
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0028209195006638765
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.00875313300639391
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.61276775598526
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.6372617483139038
24 0.0062284 	 0.6372617508
epoch_time;  36.019118785858154
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0027865273877978325
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.005565200466662645
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.5008336305618286
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.5060389041900635
25 0.0052053887 	 0.5060389308
epoch_time;  34.75064468383789
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0014959643594920635
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0039321910589933395
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.4176815152168274
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.4293104112148285
26 0.0045579102 	 0.4293104097
epoch_time;  33.76969242095947
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0014696093276143074
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0035740395542234182
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.37004420161247253
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.3773830831050873
27 0.0044909816 	 0.3773830909
epoch_time;  34.23919939994812
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.002974936505779624
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.008594227954745293
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.747992992401123
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.7756158709526062
28 0.018324369 	 0.775615865
epoch_time;  33.936363697052
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0020053500775247812
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.004772393498569727
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.5060288310050964
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.5262522101402283
29 0.0055705409 	 0.5262522164
epoch_time;  34.13693189620972
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.002005781978368759
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.004766822326928377
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.5065465569496155
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.5261707305908203
It took  1122.0451366901398  seconds.
----- ITERATION 2/10 ------
[<torch.utils.data.dataloader.DataLoader object at 0x14de604da740>, <torch.utils.data.dataloader.DataLoader object at 0x14de66a85210>, <torch.utils.data.dataloader.DataLoader object at 0x14de66a86bc0>, <torch.utils.data.dataloader.DataLoader object at 0x14de47d08460>]
LSTM(
  (lstm): LSTM(24, 96, batch_first=True, dropout=0.2)
  (layers): Sequential(
    (0): Linear(in_features=96, out_features=24, bias=True)
  )
)
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.019767312332987785
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.06300303339958191
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 1.7375108003616333
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 2.1771399974823
0 2.0354552807 	 2.1771400659
epoch_time;  33.659584283828735
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.01527912262827158
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0647093877196312
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 2.91517972946167
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 3.2118701934814453
1 0.1423034668 	 3.2118701762
epoch_time;  33.60598087310791
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.009462433867156506
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.02620612271130085
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 1.6931941509246826
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 1.9441163539886475
2 0.0312697665 	 1.9441163216
epoch_time;  33.45784568786621
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.00829807948321104
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.03566037863492966
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 2.1572790145874023
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 2.4101197719573975
3 0.0562813677 	 2.4101197395
epoch_time;  33.640254974365234
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0047299847938120365
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.015531202778220177
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 1.3469488620758057
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 1.5527623891830444
4 0.0198169134 	 1.5527624032
epoch_time;  33.5867063999176
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0025637412909418344
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.009659456089138985
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.9806455969810486
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 1.1529496908187866
5 0.0147826868 	 1.1529496761
epoch_time;  33.63008403778076
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0016752952942624688
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0066682384349405766
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.7941773533821106
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.948832631111145
6 0.0104572952 	 0.9488326243
epoch_time;  33.894718170166016
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.014225883409380913
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.018916795030236244
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.6520488858222961
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.7851196527481079
7 0.0089192769 	 0.7851196473
epoch_time;  33.763386487960815
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.004841776564717293
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.012273595668375492
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                              Epoch â–â–â–â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–…â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb: Test loss t(-10, 10)_r(-5, 5)_none â–…â–ˆâ–…â–†â–„â–ƒâ–‚â–‚â–ƒâ–‚â–â–â–â–â–‚â–‚â–â–â–ƒâ–‚â–‚â–â–â–â–ƒâ–‚â–‚â–â–â–„â–„
wandb:  Test loss t(-10, 10)_r(0, 0)_none â–‚â–‚â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–ˆ
wandb:    Test loss t(0, 0)_r(-5, 5)_none â–…â–ˆâ–…â–†â–„â–‚â–‚â–‚â–ƒâ–‚â–â–â–â–â–‚â–‚â–â–â–ƒâ–‚â–‚â–â–‚â–â–ƒâ–‚â–‚â–â–â–„â–„
wandb:     Test loss t(0, 0)_r(0, 0)_none â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–ˆ
wandb:                         Train loss â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                              Epoch 29
wandb: Test loss t(-10, 10)_r(-5, 5)_none 1.84001
wandb:  Test loss t(-10, 10)_r(0, 0)_none 0.42063
wandb:    Test loss t(0, 0)_r(-5, 5)_none 1.51245
wandb:     Test loss t(0, 0)_r(0, 0)_none 0.27354
wandb:                         Train loss 0.00794
wandb: 
wandb: ğŸš€ View run incandescent-wonton-1532 at: https://wandb.ai/nreints/thesis/runs/zr2kgtyn
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230127_050237-zr2kgtyn/logs
/gpfs/home2/nreints/MScThesis/code/lstm.py:270: DeprecationWarning: Sampling from a set deprecated
since Python 3.9 and will be removed in a subsequent version.
  train_sims = set(random.sample(sims_train, int(0.8 * n_sims_train)))
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.13.9 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.8
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230127_052048-8bc0oofr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run floating-rabbit-1539
wandb: â­ï¸ View project at https://wandb.ai/nreints/thesis
wandb: ğŸš€ View run at https://wandb.ai/nreints/thesis/runs/8bc0oofr
/home/nreints/.conda/envs/thesis/lib/python3.10/site-packages/torch/nn/modules/rnn.py:67: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  warnings.warn("dropout option adds dropout after all but last "
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 1.0171401500701904
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 1.1202553510665894
8 0.0321161442 	 1.1202553925
epoch_time;  33.565759897232056
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.006762021221220493
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.011979584582149982
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.7500751614570618
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.8453603386878967
9 0.0094761556 	 0.8453603324
epoch_time;  33.588693141937256
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0018137091537937522
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.005277242045849562
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.6071692109107971
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.6897823214530945
10 0.0085151118 	 0.6897823184
epoch_time;  33.6174738407135
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0012502375757321715
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0040376936085522175
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.5509257316589355
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.632703423500061
11 0.0080863684 	 0.6327034296
epoch_time;  33.74047827720642
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.008757916279137135
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.012423752807080746
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.4766367971897125
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.5536770820617676
12 0.0060449235 	 0.5536771008
epoch_time;  33.7781457901001
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.015528036281466484
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0199856236577034
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.46548038721084595
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.5380212664604187
13 0.0057735837 	 0.5380212605
epoch_time;  33.812246322631836
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.005304956808686256
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.013704052194952965
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.9268390536308289
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.989488422870636
14 0.0463380084 	 0.9894884
epoch_time;  33.90749144554138
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.001818156335502863
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.006509826984256506
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.7005344033241272
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.7665261626243591
15 0.0087435944 	 0.7665261905
epoch_time;  33.71130347251892
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.001864204416051507
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.005119841545820236
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.6140007972717285
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.6840019822120667
16 0.0069636317 	 0.6840019572
epoch_time;  33.51613521575928
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0029395418241620064
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.008358966559171677
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.5615782737731934
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.6328132748603821
17 0.0061287299 	 0.6328132837
epoch_time;  34.410420656204224
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0052871075458824635
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.012811115011572838
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 1.0630849599838257
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 1.1441986560821533
18 0.0441613497 	 1.1441985992
epoch_time;  34.741241693496704
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.002009026939049363
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.006065006833523512
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.8118159770965576
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.8897687792778015
19 0.008208747 	 0.889768756
epoch_time;  36.14150023460388
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0018279689829796553
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0045433384366333485
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.663996696472168
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.751133143901825
20 0.0062168939 	 0.7511331149
epoch_time;  33.680532693862915
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0021398256067186594
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.004535543732345104
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.5863603949546814
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.6694193482398987
21 0.0057457001 	 0.6694193491
epoch_time;  33.71648859977722
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.002054404467344284
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.005304468795657158
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.6628589630126953
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.7254485487937927
22 0.0100696031 	 0.7254485623
epoch_time;  33.59205222129822
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.004330902360379696
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.007129136007279158
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.5619055032730103
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.6148749589920044
23 0.005138481 	 0.6148749406
epoch_time;  33.89480710029602
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.006584579590708017
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.019451547414064407
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 1.2967206239700317
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 1.3700493574142456
24 0.0647725546 	 1.3700493297
epoch_time;  33.68448281288147
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0026724778581410646
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.008181736804544926
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.8424876928329468
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.923454999923706
25 0.0117088573 	 0.9234549992
epoch_time;  33.75709915161133
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0018185407388955355
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.00527387298643589
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.6956474781036377
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.7687452435493469
26 0.0073451722 	 0.768745261
epoch_time;  33.96317768096924
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.003915164154022932
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.006708549801260233
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.6199604272842407
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.6924583911895752
27 0.0060452585 	 0.6924583689
epoch_time;  34.00775098800659
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.004507070407271385
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.007014427334070206
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.5545335412025452
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.6233716011047363
28 0.005037746 	 0.6233715968
epoch_time;  34.04653787612915
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.27351221442222595
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.42083796858787537
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 1.5132290124893188
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 1.8384419679641724
29 0.0079360698 	 1.8384419698
epoch_time;  34.093611001968384
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.2735370099544525
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.42062729597091675
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 1.512449860572815
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 1.8400115966796875
It took  1091.006843805313  seconds.
----- ITERATION 3/10 ------
[<torch.utils.data.dataloader.DataLoader object at 0x14de30440130>, <torch.utils.data.dataloader.DataLoader object at 0x14de66a86e00>, <torch.utils.data.dataloader.DataLoader object at 0x14de66a86d70>, <torch.utils.data.dataloader.DataLoader object at 0x14de47d5aec0>]
LSTM(
  (lstm): LSTM(24, 96, batch_first=True, dropout=0.2)
  (layers): Sequential(
    (0): Linear(in_features=96, out_features=24, bias=True)
  )
)
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0136280981823802
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.05942339450120926
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 1.6897127628326416
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 2.135692834854126
0 2.0239512857 	 2.1356929537
epoch_time;  33.973836183547974
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.00830030906945467
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.03483157232403755
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 1.5361994504928589
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 1.841951608657837
1 0.1027731538 	 1.8419515834
epoch_time;  33.87367606163025
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.005280430428683758
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.018155165016651154
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 1.0655771493911743
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 1.28071129322052
2 0.0226851744 	 1.2807112864
epoch_time;  33.87262773513794
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0029264413751661777
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.010467717424035072
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.8209660053253174
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.9936059713363647
3 0.0161388666 	 0.9936059681
epoch_time;  34.09154438972473
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.026625270023941994
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.07505691796541214
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 2.9765260219573975
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 3.4320499897003174
4 0.1375358171 	 3.4320499847
epoch_time;  33.92989253997803
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.010806355625391006
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.027659744024276733
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 1.702874779701233
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 1.9749927520751953
5 0.0384803963 	 1.9749927348
epoch_time;  33.78301239013672
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.016159309074282646
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.028046783059835434
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 1.2596737146377563
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 1.4392998218536377
6 0.0192530139 	 1.4392997995
epoch_time;  33.778873682022095
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0030631590634584427
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.010182649828493595
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.9862541556358337
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 1.1313306093215942
7 0.0135948519 	 1.1313305996
epoch_time;  33.835169315338135
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.00282167736440897
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.008723394013941288
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.8157156109809875
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.9542888402938843
8 0.0104942271 	 0.9542888169
epoch_time;  33.95457720756531
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.002760744420811534
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.007097241934388876
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.6683023571968079
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.7955800890922546
9 0.0089720481 	 0.7955800774
epoch_time;  33.78649854660034
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.002173332730308175
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.006385804153978825
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.5768202543258667
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.6748074293136597
10 0.0080933813 	 0.6748074073
epoch_time;  33.7374267578125
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.007202610839158297
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.02608834020793438
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 1.451896071434021
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 1.6412062644958496
11 0.0275823982 	 1.641206217
epoch_time;  33.83408761024475
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.004143405705690384
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.01046175230294466
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.7076380252838135
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.8163212537765503
12 0.0120142223 	 0.8163212433
epoch_time;  35.78154993057251
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.012850895524024963
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.01792474463582039
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.5891673564910889
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.6685909628868103
13 0.0077946127 	 0.668590949
epoch_time;  35.42478060722351
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0029992377385497093
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.007135217543691397
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.4944693446159363
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.5558905601501465
14 0.0068856888 	 0.5558905472
epoch_time;  33.918771266937256
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.007696960121393204
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.018690191209316254
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.4914073646068573
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.5653820037841797
15 0.0067445494 	 0.5653820211
epoch_time;  33.964195728302
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0015617148019373417
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0041026645340025425
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.37703201174736023
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.4296494126319885
16 0.0052127387 	 0.4296494222
epoch_time;  33.944130182266235
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0014072010526433587
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.003871372900903225
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.3291514813899994
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.3872529864311218
17 0.005995479 	 0.387252992
epoch_time;  33.870338439941406
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0023953195195645094
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.005021797493100166
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.28486689925193787
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.3364771604537964
18 0.0053154763 	 0.3364771587
epoch_time;  33.58501887321472
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.003618244780227542
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.009912768378853798
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.669370174407959
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.7692985534667969
19 0.0314465421 	 0.7692985419
epoch_time;  33.70587730407715
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0024206822272390127
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.006116535514593124
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.4705762565135956
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.5509154200553894
20 0.0080838626 	 0.5509153983
epoch_time;  33.67440223693848
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.00333347893320024
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.006813535001128912
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.3963530957698822
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.46568652987480164
21 0.0064587229 	 0.465686533
epoch_time;  33.859461069107056
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0061541167087852955
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.014238703064620495
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.3667445480823517
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.4347159266471863
22 0.0059515609 	 0.4347159394
epoch_time;  33.82322359085083
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0013107294216752052
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.004219118971377611
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.34196051955223083
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.3982612192630768
23 0.0059309536 	 0.3982612172
epoch_time;  33.60586881637573
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0030657367315143347
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.007615252863615751
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.32554298639297485
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.3811362087726593
24 0.0051135472 	 0.3811362229
epoch_time;  33.57006001472473
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.013213644735515118
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.03026735596358776
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.9711297154426575
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                              Epoch â–â–â–â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–…â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb: Test loss t(-10, 10)_r(-5, 5)_none â–…â–„â–ƒâ–‚â–ˆâ–…â–ƒâ–ƒâ–‚â–‚â–‚â–„â–‚â–‚â–â–‚â–â–â–â–‚â–â–â–â–â–â–ƒâ–â–â–â–â–
wandb:  Test loss t(-10, 10)_r(0, 0)_none â–†â–„â–‚â–‚â–ˆâ–ƒâ–ƒâ–‚â–â–â–â–ƒâ–‚â–‚â–â–‚â–â–â–â–‚â–â–â–‚â–â–â–„â–â–â–â–â–
wandb:    Test loss t(0, 0)_r(-5, 5)_none â–…â–„â–ƒâ–‚â–ˆâ–…â–„â–ƒâ–‚â–‚â–‚â–„â–‚â–‚â–‚â–‚â–â–â–â–‚â–â–â–â–â–â–ƒâ–â–â–â–â–
wandb:     Test loss t(0, 0)_r(0, 0)_none â–„â–ƒâ–‚â–â–ˆâ–„â–…â–â–â–â–â–ƒâ–‚â–„â–â–ƒâ–â–â–â–‚â–â–‚â–‚â–â–â–„â–â–â–â–â–
wandb:                         Train loss â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                              Epoch 29
wandb: Test loss t(-10, 10)_r(-5, 5)_none 0.3485
wandb:  Test loss t(-10, 10)_r(0, 0)_none 0.00427
wandb:    Test loss t(0, 0)_r(-5, 5)_none 0.29914
wandb:     Test loss t(0, 0)_r(0, 0)_none 0.00198
wandb:                         Train loss 0.00457
wandb: 
wandb: ğŸš€ View run floating-rabbit-1539 at: https://wandb.ai/nreints/thesis/runs/8bc0oofr
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230127_052048-8bc0oofr/logs
/gpfs/home2/nreints/MScThesis/code/lstm.py:270: DeprecationWarning: Sampling from a set deprecated
since Python 3.9 and will be removed in a subsequent version.
  train_sims = set(random.sample(sims_train, int(0.8 * n_sims_train)))
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.13.9 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.8
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230127_053903-q3pj7ytv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run thriving-bao-1546
wandb: â­ï¸ View project at https://wandb.ai/nreints/thesis
wandb: ğŸš€ View run at https://wandb.ai/nreints/thesis/runs/q3pj7ytv
/home/nreints/.conda/envs/thesis/lib/python3.10/site-packages/torch/nn/modules/rnn.py:67: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  warnings.warn("dropout option adds dropout after all but last "
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 1.0526230335235596
25 0.0180807626 	 1.0526230919
epoch_time;  33.811739683151245
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0021417459938675165
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.00558163458481431
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.4290551543235779
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.5113604068756104
26 0.0084496663 	 0.511360422
epoch_time;  33.96107578277588
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.002887464128434658
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.006845549680292606
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.3477427661418915
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.4156017601490021
27 0.0056741994 	 0.4156017476
epoch_time;  33.683682680130005
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.002062400570139289
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.004163920413702726
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.3194596767425537
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.37013518810272217
28 0.004913155 	 0.3701351892
epoch_time;  33.72063207626343
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0019766155164688826
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.004270459525287151
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.2997420132160187
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.34890010952949524
29 0.0045734834 	 0.3489000949
epoch_time;  33.67774963378906
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.001978101907297969
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.004273570142686367
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.2991364002227783
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.34849804639816284
It took  1094.3588473796844  seconds.
----- ITERATION 4/10 ------
[<torch.utils.data.dataloader.DataLoader object at 0x14de47d6fc40>, <torch.utils.data.dataloader.DataLoader object at 0x14de47d0b940>, <torch.utils.data.dataloader.DataLoader object at 0x14de47d08eb0>, <torch.utils.data.dataloader.DataLoader object at 0x14de47d0b520>]
LSTM(
  (lstm): LSTM(24, 96, batch_first=True, dropout=0.2)
  (layers): Sequential(
    (0): Linear(in_features=96, out_features=24, bias=True)
  )
)
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.016658099368214607
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.04928504675626755
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 1.8592398166656494
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 2.1924750804901123
0 1.9558571203 	 2.192475195
epoch_time;  33.58631205558777
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.012513961642980576
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.041552018374204636
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 2.0437934398651123
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 2.2138025760650635
1 0.0934707676 	 2.2138024644
epoch_time;  33.77981662750244
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.00428307568654418
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.015307139605283737
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 1.1667006015777588
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 1.2772687673568726
2 0.0265361257 	 1.2772687929
epoch_time;  33.52085733413696
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0038767026271671057
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.011457610875368118
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.840796172618866
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.9091075658798218
3 0.0165498374 	 0.9091075886
epoch_time;  33.74678921699524
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.005984424613416195
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.01975558139383793
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 1.559180736541748
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 1.6307048797607422
4 0.0886467032 	 1.6307048509
epoch_time;  33.66786503791809
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.004386384040117264
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.013036767952144146
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 1.0989773273468018
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 1.1446317434310913
5 0.0176237483 	 1.144631746
epoch_time;  34.227580547332764
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0027418078389018774
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.008702048100531101
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.8993685841560364
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.9433615207672119
6 0.0125517329 	 0.9433614956
epoch_time;  36.712270736694336
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0016236829105764627
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0052407607436180115
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.7157009840011597
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.77657151222229
7 0.0100214111 	 0.7765714985
epoch_time;  35.961578369140625
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.01525056455284357
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.020747404545545578
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.6273568272590637
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.6825326681137085
8 0.0095609684 	 0.6825326879
epoch_time;  34.17552971839905
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0035627521574497223
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.008153586648404598
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.5342307090759277
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.5818600654602051
9 0.0075732086 	 0.5818600842
epoch_time;  33.89962148666382
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0012829715851694345
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.003210617695003748
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.46342021226882935
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.5016584396362305
10 0.0070473226 	 0.5016584598
epoch_time;  34.505535364151
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.00750439427793026
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.013571354560554028
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.8319132328033447
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.9020394682884216
11 0.0441672118 	 0.9020394962
epoch_time;  34.783273458480835
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.007915627211332321
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.012310061603784561
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.6365969777107239
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.6630357503890991
12 0.0088794818 	 0.6630357356
epoch_time;  35.527113914489746
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.02132255584001541
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.025035906583070755
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.5500249266624451
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.5838142037391663
13 0.00717202 	 0.5838141773
epoch_time;  35.506935834884644
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0019980547949671745
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.004268466029316187
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.4268803298473358
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.4782752990722656
14 0.0066367495 	 0.4782753106
epoch_time;  35.37989163398743
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.005173057783395052
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.01475346740335226
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 1.0291473865509033
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 1.148231029510498
15 0.0313633984 	 1.1482309762
epoch_time;  35.43020820617676
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0019037770107388496
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.005444498732686043
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.6991621255874634
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.73357093334198
16 0.0096953671 	 0.7335709402
epoch_time;  35.479005098342896
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0023413393646478653
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.005523498170077801
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.594612181186676
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.6106827855110168
17 0.0066411187 	 0.6106827843
epoch_time;  35.593743324279785
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                              Epoch â–â–â–â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–…â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb: Test loss t(-10, 10)_r(-5, 5)_none â–…â–…â–ƒâ–‚â–„â–ƒâ–‚â–‚â–‚â–â–â–‚â–‚â–â–â–ƒâ–‚â–â–â–â–â–â–â–…â–ƒâ–‚â–‚â–‚â–ˆâ–…â–…
wandb:  Test loss t(-10, 10)_r(0, 0)_none â–„â–ƒâ–‚â–‚â–‚â–‚â–â–â–‚â–â–â–‚â–‚â–‚â–â–‚â–â–â–â–â–â–â–â–†â–‚â–â–â–â–ˆâ–ƒâ–ƒ
wandb:    Test loss t(0, 0)_r(-5, 5)_none â–…â–…â–ƒâ–‚â–„â–ƒâ–‚â–‚â–‚â–â–â–‚â–‚â–â–â–ƒâ–‚â–‚â–‚â–â–â–â–â–…â–ƒâ–‚â–‚â–‚â–ˆâ–…â–…
wandb:     Test loss t(0, 0)_r(0, 0)_none â–ƒâ–ƒâ–â–â–‚â–â–â–â–ƒâ–â–â–‚â–‚â–„â–â–‚â–â–â–â–â–â–‚â–â–‡â–â–â–â–â–ˆâ–ƒâ–ƒ
wandb:                         Train loss â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–‚â–
wandb: 
wandb: Run summary:
wandb:                              Epoch 29
wandb: Test loss t(-10, 10)_r(-5, 5)_none 2.25078
wandb:  Test loss t(-10, 10)_r(0, 0)_none 0.04
wandb:    Test loss t(0, 0)_r(-5, 5)_none 2.06455
wandb:     Test loss t(0, 0)_r(0, 0)_none 0.01753
wandb:                         Train loss 0.06635
wandb: 
wandb: ğŸš€ View run thriving-bao-1546 at: https://wandb.ai/nreints/thesis/runs/q3pj7ytv
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230127_053903-q3pj7ytv/logs
/gpfs/home2/nreints/MScThesis/code/lstm.py:270: DeprecationWarning: Sampling from a set deprecated
since Python 3.9 and will be removed in a subsequent version.
  train_sims = set(random.sample(sims_train, int(0.8 * n_sims_train)))
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.13.9 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.8
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230127_055746-zub8rje8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vibrant-goat-1553
wandb: â­ï¸ View project at https://wandb.ai/nreints/thesis
wandb: ğŸš€ View run at https://wandb.ai/nreints/thesis/runs/zub8rje8
/home/nreints/.conda/envs/thesis/lib/python3.10/site-packages/torch/nn/modules/rnn.py:67: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  warnings.warn("dropout option adds dropout after all but last "
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0013952706940472126
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.003416047664359212
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.5984500050544739
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.598703145980835
18 0.0079456072 	 0.5987031597
epoch_time;  35.600573778152466
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.002929234877228737
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.005908247083425522
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.49132221937179565
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.4912763833999634
19 0.0046156808 	 0.4912763982
epoch_time;  35.39588642120361
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0020321235060691833
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.003795846365392208
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.45605984330177307
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.452629029750824
20 0.004999712 	 0.4526290202
epoch_time;  35.210753202438354
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.006598095875233412
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.010000479407608509
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.41035881638526917
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.41733428835868835
21 0.0046483046 	 0.4173342886
epoch_time;  35.38448143005371
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.001588950166478753
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0031315931119024754
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.382432222366333
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.3958096206188202
22 0.0046430894 	 0.395809623
epoch_time;  35.74639964103699
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.041146181523799896
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.08780031651258469
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 2.0375330448150635
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 2.1286027431488037
23 0.0838031697 	 2.1286027338
epoch_time;  35.666937828063965
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.004445686470717192
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.012424806132912636
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 1.127669095993042
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 1.1075083017349243
24 0.0290953054 	 1.1075082646
epoch_time;  35.331636905670166
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0038542477414011955
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.007983348332345486
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.858767569065094
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.8667207956314087
25 0.0105719859 	 0.8667207931
epoch_time;  35.46965789794922
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0036106782499700785
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.008232728578150272
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.7165973782539368
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.7349626421928406
26 0.0076664564 	 0.7349626247
epoch_time;  35.34092593193054
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.002239628927782178
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.004869094118475914
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.6422820687294006
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.6460834741592407
27 0.0066089955 	 0.6460834515
epoch_time;  35.86417627334595
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.04907757788896561
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.1153368279337883
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 3.2479896545410156
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 3.548950672149658
28 0.3682166655 	 3.5489505641
epoch_time;  35.54271602630615
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.01752566546201706
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.040009044110774994
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 2.0656325817108154
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 2.251558780670166
29 0.066345752 	 2.2515588858
epoch_time;  35.83861994743347
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.01752905361354351
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.03999602422118187
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 2.0645530223846436
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 2.250776767730713
It took  1123.0455405712128  seconds.
----- ITERATION 5/10 ------
[<torch.utils.data.dataloader.DataLoader object at 0x14de68059480>, <torch.utils.data.dataloader.DataLoader object at 0x14de47d6ff40>, <torch.utils.data.dataloader.DataLoader object at 0x14de604daa70>, <torch.utils.data.dataloader.DataLoader object at 0x14de47d095d0>]
LSTM(
  (lstm): LSTM(24, 96, batch_first=True, dropout=0.2)
  (layers): Sequential(
    (0): Linear(in_features=96, out_features=24, bias=True)
  )
)
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.012549500912427902
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.05872533470392227
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 1.8341444730758667
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 2.2685863971710205
0 1.9871161762 	 2.2685864037
epoch_time;  37.55313801765442
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.010099404491484165
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.04202103242278099
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 2.0626907348632812
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 2.398738145828247
1 0.1033968005 	 2.3987382503
epoch_time;  37.20556902885437
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.00726530933752656
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.021875251084566116
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 1.3445467948913574
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 1.5457873344421387
2 0.0259052048 	 1.5457873388
epoch_time;  35.31250596046448
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.004173735622316599
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.012916103936731815
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 1.006209135055542
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 1.1646870374679565
3 0.01679457 	 1.1646870501
epoch_time;  35.451303005218506
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.012244037352502346
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.038730766624212265
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 2.3547537326812744
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 2.546922206878662
4 0.0821607707 	 2.5469222054
epoch_time;  35.43395757675171
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.014767222106456757
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.02605324052274227
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 1.431274652481079
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 1.5761139392852783
5 0.0213407463 	 1.5761139746
epoch_time;  35.3354434967041
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.00645573390647769
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.014336907304823399
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 1.0540473461151123
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 1.1909291744232178
6 0.0131940632 	 1.1909292169
epoch_time;  35.58301496505737
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.008767744526267052
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.015442898496985435
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.807608425617218
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.9294354319572449
7 0.0108077846 	 0.9294354303
epoch_time;  35.727713108062744
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0032025931868702173
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.008498452603816986
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.6607345342636108
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.7703549265861511
8 0.0091491348 	 0.7703549019
epoch_time;  35.452701568603516
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.003208134090527892
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.007393188774585724
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.5637789964675903
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.6620488166809082
9 0.0079280751 	 0.6620488008
epoch_time;  35.58958148956299
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0713728815317154
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.19107581675052643
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 4.0673508644104
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                              Epoch â–â–â–â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–…â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb: Test loss t(-10, 10)_r(-5, 5)_none â–…â–…â–ƒâ–‚â–…â–ƒâ–‚â–‚â–‚â–â–ˆâ–„â–ƒâ–‚â–‚â–â–â–â–â–‚â–‚â–â–â–â–â–‚â–â–â–â–â–
wandb:  Test loss t(-10, 10)_r(0, 0)_none â–ƒâ–‚â–‚â–â–‚â–‚â–â–â–â–â–ˆâ–‚â–â–â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    Test loss t(0, 0)_r(-5, 5)_none â–„â–„â–ƒâ–‚â–…â–ƒâ–‚â–‚â–â–â–ˆâ–ƒâ–‚â–‚â–‚â–â–â–â–â–‚â–‚â–â–â–â–â–‚â–â–â–â–â–
wandb:     Test loss t(0, 0)_r(0, 0)_none â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–â–â–ˆâ–â–â–â–â–‚â–â–‚â–â–â–â–â–â–‚â–â–â–â–â–â–â–
wandb:                         Train loss â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                              Epoch 29
wandb: Test loss t(-10, 10)_r(-5, 5)_none 0.46919
wandb:  Test loss t(-10, 10)_r(0, 0)_none 0.00334
wandb:    Test loss t(0, 0)_r(-5, 5)_none 0.4211
wandb:     Test loss t(0, 0)_r(0, 0)_none 0.00128
wandb:                         Train loss 0.00602
wandb: 
wandb: ğŸš€ View run vibrant-goat-1553 at: https://wandb.ai/nreints/thesis/runs/zub8rje8
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230127_055746-zub8rje8/logs
/gpfs/home2/nreints/MScThesis/code/lstm.py:270: DeprecationWarning: Sampling from a set deprecated
since Python 3.9 and will be removed in a subsequent version.
  train_sims = set(random.sample(sims_train, int(0.8 * n_sims_train)))
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.13.9 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.8
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230127_061651-uw2822cu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lunar-festival-1558
wandb: â­ï¸ View project at https://wandb.ai/nreints/thesis
wandb: ğŸš€ View run at https://wandb.ai/nreints/thesis/runs/uw2822cu
/home/nreints/.conda/envs/thesis/lib/python3.10/site-packages/torch/nn/modules/rnn.py:67: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  warnings.warn("dropout option adds dropout after all but last "
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 4.0741801261901855
10 0.0678459243 	 4.0741800268
epoch_time;  34.735100746154785
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.005576709285378456
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.020390963181853294
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 1.688405990600586
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 1.7926344871520996
11 0.0410317674 	 1.7926344396
epoch_time;  35.55570602416992
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.005066549871116877
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.012932226061820984
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 1.1399807929992676
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 1.2592424154281616
12 0.0144901882 	 1.2592424007
epoch_time;  35.265387296676636
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.004244827199727297
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.012211665511131287
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.888395369052887
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 1.0059176683425903
13 0.0104184414 	 1.0059176442
epoch_time;  35.642125844955444
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.003444323316216469
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.010451409965753555
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.7246469259262085
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.8062238097190857
14 0.0084400314 	 0.8062237973
epoch_time;  35.38791584968567
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0104001984000206
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.017113881185650826
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.6052467823028564
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.6808926463127136
15 0.0071344924 	 0.6808926216
epoch_time;  35.226256370544434
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.001620161347091198
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.004945206455886364
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.6262008547782898
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.6635053753852844
16 0.0099634283 	 0.6635053929
epoch_time;  35.328659534454346
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.008104821667075157
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.012265845201909542
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.5710404515266418
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.6034827828407288
17 0.0066059092 	 0.6034827564
epoch_time;  35.388402223587036
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0016075592720881104
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.004452068824321032
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.48162713646888733
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.51968914270401
18 0.0056730367 	 0.5196891393
epoch_time;  35.50144028663635
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0033094033133238554
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.009576096199452877
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 1.0899888277053833
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 1.1023105382919312
19 0.0324437375 	 1.1023105956
epoch_time;  35.36033582687378
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0036541742738336325
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.008683042600750923
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.7468464374542236
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.7777937054634094
20 0.0083285988 	 0.7777936768
epoch_time;  35.62716341018677
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0045823948457837105
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.008443234488368034
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.6041089296340942
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.6483923196792603
21 0.0066208605 	 0.6483923229
epoch_time;  35.175856828689575
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0018784679705277085
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0050544594414532185
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.5474479794502258
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.5888980627059937
22 0.0062487795 	 0.5888980739
epoch_time;  35.53777289390564
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.008527455851435661
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.011647453531622887
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.5182828307151794
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.5588627457618713
23 0.005535134 	 0.558862738
epoch_time;  36.10461401939392
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0012587979435920715
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0033212110865861177
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.47024306654930115
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.4958851933479309
24 0.0056222667 	 0.4958851978
epoch_time;  35.26310610771179
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.002381356433033943
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.007073689252138138
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.7858523726463318
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.8209624886512756
25 0.014588504 	 0.8209624968
epoch_time;  37.56219410896301
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.002446238650009036
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.005001938436180353
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.5389595627784729
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.5574804544448853
26 0.0050760185 	 0.5574804577
epoch_time;  36.450159311294556
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.001467767171561718
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.003572420682758093
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.4672638177871704
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.49481335282325745
27 0.0048318295 	 0.4948133486
epoch_time;  36.0434045791626
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0018257084302604198
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.00444088876247406
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.39968299865722656
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.4445483684539795
28 0.0045033891 	 0.444548362
epoch_time;  35.386181116104126
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0012768978485837579
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.003346974728628993
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.4212299883365631
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.4687741994857788
29 0.006020577 	 0.468774202
epoch_time;  35.130295515060425
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0012771625770255923
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0033446752931922674
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.42109572887420654
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.46919023990631104
It took  1145.727309703827  seconds.
----- ITERATION 6/10 ------
[<torch.utils.data.dataloader.DataLoader object at 0x14de604db190>, <torch.utils.data.dataloader.DataLoader object at 0x14de66a72c20>, <torch.utils.data.dataloader.DataLoader object at 0x14de66a72bc0>, <torch.utils.data.dataloader.DataLoader object at 0x14de66a62ec0>]
LSTM(
  (lstm): LSTM(24, 96, batch_first=True, dropout=0.2)
  (layers): Sequential(
    (0): Linear(in_features=96, out_features=24, bias=True)
  )
)
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.16048774123191833
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.38163986802101135
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 5.621094226837158
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 5.975756645202637
0 2.0139383782 	 5.9757566884
epoch_time;  35.27399301528931
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.012221315875649452
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.032296761870384216
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 1.5819908380508423
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 1.7977176904678345
1 0.0635418022 	 1.7977176908
epoch_time;  35.61638307571411
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.005784429609775543
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.017674971371889114
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 1.0707027912139893
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 1.2205759286880493
2 0.0212969249 	 1.2205759838
epoch_time;  35.29139041900635
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.023421650752425194
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.06526760011911392
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 3.2207908630371094
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 3.2110249996185303
3 0.084300374 	 3.2110249038
epoch_time;  35.44075965881348
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.009105863980948925
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.021407350897789
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 1.3844616413116455
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 1.5131505727767944
4 0.0313082745 	 1.5131505868
epoch_time;  35.340163469314575
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.004059258382767439
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.01138819195330143
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 1.0164552927017212
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 1.1034139394760132
5 0.016266337 	 1.1034139305
epoch_time;  34.8954963684082
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0022238516248762608
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0075337584130465984
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.8159964084625244
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.8828577399253845
6 0.0122122248 	 0.8828577693
epoch_time;  35.0871057510376
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.00430122297257185
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.008561751805245876
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.6939792037010193
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.7536199688911438
7 0.01006149 	 0.7536199748
epoch_time;  35.26919364929199
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.002507477533072233
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.006682294886559248
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.7188454270362854
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.7533286213874817
8 0.0151711449 	 0.7533286288
epoch_time;  35.283676862716675
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0021087978966534138
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.004861007444560528
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.5928677916526794
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.618745744228363
9 0.0076463304 	 0.6187457404
epoch_time;  35.46707201004028
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.001302645425312221
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.003901947755366564
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.5357339382171631
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.5636748671531677
10 0.0079039322 	 0.5636748807
epoch_time;  34.43597078323364
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0018218603217974305
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0057731266133487225
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.7561631202697754
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.7777800559997559
11 0.0132358314 	 0.7777800315
epoch_time;  35.50625538825989
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0071342396549880505
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0113881416618824
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.550946056842804
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.5745867490768433
12 0.0060849128 	 0.5745867588
epoch_time;  35.49990439414978
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.003152288030833006
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.006181735545396805
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.5083358287811279
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.5312291979789734
13 0.006233533 	 0.5312292093
epoch_time;  35.379945516586304
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.00260551692917943
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.00791385117918253
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.7662290334701538
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.7906354069709778
14 0.0092505961 	 0.7906353999
epoch_time;  35.42438530921936
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0023234060499817133
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0052491603419184685
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.5761945247650146
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.5878276228904724
15 0.005233669 	 0.5878276076
epoch_time;  35.42100238800049
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.00276513141579926
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.004615748301148415
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.5155264139175415
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.5224663019180298
16 0.0056627445 	 0.5224663311
epoch_time;  35.391889810562134
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0057670301757752895
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.009429140947759151
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.5209332704544067
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.5166800022125244
17 0.0051451903 	 0.5166800231
epoch_time;  35.462512731552124
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0038370867259800434
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.01256243884563446
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 1.2243437767028809
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 1.2321312427520752
18 0.0304310529 	 1.2321312665
epoch_time;  38.545546531677246
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0018885360332205892
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.006235314067453146
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.8625741600990295
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.8701232671737671
19 0.0091969543 	 0.8701232726
epoch_time;  37.35550570487976
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0018217626493424177
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.004972641356289387
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.7080101370811462
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.7142856121063232
20 0.0067828422 	 0.7142855826
epoch_time;  36.01874113082886
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.001717528561130166
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.004191771149635315
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.6377684473991394
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.6466519236564636
21 0.0060594712 	 0.6466519451
epoch_time;  35.057729721069336
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0016814961563795805
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0038746988866478205
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.5227384567260742
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.5342215895652771
22 0.0050624007 	 0.5342215915
epoch_time;  35.388449907302856
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.005564759951084852
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.013964595273137093
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.9408078789710999
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 1.0075336694717407
23 0.0296414828 	 1.0075336929
epoch_time;  35.42839527130127
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0025617494247853756
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.006223819684237242
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.7139110565185547
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.7430647015571594
24 0.0093052133 	 0.743064719
epoch_time;  35.20705032348633
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0013895622687414289
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.004559538327157497
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.5881619453430176
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.6029456853866577
25 0.0064865462 	 0.6029457023
epoch_time;  35.48011779785156
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.001815917668864131
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0036700370255857706
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.5546287894248962
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.5603367686271667
26 0.0053437902 	 0.5603367555
epoch_time;  35.45410919189453
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.002011435804888606
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.003654245985671878
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.4157402217388153
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.44354161620140076
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                              Epoch â–â–â–â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–…â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb: Test loss t(-10, 10)_r(-5, 5)_none â–ˆâ–ƒâ–‚â–…â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–‚â–‚â–â–â–â–‚â–â–â–â–â–‚â–â–
wandb:  Test loss t(-10, 10)_r(0, 0)_none â–ˆâ–‚â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    Test loss t(0, 0)_r(-5, 5)_none â–ˆâ–ƒâ–‚â–…â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–‚â–‚â–â–â–â–‚â–â–â–â–â–‚â–â–
wandb:     Test loss t(0, 0)_r(0, 0)_none â–ˆâ–â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                         Train loss â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                              Epoch 29
wandb: Test loss t(-10, 10)_r(-5, 5)_none 0.56626
wandb:  Test loss t(-10, 10)_r(0, 0)_none 0.00418
wandb:    Test loss t(0, 0)_r(-5, 5)_none 0.54906
wandb:     Test loss t(0, 0)_r(0, 0)_none 0.00179
wandb:                         Train loss 0.0062
wandb: 
wandb: ğŸš€ View run lunar-festival-1558 at: https://wandb.ai/nreints/thesis/runs/uw2822cu
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230127_061651-uw2822cu/logs
/gpfs/home2/nreints/MScThesis/code/lstm.py:270: DeprecationWarning: Sampling from a set deprecated
since Python 3.9 and will be removed in a subsequent version.
  train_sims = set(random.sample(sims_train, int(0.8 * n_sims_train)))
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: wandb version 0.13.9 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.8
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230127_063553-ncvfjdn1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dancing-bao-1565
wandb: â­ï¸ View project at https://wandb.ai/nreints/thesis
wandb: ğŸš€ View run at https://wandb.ai/nreints/thesis/runs/ncvfjdn1
/home/nreints/.conda/envs/thesis/lib/python3.10/site-packages/torch/nn/modules/rnn.py:67: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  warnings.warn("dropout option adds dropout after all but last "
27 0.0082842584 	 0.4435416046
epoch_time;  35.37993884086609
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.004105857107788324
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.011326603591442108
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.8888652920722961
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.9029332399368286
28 0.0260681222 	 0.9029332648
epoch_time;  35.34258151054382
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.001794173615053296
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.004179190378636122
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.5495343804359436
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.5669488906860352
29 0.0062047459 	 0.566948882
epoch_time;  35.51680326461792
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0017932482296600938
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.004176773130893707
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.5490556359291077
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.5662627220153809
It took  1141.485954284668  seconds.
----- ITERATION 7/10 ------
[<torch.utils.data.dataloader.DataLoader object at 0x14de30443970>, <torch.utils.data.dataloader.DataLoader object at 0x14de66a61ed0>, <torch.utils.data.dataloader.DataLoader object at 0x14de47d09930>, <torch.utils.data.dataloader.DataLoader object at 0x14de47d09600>]
LSTM(
  (lstm): LSTM(24, 96, batch_first=True, dropout=0.2)
  (layers): Sequential(
    (0): Linear(in_features=96, out_features=24, bias=True)
  )
)
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.01669992506504059
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.061243098229169846
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 1.9683383703231812
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 2.3637382984161377
0 2.0150395061 	 2.3637381839
epoch_time;  35.547091007232666
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.006617065519094467
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.02483748272061348
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 1.1239328384399414
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 1.3793483972549438
1 0.0342350425 	 1.37934834
epoch_time;  35.49981617927551
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.01361704058945179
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.03572158142924309
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 1.6942981481552124
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 1.8489316701889038
2 0.0845606051 	 1.8489317188
epoch_time;  35.074440002441406
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.006102932151407003
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.017914559692144394
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 1.0867999792099
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 1.241710901260376
3 0.0194419584 	 1.2417109279
epoch_time;  35.232516288757324
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.003045568009838462
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.011732405051589012
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.8118850588798523
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.9521316289901733
4 0.0139196599 	 0.9521316574
epoch_time;  35.312171459198
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.010717484168708324
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.04433382302522659
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 2.419017791748047
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 2.473478317260742
5 0.0665149443 	 2.4734782884
epoch_time;  35.538002490997314
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0047313617542386055
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.014813244342803955
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 1.2696044445037842
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 1.350590467453003
6 0.0198286996 	 1.3505904552
epoch_time;  35.40800595283508
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0045105088502168655
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.014665838330984116
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.8857715129852295
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.9864227175712585
7 0.0121887995 	 0.9864227203
epoch_time;  35.403958320617676
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.006892940495163202
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.013711191713809967
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.733534574508667
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.8324797749519348
8 0.0099021809 	 0.8324797939
epoch_time;  35.315892934799194
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0022086268290877342
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.006371309980750084
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.5831523537635803
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.6723037362098694
9 0.0087580663 	 0.6723037213
epoch_time;  35.26944398880005
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.01331682875752449
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.019376203417778015
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.5106226205825806
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.5909615755081177
10 0.0073665306 	 0.59096156
epoch_time;  34.8075635433197
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0038408355321735144
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.013794941827654839
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.9714989066123962
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 1.0595505237579346
11 0.0273757114 	 1.0595505821
epoch_time;  37.63158917427063
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.002518166322261095
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.007643109653145075
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.7285856008529663
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.7705176472663879
12 0.0082376294 	 0.7705176316
epoch_time;  36.64942169189453
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0020116977393627167
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.005750961601734161
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.5911455154418945
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.6303266286849976
13 0.0068510064 	 0.6303266082
epoch_time;  36.129658699035645
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.001850081142038107
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.00633036345243454
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.6594707369804382
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.7263815402984619
14 0.0139835005 	 0.7263815612
epoch_time;  35.4695405960083
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.003614853136241436
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.006663110107183456
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.5107148289680481
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.5727174282073975
15 0.0053761928 	 0.5727174419
epoch_time;  35.20859622955322
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.009804056026041508
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.015732787549495697
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.7239476442337036
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.8032496571540833
16 0.0129593121 	 0.8032496703
epoch_time;  35.112536668777466
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.008436550386250019
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.013502861373126507
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.5445525050163269
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.6216705441474915
17 0.0061930765 	 0.6216705414
epoch_time;  35.16196155548096
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0017787405522540212
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.004331287927925587
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.450688898563385
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.505135715007782
18 0.0052109465 	 0.5051357119
epoch_time;  35.33366537094116
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.001975745428353548
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.00644677085801959
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.781827449798584
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.8311682939529419
19 0.0146403201 	 0.8311682756
epoch_time;  35.57795238494873
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.003556078765541315
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.006346955895423889
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                              Epoch â–â–â–â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–…â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb: Test loss t(-10, 10)_r(-5, 5)_none â–ˆâ–„â–†â–„â–ƒâ–ˆâ–„â–ƒâ–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–ƒâ–‚â–â–â–â–‚â–â–â–
wandb:  Test loss t(-10, 10)_r(0, 0)_none â–ˆâ–„â–…â–ƒâ–‚â–†â–‚â–‚â–‚â–â–ƒâ–‚â–‚â–â–â–â–‚â–‚â–â–â–â–â–‚â–â–â–â–â–â–â–â–
wandb:    Test loss t(0, 0)_r(-5, 5)_none â–†â–„â–†â–ƒâ–ƒâ–ˆâ–„â–ƒâ–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–
wandb:     Test loss t(0, 0)_r(0, 0)_none â–ˆâ–ƒâ–‡â–ƒâ–‚â–…â–ƒâ–ƒâ–„â–â–†â–‚â–‚â–â–â–‚â–…â–„â–â–â–‚â–â–‚â–â–â–‚â–â–â–‚â–â–
wandb:                         Train loss â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                              Epoch 29
wandb: Test loss t(-10, 10)_r(-5, 5)_none 0.40524
wandb:  Test loss t(-10, 10)_r(0, 0)_none 0.00416
wandb:    Test loss t(0, 0)_r(-5, 5)_none 0.36142
wandb:     Test loss t(0, 0)_r(0, 0)_none 0.00166
wandb:                         Train loss 0.00461
wandb: 
wandb: ğŸš€ View run dancing-bao-1565 at: https://wandb.ai/nreints/thesis/runs/ncvfjdn1
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230127_063553-ncvfjdn1/logs
/gpfs/home2/nreints/MScThesis/code/lstm.py:270: DeprecationWarning: Sampling from a set deprecated
since Python 3.9 and will be removed in a subsequent version.
  train_sims = set(random.sample(sims_train, int(0.8 * n_sims_train)))
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.13.9 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.8
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230127_065458-vjb7dmvt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run festive-lantern-1572
wandb: â­ï¸ View project at https://wandb.ai/nreints/thesis
wandb: ğŸš€ View run at https://wandb.ai/nreints/thesis/runs/vjb7dmvt
/home/nreints/.conda/envs/thesis/lib/python3.10/site-packages/torch/nn/modules/rnn.py:67: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  warnings.warn("dropout option adds dropout after all but last "
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.6466442942619324
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.682259738445282
20 0.0059252471 	 0.6822597354
epoch_time;  35.21520376205444
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0018280550139024854
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.004544047638773918
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.5124202966690063
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.5657389163970947
21 0.0051169832 	 0.56573892
epoch_time;  35.267616748809814
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0028319258708506823
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.008367776870727539
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.7385785579681396
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.8385650515556335
22 0.0353767632 	 0.8385650543
epoch_time;  35.35679388046265
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0018376780208200216
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.005283622071146965
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.5474055409431458
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.6296955943107605
23 0.0065781624 	 0.6296956042
epoch_time;  36.21311140060425
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0010974586475640535
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0038591325283050537
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.43688714504241943
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.5027096271514893
24 0.0060068325 	 0.5027096567
epoch_time;  35.108598709106445
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.003297529648989439
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.006759741343557835
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.38594555854797363
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.4399505853652954
25 0.0047935407 	 0.43995058
epoch_time;  35.17284560203552
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0011945118894800544
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.003512642113491893
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.34779444336891174
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.3913414180278778
26 0.0046294549 	 0.3913414255
epoch_time;  35.222928524017334
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0019241597037762403
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.006781625095754862
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.4948726296424866
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.5714032649993896
27 0.0163407351 	 0.5714032499
epoch_time;  35.04715132713318
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.003716869745403528
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.006184745579957962
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.41569551825523376
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.47195154428482056
28 0.0049874034 	 0.4719515337
epoch_time;  35.00023031234741
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0016569807194173336
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.004165541380643845
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.361878901720047
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.40506991744041443
29 0.0046068397 	 0.4050699101
epoch_time;  35.01272201538086
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0016571310115978122
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.004161366727203131
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.3614178001880646
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.40524378418922424
It took  1145.2866106033325  seconds.
----- ITERATION 8/10 ------
[<torch.utils.data.dataloader.DataLoader object at 0x14de66aee9e0>, <torch.utils.data.dataloader.DataLoader object at 0x14de30443a90>, <torch.utils.data.dataloader.DataLoader object at 0x14de66a716f0>, <torch.utils.data.dataloader.DataLoader object at 0x14de66a72470>]
LSTM(
  (lstm): LSTM(24, 96, batch_first=True, dropout=0.2)
  (layers): Sequential(
    (0): Linear(in_features=96, out_features=24, bias=True)
  )
)
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.018057798966765404
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.05382111296057701
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 1.843583345413208
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 2.3801236152648926
0 1.9751299989 	 2.380123634
epoch_time;  34.85557198524475
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.016811059787869453
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.05814570561051369
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 2.730135679244995
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 3.105255603790283
1 0.1077918284 	 3.1052555879
epoch_time;  34.723227739334106
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.007540455088019371
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.019711678847670555
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 1.5615582466125488
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 1.8063195943832397
2 0.0298363038 	 1.8063195911
epoch_time;  34.81413221359253
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.005465647205710411
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.014048684388399124
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 1.096543788909912
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 1.2900404930114746
3 0.0170603889 	 1.2900405377
epoch_time;  34.93654680252075
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.004862511996179819
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.01245162170380354
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.8275971412658691
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.9907691478729248
4 0.0130914072 	 0.9907691241
epoch_time;  35.31303644180298
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.008228153921663761
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.021249812096357346
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 1.7748031616210938
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 1.917455792427063
5 0.0696640246 	 1.9174557597
epoch_time;  37.70487380027771
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0037364012096077204
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.009740323759615421
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 1.2618967294692993
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 1.3374862670898438
6 0.0149875803 	 1.337486244
epoch_time;  35.904016971588135
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0022368356585502625
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.007021764293313026
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.9937933087348938
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 1.0842506885528564
7 0.010741667 	 1.0842506432
epoch_time;  34.74846887588501
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.004189296159893274
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.007505661807954311
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.8448967337608337
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.9379065036773682
8 0.0090125717 	 0.9379065015
epoch_time;  34.83844828605652
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.003467850387096405
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.008247342891991138
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 1.2393165826797485
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 1.292478322982788
9 0.0195965604 	 1.2924783482
epoch_time;  34.7842538356781
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0051889275200665
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.008521818555891514
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 1.0155816078186035
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 1.064947485923767
10 0.0078624744 	 1.0649474913
epoch_time;  35.022002935409546
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0029035352636128664
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.006039355881512165
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.866400420665741
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.9200707674026489
11 0.0072140011 	 0.920070775
epoch_time;  34.89656138420105
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.004837715532630682
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.014796236529946327
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 1.2686907052993774
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 1.3588461875915527
12 0.021060392 	 1.3588462438
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                              Epoch â–â–â–â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–…â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb: Test loss t(-10, 10)_r(-5, 5)_none â–†â–ˆâ–„â–ƒâ–‚â–…â–ƒâ–‚â–‚â–ƒâ–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–â–â–â–â–â–â–‚â–â–â–â–â–ƒâ–‚â–‚
wandb:  Test loss t(-10, 10)_r(0, 0)_none â–‡â–ˆâ–ƒâ–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–â–ƒâ–‚â–â–â–â–â–â–â–â–â–â–‚â–â–â–â–â–‚â–â–
wandb:    Test loss t(0, 0)_r(-5, 5)_none â–…â–ˆâ–„â–ƒâ–‚â–…â–ƒâ–ƒâ–‚â–ƒâ–ƒâ–‚â–ƒâ–‚â–‚â–‚â–‚â–â–â–â–â–â–â–‚â–‚â–â–â–â–ƒâ–‚â–‚
wandb:     Test loss t(0, 0)_r(0, 0)_none â–ˆâ–‡â–„â–ƒâ–ƒâ–„â–‚â–‚â–‚â–‚â–ƒâ–‚â–ƒâ–‚â–â–â–â–‚â–â–‚â–â–â–â–‚â–‚â–‚â–â–â–‚â–â–
wandb:                         Train loss â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                              Epoch 29
wandb: Test loss t(-10, 10)_r(-5, 5)_none 0.79157
wandb:  Test loss t(-10, 10)_r(0, 0)_none 0.00383
wandb:    Test loss t(0, 0)_r(-5, 5)_none 0.69461
wandb:     Test loss t(0, 0)_r(0, 0)_none 0.00124
wandb:                         Train loss 0.00684
wandb: 
wandb: ğŸš€ View run festive-lantern-1572 at: https://wandb.ai/nreints/thesis/runs/vjb7dmvt
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230127_065458-vjb7dmvt/logs
/gpfs/home2/nreints/MScThesis/code/lstm.py:270: DeprecationWarning: Sampling from a set deprecated
since Python 3.9 and will be removed in a subsequent version.
  train_sims = set(random.sample(sims_train, int(0.8 * n_sims_train)))
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.13.9 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.8
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230127_071336-hk7oz2tl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run chromatic-kumquat-1579
wandb: â­ï¸ View project at https://wandb.ai/nreints/thesis
wandb: ğŸš€ View run at https://wandb.ai/nreints/thesis/runs/hk7oz2tl
/home/nreints/.conda/envs/thesis/lib/python3.10/site-packages/torch/nn/modules/rnn.py:67: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  warnings.warn("dropout option adds dropout after all but last "
epoch_time;  34.82276654243469
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.002665524370968342
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0064102523028850555
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.8985593914985657
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.9770342707633972
13 0.0089489997 	 0.9770342778
epoch_time;  34.91647911071777
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.001808798755519092
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.004274639301002026
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.7867632508277893
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.8232954144477844
14 0.0072424497 	 0.8232953858
epoch_time;  35.01590299606323
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0019832986872643232
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.005950741469860077
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.9087023138999939
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.9830964803695679
15 0.0179798522 	 0.9830964887
epoch_time;  34.82896828651428
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0015613604336977005
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.004152326844632626
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.707170307636261
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.771115243434906
16 0.0065880111 	 0.7711152598
epoch_time;  34.881903409957886
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0031571935396641493
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.005912069696933031
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.6105951070785522
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.669023334980011
17 0.0055161338 	 0.6690233121
epoch_time;  34.67683434486389
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.001810600166209042
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.004079580772668123
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.5859044194221497
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.6420726776123047
18 0.0055314316 	 0.6420726949
epoch_time;  34.993062019348145
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.002378186210989952
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0045641399919986725
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.5819427967071533
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.6341221928596497
19 0.0060043187 	 0.6341221743
epoch_time;  34.71925735473633
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0018143535126000643
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0034717738162726164
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.5299291014671326
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.5757229924201965
20 0.0044092984 	 0.5757230084
epoch_time;  35.12791204452515
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0014296346344053745
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0032326681539416313
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.5360944271087646
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.5989237427711487
21 0.0066380346 	 0.5989237437
epoch_time;  34.814274311065674
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0008924513240344822
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0021214240696281195
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.497681587934494
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.5521074533462524
22 0.0044029115 	 0.5521074278
epoch_time;  34.83865737915039
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0022566274274140596
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.006695822812616825
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.8128435015678406
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.8780797719955444
23 0.0214452087 	 0.878079786
epoch_time;  34.80476665496826
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.00235453131608665
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.00454461807385087
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.6579291224479675
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.7030390501022339
24 0.0059164063 	 0.7030390714
epoch_time;  34.56920266151428
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0024004399310797453
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.005570897366851568
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.6044483184814453
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.648711621761322
25 0.0050422671 	 0.648711605
epoch_time;  34.560274600982666
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0010003721108660102
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.002602740190923214
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.5431339144706726
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.5850450396537781
26 0.0047055699 	 0.5850450222
epoch_time;  34.75830793380737
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0013673424255102873
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.003330922918394208
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.5073531866073608
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.5473054647445679
27 0.0043450163 	 0.547305473
epoch_time;  34.68055987358093
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.003915054723620415
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.011252781376242638
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.9852116107940674
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 1.1394304037094116
28 0.0202940451 	 1.1394303889
epoch_time;  35.237590312957764
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0012380280531942844
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.003831370733678341
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.6959677338600159
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.7918443083763123
29 0.0068366818 	 0.7918443017
epoch_time;  35.18741750717163
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0012372060446068645
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0038259669672697783
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.6946130990982056
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.7915678024291992
It took  1117.731190443039  seconds.
----- ITERATION 9/10 ------
[<torch.utils.data.dataloader.DataLoader object at 0x14de6850ca90>, <torch.utils.data.dataloader.DataLoader object at 0x14de66a81300>, <torch.utils.data.dataloader.DataLoader object at 0x14de66a82ce0>, <torch.utils.data.dataloader.DataLoader object at 0x14de66a82e90>]
LSTM(
  (lstm): LSTM(24, 96, batch_first=True, dropout=0.2)
  (layers): Sequential(
    (0): Linear(in_features=96, out_features=24, bias=True)
  )
)
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.01308703888207674
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.04940013960003853
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 1.9911876916885376
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 2.4556424617767334
0 2.0359387567 	 2.4556423775
epoch_time;  35.850356340408325
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.010516718961298466
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.037640903145074844
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 2.3136987686157227
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 2.524517774581909
1 0.1145255401 	 2.5245176932
epoch_time;  34.89584398269653
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.006535387597978115
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.019420793280005455
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 1.4598798751831055
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 1.6243548393249512
2 0.0267991059 	 1.6243547975
epoch_time;  34.908130407333374
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0034498292952775955
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.01145227625966072
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 1.1116901636123657
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 1.2436301708221436
3 0.0165964339 	 1.2436302162
epoch_time;  34.94530177116394
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.004651402588933706
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.013188617303967476
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 1.1254161596298218
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 1.1861525774002075
4 0.0236238845 	 1.1861526167
epoch_time;  35.09560179710388
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.003941548988223076
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.008821642957627773
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.9220126271247864
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.9743366241455078
5 0.0116290555 	 0.974336653
epoch_time;  35.003294229507446
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.5317177772521973
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.8334103226661682
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 2.7808539867401123
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 3.230695962905884
6 0.0147476052 	 3.2306959262
epoch_time;  35.16310501098633
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.002773032523691654
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.008468887768685818
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 1.1083035469055176
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 1.1508665084838867
7 0.020792354 	 1.1508664595
epoch_time;  34.79727053642273
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.001823015627451241
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0057024057023227215
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.8562763333320618
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.9035558700561523
8 0.010863463 	 0.9035558787
epoch_time;  34.719261169433594
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0029078612569719553
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.006320972926914692
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.713263213634491
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.7642773985862732
9 0.0073317709 	 0.7642773862
epoch_time;  34.596548557281494
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.005921370815485716
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.009584050625562668
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.6544560790061951
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.722182035446167
10 0.0070151626 	 0.722182029
epoch_time;  35.318161725997925
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.005008882377296686
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.014087171293795109
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 1.2433885335922241
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 1.330546259880066
11 0.0666035978 	 1.3305462149
epoch_time;  35.159327268600464
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.008797695860266685
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.013456592336297035
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.9295300245285034
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.999966561794281
12 0.0114209726 	 0.9999665321
epoch_time;  35.17915081977844
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.004897506441920996
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.008161511272192001
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.8009390234947205
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.8758902549743652
13 0.008290981 	 0.8758902651
epoch_time;  35.20576524734497
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0013984690885990858
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0043510552495718
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.7321553230285645
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.8097503781318665
14 0.0075783524 	 0.8097503754
epoch_time;  34.96759629249573
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.005634468048810959
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.008179917931556702
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.6588210463523865
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.7225578427314758
15 0.0067120768 	 0.7225578285
epoch_time;  35.006394386291504
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0016190886963158846
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0036904646549373865
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.6150263547897339
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.6566525101661682
16 0.0063403149 	 0.6566524909
epoch_time;  34.89756631851196
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.028113489970564842
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.05745016410946846
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 1.2533921003341675
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 1.4294410943984985
17 0.009698135 	 1.4294411466
epoch_time;  35.34833288192749
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.003572194604203105
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.007731257006525993
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.7118537425994873
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.7492424249649048
18 0.0078356835 	 0.749242408
epoch_time;  35.21187472343445
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0011498655658215284
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.002697239862754941
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.5887500047683716
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.6210867762565613
19 0.0053535796 	 0.621086789
epoch_time;  35.0553617477417
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0023357428144663572
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.005167218390852213
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.7972909808158875
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.8229351043701172
20 0.0098414482 	 0.8229350756
epoch_time;  34.715662479400635
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.001169433817267418
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.002907384419813752
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.6082984805107117
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.6440147161483765
21 0.0046282703 	 0.64401471
epoch_time;  34.87710118293762
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.005206970032304525
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.00952825602144003
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.58978271484375
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.6255455017089844
22 0.0045620657 	 0.6255454902
epoch_time;  35.306063175201416
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.005212589167058468
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.01552638504654169
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 1.4169529676437378
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 1.487656593322754
23 0.0210733305 	 1.4876566077
epoch_time;  35.02153301239014
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.003174112644046545
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.006501282099634409
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.8460139036178589
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.9393793940544128
24 0.0076603431 	 0.9393793665
epoch_time;  37.23816990852356
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0013062285725027323
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0037137488834559917
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.7097772359848022
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.778632402420044
25 0.0064182614 	 0.7786324031
epoch_time;  35.5457079410553
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0016072139842435718
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.005538415163755417
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.6248361468315125
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.6886005401611328
26 0.0043507102 	 0.688600569
epoch_time;  35.006951093673706
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.00468412647023797
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0066803921945393085
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.6097691059112549
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.651380717754364
27 0.0071957499 	 0.6513806945
epoch_time;  35.01617693901062
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.001323725562542677
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0026644293684512377
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.5365175008773804
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.56675785779953
28 0.0038874505 	 0.5667578475
epoch_time;  35.46229696273804
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0018567563965916634
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0036117054987698793
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.609725832939148
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.6637778282165527
29 0.0116355313 	 0.6637778383
epoch_time;  35.257309913635254
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0018560352036729455
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.022 MB of 0.022 MB uploaded (0.000 MB deduped)wandb: \ 0.022 MB of 0.022 MB uploaded (0.000 MB deduped)wandb: | 0.022 MB of 0.022 MB uploaded (0.000 MB deduped)wandb: / 0.022 MB of 0.022 MB uploaded (0.000 MB deduped)wandb: - 0.022 MB of 0.022 MB uploaded (0.000 MB deduped)wandb: \ 0.022 MB of 0.022 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:                              Epoch â–â–â–â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–…â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb: Test loss t(-10, 10)_r(-5, 5)_none â–†â–†â–„â–ƒâ–ƒâ–‚â–ˆâ–ƒâ–‚â–‚â–â–ƒâ–‚â–‚â–‚â–â–â–ƒâ–â–â–‚â–â–â–ƒâ–‚â–‚â–â–â–â–â–
wandb:  Test loss t(-10, 10)_r(0, 0)_none â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    Test loss t(0, 0)_r(-5, 5)_none â–†â–‡â–„â–ƒâ–ƒâ–‚â–ˆâ–ƒâ–‚â–‚â–â–ƒâ–‚â–‚â–‚â–â–â–ƒâ–‚â–â–‚â–â–â–„â–‚â–‚â–â–â–â–â–
wandb:     Test loss t(0, 0)_r(0, 0)_none â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                         Train loss â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                              Epoch 29
wandb: Test loss t(-10, 10)_r(-5, 5)_none 0.66461
wandb:  Test loss t(-10, 10)_r(0, 0)_none 0.00361
wandb:    Test loss t(0, 0)_r(-5, 5)_none 0.61063
wandb:     Test loss t(0, 0)_r(0, 0)_none 0.00186
wandb:                         Train loss 0.01164
wandb: 
wandb: ğŸš€ View run chromatic-kumquat-1579 at: https://wandb.ai/nreints/thesis/runs/hk7oz2tl
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230127_071336-hk7oz2tl/logs
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.003612771164625883
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.6106314659118652
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.6646116971969604
It took  1121.5590226650238  seconds.

JOB STATISTICS
==============
Job ID: 2142192
Array Job ID: 2141141_14
Cluster: snellius
User/Group: nreints/nreints
State: COMPLETED (exit code 0)
Nodes: 1
Cores per node: 18
CPU Utilized: 14:39:12
CPU Efficiency: 25.93% of 2-08:30:18 core-walltime
Job Wall-clock time: 03:08:21
Memory Utilized: 25.72 GB
Memory Efficiency: 82.31% of 31.25 GB
