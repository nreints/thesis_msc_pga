/gpfs/home2/nreints/MScThesis/code/lstm.py:270: DeprecationWarning: Sampling from a set deprecated
since Python 3.9 and will be removed in a subsequent version.
  train_sims = set(random.sample(sims_train, int(0.8 * n_sims_train)))
wandb: Currently logged in as: nreints. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.13.9 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.8
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230127_034633-cuy9p06i
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vermilion-kumquat-1507
wandb: ⭐️ View project at https://wandb.ai/nreints/thesis
wandb: 🚀 View run at https://wandb.ai/nreints/thesis/runs/cuy9p06i
/home/nreints/.conda/envs/thesis/lib/python3.10/site-packages/torch/nn/modules/rnn.py:67: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  warnings.warn("dropout option adds dropout after all but last "
BEFORE ['data_t(-10,', '10)_r(0,', '0)_none']
----- ITERATION 0/10 ------
[<torch.utils.data.dataloader.DataLoader object at 0x1534bf7fff70>, <torch.utils.data.dataloader.DataLoader object at 0x1534b8b0c520>, <torch.utils.data.dataloader.DataLoader object at 0x1534b8b0c790>, <torch.utils.data.dataloader.DataLoader object at 0x1534b8b0c640>]
LSTM(
  (lstm): LSTM(8, 96, batch_first=True, dropout=0.2)
  (layers): Sequential(
    (0): Linear(in_features=96, out_features=8, bias=True)
  )
)
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.018336843699216843
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.050973281264305115
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 3.9680607318878174
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 8.389931678771973
0 1.4426756519 	 8.3899316701
epoch_time;  41.64791560173035
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.019533466547727585
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.036169059574604034
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 1.8161067962646484
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 3.852402925491333
1 0.0336971962 	 3.8524029781
epoch_time;  41.14706063270569
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.008888691663742065
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.018304917961359024
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 1.1824945211410522
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 2.4009809494018555
2 0.0235788705 	 2.4009808774
epoch_time;  40.966068744659424
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.012827095575630665
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.021480614319443703
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.7495123147964478
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 1.5407968759536743
3 0.0174163281 	 1.5407968389
epoch_time;  40.528292655944824
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.008005676791071892
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0139066893607378
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.6067282557487488
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 1.21843683719635
4 0.0139916902 	 1.218436803
epoch_time;  41.108189821243286
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0027338347863405943
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0063985539600253105
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.49176162481307983
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 1.0429779291152954
5 0.011713368 	 1.0429778776
epoch_time;  41.219712257385254
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0029094202909618616
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.006485752295702696
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.44169506430625916
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.9272093176841736
6 0.0103049412 	 0.9272093067
epoch_time;  40.656529664993286
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0029930926393717527
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.006275931838899851
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.5658082962036133
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 1.0700314044952393
7 0.0093210063 	 1.0700313879
epoch_time;  40.827179193496704
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.008850198239088058
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.014247773215174675
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.5233575701713562
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.9890885353088379
8 0.0078490681 	 0.9890885367
epoch_time;  43.21459412574768
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.028879519551992416
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.04691057279706001
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.48304763436317444
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.908880889415741
9 0.0072410296 	 0.9088808734
epoch_time;  42.605546951293945
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.00371788302436471
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.006631489377468824
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.4329524338245392
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.8344669342041016
10 0.0064234549 	 0.83446694
epoch_time;  41.94558572769165
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0020431061275303364
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.004039512947201729
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.3249149024486542
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.6482566595077515
11 0.0063185537 	 0.6482566534
epoch_time;  41.05080437660217
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.005062630865722895
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.008354884572327137
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.2721424400806427
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.487686425447464
12 0.0055972012 	 0.4876864338
epoch_time;  41.07152509689331
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0017328041139990091
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0037895238492637873
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.24567987024784088
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.4455823302268982
13 0.0050502267 	 0.4455823178
epoch_time;  41.29715323448181
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.004587329458445311
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.007172801531851292
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.2006455361843109
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.3499791920185089
14 0.0049471469 	 0.3499792047
epoch_time;  40.74260091781616
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0019092028960585594
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0037708517629653215
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.14958222210407257
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.2858036458492279
15 0.0046391372 	 0.2858036422
epoch_time;  41.111743688583374
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0041381437331438065
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.006543974857777357
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.180589497089386
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.31456953287124634
16 0.0044796115 	 0.3145695251
epoch_time;  40.50889730453491
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.001298049814067781
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.002526169177144766
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.1407814770936966
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.2493470311164856
17 0.0039001219 	 0.2493470299
epoch_time;  40.643747329711914
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.003137598978355527
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.005657680332660675
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.1678541600704193
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.26963284611701965
18 0.0044254896 	 0.2696328523
epoch_time;  41.451945781707764
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0018488739151507616
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0037079667672514915
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.12495563924312592
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.22302031517028809
19 0.0034434476 	 0.2230203173
epoch_time;  40.96588969230652
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0014830445870757103
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0029773912392556667
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.12790927290916443
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.21523872017860413
20 0.0035156287 	 0.2152387268
epoch_time;  40.933151721954346
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0011609210632741451
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.002434325870126486
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.13612942397594452
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.2666487693786621
21 0.0037530369 	 0.2666487679
epoch_time;  40.85005474090576
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0021088323555886745
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.003878762014210224
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.11634130775928497
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.19970977306365967
22 0.0033033437 	 0.1997097741
epoch_time;  40.83831787109375
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0010722270235419273
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.022 MB of 0.022 MB uploaded (0.000 MB deduped)wandb: \ 0.022 MB of 0.143 MB uploaded (0.000 MB deduped)wandb: | 0.022 MB of 0.143 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:                              Epoch ▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇███
wandb: Test loss t(-10, 10)_r(-5, 5)_none █▄▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  Test loss t(-10, 10)_r(0, 0)_none █▆▃▄▃▂▂▂▃▇▂▁▂▁▂▁▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁
wandb:    Test loss t(0, 0)_r(-5, 5)_none █▄▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     Test loss t(0, 0)_r(0, 0)_none ▅▆▃▄▃▁▂▂▃█▂▁▂▁▂▁▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁
wandb:                         Train loss █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                              Epoch 29
wandb: Test loss t(-10, 10)_r(-5, 5)_none 0.16316
wandb:  Test loss t(-10, 10)_r(0, 0)_none 0.00227
wandb:    Test loss t(0, 0)_r(-5, 5)_none 0.10383
wandb:     Test loss t(0, 0)_r(0, 0)_none 0.0012
wandb:                         Train loss 0.00274
wandb: 
wandb: 🚀 View run vermilion-kumquat-1507 at: https://wandb.ai/nreints/thesis/runs/cuy9p06i
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230127_034633-cuy9p06i/logs
/gpfs/home2/nreints/MScThesis/code/lstm.py:270: DeprecationWarning: Sampling from a set deprecated
since Python 3.9 and will be removed in a subsequent version.
  train_sims = set(random.sample(sims_train, int(0.8 * n_sims_train)))
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.13.9 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.8
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230127_040815-52ev6ld9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run twinkling-pig-1515
wandb: ⭐️ View project at https://wandb.ai/nreints/thesis
wandb: 🚀 View run at https://wandb.ai/nreints/thesis/runs/52ev6ld9
/home/nreints/.conda/envs/thesis/lib/python3.10/site-packages/torch/nn/modules/rnn.py:67: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  warnings.warn("dropout option adds dropout after all but last "
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.002152018714696169
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.09900487959384918
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.17971354722976685
23 0.0032013367 	 0.179713546
epoch_time;  40.73090744018555
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.000846714130602777
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.001753196120262146
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.10049452632665634
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.16367124021053314
24 0.0032612301 	 0.1636712342
epoch_time;  40.46781516075134
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0012514371192082763
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.002275742357596755
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.10173201560974121
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.16532844305038452
25 0.0027688228 	 0.1653284494
epoch_time;  41.139055252075195
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.002353644696995616
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0036499742418527603
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.10169890522956848
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.16001635789871216
26 0.002941566 	 0.1600163509
epoch_time;  40.74651837348938
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.000832650694064796
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0016606993740424514
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.09391409903764725
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.15145108103752136
27 0.0029775349 	 0.1514510763
epoch_time;  40.68844485282898
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0014829603023827076
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.002869264455512166
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.09434214979410172
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.1483072191476822
28 0.0027925322 	 0.1483072241
epoch_time;  41.0601282119751
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0011988343903794885
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.002268478274345398
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.10380912572145462
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.16317665576934814
29 0.0027444965 	 0.1631766489
epoch_time;  40.91349220275879
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0011989944614470005
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0022680151741951704
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.10383184999227524
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.16315819323062897
It took  1302.9260475635529  seconds.
----- ITERATION 1/10 ------
[<torch.utils.data.dataloader.DataLoader object at 0x1534bf7fff70>, <torch.utils.data.dataloader.DataLoader object at 0x15348f5a89a0>, <torch.utils.data.dataloader.DataLoader object at 0x15348f5a89d0>, <torch.utils.data.dataloader.DataLoader object at 0x15348f078370>]
LSTM(
  (lstm): LSTM(8, 96, batch_first=True, dropout=0.2)
  (layers): Sequential(
    (0): Linear(in_features=96, out_features=8, bias=True)
  )
)
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.014131024479866028
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.05390104278922081
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 4.882951736450195
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 10.82554817199707
0 1.5581050991 	 10.8255478781
epoch_time;  43.73999094963074
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.009366123005747795
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.02919945679605007
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 2.9687602519989014
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 6.215279579162598
1 0.0343845925 	 6.2152796627
epoch_time;  41.35176062583923
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.006501524709165096
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.017205536365509033
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 2.196533441543579
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 4.143446922302246
2 0.0234328594 	 4.1434470001
epoch_time;  40.69149899482727
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.014742264524102211
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.028775393962860107
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 2.189159393310547
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 4.061825275421143
3 0.0171576059 	 4.0618251098
epoch_time;  41.97183275222778
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.004156733397394419
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.009901611134409904
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 1.55214262008667
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 2.8982155323028564
4 0.0139286538 	 2.8982154869
epoch_time;  40.850698471069336
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.00889883004128933
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.016833659261465073
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 1.3396753072738647
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 2.6494486331939697
5 0.0113175108 	 2.649448729
epoch_time;  41.357850551605225
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0066954707726836205
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.012465422041714191
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.41661545634269714
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.895621657371521
6 0.0126467885 	 0.8956216772
epoch_time;  40.788774490356445
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.008366427384316921
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.014438826590776443
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.4318276345729828
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.9172963500022888
7 0.0084475879 	 0.9172963491
epoch_time;  41.16657042503357
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0071993255987763405
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.01196600217372179
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.42281895875930786
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.9656365513801575
8 0.0074511044 	 0.9656365616
epoch_time;  40.62377953529358
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0022465847432613373
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0050776260904967785
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.42188695073127747
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.9966601133346558
9 0.007021268 	 0.9966601231
epoch_time;  40.729777574539185
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.001969454111531377
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.004693745635449886
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.3317410945892334
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.8297863006591797
10 0.0064270653 	 0.8297863179
epoch_time;  40.53829526901245
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.003105855081230402
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.005945812910795212
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.32194024324417114
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.8497241735458374
11 0.0056369671 	 0.8497241617
epoch_time;  40.88165736198425
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.00600438192486763
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.010046700946986675
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.2513178884983063
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.6032006144523621
12 0.005265381 	 0.6032006301
epoch_time;  40.790894508361816
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0020319658797234297
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.004414169117808342
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.2687937021255493
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.6647056341171265
13 0.0050585647 	 0.664705628
epoch_time;  40.86809945106506
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0016433236887678504
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0038426013197749853
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.2693836987018585
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.7092133164405823
14 0.0048108072 	 0.7092133029
epoch_time;  41.45748019218445
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.002202713629230857
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.004363776184618473
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.24645498394966125
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                              Epoch ▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇███
wandb: Test loss t(-10, 10)_r(-5, 5)_none █▅▄▄▃▃▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  Test loss t(-10, 10)_r(0, 0)_none █▅▃▅▂▃▂▃▂▁▁▂▂▁▁▁▁▁▁▁▂▁▂▁▁▁▁▁▁▁▁
wandb:    Test loss t(0, 0)_r(-5, 5)_none █▅▄▄▃▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     Test loss t(0, 0)_r(0, 0)_none █▅▄█▃▅▄▅▄▂▂▂▄▂▁▂▂▂▁▁▄▂▄▂▂▂▁▁▁▁▁
wandb:                         Train loss █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                              Epoch 29
wandb: Test loss t(-10, 10)_r(-5, 5)_none 0.22201
wandb:  Test loss t(-10, 10)_r(0, 0)_none 0.00194
wandb:    Test loss t(0, 0)_r(-5, 5)_none 0.09794
wandb:     Test loss t(0, 0)_r(0, 0)_none 0.00096
wandb:                         Train loss 0.00257
wandb: 
wandb: 🚀 View run twinkling-pig-1515 at: https://wandb.ai/nreints/thesis/runs/52ev6ld9
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230127_040815-52ev6ld9/logs
/gpfs/home2/nreints/MScThesis/code/lstm.py:270: DeprecationWarning: Sampling from a set deprecated
since Python 3.9 and will be removed in a subsequent version.
  train_sims = set(random.sample(sims_train, int(0.8 * n_sims_train)))
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.13.9 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.8
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230127_042957-8cq2jkt0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run alight-rabbit-1522
wandb: ⭐️ View project at https://wandb.ai/nreints/thesis
wandb: 🚀 View run at https://wandb.ai/nreints/thesis/runs/8cq2jkt0
/home/nreints/.conda/envs/thesis/lib/python3.10/site-packages/torch/nn/modules/rnn.py:67: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  warnings.warn("dropout option adds dropout after all but last "
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.624118983745575
15 0.0049425493 	 0.6241189548
epoch_time;  41.406858682632446
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0020234279800206423
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.004114339128136635
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.2157728374004364
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.5147838592529297
16 0.0037860434 	 0.5147838765
epoch_time;  41.082157611846924
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.003223659470677376
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.005630819126963615
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.2564770579338074
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.585371732711792
17 0.0040625219 	 0.5853717262
epoch_time;  40.926146268844604
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0010429995600134134
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0023600684944540262
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.1482318639755249
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.3169505000114441
18 0.0040415295 	 0.3169504955
epoch_time;  40.82231116294861
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.000990977743640542
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0024101040326058865
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.14428330957889557
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.31759318709373474
19 0.0034476716 	 0.3175931856
epoch_time;  40.9970281124115
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.005952779669314623
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.009406580589711666
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.1504974067211151
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.30348801612854004
20 0.0035698037 	 0.3034880255
epoch_time;  41.41674876213074
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0027653216384351254
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.005150101613253355
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.14030428230762482
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.28690803050994873
21 0.0032856939 	 0.2869080374
epoch_time;  43.5124785900116
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0061960117891430855
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.010296083055436611
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.14518806338310242
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.31181707978248596
22 0.0032801928 	 0.3118170655
epoch_time;  42.16610503196716
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0022896109148859978
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0038785517681390047
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.12048117071390152
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.2532758116722107
23 0.003082449 	 0.2532757992
epoch_time;  40.91298866271973
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0021214361768215895
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0038429247215390205
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.11981677263975143
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.26420190930366516
24 0.0029761255 	 0.264201922
epoch_time;  40.76251459121704
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.003010061103850603
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.004914198070764542
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.11551719158887863
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.2508447766304016
25 0.0031346152 	 0.2508447883
epoch_time;  41.07782983779907
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0011164196766912937
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0022391548845916986
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.10690588504076004
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.24315589666366577
26 0.0026750422 	 0.243155903
epoch_time;  41.04191780090332
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0014168241759762168
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0027134160045534372
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.10931544005870819
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.24765950441360474
27 0.0027085957 	 0.2476595046
epoch_time;  41.19823908805847
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.001817750628106296
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.003233290510252118
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.1020752489566803
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.22310727834701538
28 0.0027804265 	 0.2231072832
epoch_time;  40.885448694229126
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0009603513753972948
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0019365495536476374
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.09782756865024567
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.2222052812576294
29 0.0025660151 	 0.2222052859
epoch_time;  40.942036390304565
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0009602818172425032
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.001936719287186861
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.09793898463249207
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.22201164066791534
It took  1301.828238248825  seconds.
----- ITERATION 2/10 ------
[<torch.utils.data.dataloader.DataLoader object at 0x15348f55e530>, <torch.utils.data.dataloader.DataLoader object at 0x1534b92ad330>, <torch.utils.data.dataloader.DataLoader object at 0x1534b92aed10>, <torch.utils.data.dataloader.DataLoader object at 0x1534b92aeec0>]
LSTM(
  (lstm): LSTM(8, 96, batch_first=True, dropout=0.2)
  (layers): Sequential(
    (0): Linear(in_features=96, out_features=8, bias=True)
  )
)
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.013713088817894459
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.03503701463341713
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 3.7380683422088623
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 7.399234294891357
0 1.4959567097 	 7.3992340918
epoch_time;  41.30980944633484
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.017070172354578972
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.031296201050281525
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 1.596566081047058
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 3.35371732711792
1 0.0347955113 	 3.3537173545
epoch_time;  40.95354676246643
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.006157796364277601
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.012576406821608543
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.8712210655212402
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 1.914814829826355
2 0.0229039347 	 1.9148148367
epoch_time;  42.08538317680359
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.004087689332664013
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.008535243570804596
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.5716328024864197
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 1.2398350238800049
3 0.0174901285 	 1.2398349727
epoch_time;  40.660285234451294
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0030106445774435997
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.006148549262434244
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.39742833375930786
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.895677924156189
4 0.0134290541 	 0.895677918
epoch_time;  40.54879307746887
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.008892602287232876
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.014196859672665596
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.297087162733078
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.6647542715072632
5 0.0112806063 	 0.6647542625
epoch_time;  40.624849796295166
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.008154426701366901
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.012284274213016033
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.23509785532951355
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.5016187429428101
6 0.0100010952 	 0.5016187224
epoch_time;  40.572553634643555
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.002749613719061017
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.005763955879956484
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.2064073383808136
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.431118369102478
7 0.0084470847 	 0.4311183687
epoch_time;  40.56511974334717
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                              Epoch ▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇███
wandb: Test loss t(-10, 10)_r(-5, 5)_none █▄▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  Test loss t(-10, 10)_r(0, 0)_none █▇▃▂▂▄▃▂▂▂▁▂▂▂▁▁▁▁▁▁▁▂▂▁▁▂▁▂▁▁▁
wandb:    Test loss t(0, 0)_r(-5, 5)_none █▄▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     Test loss t(0, 0)_r(0, 0)_none ▇█▃▂▂▄▄▂▂▂▁▂▂▂▂▂▁▂▁▁▁▂▃▁▁▂▁▂▁▁▁
wandb:                         Train loss █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                              Epoch 29
wandb: Test loss t(-10, 10)_r(-5, 5)_none 0.14235
wandb:  Test loss t(-10, 10)_r(0, 0)_none 0.0018
wandb:    Test loss t(0, 0)_r(-5, 5)_none 0.07903
wandb:     Test loss t(0, 0)_r(0, 0)_none 0.00091
wandb:                         Train loss 0.00269
wandb: 
wandb: 🚀 View run alight-rabbit-1522 at: https://wandb.ai/nreints/thesis/runs/8cq2jkt0
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230127_042957-8cq2jkt0/logs
/gpfs/home2/nreints/MScThesis/code/lstm.py:270: DeprecationWarning: Sampling from a set deprecated
since Python 3.9 and will be removed in a subsequent version.
  train_sims = set(random.sample(sims_train, int(0.8 * n_sims_train)))
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.13.9 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.8
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230127_045130-sqlu17l9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run prosperous-lantern-1531
wandb: ⭐️ View project at https://wandb.ai/nreints/thesis
wandb: 🚀 View run at https://wandb.ai/nreints/thesis/runs/sqlu17l9
/home/nreints/.conda/envs/thesis/lib/python3.10/site-packages/torch/nn/modules/rnn.py:67: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  warnings.warn("dropout option adds dropout after all but last "
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0021424766164273024
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.004305535461753607
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.18578189611434937
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.36134007573127747
8 0.0075402617 	 0.3613400647
epoch_time;  40.61502528190613
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0024212913122028112
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.004950789734721184
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.19398902356624603
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.3442578613758087
9 0.0069840256 	 0.3442578503
epoch_time;  40.55891990661621
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.001657074666582048
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.00305254478007555
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.14717325568199158
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.2798846364021301
10 0.0061640086 	 0.279884638
epoch_time;  40.74241352081299
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.00212826463393867
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.004059331025928259
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.13664157688617706
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.2514142692089081
11 0.0055375568 	 0.2514142731
epoch_time;  42.78923678398132
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0023564144503325224
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.004414568655192852
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.1435958594083786
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.24846133589744568
12 0.0051251367 	 0.2484613286
epoch_time;  42.02786922454834
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.002817202126607299
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.004784674383699894
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.12190352380275726
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.2188875377178192
13 0.0050861617 	 0.2188875365
epoch_time;  41.2174859046936
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.002040487714111805
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0035598159302026033
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.11497938632965088
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.20624789595603943
14 0.0043983961 	 0.2062478887
epoch_time;  40.902374029159546
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0021165998186916113
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0033393162302672863
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.1083492636680603
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.19530896842479706
15 0.004267533 	 0.1953089734
epoch_time;  40.65450882911682
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0019801941234618425
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0039136637933552265
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.10350243747234344
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.18762856721878052
16 0.0040604186 	 0.1876285703
epoch_time;  40.792861461639404
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0020262456964701414
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0036363385152071714
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.09940660744905472
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.17883950471878052
17 0.0040423302 	 0.1788395078
epoch_time;  40.814129114151
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0009386850870214403
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0017372373258695006
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0848102942109108
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.15790024399757385
18 0.0037261785 	 0.1579002426
epoch_time;  40.60034370422363
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0009420290589332581
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0017789836274459958
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.08104176819324493
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.15533466637134552
19 0.0034092857 	 0.1553346686
epoch_time;  40.567404985427856
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0012789344182237983
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0024880715645849705
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.08245374262332916
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.15639618039131165
20 0.0033749408 	 0.1563961801
epoch_time;  40.900073528289795
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.003554818220436573
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0060469103045761585
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.08908664435148239
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.16488777101039886
21 0.0034260313 	 0.1648877769
epoch_time;  40.808758020401
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.005003868602216244
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.00839062500745058
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.09584885835647583
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.1673276573419571
22 0.0030789426 	 0.1673276504
epoch_time;  40.95371437072754
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0019635490607470274
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.003196119796484709
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.07869963347911835
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.14372596144676208
23 0.002975429 	 0.143725957
epoch_time;  41.05977416038513
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0017707556253299117
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0028573956806212664
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.08666624873876572
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.1545453816652298
24 0.0028754593 	 0.1545453835
epoch_time;  40.85303974151611
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.004012526944279671
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.005822128150612116
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0738881453871727
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.13670730590820312
25 0.0028158113 	 0.1367073059
epoch_time;  41.040714502334595
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.001465712790377438
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0025677126832306385
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.07457359880208969
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.13655565679073334
26 0.0028208791 	 0.1365556515
epoch_time;  40.836405515670776
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.003114511491730809
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.005140294320881367
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.07656547427177429
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.13901400566101074
27 0.002688566 	 0.1390140107
epoch_time;  40.86991214752197
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0008668482769280672
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0016257638344541192
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.07975801825523376
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.1471356898546219
28 0.0024733069 	 0.1471356856
epoch_time;  40.80739712715149
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0009061892051249743
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0017987930914387107
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0789574459195137
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.1425003558397293
29 0.0026862663 	 0.1425003559
epoch_time;  40.91552758216858
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0009067034116014838
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0017995000816881657
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.07902950048446655
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.14234669506549835
It took  1292.9098274707794  seconds.
----- ITERATION 3/10 ------
[<torch.utils.data.dataloader.DataLoader object at 0x1534b92eb1c0>, <torch.utils.data.dataloader.DataLoader object at 0x15348f55f280>, <torch.utils.data.dataloader.DataLoader object at 0x1534b9296da0>, <torch.utils.data.dataloader.DataLoader object at 0x1534b9296f20>]
LSTM(
  (lstm): LSTM(8, 96, batch_first=True, dropout=0.2)
  (layers): Sequential(
    (0): Linear(in_features=96, out_features=8, bias=True)
  )
)
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.021792937070131302
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.059414591640233994
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 2.9816529750823975
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 6.8741583824157715
0 1.4369099781 	 6.8741584155
epoch_time;  40.705047845840454
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.008836761116981506
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.02572333626449108
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 1.458799123764038
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 3.6227664947509766
1 0.0318300477 	 3.6227665927
epoch_time;  40.916287660598755
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.004523513372987509
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.014164010062813759
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.9659194946289062
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 2.483105182647705
2 0.0216371058 	 2.4831052475
epoch_time;  42.622782468795776
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.014968384988605976
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.02513871341943741
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.6990538239479065
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 1.8846648931503296
3 0.0162527935 	 1.8846649447
epoch_time;  41.31168985366821
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.006366230081766844
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.012248490005731583
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.41039642691612244
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 1.079398512840271
4 0.0128411734 	 1.0793985326
epoch_time;  41.05866312980652
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0029606232419610023
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.007393992505967617
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.30537229776382446
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.8017967343330383
5 0.010898876 	 0.8017967201
epoch_time;  40.916512966156006
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0023359290789812803
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.005365461576730013
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.2554601728916168
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.6498377919197083
6 0.009253852 	 0.6498378051
epoch_time;  40.796982288360596
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.01207663118839264
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.020292557775974274
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.2133057713508606
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.499815970659256
7 0.0082133046 	 0.4998159726
epoch_time;  41.16298770904541
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.00185990403406322
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.004343120846897364
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.1953754872083664
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.4268245995044708
8 0.0072073341 	 0.42682461
epoch_time;  40.976162910461426
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.002071768045425415
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.004333985969424248
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.17038266360759735
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.37177035212516785
9 0.0066935267 	 0.3717703459
epoch_time;  41.00271534919739
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0021320683881640434
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.004456976894289255
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.1540810465812683
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.32424822449684143
10 0.0059803169 	 0.3242482303
epoch_time;  40.67346811294556
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.004431202542036772
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.007869661785662174
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.15197284519672394
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.30503225326538086
11 0.0055465276 	 0.3050322518
epoch_time;  41.11532783508301
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.005676707718521357
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.008890235796570778
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.1447429209947586
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.2810673117637634
12 0.0050517421 	 0.2810673094
epoch_time;  41.24477434158325
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0017388567794114351
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.004015246406197548
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.1457587480545044
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.2914053499698639
13 0.0051745683 	 0.2914053465
epoch_time;  41.474706411361694
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.001809406909160316
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0036163150798529387
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.1365220993757248
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.257993221282959
14 0.0043627275 	 0.2579932314
epoch_time;  41.39795160293579
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.004990956746041775
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.008684055879712105
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.12310219556093216
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.2417578399181366
15 0.0042030347 	 0.2417578337
epoch_time;  41.438448667526245
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0008919502724893391
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0021235421299934387
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.11087431758642197
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.2071792036294937
16 0.0040016228 	 0.2071792049
epoch_time;  41.194501638412476
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.004668454173952341
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.007903138175606728
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.10397635400295258
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.19674435257911682
17 0.0038354936 	 0.1967443599
epoch_time;  40.82782196998596
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0006810150225646794
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0016155510675162077
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.09796155244112015
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.18741005659103394
18 0.0035775294 	 0.1874100492
epoch_time;  41.05925917625427
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0012662631925195456
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0025774782989174128
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.09654764831066132
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.18025855720043182
19 0.0035913779 	 0.1802585636
epoch_time;  41.210697412490845
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0012424240121617913
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.002494038315489888
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.09751158952713013
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.18423718214035034
20 0.0032973336 	 0.1842371892
epoch_time;  40.74410891532898
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0009398733382113278
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0019446279620751739
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.08981367945671082
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.16962328553199768
21 0.0033320323 	 0.1696232914
epoch_time;  40.64671540260315
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0012267768615856767
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.002633877797052264
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.08597444742918015
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.16414275765419006
22 0.002948863 	 0.1641427585
epoch_time;  40.70620894432068
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0016510664718225598
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.003070960519835353
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.09018663316965103
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.17244362831115723
23 0.0031666167 	 0.1724436319
epoch_time;  42.518073081970215
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0050551448948681355
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.00867806002497673
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.09672031551599503
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.19711382687091827
24 0.002769235 	 0.1971138208
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.022 MB of 0.022 MB uploaded (0.000 MB deduped)wandb: \ 0.022 MB of 0.022 MB uploaded (0.000 MB deduped)wandb: | 0.022 MB of 0.022 MB uploaded (0.000 MB deduped)wandb: / 0.022 MB of 0.022 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:                              Epoch ▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇███
wandb: Test loss t(-10, 10)_r(-5, 5)_none █▅▃▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  Test loss t(-10, 10)_r(0, 0)_none █▄▃▄▂▂▁▃▁▁▁▂▂▁▁▂▁▂▁▁▁▁▁▁▂▁▁▁▁▁▁
wandb:    Test loss t(0, 0)_r(-5, 5)_none █▄▃▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     Test loss t(0, 0)_r(0, 0)_none █▄▂▆▃▂▂▅▁▁▁▂▃▁▁▂▁▂▁▁▁▁▁▁▂▁▁▂▁▂▂
wandb:                         Train loss █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                              Epoch 29
wandb: Test loss t(-10, 10)_r(-5, 5)_none 0.15403
wandb:  Test loss t(-10, 10)_r(0, 0)_none 0.00446
wandb:    Test loss t(0, 0)_r(-5, 5)_none 0.07285
wandb:     Test loss t(0, 0)_r(0, 0)_none 0.00295
wandb:                         Train loss 0.00251
wandb: 
wandb: 🚀 View run prosperous-lantern-1531 at: https://wandb.ai/nreints/thesis/runs/sqlu17l9
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230127_045130-sqlu17l9/logs
/gpfs/home2/nreints/MScThesis/code/lstm.py:270: DeprecationWarning: Sampling from a set deprecated
since Python 3.9 and will be removed in a subsequent version.
  train_sims = set(random.sample(sims_train, int(0.8 * n_sims_train)))
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.13.9 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.8
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230127_051306-8uysor89
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lunar-fireworks-1538
wandb: ⭐️ View project at https://wandb.ai/nreints/thesis
wandb: 🚀 View run at https://wandb.ai/nreints/thesis/runs/8uysor89
/home/nreints/.conda/envs/thesis/lib/python3.10/site-packages/torch/nn/modules/rnn.py:67: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  warnings.warn("dropout option adds dropout after all but last "
epoch_time;  42.69460678100586
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0021550150122493505
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.003880122909322381
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0818595215678215
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.16810853779315948
25 0.0028679017 	 0.1681085339
epoch_time;  41.47808814048767
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0020223113242536783
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0034575648605823517
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0926889106631279
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.18429534137248993
26 0.0027671575 	 0.1842953431
epoch_time;  40.990957736968994
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.00259879301302135
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0046358429826796055
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.10058269649744034
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.21231935918331146
27 0.0025034263 	 0.2123193654
epoch_time;  40.99453520774841
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0013730665668845177
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0022826255299150944
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.08344542235136032
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.1729903519153595
28 0.0026188021 	 0.1729903552
epoch_time;  40.63507413864136
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.002947585191577673
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.004466456826776266
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.07278388738632202
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.15418961644172668
29 0.0025136301 	 0.154189614
epoch_time;  41.43775129318237
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0029464566614478827
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.004462487064301968
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.07285480201244354
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.1540335863828659
It took  1295.4801988601685  seconds.
----- ITERATION 4/10 ------
[<torch.utils.data.dataloader.DataLoader object at 0x1534b92950f0>, <torch.utils.data.dataloader.DataLoader object at 0x1534b8b0e9e0>, <torch.utils.data.dataloader.DataLoader object at 0x1534b8b0e9b0>, <torch.utils.data.dataloader.DataLoader object at 0x15348f55ec20>]
LSTM(
  (lstm): LSTM(8, 96, batch_first=True, dropout=0.2)
  (layers): Sequential(
    (0): Linear(in_features=96, out_features=8, bias=True)
  )
)
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.2109295278787613
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.3102979063987732
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 11.734950065612793
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 20.55441665649414
0 3.0818172342 	 20.5544175439
epoch_time;  41.12797141075134
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.09747761487960815
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.14732055366039276
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 8.234375
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 16.134355545043945
1 0.2009173385 	 16.1343555278
epoch_time;  41.18725109100342
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.017812853679060936
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.03891722112894058
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 4.239624977111816
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 9.113275527954102
2 0.0625042103 	 9.1132753493
epoch_time;  41.23050546646118
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0069485739804804325
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.01882115565240383
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 2.957401990890503
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 6.613337516784668
3 0.0289771133 	 6.6133373065
epoch_time;  40.94133901596069
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0207437202334404
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.03181666135787964
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 1.765264630317688
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 4.101981163024902
4 0.0193867319 	 4.1019810795
epoch_time;  41.102426528930664
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.006935819052159786
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.013870608061552048
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 1.045716404914856
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 2.5296835899353027
5 0.0165673183 	 2.5296835539
epoch_time;  41.23396301269531
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.00403453316539526
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.008549841120839119
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.5471270680427551
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 1.250529170036316
6 0.0139146873 	 1.2505292172
epoch_time;  40.83369445800781
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.005001865327358246
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.009780450724065304
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.36964577436447144
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.7794015407562256
7 0.0116994953 	 0.7794015199
epoch_time;  41.12753105163574
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.011195079423487186
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.01761891134083271
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.28202497959136963
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.527780294418335
8 0.0108857577 	 0.5277803081
epoch_time;  40.99712085723877
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0048082550056278706
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.008459402248263359
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.23542119562625885
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.4671350121498108
9 0.0092298925 	 0.4671350116
epoch_time;  41.36059641838074
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.004355494864284992
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.009006083942949772
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.2001347541809082
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.4033619463443756
10 0.0089070005 	 0.40336194
epoch_time;  41.04573702812195
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.009394478984177113
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.014073553495109081
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.19559308886528015
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.4120270013809204
11 0.0080609737 	 0.412026996
epoch_time;  40.81170463562012
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.006308310199528933
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.011310924775898457
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.19992052018642426
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.37981176376342773
12 0.0077367923 	 0.3798117508
epoch_time;  41.144866704940796
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0036026688758283854
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.006375965196639299
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.18449848890304565
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.35243192315101624
13 0.0068852896 	 0.3524319283
epoch_time;  41.1306426525116
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.004101833328604698
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0072173625230789185
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.175282821059227
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.3468318283557892
14 0.0067085877 	 0.3468318144
epoch_time;  43.103342056274414
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.003299487056210637
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.006395277101546526
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.1868172585964203
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.36627262830734253
15 0.0060850507 	 0.3662726411
epoch_time;  41.893550872802734
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.004076694138348103
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.007048328872770071
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.17514336109161377
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.33097952604293823
16 0.0060097996 	 0.330979523
epoch_time;  40.70249366760254
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.002068175468593836
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.004579265136271715
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                              Epoch ▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇███
wandb: Test loss t(-10, 10)_r(-5, 5)_none █▆▄▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  Test loss t(-10, 10)_r(0, 0)_none █▄▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁
wandb:    Test loss t(0, 0)_r(-5, 5)_none █▆▃▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     Test loss t(0, 0)_r(0, 0)_none █▄▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁
wandb:                         Train loss █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                              Epoch 29
wandb: Test loss t(-10, 10)_r(-5, 5)_none 0.27004
wandb:  Test loss t(-10, 10)_r(0, 0)_none 0.00309
wandb:    Test loss t(0, 0)_r(-5, 5)_none 0.14813
wandb:     Test loss t(0, 0)_r(0, 0)_none 0.00135
wandb:                         Train loss 0.00369
wandb: 
wandb: 🚀 View run lunar-fireworks-1538 at: https://wandb.ai/nreints/thesis/runs/8uysor89
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230127_051306-8uysor89/logs
/gpfs/home2/nreints/MScThesis/code/lstm.py:270: DeprecationWarning: Sampling from a set deprecated
since Python 3.9 and will be removed in a subsequent version.
  train_sims = set(random.sample(sims_train, int(0.8 * n_sims_train)))
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: wandb version 0.13.9 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.8
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230127_053441-o5buzbr4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glittering-fish-1545
wandb: ⭐️ View project at https://wandb.ai/nreints/thesis
wandb: 🚀 View run at https://wandb.ai/nreints/thesis/runs/o5buzbr4
/home/nreints/.conda/envs/thesis/lib/python3.10/site-packages/torch/nn/modules/rnn.py:67: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  warnings.warn("dropout option adds dropout after all but last "
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.1721898466348648
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.32531845569610596
17 0.0055521049 	 0.3253184661
epoch_time;  40.795156478881836
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0014446296263486147
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.00373837910592556
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.17873771488666534
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.33911919593811035
18 0.0053083072 	 0.339119188
epoch_time;  40.88440656661987
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0025501640047878027
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0049654822796583176
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.1744510978460312
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.33791816234588623
19 0.0056395628 	 0.3379181692
epoch_time;  40.70396971702576
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0020509310998022556
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.003991731908172369
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.17102308571338654
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.3143923282623291
20 0.0044694965 	 0.3143923203
epoch_time;  40.682626485824585
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.00996872317045927
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.015281374566257
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.17144563794136047
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.32417160272598267
21 0.0047437493 	 0.3241716137
epoch_time;  41.212005376815796
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0013778952416032553
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.003326541045680642
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.19067750871181488
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.3444455862045288
22 0.0044935 	 0.3444455887
epoch_time;  40.61976456642151
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0030997542198747396
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.005582380574196577
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.1766040027141571
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.31998851895332336
23 0.0043053486 	 0.3199885158
epoch_time;  40.72707676887512
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.020425228402018547
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.02736191637814045
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.1883256882429123
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.3367975354194641
24 0.0042649756 	 0.3367975471
epoch_time;  40.85202980041504
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.002778204157948494
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.004966480191797018
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.18107882142066956
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.3183608651161194
25 0.0040081441 	 0.3183608732
epoch_time;  41.34493660926819
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.004243150819092989
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.006653107702732086
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.15963539481163025
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.2899973392486572
26 0.003990613 	 0.2899973429
epoch_time;  41.29363560676575
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.001829130807891488
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.00373451947234571
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.16441942751407623
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.2894798517227173
27 0.0038282126 	 0.2894798578
epoch_time;  41.30565047264099
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0023921323008835316
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0046342299319803715
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.15930673480033875
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.28775930404663086
28 0.0036367367 	 0.2877593026
epoch_time;  41.4212920665741
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0013526097172871232
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0030849790200591087
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.14826807379722595
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.2694859206676483
29 0.0036880755 	 0.2694859346
epoch_time;  41.352582693099976
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0013523409143090248
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0030862127896398306
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.14812959730625153
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.27003973722457886
It took  1295.3127105236053  seconds.
----- ITERATION 5/10 ------
[<torch.utils.data.dataloader.DataLoader object at 0x1534b8b0f1f0>, <torch.utils.data.dataloader.DataLoader object at 0x1534b92a1390>, <torch.utils.data.dataloader.DataLoader object at 0x1534b92a2d70>, <torch.utils.data.dataloader.DataLoader object at 0x1534b92a2f20>]
LSTM(
  (lstm): LSTM(8, 96, batch_first=True, dropout=0.2)
  (layers): Sequential(
    (0): Linear(in_features=96, out_features=8, bias=True)
  )
)
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.015287673100829124
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0807916447520256
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 3.7737746238708496
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 8.753424644470215
0 1.6365302387 	 8.753424607
epoch_time;  41.449185371398926
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.009804452769458294
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.044290486723184586
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 1.799583077430725
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 3.992680549621582
1 0.0324933603 	 3.9926805756
epoch_time;  41.110300064086914
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.00565838348120451
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.027879899367690086
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 1.15445077419281
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 2.4246444702148438
2 0.0219781487 	 2.4246444472
epoch_time;  40.74952793121338
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.008994938805699348
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.02574395388364792
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.8750558495521545
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 1.7892448902130127
3 0.0174785039 	 1.7892448679
epoch_time;  40.864739418029785
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.010668390430510044
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.029140202328562737
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.6285191774368286
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 1.3411824703216553
4 0.0137241257 	 1.3411824667
epoch_time;  43.07208204269409
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.00393754243850708
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.012985305860638618
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.49570873379707336
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 1.0886636972427368
5 0.0113288618 	 1.0886637062
epoch_time;  42.10636377334595
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.006364590488374233
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.015332641080021858
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.39929652214050293
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.8920069336891174
6 0.0093653316 	 0.8920069576
epoch_time;  40.66736173629761
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.00817152764648199
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.01755724847316742
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.30847421288490295
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.6938304305076599
7 0.0084521765 	 0.6938304152
epoch_time;  40.75190472602844
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.009211276657879353
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.018542833626270294
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.2836207449436188
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.6189473271369934
8 0.0075138281 	 0.6189473316
epoch_time;  40.661826848983765
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0023033302277326584
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.007919221185147762
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.2520429491996765
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.5720987319946289
9 0.0068119859 	 0.5720987464
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                              Epoch ▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇███
wandb: Test loss t(-10, 10)_r(-5, 5)_none █▄▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  Test loss t(-10, 10)_r(0, 0)_none █▅▃▃▃▂▂▂▂▁▁▂▁▁▂▁▁▁▃▁▁▁▁▁▁▁▁▁▁▁▁
wandb:    Test loss t(0, 0)_r(-5, 5)_none █▄▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     Test loss t(0, 0)_r(0, 0)_none █▅▃▅▆▃▄▅▅▂▂▅▁▂▃▁▁▁▆▁▁▁▁▁▁▂▁▁▁▁▁
wandb:                         Train loss █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                              Epoch 29
wandb: Test loss t(-10, 10)_r(-5, 5)_none 0.22174
wandb:  Test loss t(-10, 10)_r(0, 0)_none 0.00255
wandb:    Test loss t(0, 0)_r(-5, 5)_none 0.10949
wandb:     Test loss t(0, 0)_r(0, 0)_none 0.00084
wandb:                         Train loss 0.00262
wandb: 
wandb: 🚀 View run glittering-fish-1545 at: https://wandb.ai/nreints/thesis/runs/o5buzbr4
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230127_053441-o5buzbr4/logs
/gpfs/home2/nreints/MScThesis/code/lstm.py:270: DeprecationWarning: Sampling from a set deprecated
since Python 3.9 and will be removed in a subsequent version.
  train_sims = set(random.sample(sims_train, int(0.8 * n_sims_train)))
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.13.9 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.8
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230127_055620-x74osiau
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cheerful-envelope-1552
wandb: ⭐️ View project at https://wandb.ai/nreints/thesis
wandb: 🚀 View run at https://wandb.ai/nreints/thesis/runs/x74osiau
/home/nreints/.conda/envs/thesis/lib/python3.10/site-packages/torch/nn/modules/rnn.py:67: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  warnings.warn("dropout option adds dropout after all but last "
epoch_time;  40.70023036003113
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.002093753544613719
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.00783194974064827
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.2372923046350479
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.5121641159057617
10 0.0059079532 	 0.512164113
epoch_time;  40.92788100242615
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.008790912106633186
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.016497809439897537
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.19738014042377472
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.44121304154396057
11 0.0055442856 	 0.4412130488
epoch_time;  41.03619694709778
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0012092716060578823
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.005052066408097744
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.18681231141090393
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.4018945097923279
12 0.0054600995 	 0.4018945147
epoch_time;  40.53224492073059
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.001975078135728836
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0058246152475476265
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.1693490892648697
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.371246337890625
13 0.0046295333 	 0.3712463379
epoch_time;  40.65847849845886
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.005078514572232962
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.010794251225888729
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.16100482642650604
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.34040817618370056
14 0.0045665814 	 0.3404081638
epoch_time;  40.9850697517395
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0016512618167325854
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.005233018659055233
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.15137115120887756
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.32618317008018494
15 0.0044177198 	 0.3261831693
epoch_time;  40.68886661529541
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0009082886390388012
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.003832127433270216
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.1382068544626236
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.3015337586402893
16 0.0041280977 	 0.3015337711
epoch_time;  40.82071876525879
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0011480101384222507
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.004056688863784075
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.13776926696300507
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.2943870425224304
17 0.0040006157 	 0.2943870567
epoch_time;  40.90732502937317
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.01118380855768919
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.020229414105415344
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.1581101268529892
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.30752238631248474
18 0.0039181644 	 0.3075223848
epoch_time;  40.93251061439514
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0014433282194659114
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.004413213115185499
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.12889641523361206
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.26504188776016235
19 0.0036630533 	 0.265041893
epoch_time;  41.28834104537964
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0010236557573080063
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0038278980646282434
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.12706056237220764
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.2713427245616913
20 0.0036395489 	 0.2713427356
epoch_time;  40.80124044418335
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0013286982430145144
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0037479118909686804
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.1293908953666687
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.2597333788871765
21 0.0031690666 	 0.2597333787
epoch_time;  40.63487458229065
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0008801514632068574
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0030150534585118294
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.11494331806898117
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.23495781421661377
22 0.0031765671 	 0.2349578074
epoch_time;  40.962547063827515
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0017137740505859256
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.004281359724700451
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.10597044974565506
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.22321012616157532
23 0.00300551 	 0.2232101302
epoch_time;  40.936306953430176
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0007490761927329004
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0028606874402612448
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.10895109921693802
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.22885198891162872
24 0.0030893944 	 0.2288519868
epoch_time;  41.0453941822052
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0027376539073884487
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.005587819032371044
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.11705657839775085
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.2319106161594391
25 0.0029153216 	 0.2319106134
epoch_time;  41.21087908744812
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0017310921102762222
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.004204718396067619
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.111928291618824
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.2261560708284378
26 0.0028245476 	 0.2261560676
epoch_time;  43.095577001571655
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0015379602555185556
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.003697863081470132
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.1097622811794281
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.22437329590320587
27 0.002680907 	 0.2243733017
epoch_time;  42.860249519348145
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0008060162072069943
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0026923627592623234
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.10335380584001541
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.21398605406284332
28 0.0027689239 	 0.2139860539
epoch_time;  40.65379190444946
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0008405667613260448
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0025497074238955975
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.10944540798664093
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.22262218594551086
29 0.0026215211 	 0.2226221828
epoch_time;  41.04604411125183
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0008412033203057945
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0025463122874498367
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.10949359089136124
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.22174414992332458
It took  1299.2406041622162  seconds.
----- ITERATION 6/10 ------
[<torch.utils.data.dataloader.DataLoader object at 0x15348f55f070>, <torch.utils.data.dataloader.DataLoader object at 0x15348f5ab6d0>, <torch.utils.data.dataloader.DataLoader object at 0x15348f5a9c90>, <torch.utils.data.dataloader.DataLoader object at 0x1534b92a0190>]
LSTM(
  (lstm): LSTM(8, 96, batch_first=True, dropout=0.2)
  (layers): Sequential(
    (0): Linear(in_features=96, out_features=8, bias=True)
  )
)
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.020837213844060898
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.05176848545670509
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 4.182740688323975
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 8.62618350982666
0 1.4882373564 	 8.6261838239
epoch_time;  40.95385956764221
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.011563190259039402
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0269811749458313
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 1.8427181243896484
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 4.038967132568359
1 0.0352396622 	 4.0389673515
epoch_time;  41.072434425354004
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.008668722584843636
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.018947672098875046
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 1.0532206296920776
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 2.3659305572509766
2 0.0244249377 	 2.3659304708
epoch_time;  41.102145195007324
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0033602232579141855
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.008779415860772133
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.714006245136261
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 1.5028918981552124
3 0.0185361728 	 1.5028918863
epoch_time;  40.93047547340393
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.004924065433442593
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.009058807976543903
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.5383567214012146
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 1.0992168188095093
4 0.0151582872 	 1.0992167954
epoch_time;  40.929049253463745
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.007082041818648577
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.011623757891356945
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.43271708488464355
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.8922537565231323
5 0.0116617837 	 0.892253772
epoch_time;  41.00891470909119
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.002742044162005186
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.005395897664129734
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.35383448004722595
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.756649911403656
6 0.0104531007 	 0.7566499278
epoch_time;  41.34720277786255
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.005313860718160868
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.009076065383851528
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.28049546480178833
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.6185926198959351
7 0.0087030203 	 0.6185925994
epoch_time;  41.084346532821655
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.006865336559712887
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.011836022138595581
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.2499190717935562
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.5199885368347168
8 0.0082146697 	 0.5199885527
epoch_time;  40.71456003189087
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.00493287481367588
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.008094722405076027
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.24390597641468048
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.473130464553833
9 0.0074370692 	 0.473130471
epoch_time;  41.005000829696655
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0023189845960587263
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.004185685887932777
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.2167331874370575
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.4235420227050781
10 0.0060864412 	 0.4235420342
epoch_time;  41.14167022705078
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0023687556385993958
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.004359223879873753
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.18651752173900604
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.36412909626960754
11 0.0061354901 	 0.3641291039
epoch_time;  41.034034967422485
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0019140951335430145
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0033826720900833607
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.17510277032852173
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.32871732115745544
12 0.0056284822 	 0.3287173268
epoch_time;  40.616453886032104
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.006121213547885418
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.010520657524466515
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.17505134642124176
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.31895875930786133
13 0.0057318837 	 0.318958755
epoch_time;  40.54108953475952
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.005056547932326794
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.008392347022891045
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.1431908905506134
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.2721189856529236
14 0.0043625803 	 0.2721189977
epoch_time;  40.78753304481506
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0016515811439603567
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.003023452591150999
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.14419801533222198
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.2728501558303833
15 0.0048203302 	 0.2728501519
epoch_time;  40.68761444091797
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0017511853948235512
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.002995505230501294
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.13654476404190063
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.26584288477897644
16 0.0042258428 	 0.2658428872
epoch_time;  42.73206114768982
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0025262439157813787
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.004037870094180107
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.12618808448314667
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.2409861832857132
17 0.003947092 	 0.2409861815
epoch_time;  41.85632276535034
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0013680472038686275
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.002588770119473338
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.12110348045825958
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.21386191248893738
18 0.0039699877 	 0.2138619092
epoch_time;  41.08584403991699
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0020771671552211046
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0034701607655733824
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.12599734961986542
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.2505587339401245
19 0.0037051106 	 0.2505587206
epoch_time;  41.25495171546936
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.002620294224470854
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.004446551203727722
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.11029978096485138
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.2054714858531952
20 0.0036325888 	 0.2054714883
epoch_time;  41.27651047706604
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.001776910969056189
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0028327200561761856
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.11353582888841629
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.20014971494674683
21 0.003478309 	 0.2001497205
epoch_time;  40.99016284942627
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0032355436123907566
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.004975342191755772
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.11271551996469498
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.1956632286310196
22 0.0032908095 	 0.1956632217
epoch_time;  41.483903884887695
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0011548930779099464
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.002033613622188568
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.11271600425243378
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.19689394533634186
23 0.0034159654 	 0.1968939513
epoch_time;  41.225929498672485
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.00737721985206008
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.010330675169825554
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.10327732563018799
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.17628838121891022
24 0.0028244823 	 0.1762883858
epoch_time;  40.687769412994385
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.003514630952849984
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0066316197626292706
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.1293751299381256
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.2228967547416687
25 0.0030761436 	 0.2228967488
epoch_time;  40.750338554382324
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.002978387987241149
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0042183795012533665
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0957002267241478
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.17541702091693878
26 0.0028866736 	 0.1754170213
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                              Epoch ▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇███
wandb: Test loss t(-10, 10)_r(-5, 5)_none █▄▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  Test loss t(-10, 10)_r(0, 0)_none █▅▃▂▂▂▂▂▂▂▁▁▁▂▂▁▁▁▁▁▁▁▂▁▂▂▁▂▁▁▁
wandb:    Test loss t(0, 0)_r(-5, 5)_none █▄▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     Test loss t(0, 0)_r(0, 0)_none █▅▄▂▂▃▂▃▃▂▂▂▁▃▂▁▁▂▁▁▂▁▂▁▃▂▂▂▁▂▂
wandb:                         Train loss █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                              Epoch 29
wandb: Test loss t(-10, 10)_r(-5, 5)_none 0.16346
wandb:  Test loss t(-10, 10)_r(0, 0)_none 0.00356
wandb:    Test loss t(0, 0)_r(-5, 5)_none 0.08249
wandb:     Test loss t(0, 0)_r(0, 0)_none 0.0022
wandb:                         Train loss 0.00258
wandb: 
wandb: 🚀 View run cheerful-envelope-1552 at: https://wandb.ai/nreints/thesis/runs/x74osiau
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230127_055620-x74osiau/logs
/gpfs/home2/nreints/MScThesis/code/lstm.py:270: DeprecationWarning: Sampling from a set deprecated
since Python 3.9 and will be removed in a subsequent version.
  train_sims = set(random.sample(sims_train, int(0.8 * n_sims_train)))
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.13.9 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.8
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230127_061752-l6sh78fy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lunar-orchid-1559
wandb: ⭐️ View project at https://wandb.ai/nreints/thesis
wandb: 🚀 View run at https://wandb.ai/nreints/thesis/runs/l6sh78fy
/home/nreints/.conda/envs/thesis/lib/python3.10/site-packages/torch/nn/modules/rnn.py:67: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  warnings.warn("dropout option adds dropout after all but last "
epoch_time;  40.778351068496704
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0038023849483579397
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0062453774735331535
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.1888357400894165
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.3153526782989502
27 0.0029920548 	 0.315352679
epoch_time;  40.57909917831421
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0007593901827931404
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0013719787821173668
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.08150085061788559
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.15302518010139465
28 0.0026483473 	 0.1530251748
epoch_time;  40.78360080718994
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.002200910123065114
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.003549268702045083
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.08247552812099457
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.16327421367168427
29 0.0025792214 	 0.1632742176
epoch_time;  40.548184394836426
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.002201165072619915
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0035593584179878235
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0824941024184227
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.1634644716978073
It took  1291.8560569286346  seconds.
----- ITERATION 7/10 ------
[<torch.utils.data.dataloader.DataLoader object at 0x1534bf8369e0>, <torch.utils.data.dataloader.DataLoader object at 0x1534bf7c13c0>, <torch.utils.data.dataloader.DataLoader object at 0x1534bf7c2dd0>, <torch.utils.data.dataloader.DataLoader object at 0x1534bf7c3010>]
LSTM(
  (lstm): LSTM(8, 96, batch_first=True, dropout=0.2)
  (layers): Sequential(
    (0): Linear(in_features=96, out_features=8, bias=True)
  )
)
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.027732253074645996
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.135897696018219
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 4.828018665313721
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 9.976280212402344
0 1.4991144589 	 9.976280005
epoch_time;  40.84485936164856
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.008246121928095818
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.06872233748435974
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 2.358715772628784
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 5.003854274749756
1 0.0330413195 	 5.0038542503
epoch_time;  40.7546660900116
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.008938876911997795
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.05112816393375397
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 1.465123176574707
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 3.0891897678375244
2 0.0221925803 	 3.0891896965
epoch_time;  41.22116708755493
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.013067503459751606
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.043935973197221756
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 1.0510284900665283
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 2.1336324214935303
3 0.0174487271 	 2.1336323257
epoch_time;  40.99498176574707
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.00366022577509284
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.025372305884957314
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.8435288071632385
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 1.627320408821106
4 0.0152245145 	 1.6273204423
epoch_time;  40.771966218948364
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.007945389486849308
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.02649596519768238
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.7384247183799744
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 1.3272209167480469
5 0.0116345964 	 1.3272209052
epoch_time;  40.89544439315796
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.00457546953111887
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.01893221214413643
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.5423794388771057
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 1.0191282033920288
6 0.009920056 	 1.019128252
epoch_time;  41.0467095375061
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.002229398814961314
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.014086788520216942
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.4541419446468353
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.9067056179046631
7 0.0086829549 	 0.9067056431
epoch_time;  42.63714241981506
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.004027319606393576
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.01598956808447838
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.32680386304855347
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.6808979511260986
8 0.0079281364 	 0.680897923
epoch_time;  41.9806764125824
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.003533693263307214
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.015034819953143597
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.27745094895362854
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.5875415205955505
9 0.007121564 	 0.5875415168
epoch_time;  41.3458993434906
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.002781637478619814
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.015839524567127228
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.24086235463619232
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.5480151176452637
10 0.0063404196 	 0.548015122
epoch_time;  40.988332986831665
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0025221214164048433
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.014722992666065693
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.212633416056633
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.45882177352905273
11 0.0060631206 	 0.4588217836
epoch_time;  40.74603605270386
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0024845916777849197
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0135698476806283
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.20302270352840424
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.4304508864879608
12 0.0054959666 	 0.4304509004
epoch_time;  40.94085884094238
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.002216961467638612
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.012983441352844238
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.21767163276672363
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.422376424074173
13 0.0053348408 	 0.4223764195
epoch_time;  40.75709843635559
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0013703368604183197
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.011056783609092236
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.18078476190567017
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.38448765873908997
14 0.0046867043 	 0.3844876707
epoch_time;  41.11257243156433
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0010433807037770748
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.00920582003891468
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.17032785713672638
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.34908735752105713
15 0.0044879585 	 0.3490873723
epoch_time;  40.86344051361084
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0014715903671458364
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.009163817390799522
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.17312899231910706
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.34930795431137085
16 0.0044150941 	 0.3493079563
epoch_time;  41.05477499961853
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0022486771922558546
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.009391776286065578
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.16214007139205933
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.31602784991264343
17 0.0039862139 	 0.3160278459
epoch_time;  40.983580112457275
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0023366566747426987
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.009826802648603916
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.1740514487028122
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.3335389494895935
18 0.00404211 	 0.3335389428
epoch_time;  41.21544623374939
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0020696334540843964
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.009535384364426136
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                              Epoch ▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇███
wandb: Test loss t(-10, 10)_r(-5, 5)_none █▄▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  Test loss t(-10, 10)_r(0, 0)_none █▄▃▃▂▂▂▁▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:    Test loss t(0, 0)_r(-5, 5)_none █▄▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     Test loss t(0, 0)_r(0, 0)_none █▃▃▄▂▃▂▁▂▂▂▁▁▁▁▁▁▁▁▁▂▁▁▁▁▂▁▁▁▁▁
wandb:                         Train loss █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                              Epoch 29
wandb: Test loss t(-10, 10)_r(-5, 5)_none 0.23859
wandb:  Test loss t(-10, 10)_r(0, 0)_none 0.00582
wandb:    Test loss t(0, 0)_r(-5, 5)_none 0.12571
wandb:     Test loss t(0, 0)_r(0, 0)_none 0.00135
wandb:                         Train loss 0.00273
wandb: 
wandb: 🚀 View run lunar-orchid-1559 at: https://wandb.ai/nreints/thesis/runs/l6sh78fy
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230127_061752-l6sh78fy/logs
/gpfs/home2/nreints/MScThesis/code/lstm.py:270: DeprecationWarning: Sampling from a set deprecated
since Python 3.9 and will be removed in a subsequent version.
  train_sims = set(random.sample(sims_train, int(0.8 * n_sims_train)))
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.13.9 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.8
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230127_063930-iamyci15
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vibrant-rabbit-1566
wandb: ⭐️ View project at https://wandb.ai/nreints/thesis
wandb: 🚀 View run at https://wandb.ai/nreints/thesis/runs/iamyci15
/home/nreints/.conda/envs/thesis/lib/python3.10/site-packages/torch/nn/modules/rnn.py:67: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  warnings.warn("dropout option adds dropout after all but last "
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.15561668574810028
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.3078664541244507
19 0.0036521712 	 0.3078664451
epoch_time;  41.19804644584656
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.002787790959700942
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.009731603786349297
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.15110063552856445
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.2946496903896332
20 0.0037858098 	 0.2946496831
epoch_time;  40.61397743225098
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.002107430947944522
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.009299512021243572
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.14566583931446075
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.2882300317287445
21 0.0032788846 	 0.2882300432
epoch_time;  40.87247014045715
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0010114661417901516
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.007225419860333204
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.14782965183258057
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.286583811044693
22 0.0034009051 	 0.2865837996
epoch_time;  41.29385709762573
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0008181857410818338
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.006586699280887842
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.13573859632015228
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.2697131931781769
23 0.0032687003 	 0.269713203
epoch_time;  41.08158540725708
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.001244575367309153
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.007131252903491259
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.13581489026546478
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.2668036222457886
24 0.0032045406 	 0.2668036147
epoch_time;  41.07324957847595
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.00369249121285975
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.010036012157797813
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.13435722887516022
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.25775450468063354
25 0.0029399384 	 0.2577545074
epoch_time;  41.33125329017639
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0011523261200636625
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.005868319887667894
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.13057918846607208
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.24802477657794952
26 0.0029136606 	 0.2480247705
epoch_time;  41.45624303817749
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.002017210703343153
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0080399289727211
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.1280941665172577
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.24565504491329193
27 0.0029010062 	 0.2456550483
epoch_time;  41.115195751190186
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0026779486797749996
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.008338307030498981
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.12690721452236176
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.2396230846643448
28 0.0026823265 	 0.2396230784
epoch_time;  40.990827322006226
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0013484200462698936
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.005752333905547857
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.1258058398962021
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.23761940002441406
29 0.002732524 	 0.2376194058
epoch_time;  43.055060625076294
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0013487401884049177
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.005818406119942665
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.1257130205631256
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.2385883331298828
It took  1297.4034297466278  seconds.
----- ITERATION 8/10 ------
[<torch.utils.data.dataloader.DataLoader object at 0x1534c1244a00>, <torch.utils.data.dataloader.DataLoader object at 0x1534bf7c1a20>, <torch.utils.data.dataloader.DataLoader object at 0x1534b92ebaf0>, <torch.utils.data.dataloader.DataLoader object at 0x1534b92eb430>]
LSTM(
  (lstm): LSTM(8, 96, batch_first=True, dropout=0.2)
  (layers): Sequential(
    (0): Linear(in_features=96, out_features=8, bias=True)
  )
)
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.023751631379127502
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.06167396903038025
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 7.149205207824707
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 13.43068790435791
0 1.9147374444 	 13.4306876652
epoch_time;  41.312983751297
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.029013648629188538
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.049075499176979065
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 3.3659989833831787
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 6.700295448303223
1 0.0470976501 	 6.7002956241
epoch_time;  40.917057037353516
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.029055532068014145
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.04001902416348457
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 1.9411782026290894
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 4.098198890686035
2 0.0279085793 	 4.0981987437
epoch_time;  40.72413635253906
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.006865123752504587
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.012564304284751415
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 1.153430461883545
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 2.5776307582855225
3 0.0216928795 	 2.5776308181
epoch_time;  40.63535714149475
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.014458604156970978
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.02310589887201786
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.778717577457428
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 1.799815058708191
4 0.0165619919 	 1.7998150137
epoch_time;  40.78507137298584
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0072532109916210175
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.011635366827249527
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.5119539499282837
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 1.2040950059890747
5 0.0136781948 	 1.2040950164
epoch_time;  40.93347454071045
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.006131630856543779
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.011355336755514145
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.4383849501609802
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 1.0368432998657227
6 0.0119415972 	 1.0368432912
epoch_time;  40.8230504989624
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0025212415494024754
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0047546629793941975
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.314728707075119
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.7851577997207642
7 0.0097055276 	 0.7851578174
epoch_time;  40.8093945980072
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.004667872563004494
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.00804804265499115
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.2126075029373169
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.5426506400108337
8 0.0092728071 	 0.5426506204
epoch_time;  40.94335079193115
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.020318977534770966
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.02800208516418934
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.2172330617904663
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.5010852813720703
9 0.0080399878 	 0.5010853102
epoch_time;  41.04331421852112
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0029789956752210855
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.005308790598064661
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.1726376712322235
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.39158663153648376
10 0.0074055633 	 0.3915866264
epoch_time;  40.97294592857361
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0026563152205199003
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.004608115181326866
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.1686907261610031
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.3458960950374603
11 0.0067855133 	 0.3458960957
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                              Epoch ▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇███
wandb: Test loss t(-10, 10)_r(-5, 5)_none █▄▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  Test loss t(-10, 10)_r(0, 0)_none █▇▅▂▃▂▂▁▂▄▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▂▁▁
wandb:    Test loss t(0, 0)_r(-5, 5)_none █▄▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     Test loss t(0, 0)_r(0, 0)_none ▇██▂▄▃▂▁▂▆▁▁▁▁▁▁▁▁▁▁▂▂▁▁▁▂▁▁▂▁▁
wandb:                         Train loss █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                              Epoch 29
wandb: Test loss t(-10, 10)_r(-5, 5)_none 0.17461
wandb:  Test loss t(-10, 10)_r(0, 0)_none 0.00269
wandb:    Test loss t(0, 0)_r(-5, 5)_none 0.09583
wandb:     Test loss t(0, 0)_r(0, 0)_none 0.0014
wandb:                         Train loss 0.00303
wandb: 
wandb: 🚀 View run vibrant-rabbit-1566 at: https://wandb.ai/nreints/thesis/runs/iamyci15
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230127_063930-iamyci15/logs
/gpfs/home2/nreints/MScThesis/code/lstm.py:270: DeprecationWarning: Sampling from a set deprecated
since Python 3.9 and will be removed in a subsequent version.
  train_sims = set(random.sample(sims_train, int(0.8 * n_sims_train)))
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.13.9 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.8
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230127_070104-jc12umky
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run luminous-wish-1573
wandb: ⭐️ View project at https://wandb.ai/nreints/thesis
wandb: 🚀 View run at https://wandb.ai/nreints/thesis/runs/jc12umky
/home/nreints/.conda/envs/thesis/lib/python3.10/site-packages/torch/nn/modules/rnn.py:67: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  warnings.warn("dropout option adds dropout after all but last "
epoch_time;  41.40609407424927
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.001930694910697639
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.003698360174894333
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.15426534414291382
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.3264029026031494
12 0.0062833926 	 0.3264029004
epoch_time;  41.12628698348999
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0023064850829541683
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.004203969147056341
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.14343127608299255
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.31254592537879944
13 0.0056727775 	 0.3125459377
epoch_time;  40.84809327125549
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0020404255483299494
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0039077396504580975
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.13693302869796753
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.2987138032913208
14 0.005481307 	 0.2987137993
epoch_time;  40.931116342544556
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.002435123547911644
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.005032678134739399
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.13709738850593567
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.2916358709335327
15 0.005167798 	 0.2916358648
epoch_time;  41.175161600112915
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.002761091571301222
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.00523578654974699
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.1430058777332306
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.29164645075798035
16 0.0049416833 	 0.2916464445
epoch_time;  40.80372977256775
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0026015425100922585
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.004111042711883783
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.12314238399267197
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.2545314133167267
17 0.0046658769 	 0.2545314224
epoch_time;  41.38477826118469
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0011540255509316921
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0023800733033567667
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.12374057620763779
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.2510007321834564
18 0.0043557082 	 0.2510007184
epoch_time;  41.41727900505066
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0022203766275197268
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.003798252437263727
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.1311691701412201
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.25681155920028687
19 0.0042002463 	 0.2568115511
epoch_time;  42.77999925613403
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0033139516599476337
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0052719274535775185
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.12056523561477661
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.2389034926891327
20 0.0041700698 	 0.2389034951
epoch_time;  42.104416847229004
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.005435698200017214
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.008054397068917751
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.13691261410713196
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.2528233230113983
21 0.003929484 	 0.252823337
epoch_time;  40.9235737323761
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0017312185373157263
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0031948466785252094
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.11443643271923065
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.21874122321605682
22 0.0037365905 	 0.2187412181
epoch_time;  40.65059971809387
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0027670718263834715
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.004047850612550974
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.11926610767841339
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.22228553891181946
23 0.0037018125 	 0.2222855444
epoch_time;  40.67593574523926
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0021827032323926687
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.003858544398099184
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.11013511568307877
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.21117708086967468
24 0.003481483 	 0.2111770768
epoch_time;  40.758533239364624
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0032546785660088062
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.005262407939881086
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.1342538595199585
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.23924098908901215
25 0.0033624196 	 0.2392409863
epoch_time;  40.803369998931885
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0011110410559922457
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.002261226763948798
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.11103010922670364
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.20936042070388794
26 0.0032553121 	 0.2093604281
epoch_time;  41.01553821563721
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0011543006403371692
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0019855694845318794
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.10321025550365448
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.19195544719696045
27 0.0030805705 	 0.1919554512
epoch_time;  40.8627655506134
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.004166487138718367
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.006478974595665932
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.10184139013290405
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.18343445658683777
28 0.0030795837 	 0.1834344547
epoch_time;  41.01134729385376
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0014008944854140282
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0026950626634061337
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.09586015343666077
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.17456205189228058
29 0.0030301377 	 0.1745620451
epoch_time;  40.98574137687683
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.00140092964284122
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0026948146987706423
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.09582670778036118
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.17460563778877258
It took  1294.5522944927216  seconds.
----- ITERATION 9/10 ------
[<torch.utils.data.dataloader.DataLoader object at 0x1534c1244a90>, <torch.utils.data.dataloader.DataLoader object at 0x1534bf7c0cd0>, <torch.utils.data.dataloader.DataLoader object at 0x1534bf7c2140>, <torch.utils.data.dataloader.DataLoader object at 0x1534bf7c22f0>]
LSTM(
  (lstm): LSTM(8, 96, batch_first=True, dropout=0.2)
  (layers): Sequential(
    (0): Linear(in_features=96, out_features=8, bias=True)
  )
)
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.013748859986662865
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0536569282412529
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 4.819533824920654
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 9.490574836730957
0 1.5471389158 	 9.4905744017
epoch_time;  40.80650067329407
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.007390020880848169
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.023649787530303
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 2.2284393310546875
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 4.683767318725586
1 0.0301561608 	 4.6837670825
epoch_time;  40.74489378929138
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.004932291340082884
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.014909838326275349
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 1.2476806640625
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 2.829728364944458
2 0.0216289653 	 2.8297283253
epoch_time;  40.982919216156006
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.008976099081337452
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.017842067405581474
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.845028817653656
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 1.9678782224655151
3 0.0161023021 	 1.9678781746
epoch_time;  40.58556866645813
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0120493583381176
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.021675260737538338
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.6045503616333008
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 1.5070021152496338
4 0.0133395805 	 1.5070020785
epoch_time;  40.54408359527588
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.007286529056727886
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.01386099774390459
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.44903379678726196
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 1.1637392044067383
5 0.0111957842 	 1.1637392534
epoch_time;  40.65895485877991
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.002116844058036804
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.006803253199905157
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.3318091332912445
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.8758730888366699
6 0.00923006 	 0.8758731162
epoch_time;  40.764419078826904
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.002735526068136096
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.006887064315378666
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.24216565489768982
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.6259939670562744
7 0.0085310016 	 0.6259939418
epoch_time;  40.48778963088989
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.004112209193408489
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.00802281592041254
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.22197359800338745
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.5677193999290466
8 0.0077229745 	 0.5677193817
epoch_time;  40.82306241989136
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.002124973339959979
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0051253060810267925
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.1743002086877823
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.4531247317790985
9 0.0061590727 	 0.4531247234
epoch_time;  41.24120354652405
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.003504290711134672
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0076971291564404964
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.15376462042331696
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.37895360589027405
10 0.0064991728 	 0.3789536168
epoch_time;  42.764692306518555
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.005286149214953184
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.00876759272068739
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.15283547341823578
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.44003424048423767
11 0.0054005645 	 0.4400342498
epoch_time;  41.07246112823486
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0014693019911646843
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.003558472264558077
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.12321853637695312
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.3453567624092102
12 0.0052718651 	 0.3453567597
epoch_time;  40.96599102020264
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0013813364785164595
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0033567321952432394
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.11887521296739578
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.3191920220851898
13 0.0047780556 	 0.3191920162
epoch_time;  40.92797017097473
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0018636442255228758
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0038963844999670982
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.1160523071885109
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.23510108888149261
14 0.0045021744 	 0.2351010833
epoch_time;  40.41727900505066
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0012953239493072033
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.002957724267616868
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.13231514394283295
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.2550240159034729
15 0.004263178 	 0.2550240139
epoch_time;  40.41794228553772
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.002314161043614149
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0043182638473808765
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.11618971824645996
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.24090823531150818
16 0.003981783 	 0.240908228
epoch_time;  40.52015709877014
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0009826126042753458
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0022405746858567
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.10141492635011673
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.20729266107082367
17 0.0038374014 	 0.2072926547
epoch_time;  40.479392290115356
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0018797102384269238
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.003931274637579918
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.10366044193506241
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.2035559117794037
18 0.0037619878 	 0.203555911
epoch_time;  40.521223306655884
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.002739959629252553
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.005331079009920359
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.10756852477788925
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.20830178260803223
19 0.0035441465 	 0.2083017862
epoch_time;  40.390559673309326
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0014750047121196985
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0030330826994031668
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.09773914515972137
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.1912016123533249
20 0.0033208301 	 0.1912016163
epoch_time;  40.52578115463257
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.00161743036005646
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.002759874565526843
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.09548695385456085
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.18296435475349426
21 0.0033034463 	 0.182964348
epoch_time;  40.45329141616821
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.002359507605433464
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0040651592426002026
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.11644256114959717
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.21104927361011505
22 0.0032577551 	 0.2110492672
epoch_time;  40.40414786338806
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.002802603878080845
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.005038128234446049
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.09395988285541534
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.17495913803577423
23 0.0029274742 	 0.1749591424
epoch_time;  40.53737735748291
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.00118700647726655
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.002095960546284914
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.08492929488420486
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.15448637306690216
24 0.0031473487 	 0.1544863767
epoch_time;  40.359822511672974
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.001125880517065525
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0022769442293792963
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.08454141765832901
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.1509251445531845
25 0.0029667707 	 0.1509251436
epoch_time;  40.60460019111633
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.002213351894170046
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0038551469333469868
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.08150015026330948
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.14777378737926483
26 0.0026892222 	 0.1477737888
epoch_time;  40.704976081848145
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0018424608279019594
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.003136844141408801
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.07943238317966461
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.14233924448490143
27 0.0025522012 	 0.1423392512
epoch_time;  40.53671169281006
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0038471268489956856
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.006447381339967251
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.08556148409843445
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.14946135878562927
28 0.0026334563 	 0.1494613601
epoch_time;  40.79831051826477
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                              Epoch ▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇███
wandb: Test loss t(-10, 10)_r(-5, 5)_none █▄▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  Test loss t(-10, 10)_r(0, 0)_none █▄▃▃▄▃▂▂▂▁▂▂▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▂▁▁
wandb:    Test loss t(0, 0)_r(-5, 5)_none █▄▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     Test loss t(0, 0)_r(0, 0)_none █▅▃▅▇▅▂▂▃▂▂▃▁▁▂▁▂▁▂▂▁▁▂▂▁▁▂▂▃▁▁
wandb:                         Train loss █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                              Epoch 29
wandb: Test loss t(-10, 10)_r(-5, 5)_none 0.13689
wandb:  Test loss t(-10, 10)_r(0, 0)_none 0.0015
wandb:    Test loss t(0, 0)_r(-5, 5)_none 0.07565
wandb:     Test loss t(0, 0)_r(0, 0)_none 0.00078
wandb:                         Train loss 0.00252
wandb: 
wandb: 🚀 View run luminous-wish-1573 at: https://wandb.ai/nreints/thesis/runs/jc12umky
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230127_070104-jc12umky/logs
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0007797798607498407
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0014970115153118968
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.07573417574167252
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.1368047297000885
29 0.0025242146 	 0.1368047363
epoch_time;  40.789915800094604
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0007800273597240448
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.001495539559982717
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.07565147429704666
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.1368933469057083
It took  1284.7911999225616  seconds.

JOB STATISTICS
==============
Job ID: 2142135
Array Job ID: 2141141_12
Cluster: snellius
User/Group: nreints/nreints
State: COMPLETED (exit code 0)
Nodes: 1
Cores per node: 18
CPU Utilized: 20:55:01
CPU Efficiency: 32.25% of 2-16:51:00 core-walltime
Job Wall-clock time: 03:36:10
Memory Utilized: 15.90 GB
Memory Efficiency: 50.87% of 31.25 GB
