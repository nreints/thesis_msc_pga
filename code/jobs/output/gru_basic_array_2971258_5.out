wandb: Currently logged in as: nreints. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_164022-ky0k0o5l
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run northern-grass-1
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal1/runs/ky0k0o5l
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone █▆▄▂▁▁▄▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone █▆▄▂▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone █▆▄▂▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone █▅▃▂▁▁▅▁▁▂
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone █▅▃▂▁▁▆▁▁▂
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone 1e-05
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone 1e-05
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone 1e-05
wandb:                                  Train loss 1e-05
wandb: 
wandb: 🚀 View run northern-grass-1 at: https://wandb.ai/nreints/ThesisFinal1/runs/ky0k0o5l
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_164022-ky0k0o5l/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_164832-9akyzhn5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run laced-cloud-39
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal1/runs/9akyzhn5
Training on dataset: data_t(5,20)_r(0,0)_combi_pNone_gNone
Testing on 5 datasets: ['data_t(5,20)_r(0,0)_full_pNone_gNone', 'data_t(5,20)_r(0,0)_combi_pNone_gNone', 'data_t(5,20)_r(0,0)_tennis_pNone_gNone', 'data_t(5,20)_r(0,0)_none_pNone_gNone', 'data_t(5,20)_r(0,0)_semi_pNone_gNone']
Focussing on identity: False
Using extra input: False
Using fr-fr as reference point.
----- ITERATION 1/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 52.869693756103516 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(0,0)_full_pNone_gNone took 13.421740770339966 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 13.131850004196167 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_tennis_pNone_gNone took 13.484286785125732 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_none_pNone_gNone took 13.476098775863647 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_semi_pNone_gNone took 13.430368185043335 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0093865013 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 7.502e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 8.10371e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 8.58997e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 7.46007e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 8.37115e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 37.45530366897583
Epoch 1/9
	 Logging train Loss: 6.39958e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 5.09051e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 5.28212e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 5.40979e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 5.04001e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 5.30356e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 35.56964087486267
Epoch 2/9
	 Logging train Loss: 3.98116e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.92063e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 3.00271e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.02748e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 2.86096e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 2.98243e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 35.1884651184082
Epoch 3/9
	 Logging train Loss: 1.86219e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 9.2882e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.00657e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.05116e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 9.1476e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.01352e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 34.835670948028564
Epoch 4/9
	 Logging train Loss: 6.9459e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.3856e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.6176e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.6591e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.3481e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.5683e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 35.178518533706665
Epoch 5/9
	 Logging train Loss: 1.23891e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 5.398e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.3538e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.0096e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 5.321e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.8323e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 35.37478709220886
Epoch 6/9
	 Logging train Loss: 8.4371e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.3842e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.95719e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 5.75428e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 2.3231e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 4.97337e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 35.25535035133362
Epoch 7/9
	 Logging train Loss: 1.36612e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.305e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 4.316e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 4.183e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 3.275e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 4.016e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 35.3996787071228
Epoch 8/9
	 Logging train Loss: 1.2157e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.042e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 4.611e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 5.266e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 3.03e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 4.958e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 35.04091763496399
Epoch 9/9
	 Logging train Loss: 1.02143e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 7.527e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 5.0632e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 9.2122e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 7.506e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 8.168e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 35.29092836380005
Saved model in  trained_models/gru/data_t(5,20)_r(0,0)_combi_pNone_gNone/'dual_quat_1'_'False'.pth
It took  490.57671666145325  seconds.
----- ITERATION 2/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 48.21169471740723 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(0,0)_full_pNone_gNone took 12.296557426452637 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 12.09964895248413 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_tennis_pNone_gNone took 12.32241702079773 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_none_pNone_gNone took 12.266513347625732 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_semi_pNone_gNone took 12.270376443862915 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0967551172 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 9.70344e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 0.0001344445 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 0.0001133842 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 9.62832e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 0.0001122087 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 35.8448052406311
Epoch 1/9
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone █▆▅▄▃▂▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone █▆▅▅▄▃▂▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone █▆▅▅▄▃▂▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone █▅▅▄▄▃▂▁▂▁
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone █▆▅▄▄▃▂▁▂▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone 0.0
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone 0.0
wandb:                                  Train loss 1e-05
wandb: 
wandb: 🚀 View run laced-cloud-39 at: https://wandb.ai/nreints/ThesisFinal1/runs/9akyzhn5
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_164832-9akyzhn5/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_165629-1qow5obo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run avid-feather-63
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal1/runs/1qow5obo
	 Logging train Loss: 9.73275e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 6.52412e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 8.73819e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 7.34121e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 6.4644e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 7.2242e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 35.5769727230072
Epoch 2/9
	 Logging train Loss: 7.60324e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 5.86779e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 7.07655e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 6.42548e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 5.79532e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 6.32005e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 35.546695709228516
Epoch 3/9
	 Logging train Loss: 6.1574e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 5.02448e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 5.61651e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 5.44217e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 4.96454e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 5.3458e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 35.532132148742676
Epoch 4/9
	 Logging train Loss: 4.79544e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.91899e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 4.19098e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 4.22215e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 3.84927e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 4.13766e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 35.42556977272034
Epoch 5/9
	 Logging train Loss: 3.30569e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.41996e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.56365e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.65796e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 2.37904e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 2.60745e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 35.322620153427124
Epoch 6/9
	 Logging train Loss: 1.69296e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 9.3544e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.00708e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.08193e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 9.2799e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.02893e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 35.791640758514404
Epoch 7/9
	 Logging train Loss: 4.7979e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.3403e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.8162e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.9919e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.2888e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.8982e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 35.60068202018738
Epoch 8/9
	 Logging train Loss: 2.1589e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.288e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 5.6361e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 9.3725e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.2743e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 9.2557e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 35.60225558280945
Epoch 9/9
	 Logging train Loss: 5.8032e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 9.753e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.2343e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.1068e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 9.651e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.098e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 35.665430545806885
Saved model in  trained_models/gru/data_t(5,20)_r(0,0)_combi_pNone_gNone/'dual_quat_1'_'False'.pth
It took  477.4502229690552  seconds.
----- ITERATION 3/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 47.183892250061035 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(0,0)_full_pNone_gNone took 12.228215456008911 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 11.968273162841797 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_tennis_pNone_gNone took 12.202397346496582 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_none_pNone_gNone took 12.135236740112305 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_semi_pNone_gNone took 12.116040229797363 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0420182012 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 6.51508e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 7.35753e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 7.86264e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 6.74969e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 7.9124e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 35.20338821411133
Epoch 1/9
	 Logging train Loss: 6.34034e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 5.38851e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 5.79731e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 6.01146e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 5.5644e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 6.07746e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 35.4147002696991
Epoch 2/9
	 Logging train Loss: 4.85314e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.87048e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 4.14126e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 4.28509e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 4.01663e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 4.32622e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 35.142141342163086
Epoch 3/9
	 Logging train Loss: 3.07194e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.99364e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.16581e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.27414e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 2.06495e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 2.27796e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 35.646345376968384
Epoch 4/9
	 Logging train Loss: 1.2463e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 4.9525e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 5.7829e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 6.3344e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone █▇▅▃▂▁▁▁▁▂
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone █▇▅▃▂▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone █▇▅▃▂▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone █▆▅▃▂▁▁▁▁▃
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone █▆▅▃▂▁▁▁▁▃
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone 1e-05
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone 2e-05
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone 2e-05
wandb:                                  Train loss 1e-05
wandb: 
wandb: 🚀 View run avid-feather-63 at: https://wandb.ai/nreints/ThesisFinal1/runs/1qow5obo
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_165629-1qow5obo/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_170424-fbmi9rkr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run splendid-thunder-93
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal1/runs/fbmi9rkr
	 Logging test loss: 5.1419e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 6.2034e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 35.80889320373535
Epoch 5/9
	 Logging train Loss: 5.3803e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 6.547e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 9.879e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.1972e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 6.672e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.1523e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 35.50547671318054
Epoch 6/9
	 Logging train Loss: 8.2184e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 4.107e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 9.97e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.4841e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 4.08e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.3638e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 35.103349924087524
Epoch 7/9
	 Logging train Loss: 1.18688e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.748e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 4.267e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 4.813e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 2.752e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 4.684e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 35.30576157569885
Epoch 8/9
	 Logging train Loss: 1.26422e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.601e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 5.632e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 6.668e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 3.621e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 6.358e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 35.49614214897156
Epoch 9/9
	 Logging train Loss: 9.3795e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.8762e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.31587e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.43183e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 2.8123e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 2.25796e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 35.507214069366455
Saved model in  trained_models/gru/data_t(5,20)_r(0,0)_combi_pNone_gNone/'dual_quat_1'_'False'.pth
It took  474.49127197265625  seconds.
----- ITERATION 4/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 46.99040126800537 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(0,0)_full_pNone_gNone took 12.105934858322144 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 11.839954137802124 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_tennis_pNone_gNone took 12.095731973648071 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_none_pNone_gNone took 12.128060340881348 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_semi_pNone_gNone took 12.147153615951538 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0355051346 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 7.79302e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 0.0001075352 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 0.0001259038 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 7.57328e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 0.0001177095 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 35.328272104263306
Epoch 1/9
	 Logging train Loss: 8.25845e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 6.8364e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 7.26308e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 7.44716e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 6.63335e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 7.33889e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 35.497309923172
Epoch 2/9
	 Logging train Loss: 6.46708e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 5.87127e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 6.07618e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 6.12075e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 5.67932e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 6.06483e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 35.101919412612915
Epoch 3/9
	 Logging train Loss: 5.28281e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 4.6019e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 4.7289e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 4.76889e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 4.43812e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 4.71031e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 35.303731203079224
Epoch 4/9
	 Logging train Loss: 3.85588e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.04146e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 3.12771e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.1647e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 2.9164e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 3.11987e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 35.42691779136658
Epoch 5/9
	 Logging train Loss: 2.23863e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.39298e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.45436e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.52194e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.33952e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.47936e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 35.84560465812683
Epoch 6/9
	 Logging train Loss: 8.079e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.9804e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 3.2213e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.4348e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 2.8434e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 3.2632e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 35.27944302558899
Epoch 7/9
	 Logging train Loss: 1.02845e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 5.498e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 7.403e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 7.65e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 5.284e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 7.134e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 35.8327841758728
Epoch 8/9
	 Logging train Loss: 1.37204e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 6.9039e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone █▆▅▄▃▂▁▁▄▁
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone █▇▆▅▄▂▁▁▂▁
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone █▇▆▅▄▂▁▁▂▁
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone █▅▅▄▃▂▁▁▆▁
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone █▅▄▄▃▂▁▁▆▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone 0.0
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone 0.0
wandb:                                  Train loss 4e-05
wandb: 
wandb: 🚀 View run splendid-thunder-93 at: https://wandb.ai/nreints/ThesisFinal1/runs/fbmi9rkr
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_170424-fbmi9rkr/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_171217-fjleb1yb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run bright-dew-123
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal1/runs/fjleb1yb
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone █▆▄▂▁▂▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone █▆▄▂▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone █▆▄▂▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone █▆▄▂▂▃▁▁▁▂
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone █▆▄▂▂▄▁▁▁▂
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone 1e-05
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone 1e-05
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone 1e-05
wandb:                                  Train loss 1e-05
wandb: 
wandb: 🚀 View run bright-dew-123 at: https://wandb.ai/nreints/ThesisFinal1/runs/fjleb1yb
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_171217-fjleb1yb/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_172013-ccyj4166
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rosy-smoke-150
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal1/runs/ccyj4166
	 Logging test loss: 4.74984e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 9.01162e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 6.7915e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 7.92141e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 35.59259510040283
Epoch 9/9
	 Logging train Loss: 3.54217e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 6.685e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 8.162e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 7.733e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 6.517e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 7.557e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 35.382912158966064
Saved model in  trained_models/gru/data_t(5,20)_r(0,0)_combi_pNone_gNone/'dual_quat_1'_'False'.pth
It took  473.33395409584045  seconds.
----- ITERATION 5/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 46.99242901802063 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(0,0)_full_pNone_gNone took 12.082868814468384 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 11.882078886032104 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_tennis_pNone_gNone took 12.092852354049683 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_none_pNone_gNone took 12.083484411239624 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_semi_pNone_gNone took 12.086483240127563 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.011684306 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 7.68409e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 8.4103e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 8.89502e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 7.95673e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 8.68854e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 35.31950807571411
Epoch 1/9
	 Logging train Loss: 7.14544e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 5.64121e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 6.05657e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 6.3014e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 5.84244e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 6.18414e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 35.471105337142944
Epoch 2/9
	 Logging train Loss: 4.78434e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.32346e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 3.63052e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.74147e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 3.43841e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 3.7149e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 35.143932580947876
Epoch 3/9
	 Logging train Loss: 2.39433e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.21719e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.36845e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.42447e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.24897e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.43309e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 35.387420892715454
Epoch 4/9
	 Logging train Loss: 8.0194e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.07e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 4.9101e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 7.6003e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 2.0853e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 7.3243e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 35.337103843688965
Epoch 5/9
	 Logging train Loss: 1.06619e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.5128e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.74209e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.34312e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.4009e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 3.00049e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 35.55128884315491
Epoch 6/9
	 Logging train Loss: 1.24248e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.915e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 9.22e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.4519e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 2.922e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.3234e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 35.40928840637207
Epoch 7/9
	 Logging train Loss: 2.07317e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.521e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 9.992e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.5254e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 3.523e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.4294e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 35.05625510215759
Epoch 8/9
	 Logging train Loss: 7.5195e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.409e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 3.362e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.242e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 2.461e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 3.14e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 35.71808218955994
Epoch 9/9
	 Logging train Loss: 1.13055e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 5.793e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 5.0455e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 9.4425e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 5.492e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 8.7404e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 37.37351393699646
Saved model in  trained_models/gru/data_t(5,20)_r(0,0)_combi_pNone_gNone/'dual_quat_1'_'False'.pth
It took  475.52895617485046  seconds.
----- ITERATION 6/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 47.125739097595215 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(0,0)_full_pNone_gNone took 12.13207197189331 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 11.915002346038818 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_tennis_pNone_gNone took 12.064428567886353 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_none_pNone_gNone took 12.062278270721436 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_semi_pNone_gNone took 12.066717386245728 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone █▆▄▂▁▁▁▁▁▅
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone █▆▄▂▁▁▁▁▁▂
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone █▆▄▂▁▁▁▁▁▂
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone █▆▄▂▁▁▁▁▁▇
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone █▆▄▂▁▁▁▁▁▇
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone 4e-05
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone 1e-05
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone 1e-05
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone 6e-05
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone 7e-05
wandb:                                  Train loss 1e-05
wandb: 
wandb: 🚀 View run rosy-smoke-150 at: https://wandb.ai/nreints/ThesisFinal1/runs/ccyj4166
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_172013-ccyj4166/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_172807-3svl8ynn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eager-hill-178
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal1/runs/3svl8ynn
Datatype: dual_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0182286929 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 6.38834e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 7.06928e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 7.3246e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 6.54419e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 7.07138e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 35.187910318374634
Epoch 1/9
	 Logging train Loss: 5.94976e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 4.71204e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 4.95279e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 5.2761e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 4.85305e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 5.08736e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 35.14508390426636
Epoch 2/9
	 Logging train Loss: 3.97352e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.77562e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.93884e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.1731e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 2.87568e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 3.04793e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 35.24827551841736
Epoch 3/9
	 Logging train Loss: 1.92528e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 9.0168e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.00065e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.11383e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 9.3589e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.07177e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 35.28543257713318
Epoch 4/9
	 Logging train Loss: 5.8514e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.1023e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.3593e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.4992e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.1483e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.4499e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 35.27710676193237
Epoch 5/9
	 Logging train Loss: 1.13329e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 4.148e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.215e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.9456e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 4.25e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.8343e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 35.404446601867676
Epoch 6/9
	 Logging train Loss: 1.2747e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.93e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 4.15e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 4.326e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 2.989e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 4.242e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 35.75050377845764
Epoch 7/9
	 Logging train Loss: 1.27596e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.982e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 4.016e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.903e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 3.034e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 3.843e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 35.32907581329346
Epoch 8/9
	 Logging train Loss: 1.03092e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.525e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 3.423e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.206e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 2.563e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 3.152e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 35.391454458236694
Epoch 9/9
	 Logging train Loss: 1.05736e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.38237e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 3.85646e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 6.55003e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.37808e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 6.12335e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 35.36529064178467
Saved model in  trained_models/gru/data_t(5,20)_r(0,0)_combi_pNone_gNone/'dual_quat_1'_'False'.pth
It took  474.6504349708557  seconds.
----- ITERATION 7/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 46.81363105773926 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(0,0)_full_pNone_gNone took 12.022154092788696 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 11.822431087493896 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_tennis_pNone_gNone took 11.979116678237915 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_none_pNone_gNone took 12.057196140289307 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_semi_pNone_gNone took 12.061700105667114 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0087193577 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 6.44542e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 6.72107e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 7.05345e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 6.37182e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 6.87118e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 35.275373220443726
Epoch 1/9
	 Logging train Loss: 5.3489e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.99297e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 4.10318e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 4.28187e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 3.9572e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 4.18322e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 35.77929973602295
Epoch 2/9
	 Logging train Loss: 2.82419e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.56499e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.64636e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.75938e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.55209e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.74034e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 35.358540773391724
Epoch 3/9
	 Logging train Loss: 8.535e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.0379e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 3.4249e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.9217e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone ▇▅▃▁▁▁▂▁█▁
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone █▅▃▁▁▁▁▁▃▁
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone █▅▃▁▁▁▁▁▃▁
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone ▅▃▂▁▁▁▂▁█▁
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone ▅▃▂▁▁▁▂▁█▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone 0.0
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone 0.0
wandb:                                  Train loss 1e-05
wandb: 
wandb: 🚀 View run eager-hill-178 at: https://wandb.ai/nreints/ThesisFinal1/runs/3svl8ynn
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_172807-3svl8ynn/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_173612-neyen42s
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run balmy-flower-208
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal1/runs/neyen42s
	 Logging test loss: 2.9341e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 3.9384e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 35.323190689086914
Epoch 4/9
	 Logging train Loss: 1.718e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.2232e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.3916e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.5238e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.1848e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.5109e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 35.17525672912598
Epoch 5/9
	 Logging train Loss: 7.9043e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.493e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 3.538e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.686e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 2.456e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 3.535e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 35.40528106689453
Epoch 6/9
	 Logging train Loss: 9.0474e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.8554e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 8.678e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.61818e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.8663e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.43605e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 35.25730490684509
Epoch 7/9
	 Logging train Loss: 1.19282e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.193e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 4.095e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 5.282e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 2.162e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 4.844e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 36.561065912246704
Epoch 8/9
	 Logging train Loss: 1.24668e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.12306e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 7.51799e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 0.000135773 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 2.1162e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 0.0001236379 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 36.57471799850464
Epoch 9/9
	 Logging train Loss: 7.3471e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.066e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 8.846e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.4125e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 3.022e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.3144e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 35.318270206451416
Saved model in  trained_models/gru/data_t(5,20)_r(0,0)_combi_pNone_gNone/'dual_quat_1'_'False'.pth
It took  484.2612335681915  seconds.
----- ITERATION 8/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 47.856714725494385 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(0,0)_full_pNone_gNone took 12.107588768005371 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 11.969006061553955 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_tennis_pNone_gNone took 12.104130744934082 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_none_pNone_gNone took 12.233409643173218 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_semi_pNone_gNone took 12.143577337265015 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0229628738 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 7.2611e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 8.28269e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 8.31622e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 7.04353e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 8.34216e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 35.55124282836914
Epoch 1/9
	 Logging train Loss: 6.97397e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 5.80357e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 6.40742e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 6.58081e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 5.64622e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 6.61902e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 35.58620095252991
Epoch 2/9
	 Logging train Loss: 5.21382e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 4.07292e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 4.4692e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 4.57768e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 3.9553e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 4.62419e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 35.3706841468811
Epoch 3/9
	 Logging train Loss: 3.26288e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.11544e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.35031e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.416e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 2.06193e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 2.46946e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 35.45094132423401
Epoch 4/9
	 Logging train Loss: 1.50133e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 6.7722e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.23185e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.73628e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 6.5851e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.70958e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 35.28035259246826
Epoch 5/9
	 Logging train Loss: 1.04696e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.1352e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.4072e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.4319e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.1378e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.4583e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 35.66138005256653
Epoch 6/9
	 Logging train Loss: 1.56131e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 4.037e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 5.694e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 5.728e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 3.944e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 5.611e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 35.51624011993408
Epoch 7/9
	 Logging train Loss: 1.12359e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.327e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone █▆▅▃▂▁▁▁▂▁
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone █▇▅▃▂▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone █▇▅▃▂▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone █▇▅▃▂▁▁▁▂▂
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone █▇▅▃▂▁▁▁▂▂
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone 1e-05
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone 1e-05
wandb:                                  Train loss 1e-05
wandb: 
wandb: 🚀 View run balmy-flower-208 at: https://wandb.ai/nreints/ThesisFinal1/runs/neyen42s
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_173612-neyen42s/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_174406-5ekdxe6i
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run warm-tree-232
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal1/runs/5ekdxe6i
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone ▇▅▃▂█▁▁▁▃▁
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone █▆▄▂▃▁▁▁▂▁
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone █▆▃▂▃▁▁▁▂▁
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone ▅▃▂▁█▁▁▁▃▁
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone ▅▃▂▁█▁▁▁▃▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone 0.0
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone 0.0
wandb:                                  Train loss 1e-05
wandb: 
wandb: 🚀 View run warm-tree-232 at: https://wandb.ai/nreints/ThesisFinal1/runs/5ekdxe6i
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_174406-5ekdxe6i/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_175158-59iqp9p6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run laced-jazz-258
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal1/runs/59iqp9p6
	 Logging test loss: 4.953e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 5.347e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 3.267e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 5.234e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 35.53692436218262
Epoch 8/9
	 Logging train Loss: 1.50928e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.1519e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 8.7011e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.71274e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.1119e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.66501e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 35.243064403533936
Epoch 9/9
	 Logging train Loss: 8.263e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 7.253e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 4.1282e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 7.6467e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 7.159e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 7.093e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 35.30141878128052
Saved model in  trained_models/gru/data_t(5,20)_r(0,0)_combi_pNone_gNone/'dual_quat_1'_'False'.pth
It took  474.4778232574463  seconds.
----- ITERATION 9/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 46.794617891311646 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(0,0)_full_pNone_gNone took 11.998887062072754 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 11.848950386047363 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_tennis_pNone_gNone took 11.96759295463562 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_none_pNone_gNone took 11.966593503952026 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_semi_pNone_gNone took 11.980897426605225 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0104675144 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 7.28779e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 7.78399e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 8.30758e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 7.10338e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 8.30731e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 35.08884263038635
Epoch 1/9
	 Logging train Loss: 6.26013e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 4.83863e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 4.92983e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 5.29493e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 4.70267e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 5.2738e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 35.20071744918823
Epoch 2/9
	 Logging train Loss: 3.80106e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.63473e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.65784e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.89046e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 2.55144e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 2.86424e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 35.03311848640442
Epoch 3/9
	 Logging train Loss: 1.77338e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 9.071e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 9.1807e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.02761e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 8.7384e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.01431e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 34.993473052978516
Epoch 4/9
	 Logging train Loss: 1.03554e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.19044e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 9.16448e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 0.0001608827 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 2.1836e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 0.0001560947 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 34.96308636665344
Epoch 5/9
	 Logging train Loss: 2.17132e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 6.608e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.1507e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.5872e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 6.264e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.5508e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 34.977667570114136
Epoch 6/9
	 Logging train Loss: 1.29466e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 4.692e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.6375e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.6328e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 4.58e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 2.5942e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 36.16595435142517
Epoch 7/9
	 Logging train Loss: 1.66247e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.202e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 4.649e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 4.805e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 3.062e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 4.844e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 36.02134418487549
Epoch 8/9
	 Logging train Loss: 1.51886e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 5.9295e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.49216e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 4.47556e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 5.9283e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 4.57636e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 34.869651556015015
Epoch 9/9
	 Logging train Loss: 1.20416e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.422e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 3.209e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.717e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 2.361e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 2.739e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 34.78981256484985
Saved model in  trained_models/gru/data_t(5,20)_r(0,0)_combi_pNone_gNone/'dual_quat_1'_'False'.pth
It took  472.0440900325775  seconds.
----- ITERATION 10/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 46.90561771392822 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(0,0)_full_pNone_gNone took 11.98352575302124 seconds.
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone █▆▄▃▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone █▇▅▃▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone █▇▅▃▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone █▆▄▃▁▁▁▁▁▁
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone █▆▄▃▁▁▁▁▁▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone 1e-05
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone 1e-05
wandb:                                  Train loss 1e-05
wandb: 
wandb: 🚀 View run laced-jazz-258 at: https://wandb.ai/nreints/ThesisFinal1/runs/59iqp9p6
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_175158-59iqp9p6/logs
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 11.851014375686646 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_tennis_pNone_gNone took 12.012861251831055 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_none_pNone_gNone took 12.009209871292114 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_semi_pNone_gNone took 12.011142015457153 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0315393023 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 7.37708e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 8.22919e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 9.04756e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 7.30291e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 8.92048e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 34.51133632659912
Epoch 1/9
	 Logging train Loss: 7.06816e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 5.97679e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 6.12843e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 6.50662e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 5.92297e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 6.35577e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 34.569551944732666
Epoch 2/9
	 Logging train Loss: 5.13569e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.93419e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 4.0642e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 4.28944e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 3.92541e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 4.2315e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 34.537092208862305
Epoch 3/9
	 Logging train Loss: 2.97416e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.72376e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.83466e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.98334e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.72654e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.94454e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 34.6503164768219
Epoch 4/9
	 Logging train Loss: 1.25705e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.4577e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 4.2359e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 4.9015e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 3.4837e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 4.8142e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 34.63076043128967
Epoch 5/9
	 Logging train Loss: 6.2351e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 4.432e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 9.176e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.1521e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 4.394e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.1306e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 35.00464487075806
Epoch 6/9
	 Logging train Loss: 7.9707e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.413e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 5.128e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 5.297e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 3.388e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 5.428e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 34.98212456703186
Epoch 7/9
	 Logging train Loss: 9.4219e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 9.55e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 3.8691e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 5.8249e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 9.439e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 6.0045e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 34.70746970176697
Epoch 8/9
	 Logging train Loss: 1.26873e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.692e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 3.656e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.41e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 2.656e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 3.365e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 34.66773080825806
Epoch 9/9
	 Logging train Loss: 1.23263e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 4.4206e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 4.9118e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 5.1178e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 4.4151e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 5.1384e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 34.8171968460083
Saved model in  trained_models/gru/data_t(5,20)_r(0,0)_combi_pNone_gNone/'dual_quat_1'_'False'.pth
It took  481.79091787338257  seconds.

JOB STATISTICS
==============
Job ID: 2971263
Array Job ID: 2971258_5
Cluster: snellius
User/Group: nreints/nreints
State: RUNNING
Nodes: 1
Cores per node: 18
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 23:57:18 core-walltime
Job Wall-clock time: 01:19:51
Memory Utilized: 0.00 MB (estimated maximum)
Memory Efficiency: 0.00% of 0.00 MB (0.00 MB/node)
WARNING: Efficiency statistics may be misleading for RUNNING jobs.
