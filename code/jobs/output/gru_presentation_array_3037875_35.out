wandb: Currently logged in as: nreints. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_180834-oldcz1kk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run elated-cloud-939
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/oldcz1kk
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue █▆▁▁▁▁▁▁▁▁
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue █▄▂▄▄▄▃▂▁▁
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue █▃▁▁▁▁▁▁▁▁
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue █▇▂▂▂▁▁▁▁▁
wandb:                                 Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 0.00407
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.0908
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.18429
wandb:                                 Train loss 1e-05
wandb: 
wandb: 🚀 View run elated-cloud-939 at: https://wandb.ai/nreints/ThesisFinal2/runs/oldcz1kk
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_180834-oldcz1kk/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_181658-w11krjik
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run worthy-dust-959
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/w11krjik
Training on dataset: data_t(0,0)_r(0,0)_combi_pNone_gTrue
Testing on 4 datasets: ['data_t(0,0)_r(0,0)_full_pTrue_gTrue', 'data_t(0,0)_r(0,0)_tennis_pTrue_gTrue', 'data_t(0,0)_r(0,0)_combi_pNone_gTrue', 'data_t(0,0)_r(0,0)_semi_pTrue_gTrue']
Focussing on identity: False
Using extra input: True
Using start-fr as reference point.
----- ITERATION 1/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 88.34096002578735 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 22.047014713287354 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 22.26136541366577 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 22.45173931121826 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 22.358640432357788 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (pre_hidden_lin_layer): Sequential(
    (0): Linear(in_features=3, out_features=96, bias=True)
    (1): ReLU()
    (2): Linear(in_features=96, out_features=96, bias=True)
    (3): ReLU()
  )
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: quat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.1131162941 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0041099335 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.2241428047 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0032541009 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1091656461 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 31.73223376274109
Epoch 1/9
	 Logging train Loss: 0.002641263 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0040827682 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.217057541 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0021695825 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0970188081 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 31.39005470275879
Epoch 2/9
	 Logging train Loss: 0.0012626278 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0040700999 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.1917008758 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.08255e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0913896486 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 31.2704336643219
Epoch 3/9
	 Logging train Loss: 1.41297e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0040869396 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.1895923018 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 8.4754e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0913722739 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 31.09569001197815
Epoch 4/9
	 Logging train Loss: 6.1428e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0040853303 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.1875729114 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 3.6922e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0916450247 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 31.256810188293457
Epoch 5/9
	 Logging train Loss: 3.3773e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0040849219 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.1865624338 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 3.2379e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0913761333 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 31.11996626853943
Epoch 6/9
	 Logging train Loss: 2.3763e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0040790373 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.1866727024 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.8766e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0910098627 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 31.227280378341675
Epoch 7/9
	 Logging train Loss: 2.4384e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0040716799 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.1860297322 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.3231e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0907988995 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 31.16273260116577
Epoch 8/9
	 Logging train Loss: 3.5074e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0040673455 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.1843672097 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.9507e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0907800645 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 30.983848571777344
Epoch 9/9
	 Logging train Loss: 5.0769e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0040670135 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.1842913032 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.4959e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0907967389 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 31.180188179016113
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'quat'_'True'.pth
It took  505.14138007164  seconds.
----- ITERATION 2/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 87.93304896354675 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 21.965796947479248 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 21.984914779663086 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 22.000160694122314 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 21.995854139328003 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (pre_hidden_lin_layer): Sequential(
    (0): Linear(in_features=3, out_features=96, bias=True)
    (1): ReLU()
    (2): Linear(in_features=96, out_features=96, bias=True)
    (3): ReLU()
  )
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: quat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0735542104 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0037973358 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.2873495817 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0001125316 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1087506413 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 31.48344659805298
Epoch 1/9
	 Logging train Loss: 6.69e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0037814339 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.2768012285 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 3.55908e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1052584201 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 31.328433990478516
Epoch 2/9
	 Logging train Loss: 2.26576e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0037760506 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.2701547146 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.3642e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1025298312 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 31.38774871826172
Epoch 3/9
	 Logging train Loss: 1.08824e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue █▃▂▂▂▁▁▃▁▁
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue ▃▁▁▂▃▄▅▇▇█
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue █▆▄▃▃▂▁▁▁▁
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue █▆▅▄▃▃▂▂▁▁
wandb:                                 Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 0.00387
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.09697
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.245
wandb:                                 Train loss 1e-05
wandb: 
wandb: 🚀 View run worthy-dust-959 at: https://wandb.ai/nreints/ThesisFinal2/runs/w11krjik
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_181658-w11krjik/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_182521-d8d1irpn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ancient-plant-979
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/d8d1irpn
	 Logging test loss: 0.0037900256 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.2647698224 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.75199e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1004932225 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 31.271950483322144
Epoch 4/9
	 Logging train Loss: 1.33496e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.003799933 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.2601251304 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.22021e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0996075496 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 31.338903427124023
Epoch 5/9
	 Logging train Loss: 1.79824e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0038238564 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.2556068003 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.6476e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0980811492 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 31.767215251922607
Epoch 6/9
	 Logging train Loss: 1.82861e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.003835032 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.2515685856 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.9865e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0974748209 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 31.814757108688354
Epoch 7/9
	 Logging train Loss: 1.2576e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0038605616 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.2495025694 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.80274e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0973677859 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 31.31282639503479
Epoch 8/9
	 Logging train Loss: 1.31314e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0038595367 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.2461372912 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 9.936e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0970934406 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 31.342342138290405
Epoch 9/9
	 Logging train Loss: 1.33141e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.003873657 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.245003745 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.3223e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0969734341 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 31.27274227142334
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'quat'_'True'.pth
It took  502.9696021080017  seconds.
----- ITERATION 3/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 88.19608783721924 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 22.069555521011353 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 22.054574251174927 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 22.036095142364502 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 22.01897954940796 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (pre_hidden_lin_layer): Sequential(
    (0): Linear(in_features=3, out_features=96, bias=True)
    (1): ReLU()
    (2): Linear(in_features=96, out_features=96, bias=True)
    (3): ReLU()
  )
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: quat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0968588665 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0039902828 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.3957785368 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 8.26717e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.3716070652 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 31.30186891555786
Epoch 1/9
	 Logging train Loss: 5.74036e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0039729574 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.3851824105 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 3.62584e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.3606303334 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 31.557206392288208
Epoch 2/9
	 Logging train Loss: 2.71981e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0039615948 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.3749997318 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.76983e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.35165295 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 31.427590131759644
Epoch 3/9
	 Logging train Loss: 1.3511e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.003966426 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.368945688 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 9.2908e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.3445044458 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 31.281790256500244
Epoch 4/9
	 Logging train Loss: 7.8249e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0039671562 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.3614932895 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 6.0012e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.3382538259 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 31.047215461730957
Epoch 5/9
	 Logging train Loss: 6.5229e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0039744596 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.3565557599 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0001135318 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.3328091204 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 31.475937604904175
Epoch 6/9
	 Logging train Loss: 1.21588e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0039623212 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.350941509 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.9105e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.3271659911 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 31.435607194900513
Epoch 7/9
	 Logging train Loss: 1.19716e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0040169694 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.3467229307 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 8.02316e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.3227638304 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 31.18632173538208
Epoch 8/9
	 Logging train Loss: 1.11647e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0040215924 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.3404355645 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 3.89177e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.3171390593 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 31.475470781326294
Epoch 9/9
	 Logging train Loss: 1.25367e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0040032282 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue ▆▃▂▁▁█▁▆▃▃
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue ▄▂▁▂▂▃▁▇█▆
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue █▇▆▅▄▃▃▂▂▁
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue █▇▆▅▄▃▃▂▂▁
wandb:                                 Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 4e-05
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 0.004
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.31195
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.33477
wandb:                                 Train loss 1e-05
wandb: 
wandb: 🚀 View run ancient-plant-979 at: https://wandb.ai/nreints/ThesisFinal2/runs/d8d1irpn
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_182521-d8d1irpn/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_183344-womyua2j
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run gentle-plasma-1003
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/womyua2j
wandb: Waiting for W&B process to finish... (success).
wandb: ERROR Error while calling W&B API: An internal error occurred. Please contact support. (<Response [500]>)
wandb: 
wandb: Run history:
wandb:                                      Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue █▃▂▁▁▁▁▂▁▁
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue ██▇▅▃▁▁▁▁▁
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue █▇▆▅▄▄▃▂▁▁
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue █▇▄▃▃▂▂▂▁▁
wandb:                                 Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 0.00355
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.18456
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.18542
wandb:                                 Train loss 1e-05
wandb: 
wandb: 🚀 View run gentle-plasma-1003 at: https://wandb.ai/nreints/ThesisFinal2/runs/womyua2j
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_183344-womyua2j/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_184228-k3py1xei
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run daily-glitter-1026
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/k3py1xei
	 Logging test loss: 0.334772259 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 3.88899e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.3119513988 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 31.495567321777344
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'quat'_'True'.pth
It took  503.0347578525543  seconds.
----- ITERATION 4/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 88.0660228729248 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 21.996118307113647 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 22.051066875457764 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 22.028162240982056 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 22.050633907318115 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (pre_hidden_lin_layer): Sequential(
    (0): Linear(in_features=3, out_features=96, bias=True)
    (1): ReLU()
    (2): Linear(in_features=96, out_features=96, bias=True)
    (3): ReLU()
  )
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: quat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0726820007 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0036117539 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.2058164775 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0001250318 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.2038330138 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 30.837194442749023
Epoch 1/9
	 Logging train Loss: 6.30096e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.00361319 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.201613158 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 4.18968e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.2015962154 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 30.70370578765869
Epoch 2/9
	 Logging train Loss: 2.85249e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0036062088 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.1955035329 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.98492e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1988248676 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 31.319854259490967
Epoch 3/9
	 Logging train Loss: 1.41129e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0035855696 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.1918573827 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.03074e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1956171989 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 31.339498043060303
Epoch 4/9
	 Logging train Loss: 9.4177e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0035726791 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.1910386831 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 6.5439e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1935168505 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 30.892571210861206
Epoch 5/9
	 Logging train Loss: 1.09402e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0035547428 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.1897035092 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 9.6109e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1920908391 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 30.688521146774292
Epoch 6/9
	 Logging train Loss: 1.88173e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0035571405 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.1887467951 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 3.8949e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1894680262 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 30.68486714363098
Epoch 7/9
	 Logging train Loss: 8.3504e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0035541998 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.1878208816 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.47918e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1877588183 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 30.954163789749146
Epoch 8/9
	 Logging train Loss: 1.31296e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0035534624 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.1863283366 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 7.2157e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1858006418 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 30.773813724517822
Epoch 9/9
	 Logging train Loss: 1.28064e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0035536233 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.1854180843 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.1092e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1845647991 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 30.858004570007324
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'quat'_'True'.pth
It took  524.4740431308746  seconds.
----- ITERATION 5/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 88.170658826828 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 22.005723476409912 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 22.085739850997925 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 22.000038862228394 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 21.982084035873413 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (pre_hidden_lin_layer): Sequential(
    (0): Linear(in_features=3, out_features=96, bias=True)
    (1): ReLU()
    (2): Linear(in_features=96, out_features=96, bias=True)
    (3): ReLU()
  )
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: quat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0688750669 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0036997327 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.2256537825 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 8.89696e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.3448347449 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 31.14283847808838
Epoch 1/9
	 Logging train Loss: 4.87186e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0036657702 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.2185418606 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.57063e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.3361025751 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 30.627687692642212
Epoch 2/9
	 Logging train Loss: 1.97083e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0036475908 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.2144625336 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.30828e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.3277827203 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 30.961669445037842
Epoch 3/9
wandb: Waiting for W&B process to finish... (success).
wandb: ERROR Error while calling W&B API: An internal error occurred. Please contact support. (<Response [500]>)
wandb: ERROR Error while calling W&B API: An internal error occurred. Please contact support. (<Response [500]>)
wandb: 
wandb: Run history:
wandb:                                      Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue █▃▂▁▁▁▁▁▂▁
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue █▆▅▄▃▂▂▂▂▁
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue █▇▆▅▄▄▃▂▁▁
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue █▇▆▆▄▄▃▂▂▁
wandb:                                 Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 0.00357
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.28601
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.17612
wandb:                                 Train loss 1e-05
wandb: 
wandb: 🚀 View run daily-glitter-1026 at: https://wandb.ai/nreints/ThesisFinal2/runs/k3py1xei
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_184228-k3py1xei/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_185104-qe37jpq1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sage-frog-1046
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/qe37jpq1
	 Logging train Loss: 1.93148e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0036354703 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.2087560594 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 7.7751e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.3207141757 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 30.648528575897217
Epoch 4/9
	 Logging train Loss: 2.69106e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0036039201 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.200556621 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 5.2011e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.3133738935 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 31.004530906677246
Epoch 5/9
	 Logging train Loss: 1.76504e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0035990647 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.1941327602 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 3.7899e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.3079358935 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 30.837680101394653
Epoch 6/9
	 Logging train Loss: 1.64894e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0035938711 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.1883267015 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.9878e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.3009592593 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 30.865821361541748
Epoch 7/9
	 Logging train Loss: 1.56725e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0035866825 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.184347868 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.7594e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.2971912324 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 30.990612030029297
Epoch 8/9
	 Logging train Loss: 1.27872e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0035910262 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.1798858941 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.93978e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.2896971405 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 30.684553623199463
Epoch 9/9
	 Logging train Loss: 1.26766e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0035736805 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.1761203557 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 3.6488e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.286013037 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 30.960057497024536
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'quat'_'True'.pth
It took  515.9978897571564  seconds.
----- ITERATION 6/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 87.9367892742157 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 21.9418363571167 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 21.972954034805298 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 21.97899627685547 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 21.95591640472412 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (pre_hidden_lin_layer): Sequential(
    (0): Linear(in_features=3, out_features=96, bias=True)
    (1): ReLU()
    (2): Linear(in_features=96, out_features=96, bias=True)
    (3): ReLU()
  )
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: quat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0614752509 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0037171356 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.2360057831 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 8.50194e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.2440229803 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 30.671658277511597
Epoch 1/9
	 Logging train Loss: 4.65173e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0036936121 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.2275625318 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.68544e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.230813697 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 31.058141946792603
Epoch 2/9
	 Logging train Loss: 1.89737e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0036818262 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.2220374346 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.44038e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.221737355 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 31.01127004623413
Epoch 3/9
	 Logging train Loss: 1.43131e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0036876402 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.2167325467 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 9.188e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.212843582 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 30.858949899673462
Epoch 4/9
	 Logging train Loss: 1.38383e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0036977439 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.2127737999 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 6.9425e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.2062840313 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 30.793922424316406
Epoch 5/9
	 Logging train Loss: 2.22276e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0036983681 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.2076710016 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 7.904e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.202969864 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 30.978548288345337
Epoch 6/9
	 Logging train Loss: 1.05305e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0037201268 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.2040391415 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 3.5324e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1990098357 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 30.789082527160645
Epoch 7/9
	 Logging train Loss: 1.56028e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0037166008 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.2020165473 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.77624e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1972042769 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 30.833776235580444
Epoch 8/9
	 Logging train Loss: 1.06356e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0037249341 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.198325932 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.8379e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1945123523 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 30.80238938331604
Epoch 9/9
	 Logging train Loss: 1.30135e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue █▃▂▂▁▁▁▃▁▁
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue ▆▃▁▂▃▃▇▆▇█
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue █▆▅▄▃▂▂▂▁▁
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue █▇▆▅▄▃▂▂▁▁
wandb:                                 Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 1e-05
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 0.00373
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.19245
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.19581
wandb:                                 Train loss 1e-05
wandb: 
wandb: 🚀 View run sage-frog-1046 at: https://wandb.ai/nreints/ThesisFinal2/runs/qe37jpq1
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_185104-qe37jpq1/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_185922-af86b22l
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run colorful-brook-1064
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/af86b22l
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue ▂▁▁▁▁▁▁▁█▁
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue ▃▁▁▁▂▂▄▅█▆
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue █▇▅▄▃▃▂▂▁▁
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue █▆▄▄▃▂▂▁▂▁
wandb:                                 Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 0.00347
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.23063
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.11588
wandb:                                 Train loss 1e-05
wandb: 
wandb: 🚀 View run colorful-brook-1064 at: https://wandb.ai/nreints/ThesisFinal2/runs/af86b22l
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_185922-af86b22l/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_190746-oxq6a10u
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run genial-plasma-1083
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/oxq6a10u
	 Logging test loss: 0.0037293276 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.1958085001 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 6.3526e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1924491376 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 30.827577590942383
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'quat'_'True'.pth
It took  497.16109466552734  seconds.
----- ITERATION 7/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 87.93782472610474 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 21.985737323760986 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 21.896836042404175 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 22.058732509613037 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 21.966939449310303 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (pre_hidden_lin_layer): Sequential(
    (0): Linear(in_features=3, out_features=96, bias=True)
    (1): ReLU()
    (2): Linear(in_features=96, out_features=96, bias=True)
    (3): ReLU()
  )
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: quat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0527494103 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0034258943 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.1303711683 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 8.56254e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.2977182865 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 31.137433767318726
Epoch 1/9
	 Logging train Loss: 5.15372e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.003409846 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.1263209283 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 3.07967e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.283770442 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 31.58967351913452
Epoch 2/9
	 Logging train Loss: 2.09104e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.003408026 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.1231191531 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.55362e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.2711080909 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 31.108316659927368
Epoch 3/9
	 Logging train Loss: 1.15808e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0034068546 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.121934101 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.00758e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.2601952553 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 31.084171295166016
Epoch 4/9
	 Logging train Loss: 1.40529e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0034161229 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.1205638871 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 8.3811e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.2531095445 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 30.975075006484985
Epoch 5/9
	 Logging train Loss: 1.53201e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0034202531 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.1188499928 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 3.1404e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.2467503697 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 31.348701000213623
Epoch 6/9
	 Logging train Loss: 1.61039e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0034374841 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.1184807643 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.7566e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.2427991629 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 31.2190682888031
Epoch 7/9
	 Logging train Loss: 1.42068e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0034570033 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.1167012081 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.269e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.2381389588 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 31.095943450927734
Epoch 8/9
	 Logging train Loss: 1.43804e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0034882934 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.1177809089 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0005502676 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.2353455126 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 31.528668880462646
Epoch 9/9
	 Logging train Loss: 1.19851e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0034664702 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.1158838794 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.4557e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.2306347489 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 31.062400817871094
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'quat'_'True'.pth
It took  504.44597935676575  seconds.
----- ITERATION 8/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 88.36099672317505 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 22.024826765060425 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 21.971717834472656 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 22.133415699005127 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 22.104925394058228 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (pre_hidden_lin_layer): Sequential(
    (0): Linear(in_features=3, out_features=96, bias=True)
    (1): ReLU()
    (2): Linear(in_features=96, out_features=96, bias=True)
    (3): ReLU()
  )
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: quat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.1195418462 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.004813978 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.2309919745 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0018039343 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1720599681 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 31.018946647644043
Epoch 1/9
	 Logging train Loss: 0.0002629023 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.00362926 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.2169133127 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 5.57911e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1596736014 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 31.338173151016235
Epoch 2/9
	 Logging train Loss: 3.78105e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0036192497 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.2159250379 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.53627e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue █▁▁▁▁▁▁▁▁▁
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue █▁▁▁▁▁▁▁▁▁
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue █▃▃▃▂▂▂▂▁▁
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue █▃▂▂▂▂▁▁▁▁
wandb:                                 Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 0.00359
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.15393
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.21205
wandb:                                 Train loss 1e-05
wandb: 
wandb: 🚀 View run genial-plasma-1083 at: https://wandb.ai/nreints/ThesisFinal2/runs/oxq6a10u
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_190746-oxq6a10u/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_191606-nzjqceze
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run tough-gorge-1097
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/nzjqceze
	 Logging test loss: 0.1584810466 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 31.067314624786377
Epoch 3/9
	 Logging train Loss: 2.04774e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0036046363 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.2160453796 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.57113e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1582268327 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 30.889709949493408
Epoch 4/9
	 Logging train Loss: 1.31795e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.003590818 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.214213714 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.04897e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1570197791 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 31.197152376174927
Epoch 5/9
	 Logging train Loss: 9.2006e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0035926586 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.2148638368 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 7.138e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1560466737 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 30.919327974319458
Epoch 6/9
	 Logging train Loss: 6.5655e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0035858734 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.2129958272 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 5.2833e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1555443257 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 31.009548664093018
Epoch 7/9
	 Logging train Loss: 5.0538e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0035891104 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.21246171 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 3.4862e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1564794332 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 30.960939645767212
Epoch 8/9
	 Logging train Loss: 6.6251e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0035954239 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.2120637745 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 8.656e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1542258114 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 30.930131435394287
Epoch 9/9
	 Logging train Loss: 8.4993e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0035860818 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.2120475471 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.5323e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1539285034 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 30.783838272094727
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'quat'_'True'.pth
It took  500.20604944229126  seconds.
----- ITERATION 9/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 88.30756664276123 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 22.01313591003418 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 22.082501888275146 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 22.13368797302246 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 21.964436054229736 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (pre_hidden_lin_layer): Sequential(
    (0): Linear(in_features=3, out_features=96, bias=True)
    (1): ReLU()
    (2): Linear(in_features=96, out_features=96, bias=True)
    (3): ReLU()
  )
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: quat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0864467695 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0037722834 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.3761346638 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0001265549 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.351637423 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 31.007943153381348
Epoch 1/9
	 Logging train Loss: 6.60657e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0037179475 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.3664846718 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 3.56708e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.3421078324 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 31.43876361846924
Epoch 2/9
	 Logging train Loss: 2.28211e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0037002226 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.3674340248 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.45326e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.3399742246 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 30.744107961654663
Epoch 3/9
	 Logging train Loss: 1.1194e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0037010603 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.3676481247 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 8.5193e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.3403727114 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 31.108741998672485
Epoch 4/9
	 Logging train Loss: 9.8218e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0037017306 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.3655832112 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 6.2998e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.3402747512 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 30.90107297897339
Epoch 5/9
	 Logging train Loss: 1.11702e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0037034259 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.3602464795 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.01716e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.3402142525 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 31.135571479797363
Epoch 6/9
	 Logging train Loss: 1.41585e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.003704573 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.3522060513 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 5.781e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.3387247622 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 31.30698299407959
Epoch 7/9
	 Logging train Loss: 1.24999e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0036948887 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.3473784626 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 7.5023e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.336797744 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 31.0023136138916
Epoch 8/9
	 Logging train Loss: 1.36608e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0037114336 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.3430598378 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 9.9927e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.3365432024 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue █▃▂▁▁▁▁▁▁▁
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue █▄▂▂▂▂▂▂▃▁
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue █▅▄▄▄▄▃▃▃▁
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue █▆▆▆▆▅▄▃▂▁
wandb:                                 Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 0.00369
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.33165
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.33825
wandb:                                 Train loss 1e-05
wandb: 
wandb: 🚀 View run tough-gorge-1097 at: https://wandb.ai/nreints/ThesisFinal2/runs/nzjqceze
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_191606-nzjqceze/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_192429-sie0l6c4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run swept-field-1109
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/sie0l6c4
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue ▄▂▁█▁▁▁▁▅▁
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue ▃▁▁▂▂▃▃▄█▄
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue █▆▅▄▃▂▂▁▁▁
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue █▆▄▄▃▃▂▂▁▁
wandb:                                 Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 0.00339
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.25606
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.38133
wandb:                                 Train loss 1e-05
wandb: 
wandb: 🚀 View run swept-field-1109 at: https://wandb.ai/nreints/ThesisFinal2/runs/sie0l6c4
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_192429-sie0l6c4/logs
		--> Epoch time; 31.55978775024414
Epoch 9/9
	 Logging train Loss: 1.32234e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0036866055 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.3382468224 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 3.7992e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.3316491246 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 31.78202176094055
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'quat'_'True'.pth
It took  502.69536662101746  seconds.
----- ITERATION 10/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 88.05460596084595 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 22.126630544662476 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 22.04291820526123 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 21.969130992889404 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 22.068466663360596 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (pre_hidden_lin_layer): Sequential(
    (0): Linear(in_features=3, out_features=96, bias=True)
    (1): ReLU()
    (2): Linear(in_features=96, out_features=96, bias=True)
    (3): ReLU()
  )
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: quat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.040838223 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0033653814 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.4283643663 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 7.30231e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.3050237596 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 31.146064281463623
Epoch 1/9
	 Logging train Loss: 4.3717e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0033322009 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.4127469063 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 3.99956e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.2920071483 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 31.035574913024902
Epoch 2/9
	 Logging train Loss: 2.9468e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0033289134 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.4020558894 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 9.8214e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.2813676298 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 31.42243528366089
Epoch 3/9
	 Logging train Loss: 2.00142e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0033457999 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.3981328011 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0001900716 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.275598228 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 31.068650007247925
Epoch 4/9
	 Logging train Loss: 1.81059e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0033521808 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.3934226334 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 3.5521e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.2696220279 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 31.008045434951782
Epoch 5/9
	 Logging train Loss: 2.39767e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0033610084 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.3956147134 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.2915e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.2632737756 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 31.284818172454834
Epoch 6/9
	 Logging train Loss: 6.2932e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0033645316 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.3911795318 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 4.4442e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.2657274902 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 30.86820888519287
Epoch 7/9
	 Logging train Loss: 1.09824e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0033739281 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.3861905634 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.2293e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.2582051754 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 31.329122066497803
Epoch 8/9
	 Logging train Loss: 1.09022e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0034451054 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.382873565 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0001171211 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.2558552921 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 31.019484519958496
Epoch 9/9
	 Logging train Loss: 1.05208e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0033861164 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.3813295662 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.0381e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.2560645342 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 31.184608459472656
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'quat'_'True'.pth
It took  501.2123532295227  seconds.

JOB STATISTICS
==============
Job ID: 3037996
Array Job ID: 3037875_35
Cluster: snellius
User/Group: nreints/nreints
State: RUNNING
Nodes: 1
Cores per node: 18
CPU Utilized: 01:29:34
CPU Efficiency: 5.89% of 1-01:21:18 core-walltime
Job Wall-clock time: 01:24:31
Memory Utilized: 7.64 GB
Memory Efficiency: 0.00% of 0.00 MB
WARNING: Efficiency statistics may be misleading for RUNNING jobs.
