wandb: Currently logged in as: nreints. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home/nreints/.netrc
/gpfs/home2/nreints/MScThesis/code/fcnn.py:566: DeprecationWarning: Sampling from a set deprecated
since Python 3.9 and will be removed in a subsequent version.
  train_sims = set(random.sample(sims_train, int(0.8 * n_sims_train)))
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230330_123650-9z8mc20i
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run apricot-pyramid-583
wandb: â­ï¸ View project at https://wandb.ai/nreints/test
wandb: ðŸš€ View run at https://wandb.ai/nreints/test/runs/9z8mc20i
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.029 MB of 0.029 MB uploaded (0.000 MB deduped)wandb: \ 0.029 MB of 0.078 MB uploaded (0.000 MB deduped)wandb: | 0.078 MB of 0.078 MB uploaded (0.000 MB deduped)wandb: / 0.078 MB of 0.078 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  Test loss t(0, 0)_r(5, 20)_tennis L1Loss() â–ˆâ–†â–†â–„â–„â–„â–„â–„â–ƒâ–‚â–ƒâ–‚â–‚â–‚â–â–â–‚â–â–‚â–â–
wandb: Test loss t(0, 0)_r(5, 20)_tennis MSELoss() â–ˆâ–…â–…â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–
wandb:     Train loss data_t(0, 0)_r(5, 20)_tennis â–ˆâ–ƒâ–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:  Test loss t(0, 0)_r(5, 20)_tennis L1Loss() 0.66729
wandb: Test loss t(0, 0)_r(5, 20)_tennis MSELoss() 2.3522
wandb:     Train loss data_t(0, 0)_r(5, 20)_tennis 2.52671
wandb: 
wandb: ðŸš€ View run apricot-pyramid-583 at: https://wandb.ai/nreints/test/runs/9z8mc20i
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230330_123650-9z8mc20i/logs
/gpfs/home2/nreints/MScThesis/code/fcnn.py:566: DeprecationWarning: Sampling from a set deprecated
since Python 3.9 and will be removed in a subsequent version.
  train_sims = set(random.sample(sims_train, int(0.8 * n_sims_train)))
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230330_124853-7287ofkg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run worthy-blaze-636
wandb: â­ï¸ View project at https://wandb.ai/nreints/test
wandb: ðŸš€ View run at https://wandb.ai/nreints/test/runs/7287ofkg
Training on dataset: data/data_t(0, 0)_r(5, 20)_tennis_pNone_gNone
Testing on datasets: ['data_t(0, 0)_r(5, 20)_tennis_pNone_gNone']
----- ITERATION 1/2 ------
Number of train simulations: 1600
Number of test simulations: 400
The dataloader took 61.838563680648804 seconds.
-- Finished Train Dataloader --
The dataloader took 15.628031492233276 seconds.
-- Finished Test Dataloader(s) --
Datatype: dual_quat
--- Started Training ---
Epoch 0
	 Logging train Loss: 38.1851945466 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 15.30445671081543 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 1.7554776668548584 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 31.977058172225952
Epoch 1
	 Logging train Loss: 11.6968788297 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 10.181413650512695 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 1.4051122665405273 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 32.069363594055176
Epoch 2
	 Logging train Loss: 8.7924766391 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 8.912577629089355 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 1.3723825216293335 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 32.248258113861084
Epoch 3
	 Logging train Loss: 7.7538105086 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 6.4017252922058105 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 1.1831830739974976 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 31.802975177764893
Epoch 4
	 Logging train Loss: 6.5983028237 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 6.41945219039917 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 1.1416254043579102 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 31.957064390182495
Epoch 5
	 Logging train Loss: 5.944129136 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 5.428442478179932 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 1.0716907978057861 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 32.47368907928467
Epoch 6
	 Logging train Loss: 5.2209143944 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 5.450952529907227 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 1.0581097602844238 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 32.31350660324097
Epoch 7
	 Logging train Loss: 4.7381583818 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 5.6346821784973145 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 1.1297460794448853 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 31.812324047088623
Epoch 8
	 Logging train Loss: 4.6903866039 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 4.781121253967285 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.9775959253311157 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 32.287370681762695
Epoch 9
	 Logging train Loss: 4.3565362669 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 3.983276128768921 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.8959941267967224 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 30.7508761882782
Epoch 10
	 Logging train Loss: 3.8604948555 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 4.030521392822266 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.9112085103988647 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 30.75050163269043
Epoch 11
	 Logging train Loss: 3.7166902829 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 3.8900506496429443 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.85516756772995 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 30.789851903915405
Epoch 12
	 Logging train Loss: 3.4129343469 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 3.0278284549713135 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.7603175640106201 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 30.62261962890625
Epoch 13
	 Logging train Loss: 3.0651769301 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 3.0613369941711426 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.8503041863441467 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 31.861793279647827
Epoch 14
	 Logging train Loss: 3.0404571334 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 2.5970335006713867 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.7353659868240356 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 30.626479625701904
Epoch 15
	 Logging train Loss: 2.7919905918 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 2.6358282566070557 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.6770099997520447 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 30.560150861740112
Epoch 16
	 Logging train Loss: 2.9265002681 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 2.815493106842041 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.7646631002426147 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 30.429977416992188
Epoch 17
	 Logging train Loss: 2.7807467193 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 2.593640089035034 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.7091233134269714 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 30.606723070144653
Epoch 18
	 Logging train Loss: 2.4134867749 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 2.786442279815674 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.8346531391143799 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 30.707278966903687
Epoch 19
	 Logging train Loss: 2.5267137714 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 2.357882022857666 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.6672175526618958 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 32.20820593833923
	 Logging test loss 2.3522043228149414 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.6672877073287964 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
It took 722.5449712276459 seconds to train & eval the model.
----- ITERATION 2/2 ------
Number of train simulations: 1600
Number of test simulations: 400
The dataloader took 57.4700071811676 seconds.
-- Finished Train Dataloader --
The dataloader took 14.54087495803833 seconds.
-- Finished Test Dataloader(s) --
Datatype: dual_quat
--- Started Training ---
Epoch 0
	 Logging train Loss: 37.848340482 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 14.418968200683594 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 1.7451895475387573 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 32.53649353981018
Epoch 1
	 Logging train Loss: 11.2345103145 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 8.959127426147461 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 1.364327311515808 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 30.79638648033142
Epoch 2
	 Logging train Loss: 8.8634854984 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 12.420304298400879 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 1.716709017753601 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 30.597843647003174
Epoch 3
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:  Test loss t(0, 0)_r(5, 20)_tennis L1Loss() â–ˆâ–†â–ˆâ–„â–„â–ƒâ–ƒâ–„â–ƒâ–ƒâ–‚â–ƒâ–ƒâ–‚â–‚â–‚â–ƒâ–ƒâ–‚â–â–
wandb: Test loss t(0, 0)_r(5, 20)_tennis MSELoss() â–ˆâ–…â–‡â–ƒâ–ƒâ–ƒâ–‚â–ƒâ–‚â–‚â–â–‚â–‚â–‚â–â–â–‚â–‚â–â–â–
wandb:     Train loss data_t(0, 0)_r(5, 20)_tennis â–ˆâ–ƒâ–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:  Test loss t(0, 0)_r(5, 20)_tennis L1Loss() 0.51586
wandb: Test loss t(0, 0)_r(5, 20)_tennis MSELoss() 1.76457
wandb:     Train loss data_t(0, 0)_r(5, 20)_tennis 2.29223
wandb: 
wandb: ðŸš€ View run worthy-blaze-636 at: https://wandb.ai/nreints/test/runs/7287ofkg
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230330_124853-7287ofkg/logs
	 Logging train Loss: 7.2752342473 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 6.208231449127197 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 1.098188042640686 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 30.283965587615967
Epoch 4
	 Logging train Loss: 6.1723907271 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 5.25458288192749 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 1.061718225479126 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 32.27677130699158
Epoch 5
	 Logging train Loss: 5.7059614992 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 4.49630069732666 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.9327394962310791 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 31.882476091384888
Epoch 6
	 Logging train Loss: 5.0161653008 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 4.021657943725586 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.877055823802948 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 31.858896732330322
Epoch 7
	 Logging train Loss: 4.7249639374 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 4.595273017883301 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 1.0242176055908203 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 30.719934940338135
Epoch 8
	 Logging train Loss: 4.3723259421 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 3.312589168548584 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.8110116720199585 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 30.67853808403015
Epoch 9
	 Logging train Loss: 3.9651322508 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 3.7219598293304443 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.9492111802101135 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 30.844284296035767
Epoch 10
	 Logging train Loss: 3.607976537 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 2.5302228927612305 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.6863613128662109 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 30.334364414215088
Epoch 11
	 Logging train Loss: 3.3322450725 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 3.5404694080352783 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.8302967548370361 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 32.022090911865234
Epoch 12
	 Logging train Loss: 3.2807607613 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 3.1203691959381104 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.8114834427833557 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 30.976887941360474
Epoch 13
	 Logging train Loss: 3.184273195 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 2.7603492736816406 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.7549460530281067 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 30.867532968521118
Epoch 14
	 Logging train Loss: 2.7810384115 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 2.5707411766052246 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.6852083802223206 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 30.592921257019043
Epoch 15
	 Logging train Loss: 2.836996081 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 2.4529757499694824 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.6569207310676575 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 30.227100372314453
Epoch 16
	 Logging train Loss: 2.4482694738 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 3.1632020473480225 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.8469358682632446 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 32.11650347709656
Epoch 17
	 Logging train Loss: 2.5098372715 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 3.083500623703003 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.8618466854095459 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 32.05877709388733
Epoch 18
	 Logging train Loss: 2.4675572215 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 2.477998733520508 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.6979886293411255 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 31.91368055343628
Epoch 19
	 Logging train Loss: 2.2922336155 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 1.7642329931259155 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.5158219337463379 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 31.2212815284729
	 Logging test loss 1.7645719051361084 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.5158605575561523 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
It took 713.967643737793 seconds to train & eval the model.

JOB STATISTICS
==============
Job ID: 2523387
Array Job ID: 2523368_19
Cluster: snellius
User/Group: nreints/nreints
State: COMPLETED (exit code 0)
Nodes: 1
Cores per node: 18
CPU Utilized: 03:45:30
CPU Efficiency: 51.66% of 07:16:30 core-walltime
Job Wall-clock time: 00:24:15
Memory Utilized: 3.64 GB
Memory Efficiency: 12.41% of 29.30 GB
