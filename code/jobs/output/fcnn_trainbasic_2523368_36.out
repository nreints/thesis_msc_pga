wandb: Currently logged in as: nreints. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home/nreints/.netrc
/gpfs/home2/nreints/MScThesis/code/fcnn.py:566: DeprecationWarning: Sampling from a set deprecated
since Python 3.9 and will be removed in a subsequent version.
  train_sims = set(random.sample(sims_train, int(0.8 * n_sims_train)))
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230330_123650-t6o7j9t7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run deft-grass-596
wandb: ⭐️ View project at https://wandb.ai/nreints/test
wandb: 🚀 View run at https://wandb.ai/nreints/test/runs/t6o7j9t7
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:  Test loss t(5, 20)_r(0, 0)_full L1Loss() █▅▆▃▃▃▃▃▃▂▂▄▂▂▂▂▁▄▁▁▁
wandb: Test loss t(5, 20)_r(0, 0)_full MSELoss() █▄▃▂▂▂▂▂▂▁▁▂▁▁▁▁▁▂▁▁▁
wandb:     Train loss data_t(5, 20)_r(0, 0)_full █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:  Test loss t(5, 20)_r(0, 0)_full L1Loss() 0.0392
wandb: Test loss t(5, 20)_r(0, 0)_full MSELoss() 0.00283
wandb:     Train loss data_t(5, 20)_r(0, 0)_full 0.00495
wandb: 
wandb: 🚀 View run deft-grass-596 at: https://wandb.ai/nreints/test/runs/t6o7j9t7
wandb: Synced 6 W&B file(s), 0 media file(s), 2 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230330_123650-t6o7j9t7/logs
/gpfs/home2/nreints/MScThesis/code/fcnn.py:566: DeprecationWarning: Sampling from a set deprecated
since Python 3.9 and will be removed in a subsequent version.
  train_sims = set(random.sample(sims_train, int(0.8 * n_sims_train)))
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230330_124635-pawf8o0p
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run legendary-gorge-600
wandb: ⭐️ View project at https://wandb.ai/nreints/test
wandb: 🚀 View run at https://wandb.ai/nreints/test/runs/pawf8o0p
Training on dataset: data/data_t(5, 20)_r(0, 0)_full_pNone_gNone
Testing on datasets: ['data_t(5, 20)_r(0, 0)_full_pNone_gNone']
----- ITERATION 1/2 ------
Number of train simulations: 1600
Number of test simulations: 400
The dataloader took 54.882364988327026 seconds.
-- Finished Train Dataloader --
The dataloader took 13.687713623046875 seconds.
-- Finished Test Dataloader(s) --
Datatype: pos
--- Started Training ---
Epoch 0
	 Logging train Loss: 5.9905560662 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.12461938709020615 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.19887253642082214 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
     --> Epoch time; 24.61571455001831
Epoch 1
	 Logging train Loss: 0.0690166748 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.05114324763417244 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.13583272695541382 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
     --> Epoch time; 25.86276149749756
Epoch 2
	 Logging train Loss: 0.0369561937 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.041372425854206085 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.14284051954746246 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
     --> Epoch time; 25.63159966468811
Epoch 3
	 Logging train Loss: 0.0262855979 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.022962385788559914 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.09299377351999283 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
     --> Epoch time; 25.64508080482483
Epoch 4
	 Logging train Loss: 0.0211834876 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.018943792209029198 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.08910293132066727 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
     --> Epoch time; 25.82578420639038
Epoch 5
	 Logging train Loss: 0.0174658657 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.01575874537229538 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.08233359456062317 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
     --> Epoch time; 25.59460425376892
Epoch 6
	 Logging train Loss: 0.0155541389 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.013150724582374096 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.07645749300718307 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
     --> Epoch time; 25.268425226211548
Epoch 7
	 Logging train Loss: 0.0132516736 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.01217644102871418 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.07653675973415375 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
     --> Epoch time; 25.64297127723694
Epoch 8
	 Logging train Loss: 0.0118362128 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.012819468043744564 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.0832117423415184 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
     --> Epoch time; 25.760326623916626
Epoch 9
	 Logging train Loss: 0.0109649995 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.008370703086256981 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.06310980021953583 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
     --> Epoch time; 25.99102544784546
Epoch 10
	 Logging train Loss: 0.0094117408 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.007914961315691471 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.0632057785987854 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
     --> Epoch time; 25.51703977584839
Epoch 11
	 Logging train Loss: 0.0089778021 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.01595517247915268 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.10113149136304855 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
     --> Epoch time; 25.435290098190308
Epoch 12
	 Logging train Loss: 0.0080417764 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.007726641371846199 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.0656210407614708 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
     --> Epoch time; 23.837788820266724
Epoch 13
	 Logging train Loss: 0.0076777115 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.0056468406692147255 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.05517027899622917 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
     --> Epoch time; 24.242597103118896
Epoch 14
	 Logging train Loss: 0.0072838104 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.005437265150249004 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.05515684559941292 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
     --> Epoch time; 23.998183488845825
Epoch 15
	 Logging train Loss: 0.0060370208 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.005329715553671122 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.05531743913888931 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
     --> Epoch time; 23.628395557403564
Epoch 16
	 Logging train Loss: 0.0060430558 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.003707998199388385 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.04413502290844917 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
     --> Epoch time; 25.59341335296631
Epoch 17
	 Logging train Loss: 0.0054950833 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.017410989850759506 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.10163380205631256 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
     --> Epoch time; 23.680299758911133
Epoch 18
	 Logging train Loss: 0.0054367689 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.0028682465199381113 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.03886302933096886 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
     --> Epoch time; 24.10490655899048
Epoch 19
	 Logging train Loss: 0.00495004 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.0028251619078218937 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.03920246288180351 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
     --> Epoch time; 23.85274863243103
	 Logging test loss 0.002825518138706684 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.03920435160398483 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
It took 584.2473955154419 seconds to train & eval the model.
----- ITERATION 2/2 ------
Number of train simulations: 1600
Number of test simulations: 400
The dataloader took 50.73071026802063 seconds.
-- Finished Train Dataloader --
The dataloader took 12.594698905944824 seconds.
-- Finished Test Dataloader(s) --
Datatype: pos
--- Started Training ---
Epoch 0
	 Logging train Loss: 5.7148577921 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.11511021107435226 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.1916458159685135 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
     --> Epoch time; 26.222633123397827
Epoch 1
	 Logging train Loss: 0.057143801 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.042452193796634674 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.12613078951835632 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
     --> Epoch time; 24.117010354995728
Epoch 2
	 Logging train Loss: 0.0301060945 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.02823587693274021 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.10784060508012772 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
     --> Epoch time; 24.12942671775818
Epoch 3
	 Logging train Loss: 0.0218033635 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:  Test loss t(5, 20)_r(0, 0)_full L1Loss() █▅▄▄▃▃▃▂▂▂▂▂▃▂▂▃▂▁▁▂▂
wandb: Test loss t(5, 20)_r(0, 0)_full MSELoss() █▄▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     Train loss data_t(5, 20)_r(0, 0)_full █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:  Test loss t(5, 20)_r(0, 0)_full L1Loss() 0.06436
wandb: Test loss t(5, 20)_r(0, 0)_full MSELoss() 0.00825
wandb:     Train loss data_t(5, 20)_r(0, 0)_full 0.00426
wandb: 
wandb: 🚀 View run legendary-gorge-600 at: https://wandb.ai/nreints/test/runs/pawf8o0p
wandb: Synced 6 W&B file(s), 0 media file(s), 2 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230330_124635-pawf8o0p/logs
	 Logging test loss 0.02108735963702202 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.09665509313344955 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
     --> Epoch time; 23.791857481002808
Epoch 4
	 Logging train Loss: 0.0174191805 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.016957754269242287 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.0889621153473854 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
     --> Epoch time; 25.526873350143433
Epoch 5
	 Logging train Loss: 0.0150415258 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.012497108429670334 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.07569308578968048 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
     --> Epoch time; 25.46136450767517
Epoch 6
	 Logging train Loss: 0.0123360752 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.012416373006999493 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.08139178156852722 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
     --> Epoch time; 25.525946617126465
Epoch 7
	 Logging train Loss: 0.0108921974 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.008626495487987995 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.06459727138280869 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
     --> Epoch time; 24.072248220443726
Epoch 8
	 Logging train Loss: 0.009958544 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.008132535964250565 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.06582450866699219 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
     --> Epoch time; 23.954843044281006
Epoch 9
	 Logging train Loss: 0.0086040846 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.006694751791656017 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.060064252465963364 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
     --> Epoch time; 24.328465223312378
Epoch 10
	 Logging train Loss: 0.0081234041 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.006376421079039574 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.059384800493717194 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
     --> Epoch time; 23.65281653404236
Epoch 11
	 Logging train Loss: 0.007425062 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.004903932102024555 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.05107526481151581 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
     --> Epoch time; 25.434898853302002
Epoch 12
	 Logging train Loss: 0.006690183 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.007483368273824453 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.06676335632801056 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
     --> Epoch time; 24.041599988937378
Epoch 13
	 Logging train Loss: 0.0060859138 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.006280323024839163 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.06289797276258469 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
     --> Epoch time; 23.974953413009644
Epoch 14
	 Logging train Loss: 0.005758854 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.006242438219487667 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.061400171369314194 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
     --> Epoch time; 23.956007719039917
Epoch 15
	 Logging train Loss: 0.0053350654 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.00852589588612318 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.07434652000665665 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
     --> Epoch time; 23.68431305885315
Epoch 16
	 Logging train Loss: 0.0051403759 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.004899688996374607 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.05636179819703102 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
     --> Epoch time; 25.916648149490356
Epoch 17
	 Logging train Loss: 0.0046087673 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.0022267207968980074 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.03540428727865219 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
     --> Epoch time; 25.64015769958496
Epoch 18
	 Logging train Loss: 0.0046338605 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.001930178957991302 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.032417722046375275 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
     --> Epoch time; 25.48662281036377
Epoch 19
	 Logging train Loss: 0.0042631826 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.008249152451753616 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.06436117738485336 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
     --> Epoch time; 24.122600555419922
	 Logging test loss 0.00824927631765604 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.06435946375131607 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
It took 572.0361065864563 seconds to train & eval the model.

JOB STATISTICS
==============
Job ID: 2523404
Array Job ID: 2523368_36
Cluster: snellius
User/Group: nreints/nreints
State: COMPLETED (exit code 0)
Nodes: 1
Cores per node: 18
CPU Utilized: 02:53:27
CPU Efficiency: 49.29% of 05:51:54 core-walltime
Job Wall-clock time: 00:19:33
Memory Utilized: 8.17 GB
Memory Efficiency: 27.89% of 29.30 GB
