wandb: Currently logged in as: nreints. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230629_111856-go71q8nx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cool-disco-24
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/go71q8nx
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone █▄▃▂▂▂▄▇▁▃
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone ▇▄▂▂▁▁▃█▁▂
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone ▇▄▂▂▁▁▃█▁▂
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone ▆▃▃▂▂▂▅█▁▃
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone ▆▃▂▂▂▂▅█▁▃
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone 1e-05
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone 2e-05
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone 2e-05
wandb:                                  Train loss 1e-05
wandb: 
wandb: 🚀 View run cool-disco-24 at: https://wandb.ai/nreints/ThesisFinal2/runs/go71q8nx
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230629_111856-go71q8nx/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230629_113204-n4vcoakt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run peachy-durian-52
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/n4vcoakt
Training on dataset: data_t(0,0)_r(5,20)_combi_pNone_gNone
Testing on 5 datasets: ['data_t(0,0)_r(5,20)_full_pNone_gNone', 'data_t(0,0)_r(5,20)_combi_pNone_gNone', 'data_t(0,0)_r(5,20)_semi_pNone_gNone', 'data_t(0,0)_r(5,20)_none_pNone_gNone', 'data_t(0,0)_r(5,20)_tennis_pNone_gNone']
Focussing on identity: False
Using extra input: False
Using fr-fr as reference point.
----- ITERATION 1/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 51.65821552276611 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(5,20)_full_pNone_gNone took 13.442300796508789 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 12.965279340744019 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_semi_pNone_gNone took 12.320265054702759 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_none_pNone_gNone took 13.2027006149292 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_tennis_pNone_gNone took 12.419859886169434 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0151040349 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.157e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.67298e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.78793e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.2551e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.0163e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 66.16311383247375
Epoch 1/9
	 Logging train Loss: 1.81825e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.3359e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.33709e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.66348e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.4419e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.71033e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 66.35478448867798
Epoch 2/9
	 Logging train Loss: 1.04596e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.02e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 9.4088e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.39292e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 7.06e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.41785e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 66.07146787643433
Epoch 3/9
	 Logging train Loss: 8.4219e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.618e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 8.0086e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.26009e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.549e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.28819e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 66.07174491882324
Epoch 4/9
	 Logging train Loss: 9.4957e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.598e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 6.9354e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.12174e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.453e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.13663e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 66.24844884872437
Epoch 5/9
	 Logging train Loss: 1.12523e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.704e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 7.3263e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.22827e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.476e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.26873e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 65.59337306022644
Epoch 6/9
	 Logging train Loss: 1.18258e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.2111e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.36921e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.30927e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.2874e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.4041e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 65.10049152374268
Epoch 7/9
	 Logging train Loss: 1.35984e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.4148e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.2556e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.78512e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.5094e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 4.03106e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 65.08494925498962
Epoch 8/9
	 Logging train Loss: 7.9512e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.025e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.158e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.031e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.585e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 7.2142e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 65.45095014572144
Epoch 9/9
	 Logging train Loss: 7.0927e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.031e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.03303e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.7619e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 6.608e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.8449e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 65.56436133384705
Saved model in  trained_models/gru/data_t(0,0)_r(5,20)_combi_pNone_gNone/'rot_mat_1'_'False'.pth
It took  789.2642092704773  seconds.
----- ITERATION 2/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 50.16213655471802 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(5,20)_full_pNone_gNone took 12.148659467697144 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 12.138975858688354 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_semi_pNone_gNone took 12.605130434036255 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_none_pNone_gNone took 12.134454488754272 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_tennis_pNone_gNone took 12.162655115127563 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0093429554 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.0285e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.53095e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.65818e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.1532e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.72936e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 66.07925510406494
Epoch 1/9
	 Logging train Loss: 1.6724e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.511e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.21592e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone █▃▂▂▂▂▁▃▁▁
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone █▃▂▂▁▁▁▃▁▂
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone █▄▂▂▁▁▁▃▁▂
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone █▄▃▃▂▂▂▅▂▁
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone █▃▃▂▂▂▂▅▂▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone 1e-05
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone 1e-05
wandb:                                  Train loss 1e-05
wandb: 
wandb: 🚀 View run peachy-durian-52 at: https://wandb.ai/nreints/ThesisFinal2/runs/n4vcoakt
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230629_113204-n4vcoakt/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230629_114509-zhhacttk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run celestial-sun-77
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/zhhacttk
	 Logging test loss: 1.55912e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 9.588e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.56785e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 66.44769954681396
Epoch 2/9
	 Logging train Loss: 9.7465e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.666e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 8.6792e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.42535e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 5.653e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.43742e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 66.35911536216736
Epoch 3/9
	 Logging train Loss: 8.0419e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.492e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 7.5535e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.31252e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.405e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.31733e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 66.09540843963623
Epoch 4/9
	 Logging train Loss: 7.4734e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.155e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 6.7183e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.19207e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.969e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.19572e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 66.05149602890015
Epoch 5/9
	 Logging train Loss: 9.5661e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.069e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 6.7405e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.22215e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.748e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.24107e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 66.07264065742493
Epoch 6/9
	 Logging train Loss: 9.5783e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.211e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 5.9629e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.09772e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.828e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.11774e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 66.08854722976685
Epoch 7/9
	 Logging train Loss: 1.03528e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.597e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.00285e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.90806e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 6.984e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.04548e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 66.17804622650146
Epoch 8/9
	 Logging train Loss: 1.02513e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.751e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 6.2884e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.2005e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.193e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.27771e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 66.55032968521118
Epoch 9/9
	 Logging train Loss: 5.841e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.831e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.9893e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 9.3594e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.216e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 9.7955e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 66.23257541656494
Saved model in  trained_models/gru/data_t(0,0)_r(5,20)_combi_pNone_gNone/'rot_mat_1'_'False'.pth
It took  784.8423681259155  seconds.
----- ITERATION 3/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 48.92689776420593 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(5,20)_full_pNone_gNone took 12.488055229187012 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 12.405402183532715 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_semi_pNone_gNone took 12.595996141433716 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_none_pNone_gNone took 12.57855224609375 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_tennis_pNone_gNone took 12.613661050796509 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0132551156 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.9997e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.83714e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.1975e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.1172e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.27117e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 65.31901025772095
Epoch 1/9
	 Logging train Loss: 2.14881e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.0102e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.60838e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.96872e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.125e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.89593e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 65.2879900932312
Epoch 2/9
	 Logging train Loss: 1.25476e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.547e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.03654e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.64888e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 6.547e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.5579e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 65.14289426803589
Epoch 3/9
	 Logging train Loss: 8.4718e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.229e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 8.1826e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.45919e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.134e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.37036e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 65.57887721061707
Epoch 4/9
	 Logging train Loss: 7.0325e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.536e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 7.4754e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.36122e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.388e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.28464e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 66.13088011741638
Epoch 5/9
	 Logging train Loss: 6.4563e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.927e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone ▄▂▂▁▁▁▂▁▁█
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone ▄▂▂▁▁▁▂▁▁█
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone ▄▃▂▁▁▁▂▁▁█
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone ▃▂▁▁▁▁▂▁▁█
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone ▂▂▁▁▁▁▂▁▁█
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone 6e-05
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone 0.00011
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone 0.00012
wandb:                                  Train loss 1e-05
wandb: 
wandb: 🚀 View run celestial-sun-77 at: https://wandb.ai/nreints/ThesisFinal2/runs/zhhacttk
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230629_114509-zhhacttk/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230629_115808-tq6c7xmn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lemon-dust-105
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/tq6c7xmn
	 Logging test loss: 7.4043e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.35256e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.684e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.29794e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 66.06039667129517
Epoch 6/9
	 Logging train Loss: 7.4547e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.999e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.07679e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.92973e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 6.628e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.96907e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 65.89765167236328
Epoch 7/9
	 Logging train Loss: 8.9324e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.347e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 5.3487e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 9.9012e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.941e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 9.4191e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 65.468346118927
Epoch 8/9
	 Logging train Loss: 8.3354e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.306e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 5.4677e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.00599e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.818e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 9.7123e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 65.26539278030396
Epoch 9/9
	 Logging train Loss: 8.6807e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.4087e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 6.22037e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.000111762 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.2541e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0001198473 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 64.61141920089722
Saved model in  trained_models/gru/data_t(0,0)_r(5,20)_combi_pNone_gNone/'rot_mat_1'_'False'.pth
It took  779.3825867176056  seconds.
----- ITERATION 4/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 49.037256479263306 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(5,20)_full_pNone_gNone took 12.62411880493164 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 12.41742992401123 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_semi_pNone_gNone took 12.670635461807251 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_none_pNone_gNone took 12.637775421142578 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_tennis_pNone_gNone took 12.659138441085815 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0302270483 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.2565e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.45347e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.64699e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.4864e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 4.47916e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 65.76097750663757
Epoch 1/9
	 Logging train Loss: 2.29205e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.0822e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.48455e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.00018e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.2114e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.88501e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 66.23276257514954
Epoch 2/9
	 Logging train Loss: 1.2187e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.954e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 9.2674e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.62549e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 7.079e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.49956e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 65.99573111534119
Epoch 3/9
	 Logging train Loss: 9.3835e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.934e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 7.8959e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.50772e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.96e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.3823e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 65.95528626441956
Epoch 4/9
	 Logging train Loss: 8.4312e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.615e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 6.6591e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.30976e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.565e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.20434e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 65.84783244132996
Epoch 5/9
	 Logging train Loss: 9.0124e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.151e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 7.5422e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.50508e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 6.037e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.44684e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 66.0285575389862
Epoch 6/9
	 Logging train Loss: 1.01441e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.933e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.06357e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.19642e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 8.871e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.15009e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 66.14637112617493
Epoch 7/9
	 Logging train Loss: 9.4413e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.36e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 5.1367e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.08833e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.031e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.03084e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 64.68260145187378
Epoch 8/9
	 Logging train Loss: 8.8853e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.1906e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.84509e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.73591e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.314e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.84829e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 65.23532748222351
Epoch 9/9
	 Logging train Loss: 8.5978e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone █▃▂▂▁▂▂▁▄▄
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone █▄▃▂▁▂▃▁█▄
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone █▄▃▂▁▂▃▁▇▄
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone █▃▂▂▁▂▃▁▆▆
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone █▃▂▂▁▂▃▁▇▆
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone 2e-05
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone 4e-05
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone 4e-05
wandb:                                  Train loss 1e-05
wandb: 
wandb: 🚀 View run lemon-dust-105 at: https://wandb.ai/nreints/ThesisFinal2/runs/tq6c7xmn
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230629_115808-tq6c7xmn/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230629_121109-jxd328b9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run clear-totem-130
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/jxd328b9
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone █▃▂▂▇▂▁▂▁▁
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone █▃▂▂▅▁▁▂▂▁
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone █▄▂▂▅▁▁▂▂▁
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone ▇▃▃▂█▂▂▂▁▁
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone ▆▃▂▂█▂▂▂▁▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone 1e-05
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone 1e-05
wandb:                                  Train loss 1e-05
wandb: 
wandb: 🚀 View run clear-totem-130 at: https://wandb.ai/nreints/ThesisFinal2/runs/jxd328b9
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230629_121109-jxd328b9/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230629_122405-u3oz1rdp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sweet-cherry-158
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/u3oz1rdp
	 Logging test loss: 1.1651e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.69488e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.53466e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.2607e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.66386e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 64.62844395637512
Saved model in  trained_models/gru/data_t(0,0)_r(5,20)_combi_pNone_gNone/'rot_mat_1'_'False'.pth
It took  780.6912894248962  seconds.
----- ITERATION 5/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 49.356123208999634 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(5,20)_full_pNone_gNone took 12.520177841186523 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 12.403076410293579 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_semi_pNone_gNone took 12.68946361541748 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_none_pNone_gNone took 12.65092158317566 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_tennis_pNone_gNone took 12.718527555465698 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0294479765 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.3998e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.79768e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.02003e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.6131e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.9757e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 63.93208050727844
Epoch 1/9
	 Logging train Loss: 2.01609e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 9.418e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.18749e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.96372e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.0896e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.89611e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 64.20387148857117
Epoch 2/9
	 Logging train Loss: 1.10417e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.213e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 8.7418e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.63984e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 7.442e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.58479e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 64.18571901321411
Epoch 3/9
	 Logging train Loss: 9.4947e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.401e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 8.3087e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.62347e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 5.468e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.59461e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 64.14226078987122
Epoch 4/9
	 Logging train Loss: 1.2536e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.5732e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.37264e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.6719e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.682e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 4.90594e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 64.37191486358643
Epoch 5/9
	 Logging train Loss: 1.20033e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.777e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 5.8366e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.18379e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.655e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.1537e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 65.94455432891846
Epoch 6/9
	 Logging train Loss: 1.05566e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.156e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 5.4335e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.11078e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.94e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.0811e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 66.00497484207153
Epoch 7/9
	 Logging train Loss: 9.8711e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.677e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 5.935e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.22255e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.358e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.20953e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 66.03466606140137
Epoch 8/9
	 Logging train Loss: 9.0414e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.091e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.0972e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.1009e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 5.699e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 7.8585e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 66.23184394836426
Epoch 9/9
	 Logging train Loss: 8.3336e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.851e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.7457e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 9.9374e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.364e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.01194e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 66.39700484275818
Saved model in  trained_models/gru/data_t(0,0)_r(5,20)_combi_pNone_gNone/'rot_mat_1'_'False'.pth
It took  776.2430257797241  seconds.
----- ITERATION 6/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 49.26784157752991 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(5,20)_full_pNone_gNone took 12.622734069824219 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 12.422669649124146 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_semi_pNone_gNone took 12.698810338973999 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_none_pNone_gNone took 12.618244409561157 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_tennis_pNone_gNone took 12.63857102394104 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0081421789 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.9838e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.87825e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.22591e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.1317e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.61806e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 64.69550848007202
Epoch 1/9
	 Logging train Loss: 1.73804e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone █▃▃▂▂▂▂▁▄▁
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone █▄▂▁▁▁▁▁▂▁
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone █▄▂▂▁▁▁▁▂▁
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone █▄▃▃▃▂▂▁▅▁
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone █▄▃▂▂▂▂▁▅▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone 1e-05
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone 1e-05
wandb:                                  Train loss 1e-05
wandb: 
wandb: 🚀 View run sweet-cherry-158 at: https://wandb.ai/nreints/ThesisFinal2/runs/u3oz1rdp
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230629_122405-u3oz1rdp/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230629_123657-qye0igeq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sparkling-eon-177
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/qye0igeq
	 Logging test loss: 8.972e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.32343e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.64036e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.0145e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.77969e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 65.0579252243042
Epoch 2/9
	 Logging train Loss: 9.3318e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.922e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 9.9519e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.39205e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 6.021e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.49572e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 64.88491749763489
Epoch 3/9
	 Logging train Loss: 7.6169e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.963e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 8.8335e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.26187e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.003e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.35645e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 64.68832349777222
Epoch 4/9
	 Logging train Loss: 6.9172e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.464e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 8.5977e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.25414e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.446e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.36034e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 64.58770322799683
Epoch 5/9
	 Logging train Loss: 6.6084e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.512e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 7.0077e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.02012e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.353e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.09728e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 65.1595687866211
Epoch 6/9
	 Logging train Loss: 8.6294e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.694e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 6.7175e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 9.9289e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.48e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.07884e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 64.89249539375305
Epoch 7/9
	 Logging train Loss: 1.03597e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.342e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 5.863e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.5994e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.033e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 9.2501e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 64.84063458442688
Epoch 8/9
	 Logging train Loss: 8.5865e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.411e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.38768e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.16672e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 6.29e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.47469e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 65.08726596832275
Epoch 9/9
	 Logging train Loss: 8.3402e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.944e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.6148e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.8272e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.462e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 7.4858e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 64.80707621574402
Saved model in  trained_models/gru/data_t(0,0)_r(5,20)_combi_pNone_gNone/'rot_mat_1'_'False'.pth
It took  771.9797005653381  seconds.
----- ITERATION 7/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 50.0368218421936 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(5,20)_full_pNone_gNone took 12.69908618927002 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 12.66668701171875 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_semi_pNone_gNone took 12.8120276927948 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_none_pNone_gNone took 12.7865891456604 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_tennis_pNone_gNone took 12.804936408996582 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0174867362 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.8822e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.95079e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.24865e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.0052e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.65893e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 64.32576751708984
Epoch 1/9
	 Logging train Loss: 2.00417e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.1151e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.49422e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.72615e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.2257e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.82395e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 64.62809920310974
Epoch 2/9
	 Logging train Loss: 1.11873e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.385e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 9.8297e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.46167e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 7.428e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.52286e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 64.24537754058838
Epoch 3/9
	 Logging train Loss: 8.3814e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.529e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 9.6619e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.6122e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 5.403e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.69967e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 64.15946125984192
Epoch 4/9
	 Logging train Loss: 7.6868e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.269e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 7.1937e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.21615e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.128e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.25871e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 63.99130392074585
Epoch 5/9
	 Logging train Loss: 9.5112e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone █▄▂▂▂▃▂▁▂▁
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone █▅▃▂▁▃▂▁▅▁
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone █▅▃▂▁▂▂▁▄▁
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone █▃▃▃▂▄▂▁▄▂
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone █▃▂▃▂▄▂▁▄▂
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone 1e-05
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone 1e-05
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone 1e-05
wandb:                                  Train loss 1e-05
wandb: 
wandb: 🚀 View run sparkling-eon-177 at: https://wandb.ai/nreints/ThesisFinal2/runs/qye0igeq
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230629_123657-qye0igeq/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230629_124954-v7jwyyzi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sage-silence-188
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/v7jwyyzi
	 Logging test loss: 5.99e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.14846e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.03755e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 6.592e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.20144e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 64.9985499382019
Epoch 6/9
	 Logging train Loss: 8.7782e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.098e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 7.4241e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.30055e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.724e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.37425e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 66.22459554672241
Epoch 7/9
	 Logging train Loss: 7.8901e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.345e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 5.2403e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 9.196e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.95e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 9.5041e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 65.88881182670593
Epoch 8/9
	 Logging train Loss: 8.4536e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.0792e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.02978e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.81314e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.1203e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.96228e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 66.43975949287415
Epoch 9/9
	 Logging train Loss: 7.0893e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.327e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 6.3571e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.1472e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.742e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.23458e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 66.62152194976807
Saved model in  trained_models/gru/data_t(0,0)_r(5,20)_combi_pNone_gNone/'rot_mat_1'_'False'.pth
It took  777.0222518444061  seconds.
----- ITERATION 8/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 48.60582447052002 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(5,20)_full_pNone_gNone took 12.67772650718689 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 12.418437719345093 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_semi_pNone_gNone took 12.71222734451294 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_none_pNone_gNone took 12.71277141571045 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_tennis_pNone_gNone took 12.714484930038452 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0104064271 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.1647e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.11921e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.56259e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.3715e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.95884e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 65.57942032814026
Epoch 1/9
	 Logging train Loss: 2.56017e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.6381e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.79809e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.99106e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.7583e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.02606e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 65.93595242500305
Epoch 2/9
	 Logging train Loss: 1.56965e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 9.059e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.13565e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.67669e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.0162e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.65076e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 65.95609140396118
Epoch 3/9
	 Logging train Loss: 1.04934e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.51e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 8.294e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.52521e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 6.6e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.49439e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 65.6621482372284
Epoch 4/9
	 Logging train Loss: 8.4064e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.895e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 7.7029e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.45963e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 8.921e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.4356e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 65.45635485649109
Epoch 5/9
	 Logging train Loss: 7.3944e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.386e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 6.4861e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.27068e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.289e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.24902e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 65.71599340438843
Epoch 6/9
	 Logging train Loss: 6.6693e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.6251e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 7.0051e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.24708e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.7072e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.23119e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 65.80842471122742
Epoch 7/9
	 Logging train Loss: 5.9547e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.623e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 5.0322e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 9.6583e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 6.3e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 9.5202e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 65.68863224983215
Epoch 8/9
	 Logging train Loss: 7.1865e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.81e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 6.2792e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.20043e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.445e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.29175e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 65.76713800430298
Epoch 9/9
	 Logging train Loss: 8.2532e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone █▅▃▂▂▂▂▁▂▁
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone █▅▃▂▃▂▄▂▂▁
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone █▅▃▂▃▂▄▂▂▁
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone █▄▃▃▃▂▂▂▂▁
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone █▄▃▃▃▂▂▂▂▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone 1e-05
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone 1e-05
wandb:                                  Train loss 1e-05
wandb: 
wandb: 🚀 View run sage-silence-188 at: https://wandb.ai/nreints/ThesisFinal2/runs/v7jwyyzi
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230629_124954-v7jwyyzi/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230629_130255-3e0mn69v
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ethereal-dust-192
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/3e0mn69v
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone █▃▂▂▃▂▁▁▁▁
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone █▄▃▂▃▂▂▁▂▂
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone █▄▃▂▃▂▂▁▂▂
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone █▄▃▃▄▂▂▁▁▁
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone █▃▃▃▄▂▂▁▁▂
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone 1e-05
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone 1e-05
wandb:                                  Train loss 1e-05
wandb: 
wandb: 🚀 View run ethereal-dust-192 at: https://wandb.ai/nreints/ThesisFinal2/runs/3e0mn69v
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230629_130255-3e0mn69v/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230629_131545-pxqfutjj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run blooming-glade-195
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/pxqfutjj
	 Logging test loss: 9.1e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.2706e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.6378e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.384e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 6.7227e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 65.98846554756165
Saved model in  trained_models/gru/data_t(0,0)_r(5,20)_combi_pNone_gNone/'rot_mat_1'_'False'.pth
It took  781.0425899028778  seconds.
----- ITERATION 9/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 50.597322940826416 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(5,20)_full_pNone_gNone took 12.875117778778076 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 12.751955509185791 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_semi_pNone_gNone took 12.787777423858643 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_none_pNone_gNone took 12.823834419250488 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_tennis_pNone_gNone took 12.886001110076904 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0138463276 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.0282e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.72583e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.3024e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.1837e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.64265e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 64.09841704368591
Epoch 1/9
	 Logging train Loss: 1.91056e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 9.498e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.19558e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.71393e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.0595e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.78587e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 64.07143115997314
Epoch 2/9
	 Logging train Loss: 1.074e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.116e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 8.3015e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.46923e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 7.077e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.52104e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 63.93720364570618
Epoch 3/9
	 Logging train Loss: 8.3137e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.196e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 7.081e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.36119e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.086e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.40316e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 64.00090861320496
Epoch 4/9
	 Logging train Loss: 7.7264e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.506e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 9.97e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.95054e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 6.352e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.15741e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 64.46980381011963
Epoch 5/9
	 Logging train Loss: 9.3798e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.887e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 6.5126e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.27831e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.594e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.38461e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 64.27561378479004
Epoch 6/9
	 Logging train Loss: 9.7675e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.797e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 5.2909e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.05462e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.4e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.08891e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 64.29897689819336
Epoch 7/9
	 Logging train Loss: 9.2057e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 9.85e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.6764e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.5846e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.523e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 7.731e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 64.28067255020142
Epoch 8/9
	 Logging train Loss: 8.8196e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.627e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.2322e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.3797e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 5.12e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 9.0024e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 64.7391197681427
Epoch 9/9
	 Logging train Loss: 7.4116e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.628e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.6194e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 9.3545e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 5.089e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 9.9898e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 65.10819625854492
Saved model in  trained_models/gru/data_t(0,0)_r(5,20)_combi_pNone_gNone/'rot_mat_1'_'False'.pth
It took  769.3085331916809  seconds.
----- ITERATION 10/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 49.83094930648804 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(5,20)_full_pNone_gNone took 12.744096994400024 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 12.571362495422363 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_semi_pNone_gNone took 12.824301481246948 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_none_pNone_gNone took 12.947878360748291 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_tennis_pNone_gNone took 12.904009819030762 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0113446768 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.5782e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 7.90873e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0001195996 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 5.7609e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0001434725 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 65.81777858734131
Epoch 1/9
	 Logging train Loss: 3.80378e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone ▇▂▁▁▁▁█▁▁▁
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone ▇▂▂▁▁▁█▁▂▁
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone ▇▂▂▁▁▁█▁▂▁
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone ▆▂▁▁▁▁█▁▁▁
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone ▆▂▁▁▁▁█▁▁▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone 1e-05
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone 2e-05
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone 3e-05
wandb:                                  Train loss 1e-05
wandb: 
wandb: 🚀 View run blooming-glade-195 at: https://wandb.ai/nreints/ThesisFinal2/runs/pxqfutjj
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230629_131545-pxqfutjj/logs
	 Logging test loss: 1.5427e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.05774e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.75707e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.6791e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.17905e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 66.13448762893677
Epoch 2/9
	 Logging train Loss: 1.63254e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 9.051e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.20982e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.8952e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.0442e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.11212e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 65.78004455566406
Epoch 3/9
	 Logging train Loss: 1.11101e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.445e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 8.8963e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.53724e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 6.752e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.68469e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 65.68120574951172
Epoch 4/9
	 Logging train Loss: 9.0625e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.734e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 7.4478e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.3385e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.897e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.46197e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 66.0074610710144
Epoch 5/9
	 Logging train Loss: 8.076e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.515e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 8.2832e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.49843e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 6.544e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.70542e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 66.14817261695862
Epoch 6/9
	 Logging train Loss: 1.05149e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.7228e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 9.37322e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0001700831 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 6.7807e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0002017666 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 66.38118410110474
Epoch 7/9
	 Logging train Loss: 1.15595e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.754e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.02039e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.9274e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 5.583e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.15512e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 66.264883518219
Epoch 8/9
	 Logging train Loss: 1.12666e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.0865e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.06346e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.94761e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.1762e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.24121e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 65.57550811767578
Epoch 9/9
	 Logging train Loss: 1.08413e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.514e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.17616e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.17347e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 7.087e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.61889e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 65.67614459991455
Saved model in  trained_models/gru/data_t(0,0)_r(5,20)_combi_pNone_gNone/'rot_mat_1'_'False'.pth
It took  784.7957870960236  seconds.

JOB STATISTICS
==============
Job ID: 2986689
Array Job ID: 2986645_8
Cluster: snellius
User/Group: nreints/nreints
State: COMPLETED (exit code 0)
Nodes: 1
Cores per node: 18
CPU Utilized: 02:17:58
CPU Efficiency: 5.89% of 1-15:03:54 core-walltime
Job Wall-clock time: 02:10:13
Memory Utilized: 9.24 GB
Memory Efficiency: 0.00% of 0.00 MB
