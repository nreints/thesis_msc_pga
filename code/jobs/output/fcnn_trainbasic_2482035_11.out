wandb: Currently logged in as: nreints. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home/nreints/.netrc
/gpfs/home2/nreints/MScThesis/code/fcnn.py:521: DeprecationWarning: Sampling from a set deprecated
since Python 3.9 and will be removed in a subsequent version.
  train_sims = set(random.sample(sims_train, int(0.8 * n_sims_train)))
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230321_162902-ih5y69xu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eternal-microwave-247
wandb: ⭐️ View project at https://wandb.ai/nreints/test
wandb: 🚀 View run at https://wandb.ai/nreints/test/runs/ih5y69xu
['data_t(5,', '20)_r(0,', '0)_full_pNone_gNone']
data/data_t(5, 20)_r(0, 0)_full_pNone_gNone
Testing on datasets: ['data_t(5, 20)_r(0, 0)_full_pNone_gNone', 'data_tennis_pNone_gNone_tennisEffect']
----- ITERATION 1/2 ------
Number of train simulations: 3200
Number of test simulations: 800
The dataloader took 81.69632816314697 seconds.
-- Finished Train Dataloader --
The dataloader took 20.397449016571045 seconds.
The dataloader took 21.295145511627197 seconds.
-- Finished Test Dataloader(s) --
Datatype: log_quat
--- Started Training ---
Epoch 0
	 Logging train Loss: 4.8241443908 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.02451780065894127 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.11327002197504044 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 698.8433837890625 (MSELoss(): tennis_pNone_gNone_tennisEffect)
	 Logging test loss 19.39288330078125 (L1Loss(): tennis_pNone_gNone_tennisEffect)
     --> Epoch_time; 80.3770751953125
Epoch 1
	 Logging train Loss: 0.0384907168 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.022871704772114754 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.10843608528375626 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 701.2034912109375 (MSELoss(): tennis_pNone_gNone_tennisEffect)
	 Logging test loss 19.453025817871094 (L1Loss(): tennis_pNone_gNone_tennisEffect)
     --> Epoch_time; 86.21752214431763
Epoch 2
	 Logging train Loss: 0.0345542833 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.01632269285619259 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.09226299822330475 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 702.1364135742188 (MSELoss(): tennis_pNone_gNone_tennisEffect)
	 Logging test loss 19.467241287231445 (L1Loss(): tennis_pNone_gNone_tennisEffect)
     --> Epoch_time; 85.62493848800659
Epoch 3
	 Logging train Loss: 0.0320372363 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.011211068369448185 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.07518608868122101 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 703.1856079101562 (MSELoss(): tennis_pNone_gNone_tennisEffect)
	 Logging test loss 19.500652313232422 (L1Loss(): tennis_pNone_gNone_tennisEffect)
     --> Epoch_time; 81.97646594047546
Epoch 4
	 Logging train Loss: 0.0271048901 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.009362859651446342 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.0711117833852768 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 704.2138061523438 (MSELoss(): tennis_pNone_gNone_tennisEffect)
	 Logging test loss 19.51036262512207 (L1Loss(): tennis_pNone_gNone_tennisEffect)
     --> Epoch_time; 86.32920384407043
Epoch 5
	 Logging train Loss: 0.0256938486 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.008119612000882626 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.06498640775680542 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 706.6298828125 (MSELoss(): tennis_pNone_gNone_tennisEffect)
	 Logging test loss 19.550357818603516 (L1Loss(): tennis_pNone_gNone_tennisEffect)
     --> Epoch_time; 86.41243815422058
Epoch 6
	 Logging train Loss: 0.0249134014 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.0032204901799559593 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.040026746690273285 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 709.4174194335938 (MSELoss(): tennis_pNone_gNone_tennisEffect)
	 Logging test loss 19.59588623046875 (L1Loss(): tennis_pNone_gNone_tennisEffect)
     --> Epoch_time; 86.92503809928894
Epoch 7
	 Logging train Loss: 0.021317194 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.004670087713748217 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.04918830841779709 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 711.5567626953125 (MSELoss(): tennis_pNone_gNone_tennisEffect)
	 Logging test loss 19.626588821411133 (L1Loss(): tennis_pNone_gNone_tennisEffect)
     --> Epoch_time; 86.44195938110352
Epoch 8
	 Logging train Loss: 0.0200941472 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.0029822378419339657 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.03904002159833908 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 713.04443359375 (MSELoss(): tennis_pNone_gNone_tennisEffect)
	 Logging test loss 19.644254684448242 (L1Loss(): tennis_pNone_gNone_tennisEffect)
     --> Epoch_time; 88.6050717830658
Epoch 9
	 Logging train Loss: 0.0176164727 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.0843539834022522 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.20209486782550812 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 715.9484252929688 (MSELoss(): tennis_pNone_gNone_tennisEffect)
	 Logging test loss 19.70290756225586 (L1Loss(): tennis_pNone_gNone_tennisEffect)
     --> Epoch_time; 83.67764019966125
Epoch 10
	 Logging train Loss: 0.0173688677 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.002044511027634144 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.0329475961625576 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 717.1036987304688 (MSELoss(): tennis_pNone_gNone_tennisEffect)
	 Logging test loss 19.724843978881836 (L1Loss(): tennis_pNone_gNone_tennisEffect)
     --> Epoch_time; 87.1099214553833
Epoch 11
	 Logging train Loss: 0.0147177453 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.006618639454245567 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.05713886767625809 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 715.9074096679688 (MSELoss(): tennis_pNone_gNone_tennisEffect)
	 Logging test loss 19.68400001525879 (L1Loss(): tennis_pNone_gNone_tennisEffect)
     --> Epoch_time; 83.79907274246216
Epoch 12
	 Logging train Loss: 0.0147721421 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.09478653222322464 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.21224573254585266 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 716.5562133789062 (MSELoss(): tennis_pNone_gNone_tennisEffect)
	 Logging test loss 19.691251754760742 (L1Loss(): tennis_pNone_gNone_tennisEffect)
     --> Epoch_time; 90.5668134689331
Epoch 13
	 Logging train Loss: 0.0132419698 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.004747036844491959 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.04872562736272812 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 719.2525024414062 (MSELoss(): tennis_pNone_gNone_tennisEffect)
	 Logging test loss 19.729022979736328 (L1Loss(): tennis_pNone_gNone_tennisEffect)
     --> Epoch_time; 88.63125324249268
Epoch 14
	 Logging train Loss: 0.0122060402 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.001131386961787939 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.02351994253695011 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 719.068115234375 (MSELoss(): tennis_pNone_gNone_tennisEffect)
	 Logging test loss 19.71642303466797 (L1Loss(): tennis_pNone_gNone_tennisEffect)
     --> Epoch_time; 85.78476357460022
Epoch 15
	 Logging train Loss: 0.0105290893 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.0018867949256673455 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.030738195404410362 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 717.5238037109375 (MSELoss(): tennis_pNone_gNone_tennisEffect)
	 Logging test loss 19.682098388671875 (L1Loss(): tennis_pNone_gNone_tennisEffect)
     --> Epoch_time; 85.15907740592957
Epoch 16
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.028 MB of 0.028 MB uploaded (0.000 MB deduped)wandb: \ 0.028 MB of 0.097 MB uploaded (0.000 MB deduped)wandb: | 0.028 MB of 0.097 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  Test loss t(5, 20)_r(0, 0)_full L1Loss() ▄▄▄▃▃▃▂▂▂█▁▂█▂▁▁▁▁▁▃▃
wandb: Test loss t(5, 20)_r(0, 0)_full MSELoss() ▃▃▂▂▂▂▁▁▁▇▁▁█▁▁▁▁▁▁▂▂
wandb:           Test loss tennisEffect L1Loss() ▁▂▃▃▃▄▅▆▆▇█▇▇██▇▇▇▇▇▇
wandb:          Test loss tennisEffect MSELoss() ▁▂▂▂▃▄▅▅▆▇▇▇▇██▇▇████
wandb:     Train loss data_t(5, 20)_r(0, 0)_full █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:  Test loss t(5, 20)_r(0, 0)_full L1Loss() 0.08746
wandb: Test loss t(5, 20)_r(0, 0)_full MSELoss() 0.01616
wandb:           Test loss tennisEffect L1Loss() 19.67356
wandb:          Test loss tennisEffect MSELoss() 718.0376
wandb:     Train loss data_t(5, 20)_r(0, 0)_full 0.00721
wandb: 
wandb: 🚀 View run eternal-microwave-247 at: https://wandb.ai/nreints/test/runs/ih5y69xu
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230321_162902-ih5y69xu/logs
/gpfs/home2/nreints/MScThesis/code/fcnn.py:521: DeprecationWarning: Sampling from a set deprecated
since Python 3.9 and will be removed in a subsequent version.
  train_sims = set(random.sample(sims_train, int(0.8 * n_sims_train)))
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230321_170011-j366ca71
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run polished-yogurt-292
wandb: ⭐️ View project at https://wandb.ai/nreints/test
wandb: 🚀 View run at https://wandb.ai/nreints/test/runs/j366ca71
	 Logging train Loss: 0.010182309 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.0030600116588175297 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.03638194873929024 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 717.6201782226562 (MSELoss(): tennis_pNone_gNone_tennisEffect)
	 Logging test loss 19.67273712158203 (L1Loss(): tennis_pNone_gNone_tennisEffect)
     --> Epoch_time; 84.00202250480652
Epoch 17
	 Logging train Loss: 0.0090197027 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.002120411256328225 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.03183385729789734 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 718.5929565429688 (MSELoss(): tennis_pNone_gNone_tennisEffect)
	 Logging test loss 19.6918888092041 (L1Loss(): tennis_pNone_gNone_tennisEffect)
     --> Epoch_time; 81.16469311714172
Epoch 18
	 Logging train Loss: 0.0091253274 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.0012726867571473122 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.024214988574385643 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 718.8849487304688 (MSELoss(): tennis_pNone_gNone_tennisEffect)
	 Logging test loss 19.693782806396484 (L1Loss(): tennis_pNone_gNone_tennisEffect)
     --> Epoch_time; 85.83652782440186
Epoch 19
	 Logging train Loss: 0.0072053529 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.016156736761331558 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.08745940774679184 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 718.037109375 (MSELoss(): tennis_pNone_gNone_tennisEffect)
	 Logging test loss 19.6735782623291 (L1Loss(): tennis_pNone_gNone_tennisEffect)
     --> Epoch_time; 81.56664061546326
	 Logging test loss 0.01615685038268566 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.0874595120549202 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 718.03759765625 (MSELoss(): tennis_pNone_gNone_tennisEffect)
	 Logging test loss 19.67356300354004 (L1Loss(): tennis_pNone_gNone_tennisEffect)
It took 1868.6954276561737 seconds to train & eval the model.
----- ITERATION 2/2 ------
Number of train simulations: 3200
Number of test simulations: 800
The dataloader took 77.45292806625366 seconds.
-- Finished Train Dataloader --
The dataloader took 19.050131797790527 seconds.
The dataloader took 19.998021364212036 seconds.
-- Finished Test Dataloader(s) --
Datatype: log_quat
--- Started Training ---
Epoch 0
	 Logging train Loss: 5.161376634 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.049061164259910583 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.15856054425239563 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 686.393798828125 (MSELoss(): tennis_pNone_gNone_tennisEffect)
	 Logging test loss 19.33686637878418 (L1Loss(): tennis_pNone_gNone_tennisEffect)
     --> Epoch_time; 84.3936779499054
Epoch 1
	 Logging train Loss: 0.0278037077 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.028008300811052322 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.11946657299995422 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 687.8074340820312 (MSELoss(): tennis_pNone_gNone_tennisEffect)
	 Logging test loss 19.352890014648438 (L1Loss(): tennis_pNone_gNone_tennisEffect)
     --> Epoch_time; 83.95878100395203
Epoch 2
	 Logging train Loss: 0.0231139439 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.011586681939661503 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.07771960645914078 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 687.9017333984375 (MSELoss(): tennis_pNone_gNone_tennisEffect)
	 Logging test loss 19.33952522277832 (L1Loss(): tennis_pNone_gNone_tennisEffect)
     --> Epoch_time; 84.45728373527527
Epoch 3
	 Logging train Loss: 0.0208830166 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.03227302059531212 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.12596352398395538 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 689.6968994140625 (MSELoss(): tennis_pNone_gNone_tennisEffect)
	 Logging test loss 19.38239288330078 (L1Loss(): tennis_pNone_gNone_tennisEffect)
     --> Epoch_time; 79.58909225463867
Epoch 4
	 Logging train Loss: 0.018143159 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.1572588086128235 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.2752930223941803 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 689.8938598632812 (MSELoss(): tennis_pNone_gNone_tennisEffect)
	 Logging test loss 19.386323928833008 (L1Loss(): tennis_pNone_gNone_tennisEffect)
     --> Epoch_time; 83.24333310127258
Epoch 5
	 Logging train Loss: 0.0179066353 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.001180980820208788 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.02221486158668995 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 692.45556640625 (MSELoss(): tennis_pNone_gNone_tennisEffect)
	 Logging test loss 19.445737838745117 (L1Loss(): tennis_pNone_gNone_tennisEffect)
     --> Epoch_time; 83.19494843482971
Epoch 6
	 Logging train Loss: 0.01502934 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.031753212213516235 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.11734259873628616 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 692.2247314453125 (MSELoss(): tennis_pNone_gNone_tennisEffect)
	 Logging test loss 19.43695831298828 (L1Loss(): tennis_pNone_gNone_tennisEffect)
     --> Epoch_time; 84.46994757652283
Epoch 7
	 Logging train Loss: 0.0143409405 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.0019257531967014074 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.030510134994983673 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 692.7955322265625 (MSELoss(): tennis_pNone_gNone_tennisEffect)
	 Logging test loss 19.44368553161621 (L1Loss(): tennis_pNone_gNone_tennisEffect)
     --> Epoch_time; 84.50869107246399
Epoch 8
	 Logging train Loss: 0.0132727193 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.007995442487299442 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.06217915192246437 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 695.3184814453125 (MSELoss(): tennis_pNone_gNone_tennisEffect)
	 Logging test loss 19.498106002807617 (L1Loss(): tennis_pNone_gNone_tennisEffect)
     --> Epoch_time; 83.66646385192871
Epoch 9
	 Logging train Loss: 0.0126592175 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.007784061133861542 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.06009213998913765 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 696.4688720703125 (MSELoss(): tennis_pNone_gNone_tennisEffect)
	 Logging test loss 19.519943237304688 (L1Loss(): tennis_pNone_gNone_tennisEffect)
     --> Epoch_time; 83.78018522262573
Epoch 10
	 Logging train Loss: 0.0114907096 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.007564682979136705 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.06063477694988251 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 697.5739135742188 (MSELoss(): tennis_pNone_gNone_tennisEffect)
	 Logging test loss 19.543895721435547 (L1Loss(): tennis_pNone_gNone_tennisEffect)
     --> Epoch_time; 84.94380164146423
Epoch 11
	 Logging train Loss: 0.0104146696 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.05196124687790871 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.15062785148620605 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 699.1875610351562 (MSELoss(): tennis_pNone_gNone_tennisEffect)
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:  Test loss t(5, 20)_r(0, 0)_full L1Loss() ▅▄▃▄█▁▄▁▂▂▂▅▂▂▂▂▃▁▁▃▃
wandb: Test loss t(5, 20)_r(0, 0)_full MSELoss() ▃▂▁▂█▁▂▁▁▁▁▃▁▁▁▁▂▁▁▂▂
wandb:           Test loss tennisEffect L1Loss() ▁▁▁▂▂▃▃▃▅▅▆▆▆▆▆▇▇████
wandb:          Test loss tennisEffect MSELoss() ▁▂▂▂▂▃▃▃▄▅▅▆▆▆▆▇▇████
wandb:     Train loss data_t(5, 20)_r(0, 0)_full █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:  Test loss t(5, 20)_r(0, 0)_full L1Loss() 0.0976
wandb: Test loss t(5, 20)_r(0, 0)_full MSELoss() 0.01977
wandb:           Test loss tennisEffect L1Loss() 19.64729
wandb:          Test loss tennisEffect MSELoss() 705.35107
wandb:     Train loss data_t(5, 20)_r(0, 0)_full 0.00528
wandb: 
wandb: 🚀 View run polished-yogurt-292 at: https://wandb.ai/nreints/test/runs/j366ca71
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230321_170011-j366ca71/logs
	 Logging test loss 19.556201934814453 (L1Loss(): tennis_pNone_gNone_tennisEffect)
     --> Epoch_time; 86.70843529701233
Epoch 12
	 Logging train Loss: 0.0096253956 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.004734446760267019 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.0483795627951622 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 700.881591796875 (MSELoss(): tennis_pNone_gNone_tennisEffect)
	 Logging test loss 19.578645706176758 (L1Loss(): tennis_pNone_gNone_tennisEffect)
     --> Epoch_time; 85.3343152999878
Epoch 13
	 Logging train Loss: 0.0089621438 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.00862494669854641 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.06468763947486877 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 700.2003784179688 (MSELoss(): tennis_pNone_gNone_tennisEffect)
	 Logging test loss 19.56656837463379 (L1Loss(): tennis_pNone_gNone_tennisEffect)
     --> Epoch_time; 86.65947103500366
Epoch 14
	 Logging train Loss: 0.0079955625 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.008913712576031685 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.06687816977500916 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 701.171630859375 (MSELoss(): tennis_pNone_gNone_tennisEffect)
	 Logging test loss 19.577463150024414 (L1Loss(): tennis_pNone_gNone_tennisEffect)
     --> Epoch_time; 84.80516862869263
Epoch 15
	 Logging train Loss: 0.0073371956 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.008504427969455719 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.0621100515127182 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 701.8112182617188 (MSELoss(): tennis_pNone_gNone_tennisEffect)
	 Logging test loss 19.58910369873047 (L1Loss(): tennis_pNone_gNone_tennisEffect)
     --> Epoch_time; 85.86902904510498
Epoch 16
	 Logging train Loss: 0.0069659295 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.026889154687523842 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.11218833923339844 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 702.3341674804688 (MSELoss(): tennis_pNone_gNone_tennisEffect)
	 Logging test loss 19.59885025024414 (L1Loss(): tennis_pNone_gNone_tennisEffect)
     --> Epoch_time; 84.278564453125
Epoch 17
	 Logging train Loss: 0.0064047315 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.0017909425077959895 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.02782963588833809 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 704.5626831054688 (MSELoss(): tennis_pNone_gNone_tennisEffect)
	 Logging test loss 19.641332626342773 (L1Loss(): tennis_pNone_gNone_tennisEffect)
     --> Epoch_time; 83.23884749412537
Epoch 18
	 Logging train Loss: 0.0058998046 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.0010934851597994566 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.022651363164186478 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 705.038818359375 (MSELoss(): tennis_pNone_gNone_tennisEffect)
	 Logging test loss 19.646678924560547 (L1Loss(): tennis_pNone_gNone_tennisEffect)
     --> Epoch_time; 83.27326798439026
Epoch 19
	 Logging train Loss: 0.005283855 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.019766829907894135 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.09760089218616486 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 705.347900390625 (MSELoss(): tennis_pNone_gNone_tennisEffect)
	 Logging test loss 19.64729118347168 (L1Loss(): tennis_pNone_gNone_tennisEffect)
     --> Epoch_time; 83.23308420181274
	 Logging test loss 0.019766658544540405 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.09759999066591263 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 705.35107421875 (MSELoss(): tennis_pNone_gNone_tennisEffect)
	 Logging test loss 19.647294998168945 (L1Loss(): tennis_pNone_gNone_tennisEffect)
It took 1844.3312847614288 seconds to train & eval the model.

JOB STATISTICS
==============
Job ID: 2482047
Array Job ID: 2482035_11
Cluster: snellius
User/Group: nreints/nreints
State: RUNNING
Nodes: 1
Cores per node: 18
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 18:38:42 core-walltime
Job Wall-clock time: 01:02:09
Memory Utilized: 0.00 MB (estimated maximum)
Memory Efficiency: 0.00% of 29.30 GB (29.30 GB/node)
WARNING: Efficiency statistics may be misleading for RUNNING jobs.
