wandb: Currently logged in as: nreints. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230710_170033-eb5kr43a
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stellar-meadow-1253
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/eb5kr43a
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                     Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb: Test loss tennis_pNone_gNone_tennisEffect â–ˆâ–…â–…â–ƒâ–„â–‚â–â–ƒâ–â–
wandb:                                Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                     Epoch 9
wandb: Test loss tennis_pNone_gNone_tennisEffect 1e-05
wandb:                                Train loss 1e-05
wandb: 
wandb: ðŸš€ View run stellar-meadow-1253 at: https://wandb.ai/nreints/ThesisFinal2/runs/eb5kr43a
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230710_170033-eb5kr43a/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230710_170504-ygcn499i
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run leafy-dragon-1258
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/ygcn499i
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                     Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb: Test loss tennis_pNone_gNone_tennisEffect â–ˆâ–†â–†â–„â–„â–ƒâ–‚â–â–â–
wandb:                                Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                     Epoch 9
wandb: Test loss tennis_pNone_gNone_tennisEffect 1e-05
wandb:                                Train loss 1e-05
wandb: 
wandb: ðŸš€ View run leafy-dragon-1258 at: https://wandb.ai/nreints/ThesisFinal2/runs/ygcn499i
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230710_170504-ygcn499i/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230710_170926-nrfyp02a
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run curious-flower-1269
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/nrfyp02a
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                     Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb: Test loss tennis_pNone_gNone_tennisEffect â–ˆâ–†â–…â–†â–„â–‚â–â–â–â–
wandb:                                Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                     Epoch 9
wandb: Test loss tennis_pNone_gNone_tennisEffect 1e-05
wandb:                                Train loss 1e-05
wandb: 
wandb: ðŸš€ View run curious-flower-1269 at: https://wandb.ai/nreints/ThesisFinal2/runs/nrfyp02a
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230710_170926-nrfyp02a/logs
Training on dataset: data_tennis_pNone_gNone_tennisEffect
Testing on 1 datasets: ['data_tennis_pNone_gNone_tennisEffect']
Focussing on identity: False
Using extra input: False
Using fr-fr as reference point.
----- ITERATION 1/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 52.61304974555969 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 13.14709186553955 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: log_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.002227406 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 4.70193e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 21.006646394729614
Epoch 1/9
	 Logging train Loss: 3.36453e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 3.41479e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 18.990274906158447
Epoch 2/9
	 Logging train Loss: 3.06439e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 3.22461e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 18.73118233680725
Epoch 3/9
	 Logging train Loss: 2.82888e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.32613e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 18.83850121498108
Epoch 4/9
	 Logging train Loss: 2.51508e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.44148e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 18.883800268173218
Epoch 5/9
	 Logging train Loss: 2.17548e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.70018e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 18.715854167938232
Epoch 6/9
	 Logging train Loss: 1.76592e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.19917e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 18.91796875
Epoch 7/9
	 Logging train Loss: 1.38808e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.13597e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 18.987465620040894
Epoch 8/9
	 Logging train Loss: 1.23455e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.32251e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.01133680343628
Epoch 9/9
	 Logging train Loss: 1.1169e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.11459e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.158365488052368
Saved model in  trained_models/gru/data_tennis_pNone_gNone_tennisEffect/'log_quat_1'_'False'.pth
It took  272.5280730724335  seconds.
----- ITERATION 2/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 47.01801896095276 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 12.029061555862427 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: log_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0018695575 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 3.67536e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 18.955546379089355
Epoch 1/9
	 Logging train Loss: 3.17776e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.86734e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.10531449317932
Epoch 2/9
	 Logging train Loss: 3.02545e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.7058e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.05560541152954
Epoch 3/9
	 Logging train Loss: 2.78749e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.15935e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.101392030715942
Epoch 4/9
	 Logging train Loss: 2.45747e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.08277e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.14915657043457
Epoch 5/9
	 Logging train Loss: 2.00673e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.49265e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.241159915924072
Epoch 6/9
	 Logging train Loss: 1.54527e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.19388e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 18.878342390060425
Epoch 7/9
	 Logging train Loss: 1.32528e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 9.6701e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.052578687667847
Epoch 8/9
	 Logging train Loss: 1.12524e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.04102e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.318230867385864
Epoch 9/9
	 Logging train Loss: 1.0913e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 8.8492e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.45597529411316
Saved model in  trained_models/gru/data_tennis_pNone_gNone_tennisEffect/'log_quat_1'_'False'.pth
It took  261.9460816383362  seconds.
----- ITERATION 3/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 45.7669460773468 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 11.445249319076538 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: log_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0017748928 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 4.05179e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.009265661239624
Epoch 1/9
	 Logging train Loss: 3.26743e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 3.25506e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.150654315948486
Epoch 2/9
	 Logging train Loss: 3.08122e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.83628e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.33380675315857
Epoch 3/9
	 Logging train Loss: 2.77667e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 3.31093e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 18.891724586486816
Epoch 4/9
	 Logging train Loss: 2.38911e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.35829e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.093992710113525
Epoch 5/9
	 Logging train Loss: 1.99631e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.4877e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 18.885366201400757
Epoch 6/9
	 Logging train Loss: 1.54337e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.08484e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.046614170074463
Epoch 7/9
	 Logging train Loss: 1.25593e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 9.7911e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 18.81544065475464
Epoch 8/9
	 Logging train Loss: 1.14676e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.01035e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 18.823867559432983
Epoch 9/9
	 Logging train Loss: 1.09438e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 9.9874e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.082406997680664
Saved model in  trained_models/gru/data_tennis_pNone_gNone_tennisEffect/'log_quat_1'_'False'.pth
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230710_171345-1ai5rdab
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run northern-wind-1283
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/1ai5rdab
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                     Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb: Test loss tennis_pNone_gNone_tennisEffect â–†â–ˆâ–†â–…â–ƒâ–ƒâ–‚â–â–â–‚
wandb:                                Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                     Epoch 9
wandb: Test loss tennis_pNone_gNone_tennisEffect 1e-05
wandb:                                Train loss 1e-05
wandb: 
wandb: ðŸš€ View run northern-wind-1283 at: https://wandb.ai/nreints/ThesisFinal2/runs/1ai5rdab
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230710_171345-1ai5rdab/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230710_171806-yylgm6yw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run quiet-surf-1292
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/yylgm6yw
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                     Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb: Test loss tennis_pNone_gNone_tennisEffect â–ˆâ–„â–„â–ƒâ–„â–‚â–‚â–â–‚â–
wandb:                                Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                     Epoch 9
wandb: Test loss tennis_pNone_gNone_tennisEffect 1e-05
wandb:                                Train loss 1e-05
wandb: 
wandb: ðŸš€ View run quiet-surf-1292 at: https://wandb.ai/nreints/ThesisFinal2/runs/yylgm6yw
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230710_171806-yylgm6yw/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230710_172224-srb2b08l
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run confused-blaze-1303
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/srb2b08l
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                     Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb: Test loss tennis_pNone_gNone_tennisEffect â–ˆâ–„â–„â–„â–„â–ƒâ–‚â–â–â–‚
wandb:                                Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                     Epoch 9
wandb: Test loss tennis_pNone_gNone_tennisEffect 1e-05
wandb:                                Train loss 1e-05
wandb: 
wandb: ðŸš€ View run confused-blaze-1303 at: https://wandb.ai/nreints/ThesisFinal2/runs/srb2b08l
wandb: Synced 7 W&B file(s), 0 media file(s), 1 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230710_172224-srb2b08l/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230710_172644-wm0zkfpw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run different-fire-1314
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/wm0zkfpw
It took  258.8473677635193  seconds.
----- ITERATION 4/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 45.392557859420776 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 11.414883852005005 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: log_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0016332162 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 3.59903e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.265291929244995
Epoch 1/9
	 Logging train Loss: 3.2662e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 4.54429e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.263256549835205
Epoch 2/9
	 Logging train Loss: 3.11147e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 3.32839e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.065781831741333
Epoch 3/9
	 Logging train Loss: 2.7711e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.8279e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 18.860683917999268
Epoch 4/9
	 Logging train Loss: 2.43113e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.12793e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.165897846221924
Epoch 5/9
	 Logging train Loss: 2.06077e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.84462e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.07100200653076
Epoch 6/9
	 Logging train Loss: 1.59826e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.20396e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 18.927000045776367
Epoch 7/9
	 Logging train Loss: 1.29822e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 9.7829e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 18.948798656463623
Epoch 8/9
	 Logging train Loss: 1.1468e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 8.9432e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.02200746536255
Epoch 9/9
	 Logging train Loss: 1.12239e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.31722e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.127958297729492
Saved model in  trained_models/gru/data_tennis_pNone_gNone_tennisEffect/'log_quat_1'_'False'.pth
It took  261.1313569545746  seconds.
----- ITERATION 5/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 45.461716413497925 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 11.430795192718506 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: log_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0026365698 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 5.45176e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 18.886083602905273
Epoch 1/9
	 Logging train Loss: 3.73142e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 3.25553e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.286356449127197
Epoch 2/9
	 Logging train Loss: 3.1156e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.9171e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.019721031188965
Epoch 3/9
	 Logging train Loss: 2.873e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.29018e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.186380863189697
Epoch 4/9
	 Logging train Loss: 2.57194e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 3.20426e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.322335720062256
Epoch 5/9
	 Logging train Loss: 2.25767e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.97641e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.165142059326172
Epoch 6/9
	 Logging train Loss: 1.75009e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.82543e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.19112229347229
Epoch 7/9
	 Logging train Loss: 1.45413e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.1556e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 18.852063179016113
Epoch 8/9
	 Logging train Loss: 1.25989e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.56226e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.213101148605347
Epoch 9/9
	 Logging train Loss: 1.18397e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.33095e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 18.938321590423584
Saved model in  trained_models/gru/data_tennis_pNone_gNone_tennisEffect/'log_quat_1'_'False'.pth
It took  258.09128880500793  seconds.
----- ITERATION 6/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 45.29155111312866 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 11.407158374786377 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: log_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.003217103 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 6.21179e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.094428062438965
Epoch 1/9
	 Logging train Loss: 3.69092e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 3.50666e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.099329471588135
Epoch 2/9
	 Logging train Loss: 3.05774e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 3.49232e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.31737184524536
Epoch 3/9
	 Logging train Loss: 2.84774e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 3.11718e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.362980365753174
Epoch 4/9
	 Logging train Loss: 2.5756e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 3.35032e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.376645803451538
Epoch 5/9
	 Logging train Loss: 2.26148e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.43392e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.468367338180542
Epoch 6/9
	 Logging train Loss: 1.82449e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.68645e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.104776620864868
Epoch 7/9
	 Logging train Loss: 1.51335e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.14012e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.128159284591675
Epoch 8/9
	 Logging train Loss: 1.27751e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 9.7474e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 18.78213858604431
Epoch 9/9
	 Logging train Loss: 1.17415e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.41052e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.183851957321167
Saved model in  trained_models/gru/data_tennis_pNone_gNone_tennisEffect/'log_quat_1'_'False'.pth
It took  260.07174587249756  seconds.
----- ITERATION 7/10 ------
Number of train simulations:  1920
Number of test simulations:  480
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                     Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb: Test loss tennis_pNone_gNone_tennisEffect â–ˆâ–„â–„â–ƒâ–‚â–ƒâ–‚â–‚â–â–
wandb:                                Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                     Epoch 9
wandb: Test loss tennis_pNone_gNone_tennisEffect 1e-05
wandb:                                Train loss 1e-05
wandb: 
wandb: ðŸš€ View run different-fire-1314 at: https://wandb.ai/nreints/ThesisFinal2/runs/wm0zkfpw
wandb: Synced 7 W&B file(s), 0 media file(s), 1 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230710_172644-wm0zkfpw/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230710_173102-mp7fkzus
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vital-monkey-1325
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/mp7fkzus
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                     Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb: Test loss tennis_pNone_gNone_tennisEffect â–ˆâ–…â–…â–…â–†â–‚â–â–‚â–‚â–
wandb:                                Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                     Epoch 9
wandb: Test loss tennis_pNone_gNone_tennisEffect 1e-05
wandb:                                Train loss 1e-05
wandb: 
wandb: ðŸš€ View run vital-monkey-1325 at: https://wandb.ai/nreints/ThesisFinal2/runs/mp7fkzus
wandb: Synced 7 W&B file(s), 0 media file(s), 1 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230710_173102-mp7fkzus/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230710_173523-516c5pee
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wobbly-star-1336
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/516c5pee
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                     Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb: Test loss tennis_pNone_gNone_tennisEffect â–‡â–ˆâ–†â–…â–„â–…â–ƒâ–â–â–
wandb:                                Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                     Epoch 9
wandb: Test loss tennis_pNone_gNone_tennisEffect 1e-05
wandb:                                Train loss 1e-05
wandb: 
wandb: ðŸš€ View run wobbly-star-1336 at: https://wandb.ai/nreints/ThesisFinal2/runs/516c5pee
wandb: Synced 7 W&B file(s), 0 media file(s), 1 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230710_173523-516c5pee/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230710_173943-g05kjg3i
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run polar-bird-1350
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/g05kjg3i
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 45.3359010219574 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 11.434969186782837 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: log_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0025478022 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 5.90607e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.07299041748047
Epoch 1/9
	 Logging train Loss: 3.62339e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 3.0584e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 18.928114414215088
Epoch 2/9
	 Logging train Loss: 2.96605e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.77473e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.09660053253174
Epoch 3/9
	 Logging train Loss: 2.84371e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.53603e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.32044744491577
Epoch 4/9
	 Logging train Loss: 2.51109e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.89896e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 18.985554933547974
Epoch 5/9
	 Logging train Loss: 2.121e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.32877e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.36088275909424
Epoch 6/9
	 Logging train Loss: 1.74157e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.35601e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 18.953505277633667
Epoch 7/9
	 Logging train Loss: 1.47183e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.40996e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.179795742034912
Epoch 8/9
	 Logging train Loss: 1.31179e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.04551e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.297537088394165
Epoch 9/9
	 Logging train Loss: 1.2463e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 9.1097e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.224201917648315
Saved model in  trained_models/gru/data_tennis_pNone_gNone_tennisEffect/'log_quat_1'_'False'.pth
It took  258.0184519290924  seconds.
----- ITERATION 8/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 45.315918922424316 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 11.3798348903656 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: log_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0019931537 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 3.51976e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.3307204246521
Epoch 1/9
	 Logging train Loss: 3.21654e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.59814e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.12079405784607
Epoch 2/9
	 Logging train Loss: 2.99106e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.30843e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.241814851760864
Epoch 3/9
	 Logging train Loss: 2.71636e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.59249e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 18.943424701690674
Epoch 4/9
	 Logging train Loss: 2.36875e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.82981e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.2770414352417
Epoch 5/9
	 Logging train Loss: 1.97767e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.54785e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 18.963425874710083
Epoch 6/9
	 Logging train Loss: 1.52915e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.21523e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 18.900182008743286
Epoch 7/9
	 Logging train Loss: 1.27373e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.5245e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 18.925800800323486
Epoch 8/9
	 Logging train Loss: 1.14641e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.50423e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.293842792510986
Epoch 9/9
	 Logging train Loss: 1.10566e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.07006e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.29443907737732
Saved model in  trained_models/gru/data_tennis_pNone_gNone_tennisEffect/'log_quat_1'_'False'.pth
It took  260.39095282554626  seconds.
----- ITERATION 9/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 45.43528699874878 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 11.378828763961792 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: log_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0018043048 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 3.88087e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 18.93037223815918
Epoch 1/9
	 Logging train Loss: 3.10725e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 4.15901e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.22535800933838
Epoch 2/9
	 Logging train Loss: 3.01838e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 3.0448e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.011873483657837
Epoch 3/9
	 Logging train Loss: 2.789e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.85815e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.172483205795288
Epoch 4/9
	 Logging train Loss: 2.51694e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.19589e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.016911268234253
Epoch 5/9
	 Logging train Loss: 2.1578e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.72484e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 18.85201668739319
Epoch 6/9
	 Logging train Loss: 1.71991e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.83366e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.088374137878418
Epoch 7/9
	 Logging train Loss: 1.35936e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.26156e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.050478219985962
Epoch 8/9
	 Logging train Loss: 1.16698e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.22315e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.40627908706665
Epoch 9/9
	 Logging train Loss: 1.09106e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.03893e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.00768756866455
Saved model in  trained_models/gru/data_tennis_pNone_gNone_tennisEffect/'log_quat_1'_'False'.pth
It took  259.99786019325256  seconds.
----- ITERATION 10/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 45.399569034576416 seconds.
-- Finished Train Dataloader --
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                     Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb: Test loss tennis_pNone_gNone_tennisEffect â–ˆâ–†â–…â–‡â–ƒâ–‚â–‚â–‚â–â–
wandb:                                Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                     Epoch 9
wandb: Test loss tennis_pNone_gNone_tennisEffect 1e-05
wandb:                                Train loss 1e-05
wandb: 
wandb: ðŸš€ View run polar-bird-1350 at: https://wandb.ai/nreints/ThesisFinal2/runs/g05kjg3i
wandb: Synced 7 W&B file(s), 0 media file(s), 1 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230710_173943-g05kjg3i/logs
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 11.371141195297241 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: log_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0019585048 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 4.0577e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 18.913846492767334
Epoch 1/9
	 Logging train Loss: 3.20772e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 3.05332e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.208581924438477
Epoch 2/9
	 Logging train Loss: 3.01956e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.66072e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 18.87970542907715
Epoch 3/9
	 Logging train Loss: 2.81583e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 3.5491e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.078097820281982
Epoch 4/9
	 Logging train Loss: 2.50025e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.96436e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.118338346481323
Epoch 5/9
	 Logging train Loss: 2.04928e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.54317e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 18.960140228271484
Epoch 6/9
	 Logging train Loss: 1.66207e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.27234e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.02784013748169
Epoch 7/9
	 Logging train Loss: 1.31205e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.29585e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 18.826639652252197
Epoch 8/9
	 Logging train Loss: 1.1873e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 9.3662e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.38659644126892
Epoch 9/9
	 Logging train Loss: 1.09862e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.01416e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.05103373527527
Saved model in  trained_models/gru/data_tennis_pNone_gNone_tennisEffect/'log_quat_1'_'False'.pth
It took  257.95797085762024  seconds.

JOB STATISTICS
==============
Job ID: 3043753
Array Job ID: 3043750_42
Cluster: snellius
User/Group: nreints/nreints
State: RUNNING
Nodes: 1
Cores per node: 18
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 13:07:12 core-walltime
Job Wall-clock time: 00:43:44
Memory Utilized: 0.00 MB (estimated maximum)
Memory Efficiency: 0.00% of 0.00 MB (0.00 MB/node)
WARNING: Efficiency statistics may be misleading for RUNNING jobs.
