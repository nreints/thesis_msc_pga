wandb: Currently logged in as: nreints. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_125108-ibbvq26o
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sunny-sunset-6
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/ibbvq26o
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue █▃▂▂▂▂▁▁▁▁
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue █▂▁▂▁▃▁▁▁▁
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue █▃▂▂▂▂▁▁▁▁
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue █▄▃▂▂▂▁▁▁▁
wandb:                                 Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue 0.00097
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.00029
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.0041
wandb:                                 Train loss 9e-05
wandb: 
wandb: 🚀 View run sunny-sunset-6 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/ibbvq26o
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_125108-ibbvq26o/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_125845-v6l8gk2v
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fresh-elevator-55
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/v6l8gk2v
Training on dataset: data_t(0,0)_r(0,0)_combi_pTrue_gTrue
Testing on 4 datasets: ['data_t(0,0)_r(0,0)_semi_pTrue_gTrue', 'data_t(0,0)_r(0,0)_tennis_pTrue_gTrue', 'data_t(0,0)_r(0,0)_combi_pTrue_gTrue', 'data_t(0,0)_r(0,0)_full_pTrue_gTrue']
Focussing on identity: False
Using extra input: False
Using start-fr as reference point.
----- ITERATION 1/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 77.26146578788757 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 19.675899744033813 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 19.042096614837646 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 20.05339765548706 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 19.256097078323364 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: log_quat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0794371516 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0069875959 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0490081273 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0157550685 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0001223943 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 30.50886631011963
Epoch 1/9
	 Logging train Loss: 0.0021092482 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0025939599 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0219336227 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0058750622 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.87527e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 28.650319814682007
Epoch 2/9
	 Logging train Loss: 0.0006180267 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0014628158 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0153054381 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0036054635 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.07476e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 28.64264965057373
Epoch 3/9
	 Logging train Loss: 0.0002677931 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0011103718 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0131449094 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0030238749 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.35657e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 28.743935108184814
Epoch 4/9
	 Logging train Loss: 0.0001892883 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0007718848 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0105260937 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0023619186 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 5.4e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 28.509347677230835
Epoch 5/9
	 Logging train Loss: 0.0001912711 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.001173499 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0098539572 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0023056783 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 4.28545e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 28.660996198654175
Epoch 6/9
	 Logging train Loss: 0.0001130263 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0004773082 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0069481507 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0015603235 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 4.2068e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 28.493433237075806
Epoch 7/9
	 Logging train Loss: 0.0001260938 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0004660971 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0056962706 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0013607848 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 5.3421e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 28.70077133178711
Epoch 8/9
	 Logging train Loss: 9.13505e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0003463378 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0049502174 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0011387677 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.9685e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 28.69912075996399
Epoch 9/9
	 Logging train Loss: 8.7348e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0002855027 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0040965024 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0009710965 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 3.4013e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 29.197572946548462
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pTrue_gTrue/'log_quat'_'False'.pth
It took  458.2795841693878  seconds.
----- ITERATION 2/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 72.22288179397583 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 18.38037657737732 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 18.33805203437805 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 18.185179948806763 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 17.746943712234497 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: log_quat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0793311745 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0093393633 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0764921829 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0144823091 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0001323633 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 29.197834014892578
Epoch 1/9
	 Logging train Loss: 0.0024438256 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0026953134 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0328520723 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0050982093 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.25978e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 28.947694301605225
Epoch 2/9
	 Logging train Loss: 0.0005661268 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0012274281 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.020397393 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0028054768 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.11179e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 29.06700110435486
Epoch 3/9
	 Logging train Loss: 0.0003364887 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0009033792 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0150101371 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0018499732 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 8.939e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 28.69900894165039
Epoch 4/9
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue █▃▂▂▁▁▁▁▁▁
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue █▂▁▁▁▂▁▁▁▁
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue █▃▂▁▁▁▁▁▁▁
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue █▄▂▂▂▂▁▁▁▁
wandb:                                 Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue 0.00045
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 1e-05
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.00033
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.00545
wandb:                                 Train loss 9e-05
wandb: 
wandb: 🚀 View run fresh-elevator-55 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/v6l8gk2v
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_125845-v6l8gk2v/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_130612-95l65jgj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dry-gorge-94
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/95l65jgj
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue █▄▃▂▁▁▁▁▁▁
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue █▂▁▁▁▁▁▁▁▂
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue █▃▃▂▁▁▁▁▁▁
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue █▃▂▂▂▁▁▁▁▁
wandb:                                 Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue 0.00038
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 2e-05
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.00029
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.0041
wandb:                                 Train loss 6e-05
wandb: 
wandb: 🚀 View run dry-gorge-94 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/95l65jgj
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_130612-95l65jgj/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_131340-pfeotokr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run neat-eon-126
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/pfeotokr
	 Logging train Loss: 0.0001775467 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0006535002 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0118725747 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0014139287 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 7.4256e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 29.000301122665405
Epoch 5/9
	 Logging train Loss: 0.0001682793 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0007524966 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0105317663 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0011323895 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.00848e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 28.820063591003418
Epoch 6/9
	 Logging train Loss: 0.000186226 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0006205866 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0089666517 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0010447913 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 8.0362e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 29.05926275253296
Epoch 7/9
	 Logging train Loss: 0.0001025436 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.000429931 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0075495648 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0006855287 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 4.4069e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 29.09170699119568
Epoch 8/9
	 Logging train Loss: 0.0001119866 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0004513098 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0062850993 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0005567099 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 7.2326e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 28.966009616851807
Epoch 9/9
	 Logging train Loss: 8.60767e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0003349811 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0054512625 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0004518353 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 6.9102e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 29.024704456329346
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pTrue_gTrue/'log_quat'_'False'.pth
It took  446.9769744873047  seconds.
----- ITERATION 3/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 71.04201698303223 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 18.26680827140808 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 18.200783729553223 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 17.98748016357422 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 18.260630130767822 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: log_quat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0697182566 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.007198256 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0480415262 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0069914651 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0001247515 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 29.276896715164185
Epoch 1/9
	 Logging train Loss: 0.0022082699 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0023003032 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0193037577 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0028047913 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.4599e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 29.15399980545044
Epoch 2/9
	 Logging train Loss: 0.0005421831 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0017968528 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0133597767 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0019925144 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.01095e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 29.135416507720947
Epoch 3/9
	 Logging train Loss: 0.0003140147 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0007875037 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.009796421 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.001126235 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 7.1644e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 29.05849266052246
Epoch 4/9
	 Logging train Loss: 0.0002551514 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0004540632 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0076258676 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0007068946 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 4.5555e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 28.97792887687683
Epoch 5/9
	 Logging train Loss: 0.0001299703 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0004302633 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0065620528 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0006239291 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 5.3055e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 29.29365301132202
Epoch 6/9
	 Logging train Loss: 0.0001070673 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0002756936 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0057015526 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0004443458 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 3.3265e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 29.042372941970825
Epoch 7/9
	 Logging train Loss: 0.0001207274 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0003041932 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0051974501 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0005490534 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 5.0641e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 29.238115787506104
Epoch 8/9
	 Logging train Loss: 0.000168966 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0001796764 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0041527809 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0003063663 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.9335e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 29.217029571533203
Epoch 9/9
	 Logging train Loss: 5.64639e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0002894878 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0041011507 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0003796929 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.80369e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 29.160656213760376
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pTrue_gTrue/'log_quat'_'False'.pth
It took  448.17677998542786  seconds.
----- ITERATION 4/10 ------
Number of train simulations:  1920
Number of test simulations:  480
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue █▃▂▂▁▁▁▁▁▁
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue █▂▁▁▁▁▁▂▁▁
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue █▃▂▁▁▂▁▁▁▁
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue █▃▂▂▁▁▁▁▁▁
wandb:                                 Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue 0.00033
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 1e-05
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.0003
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.0008
wandb:                                 Train loss 6e-05
wandb: 
wandb: 🚀 View run neat-eon-126 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/pfeotokr
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_131340-pfeotokr/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_132108-5nrx98yu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run visionary-brook-163
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/5nrx98yu
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 71.09419631958008 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 18.286494493484497 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 18.320841312408447 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 17.942246198654175 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 18.222474098205566 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: log_quat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0844183043 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0059184213 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0157785658 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0092820963 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0001443039 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 29.178537845611572
Epoch 1/9
	 Logging train Loss: 0.0027287602 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0018743414 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.00582432 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0032085022 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.51138e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 28.809406518936157
Epoch 2/9
	 Logging train Loss: 0.0007560549 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0008613351 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0029517009 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0015498223 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 7.7196e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 29.16560673713684
Epoch 3/9
	 Logging train Loss: 0.0002950652 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0006623123 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0021091693 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0010607147 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 9.026e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 28.958976984024048
Epoch 4/9
	 Logging train Loss: 0.0002477111 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0005334351 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0016529945 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0008021133 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.09727e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 29.069482564926147
Epoch 5/9
	 Logging train Loss: 0.0001428625 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0007914949 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0014789582 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0007105992 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 6.7589e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 29.141945123672485
Epoch 6/9
	 Logging train Loss: 0.0001330208 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0003447793 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0010179444 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0004750991 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 3.7726e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 29.04136323928833
Epoch 7/9
	 Logging train Loss: 0.0001088759 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0006424012 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0011410296 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0005536698 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.01344e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 29.234148740768433
Epoch 8/9
	 Logging train Loss: 0.0001255069 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0003018623 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.00088369 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0003782596 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 4.0119e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 28.918147563934326
Epoch 9/9
	 Logging train Loss: 6.26835e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0002957052 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.000801633 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0003253842 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 7.8371e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 29.00819420814514
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pTrue_gTrue/'log_quat'_'False'.pth
It took  448.06095266342163  seconds.
----- ITERATION 5/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 71.04489707946777 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 18.260826349258423 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 18.326481342315674 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 17.911298751831055 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 18.236204147338867 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: log_quat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0782329142 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0159047078 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0438547954 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0031838298 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0001529313 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 29.452752113342285
Epoch 1/9
	 Logging train Loss: 0.0023941689 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.005666438 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0209743455 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0006707173 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.01877e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 29.05229616165161
Epoch 2/9
	 Logging train Loss: 0.0006385788 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.003212356 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0141377896 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0004195035 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.34756e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 29.185108423233032
Epoch 3/9
	 Logging train Loss: 0.0003080678 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0024048802 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0115483366 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0002816999 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.3142e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 29.144612789154053
Epoch 4/9
	 Logging train Loss: 0.0002634781 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.001880796 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0096506532 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0002387194 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 8.565e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 28.975059032440186
Epoch 5/9
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue █▂▂▁▁▂▁▁▁▁
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue █▂▁▁▁▂▁▁▁▁
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue █▃▂▂▂▁▁▁▁▁
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue █▄▃▂▂▂▁▁▁▁
wandb:                                 Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue 8e-05
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.0007
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.00385
wandb:                                 Train loss 0.0001
wandb: 
wandb: 🚀 View run visionary-brook-163 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/5nrx98yu
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_132108-5nrx98yu/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_132836-661kfsk2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run snowy-dust-201
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/661kfsk2
wandb: Waiting for W&B process to finish... (success).
wandb: ERROR Error while calling W&B API: An internal error occurred. Please contact support. (<Response [500]>)
wandb: 
wandb: Run history:
wandb:                                      Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue █▂▁▁▁▁▂▁▁▁
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue █▂▁▁▂▁▄▁▁▁
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue █▂▂▁▁▁▁▁▁▁
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue █▃▂▂▂▂▁▁▁▁
wandb:                                 Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue 3e-05
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.00016
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.00385
wandb:                                 Train loss 0.00011
wandb: 
wandb: 🚀 View run snowy-dust-201 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/661kfsk2
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_132836-661kfsk2/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_133606-w2u4nmk3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vivid-snowball-234
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/w2u4nmk3
	 Logging train Loss: 0.0001628987 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0017601089 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0080363508 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0003152911 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.52978e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 28.956475496292114
Epoch 6/9
	 Logging train Loss: 0.0001460947 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0011764367 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0062819645 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.00011428 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 4.9223e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 29.135150909423828
Epoch 7/9
	 Logging train Loss: 0.0001052025 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0010596443 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0055270535 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0001416719 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 5.0297e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 29.195523262023926
Epoch 8/9
	 Logging train Loss: 0.000119536 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.00090072 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.004661154 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0001192715 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 8.0114e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 28.75398564338684
Epoch 9/9
	 Logging train Loss: 9.88426e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.000695715 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0038527255 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 8.01127e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.812e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 29.2497661113739
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pTrue_gTrue/'log_quat'_'False'.pth
It took  447.70450091362  seconds.
----- ITERATION 6/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 72.26620197296143 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 18.202237844467163 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 18.31322693824768 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 18.04333758354187 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 18.240844249725342 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: log_quat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0876273215 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.006247953 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0487828404 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0018262034 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0001346809 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 29.253332376480103
Epoch 1/9
	 Logging train Loss: 0.0027347158 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0013380165 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0192122497 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0003173077 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.9949e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 29.19976258277893
Epoch 2/9
	 Logging train Loss: 0.0007067987 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0006098514 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0119618233 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.00013168 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 9.3139e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 29.218381643295288
Epoch 3/9
	 Logging train Loss: 0.0003331174 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0005450666 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0090584923 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0001041937 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 8.5441e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 29.13349461555481
Epoch 4/9
	 Logging train Loss: 0.0002628257 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0005144089 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0072623775 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0001257293 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.51336e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 29.00167417526245
Epoch 5/9
	 Logging train Loss: 0.0001469324 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0005072202 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0073408489 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0001534984 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.16592e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 29.062344074249268
Epoch 6/9
	 Logging train Loss: 0.000133151 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0005638662 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.006456288 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0001915971 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 6.09717e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 29.125953197479248
Epoch 7/9
	 Logging train Loss: 0.0001084407 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0002504383 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.005041773 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 5.85987e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 5.8887e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 29.03716278076172
Epoch 8/9
	 Logging train Loss: 0.0001107153 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0001921548 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0042905984 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 3.7323e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 3.3143e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 29.34476113319397
Epoch 9/9
	 Logging train Loss: 0.0001097418 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0001584335 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0038493189 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 3.08291e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 3.8163e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 29.05421018600464
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pTrue_gTrue/'log_quat'_'False'.pth
It took  450.14701294898987  seconds.
----- ITERATION 7/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 71.15574383735657 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 18.100253343582153 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 18.217401027679443 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 17.96006178855896 seconds.
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue █▃▂▂▂▁▁▁▁▁
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue █▂▂▁▂▁▁▁▂▁
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue █▂▂▁▁▁▁▁▂▁
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue █▃▂▂▂▁▁▁▁▁
wandb:                                 Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue 0.00065
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.00021
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.00166
wandb:                                 Train loss 6e-05
wandb: 
wandb: 🚀 View run vivid-snowball-234 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/w2u4nmk3
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_133606-w2u4nmk3/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_134334-9zqlndav
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run floral-river-273
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/9zqlndav
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 18.222883224487305 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: log_quat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0728759915 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0053241518 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0297446325 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0152729042 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0001428622 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 29.28168797492981
Epoch 1/9
	 Logging train Loss: 0.0024250317 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0013081166 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0115269087 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0057843886 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.46389e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 29.16259789466858
Epoch 2/9
	 Logging train Loss: 0.0005999565 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0007106566 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0071229045 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0037213282 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.99865e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 28.98141837120056
Epoch 3/9
	 Logging train Loss: 0.0003160585 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0004587526 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0047808839 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0024008031 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 7.2464e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 29.167844533920288
Epoch 4/9
	 Logging train Loss: 0.0001748146 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.000531151 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0040359506 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0018731192 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.42236e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 28.963483095169067
Epoch 5/9
	 Logging train Loss: 0.0001671366 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0002938192 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0030663228 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0014593728 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 4.5251e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 29.27398943901062
Epoch 6/9
	 Logging train Loss: 0.00013653 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0002954447 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0022960368 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.000947927 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 5.1036e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 29.146366357803345
Epoch 7/9
	 Logging train Loss: 0.0001448881 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0002872561 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0022807284 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0010282212 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 3.1321e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 29.31035041809082
Epoch 8/9
	 Logging train Loss: 0.0001065725 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.000841639 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0032198618 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0015033216 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 3.11676e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 29.43980121612549
Epoch 9/9
	 Logging train Loss: 5.75557e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0002148137 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0016636438 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0006526576 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 3.5442e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 29.093703746795654
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pTrue_gTrue/'log_quat'_'False'.pth
It took  448.12625551223755  seconds.
----- ITERATION 8/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 71.90881991386414 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 18.17525315284729 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 18.258700847625732 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 18.10661292076111 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 18.239640712738037 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: log_quat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0732651576 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0078698434 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0396963283 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.01317186 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0001535038 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 29.29234266281128
Epoch 1/9
	 Logging train Loss: 0.0026570109 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0023543886 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.014114039 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0043664528 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.85527e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 29.162058115005493
Epoch 2/9
	 Logging train Loss: 0.000680492 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0012005129 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.008810834 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0025414666 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.31475e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 29.12988042831421
Epoch 3/9
	 Logging train Loss: 0.0003356209 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0013646323 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.00727326 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0020638469 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.54692e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 29.271052598953247
Epoch 4/9
	 Logging train Loss: 0.0002209746 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0007604721 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0058984472 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0015189259 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 8.1709e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 29.11604356765747
Epoch 5/9
	 Logging train Loss: 0.0001643156 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0029455328 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0088114068 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0030951013 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 3.60289e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue █▃▂▂▂▂▁▁▁▁
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue █▂▁▂▁▂▁▁▁▁
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue █▃▂▂▁▃▁▁▁▁
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue █▃▂▂▂▂▁▁▁▁
wandb:                                 Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue 0.00043
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.00031
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.00258
wandb:                                 Train loss 0.00012
wandb: 
wandb: 🚀 View run floral-river-273 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/9zqlndav
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_134334-9zqlndav/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_135103-rc42xsvn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run deft-durian-311
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/rc42xsvn
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue █▃▂▁▁▁▁▁▁▁
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue █▂▁▁▁▁▁▁▃▁
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue █▃▂▂▁▁▁▁▁▁
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue █▃▂▂▂▁▁▁▁▁
wandb:                                 Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue 0.00036
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.00037
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.00354
wandb:                                 Train loss 0.00011
wandb: 
wandb: 🚀 View run deft-durian-311 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/rc42xsvn
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_135103-rc42xsvn/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_135832-qk62hcye
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run bright-frost-341
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/qk62hcye
		--> Epoch time; 29.118054628372192
Epoch 6/9
	 Logging train Loss: 0.0001599106 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0004558352 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0036159458 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0007347866 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 4.8693e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 29.409611701965332
Epoch 7/9
	 Logging train Loss: 0.0001010065 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0007221402 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0035797183 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0007987603 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 8.0706e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 29.07916522026062
Epoch 8/9
	 Logging train Loss: 0.0001269954 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0003679877 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0029918291 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0005411634 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 7.6679e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 29.08580207824707
Epoch 9/9
	 Logging train Loss: 0.000116959 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0003091853 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0025796238 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0004334271 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 4.2322e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 29.062418222427368
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pTrue_gTrue/'log_quat'_'False'.pth
It took  449.0700421333313  seconds.
----- ITERATION 9/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 72.19526243209839 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 18.199814796447754 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 18.22731351852417 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 18.044234037399292 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 18.233994245529175 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: log_quat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.082185857 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0075660851 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0362824239 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0062253713 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0001433999 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 29.11217164993286
Epoch 1/9
	 Logging train Loss: 0.0028271943 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.002568305 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0144394469 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0019790463 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.46507e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 29.156009197235107
Epoch 2/9
	 Logging train Loss: 0.0007385252 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0014041761 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0096310033 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0009825851 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.12492e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 28.877033233642578
Epoch 3/9
	 Logging train Loss: 0.0003315758 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0009579517 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0076328791 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0007661556 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 6.6663e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 29.368247509002686
Epoch 4/9
	 Logging train Loss: 0.0002556901 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0008664413 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0060162833 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0005720445 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 7.2315e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 28.988803386688232
Epoch 5/9
	 Logging train Loss: 0.0001429545 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0005909519 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0052440129 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0004755359 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 4.1555e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 29.281884908676147
Epoch 6/9
	 Logging train Loss: 0.0001122174 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0004944367 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.004677847 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0004330015 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 3.5636e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 29.19143319129944
Epoch 7/9
	 Logging train Loss: 0.0001377208 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0004108087 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0039971792 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.000369953 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 4.6186e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 29.211750268936157
Epoch 8/9
	 Logging train Loss: 0.0001219028 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0007659603 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.004069448 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0006401315 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 4.10868e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 29.173627853393555
Epoch 9/9
	 Logging train Loss: 0.0001075075 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0003701376 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0035374591 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0003560697 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 3.4629e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 29.212409257888794
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pTrue_gTrue/'log_quat'_'False'.pth
It took  449.1408269405365  seconds.
----- ITERATION 10/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 71.80793404579163 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 18.245487689971924 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 18.244280338287354 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 18.16635298728943 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 18.26849937438965 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: log_quat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.084260121 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0070080776 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue █▃▂▂▁▁▁▁▁▁
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue █▂▁▁▁▁▁▁▁▁
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue █▃▂▁▁▁▁▁▁▁
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue █▄▃▂▂▂▁▁▁▁
wandb:                                 Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue 0.00047
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.00027
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.0029
wandb:                                 Train loss 8e-05
wandb: 
wandb: 🚀 View run bright-frost-341 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/qk62hcye
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_135832-qk62hcye/logs
	 Logging test loss: 0.043113865 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0050388477 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0001601657 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 29.16848373413086
Epoch 1/9
	 Logging train Loss: 0.0026996725 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0021888867 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0196658969 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.002012074 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 3.09097e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 29.231635093688965
Epoch 2/9
	 Logging train Loss: 0.0007294865 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0010407954 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0128728086 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0012875306 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.22894e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 29.0313458442688
Epoch 3/9
	 Logging train Loss: 0.0003775413 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0006064812 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0094517171 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0010022308 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.10798e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 29.046493530273438
Epoch 4/9
	 Logging train Loss: 0.000227897 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.000489955 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0071775671 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0007910468 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 6.2038e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 28.79910635948181
Epoch 5/9
	 Logging train Loss: 0.0001772593 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0004522617 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0059819645 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0007857099 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 4.5245e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 29.135295391082764
Epoch 6/9
	 Logging train Loss: 0.0001464644 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.000436402 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0050775344 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0006872975 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 6.1124e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 29.064135551452637
Epoch 7/9
	 Logging train Loss: 0.0001940114 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0003468262 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0039776051 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0005793585 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 4.7736e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 28.999151945114136
Epoch 8/9
	 Logging train Loss: 8.11126e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0004756704 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0037652927 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0006180975 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 6.8275e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 29.274293661117554
Epoch 9/9
	 Logging train Loss: 7.69659e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0002736749 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0029029872 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0004678689 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 3.1331e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 29.015103816986084
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pTrue_gTrue/'log_quat'_'False'.pth
It took  448.13520908355713  seconds.

JOB STATISTICS
==============
Job ID: 3081639
Array Job ID: 3081615_26
Cluster: snellius
User/Group: nreints/nreints
State: COMPLETED (exit code 0)
Nodes: 1
Cores per node: 18
CPU Utilized: 01:21:25
CPU Efficiency: 6.02% of 22:32:42 core-walltime
Job Wall-clock time: 01:15:09
Memory Utilized: 8.12 GB
Memory Efficiency: 0.00% of 0.00 MB
