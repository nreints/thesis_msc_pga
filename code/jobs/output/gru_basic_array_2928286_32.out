wandb: Currently logged in as: nreints. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230616_170717-cb09uw9r
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run neat-morning-58
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal/runs/cb09uw9r
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch ▁▂▃▃▄▅▆▆▇█
wandb: Test loss t(5,20)_r(5,20)_combiR_pNone_gNone █▃▂▂▂▂▂▁▁▁
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone █▆▆▆▅▄▄▃▂▁
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone █▃▂▂▂▂▂▁▁▁
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone █▃▂▂▂▂▁▁▁▁
wandb:                                   Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb: Test loss t(5,20)_r(5,20)_combiR_pNone_gNone 3e-05
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 2e-05
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 3e-05
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 3e-05
wandb:                                   Train loss 3e-05
wandb: 
wandb: 🚀 View run neat-morning-58 at: https://wandb.ai/nreints/ThesisFinal/runs/cb09uw9r
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230616_170717-cb09uw9r/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230616_171659-erwk3vit
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run balmy-sun-67
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal/runs/erwk3vit
Training on dataset: data_t(5,20)_r(5,20)_combiR_pNone_gNone
Testing on 4 datasets: ['data_t(5,20)_r(5,20)_combiR_pNone_gNone', 'data_t(5,20)_r(5,20)_semi_pNone_gNone', 'data_t(5,20)_r(5,20)_tennis_pNone_gNone', 'data_t(5,20)_r(5,20)_full_pNone_gNone']
Focussing on identity: False
Using extra input: None
Using fr-fr as reference point.
----- ITERATION 1/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  800
Number of test simulations:  200
The dataloader for data/data_t(5,20)_r(5,20)_combiR_pNone_gNone took 21.47929620742798 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_combiR_pNone_gNone took 5.3709094524383545 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 5.410639047622681 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 5.390051603317261 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 5.386171579360962 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.1232678965 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 0.0003402361 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 0.0004315577 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0004133052 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 9.06429e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 52.472527742385864
Epoch 1/9
	 Logging train Loss: 0.0001667374 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 0.0001169709 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 0.0001283786 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0001205022 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 7.46431e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 55.180891275405884
Epoch 2/9
	 Logging train Loss: 9.71172e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 9.44841e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 0.0001004235 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 9.78643e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 6.77095e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 53.85888075828552
Epoch 3/9
	 Logging train Loss: 8.38364e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 8.26082e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 8.90378e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 8.77916e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 6.46933e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 52.165921449661255
Epoch 4/9
	 Logging train Loss: 7.42968e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 7.45725e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 7.8681e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 7.6221e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 5.63614e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 52.079479932785034
Epoch 5/9
	 Logging train Loss: 6.59086e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 6.60848e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 6.91898e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 6.49677e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.95837e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 51.985732555389404
Epoch 6/9
	 Logging train Loss: 5.72723e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 6.02754e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 6.22672e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 5.71074e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.50254e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 51.875486850738525
Epoch 7/9
	 Logging train Loss: 4.8376e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 4.65219e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 5.09241e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.79933e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.35826e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 52.401074171066284
Epoch 8/9
	 Logging train Loss: 3.94277e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 3.70191e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 4.11285e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.775e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.65219e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 52.117109537124634
Epoch 9/9
	 Logging train Loss: 3.09298e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 2.94165e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 3.30144e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.0028e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.78775e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 52.43631148338318
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combiR_pNone_gNone/'rot_mat_1'_'None'.pth
It took  582.8956212997437  seconds.
----- ITERATION 2/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  800
Number of test simulations:  200
The dataloader for data/data_t(5,20)_r(5,20)_combiR_pNone_gNone took 19.756908178329468 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_combiR_pNone_gNone took 4.9415669441223145 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 5.011571168899536 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 5.021355628967285 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 5.029768705368042 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0794808939 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 0.0003741612 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 0.0004742196 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0004783546 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 9.71267e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 53.41658616065979
Epoch 1/9
	 Logging train Loss: 0.000185127 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 0.0001128636 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 0.0001306906 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0001319144 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 7.67416e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 53.37580227851868
Epoch 2/9
	 Logging train Loss: 0.0001013631 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 8.77918e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 0.0001009939 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 9.93383e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 6.82131e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 53.29189443588257
Epoch 3/9
	 Logging train Loss: 8.55066e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch ▁▂▃▃▄▅▆▆▇█
wandb: Test loss t(5,20)_r(5,20)_combiR_pNone_gNone █▃▂▂▂▂▂▁▁▁
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone █▆▆▅▅▄▃▃▂▁
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone █▃▂▂▂▂▂▁▁▁
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone █▃▂▂▂▂▂▁▁▁
wandb:                                   Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb: Test loss t(5,20)_r(5,20)_combiR_pNone_gNone 2e-05
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 1e-05
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 3e-05
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 3e-05
wandb:                                   Train loss 3e-05
wandb: 
wandb: 🚀 View run balmy-sun-67 at: https://wandb.ai/nreints/ThesisFinal/runs/erwk3vit
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230616_171659-erwk3vit/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230616_172649-cwdqx9cz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run silvery-shape-74
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal/runs/cwdqx9cz
	 Logging test loss: 7.81247e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 8.86462e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 8.8513e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 6.42246e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 52.99048089981079
Epoch 4/9
	 Logging train Loss: 7.50055e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 7.16982e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 8.14822e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 8.14249e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 5.99087e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 53.37719202041626
Epoch 5/9
	 Logging train Loss: 6.5385e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 5.94011e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 6.88798e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 6.51851e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.89526e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 53.228466272354126
Epoch 6/9
	 Logging train Loss: 5.56178e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 5.1818e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 5.866e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 6.01511e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.22333e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 53.18548107147217
Epoch 7/9
	 Logging train Loss: 4.5604e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 4.31312e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 4.84434e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 5.05358e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.37729e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 53.300538539886475
Epoch 8/9
	 Logging train Loss: 3.54933e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 3.1098e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 3.76243e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.61577e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.13641e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 56.11520218849182
Epoch 9/9
	 Logging train Loss: 2.60832e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 2.11261e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 2.62869e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.55926e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.233e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 54.83546018600464
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combiR_pNone_gNone/'rot_mat_1'_'None'.pth
It took  589.8913605213165  seconds.
----- ITERATION 3/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  800
Number of test simulations:  200
The dataloader for data/data_t(5,20)_r(5,20)_combiR_pNone_gNone took 19.72830629348755 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_combiR_pNone_gNone took 4.922243118286133 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 5.003588438034058 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 5.017465591430664 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 5.052923679351807 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0319875963 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 0.0001233891 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 0.0001388323 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0001473633 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 8.25178e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 51.99715733528137
Epoch 1/9
	 Logging train Loss: 0.0001085953 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 9.39612e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 0.0001046932 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0001066836 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 7.13362e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 52.08270025253296
Epoch 2/9
	 Logging train Loss: 9.0095e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 8.16884e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 8.98744e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 9.14554e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 6.49653e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 52.49896216392517
Epoch 3/9
	 Logging train Loss: 7.98272e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 7.37476e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 8.11175e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 7.96305e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 5.89303e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 52.069820404052734
Epoch 4/9
	 Logging train Loss: 7.1143e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 6.42978e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 7.1529e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 7.14891e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 5.13647e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 52.372708797454834
Epoch 5/9
	 Logging train Loss: 6.24112e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 5.59027e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 6.2827e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 6.18987e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.34853e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 52.089998960494995
Epoch 6/9
	 Logging train Loss: 5.32914e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 4.66155e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 5.32463e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 5.10423e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.49048e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 52.07122778892517
Epoch 7/9
	 Logging train Loss: 4.39164e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 3.94331e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 4.53481e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.4803e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.83959e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 52.15000653266907
Epoch 8/9
	 Logging train Loss: 3.48924e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 2.95866e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 3.52911e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.38061e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.87895e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 52.05083513259888
Epoch 9/9
	 Logging train Loss: 2.67271e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch ▁▂▃▃▄▅▆▆▇█
wandb: Test loss t(5,20)_r(5,20)_combiR_pNone_gNone █▆▅▅▄▃▃▂▂▁
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone █▇▆▆▅▄▃▃▂▁
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone █▆▅▄▄▃▃▂▁▁
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone █▆▅▄▄▃▂▂▁▁
wandb:                                   Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb: Test loss t(5,20)_r(5,20)_combiR_pNone_gNone 2e-05
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 1e-05
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 3e-05
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 3e-05
wandb:                                   Train loss 3e-05
wandb: 
wandb: 🚀 View run silvery-shape-74 at: https://wandb.ai/nreints/ThesisFinal/runs/cwdqx9cz
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230616_172649-cwdqx9cz/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230616_173623-e9nblgzy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wobbly-gorge-82
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal/runs/e9nblgzy
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch ▁▂▃▃▄▅▆▆▇█
wandb: Test loss t(5,20)_r(5,20)_combiR_pNone_gNone █▆▅▄▃▃▂▁▁▁
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone █▇▆▅▄▃▂▂▁▁
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone █▆▅▄▃▂▂▁▁▁
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone █▆▅▄▃▂▂▁▁▁
wandb:                                   Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb: Test loss t(5,20)_r(5,20)_combiR_pNone_gNone 1e-05
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 2e-05
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 3e-05
wandb:                                   Train loss 1e-05
wandb: 
wandb: 🚀 View run wobbly-gorge-82 at: https://wandb.ai/nreints/ThesisFinal/runs/e9nblgzy
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230616_173623-e9nblgzy/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230616_174603-afnqbqvp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pious-dream-89
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal/runs/afnqbqvp
	 Logging test loss: 2.2337e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 2.75584e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.62187e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.24384e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 52.08160066604614
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combiR_pNone_gNone/'rot_mat_1'_'None'.pth
It took  573.4186520576477  seconds.
----- ITERATION 4/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  800
Number of test simulations:  200
The dataloader for data/data_t(5,20)_r(5,20)_combiR_pNone_gNone took 20.072654962539673 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_combiR_pNone_gNone took 4.983487367630005 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 5.0391294956207275 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 5.07888126373291 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 5.220265626907349 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0414038673 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 0.0001000947 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 0.0001201356 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0001221153 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 6.83763e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 52.56345176696777
Epoch 1/9
	 Logging train Loss: 8.95746e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 7.8786e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 9.03813e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 8.9427e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 6.08113e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 52.35700583457947
Epoch 2/9
	 Logging train Loss: 7.18949e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 6.6763e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 7.62444e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 7.52076e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 5.20697e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 52.549429178237915
Epoch 3/9
	 Logging train Loss: 5.87652e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 5.28476e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 6.09081e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 5.89765e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.02615e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 53.25614547729492
Epoch 4/9
	 Logging train Loss: 4.72307e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 4.05956e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 4.78888e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.68486e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.95088e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 55.478914737701416
Epoch 5/9
	 Logging train Loss: 3.70072e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 3.17289e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 3.87859e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.76478e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.12571e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 52.104215145111084
Epoch 6/9
	 Logging train Loss: 2.81977e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 2.35855e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 3.06528e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.02236e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.36224e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 52.226789712905884
Epoch 7/9
	 Logging train Loss: 2.08455e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 1.60976e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 2.21996e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.22155e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 7.8949e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 52.1203830242157
Epoch 8/9
	 Logging train Loss: 1.53783e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 1.25063e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 1.89713e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.90065e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.3456e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 52.30444312095642
Epoch 9/9
	 Logging train Loss: 1.25789e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 1.44818e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 2.2932e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.5027e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.9228e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 52.3482186794281
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combiR_pNone_gNone/'rot_mat_1'_'None'.pth
It took  579.9067313671112  seconds.
----- ITERATION 5/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  800
Number of test simulations:  200
The dataloader for data/data_t(5,20)_r(5,20)_combiR_pNone_gNone took 18.61709761619568 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_combiR_pNone_gNone took 4.655280590057373 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 4.9568281173706055 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 4.947180509567261 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 4.960596799850464 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.050720524 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 0.0001668726 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 0.0002174137 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0002368461 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 9.60464e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 53.26929211616516
Epoch 1/9
	 Logging train Loss: 0.0001237026 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 0.0001070189 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 0.0001220745 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0001215303 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 8.35449e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 53.244372844696045
Epoch 2/9
	 Logging train Loss: 9.06031e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 8.3215e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 9.54456e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 9.62006e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch ▁▂▃▃▄▅▆▆▇█
wandb: Test loss t(5,20)_r(5,20)_combiR_pNone_gNone █▅▄▃▃▂▂▁▁▁
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone █▇▆▅▄▄▃▂▂▁
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone █▄▃▃▂▂▂▁▁▁
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone █▄▃▃▂▂▁▁▁▁
wandb:                                   Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb: Test loss t(5,20)_r(5,20)_combiR_pNone_gNone 3e-05
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 1e-05
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 4e-05
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 4e-05
wandb:                                   Train loss 2e-05
wandb: 
wandb: 🚀 View run pious-dream-89 at: https://wandb.ai/nreints/ThesisFinal/runs/afnqbqvp
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230616_174603-afnqbqvp/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230616_175549-iwqd2cps
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run efficient-lake-96
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal/runs/iwqd2cps
	 Logging test loss: 7.03329e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 53.24065446853638
Epoch 3/9
	 Logging train Loss: 7.70219e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 7.10724e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 8.06711e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 8.10774e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 6.05158e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 53.48089361190796
Epoch 4/9
	 Logging train Loss: 6.62155e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 6.19605e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 6.97535e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 6.94138e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 5.25731e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 53.284632205963135
Epoch 5/9
	 Logging train Loss: 5.63172e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 5.09642e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 5.79476e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 5.80215e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.30283e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 53.41957116127014
Epoch 6/9
	 Logging train Loss: 4.66454e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 4.21424e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 4.8041e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.84939e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.35948e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 53.24768137931824
Epoch 7/9
	 Logging train Loss: 3.74006e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 3.24532e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 3.81449e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.93364e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.45768e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 53.38376450538635
Epoch 8/9
	 Logging train Loss: 2.91887e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 2.6992e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 3.23827e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.40265e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.79869e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 53.58668804168701
Epoch 9/9
	 Logging train Loss: 2.25543e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 2.78135e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 3.57366e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.98755e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.17026e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 54.392021894454956
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combiR_pNone_gNone/'rot_mat_1'_'None'.pth
It took  585.8563513755798  seconds.
----- ITERATION 6/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  800
Number of test simulations:  200
The dataloader for data/data_t(5,20)_r(5,20)_combiR_pNone_gNone took 19.14247155189514 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_combiR_pNone_gNone took 4.802996873855591 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 4.943806886672974 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 4.909489154815674 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 4.911696910858154 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0339278318 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 0.000123006 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 0.0001397532 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0001390785 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 8.40098e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 52.833702087402344
Epoch 1/9
	 Logging train Loss: 9.99157e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 9.2851e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 9.9503e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 9.93092e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 7.29147e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 52.529179096221924
Epoch 2/9
	 Logging train Loss: 8.50924e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 8.24431e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 8.79192e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 8.84988e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 6.61205e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 52.320168256759644
Epoch 3/9
	 Logging train Loss: 7.61837e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 7.37934e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 7.79648e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 7.77385e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 5.99085e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 52.27420449256897
Epoch 4/9
	 Logging train Loss: 6.71412e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 6.47183e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 6.95453e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 6.88832e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 5.18246e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 52.062514305114746
Epoch 5/9
	 Logging train Loss: 5.74874e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 5.68668e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 6.22186e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 6.15967e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.41387e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 52.591280937194824
Epoch 6/9
	 Logging train Loss: 4.70464e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 4.4962e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 4.96975e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.98519e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.40039e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 52.11010789871216
Epoch 7/9
	 Logging train Loss: 3.67053e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 3.4746e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 4.02839e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.0098e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.345e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 52.17982268333435
Epoch 8/9
	 Logging train Loss: 2.75379e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 2.81761e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 3.37315e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.55349e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch ▁▂▃▃▄▅▆▆▇█
wandb: Test loss t(5,20)_r(5,20)_combiR_pNone_gNone █▆▅▅▄▃▃▂▁▁
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone █▇▆▆▅▄▃▂▂▁
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone █▅▅▄▄▃▂▂▁▁
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone █▅▅▄▃▃▂▂▁▁
wandb:                                   Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb: Test loss t(5,20)_r(5,20)_combiR_pNone_gNone 2e-05
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 1e-05
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 3e-05
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 3e-05
wandb:                                   Train loss 2e-05
wandb: 
wandb: 🚀 View run efficient-lake-96 at: https://wandb.ai/nreints/ThesisFinal/runs/iwqd2cps
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230616_175549-iwqd2cps/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230616_180523-mhwq152b
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run restful-dust-102
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal/runs/mhwq152b
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch ▁▂▃▃▄▅▆▆▇█
wandb: Test loss t(5,20)_r(5,20)_combiR_pNone_gNone █▇▆▅▄▃▂▁▁▁
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone █▇▆▅▄▃▂▁▁▁
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone █▆▅▄▄▃▂▁▁▁
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone █▆▅▄▃▃▂▁▁▁
wandb:                                   Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb: Test loss t(5,20)_r(5,20)_combiR_pNone_gNone 1e-05
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 1e-05
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 1e-05
wandb:                                   Train loss 1e-05
wandb: 
wandb: 🚀 View run restful-dust-102 at: https://wandb.ai/nreints/ThesisFinal/runs/mhwq152b
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230616_180523-mhwq152b/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230616_181514-f7p0rbyh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run leafy-thunder-107
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal/runs/f7p0rbyh
	 Logging test loss: 1.60555e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 52.212923526763916
Epoch 9/9
	 Logging train Loss: 2.05401e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 2.26714e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 2.92753e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.00444e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 8.572e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 52.2366099357605
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combiR_pNone_gNone/'rot_mat_1'_'None'.pth
It took  574.9494354724884  seconds.
----- ITERATION 7/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  800
Number of test simulations:  200
The dataloader for data/data_t(5,20)_r(5,20)_combiR_pNone_gNone took 19.070264101028442 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_combiR_pNone_gNone took 4.743783950805664 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 4.9595983028411865 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 4.959746837615967 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 4.932953596115112 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0313152336 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 0.0001027476 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 0.0001190493 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0001116173 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 7.56463e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 53.23912978172302
Epoch 1/9
	 Logging train Loss: 9.07178e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 8.38602e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 9.34066e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 8.72302e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 6.8353e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 53.21795153617859
Epoch 2/9
	 Logging train Loss: 7.68201e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 7.29377e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 8.14648e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 7.58177e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 5.97403e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 53.30233430862427
Epoch 3/9
	 Logging train Loss: 6.47046e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 5.84735e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 6.59408e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 6.11205e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.57016e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 53.22547626495361
Epoch 4/9
	 Logging train Loss: 5.22602e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 4.5674e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 5.24242e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.85238e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.41882e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 53.385982275009155
Epoch 5/9
	 Logging train Loss: 3.97771e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 3.42051e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 4.05174e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.73243e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.39751e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 54.574140548706055
Epoch 6/9
	 Logging train Loss: 2.82952e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 2.34819e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 2.95451e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.73631e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.37005e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 57.24372339248657
Epoch 7/9
	 Logging train Loss: 1.93764e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 1.61769e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 2.15892e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.02269e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 6.8788e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 53.30504631996155
Epoch 8/9
	 Logging train Loss: 1.40601e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 1.17279e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 1.65559e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.5406e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.8649e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 53.274232387542725
Epoch 9/9
	 Logging train Loss: 1.17156e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 1.02216e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 1.45967e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.37231e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.8418e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 53.709070682525635
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combiR_pNone_gNone/'rot_mat_1'_'None'.pth
It took  590.8864371776581  seconds.
----- ITERATION 8/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  800
Number of test simulations:  200
The dataloader for data/data_t(5,20)_r(5,20)_combiR_pNone_gNone took 19.307228326797485 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_combiR_pNone_gNone took 4.830554246902466 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 4.886566877365112 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 4.894662857055664 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 4.900433301925659 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0586099401 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 0.000197842 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 0.0002464033 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0002659904 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 8.31826e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 51.99350380897522
Epoch 1/9
	 Logging train Loss: 0.0001148442 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 8.85261e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 9.85495e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 9.89704e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 6.57578e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 52.133758783340454
Epoch 2/9
	 Logging train Loss: 7.90234e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 7.23129e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch ▁▂▃▃▄▅▆▆▇█
wandb: Test loss t(5,20)_r(5,20)_combiR_pNone_gNone █▄▃▃▂▂▂▁▁▁
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone █▆▆▅▄▃▃▂▁▁
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone █▃▃▃▂▂▂▁▁▁
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone █▃▃▂▂▂▁▁▁▁
wandb:                                   Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb: Test loss t(5,20)_r(5,20)_combiR_pNone_gNone 2e-05
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 1e-05
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 2e-05
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 2e-05
wandb:                                   Train loss 2e-05
wandb: 
wandb: 🚀 View run leafy-thunder-107 at: https://wandb.ai/nreints/ThesisFinal/runs/f7p0rbyh
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230616_181514-f7p0rbyh/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230616_182447-arx328fy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fragrant-water-113
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal/runs/arx328fy
	 Logging test loss: 7.93615e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 7.97171e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 5.7012e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 52.03744173049927
Epoch 3/9
	 Logging train Loss: 6.56171e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 6.24959e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 6.92232e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 6.76807e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.99292e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 52.07534670829773
Epoch 4/9
	 Logging train Loss: 5.49443e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 5.0695e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 5.60655e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 5.45533e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.94689e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 52.106446266174316
Epoch 5/9
	 Logging train Loss: 4.55061e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 4.2044e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 4.70034e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.61416e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.15835e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 52.16053128242493
Epoch 6/9
	 Logging train Loss: 3.67595e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 3.39672e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 3.88316e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.76901e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.36572e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 52.10162925720215
Epoch 7/9
	 Logging train Loss: 2.89361e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 2.73215e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 3.1762e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.14835e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.6505e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 52.048060178756714
Epoch 8/9
	 Logging train Loss: 2.21285e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 2.12939e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 2.53335e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.55056e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.11655e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 52.145463943481445
Epoch 9/9
	 Logging train Loss: 1.69411e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 1.63799e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 2.00121e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.05629e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 6.8402e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 52.102335929870605
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combiR_pNone_gNone/'rot_mat_1'_'None'.pth
It took  573.112227678299  seconds.
----- ITERATION 9/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  800
Number of test simulations:  200
The dataloader for data/data_t(5,20)_r(5,20)_combiR_pNone_gNone took 19.660374402999878 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_combiR_pNone_gNone took 4.907916069030762 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 4.952186822891235 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 4.982221841812134 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 4.961639165878296 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0636968017 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 0.0001848807 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 0.0002521678 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0002404797 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 8.87846e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 53.42631220817566
Epoch 1/9
	 Logging train Loss: 0.0001296317 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 0.0001027408 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 0.0001191441 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0001209418 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 7.40948e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 56.98681044578552
Epoch 2/9
	 Logging train Loss: 9.66611e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 9.00874e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 9.90256e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0001005794 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 6.89633e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 54.278095722198486
Epoch 3/9
	 Logging train Loss: 8.58102e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 8.09187e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 8.84819e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 9.06438e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 6.45135e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 53.26791334152222
Epoch 4/9
	 Logging train Loss: 7.77033e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 7.26893e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 8.03387e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 8.13405e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 5.85814e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 53.461119174957275
Epoch 5/9
	 Logging train Loss: 6.99199e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 6.76659e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 7.25531e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 7.3745e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 5.34803e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 53.220805406570435
Epoch 6/9
	 Logging train Loss: 6.16327e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 5.89974e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 6.37617e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 6.45421e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.55198e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 53.359896183013916
Epoch 7/9
	 Logging train Loss: 5.23514e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 4.65934e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 5.36313e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 5.32692e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.61348e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 53.11946082115173
Epoch 8/9
	 Logging train Loss: 4.20987e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch ▁▂▃▃▄▅▆▆▇█
wandb: Test loss t(5,20)_r(5,20)_combiR_pNone_gNone █▄▄▃▃▃▂▂▁▁
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone █▇▆▆▅▅▄▃▂▁
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone █▄▃▃▃▂▂▂▁▁
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone █▄▃▃▃▂▂▂▁▁
wandb:                                   Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb: Test loss t(5,20)_r(5,20)_combiR_pNone_gNone 3e-05
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 2e-05
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 3e-05
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 3e-05
wandb:                                   Train loss 3e-05
wandb: 
wandb: 🚀 View run fragrant-water-113 at: https://wandb.ai/nreints/ThesisFinal/runs/arx328fy
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230616_182447-arx328fy/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230616_183438-6ftcqsgr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lemon-eon-116
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal/runs/6ftcqsgr
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch ▁▂▃▃▄▅▆▆▇█
wandb: Test loss t(5,20)_r(5,20)_combiR_pNone_gNone █▃▂▂▂▁▁▁▁▁
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone █▆▆▅▄▃▃▂▂▁
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone █▃▂▂▁▁▁▁▁▁
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone █▂▂▂▁▁▁▁▁▁
wandb:                                   Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb: Test loss t(5,20)_r(5,20)_combiR_pNone_gNone 2e-05
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 1e-05
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 3e-05
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 3e-05
wandb:                                   Train loss 2e-05
wandb: 
wandb: 🚀 View run lemon-eon-116 at: https://wandb.ai/nreints/ThesisFinal/runs/6ftcqsgr
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230616_183438-6ftcqsgr/logs
	 Logging test loss: 3.69163e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 4.38652e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.42098e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.56131e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 53.31010127067566
Epoch 9/9
	 Logging train Loss: 3.18109e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 2.55662e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 3.18294e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.09836e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.63215e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 53.28722834587097
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combiR_pNone_gNone/'rot_mat_1'_'None'.pth
It took  590.7343821525574  seconds.
----- ITERATION 10/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  800
Number of test simulations:  200
The dataloader for data/data_t(5,20)_r(5,20)_combiR_pNone_gNone took 19.625273942947388 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_combiR_pNone_gNone took 4.908205032348633 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 4.948580265045166 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 4.961106300354004 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 4.959648132324219 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.1126657501 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 0.0006171975 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 0.0007851878 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0009475017 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0001024533 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 52.705546379089355
Epoch 1/9
	 Logging train Loss: 0.0003283519 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 0.0001632945 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 0.0001991499 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0002181126 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 7.48289e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 53.017147064208984
Epoch 2/9
	 Logging train Loss: 0.0001262281 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 0.0001093386 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 0.000126454 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0001333965 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 7.05734e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 52.969440937042236
Epoch 3/9
	 Logging train Loss: 9.43786e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 8.60278e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 0.0001012087 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0001028813 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 5.86467e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 52.824899673461914
Epoch 4/9
	 Logging train Loss: 7.61497e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 6.96391e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 8.34314e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 7.82061e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.92463e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 52.68224573135376
Epoch 5/9
	 Logging train Loss: 6.19644e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 5.67676e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 6.7112e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 6.44447e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.02292e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 52.572059631347656
Epoch 6/9
	 Logging train Loss: 5.01721e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 5.10402e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 6.16049e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 5.7481e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.78242e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 52.811975955963135
Epoch 7/9
	 Logging train Loss: 3.98731e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 4.03945e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 5.02734e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.75404e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.3307e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 52.438233613967896
Epoch 8/9
	 Logging train Loss: 3.10592e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 3.10139e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 3.80053e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.51275e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.72621e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 55.96424317359924
Epoch 9/9
	 Logging train Loss: 2.40264e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 2.49068e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 3.17266e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.0112e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.04186e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 53.390098333358765
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combiR_pNone_gNone/'rot_mat_1'_'None'.pth
It took  587.0348210334778  seconds.

JOB STATISTICS
==============
Job ID: 2929786
Array Job ID: 2928286_32
Cluster: snellius
User/Group: nreints/nreints
State: RUNNING
Nodes: 1
Cores per node: 18
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 1-05:13:12 core-walltime
Job Wall-clock time: 01:37:24
Memory Utilized: 0.00 MB (estimated maximum)
Memory Efficiency: 0.00% of 0.00 MB (0.00 MB/node)
WARNING: Efficiency statistics may be misleading for RUNNING jobs.
