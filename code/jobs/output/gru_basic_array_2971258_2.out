wandb: Currently logged in as: nreints. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_164026-hr89gn5g
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run northern-monkey-6
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal1/runs/hr89gn5g
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone █▆▃▂▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone █▆▃▂▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone █▆▃▂▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone █▅▃▂▁▁▁▁▁▁
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone █▅▃▂▁▁▁▁▁▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone 0.0
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: 🚀 View run northern-monkey-6 at: https://wandb.ai/nreints/ThesisFinal1/runs/hr89gn5g
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_164026-hr89gn5g/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_165630-l9upxhao
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run gallant-wave-64
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal1/runs/l9upxhao
Training on dataset: data_t(5,20)_r(0,0)_combi_pNone_gNone
Testing on 5 datasets: ['data_t(5,20)_r(0,0)_semi_pNone_gNone', 'data_t(5,20)_r(0,0)_none_pNone_gNone', 'data_t(5,20)_r(0,0)_tennis_pNone_gNone', 'data_t(5,20)_r(0,0)_combi_pNone_gNone', 'data_t(5,20)_r(0,0)_full_pNone_gNone']
Focussing on identity: False
Using extra input: False
Using fr-fr as reference point.
----- ITERATION 1/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 65.81715750694275 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(0,0)_semi_pNone_gNone took 16.61781406402588 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_none_pNone_gNone took 16.677770614624023 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_tennis_pNone_gNone took 16.5476131439209 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 16.56797480583191 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_full_pNone_gNone took 16.827120065689087 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0036763186 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 7.87696e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 6.13639e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 8.0627e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 6.99028e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 6.41871e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
		--> Epoch time; 79.19902443885803
Epoch 1/9
	 Logging train Loss: 5.95881e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 5.03194e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 4.23519e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 5.16642e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 4.62857e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 4.45123e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
		--> Epoch time; 79.22908639907837
Epoch 2/9
	 Logging train Loss: 3.57518e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.5e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.22998e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 2.57424e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 2.34441e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.34326e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
		--> Epoch time; 80.01264643669128
Epoch 3/9
	 Logging train Loss: 1.56182e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 8.1703e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 7.5136e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 8.5854e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 7.8362e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 7.8562e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
		--> Epoch time; 80.81827139854431
Epoch 4/9
	 Logging train Loss: 4.7172e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.979e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.707e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 3.1246e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 2.8789e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.8005e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
		--> Epoch time; 79.39787459373474
Epoch 5/9
	 Logging train Loss: 2.713e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.4437e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.2641e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 2.5616e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 2.3906e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.3462e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
		--> Epoch time; 79.388512134552
Epoch 6/9
	 Logging train Loss: 3.4154e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.1352e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.965e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 2.2248e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 2.0802e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.0322e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
		--> Epoch time; 79.20692086219788
Epoch 7/9
	 Logging train Loss: 1.11184e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.7133e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.6435e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.7861e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.7089e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.7016e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
		--> Epoch time; 80.73355984687805
Epoch 8/9
	 Logging train Loss: 6.7771e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.0742e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.4258e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 2.1212e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.7782e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.4675e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
		--> Epoch time; 81.06474447250366
Epoch 9/9
	 Logging train Loss: 4.83e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.0306e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 9.909e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.0734e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.0374e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.0213e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
		--> Epoch time; 81.44204759597778
Saved model in  trained_models/gru/data_t(5,20)_r(0,0)_combi_pNone_gNone/'rot_mat_1'_'False'.pth
It took  965.2968556880951  seconds.
----- ITERATION 2/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 64.56145000457764 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(0,0)_semi_pNone_gNone took 16.360695123672485 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_none_pNone_gNone took 16.34288716316223 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_tennis_pNone_gNone took 16.360612154006958 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 16.129600763320923 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_full_pNone_gNone took 16.328871726989746 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0018114607 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 5.80063e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 5.4428e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 5.96633e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 5.72705e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 5.35996e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
		--> Epoch time; 81.64613962173462
Epoch 1/9
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone █▄▂▁▁▃▁▂▁▁
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone █▄▂▁▁▁▁▂▁▁
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone █▄▂▁▁▁▁▂▁▁
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone █▄▂▁▁▄▁▂▁▂
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone █▄▂▁▁▄▁▂▁▂
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone 1e-05
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone 1e-05
wandb:                                  Train loss 0.0
wandb: 
wandb: 🚀 View run gallant-wave-64 at: https://wandb.ai/nreints/ThesisFinal1/runs/l9upxhao
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_165630-l9upxhao/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_171252-jf3cdhjj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stilted-dragon-125
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal1/runs/jf3cdhjj
	 Logging train Loss: 3.97132e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.52978e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.35852e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 2.53226e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 2.47565e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.34686e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
		--> Epoch time; 81.75671601295471
Epoch 2/9
	 Logging train Loss: 1.41288e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 6.5129e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 5.8369e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 6.4367e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 6.2536e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 5.813e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
		--> Epoch time; 83.25551629066467
Epoch 3/9
	 Logging train Loss: 3.7349e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.7277e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.5049e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 2.8026e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 2.7148e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.4628e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
		--> Epoch time; 83.18902778625488
Epoch 4/9
	 Logging train Loss: 6.1117e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.1667e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.1031e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 2.2365e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 2.2288e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.0644e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
		--> Epoch time; 82.7808895111084
Epoch 5/9
	 Logging train Loss: 1.03039e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.51065e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 4.2195e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 2.56106e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.40306e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 4.1945e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
		--> Epoch time; 83.35355162620544
Epoch 6/9
	 Logging train Loss: 3.5386e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.265e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.2295e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.3056e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.3189e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.21e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
		--> Epoch time; 83.69879817962646
Epoch 7/9
	 Logging train Loss: 7.109e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 4.8438e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 4.796e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 4.8802e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 5.0026e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 4.7854e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
		--> Epoch time; 83.49855375289917
Epoch 8/9
	 Logging train Loss: 3.7044e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 5.628e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 5.255e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 5.837e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 5.978e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 5.244e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
		--> Epoch time; 81.24884581565857
Epoch 9/9
	 Logging train Loss: 3.8069e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 7.402e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 7.413e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 7.3374e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 3.8451e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 7.414e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
		--> Epoch time; 79.91411423683167
Saved model in  trained_models/gru/data_t(5,20)_r(0,0)_combi_pNone_gNone/'rot_mat_1'_'False'.pth
It took  982.0505561828613  seconds.
----- ITERATION 3/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 63.67433309555054 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(0,0)_semi_pNone_gNone took 16.201081037521362 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_none_pNone_gNone took 16.222278118133545 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_tennis_pNone_gNone took 16.241361618041992 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 16.01859736442566 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_full_pNone_gNone took 16.248703241348267 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0132281324 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 7.36642e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 6.05373e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 7.58807e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 6.72944e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 6.09471e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
		--> Epoch time; 81.84928107261658
Epoch 1/9
	 Logging train Loss: 5.7785e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 4.88093e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 4.43778e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 5.08699e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 4.67315e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 4.41694e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
		--> Epoch time; 81.66424798965454
Epoch 2/9
	 Logging train Loss: 3.93049e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.09703e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 3.00892e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 3.26432e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 3.02966e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.96043e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
		--> Epoch time; 85.26721405982971
Epoch 3/9
	 Logging train Loss: 2.3097e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.48243e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.48013e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.5919e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.46338e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.43663e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
		--> Epoch time; 82.11626720428467
Epoch 4/9
	 Logging train Loss: 9.5841e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.54565e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 4.5786e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.62705e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.04355e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone █▆▄▂▂▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone █▆▄▃▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone █▆▄▃▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone █▆▄▂▂▁▁▁▁▁
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone █▆▄▂▂▁▁▁▁▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone 0.0
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone 0.0
wandb:                                  Train loss 1e-05
wandb: 
wandb: 🚀 View run stilted-dragon-125 at: https://wandb.ai/nreints/ThesisFinal1/runs/jf3cdhjj
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_171252-jf3cdhjj/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_172913-slcx0f47
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run charmed-smoke-182
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal1/runs/slcx0f47
	 Logging test loss: 4.5233e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
		--> Epoch time; 82.31270170211792
Epoch 5/9
	 Logging train Loss: 6.5838e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.8203e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.5629e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 2.9164e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 2.7337e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.5692e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
		--> Epoch time; 81.96159172058105
Epoch 6/9
	 Logging train Loss: 9.0836e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.3524e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.2505e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 2.4374e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 2.3319e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.2533e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
		--> Epoch time; 81.816579580307
Epoch 7/9
	 Logging train Loss: 1.23252e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.0025e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.9662e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 2.0743e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 2.0092e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.9665e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
		--> Epoch time; 81.88801169395447
Epoch 8/9
	 Logging train Loss: 5.316e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.642e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.6129e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.7063e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.6555e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.6106e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
		--> Epoch time; 82.12709879875183
Epoch 9/9
	 Logging train Loss: 6.7575e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.3268e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.2921e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.3847e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.3338e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.2879e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
		--> Epoch time; 82.07567858695984
Saved model in  trained_models/gru/data_t(5,20)_r(0,0)_combi_pNone_gNone/'rot_mat_1'_'False'.pth
It took  981.1528036594391  seconds.
----- ITERATION 4/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 63.73721385002136 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(0,0)_semi_pNone_gNone took 16.262300491333008 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_none_pNone_gNone took 16.267582893371582 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_tennis_pNone_gNone took 16.237481594085693 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 16.042333126068115 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_full_pNone_gNone took 16.36137890815735 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0149539551 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 6.0082e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 6.03166e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 6.34959e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 6.0055e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 5.94252e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
		--> Epoch time; 80.01998376846313
Epoch 1/9
	 Logging train Loss: 4.95961e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.63316e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 3.67239e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 3.84097e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 3.63512e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.62729e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
		--> Epoch time; 82.24914145469666
Epoch 2/9
	 Logging train Loss: 2.60853e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.57951e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.56232e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.64376e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.57649e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.58583e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
		--> Epoch time; 80.75614356994629
Epoch 3/9
	 Logging train Loss: 9.6582e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 5.1284e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 4.9253e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 5.3803e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 5.0586e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 4.8165e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
		--> Epoch time; 80.07649326324463
Epoch 4/9
	 Logging train Loss: 4.0437e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.7317e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.6128e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 2.8764e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 2.7141e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.5724e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
		--> Epoch time; 80.06424117088318
Epoch 5/9
	 Logging train Loss: 8.2775e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.2076e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.1867e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 2.3327e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 2.2408e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.1559e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
		--> Epoch time; 80.44320273399353
Epoch 6/9
	 Logging train Loss: 5.4559e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.7732e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.8161e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.8834e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.8328e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.7786e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
		--> Epoch time; 80.37078905105591
Epoch 7/9
	 Logging train Loss: 5.4126e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.0233e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.7185e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 2.1213e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.926e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.697e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
		--> Epoch time; 80.09332752227783
Epoch 8/9
	 Logging train Loss: 6.4197e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.8362e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.4185e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone █▅▃▁▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone █▅▃▁▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone █▅▃▁▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone █▅▃▁▁▁▁▁▁▂
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone █▅▃▁▁▁▁▁▁▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone 1e-05
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone 1e-05
wandb:                                  Train loss 1e-05
wandb: 
wandb: 🚀 View run charmed-smoke-182 at: https://wandb.ai/nreints/ThesisFinal1/runs/slcx0f47
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_172913-slcx0f47/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_174525-6icl4pmm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run soft-glade-240
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal1/runs/6icl4pmm
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone █▆▄▃▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone █▇▅▃▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone █▇▅▃▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone █▆▄▃▁▁▁▁▁▁
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone █▆▄▃▁▁▁▁▁▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone 0.0
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: 🚀 View run soft-glade-240 at: https://wandb.ai/nreints/ThesisFinal1/runs/6icl4pmm
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_174525-6icl4pmm/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_180152-39ilm4hv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stoic-salad-294
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal1/runs/39ilm4hv
	 Logging test loss: 2.9147e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 2.7e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.3765e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
		--> Epoch time; 79.75229334831238
Epoch 9/9
	 Logging train Loss: 5.6477e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 6.4707e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.0753e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 6.1474e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 4.0259e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.063e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
		--> Epoch time; 80.15638756752014
Saved model in  trained_models/gru/data_t(5,20)_r(0,0)_combi_pNone_gNone/'rot_mat_1'_'False'.pth
It took  972.0367612838745  seconds.
----- ITERATION 5/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 63.43388843536377 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(0,0)_semi_pNone_gNone took 16.121363878250122 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_none_pNone_gNone took 16.12716555595398 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_tennis_pNone_gNone took 16.13132381439209 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 15.984247207641602 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_full_pNone_gNone took 16.25653648376465 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0243947618 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 7.13303e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 6.49115e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 7.67415e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 7.08261e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 6.46599e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
		--> Epoch time; 81.7179012298584
Epoch 1/9
	 Logging train Loss: 6.15026e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 5.21859e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 5.1462e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 5.61903e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 5.34989e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 5.12418e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
		--> Epoch time; 84.96012735366821
Epoch 2/9
	 Logging train Loss: 4.40889e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.41522e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 3.35344e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 3.71271e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 3.47615e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.29608e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
		--> Epoch time; 82.03266525268555
Epoch 3/9
	 Logging train Loss: 2.50199e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.60163e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.5254e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.73456e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.61392e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.52622e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
		--> Epoch time; 82.00644850730896
Epoch 4/9
	 Logging train Loss: 9.53e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 4.6359e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 4.3185e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 4.9937e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 4.7181e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 4.3607e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
		--> Epoch time; 82.4888117313385
Epoch 5/9
	 Logging train Loss: 4.1364e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.4602e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.3377e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 2.6035e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 2.5099e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.3446e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
		--> Epoch time; 83.41068267822266
Epoch 6/9
	 Logging train Loss: 3.764e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.8997e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.8345e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 2.0021e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.9677e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.8506e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
		--> Epoch time; 83.68176221847534
Epoch 7/9
	 Logging train Loss: 4.7295e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.4736e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.4187e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.5444e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.5306e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.435e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
		--> Epoch time; 83.6863796710968
Epoch 8/9
	 Logging train Loss: 5.1347e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.0628e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.0189e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.1109e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.1165e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.035e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
		--> Epoch time; 83.44286370277405
Epoch 9/9
	 Logging train Loss: 4.038e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 8.499e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 8.141e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 8.779e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 8.94e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 8.284e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
		--> Epoch time; 83.33275389671326
Saved model in  trained_models/gru/data_t(5,20)_r(0,0)_combi_pNone_gNone/'rot_mat_1'_'False'.pth
It took  986.8377630710602  seconds.
----- ITERATION 6/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 63.650110483169556 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(0,0)_semi_pNone_gNone took 16.164649486541748 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_none_pNone_gNone took 16.179282903671265 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_tennis_pNone_gNone took 16.1518816947937 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 16.044126749038696 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_full_pNone_gNone took 16.229726552963257 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat_1
-- Started Training --
Epoch 0/9
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone █▆▄▂▁▁▂▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone █▆▄▂▁▁▂▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone █▆▄▂▁▁▂▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone █▆▄▂▁▁▂▁▁▁
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone █▆▄▂▁▁▂▁▁▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone 0.0
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone 0.0
wandb:                                  Train loss 1e-05
wandb: 
wandb: 🚀 View run stoic-salad-294 at: https://wandb.ai/nreints/ThesisFinal1/runs/39ilm4hv
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_180152-39ilm4hv/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_181810-0x8lc9jz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run comic-monkey-333
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal1/runs/0x8lc9jz
	 Logging train Loss: 0.069684945 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 8.36857e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 6.6265e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 8.72695e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 8.15922e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 6.80207e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
		--> Epoch time; 84.1534013748169
Epoch 1/9
	 Logging train Loss: 6.83181e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 5.62393e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 5.18324e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 5.87162e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 5.67881e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 5.3353e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
		--> Epoch time; 81.9718565940857
Epoch 2/9
	 Logging train Loss: 4.70845e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.60348e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 3.30261e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 3.80093e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 3.65661e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.43653e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
		--> Epoch time; 81.65842962265015
Epoch 3/9
	 Logging train Loss: 2.51551e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.47725e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.39071e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.5695e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.4868e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.41229e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
		--> Epoch time; 81.61700415611267
Epoch 4/9
	 Logging train Loss: 9.6443e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 5.0922e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 4.3742e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 5.4214e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 5.0983e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 4.4592e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
		--> Epoch time; 81.76339888572693
Epoch 5/9
	 Logging train Loss: 5.0183e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.4262e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 3.0202e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 3.5949e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 3.4515e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.0883e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
		--> Epoch time; 81.98319578170776
Epoch 6/9
	 Logging train Loss: 4.8603e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.25717e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 6.9423e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.33971e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.06045e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 6.9901e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
		--> Epoch time; 81.7865834236145
Epoch 7/9
	 Logging train Loss: 5.9866e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.7684e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 3.631e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 3.8399e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 3.805e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.6673e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
		--> Epoch time; 81.47480201721191
Epoch 8/9
	 Logging train Loss: 6.0769e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.1262e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.7656e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 2.2299e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 2.0855e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.8016e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
		--> Epoch time; 81.62278008460999
Epoch 9/9
	 Logging train Loss: 7.3199e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.206e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.1645e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.2591e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.2723e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.1892e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
		--> Epoch time; 81.92925786972046
Saved model in  trained_models/gru/data_t(5,20)_r(0,0)_combi_pNone_gNone/'rot_mat_1'_'False'.pth
It took  978.0702421665192  seconds.
----- ITERATION 7/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 63.47150182723999 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(0,0)_semi_pNone_gNone took 16.0855655670166 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_none_pNone_gNone took 16.119316816329956 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_tennis_pNone_gNone took 16.130255460739136 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 16.042426347732544 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_full_pNone_gNone took 16.126944065093994 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0192463305 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 8.35108e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 6.86665e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 8.55756e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 7.76794e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 6.8513e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
		--> Epoch time; 82.45165252685547
Epoch 1/9
	 Logging train Loss: 6.46319e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 5.54753e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 5.05308e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 5.74035e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 5.46117e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 5.06087e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
		--> Epoch time; 81.22240710258484
Epoch 2/9
	 Logging train Loss: 4.30749e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.35383e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 3.05277e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 3.46942e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 3.30328e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.08604e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
		--> Epoch time; 80.94032192230225
Epoch 3/9
	 Logging train Loss: 2.38226e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.63589e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.44086e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.70535e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone █▆▄▂▁▁▁▄▁▁
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone █▆▄▂▁▁▁▂▁▁
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone █▆▄▂▁▁▁▂▁▁
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone █▆▄▂▁▁▁▆▂▁
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone █▆▄▂▁▁▁▅▁▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone 0.0
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone 0.0
wandb:                                  Train loss 1e-05
wandb: 
wandb: 🚀 View run comic-monkey-333 at: https://wandb.ai/nreints/ThesisFinal1/runs/0x8lc9jz
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_181810-0x8lc9jz/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_183419-n3lzqd4j
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run celestial-salad-351
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal1/runs/n3lzqd4j
	 Logging test loss: 1.5963e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.4767e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
		--> Epoch time; 80.89173007011414
Epoch 4/9
	 Logging train Loss: 1.04178e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 6.4712e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 5.5738e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 6.7531e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 6.2884e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 5.6865e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
		--> Epoch time; 80.8874580860138
Epoch 5/9
	 Logging train Loss: 4.387e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.2991e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.9439e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 3.4078e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 3.2397e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.94e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
		--> Epoch time; 81.1114399433136
Epoch 6/9
	 Logging train Loss: 4.1622e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.7208e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.5291e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 2.8258e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 2.7192e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.5165e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
		--> Epoch time; 81.20897626876831
Epoch 7/9
	 Logging train Loss: 6.2317e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 5.51771e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 6.4162e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 5.45957e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 3.2325e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 6.4326e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
		--> Epoch time; 81.14531230926514
Epoch 8/9
	 Logging train Loss: 6.8539e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 7.5182e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 3.6755e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 7.5097e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 5.7643e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.6582e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
		--> Epoch time; 81.58120703697205
Epoch 9/9
	 Logging train Loss: 8.046e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.6153e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.556e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.689e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.661e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.5433e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
		--> Epoch time; 81.3884630203247
Saved model in  trained_models/gru/data_t(5,20)_r(0,0)_combi_pNone_gNone/'rot_mat_1'_'False'.pth
It took  969.0035004615784  seconds.
----- ITERATION 8/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 63.71985483169556 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(0,0)_semi_pNone_gNone took 16.264339685440063 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_none_pNone_gNone took 16.183425664901733 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_tennis_pNone_gNone took 16.193655014038086 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 16.135728359222412 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_full_pNone_gNone took 16.26728343963623 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0133424858 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 6.38622e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 5.88491e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 6.49869e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 6.2124e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 5.90712e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
		--> Epoch time; 81.83371615409851
Epoch 1/9
	 Logging train Loss: 5.08499e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.91906e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 3.65682e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 3.98887e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 3.82601e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.65537e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
		--> Epoch time; 82.18920969963074
Epoch 2/9
	 Logging train Loss: 2.66484e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.55979e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.41796e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.59491e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.52835e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.42783e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
		--> Epoch time; 81.70965027809143
Epoch 3/9
	 Logging train Loss: 8.0288e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.6547e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 3.0663e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 3.7062e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 3.4635e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.0742e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
		--> Epoch time; 81.53623294830322
Epoch 4/9
	 Logging train Loss: 3.0177e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.4594e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.203e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 2.4733e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 2.3766e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.2036e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
		--> Epoch time; 81.74464011192322
Epoch 5/9
	 Logging train Loss: 3.7152e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.9854e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.8482e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.9976e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.9518e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.8463e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
		--> Epoch time; 82.19076085090637
Epoch 6/9
	 Logging train Loss: 5.541e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 4.4463e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 3.9047e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 4.4663e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 4.2824e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.8993e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
		--> Epoch time; 81.5051908493042
Epoch 7/9
	 Logging train Loss: 7.1595e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.404e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone █▅▃▁▁▁▁▁▂▁
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone █▅▃▁▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone █▅▃▁▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone █▅▃▁▁▁▁▁▃▁
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone █▅▃▁▁▁▁▁▃▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone 0.0
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone 0.0
wandb:                                  Train loss 1e-05
wandb: 
wandb: 🚀 View run celestial-salad-351 at: https://wandb.ai/nreints/ThesisFinal1/runs/n3lzqd4j
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_183419-n3lzqd4j/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_185035-o2h8s67y
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run electric-valley-359
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal1/runs/o2h8s67y
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone █▆▃▂▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone █▆▄▂▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone █▆▄▂▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone █▅▃▂▁▁▁▁▁▁
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone █▅▃▂▁▁▁▁▁▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone 0.0
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone 0.0
wandb:                                  Train loss 1e-05
wandb: 
wandb: 🚀 View run electric-valley-359 at: https://wandb.ai/nreints/ThesisFinal1/runs/o2h8s67y
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_185035-o2h8s67y/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_190647-lnizlp8j
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run floral-mountain-365
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal1/runs/lnizlp8j
	 Logging test loss: 1.2693e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.4096e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.3727e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.2681e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
		--> Epoch time; 81.39558100700378
Epoch 8/9
	 Logging train Loss: 5.8316e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.9409e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.174e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.94641e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.20289e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.1899e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
		--> Epoch time; 81.81381678581238
Epoch 9/9
	 Logging train Loss: 5.348e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.0164e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 6.629e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.0165e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 8.942e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 6.647e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
		--> Epoch time; 81.37409448623657
Saved model in  trained_models/gru/data_t(5,20)_r(0,0)_combi_pNone_gNone/'rot_mat_1'_'False'.pth
It took  976.0755345821381  seconds.
----- ITERATION 9/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 63.68279695510864 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(0,0)_semi_pNone_gNone took 16.149595022201538 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_none_pNone_gNone took 16.14445209503174 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_tennis_pNone_gNone took 16.094600200653076 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 15.969544172286987 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_full_pNone_gNone took 16.10567021369934 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0091037089 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 6.71424e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 6.01997e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 7.44091e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 6.64328e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 6.28576e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
		--> Epoch time; 81.34921598434448
Epoch 1/9
	 Logging train Loss: 5.39124e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 4.34078e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 4.11148e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 4.83619e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 4.4082e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 4.29041e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
		--> Epoch time; 81.6360502243042
Epoch 2/9
	 Logging train Loss: 3.33224e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.36845e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.33039e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 2.66463e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 2.44394e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.38801e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
		--> Epoch time; 81.36229658126831
Epoch 3/9
	 Logging train Loss: 1.6714e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.0614e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.05859e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.21583e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.1055e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.08827e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
		--> Epoch time; 81.35947823524475
Epoch 4/9
	 Logging train Loss: 7.1269e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 4.1861e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 4.0752e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 4.6879e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 4.3471e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 4.2127e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
		--> Epoch time; 81.59653639793396
Epoch 5/9
	 Logging train Loss: 3.132e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.6381e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.5324e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 2.8542e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 2.7298e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.6287e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
		--> Epoch time; 81.69250512123108
Epoch 6/9
	 Logging train Loss: 2.3867e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.1043e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.0176e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 2.2977e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 2.1905e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.1078e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
		--> Epoch time; 81.47521424293518
Epoch 7/9
	 Logging train Loss: 5.8358e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.764e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.7108e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.9281e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.8505e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.7874e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
		--> Epoch time; 81.5641541481018
Epoch 8/9
	 Logging train Loss: 9.6183e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.5022e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.4099e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.6451e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.5527e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.4738e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
		--> Epoch time; 81.41294860839844
Epoch 9/9
	 Logging train Loss: 8.6869e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.4226e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.1472e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.5423e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.3659e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.197e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
		--> Epoch time; 81.76009154319763
Saved model in  trained_models/gru/data_t(5,20)_r(0,0)_combi_pNone_gNone/'rot_mat_1'_'False'.pth
It took  971.8844690322876  seconds.
----- ITERATION 10/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 63.629672050476074 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(0,0)_semi_pNone_gNone took 16.226075172424316 seconds.
slurmstepd: error: *** STEP 2971260.0 ON gcn50 CANCELLED AT 2023-06-26T19:10:19 DUE TO TIME LIMIT ***
slurmstepd: error: *** JOB 2971260 ON gcn50 CANCELLED AT 2023-06-26T19:10:19 DUE TO TIME LIMIT ***

JOB STATISTICS
==============
Job ID: 2971260
Array Job ID: 2971258_2
Cluster: snellius
User/Group: nreints/nreints
State: TIMEOUT (exit code 0)
Nodes: 1
Cores per node: 18
CPU Utilized: 00:00:01
CPU Efficiency: 0.00% of 1-21:02:06 core-walltime
Job Wall-clock time: 02:30:07
Memory Utilized: 7.07 MB
Memory Efficiency: 0.00% of 0.00 MB
