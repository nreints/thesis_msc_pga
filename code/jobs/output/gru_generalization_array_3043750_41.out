wandb: Currently logged in as: nreints. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230710_170033-6ci6hgd0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fresh-firefly-1246
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/6ci6hgd0
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                     Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb: Test loss tennis_pNone_gNone_tennisEffect â–ˆâ–ƒâ–ƒâ–‚â–‚â–‚â–â–â–â–
wandb:                                Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                     Epoch 9
wandb: Test loss tennis_pNone_gNone_tennisEffect 2e-05
wandb:                                Train loss 2e-05
wandb: 
wandb: ðŸš€ View run fresh-firefly-1246 at: https://wandb.ai/nreints/ThesisFinal2/runs/6ci6hgd0
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230710_170033-6ci6hgd0/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230710_170455-kn2b7rlc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run winter-mountain-1257
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/kn2b7rlc
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                     Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb: Test loss tennis_pNone_gNone_tennisEffect â–ˆâ–„â–‚â–‚â–‚â–â–â–â–â–
wandb:                                Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                     Epoch 9
wandb: Test loss tennis_pNone_gNone_tennisEffect 2e-05
wandb:                                Train loss 2e-05
wandb: 
wandb: ðŸš€ View run winter-mountain-1257 at: https://wandb.ai/nreints/ThesisFinal2/runs/kn2b7rlc
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230710_170455-kn2b7rlc/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230710_170910-4wxitubk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run expert-terrain-1268
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/4wxitubk
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                     Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb: Test loss tennis_pNone_gNone_tennisEffect â–ˆâ–ƒâ–‚â–‚â–‚â–â–â–â–â–
wandb:                                Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                     Epoch 9
wandb: Test loss tennis_pNone_gNone_tennisEffect 2e-05
wandb:                                Train loss 2e-05
wandb: 
wandb: ðŸš€ View run expert-terrain-1268 at: https://wandb.ai/nreints/ThesisFinal2/runs/4wxitubk
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230710_170910-4wxitubk/logs
Training on dataset: data_tennis_pNone_gNone_tennisEffect
Testing on 1 datasets: ['data_tennis_pNone_gNone_tennisEffect']
Focussing on identity: False
Using extra input: False
Using fr-fr as reference point.
----- ITERATION 1/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 52.618788719177246 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 13.141896486282349 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(24, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=24, bias=True)
)
Datatype: pos_diff_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0006068535 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 3.89633e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 18.54641366004944
Epoch 1/9
	 Logging train Loss: 3.1313e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.73855e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 17.913018226623535
Epoch 2/9
	 Logging train Loss: 2.6306e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.63035e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 17.559885025024414
Epoch 3/9
	 Logging train Loss: 2.48905e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.42858e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 17.884840965270996
Epoch 4/9
	 Logging train Loss: 2.40408e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.40311e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 17.7424099445343
Epoch 5/9
	 Logging train Loss: 2.33481e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.31086e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 17.692623615264893
Epoch 6/9
	 Logging train Loss: 2.27323e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.25291e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 17.892117500305176
Epoch 7/9
	 Logging train Loss: 2.23048e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.25858e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 17.740013360977173
Epoch 8/9
	 Logging train Loss: 2.20288e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.20168e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 18.0054988861084
Epoch 9/9
	 Logging train Loss: 2.17837e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.16986e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 17.98477292060852
Saved model in  trained_models/gru/data_tennis_pNone_gNone_tennisEffect/'pos_diff_1'_'False'.pth
It took  263.0645022392273  seconds.
----- ITERATION 2/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 50.736812353134155 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 12.857773065567017 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(24, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=24, bias=True)
)
Datatype: pos_diff_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0006317443 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 4.09772e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 17.984235525131226
Epoch 1/9
	 Logging train Loss: 3.26047e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 3.01727e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 17.77923059463501
Epoch 2/9
	 Logging train Loss: 2.67084e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.54161e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 17.889479637145996
Epoch 3/9
	 Logging train Loss: 2.49616e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.42532e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 17.832542181015015
Epoch 4/9
	 Logging train Loss: 2.39968e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.36778e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 18.021477222442627
Epoch 5/9
	 Logging train Loss: 2.32925e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.28504e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 17.933675050735474
Epoch 6/9
	 Logging train Loss: 2.26925e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.31255e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 17.825729846954346
Epoch 7/9
	 Logging train Loss: 2.23395e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.21797e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 17.90696883201599
Epoch 8/9
	 Logging train Loss: 2.20717e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.18839e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 17.836175441741943
Epoch 9/9
	 Logging train Loss: 2.18568e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.18059e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 18.043864727020264
Saved model in  trained_models/gru/data_tennis_pNone_gNone_tennisEffect/'pos_diff_1'_'False'.pth
It took  254.9881784915924  seconds.
----- ITERATION 3/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 49.139859199523926 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 12.280730247497559 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(24, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=24, bias=True)
)
Datatype: pos_diff_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0006536974 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 4.44632e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 17.68521761894226
Epoch 1/9
	 Logging train Loss: 3.18341e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.97967e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 17.8054780960083
Epoch 2/9
	 Logging train Loss: 2.58695e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.67421e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 17.859273195266724
Epoch 3/9
	 Logging train Loss: 2.43508e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.59824e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 17.643754959106445
Epoch 4/9
	 Logging train Loss: 2.34906e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.5005e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 17.92372441291809
Epoch 5/9
	 Logging train Loss: 2.2795e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.44253e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 17.78182363510132
Epoch 6/9
	 Logging train Loss: 2.22582e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.37359e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 17.843222618103027
Epoch 7/9
	 Logging train Loss: 2.19028e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.37485e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 17.663784742355347
Epoch 8/9
	 Logging train Loss: 2.16371e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.36434e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 17.605396270751953
Epoch 9/9
	 Logging train Loss: 2.14471e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.30659e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 17.68348503112793
Saved model in  trained_models/gru/data_tennis_pNone_gNone_tennisEffect/'pos_diff_1'_'False'.pth
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230710_171322-gq7o4h3u
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run restful-microwave-1280
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/gq7o4h3u
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                     Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb: Test loss tennis_pNone_gNone_tennisEffect â–ˆâ–„â–‚â–‚â–‚â–‚â–â–â–â–
wandb:                                Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                     Epoch 9
wandb: Test loss tennis_pNone_gNone_tennisEffect 2e-05
wandb:                                Train loss 2e-05
wandb: 
wandb: ðŸš€ View run restful-microwave-1280 at: https://wandb.ai/nreints/ThesisFinal2/runs/gq7o4h3u
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230710_171322-gq7o4h3u/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230710_171733-8gr7io4q
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run smart-breeze-1291
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/8gr7io4q
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                     Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb: Test loss tennis_pNone_gNone_tennisEffect â–ˆâ–ƒâ–‚â–‚â–‚â–â–â–â–â–
wandb:                                Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                     Epoch 9
wandb: Test loss tennis_pNone_gNone_tennisEffect 2e-05
wandb:                                Train loss 2e-05
wandb: 
wandb: ðŸš€ View run smart-breeze-1291 at: https://wandb.ai/nreints/ThesisFinal2/runs/8gr7io4q
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230710_171733-8gr7io4q/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230710_172145-wggzqeke
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run crimson-star-1302
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/wggzqeke
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                     Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb: Test loss tennis_pNone_gNone_tennisEffect â–ˆâ–ƒâ–‚â–‚â–â–‚â–â–â–â–
wandb:                                Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                     Epoch 9
wandb: Test loss tennis_pNone_gNone_tennisEffect 2e-05
wandb:                                Train loss 2e-05
wandb: 
wandb: ðŸš€ View run crimson-star-1302 at: https://wandb.ai/nreints/ThesisFinal2/runs/wggzqeke
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230710_172145-wggzqeke/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230710_172558-yigkzwyo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run astral-wildflower-1313
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/yigkzwyo
It took  251.9491240978241  seconds.
----- ITERATION 4/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 49.34766149520874 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 12.276076078414917 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(24, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=24, bias=True)
)
Datatype: pos_diff_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0006531122 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 4.08728e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 18.083554983139038
Epoch 1/9
	 Logging train Loss: 3.18075e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.92518e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 17.960068941116333
Epoch 2/9
	 Logging train Loss: 2.6246e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.60774e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 17.94043803215027
Epoch 3/9
	 Logging train Loss: 2.46748e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.47192e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 17.68129849433899
Epoch 4/9
	 Logging train Loss: 2.37651e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.43034e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 17.89021062850952
Epoch 5/9
	 Logging train Loss: 2.30308e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.39265e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 17.640501737594604
Epoch 6/9
	 Logging train Loss: 2.25084e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.31787e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 17.704874992370605
Epoch 7/9
	 Logging train Loss: 2.2129e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.30418e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 17.84958577156067
Epoch 8/9
	 Logging train Loss: 2.19037e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.26701e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 17.918684720993042
Epoch 9/9
	 Logging train Loss: 2.16718e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.25204e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 17.953789949417114
Saved model in  trained_models/gru/data_tennis_pNone_gNone_tennisEffect/'pos_diff_1'_'False'.pth
It took  251.37613344192505  seconds.
----- ITERATION 5/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 48.712604999542236 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 12.20502781867981 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(24, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=24, bias=True)
)
Datatype: pos_diff_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0006604812 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 4.43337e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 17.623926639556885
Epoch 1/9
	 Logging train Loss: 3.35976e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.79712e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 18.019761085510254
Epoch 2/9
	 Logging train Loss: 2.71814e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.59215e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 17.912416219711304
Epoch 3/9
	 Logging train Loss: 2.53721e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.4152e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 17.811367750167847
Epoch 4/9
	 Logging train Loss: 2.43744e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.33725e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 18.03277587890625
Epoch 5/9
	 Logging train Loss: 2.35774e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.3062e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 17.847853183746338
Epoch 6/9
	 Logging train Loss: 2.29679e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.2799e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 18.067875385284424
Epoch 7/9
	 Logging train Loss: 2.25297e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.18197e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 17.837241888046265
Epoch 8/9
	 Logging train Loss: 2.22468e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.17291e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 18.067426681518555
Epoch 9/9
	 Logging train Loss: 2.19913e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.14415e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 17.95731019973755
Saved model in  trained_models/gru/data_tennis_pNone_gNone_tennisEffect/'pos_diff_1'_'False'.pth
It took  251.51337456703186  seconds.
----- ITERATION 6/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 48.863046407699585 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 12.239454507827759 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(24, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=24, bias=True)
)
Datatype: pos_diff_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0006448923 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 4.57706e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 17.82038927078247
Epoch 1/9
	 Logging train Loss: 3.39674e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.98629e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 17.877358436584473
Epoch 2/9
	 Logging train Loss: 2.68051e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.59131e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 17.863034963607788
Epoch 3/9
	 Logging train Loss: 2.49012e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.53196e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 17.69415545463562
Epoch 4/9
	 Logging train Loss: 2.39699e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.38309e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 17.768385410308838
Epoch 5/9
	 Logging train Loss: 2.3212e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.42225e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 17.973371744155884
Epoch 6/9
	 Logging train Loss: 2.26621e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.32823e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 17.72329306602478
Epoch 7/9
	 Logging train Loss: 2.2268e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.2705e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 17.966709852218628
Epoch 8/9
	 Logging train Loss: 2.19818e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.24785e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 17.662185430526733
Epoch 9/9
	 Logging train Loss: 2.17637e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.23296e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 18.054451942443848
Saved model in  trained_models/gru/data_tennis_pNone_gNone_tennisEffect/'pos_diff_1'_'False'.pth
It took  253.52675795555115  seconds.
----- ITERATION 7/10 ------
Number of train simulations:  1920
Number of test simulations:  480
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                     Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb: Test loss tennis_pNone_gNone_tennisEffect â–ˆâ–ƒâ–‚â–‚â–‚â–â–â–â–â–
wandb:                                Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                     Epoch 9
wandb: Test loss tennis_pNone_gNone_tennisEffect 2e-05
wandb:                                Train loss 2e-05
wandb: 
wandb: ðŸš€ View run astral-wildflower-1313 at: https://wandb.ai/nreints/ThesisFinal2/runs/yigkzwyo
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230710_172558-yigkzwyo/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230710_173009-hlynqqrs
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run warm-thunder-1324
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/hlynqqrs
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                     Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb: Test loss tennis_pNone_gNone_tennisEffect â–ˆâ–„â–‚â–‚â–‚â–â–â–â–â–
wandb:                                Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                     Epoch 9
wandb: Test loss tennis_pNone_gNone_tennisEffect 2e-05
wandb:                                Train loss 2e-05
wandb: 
wandb: ðŸš€ View run warm-thunder-1324 at: https://wandb.ai/nreints/ThesisFinal2/runs/hlynqqrs
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230710_173009-hlynqqrs/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230710_173426-tygt0nyg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run solar-surf-1334
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/tygt0nyg
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                     Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb: Test loss tennis_pNone_gNone_tennisEffect â–ˆâ–ƒâ–ƒâ–‚â–‚â–‚â–â–â–â–
wandb:                                Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                     Epoch 9
wandb: Test loss tennis_pNone_gNone_tennisEffect 2e-05
wandb:                                Train loss 2e-05
wandb: 
wandb: ðŸš€ View run solar-surf-1334 at: https://wandb.ai/nreints/ThesisFinal2/runs/tygt0nyg
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230710_173426-tygt0nyg/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230710_173844-6rspzj0r
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run youthful-yogurt-1346
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/6rspzj0r
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 48.936100482940674 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 12.233235597610474 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(24, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=24, bias=True)
)
Datatype: pos_diff_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0005773276 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 4.0638e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 17.69427180290222
Epoch 1/9
	 Logging train Loss: 3.11915e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.80386e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 17.82841658592224
Epoch 2/9
	 Logging train Loss: 2.61644e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.56189e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 17.966136932373047
Epoch 3/9
	 Logging train Loss: 2.47702e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.45255e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 17.878838777542114
Epoch 4/9
	 Logging train Loss: 2.38969e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.42162e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 17.85409164428711
Epoch 5/9
	 Logging train Loss: 2.31834e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.31021e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 17.91148018836975
Epoch 6/9
	 Logging train Loss: 2.26405e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.28464e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 17.688733100891113
Epoch 7/9
	 Logging train Loss: 2.22572e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.25815e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 18.053409576416016
Epoch 8/9
	 Logging train Loss: 2.20199e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.23656e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 18.00258159637451
Epoch 9/9
	 Logging train Loss: 2.17897e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.18959e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 17.851003885269165
Saved model in  trained_models/gru/data_tennis_pNone_gNone_tennisEffect/'pos_diff_1'_'False'.pth
It took  251.10636162757874  seconds.
----- ITERATION 8/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 49.753716468811035 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 12.63625717163086 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(24, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=24, bias=True)
)
Datatype: pos_diff_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0006714216 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 3.94832e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 17.99785280227661
Epoch 1/9
	 Logging train Loss: 3.26629e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.75143e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 17.814037799835205
Epoch 2/9
	 Logging train Loss: 2.67736e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.36646e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 18.02202558517456
Epoch 3/9
	 Logging train Loss: 2.51757e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.26158e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 17.675087451934814
Epoch 4/9
	 Logging train Loss: 2.42574e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.2397e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 17.95249915122986
Epoch 5/9
	 Logging train Loss: 2.35261e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.12105e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 17.832716941833496
Epoch 6/9
	 Logging train Loss: 2.29808e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.18342e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 17.93052077293396
Epoch 7/9
	 Logging train Loss: 2.25722e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.08898e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 17.78001093864441
Epoch 8/9
	 Logging train Loss: 2.23181e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.06912e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 17.9484441280365
Epoch 9/9
	 Logging train Loss: 2.2102e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.06431e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 18.17078971862793
Saved model in  trained_models/gru/data_tennis_pNone_gNone_tennisEffect/'pos_diff_1'_'False'.pth
It took  257.0354106426239  seconds.
----- ITERATION 9/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 48.997026205062866 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 12.265422105789185 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(24, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=24, bias=True)
)
Datatype: pos_diff_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.000584485 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 4.17813e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 17.847163915634155
Epoch 1/9
	 Logging train Loss: 3.01489e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.98432e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 18.00666117668152
Epoch 2/9
	 Logging train Loss: 2.56489e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.88127e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 17.781671047210693
Epoch 3/9
	 Logging train Loss: 2.42713e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.63767e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 17.929767847061157
Epoch 4/9
	 Logging train Loss: 2.34268e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.58034e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 18.085012674331665
Epoch 5/9
	 Logging train Loss: 2.27332e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.49863e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 18.235922813415527
Epoch 6/9
	 Logging train Loss: 2.22038e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.44948e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 18.407081604003906
Epoch 7/9
	 Logging train Loss: 2.18262e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.39773e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 17.77196192741394
Epoch 8/9
	 Logging train Loss: 2.15411e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.41437e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 17.858110189437866
Epoch 9/9
	 Logging train Loss: 2.13312e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.3505e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 17.652963399887085
Saved model in  trained_models/gru/data_tennis_pNone_gNone_tennisEffect/'pos_diff_1'_'False'.pth
It took  257.52452325820923  seconds.
----- ITERATION 10/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 49.07117819786072 seconds.
-- Finished Train Dataloader --
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                     Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb: Test loss tennis_pNone_gNone_tennisEffect â–ˆâ–ƒâ–‚â–‚â–‚â–‚â–â–â–â–
wandb:                                Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                     Epoch 9
wandb: Test loss tennis_pNone_gNone_tennisEffect 2e-05
wandb:                                Train loss 2e-05
wandb: 
wandb: ðŸš€ View run youthful-yogurt-1346 at: https://wandb.ai/nreints/ThesisFinal2/runs/6rspzj0r
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230710_173844-6rspzj0r/logs
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 12.167178392410278 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(24, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=24, bias=True)
)
Datatype: pos_diff_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0006366422 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 4.18609e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 17.87672448158264
Epoch 1/9
	 Logging train Loss: 3.19142e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.89896e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 17.911184072494507
Epoch 2/9
	 Logging train Loss: 2.64504e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.60157e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 17.78950333595276
Epoch 3/9
	 Logging train Loss: 2.49206e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.56796e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 18.00811505317688
Epoch 4/9
	 Logging train Loss: 2.4065e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.43791e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 17.950966358184814
Epoch 5/9
	 Logging train Loss: 2.33226e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.39326e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 17.677056074142456
Epoch 6/9
	 Logging train Loss: 2.27283e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.30776e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 17.863115310668945
Epoch 7/9
	 Logging train Loss: 2.22945e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.28044e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 17.64321541786194
Epoch 8/9
	 Logging train Loss: 2.20301e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.25314e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 18.0049307346344
Epoch 9/9
	 Logging train Loss: 2.18089e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.23758e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 17.618503093719482
Saved model in  trained_models/gru/data_tennis_pNone_gNone_tennisEffect/'pos_diff_1'_'False'.pth
It took  250.36482095718384  seconds.

JOB STATISTICS
==============
Job ID: 3043752
Array Job ID: 3043750_41
Cluster: snellius
User/Group: nreints/nreints
State: RUNNING
Nodes: 1
Cores per node: 18
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 12:47:24 core-walltime
Job Wall-clock time: 00:42:38
Memory Utilized: 0.00 MB (estimated maximum)
Memory Efficiency: 0.00% of 0.00 MB (0.00 MB/node)
WARNING: Efficiency statistics may be misleading for RUNNING jobs.
