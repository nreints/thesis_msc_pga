wandb: Currently logged in as: nreints. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_164542-6ms0kdti
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run grateful-wave-20
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal1/runs/6ms0kdti
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone â–ˆâ–‚â–â–‚â–‚â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone â–ˆâ–‚â–‚â–‚â–‚â–â–â–â–â–
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone â–ˆâ–ƒâ–‚â–‚â–ƒâ–â–â–â–â–
wandb:                                   Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 1e-05
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 1e-05
wandb:                                   Train loss 0.0
wandb: 
wandb: ðŸš€ View run grateful-wave-20 at: https://wandb.ai/nreints/ThesisFinal1/runs/6ms0kdti
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_164542-6ms0kdti/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_165540-rurtpl0n
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stellar-pyramid-59
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal1/runs/rurtpl0n
Training on dataset: data_t(5,20)_r(5,20)_combi_pNone_gNone
Testing on 5 datasets: ['data_t(5,20)_r(5,20)_semi_pNone_gNone', 'data_t(5,20)_r(5,20)_none_pNone_gNone', 'data_t(5,20)_r(5,20)_tennis_pNone_gNone', 'data_t(5,20)_r(5,20)_full_pNone_gNone', 'data_t(5,20)_r(5,20)_combi_pNone_gNone']
Focussing on identity: False
Using extra input: True
Using fr-fr as reference point.
----- ITERATION 1/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 59.385558128356934 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 14.940945863723755 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_none_pNone_gNone took 15.018600463867188 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 15.048080205917358 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 15.287466049194336 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 14.947260856628418 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(6, 96, batch_first=True)
  (pre_hidden_lin_layer): Sequential(
    (0): Linear(in_features=3, out_features=96, bias=True)
    (1): ReLU()
    (2): Linear(in_features=96, out_features=96, bias=True)
    (3): ReLU()
  )
  (fc): Linear(in_features=96, out_features=6, bias=True)
)
Datatype: log_dualQ_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0007021782 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.85516e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.59062e-05 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 8.16831e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.49421e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 5.37226e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 46.16142559051514
Epoch 1/9
	 Logging train Loss: 3.09503e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.93441e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.5655e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.46759e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.4202e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.1925e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 44.27694630622864
Epoch 2/9
	 Logging train Loss: 1.18087e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.18795e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.3633e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.3563e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.2647e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 6.5896e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 43.857720375061035
Epoch 3/9
	 Logging train Loss: 9.4792e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.34982e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.2275e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.87987e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.1582e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 8.6843e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 43.903013944625854
Epoch 4/9
	 Logging train Loss: 7.5027e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.59348e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.5284e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.2987e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.4796e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.03279e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 45.58508586883545
Epoch 5/9
	 Logging train Loss: 6.7442e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.3572e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 6.221e-07 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 7.1199e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 5.616e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.6729e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 45.185683727264404
Epoch 6/9
	 Logging train Loss: 5.7553e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.8367e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 8.498e-07 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 9.2186e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 8.109e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.7076e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 44.11786913871765
Epoch 7/9
	 Logging train Loss: 4.9277e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.2488e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.564e-07 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 7.4917e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.144e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.7117e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 44.609336137771606
Epoch 8/9
	 Logging train Loss: 4.5812e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.7017e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 6.374e-07 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 8.9254e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 5.986e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.5362e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 44.61638045310974
Epoch 9/9
	 Logging train Loss: 3.8433e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.5811e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 7.042e-07 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 5.7517e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 6.664e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.0921e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 44.13776755332947
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gNone/'log_dualQ_1'_'True'.pth
It took  598.8602955341339  seconds.
----- ITERATION 2/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 54.365350008010864 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 13.845950365066528 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_none_pNone_gNone took 13.87142276763916 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 13.867605209350586 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 13.833577632904053 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 13.698966979980469 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(6, 96, batch_first=True)
  (pre_hidden_lin_layer): Sequential(
    (0): Linear(in_features=3, out_features=96, bias=True)
    (1): ReLU()
    (2): Linear(in_features=96, out_features=96, bias=True)
    (3): ReLU()
  )
  (fc): Linear(in_features=96, out_features=6, bias=True)
)
Datatype: log_dualQ_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0006822649 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone â–ˆâ–‚â–â–‚â–â–â–â–â–‚â–
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone â–ˆâ–‚â–â–‚â–â–â–â–â–‚â–
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone â–ˆâ–‚â–â–ƒâ–â–â–â–â–‚â–
wandb:                                   Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 1e-05
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 1e-05
wandb:                                   Train loss 0.0
wandb: 
wandb: ðŸš€ View run stellar-pyramid-59 at: https://wandb.ai/nreints/ThesisFinal1/runs/rurtpl0n
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_165540-rurtpl0n/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_170519-1wrux208
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rosy-planet-97
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal1/runs/1wrux208
	 Logging test loss: 0.0001020248 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.75325e-05 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0001282807 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.80839e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 7.29335e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 43.388535022735596
Epoch 1/9
	 Logging train Loss: 3.16361e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.32831e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.59e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.96329e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.5342e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.52946e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 43.64693284034729
Epoch 2/9
	 Logging train Loss: 1.07771e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.12982e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.0784e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.18674e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.0535e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 7.1552e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 44.67068576812744
Epoch 3/9
	 Logging train Loss: 8.5748e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.39869e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.0606e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.85098e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.0754e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.8065e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 44.481255531311035
Epoch 4/9
	 Logging train Loss: 7.5453e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.0568e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.0227e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 8.1541e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.0144e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.7677e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 44.49690890312195
Epoch 5/9
	 Logging train Loss: 6.4949e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.006e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 8.835e-07 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 8.0482e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 8.825e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.7341e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 43.85424256324768
Epoch 6/9
	 Logging train Loss: 5.631e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.4368e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 6.388e-07 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 8.3591e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 6.242e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.5268e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 44.46358346939087
Epoch 7/9
	 Logging train Loss: 5.0301e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.1634e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 6.491e-07 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 7.4405e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 6.296e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.1638e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 44.16437554359436
Epoch 8/9
	 Logging train Loss: 4.4614e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.52045e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.3041e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.76395e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.2973e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 9.6684e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 44.701093673706055
Epoch 9/9
	 Logging train Loss: 3.7601e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.815e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 7.473e-07 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 8.1256e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 7.268e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.6761e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 44.30992937088013
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gNone/'log_dualQ_1'_'True'.pth
It took  579.4425778388977  seconds.
----- ITERATION 3/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 53.925637006759644 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 13.802664279937744 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_none_pNone_gNone took 13.87294602394104 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 13.804996013641357 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 13.751827478408813 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 13.659905910491943 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(6, 96, batch_first=True)
  (pre_hidden_lin_layer): Sequential(
    (0): Linear(in_features=3, out_features=96, bias=True)
    (1): ReLU()
    (2): Linear(in_features=96, out_features=96, bias=True)
    (3): ReLU()
  )
  (fc): Linear(in_features=96, out_features=6, bias=True)
)
Datatype: log_dualQ_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0009880683 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0001325356 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.94885e-05 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0001130374 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.0416e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 8.40074e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 45.468470335006714
Epoch 1/9
	 Logging train Loss: 4.59889e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.23213e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 8.0474e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.28347e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 7.9576e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.11775e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 44.53392219543457
Epoch 2/9
	 Logging train Loss: 1.53656e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.40133e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.4267e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.75153e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.4216e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 9.4752e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 44.76566743850708
Epoch 3/9
	 Logging train Loss: 9.7244e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.00145e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–
wandb:                                   Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 1e-05
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 1e-05
wandb:                                   Train loss 0.0
wandb: 
wandb: ðŸš€ View run rosy-planet-97 at: https://wandb.ai/nreints/ThesisFinal1/runs/1wrux208
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_170519-1wrux208/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_171500-vyfec9rc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glad-water-131
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal1/runs/vyfec9rc
	 Logging test loss: 1.6831e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.20702e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.6812e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 6.443e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 44.798665046691895
Epoch 4/9
	 Logging train Loss: 8.1007e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 9.6562e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.3098e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.17274e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.2984e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 6.1326e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 44.429683208465576
Epoch 5/9
	 Logging train Loss: 6.9717e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.9339e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 8.719e-07 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 8.346e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 8.53e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.323e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 44.90038180351257
Epoch 6/9
	 Logging train Loss: 6.1378e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.9263e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 7.101e-07 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 7.5163e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 6.89e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.022e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 44.043708086013794
Epoch 7/9
	 Logging train Loss: 5.1599e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.2439e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 5.068e-07 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 7.3019e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.855e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.6844e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 44.20018744468689
Epoch 8/9
	 Logging train Loss: 4.5754e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.4154e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.671e-07 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 6.6115e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.429e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.4227e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 43.86082434654236
Epoch 9/9
	 Logging train Loss: 4.0727e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.1679e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 5.201e-07 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 7.0435e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.979e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.5692e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 44.59858298301697
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gNone/'log_dualQ_1'_'True'.pth
It took  580.6304762363434  seconds.
----- ITERATION 4/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 53.787768602371216 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 14.315216541290283 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_none_pNone_gNone took 13.950793981552124 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 13.91625452041626 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 13.849610328674316 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 13.645357847213745 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(6, 96, batch_first=True)
  (pre_hidden_lin_layer): Sequential(
    (0): Linear(in_features=3, out_features=96, bias=True)
    (1): ReLU()
    (2): Linear(in_features=96, out_features=96, bias=True)
    (3): ReLU()
  )
  (fc): Linear(in_features=96, out_features=6, bias=True)
)
Datatype: log_dualQ_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0007739846 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0001162959 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.18517e-05 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 9.60115e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.18677e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 7.02723e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 45.29971504211426
Epoch 1/9
	 Logging train Loss: 4.02742e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.74795e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.6971e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0001218009 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.6043e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 5.05998e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 44.251928091049194
Epoch 2/9
	 Logging train Loss: 1.81599e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.38973e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.8525e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.18552e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.8163e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.08261e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 44.316022634506226
Epoch 3/9
	 Logging train Loss: 1.30937e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.2205e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.437e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.58717e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.392e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 8.163e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 44.88132667541504
Epoch 4/9
	 Logging train Loss: 1.02983e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.13699e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.1349e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.74252e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.1147e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 8.3855e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 44.29642629623413
Epoch 5/9
	 Logging train Loss: 7.7368e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.4696e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 7.845e-07 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 8.2635e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 7.548e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.4614e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 44.545201539993286
Epoch 6/9
	 Logging train Loss: 7.2338e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.51208e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 9.534e-07 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone â–ˆâ–†â–‚â–â–‚â–â–‚â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone â–ˆâ–„â–â–â–â–â–‚â–â–â–
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone â–†â–ˆâ–‚â–‚â–‚â–â–‚â–â–â–
wandb:                                   Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 1e-05
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 1e-05
wandb:                                   Train loss 0.0
wandb: 
wandb: ðŸš€ View run glad-water-131 at: https://wandb.ai/nreints/ThesisFinal1/runs/vyfec9rc
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_171500-vyfec9rc/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_172445-pioov7ul
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glorious-donkey-165
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal1/runs/pioov7ul
	 Logging test loss: 2.34573e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 9.221e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.0572e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 45.02949595451355
Epoch 7/9
	 Logging train Loss: 6.0613e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.0228e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.377e-07 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 6.5696e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.075e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.4911e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 45.474597215652466
Epoch 8/9
	 Logging train Loss: 5.6087e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.01619e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 5.975e-07 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.35116e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 5.726e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 6.4178e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 44.81163740158081
Epoch 9/9
	 Logging train Loss: 4.4082e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.2414e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 6.762e-07 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 6.2936e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 6.483e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.5793e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 44.145220041275024
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gNone/'log_dualQ_1'_'True'.pth
It took  584.6712689399719  seconds.
----- ITERATION 5/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 54.639726877212524 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 13.914175748825073 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_none_pNone_gNone took 13.873060941696167 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 13.763189315795898 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 13.730752229690552 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 13.671778917312622 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(6, 96, batch_first=True)
  (pre_hidden_lin_layer): Sequential(
    (0): Linear(in_features=3, out_features=96, bias=True)
    (1): ReLU()
    (2): Linear(in_features=96, out_features=96, bias=True)
    (3): ReLU()
  )
  (fc): Linear(in_features=96, out_features=6, bias=True)
)
Datatype: log_dualQ_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0008206917 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 9.36881e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.50089e-05 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 9.1049e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.52996e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 6.31752e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 45.66085147857666
Epoch 1/9
	 Logging train Loss: 3.22399e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.95722e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 6.1878e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.75768e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 6.0071e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.71954e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 45.07589888572693
Epoch 2/9
	 Logging train Loss: 1.11553e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.21897e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.3487e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 8.05688e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.2703e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.73824e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 46.56265139579773
Epoch 3/9
	 Logging train Loss: 9.3322e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 9.5774e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.3883e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.41917e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.3446e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 6.4301e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 44.11351418495178
Epoch 4/9
	 Logging train Loss: 7.7773e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.3793e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.0081e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 8.0641e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 9.736e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.2273e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 44.24933481216431
Epoch 5/9
	 Logging train Loss: 6.7678e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.32456e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 9.55e-07 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.88657e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 9.074e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 8.2618e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 46.0991747379303
Epoch 6/9
	 Logging train Loss: 6.0169e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.4546e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 5.673e-07 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 7.883e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 5.241e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.7307e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 44.981693267822266
Epoch 7/9
	 Logging train Loss: 4.9823e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.9251e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 8.985e-07 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.00451e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 8.491e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 5.0924e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 45.53646993637085
Epoch 8/9
	 Logging train Loss: 4.6858e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.724e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.951e-07 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 5.3484e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.606e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.6143e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 44.42543339729309
Epoch 9/9
	 Logging train Loss: 3.9829e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.913e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 6.31e-07 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 7.848e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone â–ˆâ–ƒâ–„â–â–â–‚â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone â–ˆâ–‚â–ƒâ–â–â–‚â–â–â–â–
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone â–ˆâ–„â–‡â–‚â–â–‚â–â–â–â–
wandb:                                   Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 1e-05
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 1e-05
wandb:                                   Train loss 0.0
wandb: 
wandb: ðŸš€ View run glorious-donkey-165 at: https://wandb.ai/nreints/ThesisFinal1/runs/pioov7ul
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_172445-pioov7ul/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_173433-zyvgsz8c
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run worldly-flower-197
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal1/runs/zyvgsz8c
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone â–ˆâ–‚â–â–‚â–‚â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone â–ˆâ–â–â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone â–ˆâ–â–â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone â–ˆâ–‚â–‚â–‚â–‚â–â–â–â–‚â–
wandb:                                   Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 1e-05
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 1e-05
wandb:                                   Train loss 0.0
wandb: 
wandb: ðŸš€ View run worldly-flower-197 at: https://wandb.ai/nreints/ThesisFinal1/runs/zyvgsz8c
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_173433-zyvgsz8c/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_174416-e5haf3cf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run zesty-violet-235
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal1/runs/e5haf3cf
	 Logging test loss: 5.977e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.9129e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 44.72085881233215
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gNone/'log_dualQ_1'_'True'.pth
It took  587.8974566459656  seconds.
----- ITERATION 6/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 54.57245230674744 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 13.825084447860718 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_none_pNone_gNone took 13.882371664047241 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 13.828904628753662 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 14.369138717651367 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 13.89869236946106 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(6, 96, batch_first=True)
  (pre_hidden_lin_layer): Sequential(
    (0): Linear(in_features=3, out_features=96, bias=True)
    (1): ReLU()
    (2): Linear(in_features=96, out_features=96, bias=True)
    (3): ReLU()
  )
  (fc): Linear(in_features=96, out_features=6, bias=True)
)
Datatype: log_dualQ_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0011107777 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0001312924 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.91588e-05 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0001117811 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.08156e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 8.09807e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 44.26110577583313
Epoch 1/9
	 Logging train Loss: 3.86594e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.19021e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.9136e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.3019e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.9477e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.24598e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 44.90684723854065
Epoch 2/9
	 Logging train Loss: 1.08468e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.25843e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.3985e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.10377e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.4103e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 8.9022e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 45.148866176605225
Epoch 3/9
	 Logging train Loss: 8.5859e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.26412e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.0253e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.80705e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.0047e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.02107e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 44.00376486778259
Epoch 4/9
	 Logging train Loss: 8.6833e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.3036e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.0826e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.09715e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.0513e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 9.3986e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 44.217079639434814
Epoch 5/9
	 Logging train Loss: 7.3116e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.3302e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 5.576e-07 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 8.5411e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 5.227e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.5885e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 44.84855008125305
Epoch 6/9
	 Logging train Loss: 6.1348e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.3597e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 5.225e-07 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 8.3704e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 5.001e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.5601e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 44.69304537773132
Epoch 7/9
	 Logging train Loss: 5.8437e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.6582e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.248e-07 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.10125e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.906e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.8335e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 44.486796140670776
Epoch 8/9
	 Logging train Loss: 5.2933e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.12052e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 7.714e-07 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.48108e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 7.424e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 6.8007e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 44.673948764801025
Epoch 9/9
	 Logging train Loss: 4.3544e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.2355e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 5.497e-07 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 7.3251e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 5.238e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.6442e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 44.049116373062134
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gNone/'log_dualQ_1'_'True'.pth
It took  583.7379839420319  seconds.
----- ITERATION 7/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 53.85775852203369 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 13.79641342163086 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_none_pNone_gNone took 13.7745361328125 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 13.843136548995972 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 13.72705864906311 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 13.595331192016602 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(6, 96, batch_first=True)
  (pre_hidden_lin_layer): Sequential(
    (0): Linear(in_features=3, out_features=96, bias=True)
    (1): ReLU()
    (2): Linear(in_features=96, out_features=96, bias=True)
    (3): ReLU()
  )
  (fc): Linear(in_features=96, out_features=6, bias=True)
)
Datatype: log_dualQ_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0010627606 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone â–ˆâ–‚â–â–‚â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone â–ˆâ–‚â–â–‚â–â–â–â–â–â–
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone â–ˆâ–‚â–â–‚â–‚â–â–â–â–â–
wandb:                                   Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 1e-05
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 1e-05
wandb:                                   Train loss 0.0
wandb: 
wandb: ðŸš€ View run zesty-violet-235 at: https://wandb.ai/nreints/ThesisFinal1/runs/e5haf3cf
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_174416-e5haf3cf/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_175400-ygye52f7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run proud-cherry-268
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal1/runs/ygye52f7
	 Logging test loss: 0.0001330404 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.51148e-05 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0001104201 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.47606e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 8.11601e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 44.31851077079773
Epoch 1/9
	 Logging train Loss: 3.72409e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.99137e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.8706e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.76014e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.7795e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.74023e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 44.173808097839355
Epoch 2/9
	 Logging train Loss: 1.1649e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.27117e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.8512e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.29866e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.8005e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 7.6848e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 44.03967642784119
Epoch 3/9
	 Logging train Loss: 8.3917e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.52697e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.751e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.86209e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.7175e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 9.738e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 44.700074434280396
Epoch 4/9
	 Logging train Loss: 9.3214e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.05147e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.645e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.60141e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.587e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 7.7677e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 44.90160322189331
Epoch 5/9
	 Logging train Loss: 7.8625e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.6714e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 6.713e-07 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 8.1037e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 6.304e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.6026e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 45.60705852508545
Epoch 6/9
	 Logging train Loss: 6.5934e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.2365e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 5.058e-07 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 8.8069e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.703e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.5366e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 45.02982521057129
Epoch 7/9
	 Logging train Loss: 6.0239e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.1063e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.3825e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.13589e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.3477e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 7.0909e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 44.921128034591675
Epoch 8/9
	 Logging train Loss: 5.1568e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.2864e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.939e-07 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 7.8424e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.671e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.2956e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 44.74969553947449
Epoch 9/9
	 Logging train Loss: 4.6224e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.126e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 8.934e-07 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 6.6139e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 8.631e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.8293e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 44.31505513191223
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gNone/'log_dualQ_1'_'True'.pth
It took  583.8093099594116  seconds.
----- ITERATION 8/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 54.79081320762634 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 13.899112939834595 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_none_pNone_gNone took 13.82282304763794 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 13.770308017730713 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 13.777440309524536 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 13.699302911758423 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(6, 96, batch_first=True)
  (pre_hidden_lin_layer): Sequential(
    (0): Linear(in_features=3, out_features=96, bias=True)
    (1): ReLU()
    (2): Linear(in_features=96, out_features=96, bias=True)
    (3): ReLU()
  )
  (fc): Linear(in_features=96, out_features=6, bias=True)
)
Datatype: log_dualQ_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0006830778 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0001153379 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.03907e-05 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 9.93912e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.941e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 7.74381e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 43.89877200126648
Epoch 1/9
	 Logging train Loss: 3.5796e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.80154e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.1013e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.90756e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.9416e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.89577e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 44.89840817451477
Epoch 2/9
	 Logging train Loss: 1.34847e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.33683e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.6783e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.53731e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.5833e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 9.6493e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 44.47671103477478
Epoch 3/9
	 Logging train Loss: 9.2165e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.00427e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone â–ˆâ–‚â–‚â–â–‚â–â–â–‚â–â–
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone â–ˆâ–ƒâ–‚â–‚â–‚â–â–‚â–‚â–â–
wandb:                                   Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 1e-05
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 1e-05
wandb:                                   Train loss 0.0
wandb: 
wandb: ðŸš€ View run proud-cherry-268 at: https://wandb.ai/nreints/ThesisFinal1/runs/ygye52f7
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_175400-ygye52f7/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_180342-2bexyrgs
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run crisp-bush-301
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal1/runs/2bexyrgs
	 Logging test loss: 1.1039e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.66634e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.0259e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 8.8079e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 44.39666533470154
Epoch 4/9
	 Logging train Loss: 7.7535e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.29511e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.2975e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.09599e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.2449e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.09435e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 43.94606828689575
Epoch 5/9
	 Logging train Loss: 6.303e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.8086e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 6.434e-07 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 8.9121e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 5.812e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 5.3896e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 45.09329056739807
Epoch 6/9
	 Logging train Loss: 5.8475e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.14413e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 5.62e-07 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.33061e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 5.053e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 7.8849e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 45.04036831855774
Epoch 7/9
	 Logging train Loss: 4.952e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.30183e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.079e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.70178e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.0323e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 9.6834e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 44.70658540725708
Epoch 8/9
	 Logging train Loss: 4.4231e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.6368e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.551e-07 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 5.7188e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.229e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.6269e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 44.03383731842041
Epoch 9/9
	 Logging train Loss: 3.9979e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.4398e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 8.663e-07 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 6.6963e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 8.299e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.3797e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 44.28746485710144
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gNone/'log_dualQ_1'_'True'.pth
It took  581.6307890415192  seconds.
----- ITERATION 9/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 53.86374044418335 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 13.736168622970581 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_none_pNone_gNone took 13.726152181625366 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 13.772156953811646 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 13.787152767181396 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 13.63819408416748 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(6, 96, batch_first=True)
  (pre_hidden_lin_layer): Sequential(
    (0): Linear(in_features=3, out_features=96, bias=True)
    (1): ReLU()
    (2): Linear(in_features=96, out_features=96, bias=True)
    (3): ReLU()
  )
  (fc): Linear(in_features=96, out_features=6, bias=True)
)
Datatype: log_dualQ_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.001043465 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0001132377 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.35749e-05 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0001004139 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.29911e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 6.62761e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 44.27929878234863
Epoch 1/9
	 Logging train Loss: 3.33373e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.1379e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.7233e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.70991e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.5622e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.39516e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 44.853482484817505
Epoch 2/9
	 Logging train Loss: 1.06419e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.39064e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.7734e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.84231e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.6924e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.15611e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 44.63651657104492
Epoch 3/9
	 Logging train Loss: 8.5624e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.22464e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.3917e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.08621e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.3162e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 8.9219e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 43.99441480636597
Epoch 4/9
	 Logging train Loss: 8.1743e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.51904e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.6056e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.71556e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.527e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.15349e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 43.58474040031433
Epoch 5/9
	 Logging train Loss: 7.7408e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.47593e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.5357e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.86256e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.4757e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.67394e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 45.37320613861084
Epoch 6/9
	 Logging train Loss: 5.9738e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.9516e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 6.814e-07 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: ERROR Error while calling W&B API: An internal error occurred. Please contact support. (<Response [500]>)
wandb: 
wandb: Run history:
wandb:                                        Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone â–ˆâ–‚â–‚â–‚â–‚â–ƒâ–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone â–ˆâ–‚â–‚â–‚â–‚â–‚â–â–â–â–
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone â–ˆâ–ƒâ–ƒâ–‚â–ƒâ–ƒâ–‚â–â–â–
wandb:                                   Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 0.0
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 0.0
wandb:                                   Train loss 0.0
wandb: 
wandb: ðŸš€ View run crisp-bush-301 at: https://wandb.ai/nreints/ThesisFinal1/runs/2bexyrgs
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_180342-2bexyrgs/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_181324-l00n2x8v
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rare-music-324
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal1/runs/l00n2x8v
	 Logging test loss: 1.21637e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 6.313e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 5.4777e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 44.87729859352112
Epoch 7/9
	 Logging train Loss: 5.5242e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.1511e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 7.058e-07 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 6.9952e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 6.624e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.4308e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 44.81121253967285
Epoch 8/9
	 Logging train Loss: 4.6842e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.0405e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.308e-07 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 5.5772e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.015e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.6766e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 44.47560501098633
Epoch 9/9
	 Logging train Loss: 4.1258e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.1406e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.198e-07 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 4.7598e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.882e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.2203e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 44.39862036705017
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gNone/'log_dualQ_1'_'True'.pth
It took  582.5311532020569  seconds.
----- ITERATION 10/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 53.556633710861206 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 13.757458448410034 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_none_pNone_gNone took 13.746956586837769 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 13.73633337020874 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 14.01628065109253 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 13.608956098556519 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(6, 96, batch_first=True)
  (pre_hidden_lin_layer): Sequential(
    (0): Linear(in_features=3, out_features=96, bias=True)
    (1): ReLU()
    (2): Linear(in_features=96, out_features=96, bias=True)
    (3): ReLU()
  )
  (fc): Linear(in_features=96, out_features=6, bias=True)
)
Datatype: log_dualQ_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.001372562 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0001364493 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.73772e-05 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0001124196 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.78359e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 8.27612e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 43.81147384643555
Epoch 1/9
	 Logging train Loss: 5.04881e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.71449e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.1292e-05 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 4.56834e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.15813e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.63975e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 45.044673442840576
Epoch 2/9
	 Logging train Loss: 1.57534e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.45361e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.1728e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.66393e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.156e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 8.4573e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 44.799922466278076
Epoch 3/9
	 Logging train Loss: 1.02271e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 9.89e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.4794e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.04622e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.4625e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 5.6177e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 44.11888098716736
Epoch 4/9
	 Logging train Loss: 8.3917e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.61409e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.5033e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.7797e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.4601e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.15238e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 43.87933015823364
Epoch 5/9
	 Logging train Loss: 8.015e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.25851e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.4441e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.6095e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.432e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 7.5395e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 44.11827754974365
Epoch 6/9
	 Logging train Loss: 7.4712e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.65244e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.845e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 6.62922e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.833e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.79304e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 43.95723485946655
Epoch 7/9
	 Logging train Loss: 6.1446e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.649e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 8.719e-07 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 7.1274e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 8.53e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.738e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 43.16883730888367
Epoch 8/9
	 Logging train Loss: 5.2669e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.622e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 5.46e-07 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 7.5931e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 5.213e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.8801e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 43.796332359313965
Epoch 9/9
	 Logging train Loss: 4.6535e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.0067e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 5.103e-07 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 6.8147e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone â–ˆâ–ƒâ–â–â–‚â–â–ƒâ–â–â–
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone â–ˆâ–ƒâ–â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone â–ˆâ–ƒâ–â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone â–ˆâ–ƒâ–â–â–‚â–â–ƒâ–â–â–
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone â–ˆâ–„â–‚â–â–‚â–‚â–…â–â–â–
wandb:                                   Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 1e-05
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 1e-05
wandb:                                   Train loss 0.0
wandb: 
wandb: ðŸš€ View run rare-music-324 at: https://wandb.ai/nreints/ThesisFinal1/runs/l00n2x8v
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_181324-l00n2x8v/logs
	 Logging test loss: 4.859e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.2926e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 44.17091393470764
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gNone/'log_dualQ_1'_'True'.pth
It took  575.8488945960999  seconds.

JOB STATISTICS
==============
Job ID: 2971297
Array Job ID: 2971286_10
Cluster: snellius
User/Group: nreints/nreints
State: RUNNING
Nodes: 1
Cores per node: 18
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 1-05:16:12 core-walltime
Job Wall-clock time: 01:37:34
Memory Utilized: 0.00 MB (estimated maximum)
Memory Efficiency: 0.00% of 0.00 MB (0.00 MB/node)
WARNING: Efficiency statistics may be misleading for RUNNING jobs.
