wandb: Currently logged in as: nreints. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_125116-8wmip1ci
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cool-monkey-26
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/8wmip1ci
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue â–„â–‚â–â–ˆâ–â–â–â–‚â–â–
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue â–†â–‚â–‚â–ˆâ–â–‚â–â–ˆâ–â–
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue â–ƒâ–â–â–ˆâ–â–â–â–‚â–â–
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue â–„â–‚â–â–ˆâ–â–â–â–‚â–â–
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.0
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.0
wandb:                                 Train loss 0.0
wandb: 
wandb: ðŸš€ View run cool-monkey-26 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/8wmip1ci
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_125116-8wmip1ci/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_125825-1o9zfbfw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glad-voice-50
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/1o9zfbfw
Training on dataset: data_t(0,0)_r(0,0)_combi_pTrue_gTrue
Testing on 4 datasets: ['data_t(0,0)_r(0,0)_full_pTrue_gTrue', 'data_t(0,0)_r(0,0)_semi_pTrue_gTrue', 'data_t(0,0)_r(0,0)_tennis_pTrue_gTrue', 'data_t(0,0)_r(0,0)_combi_pTrue_gTrue']
Focussing on identity: True
Using extra input: False
Using fr-fr as reference point.
----- ITERATION 1/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 50.87453556060791 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 12.702897310256958 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 12.691867589950562 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 12.818347454071045 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 12.833809852600098 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0002788516 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.496e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 3.8378e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 6.077e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.4276e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 31.950032234191895
Epoch 1/9
	 Logging train Loss: 1.0722e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 7.16e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 8.481e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 1.2278e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 5.323e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 31.14195942878723
Epoch 2/9
	 Logging train Loss: 8.913e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 3.66e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 6.259e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 9.119e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 3.876e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 30.950193405151367
Epoch 3/9
	 Logging train Loss: 1.1283e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 3.553e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 1.1203e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 1.30142e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 6.6094e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 30.848193645477295
Epoch 4/9
	 Logging train Loss: 1.1275e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.72e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 2.524e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 3.853e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.596e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 30.794923305511475
Epoch 5/9
	 Logging train Loss: 1.5297e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 5.01e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 7.316e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 8.829e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 4.22e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 31.150712490081787
Epoch 6/9
	 Logging train Loss: 1.5265e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 9.2e-09 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 1.139e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 1.686e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 7.33e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 31.07311201095581
Epoch 7/9
	 Logging train Loss: 1.0448e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 3.352e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 1.1595e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 1.2994e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 7.998e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 31.183759927749634
Epoch 8/9
	 Logging train Loss: 9.225e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 7.3e-09 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 7.82e-08 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 1.086e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 5.02e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 31.02881145477295
Epoch 9/9
	 Logging train Loss: 6.565e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 7e-09 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 6.91e-08 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 9.14e-08 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 4.37e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 30.974538564682007
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pTrue_gTrue/'quat_1'_'False'.pth
It took  430.19633531570435  seconds.
----- ITERATION 2/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 49.86406755447388 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 12.670259475708008 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 12.686723470687866 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 12.682456016540527 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 12.487088680267334 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0001959585 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.669e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 4.6383e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 6.7751e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.5813e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 31.353292226791382
Epoch 1/9
	 Logging train Loss: 1.1461e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 9.66e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 1.4765e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 1.9782e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 8.065e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 31.36648440361023
Epoch 2/9
	 Logging train Loss: 1.2806e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 4.26e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 7.88e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 1.1567e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 4.307e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 31.506624698638916
Epoch 3/9
	 Logging train Loss: 1.7492e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 3.21e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 6.108e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 8.978e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 3.327e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 31.510940551757812
Epoch 4/9
	 Logging train Loss: 1.7918e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.38e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue â–ˆâ–ƒâ–‚â–‚â–‚â–‚â–â–â–â–‚
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–ƒ
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue â–ˆâ–ƒâ–‚â–‚â–‚â–‚â–â–â–â–‚
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue â–ˆâ–ƒâ–‚â–‚â–‚â–‚â–â–â–â–
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.0
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.0
wandb:                                 Train loss 0.0
wandb: 
wandb: ðŸš€ View run glad-voice-50 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/1o9zfbfw
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_125825-1o9zfbfw/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_130529-srcbl9sq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wise-grass-87
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/srcbl9sq
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue â–…â–„â–‚â–‚â–‚â–â–„â–â–â–ˆ
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue â–‚â–‚â–â–â–â–â–‚â–â–â–ˆ
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue â–„â–„â–‚â–â–‚â–â–„â–â–â–ˆ
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue â–†â–…â–‚â–‚â–‚â–â–„â–â–â–ˆ
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 1e-05
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 1e-05
wandb:                                 Train loss 0.0
wandb: 
wandb: ðŸš€ View run wise-grass-87 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/srcbl9sq
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_130529-srcbl9sq/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_131234-ynsg6fky
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run efficient-sun-118
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/ynsg6fky
	 Logging test loss: 4.481e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 6.53e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.428e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 31.10264801979065
Epoch 5/9
	 Logging train Loss: 1.2828e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.22e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 4.65e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 6.195e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.472e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 31.42761778831482
Epoch 6/9
	 Logging train Loss: 1.8535e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.22e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 1.82e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 2.495e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 9.65e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 31.029531717300415
Epoch 7/9
	 Logging train Loss: 9.423e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.87e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 3.072e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 3.7e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.648e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 31.21968936920166
Epoch 8/9
	 Logging train Loss: 8.967e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 7.7e-09 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 8.98e-08 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 1.094e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 4.75e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 30.83398962020874
Epoch 9/9
	 Logging train Loss: 7.522e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 7.54e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 4.322e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 4.899e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.573e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 31.187862396240234
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pTrue_gTrue/'quat_1'_'False'.pth
It took  424.1963725090027  seconds.
----- ITERATION 3/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 49.82877588272095 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 12.577819585800171 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 12.59474229812622 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 12.608150243759155 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 12.463486909866333 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.000179483 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.67e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 3.1193e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 5.4564e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.282e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 30.96702766418457
Epoch 1/9
	 Logging train Loss: 1.0821e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.129e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 3.4442e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 4.0578e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.95e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 31.320135354995728
Epoch 2/9
	 Logging train Loss: 9.819e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 3.23e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 6.271e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 1.1168e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 4.624e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 31.198923349380493
Epoch 3/9
	 Logging train Loss: 1.3788e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.75e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 5.008e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 8.975e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 3.733e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 31.361814737319946
Epoch 4/9
	 Logging train Loss: 1.7036e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 5.05e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 9.861e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 1.3292e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 6.089e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 31.09391689300537
Epoch 5/9
	 Logging train Loss: 1.2995e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.85e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 3.044e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 5.055e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.221e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 31.289071321487427
Epoch 6/9
	 Logging train Loss: 1.3124e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.437e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 3.2244e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 3.424e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.7105e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 31.235748291015625
Epoch 7/9
	 Logging train Loss: 1.055e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 1.619e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 2.242e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.103e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 31.27406907081604
Epoch 8/9
	 Logging train Loss: 8.965e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 6.9e-09 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 9.18e-08 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 1.266e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 6.58e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 31.28333067893982
Epoch 9/9
	 Logging train Loss: 5.879e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.0688e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 7.2252e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 7.4441e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 4.1544e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 31.571864128112793
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pTrue_gTrue/'quat_1'_'False'.pth
It took  424.90137457847595  seconds.
----- ITERATION 4/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 50.04995894432068 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 12.638912439346313 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 12.590402364730835 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 12.56907033920288 seconds.
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue â–ˆâ–ƒâ–‚â–‚â–‚â–â–â–‡â–â–„
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue â–‡â–ƒâ–‚â–‚â–â–â–â–ˆâ–â–ƒ
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue â–ˆâ–ƒâ–‚â–‚â–‚â–â–â–‡â–â–„
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue â–ˆâ–ƒâ–‚â–‚â–‚â–â–â–‡â–â–ƒ
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.0
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.0
wandb:                                 Train loss 0.0
wandb: 
wandb: ðŸš€ View run efficient-sun-118 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/ynsg6fky
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_131234-ynsg6fky/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_131939-by2jwdi7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sandy-snowflake-156
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/by2jwdi7
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 12.465622186660767 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.000154455 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.743e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 3.0894e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 3.645e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.7217e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 31.002946615219116
Epoch 1/9
	 Logging train Loss: 8.842e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 6.01e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 8.779e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 1.0105e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 4.913e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 30.863816499710083
Epoch 2/9
	 Logging train Loss: 9.22e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 3.31e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 6.371e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 7.441e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 3.515e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 31.224040746688843
Epoch 3/9
	 Logging train Loss: 1.5783e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 3.31e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 7.581e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 8.398e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 4.075e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 31.275415658950806
Epoch 4/9
	 Logging train Loss: 2.822e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.2e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 3.982e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 4.653e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.241e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 31.087904691696167
Epoch 5/9
	 Logging train Loss: 8.96e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.98e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 3.531e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 3.935e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.962e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 31.182205200195312
Epoch 6/9
	 Logging train Loss: 1.3498e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.28e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 1.907e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 2.161e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.115e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 31.410006999969482
Epoch 7/9
	 Logging train Loss: 1.0193e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.974e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 2.7027e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 2.9564e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.5144e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 31.34493398666382
Epoch 8/9
	 Logging train Loss: 7.22e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.13e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 1.581e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 1.628e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 8.75e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 31.076018571853638
Epoch 9/9
	 Logging train Loss: 6.419e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 6.14e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 1.2631e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 1.3267e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 6.747e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 31.450615406036377
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pTrue_gTrue/'quat_1'_'False'.pth
It took  425.06978726387024  seconds.
----- ITERATION 5/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 49.824504137039185 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 12.534261703491211 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 12.535067796707153 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 12.54532527923584 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 12.443079471588135 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0002474732 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.61e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 2.7371e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 4.7871e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.64e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 31.21271252632141
Epoch 1/9
	 Logging train Loss: 9.024e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 5.5e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 9.746e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 1.6864e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 5.704e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 31.226975202560425
Epoch 2/9
	 Logging train Loss: 6.006e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 3.34e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 7.664e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 1.323e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 4.414e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 31.29740810394287
Epoch 3/9
	 Logging train Loss: 1.583e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.74e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 5.98e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 1.0534e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 3.459e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 31.257851362228394
Epoch 4/9
	 Logging train Loss: 1.463e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 6.9e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 1.6903e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 2.1009e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 9.869e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 31.35991621017456
Epoch 5/9
	 Logging train Loss: 1.5492e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.13e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 4.156e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 6.731e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.434e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 31.360928535461426
Epoch 6/9
	 Logging train Loss: 1.5657e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.231e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue â–…â–‚â–‚â–‚â–ƒâ–â–ˆâ–â–ƒâ–
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue â–†â–‚â–‚â–‚â–ƒâ–â–ˆâ–â–…â–…
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue â–…â–‚â–‚â–‚â–„â–â–ˆâ–â–ƒâ–
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue â–ˆâ–ƒâ–ƒâ–‚â–„â–‚â–ˆâ–â–ƒâ–
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.0
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.0
wandb:                                 Train loss 0.0
wandb: 
wandb: ðŸš€ View run sandy-snowflake-156 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/by2jwdi7
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_131939-by2jwdi7/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_132644-81ne2dyr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rose-butterfly-192
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/81ne2dyr
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue â–„â–‚â–â–â–â–â–‚â–…â–â–ˆ
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue â–†â–ƒâ–‚â–â–â–â–‚â–„â–â–ˆ
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue â–…â–‚â–â–â–â–â–‚â–…â–â–ˆ
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue â–‡â–‚â–â–â–â–â–‚â–…â–â–ˆ
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue 1e-05
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 1e-05
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 1e-05
wandb:                                 Train loss 0.0
wandb: 
wandb: ðŸš€ View run rose-butterfly-192 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/81ne2dyr
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_132644-81ne2dyr/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_133350-hvp5c6de
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run breezy-surf-224
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/hvp5c6de
	 Logging test loss: 4.2924e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 4.7552e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.5892e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 31.300332069396973
Epoch 7/9
	 Logging train Loss: 8.433e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.06e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 1.855e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 2.822e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.105e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 31.27479887008667
Epoch 8/9
	 Logging train Loss: 1.5802e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.234e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 1.5607e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 1.7893e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 9.449e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 31.16666078567505
Epoch 9/9
	 Logging train Loss: 3.997e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.27e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 3.04e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 3.605e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.272e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 31.40051555633545
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pTrue_gTrue/'quat_1'_'False'.pth
It took  425.14319682121277  seconds.
----- ITERATION 6/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 50.01595759391785 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 12.585587978363037 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 12.552361249923706 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 12.529919385910034 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 12.502209424972534 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0010977668 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 6.053e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 8.0327e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 1.30167e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 3.2626e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 30.858994245529175
Epoch 1/9
	 Logging train Loss: 2.7117e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.162e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 1.5805e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 2.4536e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 7.829e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 31.534127712249756
Epoch 2/9
	 Logging train Loss: 8.613e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 9.32e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 8.868e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 1.3066e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 3.947e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 31.307554483413696
Epoch 3/9
	 Logging train Loss: 5.305e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 3.97e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 6.605e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 9.665e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.747e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 31.224485158920288
Epoch 4/9
	 Logging train Loss: 1.1501e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.31e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 4.336e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 6.509e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.792e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 30.94776940345764
Epoch 5/9
	 Logging train Loss: 1.4281e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.12e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 4.006e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 5.655e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.839e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 31.342394590377808
Epoch 6/9
	 Logging train Loss: 1.7843e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.397e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 1.2742e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 1.4985e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 6.916e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 31.121097087860107
Epoch 7/9
	 Logging train Loss: 2.9612e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 3.52e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 7.5497e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 8.4898e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 3.9464e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 31.256978750228882
Epoch 8/9
	 Logging train Loss: 6.619e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.7e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 3.307e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 4.089e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.703e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 31.68687677383423
Epoch 9/9
	 Logging train Loss: 1.5019e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 7.912e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 1.33155e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 1.46092e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 7.0015e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 31.673967361450195
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pTrue_gTrue/'quat_1'_'False'.pth
It took  425.174742937088  seconds.
----- ITERATION 7/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 50.08378195762634 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 12.58429765701294 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 12.552762985229492 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 12.558353185653687 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 12.503681182861328 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0002203132 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.771e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 2.0912e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 3.3722e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.5889e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 30.74006462097168
Epoch 1/9
	 Logging train Loss: 8.329e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue â–ƒâ–‚â–â–â–â–…â–â–ˆâ–â–‚
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue â–…â–‚â–‚â–â–â–…â–â–ˆâ–â–‚
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue â–ƒâ–‚â–â–â–â–…â–â–ˆâ–â–‚
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue â–ƒâ–‚â–â–â–â–…â–â–ˆâ–â–‚
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.0
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.0
wandb:                                 Train loss 0.0
wandb: 
wandb: ðŸš€ View run breezy-surf-224 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/hvp5c6de
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_133350-hvp5c6de/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_134055-kj037lub
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run breezy-vortex-262
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/kj037lub
	 Logging test loss: 6.62e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 7.686e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 1.2105e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 5.77e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 31.323464393615723
Epoch 2/9
	 Logging train Loss: 1.2456e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 3.4e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 4.978e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 7.996e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 3.715e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 31.3602352142334
Epoch 3/9
	 Logging train Loss: 1.0881e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.84e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 3.851e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 6.056e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.843e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 31.249022245407104
Epoch 4/9
	 Logging train Loss: 1.2991e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.36e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 2.976e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 4.491e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.146e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 31.25280213356018
Epoch 5/9
	 Logging train Loss: 1.5887e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.664e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 4.6804e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 5.0488e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.4753e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 31.414931297302246
Epoch 6/9
	 Logging train Loss: 7.724e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.33e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 1.354e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 1.971e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 9.91e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 31.174076318740845
Epoch 7/9
	 Logging train Loss: 9.95e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.841e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 8.1901e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 9.4438e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 4.3626e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 31.219757318496704
Epoch 8/9
	 Logging train Loss: 1.0832e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.71e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 2.486e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 2.87e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.439e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 31.47425150871277
Epoch 9/9
	 Logging train Loss: 8.223e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 4.49e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 1.12e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 1.18e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 5.936e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 31.567753553390503
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pTrue_gTrue/'quat_1'_'False'.pth
It took  425.14935183525085  seconds.
----- ITERATION 8/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 50.02937340736389 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 12.54823350906372 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 12.550557136535645 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 12.559266090393066 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 12.469780206680298 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0003563014 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.472e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 3.1414e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 4.7838e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.1381e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 30.639096975326538
Epoch 1/9
	 Logging train Loss: 9.172e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 7.45e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 9.611e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 1.4052e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 6.452e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 31.45402216911316
Epoch 2/9
	 Logging train Loss: 4.224e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 4.75e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 6.081e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 9.132e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 4.113e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 31.323995351791382
Epoch 3/9
	 Logging train Loss: 5.974e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.016e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 1.8184e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 2.1011e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 9.992e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 31.150585412979126
Epoch 4/9
	 Logging train Loss: 1.3726e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.93e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 3.001e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 4.465e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.027e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 31.045747756958008
Epoch 5/9
	 Logging train Loss: 1.1538e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.73e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 2.787e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 3.803e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.781e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 31.25880527496338
Epoch 6/9
	 Logging train Loss: 1.2813e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 4.769e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 8.2132e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 8.8766e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 4.6163e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 31.24296998977661
Epoch 7/9
	 Logging train Loss: 1.0391e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.38e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 2.005e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 2.575e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.248e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 31.31557607650757
Epoch 8/9
	 Logging train Loss: 1.05e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue â–„â–‚â–‚â–‚â–â–â–ˆâ–â–â–
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue â–…â–‚â–‚â–‚â–â–â–ˆâ–â–â–
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue â–„â–‚â–â–‚â–â–â–ˆâ–â–â–
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue â–…â–‚â–‚â–ƒâ–â–â–ˆâ–â–â–
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.0
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.0
wandb:                                 Train loss 0.0
wandb: 
wandb: ðŸš€ View run breezy-vortex-262 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/kj037lub
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_134055-kj037lub/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_134800-um65yc0i
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fragrant-microwave-292
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/um65yc0i
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue â–‚â–ƒâ–â–â–â–ˆâ–â–ƒâ–â–
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue â–ƒâ–ƒâ–â–â–â–ˆâ–â–ˆâ–‚â–‚
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue â–‚â–ƒâ–â–â–â–ˆâ–â–‚â–â–
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue â–‚â–ƒâ–â–â–â–ˆâ–â–‚â–â–
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.0
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.0
wandb:                                 Train loss 0.0
wandb: 
wandb: ðŸš€ View run fragrant-microwave-292 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/um65yc0i
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_134800-um65yc0i/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_135505-ki56fl5h
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run youthful-oath-330
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/ki56fl5h
	 Logging test loss: 1.83e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 2.155e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 2.668e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.307e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 31.32439684867859
Epoch 9/9
	 Logging train Loss: 9.894e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.27e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 1.14e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 1.465e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 7.29e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 31.269985914230347
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pTrue_gTrue/'quat_1'_'False'.pth
It took  424.97912073135376  seconds.
----- ITERATION 9/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 50.096614599227905 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 12.545451879501343 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 12.554917097091675 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 12.56928539276123 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 12.511544704437256 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0001680852 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.855e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 1.6173e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 2.2585e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.0792e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 30.481340169906616
Epoch 1/9
	 Logging train Loss: 9.387e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.739e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 5.7265e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 5.5854e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.9275e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 31.209038734436035
Epoch 2/9
	 Logging train Loss: 2.1118e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.69e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 4.815e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 6.882e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 3.187e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 31.199187517166138
Epoch 3/9
	 Logging train Loss: 2.2229e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 4.42e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 4.318e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 5.798e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.883e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 31.36214327812195
Epoch 4/9
	 Logging train Loss: 1.3582e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.02e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 3.267e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 4.123e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.058e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 31.428571939468384
Epoch 5/9
	 Logging train Loss: 1.025e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 5.932e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 1.84298e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 1.76758e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 9.8008e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 31.361557960510254
Epoch 6/9
	 Logging train Loss: 1.0056e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 9e-09 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 1.303e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 1.66e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 8.32e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 31.117666006088257
Epoch 7/9
	 Logging train Loss: 7.716e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 6.287e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 3.9998e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 3.8455e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.2745e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 31.21599245071411
Epoch 8/9
	 Logging train Loss: 6.172e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 5.45e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 4.123e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 4.283e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.415e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 31.377198696136475
Epoch 9/9
	 Logging train Loss: 5.258e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 7.71e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 1.643e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 1.785e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.258e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 31.157999277114868
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pTrue_gTrue/'quat_1'_'False'.pth
It took  425.02132391929626  seconds.
----- ITERATION 10/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 50.11646771430969 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 12.603215217590332 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 12.55858063697815 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 12.567077159881592 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 12.519739389419556 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0001474388 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.722e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 1.9263e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 2.7058e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.081e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 30.457757472991943
Epoch 1/9
	 Logging train Loss: 9.101e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 5.51e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 7.801e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 1.0829e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 4.002e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 31.365213632583618
Epoch 2/9
	 Logging train Loss: 9.523e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.96e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 5.795e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 7.962e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.89e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 31.321722984313965
Epoch 3/9
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue â–‚â–â–â–â–‚â–ˆâ–â–â–â–
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue â–‚â–â–â–â–â–ˆâ–â–â–‚â–
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue â–‚â–â–â–â–‚â–ˆâ–â–â–â–
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue â–‚â–â–â–â–‚â–ˆâ–â–â–â–
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.0
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.0
wandb:                                 Train loss 0.0
wandb: 
wandb: ðŸš€ View run youthful-oath-330 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/ki56fl5h
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_135505-ki56fl5h/logs
	 Logging train Loss: 1.9067e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.44e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 4.297e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 5.736e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.151e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 31.19738483428955
Epoch 4/9
	 Logging train Loss: 1.397e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.027e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 1.6601e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 1.8126e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 8.766e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 31.16676139831543
Epoch 5/9
	 Logging train Loss: 1.2282e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.5146e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 1.64733e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 1.79888e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 9.1352e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 31.240238904953003
Epoch 6/9
	 Logging train Loss: 1.1206e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 9.99e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 5.967e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 6.529e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 3.518e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 31.267246961593628
Epoch 7/9
	 Logging train Loss: 7.97e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.37e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 1.219e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 1.385e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 6.94e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 31.158956050872803
Epoch 8/9
	 Logging train Loss: 8.418e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.592e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 8.77e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 9.019e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 5.05e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 31.25716257095337
Epoch 9/9
	 Logging train Loss: 5.231e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.36e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 1.609e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 1.705e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 8.76e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 31.23217749595642
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pTrue_gTrue/'quat_1'_'False'.pth
It took  425.11624336242676  seconds.

JOB STATISTICS
==============
Job ID: 3081650
Array Job ID: 3081615_36
Cluster: snellius
User/Group: nreints/nreints
State: RUNNING
Nodes: 1
Cores per node: 18
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 21:20:42 core-walltime
Job Wall-clock time: 01:11:09
Memory Utilized: 0.00 MB (estimated maximum)
Memory Efficiency: 0.00% of 0.00 MB (0.00 MB/node)
WARNING: Efficiency statistics may be misleading for RUNNING jobs.
