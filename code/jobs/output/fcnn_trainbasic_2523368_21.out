wandb: Currently logged in as: nreints. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home/nreints/.netrc
/gpfs/home2/nreints/MScThesis/code/fcnn.py:566: DeprecationWarning: Sampling from a set deprecated
since Python 3.9 and will be removed in a subsequent version.
  train_sims = set(random.sample(sims_train, int(0.8 * n_sims_train)))
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230330_123651-7oc3ad29
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sweet-meadow-592
wandb: â­ï¸ View project at https://wandb.ai/nreints/test
wandb: ðŸš€ View run at https://wandb.ai/nreints/test/runs/7oc3ad29
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.029 MB of 0.029 MB uploaded (0.000 MB deduped)wandb: \ 0.029 MB of 0.079 MB uploaded (0.000 MB deduped)wandb: | 0.029 MB of 0.079 MB uploaded (0.000 MB deduped)wandb: / 0.029 MB of 0.079 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  Test loss t(0, 0)_r(5, 20)_tennis L1Loss() â–ˆâ–…â–ƒâ–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: Test loss t(0, 0)_r(5, 20)_tennis MSELoss() â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:     Train loss data_t(0, 0)_r(5, 20)_tennis â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:  Test loss t(0, 0)_r(5, 20)_tennis L1Loss() 0.10766
wandb: Test loss t(0, 0)_r(5, 20)_tennis MSELoss() 0.02724
wandb:     Train loss data_t(0, 0)_r(5, 20)_tennis 0.02425
wandb: 
wandb: ðŸš€ View run sweet-meadow-592 at: https://wandb.ai/nreints/test/runs/7oc3ad29
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230330_123651-7oc3ad29/logs
/gpfs/home2/nreints/MScThesis/code/fcnn.py:566: DeprecationWarning: Sampling from a set deprecated
since Python 3.9 and will be removed in a subsequent version.
  train_sims = set(random.sample(sims_train, int(0.8 * n_sims_train)))
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230330_124724-7dw57cgm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dandy-leaf-610
wandb: â­ï¸ View project at https://wandb.ai/nreints/test
wandb: ðŸš€ View run at https://wandb.ai/nreints/test/runs/7dw57cgm
Training on dataset: data/data_t(0, 0)_r(5, 20)_tennis_pNone_gNone
Testing on datasets: ['data_t(0, 0)_r(5, 20)_tennis_pNone_gNone']
----- ITERATION 1/2 ------
Number of train simulations: 1600
Number of test simulations: 400
The dataloader took 60.75011682510376 seconds.
-- Finished Train Dataloader --
The dataloader took 15.344881057739258 seconds.
-- Finished Test Dataloader(s) --
Datatype: pos_diff_start
--- Started Training ---
Epoch 0
	 Logging train Loss: 30.9681704453 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 2.3023107051849365 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 1.0486449003219604 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 27.971872329711914
Epoch 1
	 Logging train Loss: 1.2128796945 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.7456427812576294 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.6000406742095947 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 27.61876678466797
Epoch 2
	 Logging train Loss: 0.441610259 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.32910671830177307 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.3934308588504791 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 27.557344675064087
Epoch 3
	 Logging train Loss: 0.225416156 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.1945676952600479 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.29784199595451355 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 27.894094944000244
Epoch 4
	 Logging train Loss: 0.1397301568 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.12927411496639252 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.2395966351032257 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 27.775364875793457
Epoch 5
	 Logging train Loss: 0.0984480016 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.09360451251268387 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.20199348032474518 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 28.064451932907104
Epoch 6
	 Logging train Loss: 0.0775488062 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.0790315717458725 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.18319833278656006 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 27.82111930847168
Epoch 7
	 Logging train Loss: 0.0650569292 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.06635300815105438 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.1671590507030487 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 28.025097608566284
Epoch 8
	 Logging train Loss: 0.0569724588 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.05877891555428505 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.15568499267101288 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 27.71844792366028
Epoch 9
	 Logging train Loss: 0.0505970924 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.05695754289627075 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.15621843934059143 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 26.29369878768921
Epoch 10
	 Logging train Loss: 0.0457882052 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.050956543534994125 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.14612337946891785 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 26.26695680618286
Epoch 11
	 Logging train Loss: 0.041638403 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.047444574534893036 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.14161142706871033 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 26.123544454574585
Epoch 12
	 Logging train Loss: 0.0382103615 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.03970518335700035 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.1277635395526886 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 25.862282752990723
Epoch 13
	 Logging train Loss: 0.0353441326 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.03869037702679634 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.12642015516757965 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 27.774112224578857
Epoch 14
	 Logging train Loss: 0.0329118292 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.036081038415431976 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.12282974272966385 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 26.135777950286865
Epoch 15
	 Logging train Loss: 0.0306397307 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.031885575503110886 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.11421417444944382 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 25.870659351348877
Epoch 16
	 Logging train Loss: 0.0287227032 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.03052685596048832 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.11224053800106049 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 26.202053785324097
Epoch 17
	 Logging train Loss: 0.0271450516 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.030249755829572678 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.11339905112981796 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 26.294850826263428
Epoch 18
	 Logging train Loss: 0.0255962073 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.02739720232784748 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.1064903736114502 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 26.25198745727539
Epoch 19
	 Logging train Loss: 0.0242477666 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.02725890278816223 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.10765659064054489 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 27.473193168640137
	 Logging test loss 0.02724495343863964 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.10765723139047623 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
It took 632.956689119339 seconds to train & eval the model.
----- ITERATION 2/2 ------
Number of train simulations: 1600
Number of test simulations: 400
The dataloader took 57.511889696121216 seconds.
-- Finished Train Dataloader --
The dataloader took 14.323323726654053 seconds.
-- Finished Test Dataloader(s) --
Datatype: pos_diff_start
--- Started Training ---
Epoch 0
	 Logging train Loss: 30.8075239992 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 2.102919340133667 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 1.0153541564941406 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 28.317832946777344
Epoch 1
	 Logging train Loss: 1.1853722267 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.688378095626831 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.582480251789093 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 26.821195125579834
Epoch 2
	 Logging train Loss: 0.4439150742 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.3135356307029724 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.38829073309898376 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 26.799851417541504
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.029 MB of 0.079 MB uploaded (0.000 MB deduped)wandb: \ 0.079 MB of 0.079 MB uploaded (0.000 MB deduped)wandb: | 0.079 MB of 0.079 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  Test loss t(0, 0)_r(5, 20)_tennis L1Loss() â–ˆâ–…â–ƒâ–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: Test loss t(0, 0)_r(5, 20)_tennis MSELoss() â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:     Train loss data_t(0, 0)_r(5, 20)_tennis â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:  Test loss t(0, 0)_r(5, 20)_tennis L1Loss() 0.10131
wandb: Test loss t(0, 0)_r(5, 20)_tennis MSELoss() 0.02417
wandb:     Train loss data_t(0, 0)_r(5, 20)_tennis 0.02444
wandb: 
wandb: ðŸš€ View run dandy-leaf-610 at: https://wandb.ai/nreints/test/runs/7dw57cgm
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230330_124724-7dw57cgm/logs
Epoch 3
	 Logging train Loss: 0.2272095325 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.1791561245918274 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.2894079387187958 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 25.952993392944336
Epoch 4
	 Logging train Loss: 0.1416276321 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.12756480276584625 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.2436036914587021 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 28.000219345092773
Epoch 5
	 Logging train Loss: 0.1004238453 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.09333620965480804 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.20377156138420105 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 27.900315761566162
Epoch 6
	 Logging train Loss: 0.0798003702 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.0781572014093399 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.1851709634065628 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 28.327824354171753
Epoch 7
	 Logging train Loss: 0.0672208848 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.06522102653980255 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.16742956638336182 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 26.14210057258606
Epoch 8
	 Logging train Loss: 0.0589987262 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.05879701301455498 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.15990261733531952 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 26.330407857894897
Epoch 9
	 Logging train Loss: 0.0528725917 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.05146249756217003 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.14789564907550812 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 26.576173543930054
Epoch 10
	 Logging train Loss: 0.0475909813 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.047446344047784805 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.1425543874502182 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 25.981996297836304
Epoch 11
	 Logging train Loss: 0.0434467341 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.04498610273003578 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.1387621909379959 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 27.770968675613403
Epoch 12
	 Logging train Loss: 0.0399254169 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.043156154453754425 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.1367352455854416 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 26.01249647140503
Epoch 13
	 Logging train Loss: 0.0366917853 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.037176910787820816 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.1263248324394226 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 26.1904718875885
Epoch 14
	 Logging train Loss: 0.0338486416 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.03374672308564186 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.12014000862836838 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 26.023320198059082
Epoch 15
	 Logging train Loss: 0.0314768523 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.03360415995121002 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.12087696045637131 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 25.65342116355896
Epoch 16
	 Logging train Loss: 0.029418676 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.02986832708120346 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.11298798769712448 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 28.157172203063965
Epoch 17
	 Logging train Loss: 0.0275773341 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.02678920142352581 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.1069469228386879 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 27.762487411499023
Epoch 18
	 Logging train Loss: 0.0260247947 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.0277103204280138 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.10987836867570877 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 27.6963894367218
Epoch 19
	 Logging train Loss: 0.0244355195 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.024167999625205994 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.10130386799573898 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 26.267505884170532
	 Logging test loss 0.024168699979782104 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.10130776464939117 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
It took 625.1550755500793 seconds to train & eval the model.

JOB STATISTICS
==============
Job ID: 2523389
Array Job ID: 2523368_21
Cluster: snellius
User/Group: nreints/nreints
State: COMPLETED (exit code 0)
Nodes: 1
Cores per node: 18
CPU Utilized: 03:09:07
CPU Efficiency: 49.36% of 06:23:06 core-walltime
Job Wall-clock time: 00:21:17
Memory Utilized: 7.89 GB
Memory Efficiency: 26.94% of 29.30 GB
