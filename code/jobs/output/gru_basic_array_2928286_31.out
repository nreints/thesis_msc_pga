wandb: Currently logged in as: nreints. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230616_165716-06xojpjx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run treasured-waterfall-51
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal/runs/06xojpjx
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb: Test loss t(5,20)_r(5,20)_combiR_pNone_gNone â–ˆâ–ƒâ–ƒâ–‚â–‚â–‚â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone â–ˆâ–‚â–‚â–â–‚â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone â–ˆâ–„â–ƒâ–ƒâ–‚â–‚â–â–â–â–
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone â–ˆâ–ƒâ–ƒâ–‚â–‚â–‚â–â–â–â–
wandb:                                   Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb: Test loss t(5,20)_r(5,20)_combiR_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 0.0
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 0.0
wandb:                                   Train loss 0.0
wandb: 
wandb: ðŸš€ View run treasured-waterfall-51 at: https://wandb.ai/nreints/ThesisFinal/runs/06xojpjx
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230616_165716-06xojpjx/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230616_170319-tunnvxx4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run playful-haze-56
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal/runs/tunnvxx4
Training on dataset: data_t(5,20)_r(5,20)_combiR_pNone_gNone
Testing on 4 datasets: ['data_t(5,20)_r(5,20)_combiR_pNone_gNone', 'data_t(5,20)_r(5,20)_full_pNone_gNone', 'data_t(5,20)_r(5,20)_semi_pNone_gNone', 'data_t(5,20)_r(5,20)_tennis_pNone_gNone']
Focussing on identity: False
Using extra input: None
Using fr-fr as reference point.
----- ITERATION 1/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  800
Number of test simulations:  200
The dataloader for data/data_t(5,20)_r(5,20)_combiR_pNone_gNone took 23.58279252052307 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_combiR_pNone_gNone took 5.730279207229614 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 5.407419204711914 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 5.376488208770752 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 5.389061212539673 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(24, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=24, bias=True)
)
Datatype: pos_diff_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0004617907 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 3.54905e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 2.06063e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.86939e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.43645e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 31.679997444152832
Epoch 1/9
	 Logging train Loss: 1.9319e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 1.37923e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 3.9298e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.78769e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.81558e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 30.5217547416687
Epoch 2/9
	 Logging train Loss: 1.16083e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 1.0511e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 2.3742e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.4802e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.30105e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 30.35146713256836
Epoch 3/9
	 Logging train Loss: 9.0432e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 8.4202e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 1.5856e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.23112e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.03212e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 30.453614473342896
Epoch 4/9
	 Logging train Loss: 7.4738e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 7.9701e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 2.3233e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.13644e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 9.3872e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 30.34612464904785
Epoch 5/9
	 Logging train Loss: 6.1599e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 5.5998e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 1.1825e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 8.1193e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 6.9149e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 31.066301107406616
Epoch 6/9
	 Logging train Loss: 4.7719e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 4.5356e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 1.2822e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 6.2434e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 5.7035e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 30.30040979385376
Epoch 7/9
	 Logging train Loss: 3.7029e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 3.5948e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 1.055e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.7486e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.6515e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 30.494946241378784
Epoch 8/9
	 Logging train Loss: 3.0735e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 3.1739e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 9.19e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.1647e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.1606e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 30.490061044692993
Epoch 9/9
	 Logging train Loss: 2.7784e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 2.9767e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 7.896e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.9631e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.8389e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 30.490315675735474
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combiR_pNone_gNone/'pos_diff_1'_'None'.pth
It took  364.3249626159668  seconds.
----- ITERATION 2/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  800
Number of test simulations:  200
The dataloader for data/data_t(5,20)_r(5,20)_combiR_pNone_gNone took 19.71842908859253 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_combiR_pNone_gNone took 4.909517765045166 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 4.981120347976685 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 5.000102996826172 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 5.025557279586792 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(24, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=24, bias=True)
)
Datatype: pos_diff_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0003999393 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 2.91247e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 1.62434e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.20475e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.16902e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 31.046717166900635
Epoch 1/9
	 Logging train Loss: 1.8008e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 1.23689e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 3.7473e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.65276e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.83362e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 30.540693521499634
Epoch 2/9
	 Logging train Loss: 1.12375e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 8.9636e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 2.2963e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.32262e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.29131e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 30.396424055099487
Epoch 3/9
	 Logging train Loss: 8.8185e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb: Test loss t(5,20)_r(5,20)_combiR_pNone_gNone â–ˆâ–„â–ƒâ–‚â–‚â–‚â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone â–ˆâ–‚â–‚â–‚â–â–‚â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone â–ˆâ–„â–ƒâ–ƒâ–‚â–‚â–â–â–â–
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone â–ˆâ–„â–ƒâ–‚â–‚â–‚â–â–â–â–
wandb:                                   Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb: Test loss t(5,20)_r(5,20)_combiR_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 0.0
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 0.0
wandb:                                   Train loss 0.0
wandb: 
wandb: ðŸš€ View run playful-haze-56 at: https://wandb.ai/nreints/ThesisFinal/runs/tunnvxx4
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230616_170319-tunnvxx4/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230616_170921-lq42forw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run young-haze-61
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal/runs/lq42forw
	 Logging test loss: 7.8823e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 2.1593e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.14553e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.10797e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 30.384594917297363
Epoch 4/9
	 Logging train Loss: 7.3103e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 6.1752e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 1.4806e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 9.5672e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 8.7007e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 30.507262229919434
Epoch 5/9
	 Logging train Loss: 5.7129e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 5.28e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 1.8466e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 7.2497e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 7.4548e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 30.538177251815796
Epoch 6/9
	 Logging train Loss: 4.2403e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 3.3222e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 8.775e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.6225e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.988e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 30.36291742324829
Epoch 7/9
	 Logging train Loss: 3.3742e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 3.0685e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 9.831e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.1207e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.5696e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 30.473032474517822
Epoch 8/9
	 Logging train Loss: 3.0122e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 2.7426e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 7.844e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.7433e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.1594e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 30.565632343292236
Epoch 9/9
	 Logging train Loss: 2.7668e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 2.4812e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 6.063e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.4501e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.8461e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 34.862334966659546
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combiR_pNone_gNone/'pos_diff_1'_'None'.pth
It took  362.5774185657501  seconds.
----- ITERATION 3/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  800
Number of test simulations:  200
The dataloader for data/data_t(5,20)_r(5,20)_combiR_pNone_gNone took 19.236226797103882 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_combiR_pNone_gNone took 4.851736307144165 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 4.96302342414856 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 4.956173419952393 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 4.965735673904419 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(24, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=24, bias=True)
)
Datatype: pos_diff_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0004260374 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 3.47031e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 1.94508e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.60687e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.99738e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 30.602137565612793
Epoch 1/9
	 Logging train Loss: 1.91535e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 1.39277e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 3.9357e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.69347e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.02233e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 30.636361122131348
Epoch 2/9
	 Logging train Loss: 1.10465e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 1.02809e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 2.2628e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.33229e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.44294e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 30.596258878707886
Epoch 3/9
	 Logging train Loss: 8.4932e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 8.5616e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 1.7924e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.13522e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.17476e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 30.526259183883667
Epoch 4/9
	 Logging train Loss: 7.0116e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 8.3668e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 2.8288e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.05301e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.11116e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 30.5522198677063
Epoch 5/9
	 Logging train Loss: 5.6552e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 5.4549e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 1.2438e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 6.974e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 7.6733e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 30.671027898788452
Epoch 6/9
	 Logging train Loss: 4.3668e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 4.9503e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 1.7406e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 6.1641e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 6.7571e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 30.432546854019165
Epoch 7/9
	 Logging train Loss: 3.4432e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 3.2965e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 6.796e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.0965e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.9482e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 30.667301893234253
Epoch 8/9
	 Logging train Loss: 2.9369e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 3.0353e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 6.516e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.7263e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.5598e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 30.658982515335083
Epoch 9/9
	 Logging train Loss: 2.7443e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb: Test loss t(5,20)_r(5,20)_combiR_pNone_gNone â–ˆâ–ƒâ–ƒâ–‚â–‚â–‚â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone â–ˆâ–‚â–‚â–â–‚â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone â–ˆâ–„â–ƒâ–ƒâ–ƒâ–‚â–‚â–â–â–
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone â–ˆâ–ƒâ–ƒâ–‚â–‚â–‚â–â–â–â–
wandb:                                   Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb: Test loss t(5,20)_r(5,20)_combiR_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 0.0
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 0.0
wandb:                                   Train loss 0.0
wandb: 
wandb: ðŸš€ View run young-haze-61 at: https://wandb.ai/nreints/ThesisFinal/runs/lq42forw
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230616_170921-lq42forw/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230616_171519-07kmzhrr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fallen-wind-65
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal/runs/07kmzhrr
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb: Test loss t(5,20)_r(5,20)_combiR_pNone_gNone â–ˆâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone â–ˆâ–‚â–‚â–ƒâ–ƒâ–‚â–‚â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone â–ˆâ–„â–ƒâ–„â–ƒâ–‚â–‚â–â–â–
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone â–ˆâ–„â–ƒâ–ƒâ–ƒâ–‚â–‚â–â–â–
wandb:                                   Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb: Test loss t(5,20)_r(5,20)_combiR_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 0.0
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 0.0
wandb:                                   Train loss 0.0
wandb: 
wandb: ðŸš€ View run fallen-wind-65 at: https://wandb.ai/nreints/ThesisFinal/runs/07kmzhrr
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230616_171519-07kmzhrr/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230616_172117-q4v8lxs1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sleek-grass-69
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal/runs/q4v8lxs1
	 Logging test loss: 2.6992e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 4.4e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.3432e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.1449e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 30.51217246055603
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combiR_pNone_gNone/'pos_diff_1'_'None'.pth
It took  357.866938829422  seconds.
----- ITERATION 4/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  800
Number of test simulations:  200
The dataloader for data/data_t(5,20)_r(5,20)_combiR_pNone_gNone took 18.641979932785034 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_combiR_pNone_gNone took 4.6646363735198975 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 4.928050994873047 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 4.938484191894531 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 4.970883846282959 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(24, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=24, bias=True)
)
Datatype: pos_diff_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0004610154 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 3.33813e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 1.87759e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.44684e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.77539e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 30.69555974006653
Epoch 1/9
	 Logging train Loss: 1.95031e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 1.31324e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 3.8515e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.66614e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.00687e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 30.526222705841064
Epoch 2/9
	 Logging train Loss: 1.18684e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 9.8861e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 2.2743e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.38939e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.46756e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 30.414644956588745
Epoch 3/9
	 Logging train Loss: 9.3479e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 1.2386e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 5.6557e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.61871e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.61083e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 30.78142213821411
Epoch 4/9
	 Logging train Loss: 7.8876e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 1.05631e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 5.3667e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.39328e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.36449e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 30.551225185394287
Epoch 5/9
	 Logging train Loss: 6.686e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 6.9744e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 2.4121e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 9.5076e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 9.7651e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 30.642014026641846
Epoch 6/9
	 Logging train Loss: 5.3774e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 5.6238e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 2.1495e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 7.5731e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 7.8238e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 30.59107494354248
Epoch 7/9
	 Logging train Loss: 4.2699e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 3.8755e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 1.258e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 5.246e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 5.6388e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 30.856411695480347
Epoch 8/9
	 Logging train Loss: 3.423e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 3.4853e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 1.2462e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.5848e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 5.0224e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 30.820301055908203
Epoch 9/9
	 Logging train Loss: 2.9654e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 2.4716e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 4.357e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.3742e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.9517e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 30.820533752441406
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combiR_pNone_gNone/'pos_diff_1'_'None'.pth
It took  357.61574816703796  seconds.
----- ITERATION 5/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  800
Number of test simulations:  200
The dataloader for data/data_t(5,20)_r(5,20)_combiR_pNone_gNone took 18.721231698989868 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_combiR_pNone_gNone took 4.658937931060791 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 4.8722710609436035 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 4.8678038120269775 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 4.863547325134277 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(24, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=24, bias=True)
)
Datatype: pos_diff_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0004836985 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 3.3529e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 1.88948e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.32984e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.24277e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 30.785350799560547
Epoch 1/9
	 Logging train Loss: 1.8626e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 1.43692e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 3.8219e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.60987e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.78304e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 30.59480857849121
Epoch 2/9
	 Logging train Loss: 1.1567e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 1.08177e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 2.1611e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.29683e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.28659e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb: Test loss t(5,20)_r(5,20)_combiR_pNone_gNone â–ˆâ–„â–ƒâ–‚â–‚â–‚â–‚â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone â–ˆâ–‚â–‚â–â–â–â–ƒâ–â–â–
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone â–ˆâ–„â–ƒâ–ƒâ–‚â–‚â–ƒâ–â–â–
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone â–ˆâ–„â–ƒâ–‚â–‚â–‚â–‚â–â–â–
wandb:                                   Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb: Test loss t(5,20)_r(5,20)_combiR_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 0.0
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 0.0
wandb:                                   Train loss 0.0
wandb: 
wandb: ðŸš€ View run sleek-grass-69 at: https://wandb.ai/nreints/ThesisFinal/runs/q4v8lxs1
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230616_172117-q4v8lxs1/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230616_172722-ngc9a2lx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glad-violet-75
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal/runs/ngc9a2lx
		--> Epoch time; 30.315321683883667
Epoch 3/9
	 Logging train Loss: 9.0897e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 9.1187e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 1.8478e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.12959e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.05414e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 30.55085515975952
Epoch 4/9
	 Logging train Loss: 7.621e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 7.9651e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 1.696e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 9.7735e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 9.1693e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 30.45348048210144
Epoch 5/9
	 Logging train Loss: 6.3443e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 6.6089e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 1.7238e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 8.1136e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 7.8519e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 34.92497897148132
Epoch 6/9
	 Logging train Loss: 5.0965e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 8.9281e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 5.0658e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.00786e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.01096e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 33.91545653343201
Epoch 7/9
	 Logging train Loss: 4.0007e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 4.293e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 1.4108e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 5.0044e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 5.2825e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 30.642699003219604
Epoch 8/9
	 Logging train Loss: 3.2318e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 3.5204e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 1.0161e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.1174e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.4463e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 30.80632996559143
Epoch 9/9
	 Logging train Loss: 2.874e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 3.0407e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 7.863e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.5731e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.9445e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 30.722782135009766
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combiR_pNone_gNone/'pos_diff_1'_'None'.pth
It took  364.7418339252472  seconds.
----- ITERATION 6/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  800
Number of test simulations:  200
The dataloader for data/data_t(5,20)_r(5,20)_combiR_pNone_gNone took 18.784674644470215 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_combiR_pNone_gNone took 4.671265602111816 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 4.845491409301758 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 4.837165832519531 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 4.836528062820435 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(24, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=24, bias=True)
)
Datatype: pos_diff_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0004795188 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 4.14532e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 2.65539e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.67439e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 5.52903e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 30.748388528823853
Epoch 1/9
	 Logging train Loss: 2.18887e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 1.25574e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 3.6847e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.81976e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.90685e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 30.71823811531067
Epoch 2/9
	 Logging train Loss: 1.1796e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 9.41e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 2.1553e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.51696e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.38332e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 30.480482578277588
Epoch 3/9
	 Logging train Loss: 9.2978e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 8.9484e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 2.6797e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.43336e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.23985e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 30.714529037475586
Epoch 4/9
	 Logging train Loss: 7.7735e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 7.6734e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 2.4682e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.2131e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.06764e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 30.36380696296692
Epoch 5/9
	 Logging train Loss: 6.4071e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 5.0852e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 9.985e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 8.4958e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 7.5147e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 30.79230284690857
Epoch 6/9
	 Logging train Loss: 4.9989e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 4.6963e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 1.742e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 7.0199e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 6.5027e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 30.461106061935425
Epoch 7/9
	 Logging train Loss: 3.8394e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 2.8867e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 5.408e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.5879e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.4659e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 30.559212684631348
Epoch 8/9
	 Logging train Loss: 3.1903e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 3.0879e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 1.0263e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.5712e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.5038e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 30.56444215774536
Epoch 9/9
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb: Test loss t(5,20)_r(5,20)_combiR_pNone_gNone â–ˆâ–ƒâ–‚â–‚â–‚â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone â–ˆâ–‚â–â–‚â–‚â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone â–ˆâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–â–â–
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone â–ˆâ–ƒâ–‚â–‚â–‚â–â–â–â–â–
wandb:                                   Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb: Test loss t(5,20)_r(5,20)_combiR_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 0.0
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 0.0
wandb:                                   Train loss 0.0
wandb: 
wandb: ðŸš€ View run glad-violet-75 at: https://wandb.ai/nreints/ThesisFinal/runs/ngc9a2lx
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230616_172722-ngc9a2lx/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230616_173320-ri011s3d
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run decent-meadow-78
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal/runs/ri011s3d
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb: Test loss t(5,20)_r(5,20)_combiR_pNone_gNone â–ˆâ–ƒâ–ƒâ–‚â–‚â–‚â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone â–ˆâ–‚â–‚â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone â–ˆâ–ƒâ–ƒâ–ƒâ–‚â–‚â–â–â–â–
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone â–ˆâ–ƒâ–ƒâ–‚â–‚â–‚â–â–â–â–
wandb:                                   Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb: Test loss t(5,20)_r(5,20)_combiR_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 0.0
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 0.0
wandb:                                   Train loss 0.0
wandb: 
wandb: ðŸš€ View run decent-meadow-78 at: https://wandb.ai/nreints/ThesisFinal/runs/ri011s3d
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230616_173320-ri011s3d/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230616_173918-n4t26qha
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run snowy-aardvark-83
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal/runs/n4t26qha
	 Logging train Loss: 2.9162e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 2.5503e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 5.968e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.8755e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.9357e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 30.836153030395508
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combiR_pNone_gNone/'pos_diff_1'_'None'.pth
It took  357.94136118888855  seconds.
----- ITERATION 7/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  800
Number of test simulations:  200
The dataloader for data/data_t(5,20)_r(5,20)_combiR_pNone_gNone took 18.717448234558105 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_combiR_pNone_gNone took 4.6663525104522705 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 4.8182737827301025 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 4.835511922836304 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 4.817662477493286 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(24, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=24, bias=True)
)
Datatype: pos_diff_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0004462304 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 3.94753e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 2.35126e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.37117e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 5.14823e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 30.667718648910522
Epoch 1/9
	 Logging train Loss: 2.13717e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 1.31687e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 3.768e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.77415e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.89008e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 30.982139348983765
Epoch 2/9
	 Logging train Loss: 1.18352e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 1.10869e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 3.5698e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.61453e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.50381e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 30.648467779159546
Epoch 3/9
	 Logging train Loss: 9.4104e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 8.4455e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 1.8609e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.26481e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.14236e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 30.644487857818604
Epoch 4/9
	 Logging train Loss: 7.8214e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 6.8144e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 1.3314e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.04398e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 9.3367e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 30.39720129966736
Epoch 5/9
	 Logging train Loss: 6.5574e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 5.958e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 1.5406e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 8.8461e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 8.077e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 30.845030307769775
Epoch 6/9
	 Logging train Loss: 5.2375e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 4.0913e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 6.989e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 6.0159e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 5.7904e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 30.629403352737427
Epoch 7/9
	 Logging train Loss: 3.978e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 3.1715e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 5.913e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.4855e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.5753e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 30.712351083755493
Epoch 8/9
	 Logging train Loss: 3.1865e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 2.853e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 6.125e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.8033e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.1173e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 30.539324045181274
Epoch 9/9
	 Logging train Loss: 2.8262e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 2.804e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 7.664e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.7403e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.9963e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 30.69739580154419
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combiR_pNone_gNone/'pos_diff_1'_'None'.pth
It took  357.907194852829  seconds.
----- ITERATION 8/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  800
Number of test simulations:  200
The dataloader for data/data_t(5,20)_r(5,20)_combiR_pNone_gNone took 18.862594842910767 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_combiR_pNone_gNone took 4.70933723449707 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 4.871142148971558 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 4.870475769042969 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 4.865486145019531 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(24, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=24, bias=True)
)
Datatype: pos_diff_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0004282333 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 3.00524e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 1.79858e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.40978e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.33283e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 32.28751349449158
Epoch 1/9
	 Logging train Loss: 1.84162e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 1.18685e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 3.4684e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.65711e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.78386e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 36.16443848609924
Epoch 2/9
	 Logging train Loss: 1.12078e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 1.01497e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 3.0808e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.4879e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb: Test loss t(5,20)_r(5,20)_combiR_pNone_gNone â–ˆâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone â–ˆâ–‚â–‚â–‚â–‚â–‚â–‚â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone â–ˆâ–„â–„â–ƒâ–ƒâ–‚â–‚â–â–â–
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone â–ˆâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–â–â–
wandb:                                   Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb: Test loss t(5,20)_r(5,20)_combiR_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 0.0
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 0.0
wandb:                                   Train loss 0.0
wandb: 
wandb: ðŸš€ View run snowy-aardvark-83 at: https://wandb.ai/nreints/ThesisFinal/runs/n4t26qha
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230616_173918-n4t26qha/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230616_174523-lw8hp925
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stellar-sky-88
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal/runs/lw8hp925
	 Logging test loss: 1.40715e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 30.652637481689453
Epoch 3/9
	 Logging train Loss: 8.9279e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 8.7664e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 2.4497e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.30054e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.1882e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 30.88542628288269
Epoch 4/9
	 Logging train Loss: 7.7186e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 7.1481e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 2.0385e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.06489e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 9.8313e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 30.678831338882446
Epoch 5/9
	 Logging train Loss: 6.4139e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 6.5303e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 2.41e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 9.3645e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 8.8278e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 30.730711460113525
Epoch 6/9
	 Logging train Loss: 5.2047e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 5.0616e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 1.8862e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 7.1601e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 6.9804e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 30.565324544906616
Epoch 7/9
	 Logging train Loss: 4.0447e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 3.8622e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 1.4252e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 5.3695e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 5.4862e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 30.771737813949585
Epoch 8/9
	 Logging train Loss: 3.2881e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 3.2868e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 1.2204e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.4934e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.7667e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 30.74115252494812
Epoch 9/9
	 Logging train Loss: 2.9232e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 2.5387e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 6.403e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.6217e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.9325e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 30.704408645629883
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combiR_pNone_gNone/'pos_diff_1'_'None'.pth
It took  365.58013010025024  seconds.
----- ITERATION 9/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  800
Number of test simulations:  200
The dataloader for data/data_t(5,20)_r(5,20)_combiR_pNone_gNone took 18.618983507156372 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_combiR_pNone_gNone took 4.649048805236816 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 4.875300407409668 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 4.875074863433838 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 4.886946439743042 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(24, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=24, bias=True)
)
Datatype: pos_diff_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0004958151 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 4.87196e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 2.87665e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 5.1406e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 6.31418e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 30.535821676254272
Epoch 1/9
	 Logging train Loss: 2.35141e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 1.5033e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 4.0136e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.8802e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.18903e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 30.733351945877075
Epoch 2/9
	 Logging train Loss: 1.26259e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 1.13048e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 2.3024e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.57616e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.58922e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 30.628493785858154
Epoch 3/9
	 Logging train Loss: 9.9714e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 9.4458e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 1.6027e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.37997e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.28065e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 30.68345594406128
Epoch 4/9
	 Logging train Loss: 8.3602e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 8.2238e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 1.5112e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.20619e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.11077e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 30.397605895996094
Epoch 5/9
	 Logging train Loss: 7.0455e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 9.3552e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 3.7539e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.25233e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.18599e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 30.615384817123413
Epoch 6/9
	 Logging train Loss: 5.7293e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 6.2539e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 1.7047e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 8.7449e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 8.0983e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 30.581202507019043
Epoch 7/9
	 Logging train Loss: 4.3973e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 4.3981e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 1.3116e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 5.7812e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 5.9468e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 30.76776671409607
Epoch 8/9
	 Logging train Loss: 3.384e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 3.3449e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 8.099e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.3978e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb: Test loss t(5,20)_r(5,20)_combiR_pNone_gNone â–ˆâ–ƒâ–‚â–‚â–‚â–‚â–‚â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone â–ˆâ–‚â–â–â–â–‚â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone â–ˆâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–â–â–
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone â–ˆâ–ƒâ–‚â–‚â–‚â–‚â–â–â–â–
wandb:                                   Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb: Test loss t(5,20)_r(5,20)_combiR_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 0.0
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 0.0
wandb:                                   Train loss 0.0
wandb: 
wandb: ðŸš€ View run stellar-sky-88 at: https://wandb.ai/nreints/ThesisFinal/runs/lw8hp925
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230616_174523-lw8hp925/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230616_175121-c0azhv6u
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run floral-flower-93
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal/runs/c0azhv6u
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb: Test loss t(5,20)_r(5,20)_combiR_pNone_gNone â–ˆâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone â–ˆâ–‚â–‚â–‚â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone â–ˆâ–„â–ƒâ–ƒâ–‚â–‚â–‚â–â–â–
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone â–ˆâ–ƒâ–ƒâ–‚â–‚â–‚â–â–â–â–
wandb:                                   Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb: Test loss t(5,20)_r(5,20)_combiR_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 0.0
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 0.0
wandb:                                   Train loss 0.0
wandb: 
wandb: ðŸš€ View run floral-flower-93 at: https://wandb.ai/nreints/ThesisFinal/runs/c0azhv6u
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230616_175121-c0azhv6u/logs
	 Logging test loss: 4.6943e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 30.573122262954712
Epoch 9/9
	 Logging train Loss: 2.9308e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 2.7533e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 5.017e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.6443e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.0838e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 30.536356925964355
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combiR_pNone_gNone/'pos_diff_1'_'None'.pth
It took  357.60397696495056  seconds.
----- ITERATION 10/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  800
Number of test simulations:  200
The dataloader for data/data_t(5,20)_r(5,20)_combiR_pNone_gNone took 18.613648414611816 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_combiR_pNone_gNone took 4.65619683265686 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 4.8256003856658936 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 4.835899829864502 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 4.818272829055786 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(24, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=24, bias=True)
)
Datatype: pos_diff_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0004328745 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 3.56575e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 2.04997e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.58422e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.39598e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 30.693446397781372
Epoch 1/9
	 Logging train Loss: 1.83718e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 1.41619e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 3.7928e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.6916e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.75771e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 30.768893241882324
Epoch 2/9
	 Logging train Loss: 1.10347e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 1.05975e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 2.3374e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.34665e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.27642e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 30.79711103439331
Epoch 3/9
	 Logging train Loss: 8.854e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 9.7162e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 2.269e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.26605e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.11582e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 30.450905799865723
Epoch 4/9
	 Logging train Loss: 7.6511e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 7.4393e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 1.1887e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 9.7945e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 8.8119e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 30.533068656921387
Epoch 5/9
	 Logging train Loss: 6.517e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 7.0291e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 1.703e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 9.0377e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 8.1735e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 30.803035497665405
Epoch 6/9
	 Logging train Loss: 5.3342e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 5.6803e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 1.6008e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 7.0937e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 6.7483e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 30.349669933319092
Epoch 7/9
	 Logging train Loss: 4.2558e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 3.9144e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 6.856e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.9319e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.8783e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 35.70551061630249
Epoch 8/9
	 Logging train Loss: 3.437e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 3.449e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 7.209e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.2246e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.3101e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 32.6867949962616
Epoch 9/9
	 Logging train Loss: 2.9782e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 3.1311e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 7.471e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.779e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.9897e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 30.566409826278687
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combiR_pNone_gNone/'pos_diff_1'_'None'.pth
It took  363.5957202911377  seconds.

JOB STATISTICS
==============
Job ID: 2929715
Array Job ID: 2928286_31
Cluster: snellius
User/Group: nreints/nreints
State: COMPLETED (exit code 0)
Nodes: 1
Cores per node: 18
CPU Utilized: 12:10:10
CPU Efficiency: 67.12% of 18:07:48 core-walltime
Job Wall-clock time: 01:00:26
Memory Utilized: 8.30 GB
Memory Efficiency: 0.00% of 0.00 MB
