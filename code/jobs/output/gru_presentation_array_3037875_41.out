wandb: Currently logged in as: nreints. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_181402-y87ppx11
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fresh-frost-948
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/y87ppx11
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue ▃▂▁█▁▁▁▆▂▁
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue ▃▂▁▃▂▂▃█▄▇
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue ▄▅█▅▅▄▃▃▁▁
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue █▇▆▅▄▃▃▃▁▁
wandb:                                 Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 0.0058
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.10922
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.1705
wandb:                                 Train loss 2e-05
wandb: 
wandb: 🚀 View run fresh-frost-948 at: https://wandb.ai/nreints/ThesisFinal2/runs/y87ppx11
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_181402-y87ppx11/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_182326-qlmxka6h
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run smart-yogurt-977
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/qlmxka6h
Training on dataset: data_t(0,0)_r(0,0)_combi_pNone_gTrue
Testing on 4 datasets: ['data_t(0,0)_r(0,0)_combi_pNone_gTrue', 'data_t(0,0)_r(0,0)_tennis_pTrue_gTrue', 'data_t(0,0)_r(0,0)_full_pTrue_gTrue', 'data_t(0,0)_r(0,0)_semi_pTrue_gTrue']
Focussing on identity: False
Using extra input: True
Using start-fr as reference point.
----- ITERATION 1/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 87.22563767433167 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 21.482043743133545 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 21.487409114837646 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 22.019670248031616 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 22.10949969291687 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(6, 96, batch_first=True)
  (pre_hidden_lin_layer): Sequential(
    (0): Linear(in_features=3, out_features=96, bias=True)
    (1): ReLU()
    (2): Linear(in_features=96, out_features=96, bias=True)
    (3): ReLU()
  )
  (fc): Linear(in_features=96, out_features=6, bias=True)
)
Datatype: log_dualQ
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0394536927 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.86221e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1832857877 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0057043945 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.1100310683 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 38.960115909576416
Epoch 1/9
	 Logging train Loss: 2.82021e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.41491e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1815883368 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0056819418 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.1101827845 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 38.12661933898926
Epoch 2/9
	 Logging train Loss: 2.90184e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 9.0109e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1791584045 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0056665009 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.1110308468 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 38.117464780807495
Epoch 3/9
	 Logging train Loss: 2.90154e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0001188497 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1773560494 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0057092682 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.1102750748 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 37.31409168243408
Epoch 4/9
	 Logging train Loss: 2.66134e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.4437e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1755661666 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0056971302 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.1102256626 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 37.434868812561035
Epoch 5/9
	 Logging train Loss: 2.1378e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.0987e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1744256765 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.005696909 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.1099909022 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 37.153658390045166
Epoch 6/9
	 Logging train Loss: 2.51539e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.761e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1739041358 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0057047545 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.1096711084 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 37.127559661865234
Epoch 7/9
	 Logging train Loss: 1.5333e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 9.2896e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1734770387 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0058286493 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.1096314639 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 37.01075005531311
Epoch 8/9
	 Logging train Loss: 1.83214e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.3643e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1710940599 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.00574501 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.1093387827 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 38.097229957580566
Epoch 9/9
	 Logging train Loss: 1.70646e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.7563e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1705004126 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0058010393 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.1092151776 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 38.089513540267944
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'log_dualQ'_'True'.pth
It took  564.1358318328857  seconds.
----- ITERATION 2/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 81.36810803413391 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 20.31013536453247 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 20.48348569869995 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 20.54129719734192 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 20.560799598693848 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(6, 96, batch_first=True)
  (pre_hidden_lin_layer): Sequential(
    (0): Linear(in_features=3, out_features=96, bias=True)
    (1): ReLU()
    (2): Linear(in_features=96, out_features=96, bias=True)
    (3): ReLU()
  )
  (fc): Linear(in_features=96, out_features=6, bias=True)
)
Datatype: log_dualQ
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0296052415 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.56384e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.2661654055 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0054682828 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.1184824333 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 38.254032135009766
Epoch 1/9
	 Logging train Loss: 2.92906e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.13358e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.2515299916 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0054618591 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.117698133 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 38.30402207374573
Epoch 2/9
	 Logging train Loss: 2.86201e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.90351e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.244669497 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0054525789 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.1162398681 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 37.429686546325684
Epoch 3/9
	 Logging train Loss: 2.7897e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue ▅▄▆▂▁▂█▂▁▁
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue ▅▄▃▁▂▂▇█▇█
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue █▇▅▄▄▃▂▂▁▁
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue █▅▃▂▂▂▂▂▁▁
wandb:                                 Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 0.00551
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.1127
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.23635
wandb:                                 Train loss 1e-05
wandb: 
wandb: 🚀 View run smart-yogurt-977 at: https://wandb.ai/nreints/ThesisFinal2/runs/qlmxka6h
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_182326-qlmxka6h/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_183238-m3hk1ird
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run divine-snow-1000
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/m3hk1ird
	 Logging test loss: 5.749e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.2422722429 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0054239915 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.1150376052 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 37.280152559280396
Epoch 4/9
	 Logging train Loss: 2.35218e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.3866e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.2415721864 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0054358356 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.1148544773 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 36.92627000808716
Epoch 5/9
	 Logging train Loss: 2.18797e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.2381e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.240854755 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0054419809 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.1141534224 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 37.04897356033325
Epoch 6/9
	 Logging train Loss: 1.95588e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.42655e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.2398680449 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0055059809 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.1135777608 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 37.41633605957031
Epoch 7/9
	 Logging train Loss: 1.75677e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.1569e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.2388527691 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0055081276 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.1131707951 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 38.082178831100464
Epoch 8/9
	 Logging train Loss: 1.88705e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 9.912e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.2366879135 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0054991809 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.1127033085 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 38.15617370605469
Epoch 9/9
	 Logging train Loss: 1.23451e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.5006e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.2363473624 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0055125467 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.1126954034 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 38.23028063774109
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'log_dualQ'_'True'.pth
It took  552.0862529277802  seconds.
----- ITERATION 3/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 81.19240069389343 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 20.060996532440186 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 20.050187826156616 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 20.01453995704651 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 19.991474866867065 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(6, 96, batch_first=True)
  (pre_hidden_lin_layer): Sequential(
    (0): Linear(in_features=3, out_features=96, bias=True)
    (1): ReLU()
    (2): Linear(in_features=96, out_features=96, bias=True)
    (3): ReLU()
  )
  (fc): Linear(in_features=96, out_features=6, bias=True)
)
Datatype: log_dualQ
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.031631954 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.08414e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.2407882363 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0063673132 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.2503655553 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 38.14746069908142
Epoch 1/9
	 Logging train Loss: 1.95894e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 9.3155e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.2400460392 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0063364445 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.249018237 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 37.7037570476532
Epoch 2/9
	 Logging train Loss: 2.13949e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.15027e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.2395614684 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0063529992 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.2490541637 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 37.05986785888672
Epoch 3/9
	 Logging train Loss: 2.66999e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.61765e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.2406892031 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0063487892 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.2489980906 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 37.07354140281677
Epoch 4/9
	 Logging train Loss: 2.22567e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.80016e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.2411345094 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0063555711 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.248672083 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 37.07121276855469
Epoch 5/9
	 Logging train Loss: 2.4955e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.6092e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.2420346439 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.006309208 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.2497514337 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 37.22671937942505
Epoch 6/9
	 Logging train Loss: 1.85558e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.00817e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.2432603091 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0063284179 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.2488876134 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 38.31229567527771
Epoch 7/9
	 Logging train Loss: 1.81558e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 9.3144e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.2441317737 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0062851859 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.2492406368 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 38.218204736709595
Epoch 8/9
	 Logging train Loss: 1.91958e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.635e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.2448099852 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0062835398 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.2491756231 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 38.429850816726685
Epoch 9/9
	 Logging train Loss: 1.40853e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 9.434e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue ▃▂▂▂█▁▇▂▁▂
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue █▅▇▆▇▃▅▁▁▁
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue █▂▃▂▁▅▂▃▃▄
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue ▂▂▁▂▃▄▅▆▇█
wandb:                                 Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 1e-05
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 0.00628
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.2495
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.24557
wandb:                                 Train loss 1e-05
wandb: 
wandb: 🚀 View run divine-snow-1000 at: https://wandb.ai/nreints/ThesisFinal2/runs/m3hk1ird
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_183238-m3hk1ird/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_184148-rzp7nzuv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hearty-lake-1023
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/rzp7nzuv
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue ▅█▄▂▃▁▁▁▁▃
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue ██▇▆▆▇▅▄▄▁
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue █▅▅▄▄▄▃▂▁▁
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue █▅▃▃▄▄▂▂▁▁
wandb:                                 Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 1e-05
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 0.00624
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.16468
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.16607
wandb:                                 Train loss 1e-05
wandb: 
wandb: 🚀 View run hearty-lake-1023 at: https://wandb.ai/nreints/ThesisFinal2/runs/rzp7nzuv
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_184148-rzp7nzuv/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_185103-gdh2htbh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run expert-music-1045
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/gdh2htbh
	 Logging test loss: 0.2455689162 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.006281219 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.2495035231 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 38.28727388381958
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'log_dualQ'_'True'.pth
It took  550.0716915130615  seconds.
----- ITERATION 4/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 81.8055489063263 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 20.629767417907715 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 20.62728238105774 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 20.77322816848755 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 20.688308000564575 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(6, 96, batch_first=True)
  (pre_hidden_lin_layer): Sequential(
    (0): Linear(in_features=3, out_features=96, bias=True)
    (1): ReLU()
    (2): Linear(in_features=96, out_features=96, bias=True)
    (3): ReLU()
  )
  (fc): Linear(in_features=96, out_features=6, bias=True)
)
Datatype: log_dualQ
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0303037371 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.49535e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1730545014 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0064003174 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.1710748523 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 37.45496463775635
Epoch 1/9
	 Logging train Loss: 2.42463e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.99687e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1696863621 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0064065442 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.1684212536 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 37.37730121612549
Epoch 2/9
	 Logging train Loss: 2.85427e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.76139e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1683330089 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0063780718 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.1683173776 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 37.17166018486023
Epoch 3/9
	 Logging train Loss: 2.73571e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.5003e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1683214158 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0063553909 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.1675441265 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 37.56591820716858
Epoch 4/9
	 Logging train Loss: 2.13531e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.2646e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1692573875 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.006368591 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.1675477773 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 37.17547559738159
Epoch 5/9
	 Logging train Loss: 1.86226e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.9287e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1686213911 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0063759713 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.1673344374 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 38.47656440734863
Epoch 6/9
	 Logging train Loss: 2.66108e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.5405e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1674649417 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0063356645 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.1664878577 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 38.24879050254822
Epoch 7/9
	 Logging train Loss: 1.7606e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.2719e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1665788144 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0063169724 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.1656084806 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 38.47297644615173
Epoch 8/9
	 Logging train Loss: 1.38895e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.0079e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1661568284 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0063039372 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.1650170684 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 37.883301734924316
Epoch 9/9
	 Logging train Loss: 1.03561e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.26559e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1660673171 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0062445868 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.1646756232 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 38.54610466957092
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'log_dualQ'_'True'.pth
It took  555.6393485069275  seconds.
----- ITERATION 5/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 82.95910692214966 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 20.706809043884277 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 20.63586187362671 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 20.733376026153564 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 20.73552417755127 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(6, 96, batch_first=True)
  (pre_hidden_lin_layer): Sequential(
    (0): Linear(in_features=3, out_features=96, bias=True)
    (1): ReLU()
    (2): Linear(in_features=96, out_features=96, bias=True)
    (3): ReLU()
  )
  (fc): Linear(in_features=96, out_features=6, bias=True)
)
Datatype: log_dualQ
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0341863446 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.40881e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1395170838 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0052419445 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.2146764249 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 37.1785409450531
Epoch 1/9
	 Logging train Loss: 2.85971e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.08428e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1379744858 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0052555404 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.2117482275 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 37.27511239051819
Epoch 2/9
	 Logging train Loss: 2.81068e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.40753e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1377813369 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0052906978 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.2097118348 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 37.11776661872864
Epoch 3/9
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue ▅▃▃▁▁▆▃▁█▃
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue ▁▂▃▃▄▆▆▅▅█
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue █▅▂▂▂▃▂▃▁▁
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue █▄▄▄▄▄▄▂▂▁
wandb:                                 Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 2e-05
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 0.00542
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.20888
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.13661
wandb:                                 Train loss 1e-05
wandb: 
wandb: 🚀 View run expert-music-1045 at: https://wandb.ai/nreints/ThesisFinal2/runs/gdh2htbh
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_185103-gdh2htbh/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_190020-dmsxu0dh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run denim-firebrand-1068
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/dmsxu0dh
	 Logging train Loss: 3.05993e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.3999e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1380290538 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.005300445 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.2094519585 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 37.70803761482239
Epoch 4/9
	 Logging train Loss: 2.10125e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.3258e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1379494667 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0053126393 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.2097211033 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 38.28804612159729
Epoch 5/9
	 Logging train Loss: 2.22735e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.33022e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1377757639 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0053557782 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.2104819417 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 38.75608158111572
Epoch 6/9
	 Logging train Loss: 2.51508e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.89466e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1377712935 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0053679561 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.2098710388 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 37.8394136428833
Epoch 7/9
	 Logging train Loss: 1.77474e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.9914e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1371415854 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0053445701 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.2105141729 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 38.6354284286499
Epoch 8/9
	 Logging train Loss: 2.0695e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.10149e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1371530741 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0053444658 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.2087449878 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 38.33315062522888
Epoch 9/9
	 Logging train Loss: 9.7498e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.84745e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1366123408 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0054163439 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.2088813633 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 38.45496582984924
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'log_dualQ'_'True'.pth
It took  556.2162611484528  seconds.
----- ITERATION 6/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 82.74683284759521 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 20.598363161087036 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 20.678487539291382 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 20.75350546836853 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 20.601684093475342 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(6, 96, batch_first=True)
  (pre_hidden_lin_layer): Sequential(
    (0): Linear(in_features=3, out_features=96, bias=True)
    (1): ReLU()
    (2): Linear(in_features=96, out_features=96, bias=True)
    (3): ReLU()
  )
  (fc): Linear(in_features=96, out_features=6, bias=True)
)
Datatype: log_dualQ
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.031720493 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.7174e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1917271316 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0067576086 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.1861107498 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 37.594181299209595
Epoch 1/9
	 Logging train Loss: 3.07713e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.04532e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1905019879 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0067246915 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.1832045317 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 37.51017618179321
Epoch 2/9
	 Logging train Loss: 2.54283e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.9823e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1898135096 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0067476393 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.1811399907 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 37.63252019882202
Epoch 3/9
	 Logging train Loss: 2.52231e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.39159e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1885310262 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0067058923 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.1801380515 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 38.181586027145386
Epoch 4/9
	 Logging train Loss: 2.70421e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.5573e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1885139942 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.006678977 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.1800758541 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 38.258556842803955
Epoch 5/9
	 Logging train Loss: 2.52352e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.75478e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1876783073 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.006696735 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.1806963384 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 38.60959529876709
Epoch 6/9
	 Logging train Loss: 1.97682e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.6678e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1874530911 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0066497372 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.1805377752 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 38.310696601867676
Epoch 7/9
	 Logging train Loss: 1.92752e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.63031e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1875846237 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0066517917 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.1805146635 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 38.50463676452637
Epoch 8/9
	 Logging train Loss: 2.29588e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.0735e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.186093539 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0065946151 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.1803032756 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 38.49069404602051
Epoch 9/9
	 Logging train Loss: 1.1519e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue ▆▂▄▃▁▂▁█▁▂
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue █▇█▆▅▆▄▄▂▁
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue █▅▂▁▁▂▂▂▁▁
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue █▇▆▄▄▃▃▃▁▁
wandb:                                 Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 1e-05
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 0.00655
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.18044
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.18596
wandb:                                 Train loss 1e-05
wandb: 
wandb: 🚀 View run denim-firebrand-1068 at: https://wandb.ai/nreints/ThesisFinal2/runs/dmsxu0dh
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_190020-dmsxu0dh/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_190946-d54x285m
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run laced-pyramid-1085
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/d54x285m
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue ▁▁▁▁▁▁▁█▁▁
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue ▆▅▅▄▄▃▂█▁▁
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue ██▇▆▅▃▃▁▁▁
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue ██▇▆▅▃▄▄▁▁
wandb:                                 Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 1e-05
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 0.00569
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.19545
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.10801
wandb:                                 Train loss 1e-05
wandb: 
wandb: 🚀 View run laced-pyramid-1085 at: https://wandb.ai/nreints/ThesisFinal2/runs/d54x285m
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_190946-d54x285m/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_191908-d6i18dom
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run classic-sunset-1101
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/d6i18dom
	 Logging test loss: 1.21789e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1859599501 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0065522487 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.1804402769 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 38.435765981674194
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'log_dualQ'_'True'.pth
It took  566.2279908657074  seconds.
----- ITERATION 7/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 83.199716091156 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 20.831998109817505 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 20.844097137451172 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 20.62979531288147 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 20.642218112945557 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(6, 96, batch_first=True)
  (pre_hidden_lin_layer): Sequential(
    (0): Linear(in_features=3, out_features=96, bias=True)
    (1): ReLU()
    (2): Linear(in_features=96, out_features=96, bias=True)
    (3): ReLU()
  )
  (fc): Linear(in_features=96, out_features=6, bias=True)
)
Datatype: log_dualQ
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0258699208 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.90089e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1123635545 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0059567913 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.2093093097 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 37.65398836135864
Epoch 1/9
	 Logging train Loss: 1.96835e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.15203e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1125753969 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0059290566 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.2087708712 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 38.35170602798462
Epoch 2/9
	 Logging train Loss: 2.49718e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.57722e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1117098033 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.005916947 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.2069323063 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 38.602049589157104
Epoch 3/9
	 Logging train Loss: 2.57819e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.5864e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1113006175 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0058713658 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.2053107172 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 38.2774760723114
Epoch 4/9
	 Logging train Loss: 2.13729e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.21993e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1107674316 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0058389367 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.2032433599 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 38.29815363883972
Epoch 5/9
	 Logging train Loss: 2.81561e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.129e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1095072776 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0057945885 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.2000076026 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 38.25656318664551
Epoch 6/9
	 Logging train Loss: 1.13732e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.511e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1101165339 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0057606245 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.1990842074 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 38.404250621795654
Epoch 7/9
	 Logging train Loss: 1.68119e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0009740816 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1100869253 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0060817571 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.1957747042 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 38.56932544708252
Epoch 8/9
	 Logging train Loss: 1.78025e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.3997e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1080701128 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0057103485 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.19556427 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 38.26306986808777
Epoch 9/9
	 Logging train Loss: 1.18282e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.846e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1080061644 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0056910571 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.1954520345 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 38.105756759643555
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'log_dualQ'_'True'.pth
It took  561.7068576812744  seconds.
----- ITERATION 8/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 82.91571497917175 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 20.76405954360962 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 20.77156710624695 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 20.667150735855103 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 20.54092526435852 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(6, 96, batch_first=True)
  (pre_hidden_lin_layer): Sequential(
    (0): Linear(in_features=3, out_features=96, bias=True)
    (1): ReLU()
    (2): Linear(in_features=96, out_features=96, bias=True)
    (3): ReLU()
  )
  (fc): Linear(in_features=96, out_features=6, bias=True)
)
Datatype: log_dualQ
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0279129464 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.79534e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.2582414448 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0058714645 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.1807121485 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 38.335364818573
Epoch 1/9
	 Logging train Loss: 1.62486e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.51361e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.2540922463 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0058817123 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.1759954393 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 38.47548460960388
Epoch 2/9
	 Logging train Loss: 2.00174e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.5308e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.2499112785 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.005888911 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue ▄█▂▁▁▃▂▁▄▁
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue ▁▁▂▂▄▅▆▆██
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue █▅▄▃▂▂▂▂▁▁
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue █▇▆▅▄▄▃▂▂▁
wandb:                                 Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 0.00607
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.16766
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.2334
wandb:                                 Train loss 1e-05
wandb: 
wandb: 🚀 View run classic-sunset-1101 at: https://wandb.ai/nreints/ThesisFinal2/runs/d6i18dom
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_191908-d6i18dom/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_192828-jsazxg3y
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run still-butterfly-1113
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/jsazxg3y
	 Logging test loss: 0.1732122004 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 38.283793210983276
Epoch 3/9
	 Logging train Loss: 1.89312e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.8928e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.2476793081 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0059029385 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.1719376147 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 38.268269300460815
Epoch 4/9
	 Logging train Loss: 1.92877e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.6717e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.2436602265 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0059526139 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.170184955 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 38.278592109680176
Epoch 5/9
	 Logging train Loss: 1.72566e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.07694e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.2434265912 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0059731333 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.169331342 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 38.51239562034607
Epoch 6/9
	 Logging train Loss: 1.3942e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.9384e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.2398623228 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0060002417 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.1688920707 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 38.29189586639404
Epoch 7/9
	 Logging train Loss: 1.72664e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 9.839e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.2378087044 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0060104998 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.1699865758 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 38.26693272590637
Epoch 8/9
	 Logging train Loss: 1.26867e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.90304e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.235697642 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0060650944 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.1680759788 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 38.49187421798706
Epoch 9/9
	 Logging train Loss: 1.383e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 9.891e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.233401835 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0060674106 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.1676615775 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 37.13381910324097
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'log_dualQ'_'True'.pth
It took  560.4700214862823  seconds.
----- ITERATION 9/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 82.73407077789307 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 20.794610261917114 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 20.629101037979126 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 20.73302435874939 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 20.704302072525024 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(6, 96, batch_first=True)
  (pre_hidden_lin_layer): Sequential(
    (0): Linear(in_features=3, out_features=96, bias=True)
    (1): ReLU()
    (2): Linear(in_features=96, out_features=96, bias=True)
    (3): ReLU()
  )
  (fc): Linear(in_features=96, out_features=6, bias=True)
)
Datatype: log_dualQ
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0418072045 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.51963e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.2740736902 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.006325487 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.3072459102 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 37.13500356674194
Epoch 1/9
	 Logging train Loss: 3.18139e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.13335e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.2680684924 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.006248842 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.301874578 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 37.07406449317932
Epoch 2/9
	 Logging train Loss: 3.14627e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.07086e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.2668329477 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0062219216 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.2983703613 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 37.385515213012695
Epoch 3/9
	 Logging train Loss: 2.64202e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.84488e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.2648670673 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0062155291 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.2982797921 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 37.30830931663513
Epoch 4/9
	 Logging train Loss: 2.51261e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.87835e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.2636227906 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0062193144 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.2958715558 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 36.899505853652954
Epoch 5/9
	 Logging train Loss: 2.67758e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.9753e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.2627792656 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0062100384 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.2960925102 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 37.04069375991821
Epoch 6/9
	 Logging train Loss: 1.97086e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0001001613 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.2603531182 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0062718354 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.2945206761 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 37.39050626754761
Epoch 7/9
	 Logging train Loss: 2.22731e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.5119e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.2587807178 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0062021422 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.2923240662 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 37.07637071609497
Epoch 8/9
	 Logging train Loss: 2.10857e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.387e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.2573634684 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.006262816 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.2927279174 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue ▃▃▂▂▅▁█▃▁▂
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue █▄▂▂▂▁▅▁▄▂
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue █▆▄▄▃▄▃▂▂▁
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue █▆▅▅▄▄▃▂▂▁
wandb:                                 Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 2e-05
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 0.00623
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.28965
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.25552
wandb:                                 Train loss 1e-05
wandb: 
wandb: 🚀 View run still-butterfly-1113 at: https://wandb.ai/nreints/ThesisFinal2/runs/jsazxg3y
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_192828-jsazxg3y/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_193736-909ha5wh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run celestial-dust-1119
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/909ha5wh
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue ▂▂▁▁▁▁▁▁█▁
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue ▅▄▂▂▁▂▁▃█▂
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue █▇▆▅▅▄▅▂▂▁
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue █▆▅▅▄▅▄▃▃▁
wandb:                                 Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 0.00608
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.18162
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.29519
wandb:                                 Train loss 2e-05
wandb: 
wandb: 🚀 View run celestial-dust-1119 at: https://wandb.ai/nreints/ThesisFinal2/runs/909ha5wh
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_193736-909ha5wh/logs
		--> Epoch time; 37.1303391456604
Epoch 9/9
	 Logging train Loss: 1.17949e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.50863e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.255515784 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0062255249 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.2896502316 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 37.217344760894775
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'log_dualQ'_'True'.pth
It took  548.0574860572815  seconds.
----- ITERATION 10/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 83.0634388923645 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 20.673983573913574 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 20.65581464767456 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 20.7242751121521 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 20.82064700126648 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(6, 96, batch_first=True)
  (pre_hidden_lin_layer): Sequential(
    (0): Linear(in_features=3, out_features=96, bias=True)
    (1): ReLU()
    (2): Linear(in_features=96, out_features=96, bias=True)
    (3): ReLU()
  )
  (fc): Linear(in_features=96, out_features=6, bias=True)
)
Datatype: log_dualQ
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.032606937 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.97617e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.3105635643 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0061375266 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.1912496537 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 37.026604890823364
Epoch 1/9
	 Logging train Loss: 3.1164e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.97692e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.3068289161 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0061087473 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.1898340434 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 36.92790126800537
Epoch 2/9
	 Logging train Loss: 2.49424e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.9097e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.3043516874 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0060870568 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.1881652027 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 36.94042778015137
Epoch 3/9
	 Logging train Loss: 2.89157e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.8759e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.3033140898 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0060745338 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.1875403076 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 37.02598690986633
Epoch 4/9
	 Logging train Loss: 2.05328e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.3347e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.3016537726 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0060669347 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.186849013 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 36.74933981895447
Epoch 5/9
	 Logging train Loss: 1.8348e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.7931e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.3044484258 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0060798693 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.1854399592 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 36.960453271865845
Epoch 6/9
	 Logging train Loss: 1.84332e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.0852e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.3015406728 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0060628182 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.1869195253 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 36.97615599632263
Epoch 7/9
	 Logging train Loss: 1.89516e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.445e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.2992502749 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0060916855 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.1835785359 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 36.89020609855652
Epoch 8/9
	 Logging train Loss: 1.28625e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.000234551 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.2987371385 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0061835828 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.1826749295 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 36.7366099357605
Epoch 9/9
	 Logging train Loss: 1.65806e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 9.865e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.2951880693 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0060779825 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.1816237718 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 36.67813539505005
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'log_dualQ'_'True'.pth
It took  546.1504364013672  seconds.

JOB STATISTICS
==============
Job ID: 3038015
Array Job ID: 3037875_41
Cluster: snellius
User/Group: nreints/nreints
State: RUNNING
Nodes: 1
Cores per node: 18
CPU Utilized: 01:40:25
CPU Efficiency: 6.01% of 1-03:52:12 core-walltime
Job Wall-clock time: 01:32:54
Memory Utilized: 7.51 GB
Memory Efficiency: 0.00% of 0.00 MB
WARNING: Efficiency statistics may be misleading for RUNNING jobs.
