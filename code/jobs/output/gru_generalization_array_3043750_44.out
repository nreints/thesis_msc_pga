wandb: Currently logged in as: nreints. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230710_170033-3gruaxou
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fiery-sound-1252
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/3gruaxou
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                     Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb: Test loss tennis_pNone_gNone_tennisEffect â–ˆâ–†â–„â–‚â–‚â–â–â–â–‚â–
wandb:                                Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                     Epoch 9
wandb: Test loss tennis_pNone_gNone_tennisEffect 1e-05
wandb:                                Train loss 1e-05
wandb: 
wandb: ðŸš€ View run fiery-sound-1252 at: https://wandb.ai/nreints/ThesisFinal2/runs/3gruaxou
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230710_170033-3gruaxou/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230710_170639-y2viuz9t
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run apricot-field-1266
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/y2viuz9t
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                     Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb: Test loss tennis_pNone_gNone_tennisEffect â–†â–ˆâ–‚â–‚â–â–â–â–‚â–â–
wandb:                                Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                     Epoch 9
wandb: Test loss tennis_pNone_gNone_tennisEffect 1e-05
wandb:                                Train loss 1e-05
wandb: 
wandb: ðŸš€ View run apricot-field-1266 at: https://wandb.ai/nreints/ThesisFinal2/runs/y2viuz9t
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230710_170639-y2viuz9t/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230710_171236-c39e4auz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run noble-donkey-1278
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/c39e4auz
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                     Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb: Test loss tennis_pNone_gNone_tennisEffect â–ˆâ–‡â–‚â–ƒâ–â–‚â–â–â–â–
wandb:                                Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                     Epoch 9
wandb: Test loss tennis_pNone_gNone_tennisEffect 1e-05
wandb:                                Train loss 1e-05
wandb: 
wandb: ðŸš€ View run noble-donkey-1278 at: https://wandb.ai/nreints/ThesisFinal2/runs/c39e4auz
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230710_171236-c39e4auz/logs
Training on dataset: data_tennis_pNone_gNone_tennisEffect
Testing on 1 datasets: ['data_tennis_pNone_gNone_tennisEffect']
Focussing on identity: True
Using extra input: False
Using fr-fr as reference point.
----- ITERATION 1/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 52.60909461975098 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 13.15140962600708 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0011466739 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 3.72215e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 28.50368642807007
Epoch 1/9
	 Logging train Loss: 3.0299e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.82102e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 28.281802654266357
Epoch 2/9
	 Logging train Loss: 2.35426e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.07176e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 28.196494102478027
Epoch 3/9
	 Logging train Loss: 1.68827e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.25549e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 28.880776405334473
Epoch 4/9
	 Logging train Loss: 1.30335e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.11191e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 28.7724928855896
Epoch 5/9
	 Logging train Loss: 1.15409e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 9.3259e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 28.578741312026978
Epoch 6/9
	 Logging train Loss: 1.07469e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 8.4849e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 28.775500774383545
Epoch 7/9
	 Logging train Loss: 9.937e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 9.6871e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 28.582072973251343
Epoch 8/9
	 Logging train Loss: 9.4987e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.06611e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 28.7384672164917
Epoch 9/9
	 Logging train Loss: 9.1715e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 8.9032e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 28.425766229629517
Saved model in  trained_models/gru/data_tennis_pNone_gNone_tennisEffect/'rot_mat_1'_'False'.pth
It took  367.5394673347473  seconds.
----- ITERATION 2/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 50.42480945587158 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 12.491792678833008 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0009457137 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 3.64227e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 28.29900336265564
Epoch 1/9
	 Logging train Loss: 3.02759e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 4.69271e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 28.641263246536255
Epoch 2/9
	 Logging train Loss: 2.07044e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.40591e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 28.147599458694458
Epoch 3/9
	 Logging train Loss: 1.50662e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.46165e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 28.204329013824463
Epoch 4/9
	 Logging train Loss: 1.2686e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 9.1684e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 28.23084020614624
Epoch 5/9
	 Logging train Loss: 1.11087e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 9.2957e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 28.516176223754883
Epoch 6/9
	 Logging train Loss: 1.01721e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 9.0488e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 28.35695195198059
Epoch 7/9
	 Logging train Loss: 9.8418e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.25115e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 28.66928267478943
Epoch 8/9
	 Logging train Loss: 9.3203e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 8.0971e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 28.403920888900757
Epoch 9/9
	 Logging train Loss: 9.1016e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 8.9454e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 28.636672735214233
Saved model in  trained_models/gru/data_tennis_pNone_gNone_tennisEffect/'rot_mat_1'_'False'.pth
It took  357.07985973358154  seconds.
----- ITERATION 3/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 48.529491662979126 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 12.298211812973022 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0011144739 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 3.67926e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 29.091513633728027
Epoch 1/9
	 Logging train Loss: 3.12327e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 3.16471e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 29.11765146255493
Epoch 2/9
	 Logging train Loss: 2.17051e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.40552e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 28.849499940872192
Epoch 3/9
	 Logging train Loss: 1.52867e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.49234e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 28.71598792076111
Epoch 4/9
	 Logging train Loss: 1.27222e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.06618e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 29.098479509353638
Epoch 5/9
	 Logging train Loss: 1.12787e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.13504e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 28.88782000541687
Epoch 6/9
	 Logging train Loss: 1.02462e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 9.1447e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 29.115875720977783
Epoch 7/9
	 Logging train Loss: 9.7751e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 9.4551e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 29.03420901298523
Epoch 8/9
	 Logging train Loss: 9.263e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 8.6919e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 28.991918802261353
Epoch 9/9
	 Logging train Loss: 8.9767e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 8.8628e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 29.082996368408203
Saved model in  trained_models/gru/data_tennis_pNone_gNone_tennisEffect/'rot_mat_1'_'False'.pth
It took  392.4591906070709  seconds.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230710_171909-hfqk12pw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run crimson-jazz-1293
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/hfqk12pw
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                     Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb: Test loss tennis_pNone_gNone_tennisEffect â–ˆâ–„â–„â–â–‚â–â–â–â–â–
wandb:                                Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                     Epoch 9
wandb: Test loss tennis_pNone_gNone_tennisEffect 1e-05
wandb:                                Train loss 1e-05
wandb: 
wandb: ðŸš€ View run crimson-jazz-1293 at: https://wandb.ai/nreints/ThesisFinal2/runs/hfqk12pw
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230710_171909-hfqk12pw/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230710_172510-62kbcg9r
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fine-darkness-1310
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/62kbcg9r
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                     Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb: Test loss tennis_pNone_gNone_tennisEffect â–†â–ˆâ–‚â–‚â–ƒâ–â–â–â–â–
wandb:                                Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                     Epoch 9
wandb: Test loss tennis_pNone_gNone_tennisEffect 1e-05
wandb:                                Train loss 1e-05
wandb: 
wandb: ðŸš€ View run fine-darkness-1310 at: https://wandb.ai/nreints/ThesisFinal2/runs/62kbcg9r
wandb: Synced 7 W&B file(s), 0 media file(s), 1 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230710_172510-62kbcg9r/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230710_173107-l9dquatg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sunny-sky-1326
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/l9dquatg
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                     Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb: Test loss tennis_pNone_gNone_tennisEffect â–ˆâ–„â–‚â–‚â–â–‚â–‚â–â–â–
wandb:                                Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                     Epoch 9
wandb: Test loss tennis_pNone_gNone_tennisEffect 1e-05
wandb:                                Train loss 1e-05
wandb: 
wandb: ðŸš€ View run sunny-sky-1326 at: https://wandb.ai/nreints/ThesisFinal2/runs/l9dquatg
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230710_173107-l9dquatg/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230710_173708-ifx9z9vs
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run olive-pyramid-1339
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/ifx9z9vs
----- ITERATION 4/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 48.6155903339386 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 12.23360013961792 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0009674995 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 4.104e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 29.26996350288391
Epoch 1/9
	 Logging train Loss: 3.07703e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.1352e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 29.25508427619934
Epoch 2/9
	 Logging train Loss: 2.21155e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.42435e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 29.000493049621582
Epoch 3/9
	 Logging train Loss: 1.49955e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.0052e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 28.724907636642456
Epoch 4/9
	 Logging train Loss: 1.25296e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.22882e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 28.99241542816162
Epoch 5/9
	 Logging train Loss: 1.12325e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 9.4295e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 29.06928253173828
Epoch 6/9
	 Logging train Loss: 1.05583e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.00005e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 28.95908832550049
Epoch 7/9
	 Logging train Loss: 9.7113e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 8.4573e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 28.89594292640686
Epoch 8/9
	 Logging train Loss: 9.3143e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 8.595e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 29.20463275909424
Epoch 9/9
	 Logging train Loss: 9.2171e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 9.3233e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 29.026836395263672
Saved model in  trained_models/gru/data_tennis_pNone_gNone_tennisEffect/'rot_mat_1'_'False'.pth
It took  361.1593313217163  seconds.
----- ITERATION 5/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 49.811933755874634 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 12.464649438858032 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0013465508 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 3.29127e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 27.800970792770386
Epoch 1/9
	 Logging train Loss: 3.0203e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 4.36071e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 27.863267421722412
Epoch 2/9
	 Logging train Loss: 2.32024e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.31362e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 27.73731279373169
Epoch 3/9
	 Logging train Loss: 1.62608e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.24533e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 28.32968759536743
Epoch 4/9
	 Logging train Loss: 1.29747e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.83229e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 28.613707780838013
Epoch 5/9
	 Logging train Loss: 1.2174e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.04619e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 28.35409927368164
Epoch 6/9
	 Logging train Loss: 1.00587e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 8.6658e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 28.687405109405518
Epoch 7/9
	 Logging train Loss: 1.00073e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 9.4313e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 28.585004806518555
Epoch 8/9
	 Logging train Loss: 9.4545e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 8.5672e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 28.962419271469116
Epoch 9/9
	 Logging train Loss: 9.2444e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 9.2544e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 28.840553998947144
Saved model in  trained_models/gru/data_tennis_pNone_gNone_tennisEffect/'rot_mat_1'_'False'.pth
It took  357.26468443870544  seconds.
----- ITERATION 6/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 49.61986541748047 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 12.520183563232422 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0009250576 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 3.43926e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 28.571772575378418
Epoch 1/9
	 Logging train Loss: 2.94771e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.12684e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 28.44304347038269
Epoch 2/9
	 Logging train Loss: 2.0499e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.11498e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 28.622169733047485
Epoch 3/9
	 Logging train Loss: 1.46287e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.24843e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 28.517826318740845
Epoch 4/9
	 Logging train Loss: 1.20145e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 9.6236e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 28.548415422439575
Epoch 5/9
	 Logging train Loss: 1.08379e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.13877e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 28.660605430603027
Epoch 6/9
	 Logging train Loss: 1.03447e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.1002e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 28.497127771377563
Epoch 7/9
	 Logging train Loss: 9.3967e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 8.676e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 28.722949266433716
Epoch 8/9
	 Logging train Loss: 9.1167e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 8.7145e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 28.41220712661743
Epoch 9/9
	 Logging train Loss: 9.0207e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 8.9472e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 28.784551858901978
Saved model in  trained_models/gru/data_tennis_pNone_gNone_tennisEffect/'rot_mat_1'_'False'.pth
It took  360.75062465667725  seconds.
----- ITERATION 7/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 48.76127052307129 seconds.
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                     Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb: Test loss tennis_pNone_gNone_tennisEffect â–ˆâ–„â–ƒâ–‚â–â–â–ƒâ–â–â–
wandb:                                Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                     Epoch 9
wandb: Test loss tennis_pNone_gNone_tennisEffect 1e-05
wandb:                                Train loss 1e-05
wandb: 
wandb: ðŸš€ View run olive-pyramid-1339 at: https://wandb.ai/nreints/ThesisFinal2/runs/ifx9z9vs
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230710_173708-ifx9z9vs/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230710_174309-y8r0pnek
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run genial-voice-1354
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/y8r0pnek
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                     Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb: Test loss tennis_pNone_gNone_tennisEffect â–ˆâ–„â–„â–â–â–â–â–â–â–
wandb:                                Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                     Epoch 9
wandb: Test loss tennis_pNone_gNone_tennisEffect 1e-05
wandb:                                Train loss 1e-05
wandb: 
wandb: ðŸš€ View run genial-voice-1354 at: https://wandb.ai/nreints/ThesisFinal2/runs/y8r0pnek
wandb: Synced 7 W&B file(s), 0 media file(s), 1 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230710_174309-y8r0pnek/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230710_174912-fvqhej3m
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run denim-resonance-1363
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/fvqhej3m
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                     Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb: Test loss tennis_pNone_gNone_tennisEffect â–ˆâ–…â–ˆâ–„â–â–‚â–‚â–â–â–
wandb:                                Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                     Epoch 9
wandb: Test loss tennis_pNone_gNone_tennisEffect 1e-05
wandb:                                Train loss 1e-05
wandb: 
wandb: ðŸš€ View run denim-resonance-1363 at: https://wandb.ai/nreints/ThesisFinal2/runs/fvqhej3m
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230710_174912-fvqhej3m/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230710_175517-y9ug5rkm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rare-mountain-1370
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/y9ug5rkm
-- Finished Train Dataloader --
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 12.390094757080078 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0008955254 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 3.57993e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 29.15703511238098
Epoch 1/9
	 Logging train Loss: 3.25634e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.17583e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 28.613343954086304
Epoch 2/9
	 Logging train Loss: 2.34479e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.4223e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 28.649630546569824
Epoch 3/9
	 Logging train Loss: 1.65581e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.02742e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 29.08814287185669
Epoch 4/9
	 Logging train Loss: 1.26376e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 8.8277e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 28.579800367355347
Epoch 5/9
	 Logging train Loss: 1.10578e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 8.9394e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 29.025684118270874
Epoch 6/9
	 Logging train Loss: 1.0236e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.42619e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 28.698452711105347
Epoch 7/9
	 Logging train Loss: 9.7684e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 8.4713e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 28.86120295524597
Epoch 8/9
	 Logging train Loss: 9.2828e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 8.4767e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 28.98805832862854
Epoch 9/9
	 Logging train Loss: 9.158e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 8.1031e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 29.068294286727905
Saved model in  trained_models/gru/data_tennis_pNone_gNone_tennisEffect/'rot_mat_1'_'False'.pth
It took  361.3620536327362  seconds.
----- ITERATION 8/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 48.51920247077942 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 12.309097290039062 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0008378844 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 3.80126e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 29.21348476409912
Epoch 1/9
	 Logging train Loss: 3.23728e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.08465e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 28.781476974487305
Epoch 2/9
	 Logging train Loss: 2.17625e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.26777e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 29.111322164535522
Epoch 3/9
	 Logging train Loss: 1.50946e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 9.3534e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 28.876399040222168
Epoch 4/9
	 Logging train Loss: 1.22297e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 8.9641e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 29.229697704315186
Epoch 5/9
	 Logging train Loss: 1.13212e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 8.0629e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 28.807169914245605
Epoch 6/9
	 Logging train Loss: 1.03315e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 9.2101e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 28.900607109069824
Epoch 7/9
	 Logging train Loss: 9.7433e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 8.9769e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 29.01042890548706
Epoch 8/9
	 Logging train Loss: 9.449e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 7.6933e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 29.31773591041565
Epoch 9/9
	 Logging train Loss: 9.257e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 9.0668e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 29.24586033821106
Saved model in  trained_models/gru/data_tennis_pNone_gNone_tennisEffect/'rot_mat_1'_'False'.pth
It took  362.44847536087036  seconds.
----- ITERATION 9/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 48.686020851135254 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 12.293567419052124 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0008849331 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 3.60907e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 28.563215255737305
Epoch 1/9
	 Logging train Loss: 3.12235e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.52996e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 28.980528831481934
Epoch 2/9
	 Logging train Loss: 2.26457e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 3.61937e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 29.13546061515808
Epoch 3/9
	 Logging train Loss: 1.63936e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.96778e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 29.1941499710083
Epoch 4/9
	 Logging train Loss: 1.23018e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 9.2879e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 29.163132667541504
Epoch 5/9
	 Logging train Loss: 1.14642e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.29555e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 29.210809230804443
Epoch 6/9
	 Logging train Loss: 9.9678e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.14308e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 29.439526557922363
Epoch 7/9
	 Logging train Loss: 9.8214e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 9.044e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 28.827565670013428
Epoch 8/9
	 Logging train Loss: 9.2712e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 8.6691e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 29.013055086135864
Epoch 9/9
	 Logging train Loss: 8.9551e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 9.9745e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 28.715752124786377
Saved model in  trained_models/gru/data_tennis_pNone_gNone_tennisEffect/'rot_mat_1'_'False'.pth
It took  365.24509739875793  seconds.
----- ITERATION 10/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 48.61919331550598 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 12.270849704742432 seconds.
-- Finished Test Dataloader(s) --
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                     Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb: Test loss tennis_pNone_gNone_tennisEffect â–ˆâ–…â–ƒâ–‚â–‚â–â–‚â–â–â–
wandb:                                Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                     Epoch 9
wandb: Test loss tennis_pNone_gNone_tennisEffect 1e-05
wandb:                                Train loss 1e-05
wandb: 
wandb: ðŸš€ View run rare-mountain-1370 at: https://wandb.ai/nreints/ThesisFinal2/runs/y9ug5rkm
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230710_175517-y9ug5rkm/logs
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0008671575 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 3.19041e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 28.86417531967163
Epoch 1/9
	 Logging train Loss: 3.16207e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.34874e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 28.87875533103943
Epoch 2/9
	 Logging train Loss: 2.26278e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.4463e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 28.77028799057007
Epoch 3/9
	 Logging train Loss: 1.53022e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.10484e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 28.951235055923462
Epoch 4/9
	 Logging train Loss: 1.21696e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.07633e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 28.919837713241577
Epoch 5/9
	 Logging train Loss: 1.09869e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 9.6981e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 28.75376534461975
Epoch 6/9
	 Logging train Loss: 1.01397e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.04893e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 28.995165586471558
Epoch 7/9
	 Logging train Loss: 9.5589e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 9.8779e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 28.8101749420166
Epoch 8/9
	 Logging train Loss: 9.3489e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.0019e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 29.141488790512085
Epoch 9/9
	 Logging train Loss: 8.9644e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 8.6664e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 28.86592149734497
Saved model in  trained_models/gru/data_tennis_pNone_gNone_tennisEffect/'rot_mat_1'_'False'.pth
It took  362.9271969795227  seconds.

JOB STATISTICS
==============
Job ID: 3043755
Array Job ID: 3043750_44
Cluster: snellius
User/Group: nreints/nreints
State: RUNNING
Nodes: 1
Cores per node: 18
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 18:19:12 core-walltime
Job Wall-clock time: 01:01:04
Memory Utilized: 0.00 MB (estimated maximum)
Memory Efficiency: 0.00% of 0.00 MB (0.00 MB/node)
WARNING: Efficiency statistics may be misleading for RUNNING jobs.
