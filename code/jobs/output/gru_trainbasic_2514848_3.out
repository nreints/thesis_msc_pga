wandb: Currently logged in as: nreints. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230329_135636-svl2krcl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run solar-breeze-532
wandb: â­ï¸ View project at https://wandb.ai/nreints/test
wandb: ðŸš€ View run at https://wandb.ai/nreints/test/runs/svl2krcl
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.031 MB of 0.031 MB uploaded (0.000 MB deduped)wandb: \ 0.031 MB of 0.078 MB uploaded (0.000 MB deduped)wandb: | 0.078 MB of 0.078 MB uploaded (0.000 MB deduped)wandb: / 0.078 MB of 0.078 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:                                                  Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb: Test loss t(0, 0)_r(5, 20)_semi_pNone_gNone, MSELoss() â–ˆâ–ƒâ–„â–„â–ƒâ–‚â–‚â–â–â–â–
wandb:                                             Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                                  Epoch 9
wandb: Test loss t(0, 0)_r(5, 20)_semi_pNone_gNone, MSELoss() 0.02833
wandb:                                             Train loss 0.03754
wandb: 
wandb: ðŸš€ View run solar-breeze-532 at: https://wandb.ai/nreints/test/runs/svl2krcl
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230329_135636-svl2krcl/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230329_140444-hhpzumut
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run classic-pond-550
wandb: â­ï¸ View project at https://wandb.ai/nreints/test
wandb: ðŸš€ View run at https://wandb.ai/nreints/test/runs/hhpzumut
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.031 MB of 0.031 MB uploaded (0.000 MB deduped)wandb: \ 0.031 MB of 0.078 MB uploaded (0.000 MB deduped)wandb: | 0.031 MB of 0.078 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:                                                  Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb: Test loss t(0, 0)_r(5, 20)_semi_pNone_gNone, MSELoss() â–ˆâ–„â–„â–ƒâ–‚â–‚â–‚â–‚â–â–â–
wandb:                                             Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                                  Epoch 9
wandb: Test loss t(0, 0)_r(5, 20)_semi_pNone_gNone, MSELoss() 0.03196
wandb:                                             Train loss 0.03786
wandb: 
wandb: ðŸš€ View run classic-pond-550 at: https://wandb.ai/nreints/test/runs/hhpzumut
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230329_140444-hhpzumut/logs
Running for data type: quat
----- ITERATION 1/2 ------
Number of train simulations: 1600
Number of test simulations: 400
-- Finished Train Dataloader --
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
-- Started Training --
Epoch 0
	 Logging train Loss: 13.2636171145 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss: 0.23825088143348694 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
     --> Epoch time; 43.282225608825684
Epoch 1
	 Logging train Loss: 0.140061749 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss: 0.10073039680719376 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
     --> Epoch time; 41.234601736068726
Epoch 2
	 Logging train Loss: 0.1060204703 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss: 0.11307745426893234 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
     --> Epoch time; 41.17932057380676
Epoch 3
	 Logging train Loss: 0.0860668941 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss: 0.12190466374158859 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
     --> Epoch time; 40.70919227600098
Epoch 4
	 Logging train Loss: 0.0743203106 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss: 0.10032328963279724 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
     --> Epoch time; 40.69911980628967
Epoch 5
	 Logging train Loss: 0.0620276702 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss: 0.043495651334524155 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
     --> Epoch time; 41.47451210021973
Epoch 6
	 Logging train Loss: 0.0523950656 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss: 0.06854066252708435 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
     --> Epoch time; 41.40955376625061
Epoch 7
	 Logging train Loss: 0.0449128094 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss: 0.030081911012530327 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
     --> Epoch time; 41.936190366744995
Epoch 8
	 Logging train Loss: 0.0393583147 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss: 0.031937018036842346 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
     --> Epoch time; 44.233261585235596
Epoch 9
	 Logging train Loss: 0.037540339 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss: 0.028323961421847343 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
     --> Epoch time; 43.6905038356781
	 Logging test loss: 0.028328679502010345 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
It took  488.6312212944031  seconds.
----- ITERATION 2/2 ------
Number of train simulations: 1600
Number of test simulations: 400
-- Finished Train Dataloader --
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
-- Started Training --
Epoch 0
	 Logging train Loss: 6.7855024147 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss: 0.21730826795101166 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
     --> Epoch time; 41.456342935562134
Epoch 1
	 Logging train Loss: 0.1409165468 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss: 0.11559554189443588 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
     --> Epoch time; 41.90897297859192
Epoch 2
	 Logging train Loss: 0.1140895787 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss: 0.09903503209352493 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
     --> Epoch time; 42.01376748085022
Epoch 3
	 Logging train Loss: 0.0922895872 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss: 0.07293150573968887 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
     --> Epoch time; 41.53013014793396
Epoch 4
	 Logging train Loss: 0.0767065692 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss: 0.05852210894227028 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
     --> Epoch time; 41.27272319793701
Epoch 5
	 Logging train Loss: 0.0644709762 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss: 0.05695811286568642 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
     --> Epoch time; 41.529003381729126
Epoch 6
	 Logging train Loss: 0.0544680505 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss: 0.0543869286775589 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
     --> Epoch time; 41.46043586730957
Epoch 7
	 Logging train Loss: 0.0474480857 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss: 0.05683022364974022 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
     --> Epoch time; 41.232821226119995
Epoch 8
	 Logging train Loss: 0.0414937482 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss: 0.03457069396972656 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
     --> Epoch time; 41.64703297615051
Epoch 9
	 Logging train Loss: 0.037863888 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss: 0.03193948417901993 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
     --> Epoch time; 41.259482622146606
	 Logging test loss: 0.03195944055914879 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
It took  478.73382115364075  seconds.

JOB STATISTICS
==============
Job ID: 2514851
Array Job ID: 2514848_3
Cluster: snellius
User/Group: nreints/nreints
State: RUNNING
Nodes: 1
Cores per node: 18
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 04:54:00 core-walltime
Job Wall-clock time: 00:16:20
Memory Utilized: 0.00 MB (estimated maximum)
Memory Efficiency: 0.00% of 31.25 GB (31.25 GB/node)
WARNING: Efficiency statistics may be misleading for RUNNING jobs.
