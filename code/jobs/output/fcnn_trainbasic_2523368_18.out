wandb: Currently logged in as: nreints. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home/nreints/.netrc
/gpfs/home2/nreints/MScThesis/code/fcnn.py:566: DeprecationWarning: Sampling from a set deprecated
since Python 3.9 and will be removed in a subsequent version.
  train_sims = set(random.sample(sims_train, int(0.8 * n_sims_train)))
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230330_123650-4dkuqmfy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run icy-gorge-585
wandb: â­ï¸ View project at https://wandb.ai/nreints/test
wandb: ðŸš€ View run at https://wandb.ai/nreints/test/runs/4dkuqmfy
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.029 MB of 0.029 MB uploaded (0.000 MB deduped)wandb: \ 0.029 MB of 0.029 MB uploaded (0.000 MB deduped)wandb: | 0.029 MB of 0.029 MB uploaded (0.000 MB deduped)wandb: / 0.029 MB of 0.029 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  Test loss t(0, 0)_r(5, 20)_tennis L1Loss() â–ˆâ–„â–ƒâ–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: Test loss t(0, 0)_r(5, 20)_tennis MSELoss() â–ˆâ–ƒâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:     Train loss data_t(0, 0)_r(5, 20)_tennis â–ˆâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:  Test loss t(0, 0)_r(5, 20)_tennis L1Loss() 0.88292
wandb: Test loss t(0, 0)_r(5, 20)_tennis MSELoss() 2.19609
wandb:     Train loss data_t(0, 0)_r(5, 20)_tennis 1.94634
wandb: 
wandb: ðŸš€ View run icy-gorge-585 at: https://wandb.ai/nreints/test/runs/4dkuqmfy
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230330_123650-4dkuqmfy/logs
/gpfs/home2/nreints/MScThesis/code/fcnn.py:566: DeprecationWarning: Sampling from a set deprecated
since Python 3.9 and will be removed in a subsequent version.
  train_sims = set(random.sample(sims_train, int(0.8 * n_sims_train)))
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230330_124844-vjldw8oz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dauntless-plant-631
wandb: â­ï¸ View project at https://wandb.ai/nreints/test
wandb: ðŸš€ View run at https://wandb.ai/nreints/test/runs/vjldw8oz
Training on dataset: data/data_t(0, 0)_r(5, 20)_tennis_pNone_gNone
Testing on datasets: ['data_t(0, 0)_r(5, 20)_tennis_pNone_gNone']
----- ITERATION 1/2 ------
Number of train simulations: 1600
Number of test simulations: 400
The dataloader took 61.359251737594604 seconds.
-- Finished Train Dataloader --
The dataloader took 15.19891905784607 seconds.
-- Finished Test Dataloader(s) --
Datatype: log_quat
--- Started Training ---
Epoch 0
	 Logging train Loss: 305.9267565359 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 46.68125915527344 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 4.144180774688721 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 31.964010000228882
Epoch 1
	 Logging train Loss: 23.9418811275 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 16.004310607910156 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 2.2695462703704834 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 32.25665020942688
Epoch 2
	 Logging train Loss: 12.4001365911 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 10.409011840820312 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 1.7769615650177002 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 31.75889277458191
Epoch 3
	 Logging train Loss: 8.6552759906 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 7.75369119644165 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 1.5194284915924072 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 31.678751230239868
Epoch 4
	 Logging train Loss: 6.6870270374 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 6.1689229011535645 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 1.353990077972412 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 31.95307683944702
Epoch 5
	 Logging train Loss: 5.4973332823 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 5.327675819396973 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 1.2822082042694092 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 32.28036046028137
Epoch 6
	 Logging train Loss: 4.6813115936 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 4.445405006408691 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 1.1661313772201538 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 31.864683151245117
Epoch 7
	 Logging train Loss: 4.0998050066 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 3.95931339263916 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 1.1109894514083862 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 31.562429428100586
Epoch 8
	 Logging train Loss: 3.6661359401 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 3.5771095752716064 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 1.0633596181869507 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 31.57306957244873
Epoch 9
	 Logging train Loss: 3.3331811045 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 3.2605044841766357 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 1.0210307836532593 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 29.83742094039917
Epoch 10
	 Logging train Loss: 3.0644700393 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 3.128697395324707 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 1.0120372772216797 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 30.191556453704834
Epoch 11
	 Logging train Loss: 2.8602270987 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 2.9306206703186035 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.9827820062637329 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 30.39233684539795
Epoch 12
	 Logging train Loss: 2.6766338274 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 2.8535315990448 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.9832924008369446 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 29.709750413894653
Epoch 13
	 Logging train Loss: 2.5348733341 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 2.6503212451934814 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.9438465237617493 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 31.66038680076599
Epoch 14
	 Logging train Loss: 2.4034245111 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 2.4666850566864014 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.9106194972991943 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 29.9178786277771
Epoch 15
	 Logging train Loss: 2.2941470078 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 2.499807596206665 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.9317758679389954 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 29.828381538391113
Epoch 16
	 Logging train Loss: 2.2007951325 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 2.345886707305908 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.8994912505149841 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 29.972774267196655
Epoch 17
	 Logging train Loss: 2.1024584801 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 2.204993963241577 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.8744397163391113 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 30.34596347808838
Epoch 18
	 Logging train Loss: 2.0214575674 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 2.1467761993408203 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.8665094971656799 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 30.296921253204346
Epoch 19
	 Logging train Loss: 1.9463393267 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 2.1967358589172363 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.8828467726707458 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 31.597509145736694
	 Logging test loss 2.1960933208465576 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.8829247951507568 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
It took 713.38743019104 seconds to train & eval the model.
----- ITERATION 2/2 ------
Number of train simulations: 1600
Number of test simulations: 400
The dataloader took 55.70600867271423 seconds.
-- Finished Train Dataloader --
The dataloader took 13.899473428726196 seconds.
-- Finished Test Dataloader(s) --
Datatype: log_quat
--- Started Training ---
Epoch 0
	 Logging train Loss: 328.0802083333 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 49.82418441772461 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 4.398045063018799 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 31.82676601409912
Epoch 1
	 Logging train Loss: 25.9899458742 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 15.379307746887207 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 2.24788498878479 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 30.29649782180786
Epoch 2
	 Logging train Loss: 13.2100464665 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 9.876578330993652 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 1.753391981124878 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 30.59981679916382
Epoch 3
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.029 MB of 0.029 MB uploaded (0.000 MB deduped)wandb: \ 0.029 MB of 0.077 MB uploaded (0.000 MB deduped)wandb: | 0.029 MB of 0.077 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  Test loss t(0, 0)_r(5, 20)_tennis L1Loss() â–ˆâ–„â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–
wandb: Test loss t(0, 0)_r(5, 20)_tennis MSELoss() â–ˆâ–ƒâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:     Train loss data_t(0, 0)_r(5, 20)_tennis â–ˆâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:  Test loss t(0, 0)_r(5, 20)_tennis L1Loss() 0.83882
wandb: Test loss t(0, 0)_r(5, 20)_tennis MSELoss() 1.94654
wandb:     Train loss data_t(0, 0)_r(5, 20)_tennis 2.014
wandb: 
wandb: ðŸš€ View run dauntless-plant-631 at: https://wandb.ai/nreints/test/runs/vjldw8oz
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230330_124844-vjldw8oz/logs
	 Logging train Loss: 9.1683306526 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 7.342979907989502 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 1.4957364797592163 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 30.09993290901184
Epoch 4
	 Logging train Loss: 7.0184506485 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 5.878368377685547 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 1.336594581604004 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 32.22005009651184
Epoch 5
	 Logging train Loss: 5.7027439491 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 4.898468494415283 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 1.2263468503952026 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 31.926093339920044
Epoch 6
	 Logging train Loss: 4.8280640446 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 4.354968547821045 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 1.174129605293274 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 32.02478003501892
Epoch 7
	 Logging train Loss: 4.2040718827 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 3.821211338043213 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 1.1101454496383667 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 30.241974592208862
Epoch 8
	 Logging train Loss: 3.7569565717 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 3.5936503410339355 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 1.0940399169921875 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 30.236748695373535
Epoch 9
	 Logging train Loss: 3.4096599903 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 3.2347424030303955 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 1.0335458517074585 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 30.013530254364014
Epoch 10
	 Logging train Loss: 3.1425146165 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 2.900481700897217 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.9870165586471558 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 29.623592853546143
Epoch 11
	 Logging train Loss: 2.9290086933 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 2.876746892929077 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.9964563846588135 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 31.565832376480103
Epoch 12
	 Logging train Loss: 2.7497462852 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 2.62888765335083 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.95237797498703 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 30.560972929000854
Epoch 13
	 Logging train Loss: 2.5987821691 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 2.521505355834961 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.9384948015213013 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 30.54177737236023
Epoch 14
	 Logging train Loss: 2.4729273578 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 2.4168190956115723 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.9223244190216064 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 29.997879028320312
Epoch 15
	 Logging train Loss: 2.360203642 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 2.3305113315582275 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.9116531014442444 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 29.897825717926025
Epoch 16
	 Logging train Loss: 2.2544950597 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 2.1913137435913086 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.8845855593681335 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 31.99763560295105
Epoch 17
	 Logging train Loss: 2.1676885468 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 2.1772427558898926 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.8860078454017639 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 31.363913774490356
Epoch 18
	 Logging train Loss: 2.0795571321 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 2.0548226833343506 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.8619387745857239 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 31.550980806350708
Epoch 19
	 Logging train Loss: 2.0140001085 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 1.9458390474319458 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.8388437628746033 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 30.326134204864502
	 Logging test loss 1.9465421438217163 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.8388243913650513 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
It took 701.4239344596863 seconds to train & eval the model.

JOB STATISTICS
==============
Job ID: 2523386
Array Job ID: 2523368_18
Cluster: snellius
User/Group: nreints/nreints
State: COMPLETED (exit code 0)
Nodes: 1
Cores per node: 18
CPU Utilized: 03:34:20
CPU Efficiency: 49.89% of 07:09:36 core-walltime
Job Wall-clock time: 00:23:52
Memory Utilized: 3.53 GB
Memory Efficiency: 12.04% of 29.30 GB
