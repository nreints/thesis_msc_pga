wandb: Currently logged in as: nreints. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230710_170033-1knfwgze
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fiery-snowflake-1251
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/1knfwgze
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                     Epoch ▁▂▃▃▄▅▆▆▇█
wandb: Test loss tennis_pNone_gNone_tennisEffect █▅▇▃▂▂▂▁▁▁
wandb:                                Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                     Epoch 9
wandb: Test loss tennis_pNone_gNone_tennisEffect 2e-05
wandb:                                Train loss 1e-05
wandb: 
wandb: 🚀 View run fiery-snowflake-1251 at: https://wandb.ai/nreints/ThesisFinal2/runs/1knfwgze
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230710_170033-1knfwgze/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230710_170524-8ows0upr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dulcet-glade-1260
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/8ows0upr
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                     Epoch ▁▂▃▃▄▅▆▆▇█
wandb: Test loss tennis_pNone_gNone_tennisEffect █▆▄▃▃▂▃▁▁▁
wandb:                                Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                     Epoch 9
wandb: Test loss tennis_pNone_gNone_tennisEffect 1e-05
wandb:                                Train loss 1e-05
wandb: 
wandb: 🚀 View run dulcet-glade-1260 at: https://wandb.ai/nreints/ThesisFinal2/runs/8ows0upr
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230710_170524-8ows0upr/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230710_171006-vyfkzx42
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run young-sound-1271
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/vyfkzx42
Training on dataset: data_tennis_pNone_gNone_tennisEffect
Testing on 1 datasets: ['data_tennis_pNone_gNone_tennisEffect']
Focussing on identity: False
Using extra input: True
Using fr-fr as reference point.
----- ITERATION 1/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 60.75627279281616 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 15.327073335647583 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (pre_hidden_lin_layer): Sequential(
    (0): Linear(in_features=3, out_features=96, bias=True)
    (1): ReLU()
    (2): Linear(in_features=96, out_features=96, bias=True)
    (3): ReLU()
  )
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: log_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0020276529 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 8.48946e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 21.096035718917847
Epoch 1/9
	 Logging train Loss: 6.02474e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 4.97582e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.85501766204834
Epoch 2/9
	 Logging train Loss: 4.75656e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 7.11431e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.54101252555847
Epoch 3/9
	 Logging train Loss: 4.1544e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.92066e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.77359414100647
Epoch 4/9
	 Logging train Loss: 3.37925e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.65648e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.75456666946411
Epoch 5/9
	 Logging train Loss: 2.85663e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.40812e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.60193967819214
Epoch 6/9
	 Logging train Loss: 2.29706e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.00597e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.89655590057373
Epoch 7/9
	 Logging train Loss: 1.86869e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.79912e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.545175552368164
Epoch 8/9
	 Logging train Loss: 1.5513e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.29886e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.779223442077637
Epoch 9/9
	 Logging train Loss: 1.34061e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.79322e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.737634658813477
Saved model in  trained_models/gru/data_tennis_pNone_gNone_tennisEffect/'log_quat_1'_'True'.pth
It took  292.1695644855499  seconds.
----- ITERATION 2/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 55.50234413146973 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 14.112243890762329 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (pre_hidden_lin_layer): Sequential(
    (0): Linear(in_features=3, out_features=96, bias=True)
    (1): ReLU()
    (2): Linear(in_features=96, out_features=96, bias=True)
    (3): ReLU()
  )
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: log_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0021974007 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 7.27488e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.803194999694824
Epoch 1/9
	 Logging train Loss: 5.94633e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 5.25077e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 20.40250253677368
Epoch 2/9
	 Logging train Loss: 4.68267e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 4.08151e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 20.383642435073853
Epoch 3/9
	 Logging train Loss: 3.84912e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 3.17574e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 20.04151153564453
Epoch 4/9
	 Logging train Loss: 3.31227e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.81402e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.7949960231781
Epoch 5/9
	 Logging train Loss: 2.62325e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.88098e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.769930601119995
Epoch 6/9
	 Logging train Loss: 2.13659e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.71819e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.89572024345398
Epoch 7/9
	 Logging train Loss: 1.76102e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.33372e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.875389099121094
Epoch 8/9
	 Logging train Loss: 1.48723e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.0355e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.6307475566864
Epoch 9/9
	 Logging train Loss: 1.32138e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.03915e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.94611406326294
Saved model in  trained_models/gru/data_tennis_pNone_gNone_tennisEffect/'log_quat_1'_'True'.pth
It took  281.96426463127136  seconds.
----- ITERATION 3/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 54.13561296463013 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 13.563054084777832 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (pre_hidden_lin_layer): Sequential(
    (0): Linear(in_features=3, out_features=96, bias=True)
    (1): ReLU()
    (2): Linear(in_features=96, out_features=96, bias=True)
    (3): ReLU()
  )
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: log_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0043685199 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 9.75459e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.864237308502197
Epoch 1/9
	 Logging train Loss: 6.09866e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 6.16797e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.529958724975586
Epoch 2/9
	 Logging train Loss: 4.37811e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 5.17051e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.843595027923584
Epoch 3/9
	 Logging train Loss: 3.77858e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 7.68161e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.756681442260742
Epoch 4/9
	 Logging train Loss: 3.2291e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 4.06926e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.992050886154175
Epoch 5/9
	 Logging train Loss: 2.86653e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.30988e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.913695096969604
Epoch 6/9
	 Logging train Loss: 2.26684e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.78257e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.779094696044922
Epoch 7/9
	 Logging train Loss: 1.9924e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                     Epoch ▁▂▃▃▄▅▆▆▇█
wandb: Test loss tennis_pNone_gNone_tennisEffect █▅▄▆▃▂▁▂▁▁
wandb:                                Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                     Epoch 9
wandb: Test loss tennis_pNone_gNone_tennisEffect 1e-05
wandb:                                Train loss 1e-05
wandb: 
wandb: 🚀 View run young-sound-1271 at: https://wandb.ai/nreints/ThesisFinal2/runs/vyfkzx42
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230710_171006-vyfkzx42/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230710_171445-4ts1ss79
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run logical-serenity-1285
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/4ts1ss79
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                     Epoch ▁▂▃▃▄▅▆▆▇█
wandb: Test loss tennis_pNone_gNone_tennisEffect █▇▃▅▃▂▂▁▁▁
wandb:                                Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                     Epoch 9
wandb: Test loss tennis_pNone_gNone_tennisEffect 1e-05
wandb:                                Train loss 1e-05
wandb: 
wandb: 🚀 View run logical-serenity-1285 at: https://wandb.ai/nreints/ThesisFinal2/runs/4ts1ss79
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230710_171445-4ts1ss79/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230710_171924-hts44vlj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run elated-sunset-1295
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/hts44vlj
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                     Epoch ▁▂▃▃▄▅▆▆▇█
wandb: Test loss tennis_pNone_gNone_tennisEffect █▅▄▃▃▂▄▁▂▁
wandb:                                Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                     Epoch 9
wandb: Test loss tennis_pNone_gNone_tennisEffect 1e-05
wandb:                                Train loss 1e-05
wandb: 
wandb: 🚀 View run elated-sunset-1295 at: https://wandb.ai/nreints/ThesisFinal2/runs/hts44vlj
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230710_171924-hts44vlj/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230710_172404-0mz86nn3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run likely-dust-1307
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/0mz86nn3
	 Logging test loss: 3.0389e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.947818517684937
Epoch 8/9
	 Logging train Loss: 1.68545e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.729e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.760175943374634
Epoch 9/9
	 Logging train Loss: 1.4512e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.34884e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.922037363052368
Saved model in  trained_models/gru/data_tennis_pNone_gNone_tennisEffect/'log_quat_1'_'True'.pth
It took  278.86744356155396  seconds.
----- ITERATION 4/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 53.87313175201416 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 13.53311562538147 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (pre_hidden_lin_layer): Sequential(
    (0): Linear(in_features=3, out_features=96, bias=True)
    (1): ReLU()
    (2): Linear(in_features=96, out_features=96, bias=True)
    (3): ReLU()
  )
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: log_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0016174201 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 8.81345e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.950778007507324
Epoch 1/9
	 Logging train Loss: 5.48791e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 8.17298e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.986314058303833
Epoch 2/9
	 Logging train Loss: 4.33416e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 3.28306e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.9066321849823
Epoch 3/9
	 Logging train Loss: 3.54098e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 5.00943e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.746581554412842
Epoch 4/9
	 Logging train Loss: 3.00235e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 3.38403e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.85787582397461
Epoch 5/9
	 Logging train Loss: 2.40029e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.96084e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.84144401550293
Epoch 6/9
	 Logging train Loss: 1.97563e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.83403e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.846925973892212
Epoch 7/9
	 Logging train Loss: 1.64454e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.22908e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.83837366104126
Epoch 8/9
	 Logging train Loss: 1.42898e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.10194e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 20.01266121864319
Epoch 9/9
	 Logging train Loss: 1.28278e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.04441e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.79389262199402
Saved model in  trained_models/gru/data_tennis_pNone_gNone_tennisEffect/'log_quat_1'_'True'.pth
It took  279.3581666946411  seconds.
----- ITERATION 5/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 53.941051721572876 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 13.485449314117432 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (pre_hidden_lin_layer): Sequential(
    (0): Linear(in_features=3, out_features=96, bias=True)
    (1): ReLU()
    (2): Linear(in_features=96, out_features=96, bias=True)
    (3): ReLU()
  )
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: log_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.002605424 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 6.44277e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 20.09083652496338
Epoch 1/9
	 Logging train Loss: 4.83008e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 3.99629e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.797923803329468
Epoch 2/9
	 Logging train Loss: 4.00622e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 3.62208e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 20.050461053848267
Epoch 3/9
	 Logging train Loss: 3.48463e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.64094e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.660486936569214
Epoch 4/9
	 Logging train Loss: 3.03824e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.9962e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.771310806274414
Epoch 5/9
	 Logging train Loss: 2.583e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.78613e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 20.231371641159058
Epoch 6/9
	 Logging train Loss: 2.20894e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 3.5764e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 20.56371307373047
Epoch 7/9
	 Logging train Loss: 1.80293e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.43413e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 20.096071481704712
Epoch 8/9
	 Logging train Loss: 1.55543e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.62995e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.891083002090454
Epoch 9/9
	 Logging train Loss: 1.38351e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.15567e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.737221717834473
Saved model in  trained_models/gru/data_tennis_pNone_gNone_tennisEffect/'log_quat_1'_'True'.pth
It took  279.76874804496765  seconds.
----- ITERATION 6/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 53.80844497680664 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 13.562716484069824 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (pre_hidden_lin_layer): Sequential(
    (0): Linear(in_features=3, out_features=96, bias=True)
    (1): ReLU()
    (2): Linear(in_features=96, out_features=96, bias=True)
    (3): ReLU()
  )
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: log_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0017650035 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 8.56746e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.875422954559326
Epoch 1/9
	 Logging train Loss: 5.76773e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 5.35152e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.872400045394897
Epoch 2/9
	 Logging train Loss: 4.54725e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 3.78694e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.73711347579956
Epoch 3/9
	 Logging train Loss: 3.68018e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 3.17032e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.810373306274414
Epoch 4/9
	 Logging train Loss: 3.14374e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.4555e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.697261095046997
Epoch 5/9
	 Logging train Loss: 2.49568e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                     Epoch ▁▂▃▃▄▅▆▆▇█
wandb: Test loss tennis_pNone_gNone_tennisEffect █▅▃▃▂▃▂▁▁▂
wandb:                                Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                     Epoch 9
wandb: Test loss tennis_pNone_gNone_tennisEffect 2e-05
wandb:                                Train loss 1e-05
wandb: 
wandb: 🚀 View run likely-dust-1307 at: https://wandb.ai/nreints/ThesisFinal2/runs/0mz86nn3
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230710_172404-0mz86nn3/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230710_172842-zac0i3sp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run still-cherry-1321
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/zac0i3sp
wandb: Waiting for W&B process to finish... (success).
wandb: ERROR Error while calling W&B API: An internal error occurred. Please contact support. (<Response [500]>)
wandb: ERROR Error while calling W&B API: An internal error occurred. Please contact support. (<Response [500]>)
wandb: 
wandb: Run history:
wandb:                                     Epoch ▁▂▃▃▄▅▆▆▇█
wandb: Test loss tennis_pNone_gNone_tennisEffect █▆▅▆▃▂▂▁▂▁
wandb:                                Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                     Epoch 9
wandb: Test loss tennis_pNone_gNone_tennisEffect 1e-05
wandb:                                Train loss 1e-05
wandb: 
wandb: 🚀 View run still-cherry-1321 at: https://wandb.ai/nreints/ThesisFinal2/runs/zac0i3sp
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230710_172842-zac0i3sp/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230710_173323-s6rdriyz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run prime-glitter-1331
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/s6rdriyz
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                     Epoch ▁▂▃▃▄▅▆▆▇█
wandb: Test loss tennis_pNone_gNone_tennisEffect █▆▄▇▂▂▂▂▁▁
wandb:                                Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                     Epoch 9
wandb: Test loss tennis_pNone_gNone_tennisEffect 1e-05
wandb:                                Train loss 1e-05
wandb: 
wandb: 🚀 View run prime-glitter-1331 at: https://wandb.ai/nreints/ThesisFinal2/runs/s6rdriyz
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230710_173323-s6rdriyz/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230710_173759-67y46af1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run zany-wind-1343
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/67y46af1
	 Logging test loss: 2.76813e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.96106719970703
Epoch 6/9
	 Logging train Loss: 2.02647e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.69739e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.728779554367065
Epoch 7/9
	 Logging train Loss: 1.62821e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.40856e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.563831329345703
Epoch 8/9
	 Logging train Loss: 1.43529e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.17773e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.933844804763794
Epoch 9/9
	 Logging train Loss: 1.27038e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.89816e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.990837812423706
Saved model in  trained_models/gru/data_tennis_pNone_gNone_tennisEffect/'log_quat_1'_'True'.pth
It took  277.9560270309448  seconds.
----- ITERATION 7/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 53.64560294151306 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 13.430471897125244 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (pre_hidden_lin_layer): Sequential(
    (0): Linear(in_features=3, out_features=96, bias=True)
    (1): ReLU()
    (2): Linear(in_features=96, out_features=96, bias=True)
    (3): ReLU()
  )
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: log_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0020296823 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 6.43323e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.580655574798584
Epoch 1/9
	 Logging train Loss: 5.46656e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 4.89323e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.883766174316406
Epoch 2/9
	 Logging train Loss: 4.44329e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 3.88573e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.90387725830078
Epoch 3/9
	 Logging train Loss: 3.69705e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 5.09027e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 20.028934955596924
Epoch 4/9
	 Logging train Loss: 3.06312e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.95767e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.732531785964966
Epoch 5/9
	 Logging train Loss: 2.62843e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.07624e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.917410612106323
Epoch 6/9
	 Logging train Loss: 2.07725e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.98153e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.96907925605774
Epoch 7/9
	 Logging train Loss: 1.71279e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.34486e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.656139612197876
Epoch 8/9
	 Logging train Loss: 1.48379e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.57987e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.786458253860474
Epoch 9/9
	 Logging train Loss: 1.3635e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.1205e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.601568937301636
Saved model in  trained_models/gru/data_tennis_pNone_gNone_tennisEffect/'log_quat_1'_'True'.pth
It took  281.50789976119995  seconds.
----- ITERATION 8/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 53.75821828842163 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 13.428675651550293 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (pre_hidden_lin_layer): Sequential(
    (0): Linear(in_features=3, out_features=96, bias=True)
    (1): ReLU()
    (2): Linear(in_features=96, out_features=96, bias=True)
    (3): ReLU()
  )
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: log_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0021361697 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 6.38407e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.819456338882446
Epoch 1/9
	 Logging train Loss: 5.89647e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 4.55345e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.70701289176941
Epoch 2/9
	 Logging train Loss: 4.56197e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 3.63195e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.7484130859375
Epoch 3/9
	 Logging train Loss: 3.72589e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 5.99388e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.640419721603394
Epoch 4/9
	 Logging train Loss: 3.11596e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.0948e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.695701122283936
Epoch 5/9
	 Logging train Loss: 2.61997e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.76468e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.76605224609375
Epoch 6/9
	 Logging train Loss: 2.14955e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.90788e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.81015634536743
Epoch 7/9
	 Logging train Loss: 1.72282e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.89471e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.654733657836914
Epoch 8/9
	 Logging train Loss: 1.51992e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.00373e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.864720106124878
Epoch 9/9
	 Logging train Loss: 1.33604e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.38471e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.469931602478027
Saved model in  trained_models/gru/data_tennis_pNone_gNone_tennisEffect/'log_quat_1'_'True'.pth
It took  276.1860032081604  seconds.
----- ITERATION 9/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 53.85119986534119 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 13.490070343017578 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (pre_hidden_lin_layer): Sequential(
    (0): Linear(in_features=3, out_features=96, bias=True)
    (1): ReLU()
    (2): Linear(in_features=96, out_features=96, bias=True)
    (3): ReLU()
  )
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: log_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0021029026 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 7.00551e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.766037702560425
Epoch 1/9
	 Logging train Loss: 5.68208e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 4.75436e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.884592294692993
Epoch 2/9
	 Logging train Loss: 4.54284e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 3.99472e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.727036237716675
Epoch 3/9
	 Logging train Loss: 3.76797e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                     Epoch ▁▂▃▃▄▅▆▆▇█
wandb: Test loss tennis_pNone_gNone_tennisEffect █▅▄▅▃▃▂▁▁▁
wandb:                                Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                     Epoch 9
wandb: Test loss tennis_pNone_gNone_tennisEffect 1e-05
wandb:                                Train loss 1e-05
wandb: 
wandb: 🚀 View run zany-wind-1343 at: https://wandb.ai/nreints/ThesisFinal2/runs/67y46af1
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230710_173759-67y46af1/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230710_174236-694r1mo2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run confused-eon-1353
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/694r1mo2
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                     Epoch ▁▂▃▃▄▅▆▆▇█
wandb: Test loss tennis_pNone_gNone_tennisEffect ██▄▄▄▃▂▂▂▁
wandb:                                Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                     Epoch 9
wandb: Test loss tennis_pNone_gNone_tennisEffect 1e-05
wandb:                                Train loss 1e-05
wandb: 
wandb: 🚀 View run confused-eon-1353 at: https://wandb.ai/nreints/ThesisFinal2/runs/694r1mo2
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230710_174236-694r1mo2/logs
	 Logging test loss: 4.56922e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.83345365524292
Epoch 4/9
	 Logging train Loss: 3.11878e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.65935e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.54395294189453
Epoch 5/9
	 Logging train Loss: 2.55386e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 3.18131e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.766151428222656
Epoch 6/9
	 Logging train Loss: 2.06649e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.40551e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.585294008255005
Epoch 7/9
	 Logging train Loss: 1.66342e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.61614e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.76631188392639
Epoch 8/9
	 Logging train Loss: 1.41726e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.61775e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.74141263961792
Epoch 9/9
	 Logging train Loss: 1.26593e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.39626e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.70414900779724
Saved model in  trained_models/gru/data_tennis_pNone_gNone_tennisEffect/'log_quat_1'_'True'.pth
It took  276.1268119812012  seconds.
----- ITERATION 10/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 53.84772205352783 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 13.440630912780762 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (pre_hidden_lin_layer): Sequential(
    (0): Linear(in_features=3, out_features=96, bias=True)
    (1): ReLU()
    (2): Linear(in_features=96, out_features=96, bias=True)
    (3): ReLU()
  )
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: log_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0022456949 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 6.52093e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.715243339538574
Epoch 1/9
	 Logging train Loss: 5.49836e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 6.51031e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.694018602371216
Epoch 2/9
	 Logging train Loss: 4.46906e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 3.69123e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.763991355895996
Epoch 3/9
	 Logging train Loss: 3.75645e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 3.06693e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.753587245941162
Epoch 4/9
	 Logging train Loss: 3.16715e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.95326e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.737069129943848
Epoch 5/9
	 Logging train Loss: 2.69787e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.22075e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.986321210861206
Epoch 6/9
	 Logging train Loss: 2.28167e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.8105e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.7642719745636
Epoch 7/9
	 Logging train Loss: 1.80134e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.73845e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.569032907485962
Epoch 8/9
	 Logging train Loss: 1.49591e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.39792e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.81847357749939
Epoch 9/9
	 Logging train Loss: 1.33584e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 9.6393e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.59346914291382
Saved model in  trained_models/gru/data_tennis_pNone_gNone_tennisEffect/'log_quat_1'_'True'.pth
It took  277.8289623260498  seconds.

JOB STATISTICS
==============
Job ID: 3043758
Array Job ID: 3043750_47
Cluster: snellius
User/Group: nreints/nreints
State: RUNNING
Nodes: 1
Cores per node: 18
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 14:05:06 core-walltime
Job Wall-clock time: 00:46:57
Memory Utilized: 0.00 MB (estimated maximum)
Memory Efficiency: 0.00% of 0.00 MB (0.00 MB/node)
WARNING: Efficiency statistics may be misleading for RUNNING jobs.
