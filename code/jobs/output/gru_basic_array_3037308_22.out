wandb: Currently logged in as: nreints. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_134800-k0byliif
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run deep-sun-655
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/k0byliif
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone â–ˆâ–‚â–â–â–‚â–â–â–â–â–
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone â–ˆâ–‚â–â–‚â–‚â–â–â–â–â–
wandb:                                  Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone 0.0
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: ðŸš€ View run deep-sun-655 at: https://wandb.ai/nreints/ThesisFinal2/runs/k0byliif
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_134800-k0byliif/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_135636-6kmtc9t8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run grateful-oath-667
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/6kmtc9t8
Training on dataset: data_t(5,20)_r(0,0)_combi_pNone_gNone
Testing on 5 datasets: ['data_t(5,20)_r(0,0)_tennis_pNone_gNone', 'data_t(5,20)_r(0,0)_combi_pNone_gNone', 'data_t(5,20)_r(0,0)_none_pNone_gNone', 'data_t(5,20)_r(0,0)_full_pNone_gNone', 'data_t(5,20)_r(0,0)_semi_pNone_gNone']
Focussing on identity: True
Using extra input: False
Using fr-fr as reference point.
----- ITERATION 1/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 53.21966767311096 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(0,0)_tennis_pNone_gNone took 13.36140489578247 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 13.47311544418335 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_none_pNone_gNone took 13.327305555343628 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_full_pNone_gNone took 13.31044602394104 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_semi_pNone_gNone took 13.14492130279541 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0003306809 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.81493e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 3.85511e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.4536e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 3.481e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 3.60654e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 40.21062707901001
Epoch 1/9
	 Logging train Loss: 1.67207e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 4.6121e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 5.1924e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 4.0446e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 4.1098e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 4.383e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 38.029478311538696
Epoch 2/9
	 Logging train Loss: 4.0752e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.6032e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 2.8349e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.0303e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 2.0359e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.4795e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 37.68036961555481
Epoch 3/9
	 Logging train Loss: 3.7492e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.9598e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 2.5235e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.5629e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.5771e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.7624e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 37.82634997367859
Epoch 4/9
	 Logging train Loss: 3.1712e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.7642e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 2.7124e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.3001e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.316e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 3.6574e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 37.875964403152466
Epoch 5/9
	 Logging train Loss: 2.422e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 4.449e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 4.958e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.956e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 4.013e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 4.311e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 37.915590047836304
Epoch 6/9
	 Logging train Loss: 2.0887e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.101e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 3.423e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.659e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 2.701e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 3.012e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 38.029855728149414
Epoch 7/9
	 Logging train Loss: 1.7501e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 6.94e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 5.134e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.438e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 2.498e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 6.663e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 38.075443983078
Epoch 8/9
	 Logging train Loss: 1.1674e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.7643e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.056e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.21e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 2.266e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.7141e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 37.66808867454529
Epoch 9/9
	 Logging train Loss: 1.3662e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.375e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 2.415e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.895e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.906e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.323e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 37.63218331336975
Saved model in  trained_models/gru/data_t(5,20)_r(0,0)_combi_pNone_gNone/'dual_quat_1'_'False'.pth
It took  517.1183309555054  seconds.
----- ITERATION 2/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 48.53947925567627 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(0,0)_tennis_pNone_gNone took 12.644133567810059 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 12.177960634231567 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_none_pNone_gNone took 12.060661315917969 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_full_pNone_gNone took 12.107857704162598 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_semi_pNone_gNone took 12.21558427810669 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0001548589 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.14843e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.17506e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.02193e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.054e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.09788e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 38.22379469871521
Epoch 1/9
	 Logging train Loss: 5.6612e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.6534e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 2.8961e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone â–ˆâ–ƒâ–‚â–â–‡â–â–‚â–â–ƒâ–
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone â–ˆâ–‚â–‚â–â–ƒâ–â–‚â–‚â–â–
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone â–ˆâ–‚â–‚â–â–ƒâ–â–‚â–‚â–â–
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone â–†â–‚â–‚â–â–ˆâ–â–‚â–â–ƒâ–
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone â–†â–‚â–‚â–â–ˆâ–â–‚â–â–ƒâ–
wandb:                                  Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone 0.0
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: ðŸš€ View run grateful-oath-667 at: https://wandb.ai/nreints/ThesisFinal2/runs/6kmtc9t8
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_135636-6kmtc9t8/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_140503-kjigb9vb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run easy-cosmos-677
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/kjigb9vb
	 Logging test loss: 2.1203e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 2.17e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.5656e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 38.09618520736694
Epoch 2/9
	 Logging train Loss: 3.681e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.4241e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 2.0526e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.1289e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.1463e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.3544e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 37.84441423416138
Epoch 3/9
	 Logging train Loss: 2.5337e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 4.871e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 5.798e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 4.434e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 4.486e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 4.69e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 38.00421762466431
Epoch 4/9
	 Logging train Loss: 2.327e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.58334e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 9.3641e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.5266e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 2.5196e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.55025e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 38.52254867553711
Epoch 5/9
	 Logging train Loss: 1.3505e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 8.976e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 6.289e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.383e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 2.404e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 8.77e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 37.97824287414551
Epoch 6/9
	 Logging train Loss: 1.8729e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.3336e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 2.211e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 9.505e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 9.429e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 3.3029e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 41.18869924545288
Epoch 7/9
	 Logging train Loss: 7.718e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.0958e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.075e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 9.919e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 9.923e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.0828e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 38.17673707008362
Epoch 8/9
	 Logging train Loss: 1.0221e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 5.719e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 3.2171e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 5.197e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 5.22e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 5.6191e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 38.087284564971924
Epoch 9/9
	 Logging train Loss: 8.663e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 4.418e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 3.266e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.612e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.646e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 4.209e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 37.9074764251709
Saved model in  trained_models/gru/data_t(5,20)_r(0,0)_combi_pNone_gNone/'dual_quat_1'_'False'.pth
It took  506.944641828537  seconds.
----- ITERATION 3/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 48.320199966430664 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(0,0)_tennis_pNone_gNone took 12.088458776473999 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 11.978256225585938 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_none_pNone_gNone took 12.280797958374023 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_full_pNone_gNone took 12.303232908248901 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_semi_pNone_gNone took 12.177962064743042 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0004527743 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 4.33234e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 4.24271e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 4.12915e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 4.10268e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 4.22256e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 37.93697547912598
Epoch 1/9
	 Logging train Loss: 2.2478e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 7.6985e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 7.8284e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 6.7099e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 6.8229e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 7.3978e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 38.131471157073975
Epoch 2/9
	 Logging train Loss: 5.2048e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.5224e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 2.8379e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.3866e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 2.3525e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.4337e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 37.77222561836243
Epoch 3/9
	 Logging train Loss: 3.5156e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 4.1435e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 3.1697e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.7384e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.7178e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 3.9821e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 38.208961725234985
Epoch 4/9
	 Logging train Loss: 3.2547e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.4926e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.4587e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.2014e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.1914e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.444e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 38.43371367454529
Epoch 5/9
	 Logging train Loss: 2.5937e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 7.1001e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 4.3936e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone â–ˆâ–‚â–â–â–â–‚â–â–â–â–
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone â–ˆâ–‚â–â–‚â–â–‚â–â–â–â–
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone â–ˆâ–‚â–â–‚â–â–‚â–â–â–â–
wandb:                                  Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone 0.0
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: ðŸš€ View run easy-cosmos-677 at: https://wandb.ai/nreints/ThesisFinal2/runs/kjigb9vb
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_140503-kjigb9vb/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_141326-p48d35j1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run still-frost-683
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/p48d35j1
	 Logging test loss: 1.2676e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.2637e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 7.234e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 38.09933662414551
Epoch 6/9
	 Logging train Loss: 2.3931e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.228e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 3.577e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.889e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 2.893e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 3.128e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 38.09520387649536
Epoch 7/9
	 Logging train Loss: 2.0352e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.647e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 3.872e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.15e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 3.136e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 3.551e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 38.104535818099976
Epoch 8/9
	 Logging train Loss: 1.5548e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 4.5e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 3.782e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.241e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 2.268e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 4.374e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 38.19581723213196
Epoch 9/9
	 Logging train Loss: 1.752e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.806e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.967e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.598e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.59e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.742e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 38.019097328186035
Saved model in  trained_models/gru/data_t(5,20)_r(0,0)_combi_pNone_gNone/'dual_quat_1'_'False'.pth
It took  502.91163897514343  seconds.
----- ITERATION 4/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 48.376250982284546 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(0,0)_tennis_pNone_gNone took 12.273001194000244 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 12.20864725112915 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_none_pNone_gNone took 12.082897663116455 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_full_pNone_gNone took 12.10235857963562 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_semi_pNone_gNone took 12.161468744277954 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0004178298 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.29739e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 3.16488e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.1579e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 3.10302e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 3.27588e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 37.987306356430054
Epoch 1/9
	 Logging train Loss: 1.45374e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 4.8832e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 5.076e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 4.3598e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 4.3274e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 4.8187e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 41.869067907333374
Epoch 2/9
	 Logging train Loss: 3.4193e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.7567e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 2.7856e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.1005e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 2.0954e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.7472e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 38.21281456947327
Epoch 3/9
	 Logging train Loss: 2.914e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.3799e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.5268e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.2861e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.2923e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.3681e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 37.98357009887695
Epoch 4/9
	 Logging train Loss: 2.1641e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.6072e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.3668e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 8.78e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 8.868e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.6154e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 38.03138208389282
Epoch 5/9
	 Logging train Loss: 2.0484e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 5.652e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 5.846e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 4.696e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 4.766e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 5.633e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 38.27401351928711
Epoch 6/9
	 Logging train Loss: 1.7456e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 4.853e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 5.12e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 4.181e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 4.242e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 4.834e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 38.049628496170044
Epoch 7/9
	 Logging train Loss: 1.3734e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.89e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.6161e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.2105e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.2103e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.9215e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 38.02935028076172
Epoch 8/9
	 Logging train Loss: 1.6544e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.762e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 2.069e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.634e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.668e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.742e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 38.16748833656311
Epoch 9/9
	 Logging train Loss: 1.0986e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.687e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.966e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone â–ˆâ–‚â–‚â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone â–ˆâ–‚â–‚â–â–â–â–â–â–â–
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone â–ˆâ–‚â–‚â–â–â–â–â–â–â–
wandb:                                  Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone 0.0
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: ðŸš€ View run still-frost-683 at: https://wandb.ai/nreints/ThesisFinal2/runs/p48d35j1
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_141326-p48d35j1/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_142201-jkg65up8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run neat-frog-692
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/jkg65up8
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb:                                  Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone 0.0
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: ðŸš€ View run neat-frog-692 at: https://wandb.ai/nreints/ThesisFinal2/runs/jkg65up8
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_142201-jkg65up8/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_143026-2ouwcnr5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hopeful-wildflower-701
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/2ouwcnr5
	 Logging test loss: 1.556e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.587e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.69e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 38.16985630989075
Saved model in  trained_models/gru/data_t(5,20)_r(0,0)_combi_pNone_gNone/'dual_quat_1'_'False'.pth
It took  514.8925821781158  seconds.
----- ITERATION 5/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 48.29195547103882 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(0,0)_tennis_pNone_gNone took 12.141485929489136 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 12.319385766983032 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_none_pNone_gNone took 12.294631481170654 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_full_pNone_gNone took 12.215157508850098 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_semi_pNone_gNone took 12.16088080406189 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0004387049 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 4.09577e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 3.94842e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.64062e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 3.73514e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 3.75117e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 37.931763887405396
Epoch 1/9
	 Logging train Loss: 1.76644e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 4.3628e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 4.6093e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.6511e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 3.7066e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 4.0422e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 38.51699447631836
Epoch 2/9
	 Logging train Loss: 3.2178e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.2165e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 2.4859e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.0095e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 2.05e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.0652e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 38.01363396644592
Epoch 3/9
	 Logging train Loss: 2.8756e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.0349e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 2.1858e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.8877e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.9041e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.9504e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 37.868263721466064
Epoch 4/9
	 Logging train Loss: 2.4591e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 6.812e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 7.656e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 6.253e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 6.255e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 6.403e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 37.91897130012512
Epoch 5/9
	 Logging train Loss: 1.9531e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.755e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 4.267e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.416e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 3.413e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 3.54e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 38.498698234558105
Epoch 6/9
	 Logging train Loss: 1.7634e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 6.416e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 5.51e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.605e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 3.541e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 6.098e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 38.209144115448
Epoch 7/9
	 Logging train Loss: 1.511e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.735e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 2.042e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.627e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.602e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.66e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 38.07635426521301
Epoch 8/9
	 Logging train Loss: 1.5874e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.327e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 2.414e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.888e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.888e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.257e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 38.41145420074463
Epoch 9/9
	 Logging train Loss: 1.2695e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 5.408e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 4.489e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.657e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 2.674e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 5.516e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 38.43091559410095
Saved model in  trained_models/gru/data_t(5,20)_r(0,0)_combi_pNone_gNone/'dual_quat_1'_'False'.pth
It took  505.0238826274872  seconds.
----- ITERATION 6/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 49.211081981658936 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(0,0)_tennis_pNone_gNone took 12.075901746749878 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 12.096251249313354 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_none_pNone_gNone took 12.239315032958984 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_full_pNone_gNone took 12.143325567245483 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_semi_pNone_gNone took 12.139659404754639 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0003900398 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.31106e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.3276e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.20908e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.12815e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.34896e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 38.38664174079895
Epoch 1/9
	 Logging train Loss: 4.8247e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.6363e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 3.1063e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone â–ˆâ–ƒâ–‚â–ƒâ–â–â–â–‚â–â–ƒ
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone â–ˆâ–‚â–‚â–‚â–â–â–â–‚â–â–‚
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone â–ˆâ–‚â–‚â–‚â–â–â–â–‚â–â–‚
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone â–ˆâ–‚â–‚â–ƒâ–â–â–â–‚â–â–„
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone â–ˆâ–‚â–‚â–ƒâ–â–â–â–‚â–â–„
wandb:                                  Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone 1e-05
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone 1e-05
wandb:                                  Train loss 0.0
wandb: 
wandb: ðŸš€ View run hopeful-wildflower-701 at: https://wandb.ai/nreints/ThesisFinal2/runs/2ouwcnr5
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_143026-2ouwcnr5/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_143850-rdwbuytb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lyric-water-707
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/rdwbuytb
	 Logging test loss: 2.4533e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 2.3439e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.6032e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 38.17004466056824
Epoch 2/9
	 Logging train Loss: 2.253e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.2078e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.5152e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.0993e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.0399e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.1983e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 38.07571196556091
Epoch 3/9
	 Logging train Loss: 1.7702e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 4.5917e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 3.351e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.3774e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.3531e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 4.6472e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 37.89649152755737
Epoch 4/9
	 Logging train Loss: 1.8753e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 5.202e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 5.63e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.605e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 3.508e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 5.167e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 37.72065019607544
Epoch 5/9
	 Logging train Loss: 1.6992e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 8.568e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 6.432e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.269e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 2.234e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 8.417e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 38.344440937042236
Epoch 6/9
	 Logging train Loss: 1.5993e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.898e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 2.388e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.665e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.641e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.853e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 38.22410774230957
Epoch 7/9
	 Logging train Loss: 1.2356e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.2473e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.8035e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.1732e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.1721e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.2685e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 38.303091287612915
Epoch 8/9
	 Logging train Loss: 1.2494e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.239e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 2.569e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.138e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 2.133e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.195e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 37.95674467086792
Epoch 9/9
	 Logging train Loss: 1.1463e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 5.8391e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 3.7831e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.327e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.3293e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 5.8969e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 37.76667547225952
Saved model in  trained_models/gru/data_t(5,20)_r(0,0)_combi_pNone_gNone/'dual_quat_1'_'False'.pth
It took  504.1460587978363  seconds.
----- ITERATION 7/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 48.39070963859558 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(0,0)_tennis_pNone_gNone took 12.14246153831482 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 12.164662837982178 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_none_pNone_gNone took 12.299634456634521 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_full_pNone_gNone took 12.26693081855774 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_semi_pNone_gNone took 12.255139827728271 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0003865168 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.10895e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 3.10283e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.98257e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 2.88945e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 3.11124e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 37.945735454559326
Epoch 1/9
	 Logging train Loss: 1.09788e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.7177e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 3.2898e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.5875e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 2.5117e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.7378e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 38.28616976737976
Epoch 2/9
	 Logging train Loss: 2.7541e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.5356e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.9009e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.4941e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.4523e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.5521e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 38.1071982383728
Epoch 3/9
	 Logging train Loss: 2.7102e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 8.37e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.0213e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 8.017e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 7.82e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 8.484e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 37.84305715560913
Epoch 4/9
	 Logging train Loss: 2.0497e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 4.445e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 5.417e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 4.092e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 4.021e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 4.515e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 37.78243017196655
Epoch 5/9
	 Logging train Loss: 1.7612e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.674e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 3.37e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb:                                  Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone 0.0
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: ðŸš€ View run lyric-water-707 at: https://wandb.ai/nreints/ThesisFinal2/runs/rdwbuytb
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_143850-rdwbuytb/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_144717-gml6btjf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run skilled-water-717
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/gml6btjf
	 Logging test loss: 2.433e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 2.409e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.706e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 38.05652856826782
Epoch 6/9
	 Logging train Loss: 1.8513e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 5.648e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 4.566e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.069e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 2.057e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 5.612e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 38.6922173500061
Epoch 7/9
	 Logging train Loss: 2.3903e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 6.452e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 5.643e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.639e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 3.613e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 6.279e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 42.183879375457764
Epoch 8/9
	 Logging train Loss: 1.0988e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.76e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 2.146e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.612e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.613e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.763e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 37.999985218048096
Epoch 9/9
	 Logging train Loss: 1.3023e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.63e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.1029e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.948e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 3.986e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.5715e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 38.20374798774719
Saved model in  trained_models/gru/data_t(5,20)_r(0,0)_combi_pNone_gNone/'dual_quat_1'_'False'.pth
It took  507.4053473472595  seconds.
----- ITERATION 8/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 48.88664174079895 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(0,0)_tennis_pNone_gNone took 12.191364765167236 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 12.209957838058472 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_none_pNone_gNone took 12.276388883590698 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_full_pNone_gNone took 12.227823972702026 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_semi_pNone_gNone took 12.319648504257202 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0003960218 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.61716e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 3.65095e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.56881e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 3.44285e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 3.64964e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 37.84359669685364
Epoch 1/9
	 Logging train Loss: 1.56559e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.7094e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 4.1636e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.3485e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 3.2904e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 3.7396e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 38.23363757133484
Epoch 2/9
	 Logging train Loss: 3.0063e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.4686e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 2.5967e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.873e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.8474e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.4275e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 37.93970203399658
Epoch 3/9
	 Logging train Loss: 2.9739e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.2854e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.4559e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.1558e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.1475e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.3008e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 37.93192505836487
Epoch 4/9
	 Logging train Loss: 3.6182e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.3235e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.6613e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 7.315e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 7.349e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.1705e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 37.72827482223511
Epoch 5/9
	 Logging train Loss: 1.9679e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.0007e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 9.287e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 6.629e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 6.696e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 9.841e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 38.15772604942322
Epoch 6/9
	 Logging train Loss: 2.4068e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 4.585e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 4.129e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.47e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 2.493e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 4.425e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 38.40439486503601
Epoch 7/9
	 Logging train Loss: 2.4359e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.951e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 2.343e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.769e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.801e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.937e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 37.83881688117981
Epoch 8/9
	 Logging train Loss: 1.1169e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.9695e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 2.9068e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.7435e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 2.7441e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.9533e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 38.155176639556885
Epoch 9/9
	 Logging train Loss: 1.6155e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.248e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 2.517e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone â–ˆâ–‚â–â–â–â–â–â–â–‚â–
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone â–ˆâ–‚â–â–â–â–â–â–â–‚â–
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone â–ˆâ–‚â–â–â–â–â–â–â–‚â–
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone â–ˆâ–‚â–â–â–â–â–â–â–‚â–
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone â–ˆâ–‚â–â–â–â–â–â–â–‚â–
wandb:                                  Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone 0.0
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: ðŸš€ View run skilled-water-717 at: https://wandb.ai/nreints/ThesisFinal2/runs/gml6btjf
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_144717-gml6btjf/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_145540-cn0gribd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run polished-frog-726
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/cn0gribd
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone â–ˆâ–ƒâ–â–‚â–â–ƒâ–â–â–â–
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone â–ˆâ–ƒâ–â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone â–ˆâ–ƒâ–â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone â–ˆâ–ƒâ–â–‚â–â–…â–â–â–â–
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone â–ˆâ–ƒâ–â–‚â–â–†â–â–â–â–
wandb:                                  Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone 0.0
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: ðŸš€ View run polished-frog-726 at: https://wandb.ai/nreints/ThesisFinal2/runs/cn0gribd
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_145540-cn0gribd/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_150405-ofprns61
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run visionary-fire-732
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/ofprns61
	 Logging test loss: 2.118e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 2.133e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.241e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 38.07279443740845
Saved model in  trained_models/gru/data_t(5,20)_r(0,0)_combi_pNone_gNone/'dual_quat_1'_'False'.pth
It took  502.9214913845062  seconds.
----- ITERATION 9/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 48.06824326515198 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(0,0)_tennis_pNone_gNone took 12.071641683578491 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 12.04726505279541 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_none_pNone_gNone took 12.264991998672485 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_full_pNone_gNone took 12.04965353012085 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_semi_pNone_gNone took 12.107577323913574 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0008914918 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 5.51421e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 5.49537e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 5.20665e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 5.31929e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 5.52037e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 38.14940690994263
Epoch 1/9
	 Logging train Loss: 3.72863e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.97756e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.96659e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.82168e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.86584e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.96715e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 38.24924182891846
Epoch 2/9
	 Logging train Loss: 9.4816e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.4567e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 3.8855e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.0817e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 3.1798e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 3.4622e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 37.78418254852295
Epoch 3/9
	 Logging train Loss: 2.9962e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 8.4166e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 5.5712e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.3891e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 2.4384e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 7.7182e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 37.89321208000183
Epoch 4/9
	 Logging train Loss: 2.9085e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.3954e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.523e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.2215e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.2474e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.384e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 41.58362674713135
Epoch 5/9
	 Logging train Loss: 4.2103e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.68013e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.90804e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.1939e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 3.273e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 3.23516e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 37.9965033531189
Epoch 6/9
	 Logging train Loss: 2.407e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 5.157e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 5.636e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 4.496e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 4.566e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 5.147e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 38.12277841567993
Epoch 7/9
	 Logging train Loss: 2.1419e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 4.33e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 4.186e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.85e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 2.883e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 4.188e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 38.01845073699951
Epoch 8/9
	 Logging train Loss: 2.1704e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 8.356e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 6.285e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.554e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 3.528e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 7.903e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 38.113762617111206
Epoch 9/9
	 Logging train Loss: 1.6821e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.189e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 2.522e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.934e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.949e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.133e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 38.299269676208496
Saved model in  trained_models/gru/data_t(5,20)_r(0,0)_combi_pNone_gNone/'dual_quat_1'_'False'.pth
It took  504.91490411758423  seconds.
----- ITERATION 10/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 48.40023493766785 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(0,0)_tennis_pNone_gNone took 12.114415407180786 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 12.042475938796997 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_none_pNone_gNone took 12.073993444442749 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_full_pNone_gNone took 12.09190034866333 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_semi_pNone_gNone took 12.073262929916382 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0002774337 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.38747e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 2.42942e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.21515e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 2.26171e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.39422e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 37.965137243270874
Epoch 1/9
	 Logging train Loss: 1.06818e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.6604e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 4.2789e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone â–ˆâ–‚â–‚â–â–‚â–ƒâ–â–â–â–
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone â–ˆâ–‚â–‚â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone â–ˆâ–‚â–‚â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone â–ˆâ–‚â–‚â–â–ƒâ–…â–â–â–â–
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone â–ˆâ–‚â–‚â–â–ƒâ–…â–â–â–â–
wandb:                                  Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone 0.0
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: ðŸš€ View run visionary-fire-732 at: https://wandb.ai/nreints/ThesisFinal2/runs/ofprns61
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_150405-ofprns61/logs
	 Logging test loss: 3.3753e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 3.4763e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 3.6463e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 38.298938512802124
Epoch 2/9
	 Logging train Loss: 3.6687e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.1004e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 2.4631e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.8649e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.9343e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.0799e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 38.079142570495605
Epoch 3/9
	 Logging train Loss: 3.6037e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.2221e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.4099e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.094e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.1197e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.2105e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 37.87291979789734
Epoch 4/9
	 Logging train Loss: 2.886e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 8.4623e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 4.8408e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 9.302e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 9.409e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 8.2233e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 37.91595125198364
Epoch 5/9
	 Logging train Loss: 2.846e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.51328e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 8.3376e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.5505e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.557e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.48748e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 38.09204936027527
Epoch 6/9
	 Logging train Loss: 1.7528e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 7.308e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 6.108e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.727e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 3.717e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 7.135e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 38.342817068099976
Epoch 7/9
	 Logging train Loss: 1.6143e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.835e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 2.231e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.741e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.744e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.851e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 38.05007600784302
Epoch 8/9
	 Logging train Loss: 1.2929e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.4587e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.3192e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.0875e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.0854e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.4513e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 38.518878698349
Epoch 9/9
	 Logging train Loss: 1.2764e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.142e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 2.186e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.602e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.621e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.126e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
		--> Epoch time; 38.12185549736023
Saved model in  trained_models/gru/data_t(5,20)_r(0,0)_combi_pNone_gNone/'dual_quat_1'_'False'.pth
It took  502.8922350406647  seconds.

JOB STATISTICS
==============
Job ID: 3037312
Array Job ID: 3037308_22
Cluster: snellius
User/Group: nreints/nreints
State: RUNNING
Nodes: 1
Cores per node: 18
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 1-01:25:48 core-walltime
Job Wall-clock time: 01:24:46
Memory Utilized: 0.00 MB (estimated maximum)
Memory Efficiency: 0.00% of 0.00 MB (0.00 MB/node)
WARNING: Efficiency statistics may be misleading for RUNNING jobs.
