wandb: Currently logged in as: nreints. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230620_120353-h63wcaa2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pleasant-firebrand-137
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal/runs/h63wcaa2
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone █▃▂▂▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone █▃▂▂▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone █▃▂▁▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone █▃▂▂▁▁▁▁▂▁
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone █▃▂▂▁▁▁▁▂▁
wandb:                                   Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone 0.00202
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 0.00091
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone 0.0005
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 0.0027
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 0.0035
wandb:                                   Train loss 0.002
wandb: 
wandb: 🚀 View run pleasant-firebrand-137 at: https://wandb.ai/nreints/ThesisFinal/runs/h63wcaa2
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230620_120353-h63wcaa2/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230620_122537-01fkud07
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dry-pyramid-148
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal/runs/01fkud07
Training on dataset: data_t(5,20)_r(5,20)_combi_pNone_gNone
Testing on 5 datasets: ['data_t(5,20)_r(5,20)_full_pNone_gNone', 'data_t(5,20)_r(5,20)_none_pNone_gNone', 'data_t(5,20)_r(5,20)_tennis_pNone_gNone', 'data_t(5,20)_r(5,20)_semi_pNone_gNone', 'data_t(5,20)_r(5,20)_combi_pNone_gNone']
Focussing on identity: False
Using extra input: inertia_body
Using start-fr as reference point.
----- ITERATION 1/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 87.95582437515259 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 21.97482466697693 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_none_pNone_gNone took 21.967036724090576 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 22.181198835372925 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 22.368012189865112 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 22.46328091621399 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (pre_hidden_lin_layer): Sequential(
    (0): Linear(in_features=3, out_features=96, bias=True)
    (1): ReLU()
    (2): Linear(in_features=96, out_features=96, bias=True)
    (3): ReLU()
  )
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: log_quat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 3.4169547558 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0168309379 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0169641823 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0537689589 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0429314412 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0363247879 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 110.82321405410767
Epoch 1/9
	 Logging train Loss: 0.0163126197 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0047900416 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0040704343 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0180067029 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0147615997 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0115857637 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 105.09732103347778
Epoch 2/9
	 Logging train Loss: 0.0072978484 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0027750626 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0020222787 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0115063163 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0095129348 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0070884861 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 104.02715182304382
Epoch 3/9
	 Logging train Loss: 0.004966042 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0021102254 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0013505921 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0074294452 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0062590293 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0046692993 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 105.64076566696167
Epoch 4/9
	 Logging train Loss: 0.0039385986 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0016933386 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0009168423 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0063924259 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0051343474 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0037890996 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 109.2347776889801
Epoch 5/9
	 Logging train Loss: 0.0032928053 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0015035614 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0007671947 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0064404053 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0051367194 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0037471913 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 107.05309820175171
Epoch 6/9
	 Logging train Loss: 0.0027919717 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0016262024 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0009649154 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0053342022 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0042292308 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0032858679 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 110.12019419670105
Epoch 7/9
	 Logging train Loss: 0.0025353103 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0011575748 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0005718482 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0041834996 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0032537975 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0024274429 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 113.70244359970093
Epoch 8/9
	 Logging train Loss: 0.0022295597 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0015896658 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.001095296 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0071919714 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0057909931 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0041132034 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 113.98619818687439
Epoch 9/9
	 Logging train Loss: 0.0019981372 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0009109591 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0004990672 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0034976809 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0027023484 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0020174747 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 111.18288731575012
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gNone/'log_quat'_'inertia_body'.pth
It took  1304.31307888031  seconds.
----- ITERATION 2/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 80.64443039894104 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 20.51365089416504 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_none_pNone_gNone took 20.409154653549194 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 20.555538654327393 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 20.48242712020874 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 20.157625913619995 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (pre_hidden_lin_layer): Sequential(
    (0): Linear(in_features=3, out_features=96, bias=True)
    (1): ReLU()
    (2): Linear(in_features=96, out_features=96, bias=True)
    (3): ReLU()
  )
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: log_quat
-- Started Training --
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone █▂▂▁▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone █▃▂▂▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone █▃▂▂▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone █▂▂▁▁▁▁▁▁▁
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone █▂▂▁▁▁▁▁▁▁
wandb:                                   Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone 0.09735
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 0.01461
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone 0.00978
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 0.16725
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 0.1969
wandb:                                   Train loss 0.0711
wandb: 
wandb: 🚀 View run dry-pyramid-148 at: https://wandb.ai/nreints/ThesisFinal/runs/01fkud07
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230620_122537-01fkud07/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230620_124701-zrcmv40o
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sparkling-breeze-167
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal/runs/zrcmv40o
Epoch 0/9
	 Logging train Loss: 4.6930470467 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.1179903299 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0964347869 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.7485573292 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.4509677887 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.862633884 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 104.06983494758606
Epoch 1/9
	 Logging train Loss: 0.3933013976 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0391377397 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0270182565 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.4883578122 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.4017678201 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.2389077991 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 104.33489799499512
Epoch 2/9
	 Logging train Loss: 0.1831400245 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0267763492 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0182540435 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.3225257993 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.2765232623 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.1609335095 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 103.66741442680359
Epoch 3/9
	 Logging train Loss: 0.1331615597 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0211991053 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0138769345 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.2614872754 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.2219396979 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.1289035827 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 109.28504276275635
Epoch 4/9
	 Logging train Loss: 0.1106418669 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0181379616 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0119438889 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.2284953892 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.2023294866 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.1143750697 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 114.81172895431519
Epoch 5/9
	 Logging train Loss: 0.0970979258 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0151170557 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0093987184 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.2015524805 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.1742464751 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0993353575 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 114.91700983047485
Epoch 6/9
	 Logging train Loss: 0.0888204053 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0134661077 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0080324812 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.1849255115 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.1602657139 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.091229938 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 114.9797191619873
Epoch 7/9
	 Logging train Loss: 0.0814331025 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0122478222 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0071580303 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.1684252471 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.1445124745 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0833135247 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 111.16292142868042
Epoch 8/9
	 Logging train Loss: 0.0762296319 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0117484434 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0068608313 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.1575098783 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.1341637224 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.077482976 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 106.22515106201172
Epoch 9/9
	 Logging train Loss: 0.0710991621 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0146096125 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0097788842 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.1968998313 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.1672517806 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0973512828 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 104.0708179473877
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gNone/'log_quat'_'inertia_body'.pth
It took  1284.8210413455963  seconds.
----- ITERATION 3/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 81.30837035179138 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 20.48271131515503 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_none_pNone_gNone took 20.40379571914673 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 20.5686137676239 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 20.384503602981567 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 20.285924673080444 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (pre_hidden_lin_layer): Sequential(
    (0): Linear(in_features=3, out_features=96, bias=True)
    (1): ReLU()
    (2): Linear(in_features=96, out_features=96, bias=True)
    (3): ReLU()
  )
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: log_quat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 3.5439424515 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0159102492 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0127153927 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0474212319 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0413123183 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0299777631 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 103.04737997055054
Epoch 1/9
	 Logging train Loss: 0.0163393691 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0048934752 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0034884247 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0172669832 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0150472401 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0103370892 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 111.11256265640259
Epoch 2/9
	 Logging train Loss: 0.0071575656 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0028302213 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0018376891 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0130135678 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0109376535 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0077420166 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
slurmstepd: error: *** JOB 2943920 ON gcn6 CANCELLED AT 2023-06-20T13:04:07 ***
slurmstepd: error: *** STEP 2943920.0 ON gcn6 CANCELLED AT 2023-06-20T13:04:07 ***

JOB STATISTICS
==============
Job ID: 2943920
Array Job ID: 2943913_5
Cluster: snellius
User/Group: nreints/nreints
State: CANCELLED (exit code 0)
Nodes: 1
Cores per node: 18
CPU Utilized: 12:15:54
CPU Efficiency: 67.58% of 18:09:00 core-walltime
Job Wall-clock time: 01:00:30
Memory Utilized: 16.40 GB
Memory Efficiency: 0.00% of 0.00 MB
