wandb: Currently logged in as: nreints. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230329_124735-16u8oqh4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run good-flower-486
wandb: â­ï¸ View project at https://wandb.ai/nreints/test
wandb: ðŸš€ View run at https://wandb.ai/nreints/test/runs/16u8oqh4
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.031 MB of 0.031 MB uploaded (0.000 MB deduped)wandb: \ 0.031 MB of 0.031 MB uploaded (0.000 MB deduped)wandb: | 0.031 MB of 0.031 MB uploaded (0.000 MB deduped)wandb: / 0.031 MB of 0.031 MB uploaded (0.000 MB deduped)wandb: - 0.031 MB of 0.031 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:                                                  Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb: Test loss t(5, 20)_r(0, 0)_full_pNone_gNone, MSELoss() â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:                                             Train loss â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                                  Epoch 9
wandb: Test loss t(5, 20)_r(0, 0)_full_pNone_gNone, MSELoss() 0.01575
wandb:                                             Train loss 0.00957
wandb: 
wandb: ðŸš€ View run good-flower-486 at: https://wandb.ai/nreints/test/runs/16u8oqh4
wandb: Synced 6 W&B file(s), 0 media file(s), 2 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230329_124735-16u8oqh4/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230329_125502-f32wuy2e
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cerulean-surf-488
wandb: â­ï¸ View project at https://wandb.ai/nreints/test
wandb: ðŸš€ View run at https://wandb.ai/nreints/test/runs/f32wuy2e
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                                  Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb: Test loss t(5, 20)_r(0, 0)_full_pNone_gNone, MSELoss() â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:                                             Train loss â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                                  Epoch 9
wandb: Test loss t(5, 20)_r(0, 0)_full_pNone_gNone, MSELoss() 0.01838
wandb:                                             Train loss 0.00976
wandb: 
wandb: ðŸš€ View run cerulean-surf-488 at: https://wandb.ai/nreints/test/runs/f32wuy2e
wandb: Synced 6 W&B file(s), 0 media file(s), 2 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230329_125502-f32wuy2e/logs
Running for data type: pos
----- ITERATION 1/2 ------
Number of train simulations: 1600
Number of test simulations: 400
-- Finished Train Dataloader --
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(24, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=24, bias=True)
)
-- Started Training --
Epoch 0
	 Logging train Loss: 17.4663040304 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss: 3.1076526641845703 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
     --> Epoch time; 39.6810622215271
Epoch 1
	 Logging train Loss: 1.3317299857 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss: 0.6040970087051392 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
     --> Epoch time; 37.45395278930664
Epoch 2
	 Logging train Loss: 0.3241742775 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss: 0.24053634703159332 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
     --> Epoch time; 37.46167349815369
Epoch 3
	 Logging train Loss: 0.1344261322 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss: 0.12451542913913727 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
     --> Epoch time; 37.602163791656494
Epoch 4
	 Logging train Loss: 0.067861967 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss: 0.07454988360404968 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
     --> Epoch time; 37.27048397064209
Epoch 5
	 Logging train Loss: 0.0391891006 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss: 0.04904212802648544 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
     --> Epoch time; 37.61087894439697
Epoch 6
	 Logging train Loss: 0.0249542751 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss: 0.03378772363066673 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
     --> Epoch time; 37.3682804107666
Epoch 7
	 Logging train Loss: 0.0172072246 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss: 0.024649782106280327 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
     --> Epoch time; 37.65243101119995
Epoch 8
	 Logging train Loss: 0.0126652329 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss: 0.018755972385406494 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
     --> Epoch time; 37.308802127838135
Epoch 9
	 Logging train Loss: 0.0095657004 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss: 0.01578817516565323 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
     --> Epoch time; 37.63874912261963
	 Logging test loss: 0.015753207728266716 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
It took  447.9597361087799  seconds.
----- ITERATION 2/2 ------
Number of train simulations: 1600
Number of test simulations: 400
-- Finished Train Dataloader --
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(24, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=24, bias=True)
)
-- Started Training --
Epoch 0
	 Logging train Loss: 17.8044541159 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss: 3.080465793609619 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
     --> Epoch time; 38.772220849990845
Epoch 1
	 Logging train Loss: 1.3532075971 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss: 0.6077890396118164 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
     --> Epoch time; 37.67791795730591
Epoch 2
	 Logging train Loss: 0.3171184015 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss: 0.24712154269218445 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
     --> Epoch time; 37.55480718612671
Epoch 3
	 Logging train Loss: 0.1305377181 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss: 0.13574309647083282 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
     --> Epoch time; 37.54529023170471
Epoch 4
	 Logging train Loss: 0.0673256481 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss: 0.08299461007118225 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
     --> Epoch time; 37.77851486206055
Epoch 5
	 Logging train Loss: 0.0388781009 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss: 0.05557567998766899 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
     --> Epoch time; 37.57614302635193
Epoch 6
	 Logging train Loss: 0.024899675 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss: 0.039939090609550476 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
     --> Epoch time; 37.704387187957764
Epoch 7
	 Logging train Loss: 0.0171946002 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss: 0.0307910218834877 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
     --> Epoch time; 37.67167353630066
Epoch 8
	 Logging train Loss: 0.0126336738 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss: 0.022975673899054527 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
     --> Epoch time; 37.59810423851013
Epoch 9
	 Logging train Loss: 0.0097604065 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss: 0.018374329432845116 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
     --> Epoch time; 37.30882239341736
	 Logging test loss: 0.018378321081399918 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
It took  441.8160104751587  seconds.

JOB STATISTICS
==============
Job ID: 2514687
Array Job ID: 2514679_8
Cluster: snellius
User/Group: nreints/nreints
State: COMPLETED (exit code 0)
Nodes: 1
Cores per node: 18
CPU Utilized: 02:52:32
CPU Efficiency: 63.06% of 04:33:36 core-walltime
Job Wall-clock time: 00:15:12
Memory Utilized: 27.87 GB
Memory Efficiency: 89.19% of 31.25 GB
