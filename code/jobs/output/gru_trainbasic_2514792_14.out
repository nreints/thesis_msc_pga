wandb: Currently logged in as: nreints. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230329_133616-s3inz8k2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fine-deluge-502
wandb: â­ï¸ View project at https://wandb.ai/nreints/test
wandb: ðŸš€ View run at https://wandb.ai/nreints/test/runs/s3inz8k2
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                                    Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb: Test loss t(5, 20)_r(0, 0)_tennis_pNone_gNone, MSELoss() â–ˆâ–‚â–â–â–â–â–â–â–â–â–
wandb:                                               Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                                    Epoch 9
wandb: Test loss t(5, 20)_r(0, 0)_tennis_pNone_gNone, MSELoss() 0.00046
wandb:                                               Train loss 0.00075
wandb: 
wandb: ðŸš€ View run fine-deluge-502 at: https://wandb.ai/nreints/test/runs/s3inz8k2
wandb: Synced 6 W&B file(s), 0 media file(s), 2 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230329_133616-s3inz8k2/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230329_134348-eyujvzij
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dark-frog-519
wandb: â­ï¸ View project at https://wandb.ai/nreints/test
wandb: ðŸš€ View run at https://wandb.ai/nreints/test/runs/eyujvzij
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                                    Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb: Test loss t(5, 20)_r(0, 0)_tennis_pNone_gNone, MSELoss() â–ˆâ–‚â–â–â–â–â–â–â–â–â–
wandb:                                               Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                                    Epoch 9
wandb: Test loss t(5, 20)_r(0, 0)_tennis_pNone_gNone, MSELoss() 0.00099
wandb:                                               Train loss 0.00068
wandb: 
wandb: ðŸš€ View run dark-frog-519 at: https://wandb.ai/nreints/test/runs/eyujvzij
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230329_134348-eyujvzij/logs
Running for data type: pos_diff_start
----- ITERATION 1/2 ------
Number of train simulations: 1600
Number of test simulations: 400
-- Finished Train Dataloader --
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(24, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=24, bias=True)
)
-- Started Training --
Epoch 0
	 Logging train Loss: 4.8058498571 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss: 0.2784346640110016 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 40.336853981018066
Epoch 1
	 Logging train Loss: 0.104765766 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss: 0.03779488801956177 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 38.24359369277954
Epoch 2
	 Logging train Loss: 0.0217851555 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss: 0.011237779632210732 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 37.64220094680786
Epoch 3
	 Logging train Loss: 0.0083845461 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss: 0.004916690289974213 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 38.140645027160645
Epoch 4
	 Logging train Loss: 0.004250874 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss: 0.0026583741419017315 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 38.00549602508545
Epoch 5
	 Logging train Loss: 0.0025305204 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss: 0.0016008527018129826 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 38.3071494102478
Epoch 6
	 Logging train Loss: 0.001672662 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss: 0.002448833314701915 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 38.47658085823059
Epoch 7
	 Logging train Loss: 0.0012089876 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss: 0.0011343584628775716 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 38.32799935340881
Epoch 8
	 Logging train Loss: 0.0009049441 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss: 0.0011170770740136504 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 38.092795848846436
Epoch 9
	 Logging train Loss: 0.0007509233 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss: 0.0004575519706122577 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 38.098543643951416
	 Logging test loss: 0.00045759990462101996 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
It took  452.7878098487854  seconds.
----- ITERATION 2/2 ------
Number of train simulations: 1600
Number of test simulations: 400
-- Finished Train Dataloader --
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(24, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=24, bias=True)
)
-- Started Training --
Epoch 0
	 Logging train Loss: 4.8839210745 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss: 0.2891223132610321 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 38.975902795791626
Epoch 1
	 Logging train Loss: 0.1112973935 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss: 0.04063161835074425 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 38.27215361595154
Epoch 2
	 Logging train Loss: 0.0228118387 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss: 0.013133845292031765 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 38.701679706573486
Epoch 3
	 Logging train Loss: 0.0086291279 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss: 0.005946153774857521 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 38.0077588558197
Epoch 4
	 Logging train Loss: 0.0043157121 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss: 0.0031921896152198315 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 38.57620120048523
Epoch 5
	 Logging train Loss: 0.002507777 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss: 0.002411770634353161 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 40.92740321159363
Epoch 6
	 Logging train Loss: 0.0016433903 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss: 0.0012655638856813312 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 42.61267876625061
Epoch 7
	 Logging train Loss: 0.0011541458 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss: 0.0008067219750955701 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 42.227710008621216
Epoch 8
	 Logging train Loss: 0.0009347102 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss: 0.0005778561462648213 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 38.37420964241028
Epoch 9
	 Logging train Loss: 0.0006833397 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss: 0.0009865382453426719 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 38.07091307640076
	 Logging test loss: 0.0009866353357210755 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
It took  457.60661911964417  seconds.
