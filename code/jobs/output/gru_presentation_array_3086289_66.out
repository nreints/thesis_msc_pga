wandb: Currently logged in as: nreints. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_211347-k0c1soxj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run crisp-sponge-463
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/k0c1soxj
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gTrue █▂▁▂▁▁▁▁▂▁
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gTrue █▂▁▁▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gTrue █▂▂▂▁▁▁▁▂▁
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gTrue █▂▂▂▁▁▁▁▂▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gTrue 0.0
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gTrue 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: 🚀 View run crisp-sponge-463 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/k0c1soxj
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_211347-k0c1soxj/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_212100-s0b36jps
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run super-river-468
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/s0b36jps
Training on dataset: data_t(5,20)_r(0,0)_combi_pNone_gTrue
Testing on 4 datasets: ['data_t(5,20)_r(0,0)_semi_pNone_gTrue', 'data_t(5,20)_r(0,0)_full_pNone_gTrue', 'data_t(5,20)_r(0,0)_combi_pNone_gTrue', 'data_t(5,20)_r(0,0)_tennis_pNone_gTrue']
Focussing on identity: True
Using extra input: False
Using fr-fr as reference point.
----- ITERATION 1/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gTrue took 50.636017084121704 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(0,0)_semi_pNone_gTrue took 12.645383358001709 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_full_pNone_gTrue took 12.633816719055176 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gTrue took 12.801816940307617 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_tennis_pNone_gTrue took 12.959028482437134 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0003203811 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.44153e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.38083e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.42323e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.37744e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 32.25420546531677
Epoch 1/9
	 Logging train Loss: 7.8849e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.1082e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.9959e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.0973e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.0774e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 31.790252923965454
Epoch 2/9
	 Logging train Loss: 3.3105e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.9208e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.6511e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.8228e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.8802e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 31.765572786331177
Epoch 3/9
	 Logging train Loss: 2.0321e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.3995e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 9.408e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.2821e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.1508e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 31.71811294555664
Epoch 4/9
	 Logging train Loss: 2.1205e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.3936e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 4.854e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 9.54e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.2639e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 31.65803575515747
Epoch 5/9
	 Logging train Loss: 1.1301e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.558e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.387e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.532e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.503e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 31.90414524078369
Epoch 6/9
	 Logging train Loss: 1.4705e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.75e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.702e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.775e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.728e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 31.697869777679443
Epoch 7/9
	 Logging train Loss: 1.1828e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.523e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.502e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.533e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.503e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 31.63456916809082
Epoch 8/9
	 Logging train Loss: 9.319e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.8359e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.712e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.1536e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.4395e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 31.529719352722168
Epoch 9/9
	 Logging train Loss: 9.973e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.631e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.718e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.202e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.547e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 31.588472843170166
Saved model in  trained_models/gru/data_t(5,20)_r(0,0)_combi_pNone_gTrue/'quat_1'_'False'.pth
It took  433.36285734176636  seconds.
----- ITERATION 2/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gTrue took 49.80777835845947 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(0,0)_semi_pNone_gTrue took 12.58864951133728 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_full_pNone_gTrue took 12.650436401367188 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gTrue took 12.499743700027466 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_tennis_pNone_gTrue took 12.646671056747437 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0002542638 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.23867e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.3448e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.26956e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.40863e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 31.97058868408203
Epoch 1/9
	 Logging train Loss: 8.1507e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.3719e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 3.4029e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.3529e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.5399e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 31.956961393356323
Epoch 2/9
	 Logging train Loss: 3.3779e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.9965e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.0687e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.0138e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.0994e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 31.792974710464478
Epoch 3/9
	 Logging train Loss: 2.863e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.0811e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.1604e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.0647e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.1819e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 31.752946853637695
Epoch 4/9
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gTrue █▂▂▂▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gTrue █▂▂▁▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gTrue █▂▂▂▁▁▁▁▁▁
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gTrue █▂▂▂▁▁▁▁▁▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gTrue 0.0
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gTrue 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: 🚀 View run super-river-468 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/s0b36jps
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_212100-s0b36jps/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_212810-3kkgmqvh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run serene-music-478
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/3kkgmqvh
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gTrue █▂▂▁▂▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gTrue █▂▂▁▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gTrue █▂▂▁▂▁▁▁▁▁
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gTrue █▂▂▁▂▁▁▁▁▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gTrue 0.0
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gTrue 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: 🚀 View run serene-music-478 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/3kkgmqvh
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_212810-3kkgmqvh/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_213522-rwvtr26t
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run valiant-sunset-486
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/rwvtr26t
	 Logging train Loss: 2.2089e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.892e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 5.022e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 4.928e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.146e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 31.921444177627563
Epoch 5/9
	 Logging train Loss: 2.5284e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.484e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.477e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.476e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.599e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 31.851316213607788
Epoch 6/9
	 Logging train Loss: 9.003e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.0924e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 4.241e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 7.462e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.1108e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 31.997767210006714
Epoch 7/9
	 Logging train Loss: 1.9617e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.711e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.648e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.694e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.751e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 31.887726306915283
Epoch 8/9
	 Logging train Loss: 7.887e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.488e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.445e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.478e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.514e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 31.614728212356567
Epoch 9/9
	 Logging train Loss: 1.0067e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.44e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.418e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.446e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.467e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 31.907045602798462
Saved model in  trained_models/gru/data_t(5,20)_r(0,0)_combi_pNone_gTrue/'quat_1'_'False'.pth
It took  429.95433950424194  seconds.
----- ITERATION 3/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gTrue took 49.550477027893066 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(0,0)_semi_pNone_gTrue took 12.674257516860962 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_full_pNone_gTrue took 12.572671175003052 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gTrue took 12.45605206489563 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_tennis_pNone_gTrue took 12.608104705810547 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0002356108 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.63234e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.56571e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.61961e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.57063e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 32.02833557128906
Epoch 1/9
	 Logging train Loss: 8.2822e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.7193e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 3.6069e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.7189e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.6096e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 32.0311803817749
Epoch 2/9
	 Logging train Loss: 3.5041e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.3203e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.0522e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.2263e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.2563e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 31.728174209594727
Epoch 3/9
	 Logging train Loss: 3.0878e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.0534e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.0313e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.0564e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.0279e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 31.855030298233032
Epoch 4/9
	 Logging train Loss: 2.0369e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.252e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 5.594e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.5643e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.2077e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 31.659956455230713
Epoch 5/9
	 Logging train Loss: 1.5192e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.261e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.142e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.194e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.198e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 31.815463066101074
Epoch 6/9
	 Logging train Loss: 1.2127e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.5197e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.07e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 9.235e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.4754e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 31.95977258682251
Epoch 7/9
	 Logging train Loss: 1.1402e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.547e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.474e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.494e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.518e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 31.906782627105713
Epoch 8/9
	 Logging train Loss: 1.2326e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.739e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.412e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.552e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.71e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 31.774712800979614
Epoch 9/9
	 Logging train Loss: 8.572e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.534e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.443e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.468e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.518e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 31.835041999816895
Saved model in  trained_models/gru/data_t(5,20)_r(0,0)_combi_pNone_gTrue/'quat_1'_'False'.pth
It took  431.9705083370209  seconds.
----- ITERATION 4/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gTrue took 49.69113516807556 seconds.
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gTrue █▂▅▅▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gTrue █▂▂▂▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gTrue ▇▂█▇▁▁▁▁▁▁
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gTrue ▇▂█▇▁▁▁▁▁▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gTrue 0.0
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gTrue 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: 🚀 View run valiant-sunset-486 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/rwvtr26t
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_213522-rwvtr26t/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_214232-umq0o2b8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rosy-surf-496
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/umq0o2b8
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(0,0)_semi_pNone_gTrue took 12.54457974433899 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_full_pNone_gTrue took 12.528928995132446 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gTrue took 12.47177243232727 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_tennis_pNone_gTrue took 12.536457538604736 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0002411681 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.79646e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.8641e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.84542e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.84003e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 31.769453287124634
Epoch 1/9
	 Logging train Loss: 1.19008e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.7506e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 3.8156e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.7994e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.8129e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 31.531402349472046
Epoch 2/9
	 Logging train Loss: 3.5964e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.0608e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 3.112e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.73823e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.32165e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 31.77254319190979
Epoch 3/9
	 Logging train Loss: 2.6956e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.73506e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.2422e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.54331e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.97742e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 31.562227725982666
Epoch 4/9
	 Logging train Loss: 3.8176e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.078e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 6.986e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 7.131e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.112e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 31.803422927856445
Epoch 5/9
	 Logging train Loss: 1.5404e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.7385e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 5.604e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.1708e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.817e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 31.78666067123413
Epoch 6/9
	 Logging train Loss: 1.4932e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.989e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.665e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.867e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.989e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 31.957576751708984
Epoch 7/9
	 Logging train Loss: 1.4414e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.722e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.616e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.695e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.705e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 31.849055528640747
Epoch 8/9
	 Logging train Loss: 1.1862e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.569e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.484e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.521e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.516e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 31.832622051239014
Epoch 9/9
	 Logging train Loss: 5.605e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.316e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 4.528e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 4.903e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.309e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 31.60265278816223
Saved model in  trained_models/gru/data_t(5,20)_r(0,0)_combi_pNone_gTrue/'quat_1'_'False'.pth
It took  429.97796988487244  seconds.
----- ITERATION 5/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gTrue took 49.390618324279785 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(0,0)_semi_pNone_gTrue took 12.520441770553589 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_full_pNone_gTrue took 12.530517101287842 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gTrue took 12.433445692062378 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_tennis_pNone_gTrue took 12.535446643829346 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0003389628 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.09455e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 3.14962e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.11575e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.18496e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 31.798285484313965
Epoch 1/9
	 Logging train Loss: 1.19263e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.0974e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 4.1574e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 4.1537e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.2258e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 31.91099739074707
Epoch 2/9
	 Logging train Loss: 3.6148e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.5473e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.6079e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.584e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.6173e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 32.00400185585022
Epoch 3/9
	 Logging train Loss: 3.4209e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.5132e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.5601e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.5273e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.5492e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 31.891750812530518
Epoch 4/9
	 Logging train Loss: 2.4416e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.323e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 8.2e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 8.136e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.552e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 32.005749225616455
Epoch 5/9
	 Logging train Loss: 2.0988e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gTrue █▂▂▁▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gTrue █▂▂▁▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gTrue █▂▂▁▁▁▁▁▁▁
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gTrue █▂▂▁▁▁▁▁▁▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gTrue 0.0
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gTrue 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: 🚀 View run rosy-surf-496 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/umq0o2b8
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_214232-umq0o2b8/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_214944-xcnbqwpa
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run winter-sound-506
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/xcnbqwpa
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gTrue █▂▁▁▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gTrue █▂▁▁▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gTrue █▂▁▁▂▁▂▁▁▁
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gTrue █▂▁▁▂▁▂▁▁▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gTrue 0.0
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gTrue 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: 🚀 View run winter-sound-506 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/xcnbqwpa
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_214944-xcnbqwpa/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_215648-rl812seh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run tough-mountain-514
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/rl812seh
	 Logging test loss: 3.849e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 3.943e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.81e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.916e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 32.0922417640686
Epoch 6/9
	 Logging train Loss: 1.9094e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.236e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.182e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.166e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.259e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 31.92397141456604
Epoch 7/9
	 Logging train Loss: 9.347e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.835e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.737e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.776e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.869e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 31.896425008773804
Epoch 8/9
	 Logging train Loss: 1.1796e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.789e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.557e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.21e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.022e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 31.739527940750122
Epoch 9/9
	 Logging train Loss: 7.394e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.355e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.817e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.637e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.596e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 32.060567140579224
Saved model in  trained_models/gru/data_t(5,20)_r(0,0)_combi_pNone_gTrue/'quat_1'_'False'.pth
It took  431.9605140686035  seconds.
----- ITERATION 6/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gTrue took 49.41637206077576 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(0,0)_semi_pNone_gTrue took 12.52860713005066 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_full_pNone_gTrue took 12.503356695175171 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gTrue took 12.403847455978394 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_tennis_pNone_gTrue took 12.50549840927124 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.001075235 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.34466e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 4.43699e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 4.43791e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.55373e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 31.35268473625183
Epoch 1/9
	 Logging train Loss: 2.17999e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.8276e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 6.9541e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 7.0164e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.2994e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 31.35114312171936
Epoch 2/9
	 Logging train Loss: 3.8028e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.4935e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.415e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.4968e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.6346e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 31.348207712173462
Epoch 3/9
	 Logging train Loss: 2.227e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.607e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.535e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.597e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.7069e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 31.15907335281372
Epoch 4/9
	 Logging train Loss: 2.2374e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.5085e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.0542e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.2801e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.6582e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 31.303022146224976
Epoch 5/9
	 Logging train Loss: 1.8855e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.61e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 4.391e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 5.099e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.985e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 31.18420720100403
Epoch 6/9
	 Logging train Loss: 2.1598e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.3573e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 3.767e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.8822e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.4966e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 30.912537574768066
Epoch 7/9
	 Logging train Loss: 1.8269e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.014e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.755e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.932e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.109e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 31.099685668945312
Epoch 8/9
	 Logging train Loss: 1.5643e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.728e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.524e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.672e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.775e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 31.22250771522522
Epoch 9/9
	 Logging train Loss: 1.7323e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.6e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.478e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.58e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.65e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 31.16734743118286
Saved model in  trained_models/gru/data_t(5,20)_r(0,0)_combi_pNone_gTrue/'quat_1'_'False'.pth
It took  424.06313395500183  seconds.
----- ITERATION 7/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gTrue took 49.38323378562927 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(0,0)_semi_pNone_gTrue took 12.466773986816406 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_full_pNone_gTrue took 12.491997241973877 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gTrue took 12.498101234436035 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_tennis_pNone_gTrue took 12.558811664581299 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gTrue ██▂▁▁▁▁▂▁▂
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gTrue █▄▂▁▁▁▁▂▁▁
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gTrue ▆█▂▁▁▁▁▂▁▂
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gTrue ▆█▂▁▁▁▁▂▁▂
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gTrue 0.0
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gTrue 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: 🚀 View run tough-mountain-514 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/rl812seh
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_215648-rl812seh/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_220352-4vyultjf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run youthful-elevator-524
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/4vyultjf
Datatype: quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0002530218 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.3883e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 5.6124e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 5.3692e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.6383e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 31.10666823387146
Epoch 1/9
	 Logging train Loss: 3.0757e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.8622e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.1429e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 5.0068e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.2073e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 31.31714963912964
Epoch 2/9
	 Logging train Loss: 2.0603e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.3107e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 8.271e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.0606e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.2798e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 31.237126350402832
Epoch 3/9
	 Logging train Loss: 1.6611e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.845e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 3.639e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.706e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.951e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 31.122541666030884
Epoch 4/9
	 Logging train Loss: 1.2693e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.911e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.86e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.88e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.956e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 31.104773998260498
Epoch 5/9
	 Logging train Loss: 1.3694e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.556e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.532e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.554e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.6e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 31.32382607460022
Epoch 6/9
	 Logging train Loss: 1.4072e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.193e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.115e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.174e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.238e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 31.362008333206177
Epoch 7/9
	 Logging train Loss: 1.0288e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.7629e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 5.599e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.2084e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.6509e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 31.36256504058838
Epoch 8/9
	 Logging train Loss: 1.129e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.449e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.411e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.441e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.487e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 31.425710916519165
Epoch 9/9
	 Logging train Loss: 8.385e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.745e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.659e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 5.3e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.034e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 31.30356502532959
Saved model in  trained_models/gru/data_t(5,20)_r(0,0)_combi_pNone_gTrue/'quat_1'_'False'.pth
It took  423.95988154411316  seconds.
----- ITERATION 8/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gTrue took 49.75905251502991 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(0,0)_semi_pNone_gTrue took 12.537635564804077 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_full_pNone_gTrue took 12.561211824417114 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gTrue took 12.456846952438354 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_tennis_pNone_gTrue took 12.513607501983643 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0004192308 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.15091e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.09088e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.99634e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.1044e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 31.027538776397705
Epoch 1/9
	 Logging train Loss: 9.114e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.8147e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.7893e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.7006e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.7916e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 31.387242078781128
Epoch 2/9
	 Logging train Loss: 2.1681e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.8356e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.747e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.725e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.7975e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 31.160679578781128
Epoch 3/9
	 Logging train Loss: 1.644e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.2305e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 9.564e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.0651e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.2243e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 31.158380031585693
Epoch 4/9
	 Logging train Loss: 1.9994e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.423e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 5.138e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 5.059e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.272e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 30.870773792266846
Epoch 5/9
	 Logging train Loss: 1.2805e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.083e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.859e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.865e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.992e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 31.215681552886963
Epoch 6/9
	 Logging train Loss: 1.3859e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.017e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.894e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gTrue █▂▂▁▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gTrue █▂▂▁▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gTrue █▂▂▁▁▁▁▁▁▁
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gTrue █▂▂▁▁▁▁▁▁▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gTrue 0.0
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gTrue 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: 🚀 View run youthful-elevator-524 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/4vyultjf
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_220352-4vyultjf/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_221056-wirqb0s6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run restful-puddle-534
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/wirqb0s6
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gTrue █▂▂▁▁▄▂▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gTrue █▂▂▁▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gTrue █▂▂▁▁▆▃▁▁▁
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gTrue █▂▂▁▁▆▃▁▁▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gTrue 0.0
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gTrue 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: 🚀 View run restful-puddle-534 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/wirqb0s6
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_221056-wirqb0s6/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_221758-4dtf71e4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glowing-cherry-542
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/4dtf71e4
	 Logging test loss: 1.913e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.958e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 31.213975191116333
Epoch 7/9
	 Logging train Loss: 1.3867e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.041e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.789e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.476e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.07e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 30.991113901138306
Epoch 8/9
	 Logging train Loss: 1.2455e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.676e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.722e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.725e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.714e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 31.036017894744873
Epoch 9/9
	 Logging train Loss: 1.2456e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.971e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 3.2e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.61e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.979e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 30.8323814868927
Saved model in  trained_models/gru/data_t(5,20)_r(0,0)_combi_pNone_gTrue/'quat_1'_'False'.pth
It took  424.0230839252472  seconds.
----- ITERATION 9/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gTrue took 49.802438497543335 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(0,0)_semi_pNone_gTrue took 12.50391960144043 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_full_pNone_gTrue took 12.474105834960938 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gTrue took 12.407747030258179 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_tennis_pNone_gTrue took 12.501024961471558 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0001979882 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.08077e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.09166e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.04661e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.13891e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 30.820032119750977
Epoch 1/9
	 Logging train Loss: 4.7246e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.2878e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.257e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.1993e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.3851e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 31.078986644744873
Epoch 2/9
	 Logging train Loss: 3.5519e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.1747e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.1833e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.1455e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.2381e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 30.837852716445923
Epoch 3/9
	 Logging train Loss: 3.0435e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.124e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 6.186e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 5.932e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.473e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 30.988794326782227
Epoch 4/9
	 Logging train Loss: 1.4055e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.375e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 3.436e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.787e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.453e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 31.18116044998169
Epoch 5/9
	 Logging train Loss: 1.7304e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.7691e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 4.819e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 4.1473e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.6298e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 31.045984983444214
Epoch 6/9
	 Logging train Loss: 1.0037e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.7066e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 5.548e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.0446e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.4542e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 30.945767879486084
Epoch 7/9
	 Logging train Loss: 1.0305e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.196e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.757e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.995e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.171e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 31.196764707565308
Epoch 8/9
	 Logging train Loss: 8.867e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.305e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.762e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.032e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.288e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 31.449434518814087
Epoch 9/9
	 Logging train Loss: 7.659e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.997e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.711e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.826e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.818e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 31.183449745178223
Saved model in  trained_models/gru/data_t(5,20)_r(0,0)_combi_pNone_gTrue/'quat_1'_'False'.pth
It took  422.09528136253357  seconds.
----- ITERATION 10/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gTrue took 49.752023458480835 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(0,0)_semi_pNone_gTrue took 12.517858743667603 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_full_pNone_gTrue took 12.501848936080933 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gTrue took 12.464946031570435 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_tennis_pNone_gTrue took 12.530366897583008 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0001744178 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.31875e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.42444e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.41783e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.42367e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 31.086719512939453
Epoch 1/9
	 Logging train Loss: 4.9539e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gTrue █▂▂▁▁▁▁▁▁▄
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gTrue █▂▂▁▁▁▁▁▁▂
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gTrue █▃▂▁▁▁▁▁▂▇
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gTrue █▃▂▁▁▁▁▁▂▇
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gTrue 1e-05
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gTrue 1e-05
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gTrue 1e-05
wandb:                                  Train loss 0.0
wandb: 
wandb: 🚀 View run glowing-cherry-542 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/4dtf71e4
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_221758-4dtf71e4/logs
	 Logging test loss: 3.1847e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.5795e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.8244e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.3771e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 31.372718811035156
Epoch 2/9
	 Logging train Loss: 2.697e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.2378e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.2981e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.2683e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.3315e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 31.100362062454224
Epoch 3/9
	 Logging train Loss: 2.1199e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.763e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 5.859e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 5.775e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.135e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 30.929768562316895
Epoch 4/9
	 Logging train Loss: 2.0135e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.066e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 3.317e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 4.014e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.076e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 30.91025137901306
Epoch 5/9
	 Logging train Loss: 1.1768e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.387e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.711e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.855e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.51e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 31.261858463287354
Epoch 6/9
	 Logging train Loss: 1.7173e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.251e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.734e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.776e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.103e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 31.040249824523926
Epoch 7/9
	 Logging train Loss: 8.629e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.459e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.414e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.454e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.464e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 31.26063299179077
Epoch 8/9
	 Logging train Loss: 8.389e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.1341e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.855e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 5.83e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.1615e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 31.130906105041504
Epoch 9/9
	 Logging train Loss: 8.999e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.17668e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.2082e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 5.5282e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.15983e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 31.101274251937866
Saved model in  trained_models/gru/data_t(5,20)_r(0,0)_combi_pNone_gTrue/'quat_1'_'False'.pth
It took  422.1797089576721  seconds.

JOB STATISTICS
==============
Job ID: 3086314
Array Job ID: 3086289_66
Cluster: snellius
User/Group: nreints/nreints
State: COMPLETED (exit code 0)
Nodes: 1
Cores per node: 18
CPU Utilized: 01:18:39
CPU Efficiency: 6.11% of 21:27:00 core-walltime
Job Wall-clock time: 01:11:30
Memory Utilized: 7.74 GB
Memory Efficiency: 0.00% of 0.00 MB
