wandb: Currently logged in as: nreints. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_125108-8thfdmzt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run twilight-elevator-4
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/8thfdmzt
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue ▇▃█▂▂▃▂▂▁▁
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue █▂█▁▇▄▂▄▁▁
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue █▅▇▂▃▃▁▂▁▁
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue █▃▃▂▁▂▁▁▁▁
wandb:                                 Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue 0.00114
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 1e-05
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.00155
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.00638
wandb:                                 Train loss 0.00116
wandb: 
wandb: 🚀 View run twilight-elevator-4 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/8thfdmzt
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_125108-8thfdmzt/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_125921-oecn1uza
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wandering-pyramid-67
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/oecn1uza
Training on dataset: data_t(0,0)_r(0,0)_combi_pTrue_gTrue
Testing on 4 datasets: ['data_t(0,0)_r(0,0)_full_pTrue_gTrue', 'data_t(0,0)_r(0,0)_tennis_pTrue_gTrue', 'data_t(0,0)_r(0,0)_semi_pTrue_gTrue', 'data_t(0,0)_r(0,0)_combi_pTrue_gTrue']
Focussing on identity: False
Using extra input: False
Using start-fr as reference point.
----- ITERATION 1/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 77.26158452033997 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 19.335588932037354 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 19.29589867591858 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 18.769155025482178 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 19.009997606277466 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.1091733798 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0001480408 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.1602176875 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0303588063 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0123989787 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 34.18798780441284
Epoch 1/9
	 Logging train Loss: 0.0028856432 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.75398e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0506735556 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0171958227 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0039696484 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 32.27492904663086
Epoch 2/9
	 Logging train Loss: 0.0032762443 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0001508982 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0601857603 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.025091609 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.014400335 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 32.489827156066895
Epoch 3/9
	 Logging train Loss: 0.0013000141 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.3256e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0260536112 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0049514957 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0026435 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 32.0133171081543
Epoch 4/9
	 Logging train Loss: 0.0021705164 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0001311108 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0132798962 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0078335637 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0022692773 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 32.01772403717041
Epoch 5/9
	 Logging train Loss: 0.0012407626 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 7.82939e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0208256561 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0078367265 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.004072851 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 32.199363470077515
Epoch 6/9
	 Logging train Loss: 0.0012967957 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.35931e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0118879667 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0030434043 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0022651651 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 32.085898637771606
Epoch 7/9
	 Logging train Loss: 0.0007999071 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 6.11196e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0153973568 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0047133397 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0036648761 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 32.354997634887695
Epoch 8/9
	 Logging train Loss: 0.0009414637 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.42434e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0059939479 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.002060493 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0010951561 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 32.23800778388977
Epoch 9/9
	 Logging train Loss: 0.0011648049 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.06645e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0063808351 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0015499144 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0011354926 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 32.432103633880615
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pTrue_gTrue/'dual_quat'_'False'.pth
It took  494.2217354774475  seconds.
----- ITERATION 2/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 69.24446845054626 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 17.936142921447754 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 17.304298162460327 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 17.278884410858154 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 17.265061616897583 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0958919823 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0001277313 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0641181991 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0104177212 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0065851081 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 32.60425591468811
Epoch 1/9
	 Logging train Loss: 0.00425435 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 6.69926e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.026101375 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0058403751 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0088736946 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 32.30192494392395
Epoch 2/9
	 Logging train Loss: 0.0030662057 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 3.44448e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0259300321 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0080261054 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0041822004 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 32.51454305648804
Epoch 3/9
	 Logging train Loss: 0.001674668 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0001370178 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.026248917 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0095356181 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0088832397 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 32.23641514778137
Epoch 4/9
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue ▂▂▁▂▁▁▂█▁▁
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue ▂▁▁▂▂▁▂█▁▁
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue ▂▁▂▂▂▁▂█▁▂
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue ▄▂▂▂▂▁▂█▁▂
wandb:                                 Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue 0.00175
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 8e-05
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.0073
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.02011
wandb:                                 Train loss 0.00085
wandb: 
wandb: 🚀 View run wandering-pyramid-67 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/oecn1uza
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_125921-oecn1uza/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_130717-w70xg6jl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run different-sky-105
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/w70xg6jl
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue █▄▂▂▂▃▁▁▁▁
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue █▃▂▁▁▃▁▁▁▁
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue █▄▃▃▂▃▁▁▁▁
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue █▄▃▂▂▂▁▁▁▁
wandb:                                 Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue 0.00086
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 1e-05
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.00094
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.00594
wandb:                                 Train loss 0.00111
wandb: 
wandb: 🚀 View run different-sky-105 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/w70xg6jl
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_130717-w70xg6jl/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_131514-dzcq4f0u
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run atomic-cosmos-142
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/dzcq4f0u
	 Logging train Loss: 0.0017027695 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0002417265 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0286570378 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0096361069 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0044867252 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 32.60449194908142
Epoch 5/9
	 Logging train Loss: 0.0007324339 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.91049e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0077506094 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0018380079 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0013171787 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 32.29637837409973
Epoch 6/9
	 Logging train Loss: 0.0013766319 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0001971329 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0251239203 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0070520416 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0071026767 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 32.441614389419556
Epoch 7/9
	 Logging train Loss: 0.0012382491 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0014238297 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.1684486568 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0798152164 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0738090873 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 32.257673025131226
Epoch 8/9
	 Logging train Loss: 0.0012307352 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 7.6988e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0051329695 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0010348393 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0004813273 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 32.55606484413147
Epoch 9/9
	 Logging train Loss: 0.0008488882 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 8.33511e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0201106276 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0073003476 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0017528128 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 32.31490731239319
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pTrue_gTrue/'dual_quat'_'False'.pth
It took  476.1322867870331  seconds.
----- ITERATION 3/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 69.63699531555176 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 17.32111358642578 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 17.279680490493774 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 17.379851579666138 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 17.269254446029663 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0891500562 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0002529589 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.1258337796 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0236273967 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0167397913 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 32.530359983444214
Epoch 1/9
	 Logging train Loss: 0.0040938393 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 5.96842e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0553440973 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0116889104 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0069019585 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 32.145936727523804
Epoch 2/9
	 Logging train Loss: 0.002598136 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.53494e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0367334038 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0072201705 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.003804775 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 32.38545536994934
Epoch 3/9
	 Logging train Loss: 0.0023503483 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.76293e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0254965797 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0061930413 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0041426583 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 32.63119029998779
Epoch 4/9
	 Logging train Loss: 0.0006986677 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.27574e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0167417806 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0048051509 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0040827538 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 32.32382416725159
Epoch 5/9
	 Logging train Loss: 0.0015964481 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 9.08688e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0263968967 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0069052582 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0058989078 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 32.296287059783936
Epoch 6/9
	 Logging train Loss: 0.0014705027 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.48901e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0109722214 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0013215584 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0011055769 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 32.6596896648407
Epoch 7/9
	 Logging train Loss: 0.0013574122 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.31087e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0127573544 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0014725443 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0015385783 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 32.656291007995605
Epoch 8/9
	 Logging train Loss: 0.0006944007 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 6.1234e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0070091705 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0008150046 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0008743989 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 32.47357439994812
Epoch 9/9
	 Logging train Loss: 0.0011110021 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 7.872e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0059449729 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0009389342 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0008639547 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 32.47303366661072
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pTrue_gTrue/'dual_quat'_'False'.pth
It took  477.3705861568451  seconds.
----- ITERATION 4/10 ------
Number of train simulations:  1920
Number of test simulations:  480
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue ▃█▂▃▁▁▂▁▂▁
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue █▄▂▃▁▁▄▁▃▁
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue ▅█▂▆▁▁▅▁▂▁
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue ▄█▂▄▂▁▃▁▂▁
wandb:                                 Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue 0.0005
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 1e-05
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.00028
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.00125
wandb:                                 Train loss 0.0008
wandb: 
wandb: 🚀 View run atomic-cosmos-142 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/dzcq4f0u
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_131514-dzcq4f0u/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_132311-b8vy8nek
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run northern-feather-174
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/b8vy8nek
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 69.67661094665527 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 17.28060245513916 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 17.313239812850952 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 17.358915090560913 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 17.280707597732544 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0869552121 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 7.38026e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0132448096 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0048294174 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0051391036 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 32.59202790260315
Epoch 1/9
	 Logging train Loss: 0.0019569104 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 3.79701e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0255373139 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0074103018 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0171037111 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 32.142417192459106
Epoch 2/9
	 Logging train Loss: 0.0019770584 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.77033e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.004967913 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0013654606 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0021794396 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 32.43363308906555
Epoch 3/9
	 Logging train Loss: 0.0013710391 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.20865e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0105024735 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0057012695 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0048451344 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 32.76327991485596
Epoch 4/9
	 Logging train Loss: 0.002065399 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 8.2183e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0031569051 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0005226467 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0014107965 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 32.35767602920532
Epoch 5/9
	 Logging train Loss: 0.0018026439 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 9.0173e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0023585176 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0005218117 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0009753591 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 32.36588430404663
Epoch 6/9
	 Logging train Loss: 0.0004233957 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 3.60237e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0064795413 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0041796849 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0031296501 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 32.25209450721741
Epoch 7/9
	 Logging train Loss: 0.0013583031 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 9.2763e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0022226528 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0007439776 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0009231881 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 32.35840630531311
Epoch 8/9
	 Logging train Loss: 0.0004600707 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.95829e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.003814647 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0014808396 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0017945134 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 32.34837341308594
Epoch 9/9
	 Logging train Loss: 0.0008022801 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 6.8078e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0012541765 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0002846929 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0005048108 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 32.270209312438965
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pTrue_gTrue/'dual_quat'_'False'.pth
It took  476.24118399620056  seconds.
----- ITERATION 5/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 69.23388910293579 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 17.430882930755615 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 17.681507349014282 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 17.698736906051636 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 17.627832412719727 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0673345029 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 6.6583e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0568233915 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0120466948 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.001733027 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 32.64085245132446
Epoch 1/9
	 Logging train Loss: 0.0027532724 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.02299e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0281223133 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0064445394 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0007861913 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 32.28453040122986
Epoch 2/9
	 Logging train Loss: 0.0018662248 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.22106e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0203276463 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0039660963 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0005608518 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 32.50001764297485
Epoch 3/9
	 Logging train Loss: 0.0031861267 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0001184177 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0214577317 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0042125587 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0023463198 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 32.557995080947876
Epoch 4/9
	 Logging train Loss: 0.002166687 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 8.0699e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0101130959 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0027138393 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0002606307 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 32.7547447681427
Epoch 5/9
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue ▆▃▂█▁▂▁▁▃▂
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue ▅▂▁█▁▂▁▁▃▁
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue █▄▂▃▂▁▁▁▁▂
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue █▄▃▃▁▂▁▁▁▁
wandb:                                 Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue 0.00052
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 1e-05
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.00329
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.00825
wandb:                                 Train loss 0.00112
wandb: 
wandb: 🚀 View run northern-feather-174 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/b8vy8nek
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_132311-b8vy8nek/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_133109-pftjx4g5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run good-wildflower-214
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/pftjx4g5
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue █▆▇▁▁▁▁▁▁▁
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue █▄▃▁▁▁▁▁▁▁
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue █▆▆▁▂▁▁▁▂▁
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue █▅▄▃▂▂▂▁▁▁
wandb:                                 Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue 0.0001
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 1e-05
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.00099
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.00966
wandb:                                 Train loss 0.00165
wandb: 
wandb: 🚀 View run good-wildflower-214 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/pftjx4g5
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_133109-pftjx4g5/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_133907-xo4dkwt4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run apricot-grass-255
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/xo4dkwt4
	 Logging train Loss: 0.0013381731 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.61393e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0125750415 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0023328799 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0006402721 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 32.43385910987854
Epoch 6/9
	 Logging train Loss: 0.0014238021 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 7.0469e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.008170207 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0020025345 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0001999572 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 32.72052454948425
Epoch 7/9
	 Logging train Loss: 0.0007806521 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 9.2471e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0071034497 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0017695362 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0001816503 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 32.500354290008545
Epoch 8/9
	 Logging train Loss: 0.0007223446 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 4.34148e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0104208691 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0022021749 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0008548285 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 32.57279062271118
Epoch 9/9
	 Logging train Loss: 0.0011219393 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.4328e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0082500838 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0032914814 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0005229279 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 32.731658697128296
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pTrue_gTrue/'dual_quat'_'False'.pth
It took  478.7121615409851  seconds.
----- ITERATION 6/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 69.97018933296204 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 17.283323764801025 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 17.291391611099243 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 17.693135499954224 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 17.528642416000366 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.1572879404 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.000109532 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0954964682 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0058359951 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0010768283 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 32.52863311767578
Epoch 1/9
	 Logging train Loss: 0.001362616 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 4.60376e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0623122789 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0041702758 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0008398923 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 32.574542760849
Epoch 2/9
	 Logging train Loss: 0.00250802 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 3.68653e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0506988317 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0040284568 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0009022517 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 32.5519905090332
Epoch 3/9
	 Logging train Loss: 0.001467035 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 8.6778e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.029924633 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0008835638 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 8.32317e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 32.25007343292236
Epoch 4/9
	 Logging train Loss: 0.0020556787 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.02982e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0242376905 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0012299158 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 9.18972e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 32.178436040878296
Epoch 5/9
	 Logging train Loss: 0.0017762696 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 6.1781e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0174142364 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0007257392 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 7.64368e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 32.4579656124115
Epoch 6/9
	 Logging train Loss: 0.0007192877 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 7.3094e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0159500949 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0006698903 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 5.73465e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 32.26336312294006
Epoch 7/9
	 Logging train Loss: 0.0010503333 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 6.5667e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.013826427 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0006649009 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 7.71527e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 32.2671480178833
Epoch 8/9
	 Logging train Loss: 0.0006810236 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.14582e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.010540464 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0012734175 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0001145358 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 32.492615699768066
Epoch 9/9
	 Logging train Loss: 0.001650365 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.02466e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0096553788 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0009900081 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0001019813 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 32.44405913352966
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pTrue_gTrue/'dual_quat'_'False'.pth
It took  477.213907957077  seconds.
----- ITERATION 7/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 70.20332193374634 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 17.244788646697998 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 17.43405795097351 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 17.635794639587402 seconds.
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue █▆▄▄▂▃▂▂▁▁
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue █▂▂▁▁▂▂▁▁▁
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue █▄▃▂▂▂▄▁▁▁
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue █▃▂▂▂▂▂▁▁▁
wandb:                                 Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue 0.00056
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 1e-05
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.00076
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.00361
wandb:                                 Train loss 0.00049
wandb: 
wandb: 🚀 View run apricot-grass-255 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/xo4dkwt4
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_133907-xo4dkwt4/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_134707-ji2eoalq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run worldly-cherry-290
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/ji2eoalq
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 17.572685480117798 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.1570456326 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0002078751 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0472276546 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0104009314 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0053146495 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 32.2669472694397
Epoch 1/9
	 Logging train Loss: 0.0047153453 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 4.77451e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0160008315 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0052681947 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0042078081 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 32.42105507850647
Epoch 2/9
	 Logging train Loss: 0.0018859173 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 3.52442e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0115637537 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0037123016 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0024519854 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 32.220134258270264
Epoch 3/9
	 Logging train Loss: 0.0020816666 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.72533e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0083411764 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0027029649 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0023119908 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 32.16142749786377
Epoch 4/9
	 Logging train Loss: 0.0013208601 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.01554e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0081641227 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0026207727 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0014121084 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 32.15020036697388
Epoch 5/9
	 Logging train Loss: 0.001719832 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.70052e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0090798717 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0021553996 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0017446958 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 32.574976205825806
Epoch 6/9
	 Logging train Loss: 0.000214815 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 3.22774e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0114985667 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0042156861 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0011597024 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 32.39877891540527
Epoch 7/9
	 Logging train Loss: 0.001218786 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.41072e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0048442362 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.000996685 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0009136688 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 32.455785512924194
Epoch 8/9
	 Logging train Loss: 0.0010688625 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.71982e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0058065834 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0014330461 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0007759516 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 32.3325412273407
Epoch 9/9
	 Logging train Loss: 0.0004880558 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 8.9491e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.00361218 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0007619808 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0005645017 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 32.17070984840393
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pTrue_gTrue/'dual_quat'_'False'.pth
It took  480.3085255622864  seconds.
----- ITERATION 8/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 70.31247806549072 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 17.661314725875854 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 17.640204668045044 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 17.667317390441895 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 17.52737045288086 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0701209605 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0001243077 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.076807335 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0152844153 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0150391934 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 32.17735052108765
Epoch 1/9
	 Logging train Loss: 0.0034613765 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.83559e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0216041412 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.005238336 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0030368136 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 32.516751289367676
Epoch 2/9
	 Logging train Loss: 0.0016726875 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.53425e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.01261546 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0031274578 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0026990387 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 32.293418169021606
Epoch 3/9
	 Logging train Loss: 0.0022091691 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 5.13547e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0126645071 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0031052218 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0021738322 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 32.261566162109375
Epoch 4/9
	 Logging train Loss: 0.0019278912 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.27215e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0061442568 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0019280901 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0012265019 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 32.32289266586304
Epoch 5/9
	 Logging train Loss: 0.0007522473 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0001284909 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0133664059 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0040722066 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0049192817 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue ▇▂▂▂▁▃▂▁█▁
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue ▃▁▁▂▁▄▁▁█▁
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue ▆▃▂▂▁▂▂▁█▁
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue █▃▂▂▁▂▂▁▅▁
wandb:                                 Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue 0.00046
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 1e-05
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.00073
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.00287
wandb:                                 Train loss 0.00065
wandb: 
wandb: 🚀 View run worldly-cherry-290 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/ji2eoalq
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_134707-ji2eoalq/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_135504-ji04ih3p
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dandy-planet-329
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/ji04ih3p
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue ▃▂▁█▁▁▄▁▁▁
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue ▇▂▁█▁▁▅▁▂▁
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue ▄▂▂█▁▁▃▁▁▁
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue ▄▂▂█▁▁▃▁▁▁
wandb:                                 Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue 0.00046
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 1e-05
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.00112
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.00475
wandb:                                 Train loss 0.00101
wandb: 
wandb: 🚀 View run dandy-planet-329 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/ji04ih3p
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_135504-ji04ih3p/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_140301-jf0xfo8r
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run devout-cherry-356
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/jf0xfo8r
		--> Epoch time; 32.4329674243927
Epoch 6/9
	 Logging train Loss: 0.0010861835 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.78424e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0116937589 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0039146859 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0027070197 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 32.4364538192749
Epoch 7/9
	 Logging train Loss: 0.0010253206 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 5.7406e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0035097068 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.000754991 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0005532969 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 32.50688123703003
Epoch 8/9
	 Logging train Loss: 0.0010430543 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0003426422 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0495314449 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.019457005 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0189147592 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 32.52700853347778
Epoch 9/9
	 Logging train Loss: 0.0006487417 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 7.7334e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0028655659 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0007286627 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0004612545 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 32.06906485557556
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pTrue_gTrue/'dual_quat'_'False'.pth
It took  477.25101470947266  seconds.
----- ITERATION 9/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 70.33268308639526 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 17.611981868743896 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 17.645910501480103 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 17.696799755096436 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 17.755119800567627 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.1145357713 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0002204278 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0667991713 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0133569175 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.006426116 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 32.143596172332764
Epoch 1/9
	 Logging train Loss: 0.0045790249 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 4.65737e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0302662551 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0072037312 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0021286637 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 32.27444911003113
Epoch 2/9
	 Logging train Loss: 0.0025119502 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.42286e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0170095731 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0039865901 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0012328706 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 32.0527446269989
Epoch 3/9
	 Logging train Loss: 0.0018856869 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0002544371 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.1393021345 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0313616581 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0221770667 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 32.32340431213379
Epoch 4/9
	 Logging train Loss: 0.0019784411 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.44019e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0096112816 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0027077433 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0009841869 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 32.39703178405762
Epoch 5/9
	 Logging train Loss: 0.0017073811 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.04629e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.006724095 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0016780702 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0006966736 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 32.4126718044281
Epoch 6/9
	 Logging train Loss: 0.0018152372 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0001314949 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0500457212 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0117007233 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0087312385 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 32.21987438201904
Epoch 7/9
	 Logging train Loss: 0.0003683998 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 8.1729e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0068690195 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0016842757 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0009284295 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 32.15757989883423
Epoch 8/9
	 Logging train Loss: 0.0009379297 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 3.05118e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0104871001 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0028527973 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0016391731 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 32.320756912231445
Epoch 9/9
	 Logging train Loss: 0.0010098375 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.39145e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0047522197 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0011230613 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0004647126 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 32.201274156570435
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pTrue_gTrue/'dual_quat'_'False'.pth
It took  477.11867094039917  seconds.
----- ITERATION 10/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 70.50132322311401 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 17.278605222702026 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 17.741759061813354 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 17.800180196762085 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 17.5207736492157 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.1392614543 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0001623227 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue ▆▄▆▇█▃▃▁▂▁
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue ▅▂▄▆█▁▂▁▂▁
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue ▇▄▇▇█▃▄▂▂▁
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue ▅▄▇▄█▂▄▁▁▁
wandb:                                 Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue 0.00025
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 1e-05
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.0008
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.00296
wandb:                                 Train loss 0.00112
wandb: 
wandb: 🚀 View run devout-cherry-356 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/jf0xfo8r
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_140301-jf0xfo8r/logs
	 Logging test loss: 0.025824083 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0072952099 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0033516365 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 32.15265107154846
Epoch 1/9
	 Logging train Loss: 0.0045167692 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 4.54417e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0172791835 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0038002464 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0023735573 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 32.28417444229126
Epoch 2/9
	 Logging train Loss: 0.0021078088 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0001377601 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0350251794 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0070752888 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0030283146 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 32.3627495765686
Epoch 3/9
	 Logging train Loss: 0.002341873 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0002329692 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0221482236 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0074062897 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0041683624 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 31.958987951278687
Epoch 4/9
	 Logging train Loss: 0.0017894559 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.000310681 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.041998066 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0081362231 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0045426092 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 31.963205814361572
Epoch 5/9
	 Logging train Loss: 0.001647807 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.69152e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0085164076 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0024248001 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0012659256 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 32.3498957157135
Epoch 6/9
	 Logging train Loss: 0.0015335247 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 4.06992e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0172033999 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0039577363 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0014916341 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 32.24645137786865
Epoch 7/9
	 Logging train Loss: 0.0011298448 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.00854e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0036125048 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0015798082 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0003308626 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 32.049357414245605
Epoch 8/9
	 Logging train Loss: 0.0007512722 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 3.05042e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0053470745 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0016650956 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0008403292 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 32.43423342704773
Epoch 9/9
	 Logging train Loss: 0.0011221509 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 7.1329e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0029623606 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0007951325 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0002452604 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 32.34847640991211
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pTrue_gTrue/'dual_quat'_'False'.pth
It took  475.04504895210266  seconds.

JOB STATISTICS
==============
Job ID: 3081640
Array Job ID: 3081615_27
Cluster: snellius
User/Group: nreints/nreints
State: COMPLETED (exit code 0)
Nodes: 1
Cores per node: 18
CPU Utilized: 01:27:50
CPU Efficiency: 6.09% of 1-00:01:12 core-walltime
Job Wall-clock time: 01:20:04
Memory Utilized: 8.67 GB
Memory Efficiency: 0.00% of 0.00 MB
