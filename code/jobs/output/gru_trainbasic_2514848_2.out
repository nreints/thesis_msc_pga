wandb: Currently logged in as: nreints. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230329_135637-grdctao6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run snowy-bush-539
wandb: â­ï¸ View project at https://wandb.ai/nreints/test
wandb: ðŸš€ View run at https://wandb.ai/nreints/test/runs/grdctao6
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                                  Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb: Test loss t(0, 0)_r(5, 20)_semi_pNone_gNone, MSELoss() â–ˆâ–‡â–…â–ƒâ–‚â–â–â–â–â–â–
wandb:                                             Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                                  Epoch 9
wandb: Test loss t(0, 0)_r(5, 20)_semi_pNone_gNone, MSELoss() 0.03593
wandb:                                             Train loss 0.0372
wandb: 
wandb: ðŸš€ View run snowy-bush-539 at: https://wandb.ai/nreints/test/runs/grdctao6
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230329_135637-grdctao6/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230329_140413-mjdqssvo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run avid-field-549
wandb: â­ï¸ View project at https://wandb.ai/nreints/test
wandb: ðŸš€ View run at https://wandb.ai/nreints/test/runs/mjdqssvo
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.031 MB of 0.031 MB uploaded (0.000 MB deduped)wandb: \ 0.031 MB of 0.079 MB uploaded (0.000 MB deduped)wandb: | 0.031 MB of 0.079 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:                                                  Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb: Test loss t(0, 0)_r(5, 20)_semi_pNone_gNone, MSELoss() â–ˆâ–‡â–†â–ƒâ–‚â–â–â–â–â–â–
wandb:                                             Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                                  Epoch 9
wandb: Test loss t(0, 0)_r(5, 20)_semi_pNone_gNone, MSELoss() 0.03317
wandb:                                             Train loss 0.03455
wandb: 
wandb: ðŸš€ View run avid-field-549 at: https://wandb.ai/nreints/test/runs/mjdqssvo
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230329_140413-mjdqssvo/logs
Running for data type: eucl_motion
----- ITERATION 1/2 ------
Number of train simulations: 1600
Number of test simulations: 400
-- Finished Train Dataloader --
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
-- Started Training --
Epoch 0
	 Logging train Loss: 13.3949575997 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss: 0.5752041935920715 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
     --> Epoch time; 40.78736090660095
Epoch 1
	 Logging train Loss: 0.524788626 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss: 0.4906761050224304 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
     --> Epoch time; 38.48626184463501
Epoch 2
	 Logging train Loss: 0.4247957237 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss: 0.32772600650787354 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
     --> Epoch time; 38.3922598361969
Epoch 3
	 Logging train Loss: 0.2367482408 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss: 0.15421372652053833 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
     --> Epoch time; 38.286437034606934
Epoch 4
	 Logging train Loss: 0.1152928738 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss: 0.08440225571393967 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
     --> Epoch time; 38.42935085296631
Epoch 5
	 Logging train Loss: 0.0711749221 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss: 0.0611405111849308 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
     --> Epoch time; 38.169687271118164
Epoch 6
	 Logging train Loss: 0.0545935433 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss: 0.04995371028780937 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
     --> Epoch time; 38.47266483306885
Epoch 7
	 Logging train Loss: 0.0455869973 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss: 0.043695226311683655 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
     --> Epoch time; 38.5284059047699
Epoch 8
	 Logging train Loss: 0.0405363152 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss: 0.038520392030477524 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
     --> Epoch time; 39.96998190879822
Epoch 9
	 Logging train Loss: 0.0371953839 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss: 0.0359172560274601 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
     --> Epoch time; 40.130417585372925
	 Logging test loss: 0.03593066334724426 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
It took  456.79591703414917  seconds.
----- ITERATION 2/2 ------
Number of train simulations: 1600
Number of test simulations: 400
-- Finished Train Dataloader --
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
-- Started Training --
Epoch 0
	 Logging train Loss: 12.6081976489 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss: 0.5741753578186035 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
     --> Epoch time; 39.05833029747009
Epoch 1
	 Logging train Loss: 0.5280026282 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss: 0.5068180561065674 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
     --> Epoch time; 38.6193425655365
Epoch 2
	 Logging train Loss: 0.4791525827 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss: 0.4321647882461548 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
     --> Epoch time; 38.58365178108215
Epoch 3
	 Logging train Loss: 0.2927241816 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss: 0.1726173460483551 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
     --> Epoch time; 38.77821898460388
Epoch 4
	 Logging train Loss: 0.1131086057 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss: 0.08153904229402542 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
     --> Epoch time; 38.952369928359985
Epoch 5
	 Logging train Loss: 0.0615584268 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss: 0.0520595908164978 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
     --> Epoch time; 38.37187314033508
Epoch 6
	 Logging train Loss: 0.0456496978 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss: 0.04329664632678032 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
     --> Epoch time; 38.814377784729004
Epoch 7
	 Logging train Loss: 0.0399154643 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss: 0.03850759193301201 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
     --> Epoch time; 38.68518543243408
Epoch 8
	 Logging train Loss: 0.0367706513 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss: 0.036797069013118744 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
     --> Epoch time; 38.877713441848755
Epoch 9
	 Logging train Loss: 0.034554167 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss: 0.03312743827700615 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
     --> Epoch time; 38.81326484680176
	 Logging test loss: 0.033171068876981735 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
It took  450.7217297554016  seconds.

JOB STATISTICS
==============
Job ID: 2514850
Array Job ID: 2514848_2
Cluster: snellius
User/Group: nreints/nreints
State: COMPLETED (exit code 0)
Nodes: 1
Cores per node: 18
CPU Utilized: 02:59:02
CPU Efficiency: 64.87% of 04:36:00 core-walltime
Job Wall-clock time: 00:15:20
Memory Utilized: 25.62 GB
Memory Efficiency: 81.98% of 31.25 GB
