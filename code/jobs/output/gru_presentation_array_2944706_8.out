wandb: Currently logged in as: nreints. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230620_141200-26u27rfp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run curious-bird-276
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal/runs/26u27rfp
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone █▃▂▂▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone █▆▄▂▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone █▆▄▂▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone █▃▂▂▁▁▁▁▁▁
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone █▃▂▂▁▁▁▁▁▁
wandb:                                   Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone 1e-05
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 1e-05
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 1e-05
wandb:                                   Train loss 2e-05
wandb: 
wandb: 🚀 View run curious-bird-276 at: https://wandb.ai/nreints/ThesisFinal/runs/26u27rfp
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230620_141200-26u27rfp/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230620_142054-wcupxteg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run trim-grass-305
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal/runs/wcupxteg
Training on dataset: data_t(5,20)_r(5,20)_combi_pNone_gNone
Testing on 5 datasets: ['data_t(5,20)_r(5,20)_full_pNone_gNone', 'data_t(5,20)_r(5,20)_semi_pNone_gNone', 'data_t(5,20)_r(5,20)_none_pNone_gNone', 'data_t(5,20)_r(5,20)_combi_pNone_gNone', 'data_t(5,20)_r(5,20)_tennis_pNone_gNone']
Focussing on identity: False
Using extra input: inertia_body
Using fr-fr as reference point.
----- ITERATION 1/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 60.44927954673767 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 15.192904472351074 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 15.153692245483398 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_none_pNone_gNone took 15.31589412689209 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 15.31493091583252 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 15.323357343673706 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (pre_hidden_lin_layer): Sequential(
    (0): Linear(in_features=3, out_features=96, bias=True)
    (1): ReLU()
    (2): Linear(in_features=96, out_features=96, bias=True)
    (3): ReLU()
  )
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0108729852 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.1364e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0003122682 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 6.81407e-05 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0002533549 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0005838057 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 39.37386226654053
Epoch 1/9
	 Logging train Loss: 0.0001613011 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.92932e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0001135254 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.66705e-05 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 8.91039e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0001518621 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 38.117319107055664
Epoch 2/9
	 Logging train Loss: 6.33264e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.66994e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 6.08492e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.52283e-05 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 4.43341e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.42229e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 38.2099175453186
Epoch 3/9
	 Logging train Loss: 3.16326e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 9.0125e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 5.33202e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 8.4719e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 4.06336e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.95064e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 37.8274872303009
Epoch 4/9
	 Logging train Loss: 2.2549e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.365e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.3476e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.4359e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.10347e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.19986e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 38.13429832458496
Epoch 5/9
	 Logging train Loss: 2.717e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.1768e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.79339e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.243e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.80599e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.90549e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 37.95631742477417
Epoch 6/9
	 Logging train Loss: 2.72936e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.4184e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.64131e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.4193e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 9.2107e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.74698e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 38.308894872665405
Epoch 7/9
	 Logging train Loss: 2.01637e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.2117e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.82337e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.2628e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.75365e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.47833e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 38.15878772735596
Epoch 8/9
	 Logging train Loss: 1.95643e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.1191e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.64404e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.0975e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.64261e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.28679e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 37.87350511550903
Epoch 9/9
	 Logging train Loss: 1.90126e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.0881e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.24072e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.104e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 6.8323e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.25333e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 37.93602132797241
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gNone/'dual_quat_1'_'inertia_body'.pth
It took  535.3531224727631  seconds.
----- ITERATION 2/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 55.401466846466064 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 14.036901235580444 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 14.01921796798706 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_none_pNone_gNone took 14.084328651428223 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 13.875073432922363 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 14.035618543624878 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (pre_hidden_lin_layer): Sequential(
    (0): Linear(in_features=3, out_features=96, bias=True)
    (1): ReLU()
    (2): Linear(in_features=96, out_features=96, bias=True)
    (3): ReLU()
  )
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat_1
-- Started Training --
Epoch 0/9
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone █▄▂▂▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone █▇▅▄▂▁▁▁▁▁
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone █▇▅▄▂▁▁▁▁▁
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone █▄▃▂▁▁▁▁▁▁
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone █▃▂▂▁▁▁▁▁▁
wandb:                                   Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone 1e-05
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 2e-05
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 3e-05
wandb:                                   Train loss 3e-05
wandb: 
wandb: 🚀 View run trim-grass-305 at: https://wandb.ai/nreints/ThesisFinal/runs/wcupxteg
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230620_142054-wcupxteg/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230620_142930-zsh2irak
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pious-paper-323
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal/runs/zsh2irak
	 Logging train Loss: 0.0259460323 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.07294e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0003306619 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 8.30971e-05 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0003423888 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0008338227 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 37.9565167427063
Epoch 1/9
	 Logging train Loss: 0.0001961907 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.59065e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0001435524 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 6.68837e-05 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0001334423 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.000253564 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 37.818448066711426
Epoch 2/9
	 Logging train Loss: 9.29911e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.01993e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 8.71313e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 5.10006e-05 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 7.3685e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0001041683 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 37.92283797264099
Epoch 3/9
	 Logging train Loss: 6.03886e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.26332e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 6.49276e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.32984e-05 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 6.27131e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0001075457 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 38.218207597732544
Epoch 4/9
	 Logging train Loss: 4.20506e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.53636e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.59244e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.59519e-05 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.7532e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.03956e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 38.26536273956299
Epoch 5/9
	 Logging train Loss: 2.87023e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.8547e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.86554e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 5.1509e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.10779e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.42191e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 37.87233257293701
Epoch 6/9
	 Logging train Loss: 2.85823e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.8291e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.87991e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.9328e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.15636e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.28651e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 37.6439266204834
Epoch 7/9
	 Logging train Loss: 2.67116e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.3124e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.82617e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.3766e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.05164e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.98743e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 37.7416353225708
Epoch 8/9
	 Logging train Loss: 2.65775e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.0749e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.57173e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.1188e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 9.3574e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.88615e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 38.26571798324585
Epoch 9/9
	 Logging train Loss: 2.5256e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.435e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.94557e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.4721e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.28522e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.68312e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 36.98493814468384
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gNone/'dual_quat_1'_'inertia_body'.pth
It took  516.3384246826172  seconds.
----- ITERATION 3/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 54.84811305999756 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 13.996720552444458 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 13.963384628295898 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_none_pNone_gNone took 13.898954391479492 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 13.789448976516724 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 14.004690885543823 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (pre_hidden_lin_layer): Sequential(
    (0): Linear(in_features=3, out_features=96, bias=True)
    (1): ReLU()
    (2): Linear(in_features=96, out_features=96, bias=True)
    (3): ReLU()
  )
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0304930359 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.00303e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0003802913 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 7.8834e-05 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0003910089 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0009805012 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 37.78266978263855
Epoch 1/9
	 Logging train Loss: 0.000236492 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.22749e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0001320339 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 6.18352e-05 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0001407159 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0003059513 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 37.58492469787598
Epoch 2/9
	 Logging train Loss: 9.30846e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.68598e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 7.68805e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.66093e-05 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 6.79185e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0001034512 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 38.01678514480591
Epoch 3/9
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone █▃▂▂▁▁▂▂▁▁
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone █▆▅▄▂▁▁▁▁▁
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone █▆▅▄▂▁▁▁▁▁
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone █▃▂▂▂▁▂▂▁▁
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone █▃▂▁▁▁▂▂▁▁
wandb:                                   Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone 1e-05
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 1e-05
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 2e-05
wandb:                                   Train loss 2e-05
wandb: 
wandb: 🚀 View run pious-paper-323 at: https://wandb.ai/nreints/ThesisFinal/runs/zsh2irak
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230620_142930-zsh2irak/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230620_143808-xvehmn5d
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run graceful-donkey-339
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal/runs/xvehmn5d
	 Logging train Loss: 5.43141e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.99416e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 5.28367e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.98768e-05 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 4.29722e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.14087e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 38.03970813751221
Epoch 4/9
	 Logging train Loss: 3.8496e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.408e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.59385e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.41053e-05 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.46771e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.55431e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 38.69250750541687
Epoch 5/9
	 Logging train Loss: 3.0699e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.1945e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.07886e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.249e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.45889e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.88274e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 38.19500923156738
Epoch 6/9
	 Logging train Loss: 2.40584e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.8153e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 6.61958e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.802e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 4.44153e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0001054411 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 38.3497474193573
Epoch 7/9
	 Logging train Loss: 2.61856e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.5748e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 6.60035e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.5837e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 4.51896e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.000108672 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 37.97025227546692
Epoch 8/9
	 Logging train Loss: 2.3267e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.961e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.25968e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.0268e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.4078e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.94887e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 37.988227128982544
Epoch 9/9
	 Logging train Loss: 1.96862e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.0528e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.42681e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.1059e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 8.478e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.8188e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 38.289018869400024
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gNone/'dual_quat_1'_'inertia_body'.pth
It took  517.4306640625  seconds.
----- ITERATION 4/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 54.72676491737366 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 13.99326777458191 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 13.979344606399536 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_none_pNone_gNone took 13.949763298034668 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 13.695558309555054 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 13.978425979614258 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (pre_hidden_lin_layer): Sequential(
    (0): Linear(in_features=3, out_features=96, bias=True)
    (1): ReLU()
    (2): Linear(in_features=96, out_features=96, bias=True)
    (3): ReLU()
  )
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0048860447 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.54163e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0001295973 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 6.78096e-05 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0001178155 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0002407197 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 38.175952672958374
Epoch 1/9
	 Logging train Loss: 7.98108e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.92212e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 6.52398e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.07301e-05 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 5.46338e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.69012e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 38.36534285545349
Epoch 2/9
	 Logging train Loss: 4.29046e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.52862e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.73557e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.59017e-05 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.7055e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.51339e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 38.22509956359863
Epoch 3/9
	 Logging train Loss: 2.9405e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.3134e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.92947e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.5344e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.17482e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.9921e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 37.90262532234192
Epoch 4/9
	 Logging train Loss: 2.98738e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.4283e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.82999e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.5461e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 9.6752e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.41069e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 37.88911032676697
Epoch 5/9
	 Logging train Loss: 2.41647e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.5004e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.52969e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.6095e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.35962e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.44883e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 37.9930636882782
Epoch 6/9
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone █▄▂▂▁▁▁▃▁▁
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone █▅▃▁▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone █▅▃▁▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone █▄▂▃▁▂▁▅▁▁
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone █▃▂▂▁▂▁▃▁▁
wandb:                                   Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone 1e-05
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 1e-05
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 2e-05
wandb:                                   Train loss 1e-05
wandb: 
wandb: 🚀 View run graceful-donkey-339 at: https://wandb.ai/nreints/ThesisFinal/runs/xvehmn5d
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230620_143808-xvehmn5d/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230620_144650-ynxh3qoe
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run peachy-bee-358
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal/runs/ynxh3qoe
	 Logging train Loss: 1.95687e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.0639e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.89765e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.164e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 9.915e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.38226e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 39.70032858848572
Epoch 7/9
	 Logging train Loss: 1.92442e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.1572e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 7.80967e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.2223e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.81781e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.22877e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 39.43867754936218
Epoch 8/9
	 Logging train Loss: 1.68092e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 9.802e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.28923e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.0557e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 6.6199e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.52302e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 37.73886299133301
Epoch 9/9
	 Logging train Loss: 1.2747e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.0813e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.39306e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.0731e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 9.4864e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.04273e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 38.313902616500854
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gNone/'dual_quat_1'_'inertia_body'.pth
It took  521.7804481983185  seconds.
----- ITERATION 5/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 54.794374227523804 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 13.856227397918701 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 13.848378896713257 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_none_pNone_gNone took 13.874513387680054 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 13.771875381469727 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 13.866684436798096 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (pre_hidden_lin_layer): Sequential(
    (0): Linear(in_features=3, out_features=96, bias=True)
    (1): ReLU()
    (2): Linear(in_features=96, out_features=96, bias=True)
    (3): ReLU()
  )
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0440061092 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0004340329 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.006859865 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0004466732 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0055886167 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0136364186 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 37.59693479537964
Epoch 1/9
	 Logging train Loss: 0.0027642304 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.000186691 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0048812474 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0001910825 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0027239798 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0052003246 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 37.9687602519989
Epoch 2/9
	 Logging train Loss: 0.0021209896 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0001448545 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0030775983 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0001463051 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0017833135 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0034393994 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 37.392136335372925
Epoch 3/9
	 Logging train Loss: 0.0008326039 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.80365e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0006193165 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 8.58766e-05 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0004370531 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0008774146 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 37.677945613861084
Epoch 4/9
	 Logging train Loss: 0.0002966631 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.08238e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0003403439 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 6.97106e-05 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0002520745 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0004947275 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 37.66347122192383
Epoch 5/9
	 Logging train Loss: 0.0001780915 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.9048e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0001777157 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 5.77372e-05 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0001483095 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0002776707 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 37.691667556762695
Epoch 6/9
	 Logging train Loss: 0.0001029164 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.57668e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 8.43058e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.51645e-05 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 8.30345e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0001485406 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 38.42278075218201
Epoch 7/9
	 Logging train Loss: 5.78394e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.76006e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.6137e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.71853e-05 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 4.31617e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.03113e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 37.49172401428223
Epoch 8/9
	 Logging train Loss: 3.38624e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.00158e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.29077e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 9.6963e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.20917e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.26438e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 37.327308893203735
Epoch 9/9
wandb: Waiting for W&B process to finish... (success).
wandb: ERROR Error while calling W&B API: An internal error occurred. Please contact support. (<Response [500]>)
wandb: 
wandb: Run history:
wandb:                                        Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone █▄▃▂▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone █▄▃▂▂▂▂▁▁▁
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone █▄▃▂▂▂▂▁▁▁
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone █▆▄▂▁▁▁▁▁▁
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone █▄▃▁▁▁▁▁▁▁
wandb:                                   Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone 1e-05
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 2e-05
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 2e-05
wandb:                                   Train loss 2e-05
wandb: 
wandb: 🚀 View run peachy-bee-358 at: https://wandb.ai/nreints/ThesisFinal/runs/ynxh3qoe
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230620_144650-ynxh3qoe/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230620_145525-zz6b1v7n
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fresh-galaxy-376
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal/runs/zz6b1v7n
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone █▅▃▂▁▁▁▁▂▁
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone █▆▅▃▂▁▁▁▁▁
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone █▆▅▃▂▁▁▁▁▁
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone █▄▃▂▁▁▁▁▂▁
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone █▄▂▂▁▁▁▁▂▁
wandb:                                   Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone 1e-05
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 2e-05
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 4e-05
wandb:                                   Train loss 2e-05
wandb: 
wandb: 🚀 View run fresh-galaxy-376 at: https://wandb.ai/nreints/ThesisFinal/runs/zz6b1v7n
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230620_145525-zz6b1v7n/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230620_150400-p5pd70w5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run neat-sponge-393
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal/runs/p5pd70w5
	 Logging train Loss: 2.418e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.9149e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.64513e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.8701e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.05865e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.93149e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 37.124260663986206
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gNone/'dual_quat_1'_'inertia_body'.pth
It took  515.5191876888275  seconds.
----- ITERATION 6/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 54.61562943458557 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 13.81727933883667 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 13.829257488250732 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_none_pNone_gNone took 13.949412822723389 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 13.71602749824524 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 13.944812297821045 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (pre_hidden_lin_layer): Sequential(
    (0): Linear(in_features=3, out_features=96, bias=True)
    (1): ReLU()
    (2): Linear(in_features=96, out_features=96, bias=True)
    (3): ReLU()
  )
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0299684051 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 9.16826e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0003882378 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 9.73626e-05 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0002744545 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0006223916 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 37.11736512184143
Epoch 1/9
	 Logging train Loss: 0.0002122804 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.36978e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.00019782 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 6.51712e-05 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0001512491 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0003161527 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 38.50351071357727
Epoch 2/9
	 Logging train Loss: 0.0001150546 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.95954e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 9.62547e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 5.0632e-05 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 7.90344e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0001266945 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 37.47370743751526
Epoch 3/9
	 Logging train Loss: 6.04598e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.32977e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 5.41037e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.40883e-05 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 4.54411e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.26233e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 39.33006978034973
Epoch 4/9
	 Logging train Loss: 3.60918e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.67087e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.52815e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.71854e-05 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.65536e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.93561e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 39.01254749298096
Epoch 5/9
	 Logging train Loss: 1.91228e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.9626e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.98205e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 5.1019e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.2443e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.19305e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 37.94381022453308
Epoch 6/9
	 Logging train Loss: 1.72771e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.4618e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.52643e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.5842e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 8.0354e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.58812e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 37.09576487541199
Epoch 7/9
	 Logging train Loss: 2.09838e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.7466e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.36586e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.8223e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.34611e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.15113e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 37.27162790298462
Epoch 8/9
	 Logging train Loss: 2.16929e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.0714e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 5.32624e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.1732e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.98047e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.86457e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 37.457985639572144
Epoch 9/9
	 Logging train Loss: 1.87644e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.2552e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.23902e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.3347e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.35878e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.59842e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 37.14921164512634
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gNone/'dual_quat_1'_'inertia_body'.pth
It took  515.1435539722443  seconds.
----- ITERATION 7/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 54.993366718292236 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 13.95673155784607 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 13.856251955032349 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_none_pNone_gNone took 13.900152206420898 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 13.79381251335144 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 13.949584007263184 seconds.
-- Finished Test Dataloader(s) --
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone █▃▂▁▁▁▇▁▁▁
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone █▆▃▂▁▁▃▁▁▁
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone █▆▃▂▁▁▃▁▁▁
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone ▇▃▂▁▁▁█▁▁▁
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone █▂▁▁▁▁▇▁▁▁
wandb:                                   Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone 2e-05
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 4e-05
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 4e-05
wandb:                                   Train loss 2e-05
wandb: 
wandb: 🚀 View run neat-sponge-393 at: https://wandb.ai/nreints/ThesisFinal/runs/p5pd70w5
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230620_150400-p5pd70w5/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230620_151233-vwxxky8d
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vocal-forest-411
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal/runs/vwxxky8d
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (pre_hidden_lin_layer): Sequential(
    (0): Linear(in_features=3, out_features=96, bias=True)
    (1): ReLU()
    (2): Linear(in_features=96, out_features=96, bias=True)
    (3): ReLU()
  )
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0150921401 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.54926e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0002954652 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 6.55354e-05 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0002621301 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.000570463 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 37.16737079620361
Epoch 1/9
	 Logging train Loss: 0.0001366466 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.50698e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 9.42979e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.49541e-05 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 7.40661e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0001050122 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 38.42029690742493
Epoch 2/9
	 Logging train Loss: 5.33511e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.34153e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 5.28002e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.34051e-05 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.9163e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.38232e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 37.78587031364441
Epoch 3/9
	 Logging train Loss: 3.16206e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.7681e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.03399e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 6.8729e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.9505e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.16862e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 37.311772108078
Epoch 4/9
	 Logging train Loss: 2.52912e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.0296e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.57589e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.1183e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.25458e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.26717e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 37.75690960884094
Epoch 5/9
	 Logging train Loss: 2.56579e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.0069e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.48571e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.0719e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.61148e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.20253e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 37.30282020568848
Epoch 6/9
	 Logging train Loss: 2.42638e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.81469e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0003610881 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.85733e-05 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0002273364 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0004662891 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 37.52661466598511
Epoch 7/9
	 Logging train Loss: 2.36828e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.4107e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.69119e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.4997e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.50886e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.19427e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 37.072362184524536
Epoch 8/9
	 Logging train Loss: 1.92072e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.647e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.40504e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 9.211e-07 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 8.3196e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.63753e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 37.35656476020813
Epoch 9/9
	 Logging train Loss: 1.68435e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.4613e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.65481e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.5367e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.26991e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.36162e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 37.49860215187073
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gNone/'dual_quat_1'_'inertia_body'.pth
It took  512.4736659526825  seconds.
----- ITERATION 8/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 55.3576602935791 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 13.965121030807495 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 13.86435055732727 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_none_pNone_gNone took 13.960459232330322 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 13.845771551132202 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 13.860546588897705 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (pre_hidden_lin_layer): Sequential(
    (0): Linear(in_features=3, out_features=96, bias=True)
    (1): ReLU()
    (2): Linear(in_features=96, out_features=96, bias=True)
    (3): ReLU()
  )
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0197528191 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.48229e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0004719252 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 7.311e-05 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0003880328 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0009339618 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 36.16777777671814
Epoch 1/9
	 Logging train Loss: 0.0002296072 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.34788e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0001538383 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 5.21341e-05 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0001289699 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0002527023 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 36.37283635139465
Epoch 2/9
	 Logging train Loss: 8.35958e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.15825e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone █▃▂▁▁▁▁▁▂▁
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone █▆▄▂▁▁▁▁▁▂
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone █▆▄▂▁▁▁▁▁▂
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone █▃▂▁▁▁▁▁▂▁
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone █▃▁▁▁▁▁▁▁▁
wandb:                                   Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone 2e-05
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 1e-05
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone 1e-05
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 4e-05
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 4e-05
wandb:                                   Train loss 2e-05
wandb: 
wandb: 🚀 View run vocal-forest-411 at: https://wandb.ai/nreints/ThesisFinal/runs/vwxxky8d
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230620_151233-vwxxky8d/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230620_152057-ud7bbfbb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run likely-moon-425
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal/runs/ud7bbfbb
	 Logging test loss: 7.46947e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.0706e-05 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 5.60717e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.24709e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 37.51439356803894
Epoch 3/9
	 Logging train Loss: 4.52605e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.26681e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 5.01249e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.2323e-05 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.4243e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.87478e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 35.53975558280945
Epoch 4/9
	 Logging train Loss: 3.41764e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.9202e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.29393e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.8402e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.51585e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.37565e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 35.85565185546875
Epoch 5/9
	 Logging train Loss: 3.17115e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.9679e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.31742e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.9959e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.26063e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.61867e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 36.21558618545532
Epoch 6/9
	 Logging train Loss: 2.89126e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.127e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.79622e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.1783e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.03237e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.88954e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 37.914061307907104
Epoch 7/9
	 Logging train Loss: 2.60559e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.3453e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.49255e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.395e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.3846e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.49079e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 37.345667362213135
Epoch 8/9
	 Logging train Loss: 2.09636e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.8295e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 7.15941e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.8622e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 4.03801e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.18464e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 37.55801439285278
Epoch 9/9
	 Logging train Loss: 1.90725e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.744e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.84902e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 8.7498e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.4238e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.8625e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 37.332767963409424
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gNone/'dual_quat_1'_'inertia_body'.pth
It took  504.42000007629395  seconds.
----- ITERATION 9/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 54.74988603591919 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 13.86387825012207 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 13.85791301727295 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_none_pNone_gNone took 13.883687257766724 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 13.683919668197632 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 13.849690437316895 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (pre_hidden_lin_layer): Sequential(
    (0): Linear(in_features=3, out_features=96, bias=True)
    (1): ReLU()
    (2): Linear(in_features=96, out_features=96, bias=True)
    (3): ReLU()
  )
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0137180984 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.47715e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0002971571 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 8.78312e-05 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0002827731 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0005639262 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 37.416800022125244
Epoch 1/9
	 Logging train Loss: 0.0001696462 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.2983e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0001360268 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 6.62526e-05 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0001253079 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0002102571 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 37.463210582733154
Epoch 2/9
	 Logging train Loss: 8.5101e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.02747e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 8.17415e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.25074e-05 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 6.7708e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 9.65019e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 37.30800914764404
Epoch 3/9
	 Logging train Loss: 4.6974e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.78e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.58858e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.89518e-05 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.47479e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.00817e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 37.11179327964783
Epoch 4/9
	 Logging train Loss: 3.65878e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.8725e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.92894e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 5.3242e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.9982e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.51922e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 37.55056643486023
Epoch 5/9
	 Logging train Loss: 2.99612e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.6032e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone █▄▂▁▁▂▁▂▁▁
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone █▆▄▂▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone █▆▄▂▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone █▄▂▂▁▂▂▃▂▁
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone █▃▂▁▁▂▁▂▁▁
wandb:                                   Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone 2e-05
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 3e-05
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 3e-05
wandb:                                   Train loss 2e-05
wandb: 
wandb: 🚀 View run likely-moon-425 at: https://wandb.ai/nreints/ThesisFinal/runs/ud7bbfbb
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230620_152057-ud7bbfbb/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230620_152931-n2an34xz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run peach-planet-443
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal/runs/n2an34xz
	 Logging test loss: 6.13907e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 7.7915e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 4.00537e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.35146e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 37.8676598072052
Epoch 6/9
	 Logging train Loss: 2.75056e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.3682e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 5.12118e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.4522e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.12508e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.66123e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 37.60165071487427
Epoch 7/9
	 Logging train Loss: 2.483e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.9454e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0001025872 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.9686e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 6.99897e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0001378846 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 37.66480231285095
Epoch 8/9
	 Logging train Loss: 2.34731e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.6773e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.89822e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 6.7274e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.43373e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.47428e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 38.33615064620972
Epoch 9/9
	 Logging train Loss: 1.95461e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.4404e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.60273e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.5154e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.7158e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.14114e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 37.424203395843506
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gNone/'dual_quat_1'_'inertia_body'.pth
It took  513.3669455051422  seconds.
----- ITERATION 10/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 54.8205783367157 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 13.905358791351318 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 13.82270359992981 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_none_pNone_gNone took 13.847052335739136 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 13.673527717590332 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 13.928763628005981 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (pre_hidden_lin_layer): Sequential(
    (0): Linear(in_features=3, out_features=96, bias=True)
    (1): ReLU()
    (2): Linear(in_features=96, out_features=96, bias=True)
    (3): ReLU()
  )
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0114833424 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.71503e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0002981308 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 7.39577e-05 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.000294599 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0005636981 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 38.225929498672485
Epoch 1/9
	 Logging train Loss: 0.0001570546 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.06758e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0001104393 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.85913e-05 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0001006483 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0001676529 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 37.99811029434204
Epoch 2/9
	 Logging train Loss: 6.39866e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.49479e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 5.76014e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.38653e-05 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 4.62052e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.8961e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 37.80149507522583
Epoch 3/9
	 Logging train Loss: 3.18255e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.5397e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.49192e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 7.2334e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.51358e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.23827e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 37.20502996444702
Epoch 4/9
	 Logging train Loss: 2.81971e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.0896e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.16496e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.0815e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.46172e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.59213e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 37.732805252075195
Epoch 5/9
	 Logging train Loss: 3.07302e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.8789e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.00094e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.9041e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.77781e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.16122e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 38.14070272445679
Epoch 6/9
	 Logging train Loss: 2.77496e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.9273e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.91809e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.8724e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.64102e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.76959e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 38.05431866645813
Epoch 7/9
	 Logging train Loss: 2.86578e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.1386e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.00202e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.1494e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.47258e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.48804e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 37.95365834236145
Epoch 8/9
	 Logging train Loss: 1.88084e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.2512e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone █▃▂▁▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone █▆▃▂▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone █▆▃▂▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone █▃▂▁▁▂▁▁▁▂
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone █▃▂▁▁▁▁▁▁▁
wandb:                                   Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone 3e-05
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 4e-05
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 5e-05
wandb:                                   Train loss 2e-05
wandb: 
wandb: 🚀 View run peach-planet-443 at: https://wandb.ai/nreints/ThesisFinal/runs/n2an34xz
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230620_152931-n2an34xz/logs
	 Logging test loss: 2.35616e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 5.201e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.58786e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.43351e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 38.23095393180847
Epoch 9/9
	 Logging train Loss: 1.7333e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.8897e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.07409e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.9112e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.5791e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.69657e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 37.866360664367676
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gNone/'dual_quat_1'_'inertia_body'.pth
It took  516.2066278457642  seconds.

JOB STATISTICS
==============
Job ID: 2944777
Array Job ID: 2944706_8
Cluster: snellius
User/Group: nreints/nreints
State: RUNNING
Nodes: 1
Cores per node: 18
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 1-01:54:36 core-walltime
Job Wall-clock time: 01:26:22
Memory Utilized: 0.00 MB (estimated maximum)
Memory Efficiency: 0.00% of 0.00 MB (0.00 MB/node)
WARNING: Efficiency statistics may be misleading for RUNNING jobs.
