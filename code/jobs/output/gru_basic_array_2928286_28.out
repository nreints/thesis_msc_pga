wandb: Currently logged in as: nreints. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230616_155420-ixld9nvw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glad-galaxy-6
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal/runs/ixld9nvw
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone â–ˆâ–„â–‚â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone â–ˆâ–†â–ƒâ–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone â–ˆâ–„â–‚â–â–â–â–â–â–â–
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone â–ˆâ–„â–‚â–â–â–â–â–â–â–
wandb:                                   Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone 1e-05
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 1e-05
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 1e-05
wandb:                                   Train loss 1e-05
wandb: 
wandb: ðŸš€ View run glad-galaxy-6 at: https://wandb.ai/nreints/ThesisFinal/runs/ixld9nvw
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230616_155420-ixld9nvw/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230616_160134-7fr66yc1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run polar-wave-9
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal/runs/7fr66yc1
Training on dataset: data_t(5,20)_r(5,20)_combi_pNone_gNone
Testing on 4 datasets: ['data_t(5,20)_r(5,20)_semi_pNone_gNone', 'data_t(5,20)_r(5,20)_full_pNone_gNone', 'data_t(5,20)_r(5,20)_tennis_pNone_gNone', 'data_t(5,20)_r(5,20)_combi_pNone_gNone']
Focussing on identity: False
Using extra input: None
Using fr-fr as reference point.
----- ITERATION 1/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  800
Number of test simulations:  200
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 21.72102117538452 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 5.572366714477539 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 5.542518138885498 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 5.57252836227417 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 5.5315351486206055 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: log_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0018501005 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0002724247 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 6.82001e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0003112413 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0002042212 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 38.3467812538147
Epoch 1/9
	 Logging train Loss: 0.0001346128 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0001294619 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.62091e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0001453608 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0001020056 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 37.58067178726196
Epoch 2/9
	 Logging train Loss: 6.39785e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.0593e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.23494e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 5.63534e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.14568e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 37.852755308151245
Epoch 3/9
	 Logging train Loss: 2.30876e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.76098e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 5.5625e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.98576e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.37832e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 37.87760400772095
Epoch 4/9
	 Logging train Loss: 8.7955e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.09836e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.5033e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.24532e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 8.2403e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 37.58713150024414
Epoch 5/9
	 Logging train Loss: 6.2602e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.21366e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.084e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.35439e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 8.5898e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 38.06481456756592
Epoch 6/9
	 Logging train Loss: 5.5247e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.378e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.6347e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 9.2673e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 6.1899e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 37.58557105064392
Epoch 7/9
	 Logging train Loss: 5.1139e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.18965e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.5036e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.37478e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 8.2182e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 37.707199811935425
Epoch 8/9
	 Logging train Loss: 5.02e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.00965e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.2032e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.13054e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 7.0144e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 37.773200035095215
Epoch 9/9
	 Logging train Loss: 5.3968e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.03848e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.0351e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.16295e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 7.1502e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 37.87627363204956
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gNone/'log_quat_1'_'None'.pth
It took  434.6469089984894  seconds.
----- ITERATION 2/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  800
Number of test simulations:  200
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 20.961705446243286 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 5.173711061477661 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 5.17943000793457 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 5.184611797332764 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 5.20467209815979 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: log_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0015453262 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0002362363 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 7.62416e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0002332858 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0001616648 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 38.2629656791687
Epoch 1/9
	 Logging train Loss: 0.0001257339 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0001041105 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 5.1149e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0001037775 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 7.98451e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 37.504560232162476
Epoch 2/9
	 Logging train Loss: 5.63226e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.69087e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.57437e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.72426e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.6577e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 41.012364864349365
Epoch 3/9
	 Logging train Loss: 2.19984e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone â–ˆâ–„â–‚â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone â–ˆâ–†â–ƒâ–‚â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone â–ˆâ–„â–‚â–â–â–â–â–â–â–
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone â–ˆâ–„â–‚â–â–â–â–â–â–â–
wandb:                                   Train loss â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 1e-05
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 1e-05
wandb:                                   Train loss 1e-05
wandb: 
wandb: ðŸš€ View run polar-wave-9 at: https://wandb.ai/nreints/ThesisFinal/runs/7fr66yc1
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230616_160134-7fr66yc1/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230616_160858-kxl0yz64
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run generous-oath-15
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal/runs/kxl0yz64
	 Logging test loss: 1.72001e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 8.4938e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.72699e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.27302e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 45.74919414520264
Epoch 4/9
	 Logging train Loss: 9.5707e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.17115e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.1468e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.17866e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 7.501e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 37.969151973724365
Epoch 5/9
	 Logging train Loss: 6.6787e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.23361e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.1491e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.2865e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 7.4967e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 38.08622455596924
Epoch 6/9
	 Logging train Loss: 6.2421e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.25902e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.8127e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.27347e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 7.345e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 37.75299835205078
Epoch 7/9
	 Logging train Loss: 6.5796e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.08027e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.5241e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.08597e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 6.323e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 37.79610085487366
Epoch 8/9
	 Logging train Loss: 5.9506e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.15281e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.3449e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.18458e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 6.6102e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 38.13115310668945
Epoch 9/9
	 Logging train Loss: 6.7312e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.3328e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.044e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 7.33e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.2861e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 37.81567454338074
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gNone/'log_quat_1'_'None'.pth
It took  444.03364992141724  seconds.
----- ITERATION 3/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  800
Number of test simulations:  200
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 19.849989652633667 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 5.067890644073486 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 5.074820041656494 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 5.131545543670654 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 5.054228067398071 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: log_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0014392642 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0002268441 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 6.12619e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0002416432 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.000150568 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 37.83992266654968
Epoch 1/9
	 Logging train Loss: 0.0001060401 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 9.63124e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.76629e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 9.92618e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 6.75572e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 37.955291509628296
Epoch 2/9
	 Logging train Loss: 4.38862e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.645e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.48816e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.64511e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.52771e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 37.58460807800293
Epoch 3/9
	 Logging train Loss: 1.57718e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.11387e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.4894e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.20233e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.32455e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 38.154937982559204
Epoch 4/9
	 Logging train Loss: 8.6065e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.30493e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.4005e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.3475e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 7.9863e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 37.95440220832825
Epoch 5/9
	 Logging train Loss: 7.3016e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.92403e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.1957e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.06622e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.12781e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 37.741207122802734
Epoch 6/9
	 Logging train Loss: 6.9504e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 9.7355e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.6663e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 9.8029e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 5.9663e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 37.98115873336792
Epoch 7/9
	 Logging train Loss: 6.6393e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.6063e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.4113e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 8.8393e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 5.2824e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 37.778969049453735
Epoch 8/9
	 Logging train Loss: 6.7696e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.30592e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.8146e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 7.24388e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.55746e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 37.819185972213745
Epoch 9/9
	 Logging train Loss: 6.156e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone â–ˆâ–„â–‚â–â–â–â–â–â–‚â–
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone â–ˆâ–…â–ƒâ–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone â–ˆâ–„â–‚â–â–â–â–â–â–ƒâ–
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone â–ˆâ–„â–‚â–â–â–â–â–â–ƒâ–
wandb:                                   Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone 1e-05
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 1e-05
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 1e-05
wandb:                                   Train loss 1e-05
wandb: 
wandb: ðŸš€ View run generous-oath-15 at: https://wandb.ai/nreints/ThesisFinal/runs/kxl0yz64
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230616_160858-kxl0yz64/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230616_161611-o46lfu68
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run atomic-resonance-21
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal/runs/o46lfu68
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone â–ˆâ–„â–‚â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone â–ˆâ–…â–ƒâ–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone â–ˆâ–„â–‚â–â–â–‚â–â–‚â–â–
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone â–ˆâ–„â–‚â–â–â–‚â–â–‚â–â–
wandb:                                   Train loss â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone 1e-05
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 1e-05
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 1e-05
wandb:                                   Train loss 1e-05
wandb: 
wandb: ðŸš€ View run atomic-resonance-21 at: https://wandb.ai/nreints/ThesisFinal/runs/o46lfu68
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230616_161611-o46lfu68/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230616_162334-iai4ogq4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run different-firebrand-26
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal/runs/iai4ogq4
	 Logging test loss: 1.36095e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.1974e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.47631e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 8.0125e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 37.97244834899902
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gNone/'log_quat_1'_'None'.pth
It took  432.4970529079437  seconds.
----- ITERATION 4/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  800
Number of test simulations:  200
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 20.086760759353638 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 5.117056846618652 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 5.131396532058716 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 5.130390882492065 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 5.075234413146973 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: log_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0014641557 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0002519203 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 6.6868e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0002515648 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0001614219 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 37.85228228569031
Epoch 1/9
	 Logging train Loss: 0.0001165771 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0001001994 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.01716e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0001003756 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 7.00808e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 37.733713150024414
Epoch 2/9
	 Logging train Loss: 4.62311e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.59696e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.52904e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.60438e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.54481e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 37.9841673374176
Epoch 3/9
	 Logging train Loss: 1.60115e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.43088e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.275e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.42526e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 9.3833e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 38.180880546569824
Epoch 4/9
	 Logging train Loss: 7.4699e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.18523e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.2559e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.16216e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 7.2687e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 43.70222496986389
Epoch 5/9
	 Logging train Loss: 6.0719e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.65642e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.3477e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.66873e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.51299e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 42.98005795478821
Epoch 6/9
	 Logging train Loss: 5.7103e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.2787e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.4565e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 7.9082e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.9135e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 37.70710253715515
Epoch 7/9
	 Logging train Loss: 5.6148e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.64111e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.7442e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.63096e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.49035e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 37.782784938812256
Epoch 8/9
	 Logging train Loss: 5.7869e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 9.5852e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.0598e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 9.1984e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 5.459e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 37.86172389984131
Epoch 9/9
	 Logging train Loss: 5.6148e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.30081e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.0029e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.28033e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 7.2665e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 37.647929191589355
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gNone/'log_quat_1'_'None'.pth
It took  443.120085477829  seconds.
----- ITERATION 5/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  800
Number of test simulations:  200
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 20.315434217453003 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 5.085770130157471 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 5.12910795211792 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 5.126750469207764 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 5.104847192764282 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: log_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0016415231 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0002887594 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 7.01674e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.000276828 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.00018809 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 37.96933603286743
Epoch 1/9
	 Logging train Loss: 0.0001173349 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0001236456 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.55264e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0001213253 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 8.62117e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 37.461113691329956
Epoch 2/9
	 Logging train Loss: 4.29153e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.95293e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 8.2648e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.95595e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.69373e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 37.92123031616211
Epoch 3/9
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone â–ˆâ–„â–‚â–â–â–â–â–â–â–ƒ
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone â–ˆâ–…â–‚â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone â–ˆâ–„â–‚â–â–â–â–â–â–â–ƒ
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone â–ˆâ–„â–‚â–â–â–â–â–â–â–ƒ
wandb:                                   Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone 5e-05
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 9e-05
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 9e-05
wandb:                                   Train loss 0.0
wandb: 
wandb: ðŸš€ View run different-firebrand-26 at: https://wandb.ai/nreints/ThesisFinal/runs/iai4ogq4
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230616_162334-iai4ogq4/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230616_163047-3vlnv6o4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run trim-eon-31
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal/runs/3vlnv6o4
	 Logging train Loss: 1.33258e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.48266e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.3291e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.45294e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 9.5598e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 37.96603536605835
Epoch 4/9
	 Logging train Loss: 6.9766e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.11679e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.6489e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.08931e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 6.8857e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 37.797703981399536
Epoch 5/9
	 Logging train Loss: 5.5816e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.57382e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.5116e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.56583e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 9.2072e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 38.55527210235596
Epoch 6/9
	 Logging train Loss: 5.3771e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.2029e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.0942e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 7.7866e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.8274e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 37.920530557632446
Epoch 7/9
	 Logging train Loss: 5.0665e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.25616e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.0474e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.22834e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 7.0547e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 37.82535719871521
Epoch 8/9
	 Logging train Loss: 4.8679e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.3498e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 7.184e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 6.7702e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.135e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 37.772329330444336
Epoch 9/9
	 Logging train Loss: 4.8579e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.54612e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.9079e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 9.34949e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.85104e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 37.90756678581238
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gNone/'log_quat_1'_'None'.pth
It took  433.7805247306824  seconds.
----- ITERATION 6/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  800
Number of test simulations:  200
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 20.58699655532837 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 5.052409887313843 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 5.080081224441528 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 5.075836181640625 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 5.060361385345459 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: log_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0024417092 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0002644688 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 7.12071e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0002719166 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0001708917 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 38.07952642440796
Epoch 1/9
	 Logging train Loss: 0.0001381407 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0001406206 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.92963e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0001396029 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 9.51877e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 37.56268072128296
Epoch 2/9
	 Logging train Loss: 6.97956e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.6452e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.90063e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 6.42936e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.7248e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 37.76080679893494
Epoch 3/9
	 Logging train Loss: 3.33397e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.19316e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.38629e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.08443e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.28617e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 37.997225522994995
Epoch 4/9
	 Logging train Loss: 1.40405e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.36215e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.4198e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.34107e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 8.4408e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 42.670024394989014
Epoch 5/9
	 Logging train Loss: 7.1715e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.26902e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.1496e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.3433e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 7.4178e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 43.51752972602844
Epoch 6/9
	 Logging train Loss: 5.8643e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.32986e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.709e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.41629e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 7.4509e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 37.690884828567505
Epoch 7/9
	 Logging train Loss: 5.2976e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.8832e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.3151e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 8.8509e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 5.0013e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 37.853771686553955
Epoch 8/9
	 Logging train Loss: 5.2127e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.2524e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.1019e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 8.2202e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.569e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 37.61079120635986
Epoch 9/9
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone â–ˆâ–…â–ƒâ–‚â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone â–ˆâ–†â–„â–‚â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone â–ˆâ–…â–ƒâ–‚â–â–â–â–â–â–
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone â–ˆâ–„â–‚â–‚â–â–â–â–â–â–
wandb:                                   Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone 1e-05
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 1e-05
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 2e-05
wandb:                                   Train loss 0.0
wandb: 
wandb: ðŸš€ View run trim-eon-31 at: https://wandb.ai/nreints/ThesisFinal/runs/3vlnv6o4
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230616_163047-3vlnv6o4/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230616_163810-4n92en5w
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run mild-feather-38
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal/runs/4n92en5w
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone â–ˆâ–ƒâ–â–â–â–â–‚â–â–‚â–
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone â–ˆâ–ƒâ–â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone â–ˆâ–ƒâ–â–â–â–â–‚â–â–‚â–‚
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone â–ˆâ–ƒâ–â–â–â–â–‚â–â–‚â–‚
wandb:                                   Train loss â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone 1e-05
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 3e-05
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 2e-05
wandb:                                   Train loss 1e-05
wandb: 
wandb: ðŸš€ View run mild-feather-38 at: https://wandb.ai/nreints/ThesisFinal/runs/4n92en5w
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230616_163810-4n92en5w/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230616_164523-twrchxt2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run decent-dawn-44
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal/runs/twrchxt2
	 Logging train Loss: 4.8734e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.3671e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.185e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.52619e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 7.432e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 37.80848145484924
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gNone/'log_quat_1'_'None'.pth
It took  442.9144563674927  seconds.
----- ITERATION 7/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  800
Number of test simulations:  200
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 20.431492567062378 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 5.112810134887695 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 5.108048915863037 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 5.08633828163147 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 5.202603340148926 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: log_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0009887924 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0002396793 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 5.29668e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0002294854 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0001438184 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 37.68371629714966
Epoch 1/9
	 Logging train Loss: 9.45095e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.18697e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.92988e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 6.89423e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.35016e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 37.77271819114685
Epoch 2/9
	 Logging train Loss: 2.45789e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.6062e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.3916e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.45774e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 9.4183e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 38.1128134727478
Epoch 3/9
	 Logging train Loss: 7.3184e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.1337e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.7104e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.04299e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 6.4678e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 37.660409450531006
Epoch 4/9
	 Logging train Loss: 5.6153e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.3091e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.2687e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 7.6698e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.8291e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 37.75870680809021
Epoch 5/9
	 Logging train Loss: 5.3902e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.90064e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.3837e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.84874e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.00341e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 38.042832136154175
Epoch 6/9
	 Logging train Loss: 5.5e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.91747e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.6868e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.7962e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.03222e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 37.75943160057068
Epoch 7/9
	 Logging train Loss: 5.7043e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.01218e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 7.212e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 9.3695e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 5.3006e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 37.8852858543396
Epoch 8/9
	 Logging train Loss: 4.972e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.38295e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.8629e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 5.36963e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.70122e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 37.812336921691895
Epoch 9/9
	 Logging train Loss: 5.7539e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.61731e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.0924e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.44466e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.31817e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 37.89092969894409
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gNone/'log_quat_1'_'None'.pth
It took  432.94499802589417  seconds.
----- ITERATION 8/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  800
Number of test simulations:  200
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 20.441770315170288 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 5.100650310516357 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 5.081531047821045 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 5.0979766845703125 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 5.0948662757873535 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: log_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0006827738 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0001907332 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.06778e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0002340249 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0001349264 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 38.03200936317444
Epoch 1/9
	 Logging train Loss: 5.34288e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.33098e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.04845e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.73626e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.48997e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 37.617809772491455
Epoch 2/9
	 Logging train Loss: 1.42358e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 9.7083e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.8471e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.08952e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone â–ˆâ–‚â–â–â–‚â–â–â–â–‚â–
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone â–ˆâ–ƒâ–â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone â–ˆâ–‚â–â–â–‚â–â–â–â–‚â–
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone â–ˆâ–‚â–â–â–‚â–â–â–â–‚â–
wandb:                                   Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone 1e-05
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 2e-05
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 2e-05
wandb:                                   Train loss 1e-05
wandb: 
wandb: ðŸš€ View run decent-dawn-44 at: https://wandb.ai/nreints/ThesisFinal/runs/twrchxt2
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230616_164523-twrchxt2/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230616_165247-pkfhr92c
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run revived-galaxy-48
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal/runs/pkfhr92c
	 Logging test loss: 7.2579e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 37.809669971466064
Epoch 3/9
	 Logging train Loss: 9.2221e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.11184e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.7518e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.31608e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 7.6306e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 37.831809759140015
Epoch 4/9
	 Logging train Loss: 7.6585e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.17196e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.8455e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.70882e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.43148e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 37.73202562332153
Epoch 5/9
	 Logging train Loss: 7.132e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.071e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.1607e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 9.4627e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 5.6305e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 38.164583921432495
Epoch 6/9
	 Logging train Loss: 7.0184e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 9.9188e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.0488e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.19689e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 6.6523e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 46.844194650650024
Epoch 7/9
	 Logging train Loss: 7.0456e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.9892e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 7.973e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 8.1809e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.7414e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 39.708089113235474
Epoch 8/9
	 Logging train Loss: 6.3645e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.0027e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.4478e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.75848e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.89695e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 37.73571848869324
Epoch 9/9
	 Logging train Loss: 6.3594e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.72055e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 9.526e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.18394e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.08113e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 37.752829790115356
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gNone/'log_quat_1'_'None'.pth
It took  443.97270607948303  seconds.
----- ITERATION 9/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  800
Number of test simulations:  200
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 20.438027143478394 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 5.108531951904297 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 5.117579221725464 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 5.120358228683472 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 5.101129531860352 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: log_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0008034367 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0002258444 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 6.02569e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0002008786 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0001463337 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 37.94908905029297
Epoch 1/9
	 Logging train Loss: 7.55054e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.20068e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.5077e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.62408e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.79429e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 37.774718284606934
Epoch 2/9
	 Logging train Loss: 1.99838e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.15908e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 6.5731e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.93757e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.02245e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 37.92520785331726
Epoch 3/9
	 Logging train Loss: 9.2142e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.07963e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.3216e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 9.0182e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 6.8862e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 37.80636405944824
Epoch 4/9
	 Logging train Loss: 7.7799e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.25862e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.9465e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.09914e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 7.6534e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 37.90375566482544
Epoch 5/9
	 Logging train Loss: 6.8916e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.5373e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.7223e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.38621e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 9.1314e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 37.73392939567566
Epoch 6/9
	 Logging train Loss: 6.6462e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.50327e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.3015e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.28007e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.51217e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 37.79283595085144
Epoch 7/9
	 Logging train Loss: 6.6393e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.72584e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.3489e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.53315e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 9.7787e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 37.87653112411499
Epoch 8/9
	 Logging train Loss: 6.1365e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.66328e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.1518e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.55002e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone â–ˆâ–ƒâ–‚â–â–â–â–‚â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone â–ˆâ–„â–‚â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone â–ˆâ–‚â–‚â–â–â–â–‚â–â–â–
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone â–ˆâ–‚â–‚â–â–â–â–‚â–â–â–
wandb:                                   Train loss â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone 1e-05
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 2e-05
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 2e-05
wandb:                                   Train loss 1e-05
wandb: 
wandb: ðŸš€ View run revived-galaxy-48 at: https://wandb.ai/nreints/ThesisFinal/runs/pkfhr92c
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230616_165247-pkfhr92c/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230616_170002-eijqjuev
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fanciful-vortex-54
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal/runs/eijqjuev
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone â–ˆâ–„â–‚â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone â–ˆâ–ƒâ–â–â–â–â–â–‚â–â–
wandb:                                   Train loss â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone 1e-05
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 1e-05
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 1e-05
wandb:                                   Train loss 1e-05
wandb: 
wandb: ðŸš€ View run fanciful-vortex-54 at: https://wandb.ai/nreints/ThesisFinal/runs/eijqjuev
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230616_170002-eijqjuev/logs
	 Logging test loss: 9.6774e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 37.90008330345154
Epoch 9/9
	 Logging train Loss: 6.5581e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.35627e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.2007e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.15919e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.30946e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 37.78748416900635
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gNone/'log_quat_1'_'None'.pth
It took  434.2213408946991  seconds.
----- ITERATION 10/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  800
Number of test simulations:  200
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 20.34225034713745 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 5.104491949081421 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 5.12979793548584 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 5.176674842834473 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 5.132498741149902 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: log_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0012018249 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0002450724 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 6.37377e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0002559088 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0001796369 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 37.76658248901367
Epoch 1/9
	 Logging train Loss: 9.91712e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.1705e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.06953e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 8.4265e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 6.33789e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 38.187663555145264
Epoch 2/9
	 Logging train Loss: 3.48923e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.74335e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.24452e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.67275e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.17977e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 37.70702910423279
Epoch 3/9
	 Logging train Loss: 1.25126e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.64331e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.2803e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.67846e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.16917e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 37.93026518821716
Epoch 4/9
	 Logging train Loss: 7.0577e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.2542e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.8817e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.25025e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 8.8203e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 37.73220229148865
Epoch 5/9
	 Logging train Loss: 6.2807e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.30376e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.8926e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.49015e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.53053e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 37.89093637466431
Epoch 6/9
	 Logging train Loss: 5.8315e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.34046e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.3864e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.37478e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 9.119e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 38.11782360076904
Epoch 7/9
	 Logging train Loss: 5.8021e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.58524e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.5827e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.84151e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.70062e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 44.30458402633667
Epoch 8/9
	 Logging train Loss: 6.1014e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.00086e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 9.452e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 9.8208e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 6.8546e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 41.65920853614807
Epoch 9/9
	 Logging train Loss: 5.4445e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.13334e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 8.779e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.12898e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 7.6393e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 37.74728274345398
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gNone/'log_quat_1'_'None'.pth
It took  443.94427490234375  seconds.

JOB STATISTICS
==============
Job ID: 2928290
Array Job ID: 2928286_28
Cluster: snellius
User/Group: nreints/nreints
State: COMPLETED (exit code 0)
Nodes: 1
Cores per node: 18
CPU Utilized: 15:32:07
CPU Efficiency: 70.52% of 22:01:48 core-walltime
Job Wall-clock time: 01:13:26
Memory Utilized: 7.29 GB
Memory Efficiency: 0.00% of 0.00 MB
