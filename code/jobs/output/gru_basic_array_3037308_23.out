wandb: Currently logged in as: nreints. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_134800-bl9b5c6x
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run brisk-star-655
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/bl9b5c6x
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone â–†â–…â–ˆâ–„â–‚â–‚â–‚â–‚â–â–
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone â–ˆâ–ƒâ–†â–‚â–â–â–‚â–‚â–â–
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone â–ˆâ–ƒâ–†â–‚â–‚â–‚â–‚â–‚â–â–
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone â–…â–…â–ˆâ–„â–‚â–‚â–‚â–‚â–â–
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone â–…â–„â–ˆâ–„â–‚â–‚â–‚â–‚â–â–
wandb:                                  Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone 0.0
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: ðŸš€ View run brisk-star-655 at: https://wandb.ai/nreints/ThesisFinal2/runs/bl9b5c6x
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_134800-bl9b5c6x/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_140127-q5zly1i6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sparkling-thunder-672
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/q5zly1i6
Training on dataset: data_t(0,0)_r(5,20)_combi_pNone_gNone
Testing on 5 datasets: ['data_t(0,0)_r(5,20)_combi_pNone_gNone', 'data_t(0,0)_r(5,20)_none_pNone_gNone', 'data_t(0,0)_r(5,20)_semi_pNone_gNone', 'data_t(0,0)_r(5,20)_full_pNone_gNone', 'data_t(0,0)_r(5,20)_tennis_pNone_gNone']
Focussing on identity: True
Using extra input: False
Using fr-fr as reference point.
----- ITERATION 1/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 53.61062431335449 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 13.376607179641724 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_none_pNone_gNone took 12.9542715549469 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_semi_pNone_gNone took 13.431101322174072 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_full_pNone_gNone took 13.197166681289673 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_tennis_pNone_gNone took 13.095820903778076 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0003147859 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.9292e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.716e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 8.9361e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 6.043e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 9.377e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 67.78129291534424
Epoch 1/9
	 Logging train Loss: 5.0543e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.069e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.665e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 8.6167e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.139e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 8.9176e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 67.32617950439453
Epoch 2/9
	 Logging train Loss: 4.2158e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.8253e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.14e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.52657e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.641e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.60858e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 67.48388123512268
Epoch 3/9
	 Logging train Loss: 3.8293e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.9217e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.68e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 6.8633e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.344e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 7.1807e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 67.79945087432861
Epoch 4/9
	 Logging train Loss: 3.3037e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.5589e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 9.43e-08 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 4.4201e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 6.79e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.6227e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 68.78261280059814
Epoch 5/9
	 Logging train Loss: 2.8395e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.0691e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 9.45e-08 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.5516e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 7.48e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.7862e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 67.91863369941711
Epoch 6/9
	 Logging train Loss: 2.4973e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.9795e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.044e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.3643e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 8.87e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.6095e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 67.53832650184631
Epoch 7/9
	 Logging train Loss: 1.9586e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.8519e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.611e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.0894e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.523e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.3775e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 66.89511704444885
Epoch 8/9
	 Logging train Loss: 1.6967e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.2293e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.54e-08 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.0718e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 6.74e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.2292e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 65.36072850227356
Epoch 9/9
	 Logging train Loss: 1.4394e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.0493e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.79e-08 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.7761e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.88e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.9253e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 65.10429191589355
Saved model in  trained_models/gru/data_t(0,0)_r(5,20)_combi_pNone_gNone/'rot_mat_1'_'False'.pth
It took  807.4993567466736  seconds.
----- ITERATION 2/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 50.94708228111267 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 13.421310901641846 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_none_pNone_gNone took 12.85108757019043 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_semi_pNone_gNone took 12.797383069992065 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_full_pNone_gNone took 12.662973642349243 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_tennis_pNone_gNone took 12.792201042175293 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0002352518 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.0419e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.472e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 8.6158e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.049e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 8.8062e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 68.3176486492157
Epoch 1/9
	 Logging train Loss: 4.9158e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.0687e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.96e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 7.4783e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone â–‡â–„â–ˆâ–ƒâ–ƒâ–ƒâ–â–‚â–‚â–
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone â–‡â–ƒâ–ˆâ–â–‚â–‚â–â–â–‚â–
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone â–‡â–ƒâ–ˆâ–‚â–‚â–‚â–â–â–‚â–
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone â–…â–„â–ˆâ–ƒâ–ƒâ–ƒâ–â–‚â–‚â–
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone â–…â–„â–ˆâ–ƒâ–ƒâ–ƒâ–â–‚â–‚â–
wandb:                                  Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone 0.0
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: ðŸš€ View run sparkling-thunder-672 at: https://wandb.ai/nreints/ThesisFinal2/runs/q5zly1i6
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_140127-q5zly1i6/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_141443-ochj0o66
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run distinctive-pyramid-687
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/ochj0o66
	 Logging test loss: 1.6e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 7.6903e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 68.01326847076416
Epoch 2/9
	 Logging train Loss: 4.357e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.2667e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.858e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.3839e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.7e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.51018e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 67.77448987960815
Epoch 3/9
	 Logging train Loss: 3.8562e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.469e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.12e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 4.6428e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 8.86e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.8119e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 66.89745259284973
Epoch 4/9
	 Logging train Loss: 3.0335e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.3641e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.301e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 4.5527e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.169e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.7554e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 66.18287825584412
Epoch 5/9
	 Logging train Loss: 2.5416e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.8286e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.423e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 5.5314e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.348e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 5.9895e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 65.88969445228577
Epoch 6/9
	 Logging train Loss: 1.9216e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.3316e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.67e-08 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.5249e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 8.05e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.717e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 66.14626574516296
Epoch 7/9
	 Logging train Loss: 1.7107e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.6595e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.67e-08 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.2189e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 8.23e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.472e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 66.14597129821777
Epoch 8/9
	 Logging train Loss: 1.6042e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.8523e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.109e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.5409e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.052e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.958e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 66.80062961578369
Epoch 9/9
	 Logging train Loss: 1.3584e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 9.584e-07 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.81e-08 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.7925e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 7.38e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.8936e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 66.6211531162262
Saved model in  trained_models/gru/data_t(0,0)_r(5,20)_combi_pNone_gNone/'rot_mat_1'_'False'.pth
It took  796.2280976772308  seconds.
----- ITERATION 3/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 51.99412536621094 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 12.768056869506836 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_none_pNone_gNone took 12.694422483444214 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_semi_pNone_gNone took 12.71848750114441 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_full_pNone_gNone took 12.795067548751831 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_tennis_pNone_gNone took 12.96093225479126 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0002914809 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.0182e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.179e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 9.2924e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.447e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 8.8472e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 67.28761696815491
Epoch 1/9
	 Logging train Loss: 5.1235e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.2857e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.516e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.11273e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.074e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.13118e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 67.93880867958069
Epoch 2/9
	 Logging train Loss: 4.3527e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.3651e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.519e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 7.8835e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.188e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 7.8802e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 67.04262900352478
Epoch 3/9
	 Logging train Loss: 3.701e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.4159e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.585e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 9.612e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.337e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 9.9336e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 67.4747965335846
Epoch 4/9
	 Logging train Loss: 3.1935e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.246e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.752e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.09643e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.696e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.19218e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 67.63622403144836
Epoch 5/9
	 Logging train Loss: 2.6679e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.2395e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.324e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.8405e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone â–ˆâ–‡â–…â–†â–‡â–‚â–â–‚â–â–ƒ
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone â–„â–‚â–‚â–ƒâ–„â–ƒâ–â–„â–â–ˆ
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone â–„â–ƒâ–‚â–„â–„â–ƒâ–â–„â–â–ˆ
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone â–‡â–ˆâ–†â–‡â–ˆâ–ƒâ–â–‚â–â–ƒ
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone â–†â–ˆâ–…â–‡â–ˆâ–‚â–â–‚â–â–ƒ
wandb:                                  Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone 0.0
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: ðŸš€ View run distinctive-pyramid-687 at: https://wandb.ai/nreints/ThesisFinal2/runs/ochj0o66
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_141443-ochj0o66/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_142804-3pg38237
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run happy-deluge-696
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/3pg38237
	 Logging test loss: 3.128e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.836e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 67.4629282951355
Epoch 6/9
	 Logging train Loss: 2.238e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.3282e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.11e-08 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.4057e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 6.14e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.3812e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 67.63669204711914
Epoch 7/9
	 Logging train Loss: 1.6624e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.2266e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.751e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.7665e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.669e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.95e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 67.05206871032715
Epoch 8/9
	 Logging train Loss: 1.462e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.0268e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.3e-08 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.8469e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.75e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.8483e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 67.06400084495544
Epoch 9/9
	 Logging train Loss: 1.4114e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.9069e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.801e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 4.6015e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 8.715e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.8518e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 67.31974244117737
Saved model in  trained_models/gru/data_t(0,0)_r(5,20)_combi_pNone_gNone/'rot_mat_1'_'False'.pth
It took  801.036229133606  seconds.
----- ITERATION 4/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 50.68134951591492 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 12.6244637966156 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_none_pNone_gNone took 12.848782300949097 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_semi_pNone_gNone took 13.149492979049683 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_full_pNone_gNone took 13.085306167602539 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_tennis_pNone_gNone took 13.026687383651733 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0002542239 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.49233e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.0964e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.50492e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 9.966e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.59476e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 68.33386898040771
Epoch 1/9
	 Logging train Loss: 6.2423e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.5668e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.437e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 9.1483e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.938e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 8.8826e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 69.81674480438232
Epoch 2/9
	 Logging train Loss: 4.4462e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.6295e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.003e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 5.4042e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 6.54e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 5.0711e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 66.64792084693909
Epoch 3/9
	 Logging train Loss: 3.9492e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.5343e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.047e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 5.2431e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 7.6e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 5.0819e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 67.26936364173889
Epoch 4/9
	 Logging train Loss: 3.1438e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.7218e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.73e-08 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.4965e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 5.92e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.4362e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 67.6863317489624
Epoch 5/9
	 Logging train Loss: 2.4897e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.5158e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.63e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 7.1032e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.375e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 7.4413e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 67.7691297531128
Epoch 6/9
	 Logging train Loss: 1.9442e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.4655e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.431e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.5627e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.315e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.5374e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 67.92522644996643
Epoch 7/9
	 Logging train Loss: 1.6726e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.4127e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.659e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.7547e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.56e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.7852e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 68.1140251159668
Epoch 8/9
	 Logging train Loss: 1.525e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.6811e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.069e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.5037e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 9.56e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.6143e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 68.01369619369507
Epoch 9/9
	 Logging train Loss: 1.4128e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.0719e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 9.6e-08 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.178e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone â–ˆâ–ƒâ–‚â–‚â–â–‚â–â–â–â–
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone â–ˆâ–‚â–â–â–â–‚â–„â–‚â–â–
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone â–ˆâ–‚â–â–â–â–‚â–„â–‚â–â–
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone â–ˆâ–ƒâ–‚â–‚â–â–ƒâ–â–â–â–
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone â–ˆâ–ƒâ–‚â–‚â–â–ƒâ–â–â–â–
wandb:                                  Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone 0.0
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: ðŸš€ View run happy-deluge-696 at: https://wandb.ai/nreints/ThesisFinal2/runs/3pg38237
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_142804-3pg38237/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_144134-k9ishpbc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ancient-terrain-710
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/k9ishpbc
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone â–ˆâ–‡â–…â–„â–„â–„â–†â–‚â–â–
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone â–ƒâ–„â–‚â–â–‚â–‚â–ˆâ–ƒâ–â–
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone â–ƒâ–„â–‚â–‚â–‚â–‚â–ˆâ–ƒâ–â–
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone â–ˆâ–ˆâ–†â–„â–„â–„â–†â–‚â–â–
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone â–ˆâ–ˆâ–†â–„â–„â–„â–†â–‚â–â–
wandb:                                  Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone 0.0
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: ðŸš€ View run ancient-terrain-710 at: https://wandb.ai/nreints/ThesisFinal2/runs/k9ishpbc
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_144134-k9ishpbc/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_145453-j740erw7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vibrant-totem-723
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/j740erw7
	 Logging test loss: 8.63e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.1867e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 69.06259942054749
Saved model in  trained_models/gru/data_t(0,0)_r(5,20)_combi_pNone_gNone/'rot_mat_1'_'False'.pth
It took  810.1027522087097  seconds.
----- ITERATION 5/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 51.65242290496826 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 12.883824348449707 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_none_pNone_gNone took 12.850491046905518 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_semi_pNone_gNone took 12.83718466758728 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_full_pNone_gNone took 12.930941581726074 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_tennis_pNone_gNone took 12.928736686706543 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0003337569 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.7591e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.066e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 9.115e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.384e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 8.8439e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 67.2455084323883
Epoch 1/9
	 Logging train Loss: 4.3884e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.4163e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.162e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 9.0417e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.65e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 8.8944e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 67.42791771888733
Epoch 2/9
	 Logging train Loss: 4.2265e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.31e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.553e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 7.0121e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.141e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 6.894e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 67.14210748672485
Epoch 3/9
	 Logging train Loss: 3.8921e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.4023e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.289e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 5.0781e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 9.39e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.9611e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 67.12032151222229
Epoch 4/9
	 Logging train Loss: 3.4439e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.5143e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.547e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 5.238e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.289e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 5.2655e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 65.84328579902649
Epoch 5/9
	 Logging train Loss: 2.7252e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.5716e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.176e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 5.1609e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.964e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 5.3837e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 66.2944118976593
Epoch 6/9
	 Logging train Loss: 2.2559e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.6683e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.659e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 6.7271e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 7.603e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 7.1561e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 66.59148597717285
Epoch 7/9
	 Logging train Loss: 1.8665e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.6575e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.767e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.2192e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.647e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.3421e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 67.82242178916931
Epoch 8/9
	 Logging train Loss: 1.6279e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 9.36e-07 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.85e-08 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.9074e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 5.98e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.9472e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 68.01072311401367
Epoch 9/9
	 Logging train Loss: 1.4585e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 9.781e-07 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.077e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.9544e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 9.99e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.0059e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 68.02489709854126
Saved model in  trained_models/gru/data_t(0,0)_r(5,20)_combi_pNone_gNone/'rot_mat_1'_'False'.pth
It took  799.0142238140106  seconds.
----- ITERATION 6/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 50.989028215408325 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 12.667415857315063 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_none_pNone_gNone took 12.884964227676392 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_semi_pNone_gNone took 12.855310201644897 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_full_pNone_gNone took 12.863793849945068 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_tennis_pNone_gNone took 12.914051055908203 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0001995076 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.8401e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.112e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 6.997e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.583e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 7.6302e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 67.31193900108337
Epoch 1/9
	 Logging train Loss: 4.2897e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.2926e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.126e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.12885e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone â–…â–ˆâ–ƒâ–…â–‚â–‚â–ƒâ–â–‚â–‚
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone â–‚â–ƒâ–â–‡â–‚â–‚â–ˆâ–‚â–â–‚
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone â–‚â–ƒâ–â–‡â–‚â–â–ˆâ–â–â–
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone â–…â–ˆâ–ƒâ–…â–‚â–‚â–ƒâ–â–‚â–‚
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone â–…â–ˆâ–ƒâ–…â–‚â–‚â–ƒâ–â–‚â–‚
wandb:                                  Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone 0.0
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: ðŸš€ View run vibrant-totem-723 at: https://wandb.ai/nreints/ThesisFinal2/runs/j740erw7
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_145453-j740erw7/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_150811-rrtbmpeh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run morning-darkness-734
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/rrtbmpeh
	 Logging test loss: 2.549e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.25703e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 67.93859577178955
Epoch 2/9
	 Logging train Loss: 3.6003e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.3841e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.352e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 5.0274e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.003e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 5.4852e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 68.08798551559448
Epoch 3/9
	 Logging train Loss: 3.3497e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.743e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.583e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 7.0696e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 5.251e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 7.8789e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 68.25751113891602
Epoch 4/9
	 Logging train Loss: 2.9126e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.4883e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.678e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.6801e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.44e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.0648e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 66.45551300048828
Epoch 5/9
	 Logging train Loss: 2.2853e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.2147e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.583e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.2776e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.396e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.6702e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 66.51779627799988
Epoch 6/9
	 Logging train Loss: 1.9244e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.9634e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.552e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 4.2265e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 6.404e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.7197e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 67.0814995765686
Epoch 7/9
	 Logging train Loss: 1.5458e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.37e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.541e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.9686e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.439e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.202e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 66.17595362663269
Epoch 8/9
	 Logging train Loss: 1.3501e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.0725e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.268e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.1263e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.134e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.5965e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 66.29376769065857
Epoch 9/9
	 Logging train Loss: 1.3047e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.0036e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.555e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.993e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.438e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.4162e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 66.56827926635742
Saved model in  trained_models/gru/data_t(0,0)_r(5,20)_combi_pNone_gNone/'rot_mat_1'_'False'.pth
It took  798.0385692119598  seconds.
----- ITERATION 7/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 50.79561257362366 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 12.841120481491089 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_none_pNone_gNone took 12.875767469406128 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_semi_pNone_gNone took 12.786717891693115 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_full_pNone_gNone took 12.736034393310547 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_tennis_pNone_gNone took 12.722128629684448 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0002285776 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.6234e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.12e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.06309e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 6.471e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.12683e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 68.41586136817932
Epoch 1/9
	 Logging train Loss: 5.9468e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.8132e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.317e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 8.2115e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.89e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 8.711e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 68.84844183921814
Epoch 2/9
	 Logging train Loss: 4.5991e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.425e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.123e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 6.02e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 7.79e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 6.3242e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 66.73611807823181
Epoch 3/9
	 Logging train Loss: 3.7912e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.0506e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.021e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 5.4504e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 7.56e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 5.7534e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 66.68460321426392
Epoch 4/9
	 Logging train Loss: 3.204e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.2377e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.49e-08 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 4.0401e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 5.5e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.2626e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 66.66100907325745
Epoch 5/9
	 Logging train Loss: 2.5985e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.171e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.378e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.9336e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone â–ˆâ–…â–ƒâ–ƒâ–‚â–‚â–‚â–â–â–
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone â–ˆâ–ƒâ–â–â–â–‚â–‚â–â–â–
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone â–ˆâ–ƒâ–‚â–‚â–â–‚â–‚â–â–â–
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone â–ˆâ–†â–„â–„â–ƒâ–ƒâ–ƒâ–â–â–
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone â–ˆâ–†â–„â–„â–ƒâ–ƒâ–ƒâ–â–â–
wandb:                                  Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone 0.0
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: ðŸš€ View run morning-darkness-734 at: https://wandb.ai/nreints/ThesisFinal2/runs/rrtbmpeh
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_150811-rrtbmpeh/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_152135-1vqityue
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dazzling-butterfly-738
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/1vqityue
	 Logging test loss: 1.24e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.236e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 67.14445662498474
Epoch 6/9
	 Logging train Loss: 2.0609e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.3094e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.414e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 4.2161e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.33e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.6513e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 67.64374160766602
Epoch 7/9
	 Logging train Loss: 1.6757e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.2409e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 9.11e-08 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.1946e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 8.4e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.3976e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 68.34083580970764
Epoch 8/9
	 Logging train Loss: 1.6328e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.2857e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.81e-08 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.3228e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 7.14e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.5772e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 68.19507455825806
Epoch 9/9
	 Logging train Loss: 1.3186e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 9.862e-07 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.89e-08 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.7806e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.26e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.9671e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 68.1818675994873
Saved model in  trained_models/gru/data_t(0,0)_r(5,20)_combi_pNone_gNone/'rot_mat_1'_'False'.pth
It took  804.0950558185577  seconds.
----- ITERATION 8/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 50.86639714241028 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 12.656736373901367 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_none_pNone_gNone took 12.68809700012207 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_semi_pNone_gNone took 12.663859605789185 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_full_pNone_gNone took 12.719781637191772 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_tennis_pNone_gNone took 12.817919254302979 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0001858428 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.2258e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.809e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.31029e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.195e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.42939e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 68.10230922698975
Epoch 1/9
	 Logging train Loss: 5.9255e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.7211e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.49e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 7.4098e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.028e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 7.5857e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 68.548668384552
Epoch 2/9
	 Logging train Loss: 4.4596e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.4925e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.458e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 6.9266e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.091e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 7.2618e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 67.74756598472595
Epoch 3/9
	 Logging train Loss: 3.5143e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.1975e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.207e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 8.3355e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.858e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 9.111e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 67.6281669139862
Epoch 4/9
	 Logging train Loss: 2.9103e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.4564e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.296e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 4.7929e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.068e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 5.3542e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 67.56586170196533
Epoch 5/9
	 Logging train Loss: 2.2795e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.1621e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.4e-08 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.2544e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 5.11e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.4476e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 68.11625671386719
Epoch 6/9
	 Logging train Loss: 1.7926e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.37e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.125e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.6084e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.013e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.918e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 67.81698369979858
Epoch 7/9
	 Logging train Loss: 1.5668e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.0313e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.197e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.7946e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.054e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.3778e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 67.91384029388428
Epoch 8/9
	 Logging train Loss: 1.3925e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.0064e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.16e-08 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.9001e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 6.35e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.1006e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 68.74982213973999
Epoch 9/9
	 Logging train Loss: 1.3633e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.108e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.204e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.9647e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone â–ˆâ–„â–ƒâ–„â–‚â–â–â–‚â–â–
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone â–ˆâ–‚â–‚â–„â–‚â–â–‚â–‚â–â–„
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone â–ˆâ–‚â–‚â–„â–‚â–â–‚â–‚â–â–„
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone â–ˆâ–„â–„â–…â–ƒâ–â–â–‚â–â–
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone â–ˆâ–„â–„â–…â–ƒâ–â–â–‚â–â–
wandb:                                  Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone 0.0
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: ðŸš€ View run dazzling-butterfly-738 at: https://wandb.ai/nreints/ThesisFinal2/runs/1vqityue
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_152135-1vqityue/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_153503-vplozbk3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run snowy-morning-741
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/vplozbk3
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone â–ˆâ–†â–ƒâ–„â–‚â–‚â–â–â–â–
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone â–ˆâ–†â–‚â–„â–â–â–â–‚â–„â–
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone â–ˆâ–†â–‚â–„â–â–â–â–‚â–ƒâ–
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone â–ˆâ–‡â–„â–…â–‚â–‚â–â–â–â–
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone â–ˆâ–‡â–„â–…â–‚â–‚â–â–â–â–
wandb:                                  Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone 0.0
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: ðŸš€ View run snowy-morning-741 at: https://wandb.ai/nreints/ThesisFinal2/runs/vplozbk3
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_153503-vplozbk3/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_154812-4indiaiw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run northern-star-744
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/4indiaiw
	 Logging test loss: 2.117e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.1877e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 69.4046905040741
Saved model in  trained_models/gru/data_t(0,0)_r(5,20)_combi_pNone_gNone/'rot_mat_1'_'False'.pth
It took  808.1054875850677  seconds.
----- ITERATION 9/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 50.56439423561096 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 12.58382511138916 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_none_pNone_gNone took 12.751097440719604 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_semi_pNone_gNone took 12.673007011413574 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_full_pNone_gNone took 12.665393829345703 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_tennis_pNone_gNone took 12.607906818389893 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0002198167 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.0812e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.193e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.31565e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.6e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.42941e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 67.17022228240967
Epoch 1/9
	 Logging train Loss: 5.9343e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.002e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.974e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.18953e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.515e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.30181e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 67.8512830734253
Epoch 2/9
	 Logging train Loss: 4.4265e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.9407e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.51e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 5.9364e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.17e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 6.312e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 67.89976716041565
Epoch 3/9
	 Logging train Loss: 3.8536e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.2939e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.512e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 8.5942e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.197e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 9.4169e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 66.63761281967163
Epoch 4/9
	 Logging train Loss: 3.1808e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.8369e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.5e-08 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.7811e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 6.32e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.0167e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 65.55183672904968
Epoch 5/9
	 Logging train Loss: 2.7741e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.5928e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.075e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.2714e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 9.1e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.5062e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 65.85015177726746
Epoch 6/9
	 Logging train Loss: 2.2301e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.1823e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.71e-08 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.4116e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 7.6e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.6427e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 65.82127285003662
Epoch 7/9
	 Logging train Loss: 1.7468e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.1159e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.541e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.165e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.441e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.4369e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 65.95649766921997
Epoch 8/9
	 Logging train Loss: 1.5976e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.0765e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.224e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.039e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.142e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.2212e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 65.54045701026917
Epoch 9/9
	 Logging train Loss: 1.5009e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.128e-07 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.81e-08 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.6301e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 7.08e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.7881e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 65.9757432937622
Saved model in  trained_models/gru/data_t(0,0)_r(5,20)_combi_pNone_gNone/'rot_mat_1'_'False'.pth
It took  789.1330895423889  seconds.
----- ITERATION 10/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 50.94638800621033 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 12.652180433273315 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_none_pNone_gNone took 12.720933198928833 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_semi_pNone_gNone took 12.71105694770813 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_full_pNone_gNone took 12.731305599212646 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_tennis_pNone_gNone took 12.638548612594604 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0002094332 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.7023e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.428e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 9.0948e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 5.717e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.00449e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 69.01506686210632
Epoch 1/9
	 Logging train Loss: 6.3767e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.3219e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.148e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 7.853e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone â–ˆâ–…â–ƒâ–„â–‚â–ƒâ–ƒâ–â–â–
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone â–ˆâ–‚â–â–ˆâ–‚â–‚â–‚â–â–â–
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone â–ˆâ–ƒâ–â–ˆâ–‚â–‚â–‚â–â–â–
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone â–ˆâ–‡â–„â–…â–ƒâ–ƒâ–ƒâ–â–â–
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone â–ˆâ–‡â–„â–…â–ƒâ–ƒâ–ƒâ–â–â–
wandb:                                  Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone 0.0
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: ðŸš€ View run northern-star-744 at: https://wandb.ai/nreints/ThesisFinal2/runs/4indiaiw
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_154812-4indiaiw/logs
	 Logging test loss: 1.644e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 8.9114e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 69.02698397636414
Epoch 2/9
	 Logging train Loss: 4.7753e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.5367e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.018e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 4.9281e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 6.18e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 5.3278e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 68.340744972229
Epoch 3/9
	 Logging train Loss: 3.6511e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.2079e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.171e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 5.6703e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 5.895e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 6.2921e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 67.16953659057617
Epoch 4/9
	 Logging train Loss: 3.1865e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.0213e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.463e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.7992e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.263e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.3477e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 67.22476625442505
Epoch 5/9
	 Logging train Loss: 2.465e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.2636e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.787e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 4.1451e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.633e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.8162e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 67.61931204795837
Epoch 6/9
	 Logging train Loss: 1.9838e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.2735e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.364e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 4.1298e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.289e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.8662e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 66.68072509765625
Epoch 7/9
	 Logging train Loss: 1.6006e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.0065e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.12e-08 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.8743e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 6.29e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.1828e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 66.60579586029053
Epoch 8/9
	 Logging train Loss: 1.4727e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.2043e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.37e-08 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.2282e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 7.54e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.6152e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 66.59192848205566
Epoch 9/9
	 Logging train Loss: 1.4122e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.1149e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 9.8e-08 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.9592e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 9.05e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.3064e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 67.35285878181458
Saved model in  trained_models/gru/data_t(0,0)_r(5,20)_combi_pNone_gNone/'rot_mat_1'_'False'.pth
It took  802.2029201984406  seconds.

JOB STATISTICS
==============
Job ID: 3037313
Array Job ID: 3037308_23
Cluster: snellius
User/Group: nreints/nreints
State: RUNNING
Nodes: 1
Cores per node: 18
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 1-16:09:54 core-walltime
Job Wall-clock time: 02:13:53
Memory Utilized: 0.00 MB (estimated maximum)
Memory Efficiency: 0.00% of 0.00 MB (0.00 MB/node)
WARNING: Efficiency statistics may be misleading for RUNNING jobs.
