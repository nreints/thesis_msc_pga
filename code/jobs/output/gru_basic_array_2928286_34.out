wandb: Currently logged in as: nreints. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230616_171819-08sp1q2l
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run whole-galaxy-68
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal/runs/08sp1q2l
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch ▁▂▃▃▄▅▆▆▇█
wandb: Test loss t(5,20)_r(5,20)_combiR_pNone_gNone █▂▁▁▂▁▁▁▁▂
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone █▂▁▁▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone █▂▁▁▂▁▁▁▁▂
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone █▂▁▁▂▁▁▁▁▂
wandb:                                   Train loss █▂▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb: Test loss t(5,20)_r(5,20)_combiR_pNone_gNone 3e-05
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 3e-05
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 3e-05
wandb:                                   Train loss 1e-05
wandb: 
wandb: 🚀 View run whole-galaxy-68 at: https://wandb.ai/nreints/ThesisFinal/runs/08sp1q2l
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230616_171819-08sp1q2l/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230616_172537-tke8b7mr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dry-energy-72
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal/runs/tke8b7mr
Training on dataset: data_t(5,20)_r(5,20)_combiR_pNone_gNone
Testing on 4 datasets: ['data_t(5,20)_r(5,20)_full_pNone_gNone', 'data_t(5,20)_r(5,20)_semi_pNone_gNone', 'data_t(5,20)_r(5,20)_tennis_pNone_gNone', 'data_t(5,20)_r(5,20)_combiR_pNone_gNone']
Focussing on identity: False
Using extra input: None
Using fr-fr as reference point.
----- ITERATION 1/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  800
Number of test simulations:  200
The dataloader for data/data_t(5,20)_r(5,20)_combiR_pNone_gNone took 21.873634338378906 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 5.472978591918945 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 5.474440813064575 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 5.47088885307312 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_combiR_pNone_gNone took 5.457622289657593 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: log_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0009128776 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 5.33525e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0002213127 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0002229536 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0001833863 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
		--> Epoch time; 38.85243606567383
Epoch 1/9
	 Logging train Loss: 8.79347e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 1.15107e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.15415e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.15084e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.44257e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
		--> Epoch time; 38.25789260864258
Epoch 2/9
	 Logging train Loss: 1.50888e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 2.1601e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.56953e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.59334e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.26255e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
		--> Epoch time; 38.17539882659912
Epoch 3/9
	 Logging train Loss: 8.0779e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 1.6686e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.70859e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.79265e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.36003e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
		--> Epoch time; 38.53882050514221
Epoch 4/9
	 Logging train Loss: 7.6158e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 1.7328e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.68904e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.73533e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.11268e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
		--> Epoch time; 37.98668432235718
Epoch 5/9
	 Logging train Loss: 8.4364e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 1.0573e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.11631e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.11512e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 8.7191e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
		--> Epoch time; 38.58216857910156
Epoch 6/9
	 Logging train Loss: 7.0125e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 8.215e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 8.3961e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 8.2272e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 6.4697e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
		--> Epoch time; 38.28335189819336
Epoch 7/9
	 Logging train Loss: 7.5518e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 6.935e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 8.2063e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 8.1598e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 6.4412e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
		--> Epoch time; 38.22558283805847
Epoch 8/9
	 Logging train Loss: 7.2073e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 6.746e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.08388e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.12679e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 8.6144e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
		--> Epoch time; 38.002039432525635
Epoch 9/9
	 Logging train Loss: 7.0745e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 1.2564e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.1016e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.4651e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.55103e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
		--> Epoch time; 37.9361138343811
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combiR_pNone_gNone/'log_quat_1'_'None'.pth
It took  438.87071347236633  seconds.
----- ITERATION 2/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  800
Number of test simulations:  200
The dataloader for data/data_t(5,20)_r(5,20)_combiR_pNone_gNone took 20.483478307724 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 5.140383243560791 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 5.13262414932251 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 5.1553955078125 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_combiR_pNone_gNone took 5.091570138931274 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: log_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0016807041 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 7.00123e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0002552661 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.00023984 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0001824636 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
		--> Epoch time; 38.15747356414795
Epoch 1/9
	 Logging train Loss: 0.0001238328 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 4.1114e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 9.97006e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 9.3629e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 7.51931e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
		--> Epoch time; 38.084839820861816
Epoch 2/9
	 Logging train Loss: 5.27866e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 1.67077e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.05849e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.80994e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.0736e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
		--> Epoch time; 38.0858633518219
Epoch 3/9
	 Logging train Loss: 2.21672e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch ▁▂▃▃▄▅▆▆▇█
wandb: Test loss t(5,20)_r(5,20)_combiR_pNone_gNone █▄▂▁▁▁▁▁▁▃
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone █▅▃▁▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone █▄▂▁▁▁▁▁▁▃
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone █▄▂▁▁▁▁▁▁▃
wandb:                                   Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb: Test loss t(5,20)_r(5,20)_combiR_pNone_gNone 5e-05
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 7e-05
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 7e-05
wandb:                                   Train loss 1e-05
wandb: 
wandb: 🚀 View run dry-energy-72 at: https://wandb.ai/nreints/ThesisFinal/runs/tke8b7mr
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230616_172537-tke8b7mr/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230616_173307-7tczi8t7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run proud-spaceship-77
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal/runs/7tczi8t7
	 Logging test loss: 5.1273e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.72037e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.61473e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.24916e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
		--> Epoch time; 38.39627194404602
Epoch 4/9
	 Logging train Loss: 1.16165e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 2.6386e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.2044e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.07575e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.52367e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
		--> Epoch time; 38.05136704444885
Epoch 5/9
	 Logging train Loss: 9.052e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 2.0732e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.67514e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.63481e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.17234e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
		--> Epoch time; 38.04344296455383
Epoch 6/9
	 Logging train Loss: 8.5799e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 1.7877e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.61357e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.51377e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.09301e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
		--> Epoch time; 39.69266724586487
Epoch 7/9
	 Logging train Loss: 8.3274e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 1.5012e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.30712e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.28796e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 8.924e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
		--> Epoch time; 42.89880847930908
Epoch 8/9
	 Logging train Loss: 7.8924e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 1.2318e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 9.4677e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 8.9741e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 6.4628e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
		--> Epoch time; 38.47046113014221
Epoch 9/9
	 Logging train Loss: 8.4085e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 2.7803e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 6.89096e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 6.69661e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.66088e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
		--> Epoch time; 38.077258348464966
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combiR_pNone_gNone/'log_quat_1'_'None'.pth
It took  449.76780581474304  seconds.
----- ITERATION 3/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  800
Number of test simulations:  200
The dataloader for data/data_t(5,20)_r(5,20)_combiR_pNone_gNone took 20.215067625045776 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 5.110493183135986 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 5.112927436828613 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 5.1215269565582275 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_combiR_pNone_gNone took 5.051334619522095 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: log_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0013037312 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 6.58465e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0002208569 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0002234073 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0001662538 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
		--> Epoch time; 38.191110372543335
Epoch 1/9
	 Logging train Loss: 0.000112663 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 3.21555e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 6.92313e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 6.77793e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 5.57457e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
		--> Epoch time; 38.6014621257782
Epoch 2/9
	 Logging train Loss: 3.32508e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 9.7459e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.92789e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.89592e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.55138e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
		--> Epoch time; 38.04390215873718
Epoch 3/9
	 Logging train Loss: 1.17902e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 2.7001e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.10788e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.06669e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 8.0426e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
		--> Epoch time; 38.19970440864563
Epoch 4/9
	 Logging train Loss: 8.5224e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 1.8043e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.1197e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.09536e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 7.9652e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
		--> Epoch time; 37.99255967140198
Epoch 5/9
	 Logging train Loss: 7.7252e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 1.571e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.22413e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.20174e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 8.5658e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
		--> Epoch time; 38.03311252593994
Epoch 6/9
	 Logging train Loss: 8.2314e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 1.315e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.03366e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.01395e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 7.208e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
		--> Epoch time; 38.3543815612793
Epoch 7/9
	 Logging train Loss: 8.0002e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 1.2388e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.28734e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.31929e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 9.0074e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
		--> Epoch time; 38.16201066970825
Epoch 8/9
	 Logging train Loss: 7.2348e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 9.941e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 8.3736e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 8.0876e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 5.8143e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
		--> Epoch time; 37.97638750076294
Epoch 9/9
	 Logging train Loss: 7.7184e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch ▁▂▃▃▄▅▆▆▇█
wandb: Test loss t(5,20)_r(5,20)_combiR_pNone_gNone █▃▁▁▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone █▄▂▁▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone █▃▁▁▁▁▁▁▁▁
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone █▃▁▁▁▁▁▁▁▁
wandb:                                   Train loss █▂▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb: Test loss t(5,20)_r(5,20)_combiR_pNone_gNone 1e-05
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 1e-05
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 1e-05
wandb:                                   Train loss 1e-05
wandb: 
wandb: 🚀 View run proud-spaceship-77 at: https://wandb.ai/nreints/ThesisFinal/runs/7tczi8t7
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230616_173307-7tczi8t7/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230616_174022-mf7f09rc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run revived-fire-84
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal/runs/mf7f09rc
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch ▁▂▃▃▄▅▆▆▇█
wandb: Test loss t(5,20)_r(5,20)_combiR_pNone_gNone █▄▂▁▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone █▃▁▁▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone █▄▂▁▁▁▁▁▁▁
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone █▄▂▁▁▁▁▁▁▁
wandb:                                   Train loss █▂▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb: Test loss t(5,20)_r(5,20)_combiR_pNone_gNone 1e-05
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 1e-05
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 1e-05
wandb:                                   Train loss 1e-05
wandb: 
wandb: 🚀 View run revived-fire-84 at: https://wandb.ai/nreints/ThesisFinal/runs/mf7f09rc
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230616_174022-mf7f09rc/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230616_174745-4q7buj98
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run charmed-water-90
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal/runs/4q7buj98
	 Logging test loss: 8.643e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.01638e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 9.9687e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 7.1207e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
		--> Epoch time; 38.06591033935547
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combiR_pNone_gNone/'log_quat_1'_'None'.pth
It took  434.8100619316101  seconds.
----- ITERATION 4/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  800
Number of test simulations:  200
The dataloader for data/data_t(5,20)_r(5,20)_combiR_pNone_gNone took 20.293909549713135 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 5.1967103481292725 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 5.187934160232544 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 5.159409761428833 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_combiR_pNone_gNone took 5.043077707290649 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: log_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0013359641 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 5.80127e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0002419225 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0002653423 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0002115461 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
		--> Epoch time; 38.25817012786865
Epoch 1/9
	 Logging train Loss: 0.0001185222 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 2.04147e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 9.30946e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0001011387 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 8.10318e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
		--> Epoch time; 38.520087480545044
Epoch 2/9
	 Logging train Loss: 3.46751e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 2.8041e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.43779e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.70657e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.0803e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
		--> Epoch time; 37.785144567489624
Epoch 3/9
	 Logging train Loss: 1.15294e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 1.567e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.20347e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.31624e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.02193e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
		--> Epoch time; 38.0395610332489
Epoch 4/9
	 Logging train Loss: 7.6906e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 1.2043e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 9.4653e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.02616e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 7.8815e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
		--> Epoch time; 38.46200203895569
Epoch 5/9
	 Logging train Loss: 7.8001e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 9.586e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 7.636e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 8.2971e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 6.3994e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
		--> Epoch time; 37.8507981300354
Epoch 6/9
	 Logging train Loss: 6.6219e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 1.0316e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.46829e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.57477e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.19759e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
		--> Epoch time; 38.29778814315796
Epoch 7/9
	 Logging train Loss: 7.0933e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 7.381e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 9.3189e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.00896e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 7.6516e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
		--> Epoch time; 42.35908007621765
Epoch 8/9
	 Logging train Loss: 6.3585e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 7.777e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.39744e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.4989e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.13184e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
		--> Epoch time; 41.250545263290405
Epoch 9/9
	 Logging train Loss: 6.381e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 5.046e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 7.0226e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 7.6375e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 5.8307e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
		--> Epoch time; 38.29658913612366
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combiR_pNone_gNone/'log_quat_1'_'None'.pth
It took  442.8811538219452  seconds.
----- ITERATION 5/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  800
Number of test simulations:  200
The dataloader for data/data_t(5,20)_r(5,20)_combiR_pNone_gNone took 20.478025674819946 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 5.127260446548462 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 5.11354923248291 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 5.114522218704224 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_combiR_pNone_gNone took 5.025106430053711 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: log_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0022098601 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 7.41872e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0002670054 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0002585828 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0002164237 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
		--> Epoch time; 38.44479942321777
Epoch 1/9
	 Logging train Loss: 0.0001533323 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 5.57327e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0001406469 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0001368151 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0001187013 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
		--> Epoch time; 38.27192783355713
Epoch 2/9
	 Logging train Loss: 7.85658e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 3.4763e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 6.33306e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 6.21982e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 5.64272e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch ▁▂▃▃▄▅▆▆▇█
wandb: Test loss t(5,20)_r(5,20)_combiR_pNone_gNone █▅▃▁▁▁▁▁▁▂
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone █▆▄▂▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone █▅▂▁▁▁▁▁▁▂
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone █▅▃▁▁▁▁▁▁▂
wandb:                                   Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb: Test loss t(5,20)_r(5,20)_combiR_pNone_gNone 2e-05
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 3e-05
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 3e-05
wandb:                                   Train loss 1e-05
wandb: 
wandb: 🚀 View run charmed-water-90 at: https://wandb.ai/nreints/ThesisFinal/runs/4q7buj98
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230616_174745-4q7buj98/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230616_175502-6zq51hp9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lucky-vortex-95
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal/runs/6zq51hp9
		--> Epoch time; 38.419365644454956
Epoch 3/9
	 Logging train Loss: 3.3949e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 1.23508e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.37049e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.30681e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.07237e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
		--> Epoch time; 38.194414138793945
Epoch 4/9
	 Logging train Loss: 1.20316e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 2.7543e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.16282e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.06934e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 9.0831e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
		--> Epoch time; 38.01862120628357
Epoch 5/9
	 Logging train Loss: 7.1622e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 1.9586e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.1148e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.02191e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 8.4927e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
		--> Epoch time; 38.54782748222351
Epoch 6/9
	 Logging train Loss: 6.4864e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 1.6089e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 8.6026e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 7.5925e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 6.5309e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
		--> Epoch time; 38.55378079414368
Epoch 7/9
	 Logging train Loss: 6.1314e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 1.3893e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 8.599e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 7.6516e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 6.4843e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
		--> Epoch time; 38.335304975509644
Epoch 8/9
	 Logging train Loss: 7.2654e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 1.2158e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 8.7926e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 7.8023e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 6.5508e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
		--> Epoch time; 38.01652908325195
Epoch 9/9
	 Logging train Loss: 6.6365e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 1.6357e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.17367e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.02545e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.35481e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
		--> Epoch time; 38.055217027664185
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combiR_pNone_gNone/'log_quat_1'_'None'.pth
It took  436.9264831542969  seconds.
----- ITERATION 6/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  800
Number of test simulations:  200
The dataloader for data/data_t(5,20)_r(5,20)_combiR_pNone_gNone took 20.15596079826355 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 5.06305193901062 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 5.054136514663696 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 5.094363451004028 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_combiR_pNone_gNone took 5.118162631988525 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: log_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0020801404 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 7.11106e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0002473258 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.000279012 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0001968214 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
		--> Epoch time; 38.30562996864319
Epoch 1/9
	 Logging train Loss: 0.0001523776 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 4.72658e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0001217574 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0001350647 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0001029139 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
		--> Epoch time; 38.621254205703735
Epoch 2/9
	 Logging train Loss: 7.05308e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 2.25024e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.71946e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 5.12154e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.17709e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
		--> Epoch time; 38.23001837730408
Epoch 3/9
	 Logging train Loss: 2.5597e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 6.6775e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.78784e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.95376e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.5114e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
		--> Epoch time; 38.26232171058655
Epoch 4/9
	 Logging train Loss: 1.03325e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 2.374e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.14662e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.25599e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 8.8271e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
		--> Epoch time; 38.05903172492981
Epoch 5/9
	 Logging train Loss: 7.034e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 1.8252e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.58289e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.77502e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.169e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
		--> Epoch time; 38.16144847869873
Epoch 6/9
	 Logging train Loss: 6.3874e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 1.3482e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 8.152e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 8.7573e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 5.9743e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
		--> Epoch time; 38.09360671043396
Epoch 7/9
	 Logging train Loss: 6.2548e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 1.1314e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 7.2933e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 7.6794e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 5.2508e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
		--> Epoch time; 38.04487228393555
Epoch 8/9
	 Logging train Loss: 6.6124e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 1.8037e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.26783e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.89455e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.37816e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
		--> Epoch time; 41.01470470428467
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch ▁▂▃▃▄▅▆▆▇█
wandb: Test loss t(5,20)_r(5,20)_combiR_pNone_gNone █▅▂▁▁▁▁▁▂▂
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone █▆▃▂▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone █▄▂▁▁▁▁▁▂▂
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone █▄▂▁▁▁▁▁▂▃
wandb:                                   Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb: Test loss t(5,20)_r(5,20)_combiR_pNone_gNone 4e-05
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 6e-05
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 7e-05
wandb:                                   Train loss 1e-05
wandb: 
wandb: 🚀 View run lucky-vortex-95 at: https://wandb.ai/nreints/ThesisFinal/runs/6zq51hp9
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230616_175502-6zq51hp9/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230616_180222-35rbknsg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run woven-fire-99
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal/runs/35rbknsg
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch ▁▂▃▃▄▅▆▆▇█
wandb: Test loss t(5,20)_r(5,20)_combiR_pNone_gNone █▄▂▁▁▁▁▁▁▂
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone █▅▃▁▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone █▄▂▁▁▁▁▁▁▂
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone █▄▂▁▁▁▁▁▁▂
wandb:                                   Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb: Test loss t(5,20)_r(5,20)_combiR_pNone_gNone 3e-05
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 4e-05
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 4e-05
wandb:                                   Train loss 1e-05
wandb: 
wandb: 🚀 View run woven-fire-99 at: https://wandb.ai/nreints/ThesisFinal/runs/35rbknsg
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230616_180222-35rbknsg/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230616_180937-njdolbpf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run amber-forest-105
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal/runs/njdolbpf
Epoch 9/9
	 Logging train Loss: 6.6274e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 2.2786e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 5.65884e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 6.60058e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.04789e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
		--> Epoch time; 41.447099685668945
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combiR_pNone_gNone/'log_quat_1'_'None'.pth
It took  440.72547149658203  seconds.
----- ITERATION 7/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  800
Number of test simulations:  200
The dataloader for data/data_t(5,20)_r(5,20)_combiR_pNone_gNone took 19.859766483306885 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 5.086308240890503 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 5.069017648696899 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 5.08130407333374 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_combiR_pNone_gNone took 4.987831354141235 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: log_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0020145176 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 7.01424e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0002494321 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0002533695 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0001967068 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
		--> Epoch time; 38.10200834274292
Epoch 1/9
	 Logging train Loss: 0.0001390448 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 4.10539e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0001075518 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0001065792 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 8.82081e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
		--> Epoch time; 38.168452978134155
Epoch 2/9
	 Logging train Loss: 5.4945e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 1.67921e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.60161e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.48415e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.03654e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
		--> Epoch time; 38.03137254714966
Epoch 3/9
	 Logging train Loss: 1.75117e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 3.244e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.315e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.24025e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 9.9714e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
		--> Epoch time; 38.029733419418335
Epoch 4/9
	 Logging train Loss: 7.589e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 1.6387e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.0626e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 9.7653e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 7.6172e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
		--> Epoch time; 38.260722160339355
Epoch 5/9
	 Logging train Loss: 6.3933e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 1.5769e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.83563e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.7917e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.31994e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
		--> Epoch time; 38.04106044769287
Epoch 6/9
	 Logging train Loss: 6.1527e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 1.131e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.01424e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 9.93e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 7.2793e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
		--> Epoch time; 38.16788983345032
Epoch 7/9
	 Logging train Loss: 6.0331e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 1.1345e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.52321e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.57749e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.11698e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
		--> Epoch time; 38.39996337890625
Epoch 8/9
	 Logging train Loss: 6.0028e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 8.172e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.01281e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.00847e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 7.1697e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
		--> Epoch time; 37.82319259643555
Epoch 9/9
	 Logging train Loss: 6.4104e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 1.4824e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.68161e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.65997e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.58281e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
		--> Epoch time; 38.11227536201477
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combiR_pNone_gNone/'log_quat_1'_'None'.pth
It took  434.8550305366516  seconds.
----- ITERATION 8/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  800
Number of test simulations:  200
The dataloader for data/data_t(5,20)_r(5,20)_combiR_pNone_gNone took 19.12063479423523 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 5.020457029342651 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 5.019615173339844 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 5.047078609466553 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_combiR_pNone_gNone took 4.757913589477539 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: log_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0017277856 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 6.98308e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0002360341 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0002328936 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0001925401 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
		--> Epoch time; 38.332759380340576
Epoch 1/9
	 Logging train Loss: 0.0001216489 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 4.23519e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 9.44862e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 9.18115e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 8.01634e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
		--> Epoch time; 38.203664779663086
Epoch 2/9
	 Logging train Loss: 4.81747e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 1.63171e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.27371e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.06761e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch ▁▂▃▃▄▅▆▆▇█
wandb: Test loss t(5,20)_r(5,20)_combiR_pNone_gNone █▄▂▁▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone █▅▃▂▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone █▄▂▁▁▁▁▁▁▁
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone █▄▂▁▁▁▁▁▁▁
wandb:                                   Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb: Test loss t(5,20)_r(5,20)_combiR_pNone_gNone 1e-05
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 1e-05
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 1e-05
wandb:                                   Train loss 1e-05
wandb: 
wandb: 🚀 View run amber-forest-105 at: https://wandb.ai/nreints/ThesisFinal/runs/njdolbpf
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230616_180937-njdolbpf/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230616_181651-s42ueria
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rural-wind-109
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal/runs/s42ueria
	 Logging test loss: 2.79004e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
		--> Epoch time; 37.87013602256775
Epoch 3/9
	 Logging train Loss: 1.84813e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 6.3506e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.52089e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.4311e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.27719e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
		--> Epoch time; 37.985979080200195
Epoch 4/9
	 Logging train Loss: 9.8875e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 2.6228e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.16045e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.14697e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 9.4851e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
		--> Epoch time; 38.1179473400116
Epoch 5/9
	 Logging train Loss: 8.12e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 1.8354e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 9.4678e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 9.0415e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 7.4312e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
		--> Epoch time; 38.137369871139526
Epoch 6/9
	 Logging train Loss: 7.1076e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 1.637e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.2019e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.25079e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 9.8398e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
		--> Epoch time; 37.98768973350525
Epoch 7/9
	 Logging train Loss: 7.0018e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 1.3046e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 9.1685e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 9.0985e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 7.2738e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
		--> Epoch time; 38.36426758766174
Epoch 8/9
	 Logging train Loss: 6.9473e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 1.3634e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.71399e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.81746e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.33195e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
		--> Epoch time; 38.19207429885864
Epoch 9/9
	 Logging train Loss: 6.668e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 1.0231e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.18088e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.21814e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 9.1607e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
		--> Epoch time; 38.61253881454468
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combiR_pNone_gNone/'log_quat_1'_'None'.pth
It took  433.77525329589844  seconds.
----- ITERATION 9/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  800
Number of test simulations:  200
The dataloader for data/data_t(5,20)_r(5,20)_combiR_pNone_gNone took 19.126646041870117 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 4.904749870300293 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 4.909236907958984 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 4.916511535644531 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_combiR_pNone_gNone took 4.762710332870483 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: log_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0023021135 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 6.51546e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0002668508 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0002681988 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0002206597 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
		--> Epoch time; 38.122082471847534
Epoch 1/9
	 Logging train Loss: 0.0001392428 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 4.00046e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0001182431 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0001201658 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0001030307 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
		--> Epoch time; 38.03170847892761
Epoch 2/9
	 Logging train Loss: 6.07301e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 2.27663e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.68392e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.81857e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.35247e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
		--> Epoch time; 38.03100872039795
Epoch 3/9
	 Logging train Loss: 2.6339e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 1.01483e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.07219e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.10394e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.92269e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
		--> Epoch time; 37.78041863441467
Epoch 4/9
	 Logging train Loss: 1.18788e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 3.5674e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.41163e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.45693e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.18037e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
		--> Epoch time; 37.884689807891846
Epoch 5/9
	 Logging train Loss: 6.8323e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 1.7515e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 8.8767e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 9.0702e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 7.2926e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
		--> Epoch time; 38.194836378097534
Epoch 6/9
	 Logging train Loss: 5.7454e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 1.448e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 8.3899e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 8.4784e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 6.8859e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
		--> Epoch time; 37.70466351509094
Epoch 7/9
	 Logging train Loss: 5.5711e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 1.2433e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 8.6915e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 8.8665e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 6.9179e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
		--> Epoch time; 38.078469038009644
Epoch 8/9
	 Logging train Loss: 5.7152e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 1.4221e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.05755e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.19077e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch ▁▂▃▃▄▅▆▆▇█
wandb: Test loss t(5,20)_r(5,20)_combiR_pNone_gNone █▄▂▁▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone █▅▃▂▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone █▄▂▁▁▁▁▁▁▁
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone █▄▂▁▁▁▁▁▁▁
wandb:                                   Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb: Test loss t(5,20)_r(5,20)_combiR_pNone_gNone 1e-05
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 2e-05
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 2e-05
wandb:                                   Train loss 1e-05
wandb: 
wandb: 🚀 View run rural-wind-109 at: https://wandb.ai/nreints/ThesisFinal/runs/s42ueria
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230616_181651-s42ueria/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230616_182403-cbjs5la1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run devout-breeze-111
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal/runs/cbjs5la1
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch ▁▂▃▃▄▅▆▆▇█
wandb: Test loss t(5,20)_r(5,20)_combiR_pNone_gNone █▂▁▁▃▁▂▁▁▁
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone █▃▁▁▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone █▂▁▁▃▁▃▁▁▁
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone █▂▁▁▄▁▃▁▁▁
wandb:                                   Train loss █▂▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb: Test loss t(5,20)_r(5,20)_combiR_pNone_gNone 1e-05
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 2e-05
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 2e-05
wandb:                                   Train loss 1e-05
wandb: 
wandb: 🚀 View run devout-breeze-111 at: https://wandb.ai/nreints/ThesisFinal/runs/cbjs5la1
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230616_182403-cbjs5la1/logs
	 Logging test loss: 1.58382e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
		--> Epoch time; 38.144612550735474
Epoch 9/9
	 Logging train Loss: 5.9418e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 1.2309e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.89885e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.98994e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.47188e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
		--> Epoch time; 37.78536128997803
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combiR_pNone_gNone/'log_quat_1'_'None'.pth
It took  431.8866608142853  seconds.
----- ITERATION 10/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  800
Number of test simulations:  200
The dataloader for data/data_t(5,20)_r(5,20)_combiR_pNone_gNone took 19.137389421463013 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 4.9307661056518555 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 4.923162221908569 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 4.924761056900024 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_combiR_pNone_gNone took 4.766700267791748 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: log_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0009288317 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 5.7435e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0002020795 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0001893274 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0001583072 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
		--> Epoch time; 38.27422547340393
Epoch 1/9
	 Logging train Loss: 7.76637e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 1.6837e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.13463e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.82788e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.34858e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
		--> Epoch time; 37.90908741950989
Epoch 2/9
	 Logging train Loss: 1.76429e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 2.9808e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.09956e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 9.8435e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 8.2804e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
		--> Epoch time; 37.76848077774048
Epoch 3/9
	 Logging train Loss: 9.3522e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 2.0875e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 9.4472e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 8.4987e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 6.9435e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
		--> Epoch time; 38.30035042762756
Epoch 4/9
	 Logging train Loss: 9.1773e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 3.5543e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 7.68723e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 7.66071e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 5.50835e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
		--> Epoch time; 38.018349170684814
Epoch 5/9
	 Logging train Loss: 8.5045e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 1.6731e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.8437e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.77254e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.31348e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
		--> Epoch time; 38.27803373336792
Epoch 6/9
	 Logging train Loss: 8.1215e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 2.3063e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 5.30359e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 5.14232e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.9088e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
		--> Epoch time; 38.19377255439758
Epoch 7/9
	 Logging train Loss: 7.4331e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 1.3098e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.08018e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.96873e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.46707e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
		--> Epoch time; 37.9457483291626
Epoch 8/9
	 Logging train Loss: 6.8976e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 1.1054e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.95642e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.83453e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.37172e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
		--> Epoch time; 38.178823471069336
Epoch 9/9
	 Logging train Loss: 7.0937e-06 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 9.824e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.86264e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.77973e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.3078e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
		--> Epoch time; 37.791056394577026
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combiR_pNone_gNone/'log_quat_1'_'None'.pth
It took  439.70571756362915  seconds.

JOB STATISTICS
==============
Job ID: 2929847
Array Job ID: 2928286_34
Cluster: snellius
User/Group: nreints/nreints
State: COMPLETED (exit code 0)
Nodes: 1
Cores per node: 18
CPU Utilized: 15:24:10
CPU Efficiency: 70.04% of 21:59:24 core-walltime
Job Wall-clock time: 01:13:18
Memory Utilized: 7.20 GB
Memory Efficiency: 0.00% of 0.00 MB
