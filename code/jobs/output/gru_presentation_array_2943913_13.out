wandb: Currently logged in as: nreints. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230620_120349-h7tf9qxi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run usual-wave-121
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal/runs/h7tf9qxi
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone █▂▂▂▂▂▂▂▁▁
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone █▁▁▁▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone █▁▂▁▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone █▂▂▃▂▃▂▂▁▁
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone █▂▂▃▂▃▂▂▁▁
wandb:                                   Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 0.0
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 0.0
wandb:                                   Train loss 0.0
wandb: 
wandb: 🚀 View run usual-wave-121 at: https://wandb.ai/nreints/ThesisFinal/runs/h7tf9qxi
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230620_120349-h7tf9qxi/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230620_122523-0hdc8qj4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run winter-darkness-147
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal/runs/0hdc8qj4
Training on dataset: data_t(5,20)_r(5,20)_combi_pNone_gNone
Testing on 5 datasets: ['data_t(5,20)_r(5,20)_full_pNone_gNone', 'data_t(5,20)_r(5,20)_tennis_pNone_gNone', 'data_t(5,20)_r(5,20)_combi_pNone_gNone', 'data_t(5,20)_r(5,20)_semi_pNone_gNone', 'data_t(5,20)_r(5,20)_none_pNone_gNone']
Focussing on identity: True
Using extra input: None
Using fr-fr as reference point.
----- ITERATION 1/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 52.69967293739319 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 13.400807619094849 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 13.43822979927063 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 13.174347877502441 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 13.312925577163696 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_none_pNone_gNone took 13.450658321380615 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0006729468 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.07091e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.16696e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.13566e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.23433e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.0169e-05 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 115.83506321907043
Epoch 1/9
	 Logging train Loss: 1.3665e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.341e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 9.6794e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 5.5038e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.04553e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.3539e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 121.95312690734863
Epoch 2/9
	 Logging train Loss: 7.4417e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.7047e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.11091e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 6.3752e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.17311e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.7325e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 114.27168321609497
Epoch 3/9
	 Logging train Loss: 7.2917e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.0999e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.51738e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 7.9017e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.57453e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.1336e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 114.48861145973206
Epoch 4/9
	 Logging train Loss: 6.9419e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.442e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 9.0287e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.9279e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 9.5313e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 8.85e-07 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 114.22489905357361
Epoch 5/9
	 Logging train Loss: 6.0224e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.964e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.30189e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 6.8959e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.3605e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 9.396e-07 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 114.12227511405945
Epoch 6/9
	 Logging train Loss: 5.5236e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.556e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 9.2933e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.8106e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 9.5997e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.935e-07 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 114.1657407283783
Epoch 7/9
	 Logging train Loss: 4.7464e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.479e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 7.5486e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.0907e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.7498e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 7.777e-07 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 114.0377516746521
Epoch 8/9
	 Logging train Loss: 3.912e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.819e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 5.2346e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.7612e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.5551e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.138e-07 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 114.8667664527893
Epoch 9/9
	 Logging train Loss: 3.5253e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.896e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.6389e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.9441e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.8202e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.137e-07 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 121.14139366149902
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gNone/'dual_quat_1'_'None'.pth
It took  1294.9251680374146  seconds.
----- ITERATION 2/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 48.103373289108276 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 12.377757549285889 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 12.396085023880005 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 12.057554244995117 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 12.364614963531494 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_none_pNone_gNone took 12.473047256469727 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0005798353 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.15868e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 5.9261e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.70948e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.13411e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.25197e-05 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone █▅▂▂▁▂▁▁▁▁
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone █▂▁▁▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone █▂▁▁▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone █▇▂▂▂▂▂▂▁▁
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone █▇▂▂▂▂▂▂▁▁
wandb:                                   Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 0.0
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 0.0
wandb:                                   Train loss 0.0
wandb: 
wandb: 🚀 View run winter-darkness-147 at: https://wandb.ai/nreints/ThesisFinal/runs/0hdc8qj4
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230620_122523-0hdc8qj4/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230620_124640-0j84uoi5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run prime-water-166
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal/runs/0j84uoi5
		--> Epoch time; 114.95711398124695
Epoch 1/9
	 Logging train Loss: 2.27598e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.3563e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 5.14706e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.95318e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.0614e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 5.5002e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 114.57735872268677
Epoch 2/9
	 Logging train Loss: 9.1342e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.6276e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.46507e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 8.7805e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.55058e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.7266e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 114.3861026763916
Epoch 3/9
	 Logging train Loss: 7.9517e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.0554e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 9.0824e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 5.5817e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 9.9276e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.1317e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 114.07653594017029
Epoch 4/9
	 Logging train Loss: 7.4391e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 9.044e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 8.6942e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 5.2902e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 9.5999e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 9.638e-07 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 114.36708879470825
Epoch 5/9
	 Logging train Loss: 6.4403e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.585e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.32665e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 7.446e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.38093e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 8.106e-07 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 114.86320304870605
Epoch 6/9
	 Logging train Loss: 5.2017e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.085e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 8.4282e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.8137e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.9033e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 5.485e-07 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 121.76173114776611
Epoch 7/9
	 Logging train Loss: 4.7883e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.092e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 8.6544e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 5.1455e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 9.1764e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 7.466e-07 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 113.98166918754578
Epoch 8/9
	 Logging train Loss: 4.0211e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.079e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.2159e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.5318e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.7091e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.338e-07 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 113.62847995758057
Epoch 9/9
	 Logging train Loss: 3.555e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.536e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.5953e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.1566e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.9991e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.752e-07 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 114.80526876449585
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gNone/'dual_quat_1'_'None'.pth
It took  1277.6432185173035  seconds.
----- ITERATION 3/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 48.58296084403992 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 12.319145202636719 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 12.311309337615967 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 12.122620344161987 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 12.210648775100708 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_none_pNone_gNone took 12.339813947677612 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0007299692 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.05513e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 6.85176e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.62581e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.48177e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.99952e-05 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 114.24243545532227
Epoch 1/9
	 Logging train Loss: 2.103e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.6497e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.79551e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 9.1155e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.63765e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.6378e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 114.0678141117096
Epoch 2/9
	 Logging train Loss: 8.2749e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.5817e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.25344e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 6.2711e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.15659e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.6035e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 114.78081202507019
Epoch 3/9
	 Logging train Loss: 7.5764e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.0314e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 9.4725e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.6021e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.6656e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.0498e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 122.06219840049744
Epoch 4/9
	 Logging train Loss: 6.7314e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.1601e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.0026e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
slurmstepd: error: *** JOB 2943928 ON gcn34 CANCELLED AT 2023-06-20T13:04:07 ***
slurmstepd: error: *** STEP 2943928.0 ON gcn34 CANCELLED AT 2023-06-20T13:04:07 ***

JOB STATISTICS
==============
Job ID: 2943928
Array Job ID: 2943913_13
Cluster: snellius
User/Group: nreints/nreints
State: CANCELLED (exit code 0)
Nodes: 1
Cores per node: 18
CPU Utilized: 00:00:01
CPU Efficiency: 0.00% of 18:09:00 core-walltime
Job Wall-clock time: 01:00:30
Memory Utilized: 6.43 MB
Memory Efficiency: 0.00% of 0.00 MB
