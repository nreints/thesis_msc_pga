wandb: Currently logged in as: nreints. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230329_124733-8y94b78w
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run magic-violet-484
wandb: ⭐️ View project at https://wandb.ai/nreints/test
wandb: 🚀 View run at https://wandb.ai/nreints/test/runs/8y94b78w
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.031 MB of 0.031 MB uploaded (0.000 MB deduped)wandb: \ 0.031 MB of 0.078 MB uploaded (0.000 MB deduped)wandb: | 0.031 MB of 0.078 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:                                                  Epoch ▁▂▃▃▄▅▆▆▇█
wandb: Test loss t(5, 20)_r(0, 0)_full_pNone_gNone, MSELoss() █▂▁▁▁▁▁▁▁▁▁
wandb:                                             Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                                  Epoch 9
wandb: Test loss t(5, 20)_r(0, 0)_full_pNone_gNone, MSELoss() 0.00516
wandb:                                             Train loss 0.00077
wandb: 
wandb: 🚀 View run magic-violet-484 at: https://wandb.ai/nreints/test/runs/8y94b78w
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230329_124733-8y94b78w/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230329_125602-5fb33hlq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run leafy-dust-498
wandb: ⭐️ View project at https://wandb.ai/nreints/test
wandb: 🚀 View run at https://wandb.ai/nreints/test/runs/5fb33hlq
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                                  Epoch ▁▂▃▃▄▅▆▆▇█
wandb: Test loss t(5, 20)_r(0, 0)_full_pNone_gNone, MSELoss() █▂▁▁▁▁▁▁▁▁▁
wandb:                                             Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                                  Epoch 9
wandb: Test loss t(5, 20)_r(0, 0)_full_pNone_gNone, MSELoss() 0.0008
wandb:                                             Train loss 0.00087
wandb: 
wandb: 🚀 View run leafy-dust-498 at: https://wandb.ai/nreints/test/runs/5fb33hlq
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230329_125602-5fb33hlq/logs
Running for data type: log_quat
----- ITERATION 1/2 ------
Number of train simulations: 1600
Number of test simulations: 400
-- Finished Train Dataloader --
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
-- Started Training --
Epoch 0
	 Logging train Loss: 3.9880283086 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss: 0.17484255135059357 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
     --> Epoch time; 45.93235731124878
Epoch 1
	 Logging train Loss: 0.0710787754 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss: 0.028140943497419357 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
     --> Epoch time; 43.957035541534424
Epoch 2
	 Logging train Loss: 0.0160788267 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss: 0.010699490085244179 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
     --> Epoch time; 44.04523587226868
Epoch 3
	 Logging train Loss: 0.0068989889 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss: 0.005192503798753023 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
     --> Epoch time; 44.023085832595825
Epoch 4
	 Logging train Loss: 0.0038329441 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss: 0.003849068423733115 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
     --> Epoch time; 43.36698079109192
Epoch 5
	 Logging train Loss: 0.0023820989 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss: 0.002956175711005926 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
     --> Epoch time; 43.860145807266235
Epoch 6
	 Logging train Loss: 0.0016827082 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss: 0.001323117408901453 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
     --> Epoch time; 43.87096381187439
Epoch 7
	 Logging train Loss: 0.0011688498 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss: 0.0008389137219637632 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
     --> Epoch time; 44.02776837348938
Epoch 8
	 Logging train Loss: 0.0009746439 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss: 0.0006490614032372832 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
     --> Epoch time; 44.22250962257385
Epoch 9
	 Logging train Loss: 0.0007745506 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss: 0.005150256212800741 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
     --> Epoch time; 43.82128095626831
	 Logging test loss: 0.005155924241989851 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
It took  510.3534126281738  seconds.
----- ITERATION 2/2 ------
Number of train simulations: 1600
Number of test simulations: 400
-- Finished Train Dataloader --
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
-- Started Training --
Epoch 0
	 Logging train Loss: 4.1705405384 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss: 0.21406330168247223 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
     --> Epoch time; 45.09180021286011
Epoch 1
	 Logging train Loss: 0.0808133073 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss: 0.03611813113093376 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
     --> Epoch time; 44.27218675613403
Epoch 2
	 Logging train Loss: 0.0178285161 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss: 0.012670851312577724 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
     --> Epoch time; 44.40571212768555
Epoch 3
	 Logging train Loss: 0.0074247601 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss: 0.006564151030033827 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
     --> Epoch time; 43.99486494064331
Epoch 4
	 Logging train Loss: 0.0040029779 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss: 0.0034587648697197437 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
     --> Epoch time; 44.566810131073
Epoch 5
	 Logging train Loss: 0.0025414173 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss: 0.002238089218735695 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
     --> Epoch time; 44.44743371009827
Epoch 6
	 Logging train Loss: 0.0017227902 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss: 0.0013999056536704302 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
     --> Epoch time; 44.550644874572754
Epoch 7
	 Logging train Loss: 0.0013465038 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss: 0.0016062053618952632 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
     --> Epoch time; 44.6341667175293
Epoch 8
	 Logging train Loss: 0.0010055211 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss: 0.0016323282616212964 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
     --> Epoch time; 44.22944927215576
Epoch 9
	 Logging train Loss: 0.0008702672 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss: 0.0007970639853738248 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
     --> Epoch time; 44.36224436759949
	 Logging test loss: 0.0007974744657985866 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
It took  506.01077127456665  seconds.

JOB STATISTICS
==============
Job ID: 2514690
Array Job ID: 2514679_11
Cluster: snellius
User/Group: nreints/nreints
State: COMPLETED (exit code 0)
Nodes: 1
Cores per node: 18
CPU Utilized: 03:29:25
CPU Efficiency: 67.31% of 05:11:06 core-walltime
Job Wall-clock time: 00:17:17
Memory Utilized: 24.86 GB
Memory Efficiency: 79.54% of 31.25 GB
