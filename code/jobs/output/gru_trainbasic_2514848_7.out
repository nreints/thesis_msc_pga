wandb: Currently logged in as: nreints. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230329_135637-p64ccfln
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lunar-meadow-539
wandb: â­ï¸ View project at https://wandb.ai/nreints/test
wandb: ðŸš€ View run at https://wandb.ai/nreints/test/runs/p64ccfln
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.031 MB of 0.031 MB uploaded (0.000 MB deduped)wandb: \ 0.031 MB of 0.078 MB uploaded (0.000 MB deduped)wandb: | 0.058 MB of 0.078 MB uploaded (0.000 MB deduped)wandb: / 0.058 MB of 0.078 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:                                                  Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb: Test loss t(0, 0)_r(5, 20)_semi_pNone_gNone, MSELoss() â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–
wandb:                                             Train loss â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                                  Epoch 9
wandb: Test loss t(0, 0)_r(5, 20)_semi_pNone_gNone, MSELoss() 0.22152
wandb:                                             Train loss 0.2679
wandb: 
wandb: ðŸš€ View run lunar-meadow-539 at: https://wandb.ai/nreints/test/runs/p64ccfln
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230329_135637-p64ccfln/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230329_140411-mnmj4zr5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run peachy-capybara-547
wandb: â­ï¸ View project at https://wandb.ai/nreints/test
wandb: ðŸš€ View run at https://wandb.ai/nreints/test/runs/mnmj4zr5
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                                  Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb: Test loss t(0, 0)_r(5, 20)_semi_pNone_gNone, MSELoss() â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–
wandb:                                             Train loss â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                                  Epoch 9
wandb: Test loss t(0, 0)_r(5, 20)_semi_pNone_gNone, MSELoss() 0.24812
wandb:                                             Train loss 0.25198
wandb: 
wandb: ðŸš€ View run peachy-capybara-547 at: https://wandb.ai/nreints/test/runs/mnmj4zr5
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230329_140411-mnmj4zr5/logs
Running for data type: pos_diff_start
----- ITERATION 1/2 ------
Number of train simulations: 1600
Number of test simulations: 400
-- Finished Train Dataloader --
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(24, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=24, bias=True)
)
-- Started Training --
Epoch 0
	 Logging train Loss: 261.0080106809 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss: 75.54920959472656 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
     --> Epoch time; 39.72319722175598
Epoch 1
	 Logging train Loss: 46.5098777537 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss: 20.26504898071289 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
     --> Epoch time; 37.20403790473938
Epoch 2
	 Logging train Loss: 15.0857797376 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss: 7.929245471954346 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
     --> Epoch time; 37.273136377334595
Epoch 3
	 Logging train Loss: 6.4595821773 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss: 3.732952117919922 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
     --> Epoch time; 37.30123782157898
Epoch 4
	 Logging train Loss: 3.1599958799 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss: 1.8885090351104736 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
     --> Epoch time; 37.846205949783325
Epoch 5
	 Logging train Loss: 1.6295097565 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss: 1.040155053138733 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
     --> Epoch time; 47.62893867492676
Epoch 6
	 Logging train Loss: 0.9267558568 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss: 0.6382500529289246 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
     --> Epoch time; 37.59040808677673
Epoch 7
	 Logging train Loss: 0.5699591643 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss: 0.4204272925853729 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
     --> Epoch time; 37.47526240348816
Epoch 8
	 Logging train Loss: 0.3781079851 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss: 0.2944642901420593 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
     --> Epoch time; 37.461421251297
Epoch 9
	 Logging train Loss: 0.2678956871 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss: 0.22079148888587952 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
     --> Epoch time; 37.37915372848511
	 Logging test loss: 0.22152400016784668 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
It took  454.5893795490265  seconds.
----- ITERATION 2/2 ------
Number of train simulations: 1600
Number of test simulations: 400
-- Finished Train Dataloader --
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(24, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=24, bias=True)
)
-- Started Training --
Epoch 0
	 Logging train Loss: 259.1346378505 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss: 83.96131134033203 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
     --> Epoch time; 38.559601068496704
Epoch 1
	 Logging train Loss: 45.7747934746 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss: 23.455617904663086 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
     --> Epoch time; 37.70588755607605
Epoch 2
	 Logging train Loss: 14.9991655541 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss: 9.425948143005371 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
     --> Epoch time; 37.65150737762451
Epoch 3
	 Logging train Loss: 6.461939487 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss: 4.483880996704102 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
     --> Epoch time; 37.263997077941895
Epoch 4
	 Logging train Loss: 3.1577960067 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss: 2.3480117321014404 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
     --> Epoch time; 37.54460573196411
Epoch 5
	 Logging train Loss: 1.6805093966 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss: 1.3032082319259644 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
     --> Epoch time; 37.75364875793457
Epoch 6
	 Logging train Loss: 0.9651298574 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss: 0.8025656938552856 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
     --> Epoch time; 37.55062294006348
Epoch 7
	 Logging train Loss: 0.5943365976 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss: 0.5098127126693726 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
     --> Epoch time; 37.67685794830322
Epoch 8
	 Logging train Loss: 0.3672622253 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss: 0.3467479348182678 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
     --> Epoch time; 37.926777601242065
Epoch 9
	 Logging train Loss: 0.2519799552 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss: 0.24857380986213684 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
     --> Epoch time; 37.61756730079651
	 Logging test loss: 0.24812209606170654 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
It took  440.6062455177307  seconds.

JOB STATISTICS
==============
Job ID: 2514855
Array Job ID: 2514848_7
Cluster: snellius
User/Group: nreints/nreints
State: COMPLETED (exit code 0)
Nodes: 1
Cores per node: 18
CPU Utilized: 02:55:36
CPU Efficiency: 64.39% of 04:32:42 core-walltime
Job Wall-clock time: 00:15:09
Memory Utilized: 28.22 GB
Memory Efficiency: 90.31% of 31.25 GB
