wandb: Currently logged in as: nreints. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_165343-qnsipnho
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run neat-dawn-746
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/qnsipnho
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue â–…â–‚â–‚â–ˆâ–â–â–â–„â–‚â–†
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue â–ˆâ–‚â–‚â–ƒâ–â–â–â–â–‚â–‚
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue â–„â–â–â–ˆâ–â–â–â–„â–â–†
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue â–„â–‚â–â–ˆâ–â–â–â–„â–â–†
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 1e-05
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 1e-05
wandb:                                 Train loss 0.0
wandb: 
wandb: ðŸš€ View run neat-dawn-746 at: https://wandb.ai/nreints/ThesisFinal2/runs/qnsipnho
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_165343-qnsipnho/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_170157-olewna0k
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run silvery-forest-772
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/olewna0k
Training on dataset: data_t(0,0)_r(0,0)_combi_pTrue_gTrue
Testing on 4 datasets: ['data_t(0,0)_r(0,0)_semi_pTrue_gTrue', 'data_t(0,0)_r(0,0)_full_pTrue_gTrue', 'data_t(0,0)_r(0,0)_combi_pTrue_gTrue', 'data_t(0,0)_r(0,0)_tennis_pTrue_gTrue']
Focussing on identity: False
Using extra input: False
Using fr-fr as reference point.
----- ITERATION 1/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 52.50949048995972 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 13.100028991699219 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 12.876393556594849 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 13.060625076293945 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 12.103012084960938 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(6, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=6, bias=True)
)
Datatype: log_dualQ_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0004475767 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 3.5525e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 3.0271e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 3.1841e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 4.0076e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 38.9170286655426
Epoch 1/9
	 Logging train Loss: 1.4173e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 7.219e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 5.193e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 6.234e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 8.19e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 37.62974286079407
Epoch 2/9
	 Logging train Loss: 6.227e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 5.658e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 4.413e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 4.942e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 6.28e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 37.36259698867798
Epoch 3/9
	 Logging train Loss: 6.143e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 8.6603e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 1.0227e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 5.0966e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 9.4145e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 37.42825436592102
Epoch 4/9
	 Logging train Loss: 1.6427e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.735e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 2.049e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 2.337e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 3.064e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 37.54037141799927
Epoch 5/9
	 Logging train Loss: 1.6846e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.893e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 1.265e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 1.593e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.129e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 37.44684314727783
Epoch 6/9
	 Logging train Loss: 1.5834e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.19e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 7.01e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 9.82e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.341e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 37.68654417991638
Epoch 7/9
	 Logging train Loss: 6.88e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 4.2249e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 2.283e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 2.31e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 4.6389e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 37.53575253486633
Epoch 8/9
	 Logging train Loss: 1.2611e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 6.264e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 4.684e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 5.573e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 6.545e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 37.52081227302551
Epoch 9/9
	 Logging train Loss: 1.0722e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 6.2297e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 5.434e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 3.6318e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 7.303e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 37.58921813964844
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pTrue_gTrue/'log_dualQ_1'_'False'.pth
It took  495.19031834602356  seconds.
----- ITERATION 2/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 46.99683952331543 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 11.992307901382446 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 12.001476287841797 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 11.825177431106567 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 12.000610589981079 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(6, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=6, bias=True)
)
Datatype: log_dualQ_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0002811692 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.826e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 2.2104e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 2.4494e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 3.6636e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 37.87014579772949
Epoch 1/9
	 Logging train Loss: 1.1317e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 6.521e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 4.582e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 5.532e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 8.286e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 37.7873694896698
Epoch 2/9
	 Logging train Loss: 9.076e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 5.02e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 3.749e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 4.274e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 6.262e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 37.64822340011597
Epoch 3/9
	 Logging train Loss: 1.1517e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 4.006e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 2.978e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 3.374e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 4.942e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 37.76795029640198
Epoch 4/9
	 Logging train Loss: 1.8394e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.913e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
wandb: Waiting for W&B process to finish... (success).
wandb: ERROR Error while calling W&B API: An internal error occurred. Please contact support. (<Response [500]>)
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue â–ˆâ–‚â–‚â–‚â–‚â–â–â–â–‚â–
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue â–ˆâ–‚â–‚â–‚â–‚â–â–â–â–â–
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue â–ˆâ–‚â–‚â–‚â–‚â–â–â–â–‚â–
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue â–ˆâ–‚â–‚â–‚â–‚â–â–â–â–‚â–
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.0
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.0
wandb:                                 Train loss 0.0
wandb: 
wandb: ðŸš€ View run silvery-forest-772 at: https://wandb.ai/nreints/ThesisFinal2/runs/olewna0k
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_170157-olewna0k/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_171004-lo1as2yq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vocal-vortex-792
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/lo1as2yq
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue â–ˆâ–ƒâ–â–‚â–â–‚â–‚â–‚â–â–
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue â–ˆâ–ƒâ–â–â–â–â–â–â–â–
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue â–ˆâ–ƒâ–â–‚â–â–‚â–ƒâ–ƒâ–â–
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue â–ˆâ–ƒâ–â–‚â–â–‚â–ƒâ–ƒâ–â–
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.0
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.0
wandb:                                 Train loss 0.0
wandb: 
wandb: ðŸš€ View run vocal-vortex-792 at: https://wandb.ai/nreints/ThesisFinal2/runs/lo1as2yq
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_171004-lo1as2yq/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_171805-9iu0ggjt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dashing-dust-810
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/9iu0ggjt
	 Logging test loss: 2.082e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 2.466e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 3.619e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 37.668981075286865
Epoch 5/9
	 Logging train Loss: 1.5341e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.092e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 1.351e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 1.705e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.544e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 37.60256338119507
Epoch 6/9
	 Logging train Loss: 1.3413e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.379e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 7.16e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 1.081e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.644e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 37.804224491119385
Epoch 7/9
	 Logging train Loss: 1.2231e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.473e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 4.59e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 1.046e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.734e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 38.08942794799805
Epoch 8/9
	 Logging train Loss: 1.1749e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 5.047e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 4.67e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 3.243e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 5.507e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 37.4444420337677
Epoch 9/9
	 Logging train Loss: 1.0173e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 6.49e-08 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 2.32e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 4.77e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 7.3e-08 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 37.342188358306885
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pTrue_gTrue/'log_dualQ_1'_'False'.pth
It took  487.05809354782104  seconds.
----- ITERATION 3/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 44.91702198982239 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 11.817174434661865 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 11.808098554611206 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 11.219966411590576 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 11.80018162727356 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(6, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=6, bias=True)
)
Datatype: log_dualQ_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0005240962 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.05626e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 6.0044e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 9.533e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.08197e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 37.76390552520752
Epoch 1/9
	 Logging train Loss: 3.5543e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.4098e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 1.3537e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 2.1406e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.4629e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 37.924922466278076
Epoch 2/9
	 Logging train Loss: 9.995e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 8.49e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 4.46e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 7.346e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 8.768e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 37.62823128700256
Epoch 3/9
	 Logging train Loss: 8.078e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.3166e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 3.844e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 8.965e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.3616e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 37.677451848983765
Epoch 4/9
	 Logging train Loss: 1.3379e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 5.619e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 2.949e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 4.836e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 5.81e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 37.48925995826721
Epoch 5/9
	 Logging train Loss: 1.1406e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.8677e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 3.565e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 1.1265e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.9689e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 37.75898051261902
Epoch 6/9
	 Logging train Loss: 1.3774e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 3.1396e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 4.555e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 1.7728e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 3.2415e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 37.65459442138672
Epoch 7/9
	 Logging train Loss: 1.4317e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.6636e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 4.428e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 1.505e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.7742e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 37.89811873435974
Epoch 8/9
	 Logging train Loss: 1.1383e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.542e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 6.98e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 1.231e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.642e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 37.81726384162903
Epoch 9/9
	 Logging train Loss: 1.0274e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.912e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 6.13e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 1.311e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.005e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 37.7664430141449
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pTrue_gTrue/'log_dualQ_1'_'False'.pth
It took  480.97787404060364  seconds.
----- ITERATION 4/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 44.9276647567749 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 11.791577816009521 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 11.804229021072388 seconds.
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue â–ˆâ–‚â–‚â–â–‚â–‚â–â–â–ƒâ–
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue â–ˆâ–‚â–‚â–â–â–â–â–â–â–
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue â–ˆâ–‚â–‚â–â–‚â–‚â–â–â–ƒâ–
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue â–ˆâ–‚â–‚â–â–‚â–‚â–â–â–„â–
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.0
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.0
wandb:                                 Train loss 0.0
wandb: 
wandb: ðŸš€ View run dashing-dust-810 at: https://wandb.ai/nreints/ThesisFinal2/runs/9iu0ggjt
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_171805-9iu0ggjt/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_172600-qzq34qg7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rare-sponge-824
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/qzq34qg7
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 11.39319372177124 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 11.867294311523438 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(6, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=6, bias=True)
)
Datatype: log_dualQ_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.000523726 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 4.7778e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 3.3923e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 3.2415e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 4.1726e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 36.989824056625366
Epoch 1/9
	 Logging train Loss: 1.4814e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 7.227e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 4.475e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 4.897e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 6.857e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 36.70485973358154
Epoch 2/9
	 Logging train Loss: 4.67e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 5.695e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 3.355e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 3.771e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 5.28e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 36.941468238830566
Epoch 3/9
	 Logging train Loss: 6.456e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 4.074e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 2.609e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 2.741e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 3.685e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 37.057244300842285
Epoch 4/9
	 Logging train Loss: 7.682e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 4.946e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 2.006e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 3.168e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 4.976e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 36.80861496925354
Epoch 5/9
	 Logging train Loss: 9.867e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 6.485e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 1.507e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 3.89e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 6.459e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 37.02193474769592
Epoch 6/9
	 Logging train Loss: 1.2157e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.825e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 8.3e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 1.235e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.886e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 37.13316988945007
Epoch 7/9
	 Logging train Loss: 1.4364e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.274e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 6.9e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 9.61e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.376e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 37.081191062927246
Epoch 8/9
	 Logging train Loss: 1.167e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.6963e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 8.45e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 9.235e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.7122e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 37.06977462768555
Epoch 9/9
	 Logging train Loss: 1.0145e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 9.83e-08 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 3.16e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 6.67e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.112e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 36.84213161468506
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pTrue_gTrue/'log_dualQ_1'_'False'.pth
It took  474.9028227329254  seconds.
----- ITERATION 5/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 45.15403747558594 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 11.858030796051025 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 11.796555757522583 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 11.473159551620483 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 11.812250137329102 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(6, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=6, bias=True)
)
Datatype: log_dualQ_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0001911908 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.7205e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 1.5495e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 1.9261e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.1543e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 37.0220685005188
Epoch 1/9
	 Logging train Loss: 7.726e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 6.87e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 3.912e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 4.726e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 5.555e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 36.76045775413513
Epoch 2/9
	 Logging train Loss: 7.503e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 5.255e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 3.11e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 3.616e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 4.29e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 36.79973006248474
Epoch 3/9
	 Logging train Loss: 1.0692e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 4.004e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 2.24e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 2.766e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 3.317e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 36.652095556259155
Epoch 4/9
	 Logging train Loss: 1.2596e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.943e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 1.54e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 1.998e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.498e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 36.95900106430054
Epoch 5/9
	 Logging train Loss: 9.568e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.8562e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 2.294e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 1.5465e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 3.1356e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 36.94674205780029
Epoch 6/9
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue â–ˆâ–ƒâ–‚â–‚â–‚â–‡â–ƒâ–â–ƒâ–
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue â–ˆâ–ƒâ–‚â–‚â–‚â–‚â–‚â–â–‚â–
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue â–ˆâ–ƒâ–‚â–‚â–‚â–ˆâ–ƒâ–â–ƒâ–
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue â–†â–‚â–‚â–‚â–â–ˆâ–ƒâ–â–ƒâ–
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.0
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.0
wandb:                                 Train loss 0.0
wandb: 
wandb: ðŸš€ View run rare-sponge-824 at: https://wandb.ai/nreints/ThesisFinal2/runs/qzq34qg7
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_172600-qzq34qg7/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_173354-mpob3xn2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run giddy-gorge-848
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/mpob3xn2
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue â–ˆâ–‚â–‡â–â–â–â–ƒâ–â–ƒâ–
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue â–ˆâ–‚â–‚â–â–â–â–â–â–‚â–
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue â–‡â–‚â–ˆâ–â–â–â–ƒâ–â–ƒâ–
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue â–†â–‚â–ˆâ–â–â–â–ƒâ–â–ƒâ–
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.0
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.0
wandb:                                 Train loss 0.0
wandb: 
wandb: ðŸš€ View run giddy-gorge-848 at: https://wandb.ai/nreints/ThesisFinal2/runs/mpob3xn2
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_173354-mpob3xn2/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_174147-ya8qhwtq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vibrant-fog-869
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/ya8qhwtq
	 Logging train Loss: 1.2989e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.0468e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 3.295e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 6.838e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.0949e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 36.93048930168152
Epoch 7/9
	 Logging train Loss: 1.4022e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.008e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 3.63e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 6.66e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 9.57e-08 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 36.84028768539429
Epoch 8/9
	 Logging train Loss: 5.398e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 8.789e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 3.437e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 6.156e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 8.941e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 36.883445739746094
Epoch 9/9
	 Logging train Loss: 9.878e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 6.84e-08 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 2.48e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 4.58e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 6.61e-08 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 36.86799192428589
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pTrue_gTrue/'log_dualQ_1'_'False'.pth
It took  474.03436398506165  seconds.
----- ITERATION 6/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 44.92794322967529 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 11.768032789230347 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 11.772632837295532 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 11.474961757659912 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 11.833645105361938 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(6, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=6, bias=True)
)
Datatype: log_dualQ_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0005211496 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 6.3939e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 4.678e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 5.1295e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 5.9475e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 36.75211477279663
Epoch 1/9
	 Logging train Loss: 2.3653e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.1698e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 7.943e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 9.596e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.1495e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 36.98608136177063
Epoch 2/9
	 Logging train Loss: 6.857e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 7.6375e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 6.796e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 4.5327e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 8.3922e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 36.86400389671326
Epoch 3/9
	 Logging train Loss: 1.2524e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 5.358e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 3.468e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 4.077e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 4.883e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 36.86152148246765
Epoch 4/9
	 Logging train Loss: 6.312e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 4.255e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 2.74e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 3.219e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 3.881e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 36.955859422683716
Epoch 5/9
	 Logging train Loss: 1.0603e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 3.325e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 1.987e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 2.454e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 3.05e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 37.431655406951904
Epoch 6/9
	 Logging train Loss: 1.1738e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.4484e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 1.923e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 1.4921e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.5966e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 36.909056663513184
Epoch 7/9
	 Logging train Loss: 1.2377e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.579e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 6.66e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 1.094e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.556e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 36.766231536865234
Epoch 8/9
	 Logging train Loss: 1.25e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.4252e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 6.322e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 1.6162e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.6361e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 37.14369201660156
Epoch 9/9
	 Logging train Loss: 6.82e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.072e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 3.63e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 7.44e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.169e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 37.059149980545044
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pTrue_gTrue/'log_dualQ_1'_'False'.pth
It took  473.0007293224335  seconds.
----- ITERATION 7/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 45.065574645996094 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 11.716029405593872 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 11.684714794158936 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 11.529923677444458 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 11.871662378311157 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(6, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=6, bias=True)
)
Datatype: log_dualQ_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0001267229 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.3712e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 7.42e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 8.478e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue â–‚â–‚â–â–ˆâ–â–â–â–â–‚â–
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue â–ˆâ–„â–ƒâ–†â–‚â–â–â–â–ƒâ–
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue â–‚â–â–â–ˆâ–â–â–â–â–‚â–
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue â–‚â–â–â–ˆâ–â–â–â–â–‚â–
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.0
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.0
wandb:                                 Train loss 0.0
wandb: 
wandb: ðŸš€ View run vibrant-fog-869 at: https://wandb.ai/nreints/ThesisFinal2/runs/ya8qhwtq
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_174147-ya8qhwtq/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_174941-xpzfh6a4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stilted-butterfly-885
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/xpzfh6a4
	 Logging test loss: 9.988e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 36.513834953308105
Epoch 1/9
	 Logging train Loss: 8.273e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 5.977e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 3.568e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 3.846e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 4.467e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 37.01288366317749
Epoch 2/9
	 Logging train Loss: 1.4468e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 4.567e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 2.778e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 2.952e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 3.463e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 36.961225748062134
Epoch 3/9
	 Logging train Loss: 1.4219e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 7.3453e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 5.606e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 3.9761e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 8.6229e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 36.69484066963196
Epoch 4/9
	 Logging train Loss: 1.7601e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 5.17e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 1.602e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 3.123e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 5.175e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 36.88597583770752
Epoch 5/9
	 Logging train Loss: 1.3929e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.562e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 7.27e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 9.72e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.328e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 36.94442915916443
Epoch 6/9
	 Logging train Loss: 9.858e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 5.604e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 6.22e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 3.079e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 6.225e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 36.844836473464966
Epoch 7/9
	 Logging train Loss: 1.1568e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.185e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 2.69e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 6.9e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.196e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 37.10814642906189
Epoch 8/9
	 Logging train Loss: 8.189e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 6.755e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 1.946e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 4.331e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 7.347e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 37.0074462890625
Epoch 9/9
	 Logging train Loss: 9.33e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.691e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 2.91e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 9.61e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.826e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 36.826531171798706
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pTrue_gTrue/'log_dualQ_1'_'False'.pth
It took  474.09204483032227  seconds.
----- ITERATION 8/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 44.99666118621826 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 11.652930974960327 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 11.658152341842651 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 11.488489866256714 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 11.663323879241943 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(6, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=6, bias=True)
)
Datatype: log_dualQ_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0001872017 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.4353e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 7.631e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 1.0355e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.6448e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 36.95388054847717
Epoch 1/9
	 Logging train Loss: 7.296e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 7.664e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 4.784e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 5.78e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 8.479e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 36.93516278266907
Epoch 2/9
	 Logging train Loss: 1.0629e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.38018e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 1.4033e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 7.7572e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.44772e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 36.613574743270874
Epoch 3/9
	 Logging train Loss: 1.1883e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 8.40431e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 3.6983e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 4.52628e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 8.99129e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 36.80098366737366
Epoch 4/9
	 Logging train Loss: 1.3039e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.467e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 1.488e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 1.805e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.729e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 36.87287163734436
Epoch 5/9
	 Logging train Loss: 1.4571e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.8614e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 5.798e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 1.2259e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.9516e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 37.09864783287048
Epoch 6/9
	 Logging train Loss: 8.763e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 5.19e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 2.669e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 3.901e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 5.604e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 36.86863160133362
Epoch 7/9
	 Logging train Loss: 1.016e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.281e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 4.8e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 8.73e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.471e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue â–â–â–‚â–ˆâ–â–â–â–â–â–
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue â–‚â–‚â–„â–ˆâ–â–‚â–â–â–â–
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue â–â–â–‚â–ˆâ–â–â–â–â–â–
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue â–â–â–‚â–ˆâ–â–â–â–â–â–
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.0
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.0
wandb:                                 Train loss 0.0
wandb: 
wandb: ðŸš€ View run stilted-butterfly-885 at: https://wandb.ai/nreints/ThesisFinal2/runs/xpzfh6a4
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_174941-xpzfh6a4/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_175734-uprmdlen
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fiery-wood-910
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/uprmdlen
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue â–‡â–‚â–‚â–â–„â–ˆâ–â–‚â–â–
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue â–ˆâ–‚â–‚â–‚â–‚â–ƒâ–â–â–â–
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue â–…â–‚â–â–â–„â–ˆâ–â–‚â–â–
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue â–…â–‚â–â–â–„â–ˆâ–â–‚â–â–
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.0
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.0
wandb:                                 Train loss 0.0
wandb: 
wandb: ðŸš€ View run fiery-wood-910 at: https://wandb.ai/nreints/ThesisFinal2/runs/uprmdlen
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_175734-uprmdlen/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_180526-eigst93p
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run silver-haze-931
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/eigst93p
		--> Epoch time; 36.77964806556702
Epoch 8/9
	 Logging train Loss: 8.234e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 4.536e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 9.88e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 2.83e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 5.117e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 36.84345364570618
Epoch 9/9
	 Logging train Loss: 9.223e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 4.001e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 4.66e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 2.335e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 4.455e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 36.718037366867065
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pTrue_gTrue/'log_dualQ_1'_'False'.pth
It took  473.0657842159271  seconds.
----- ITERATION 9/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 45.000380754470825 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 11.66019582748413 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 11.672073364257812 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 11.506880760192871 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 11.761322498321533 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(6, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=6, bias=True)
)
Datatype: log_dualQ_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0006078252 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 7.2633e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 3.9405e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 6.2263e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 7.3471e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 36.7474308013916
Epoch 1/9
	 Logging train Loss: 1.8676e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.1981e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 6.088e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 1.0021e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.2256e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 36.912697553634644
Epoch 2/9
	 Logging train Loss: 5.317e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 7.969e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 4.217e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 6.72e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 8.055e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 36.681456089019775
Epoch 3/9
	 Logging train Loss: 4.19e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 6.422e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 3.459e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 5.396e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 6.452e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 36.983322858810425
Epoch 4/9
	 Logging train Loss: 1.2019e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 5.182e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 4.545e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 3.4122e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 5.6756e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 36.85920763015747
Epoch 5/9
	 Logging train Loss: 9.437e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.2223e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 1.1932e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 7.3204e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.30088e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 36.87283205986023
Epoch 6/9
	 Logging train Loss: 1.5183e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 6.875e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 2.836e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 5.168e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 6.956e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 36.64162063598633
Epoch 7/9
	 Logging train Loss: 1.7514e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.1605e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 1.536e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 7.397e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.2556e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 36.97164726257324
Epoch 8/9
	 Logging train Loss: 9.124e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.384e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 6.31e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 1.119e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.423e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 36.883930683135986
Epoch 9/9
	 Logging train Loss: 1.4403e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.016e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 4.35e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 8.15e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.075e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 36.67490005493164
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pTrue_gTrue/'log_dualQ_1'_'False'.pth
It took  472.0210955142975  seconds.
----- ITERATION 10/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 45.14518904685974 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 11.649162292480469 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 11.677951574325562 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 11.489461183547974 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 11.718942642211914 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(6, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=6, bias=True)
)
Datatype: log_dualQ_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0006179608 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 6.3413e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 3.8344e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 3.3222e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 7.3517e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 36.51152181625366
Epoch 1/9
	 Logging train Loss: 1.9618e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 9.476e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 5.479e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 5.231e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.138e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 37.039347648620605
Epoch 2/9
	 Logging train Loss: 5.664e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 6.726e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 4.029e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 3.719e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue â–ˆâ–‚â–‚â–â–â–â–ƒâ–â–‚â–
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue â–ˆâ–‚â–‚â–‚â–â–â–â–â–â–
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue â–ˆâ–‚â–‚â–â–â–â–ƒâ–â–â–
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue â–ˆâ–‚â–‚â–â–â–â–ƒâ–â–â–
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.0
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.0
wandb:                                 Train loss 0.0
wandb: 
wandb: ðŸš€ View run silver-haze-931 at: https://wandb.ai/nreints/ThesisFinal2/runs/eigst93p
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_180526-eigst93p/logs
	 Logging test loss: 7.766e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 36.81001901626587
Epoch 3/9
	 Logging train Loss: 4.43e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 5.329e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 3.166e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 2.948e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 6.115e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 37.03442025184631
Epoch 4/9
	 Logging train Loss: 9.28e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 3.942e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 2.28e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 2.199e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 4.56e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 37.137922286987305
Epoch 5/9
	 Logging train Loss: 1.1147e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.715e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 1.533e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 1.542e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 3.182e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 37.18530082702637
Epoch 6/9
	 Logging train Loss: 1.1835e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.0494e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 1.417e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 1.0257e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.1322e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 37.15350294113159
Epoch 7/9
	 Logging train Loss: 9.051e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 4.065e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 8.8e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 2.282e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 4.455e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 36.922672510147095
Epoch 8/9
	 Logging train Loss: 1.0558e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 4.642e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 2.309e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 3.438e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 5.099e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 36.9929473400116
Epoch 9/9
	 Logging train Loss: 1.1033e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.164e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 3.07e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 7.11e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.431e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 36.73829793930054
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pTrue_gTrue/'log_dualQ_1'_'False'.pth
It took  474.07535552978516  seconds.

JOB STATISTICS
==============
Job ID: 3037735
Array Job ID: 3037727_36
Cluster: snellius
User/Group: nreints/nreints
State: RUNNING
Nodes: 1
Cores per node: 18
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 23:58:30 core-walltime
Job Wall-clock time: 01:19:55
Memory Utilized: 0.00 MB (estimated maximum)
Memory Efficiency: 0.00% of 0.00 MB (0.00 MB/node)
WARNING: Efficiency statistics may be misleading for RUNNING jobs.
