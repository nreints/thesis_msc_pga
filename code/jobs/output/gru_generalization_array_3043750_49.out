wandb: Currently logged in as: nreints. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230710_170035-729l9g02
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run twilight-spaceship-1256
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/729l9g02
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                     Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb: Test loss tennis_pNone_gNone_tennisEffect â–ˆâ–†â–ƒâ–‚â–â–â–â–â–‚â–
wandb:                                Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                     Epoch 9
wandb: Test loss tennis_pNone_gNone_tennisEffect 1e-05
wandb:                                Train loss 1e-05
wandb: 
wandb: ðŸš€ View run twilight-spaceship-1256 at: https://wandb.ai/nreints/ThesisFinal2/runs/729l9g02
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230710_170035-729l9g02/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230710_170655-smoowf8w
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sparkling-dawn-1267
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/smoowf8w
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                     Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb: Test loss tennis_pNone_gNone_tennisEffect â–ˆâ–†â–„â–‚â–‚â–â–â–â–â–
wandb:                                Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                     Epoch 9
wandb: Test loss tennis_pNone_gNone_tennisEffect 1e-05
wandb:                                Train loss 1e-05
wandb: 
wandb: ðŸš€ View run sparkling-dawn-1267 at: https://wandb.ai/nreints/ThesisFinal2/runs/smoowf8w
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230710_170655-smoowf8w/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230710_171311-ilez78az
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run morning-sun-1279
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/ilez78az
Training on dataset: data_tennis_pNone_gNone_tennisEffect
Testing on 1 datasets: ['data_tennis_pNone_gNone_tennisEffect']
Focussing on identity: True
Using extra input: True
Using fr-fr as reference point.
----- ITERATION 1/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 59.90139842033386 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 15.00715446472168 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (pre_hidden_lin_layer): Sequential(
    (0): Linear(in_features=3, out_features=96, bias=True)
    (1): ReLU()
    (2): Linear(in_features=96, out_features=96, bias=True)
    (3): ReLU()
  )
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0013719682 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 4.63652e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 29.099514961242676
Epoch 1/9
	 Logging train Loss: 4.02012e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 3.37805e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 29.208925485610962
Epoch 2/9
	 Logging train Loss: 2.74324e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.1387e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 28.856995105743408
Epoch 3/9
	 Logging train Loss: 1.79924e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.35756e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 29.07087469100952
Epoch 4/9
	 Logging train Loss: 1.43003e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.02517e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 28.977473735809326
Epoch 5/9
	 Logging train Loss: 1.26881e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 9.212e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 28.840723514556885
Epoch 6/9
	 Logging train Loss: 1.12762e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 9.4402e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 29.231086254119873
Epoch 7/9
	 Logging train Loss: 1.04824e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 8.7824e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 28.88999891281128
Epoch 8/9
	 Logging train Loss: 1.00039e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.25645e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 29.61019492149353
Epoch 9/9
	 Logging train Loss: 9.5972e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 9.1896e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 29.819215059280396
Saved model in  trained_models/gru/data_tennis_pNone_gNone_tennisEffect/'rot_mat_1'_'True'.pth
It took  381.55631709098816  seconds.
----- ITERATION 2/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 57.55837082862854 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 14.388126134872437 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (pre_hidden_lin_layer): Sequential(
    (0): Linear(in_features=3, out_features=96, bias=True)
    (1): ReLU()
    (2): Linear(in_features=96, out_features=96, bias=True)
    (3): ReLU()
  )
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0012799212 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 5.6146e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 28.825534105300903
Epoch 1/9
	 Logging train Loss: 4.41869e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 4.11945e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 28.683526754379272
Epoch 2/9
	 Logging train Loss: 2.97281e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 3.22033e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 29.022276639938354
Epoch 3/9
	 Logging train Loss: 1.9309e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.46208e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 29.430278301239014
Epoch 4/9
	 Logging train Loss: 1.44032e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.79016e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 29.57653832435608
Epoch 5/9
	 Logging train Loss: 1.26853e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.12081e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 29.52352023124695
Epoch 6/9
	 Logging train Loss: 1.13131e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.18116e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 29.702247142791748
Epoch 7/9
	 Logging train Loss: 1.06773e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.07307e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 29.5774085521698
Epoch 8/9
	 Logging train Loss: 9.9012e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 9.1734e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 29.44538450241089
Epoch 9/9
	 Logging train Loss: 9.5924e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 8.9272e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 29.701392889022827
Saved model in  trained_models/gru/data_tennis_pNone_gNone_tennisEffect/'rot_mat_1'_'True'.pth
It took  376.0385172367096  seconds.
----- ITERATION 3/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 57.46374702453613 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 14.36564588546753 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (pre_hidden_lin_layer): Sequential(
    (0): Linear(in_features=3, out_features=96, bias=True)
    (1): ReLU()
    (2): Linear(in_features=96, out_features=96, bias=True)
    (3): ReLU()
  )
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0009823531 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 4.74314e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 29.32591700553894
Epoch 1/9
	 Logging train Loss: 3.98062e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 4.07048e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 29.068779468536377
Epoch 2/9
	 Logging train Loss: 2.54304e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.72356e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 29.29612946510315
Epoch 3/9
	 Logging train Loss: 1.58539e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.11524e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 29.49805521965027
Epoch 4/9
	 Logging train Loss: 1.28917e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.15592e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 29.52134895324707
Epoch 5/9
	 Logging train Loss: 1.13899e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.06649e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 29.52970814704895
Epoch 6/9
	 Logging train Loss: 1.06656e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.17411e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 29.487496614456177
Epoch 7/9
	 Logging train Loss: 9.8986e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 9.3739e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                     Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb: Test loss tennis_pNone_gNone_tennisEffect â–ˆâ–‡â–ƒâ–â–â–â–ƒâ–â–â–
wandb:                                Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                     Epoch 9
wandb: Test loss tennis_pNone_gNone_tennisEffect 1e-05
wandb:                                Train loss 1e-05
wandb: 
wandb: ðŸš€ View run morning-sun-1279 at: https://wandb.ai/nreints/ThesisFinal2/runs/ilez78az
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230710_171311-ilez78az/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230710_171930-jczsh24s
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run graceful-cosmos-1296
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/jczsh24s
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                     Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb: Test loss tennis_pNone_gNone_tennisEffect â–ˆâ–‡â–ƒâ–â–ƒâ–‚â–â–â–â–
wandb:                                Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                     Epoch 9
wandb: Test loss tennis_pNone_gNone_tennisEffect 1e-05
wandb:                                Train loss 1e-05
wandb: 
wandb: ðŸš€ View run graceful-cosmos-1296 at: https://wandb.ai/nreints/ThesisFinal2/runs/jczsh24s
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230710_171930-jczsh24s/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230710_172551-dpqc9mw8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run jolly-pine-1312
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/dpqc9mw8
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                     Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb: Test loss tennis_pNone_gNone_tennisEffect â–ˆâ–‡â–…â–‚â–â–â–‚â–â–â–
wandb:                                Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                     Epoch 9
wandb: Test loss tennis_pNone_gNone_tennisEffect 1e-05
wandb:                                Train loss 1e-05
wandb: 
wandb: ðŸš€ View run jolly-pine-1312 at: https://wandb.ai/nreints/ThesisFinal2/runs/dpqc9mw8
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230710_172551-dpqc9mw8/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230710_173207-blhbn9ml
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run logical-deluge-1328
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/blhbn9ml
		--> Epoch time; 29.673280000686646
Epoch 8/9
	 Logging train Loss: 9.5821e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 8.9271e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 29.66870927810669
Epoch 9/9
	 Logging train Loss: 9.1446e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 9.4994e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 30.02178931236267
Saved model in  trained_models/gru/data_tennis_pNone_gNone_tennisEffect/'rot_mat_1'_'True'.pth
It took  378.62818789482117  seconds.
----- ITERATION 4/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 57.4970223903656 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 14.361384153366089 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (pre_hidden_lin_layer): Sequential(
    (0): Linear(in_features=3, out_features=96, bias=True)
    (1): ReLU()
    (2): Linear(in_features=96, out_features=96, bias=True)
    (3): ReLU()
  )
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0011003813 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 6.60647e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 29.275699138641357
Epoch 1/9
	 Logging train Loss: 4.59467e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 5.43295e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 29.534756183624268
Epoch 2/9
	 Logging train Loss: 2.97826e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.20875e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 30.35032820701599
Epoch 3/9
	 Logging train Loss: 1.9268e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.13368e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 30.284575700759888
Epoch 4/9
	 Logging train Loss: 1.42481e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.17238e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 29.799835205078125
Epoch 5/9
	 Logging train Loss: 1.16724e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.29133e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 29.843910217285156
Epoch 6/9
	 Logging train Loss: 1.09846e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.00202e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 29.730244636535645
Epoch 7/9
	 Logging train Loss: 1.0306e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 8.4996e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 29.508628129959106
Epoch 8/9
	 Logging train Loss: 9.5328e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 8.6243e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 29.729594230651855
Epoch 9/9
	 Logging train Loss: 9.3431e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 8.9378e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 29.37888264656067
Saved model in  trained_models/gru/data_tennis_pNone_gNone_tennisEffect/'rot_mat_1'_'True'.pth
It took  381.4074776172638  seconds.
----- ITERATION 5/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 57.56003522872925 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 14.416392087936401 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (pre_hidden_lin_layer): Sequential(
    (0): Linear(in_features=3, out_features=96, bias=True)
    (1): ReLU()
    (2): Linear(in_features=96, out_features=96, bias=True)
    (3): ReLU()
  )
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.001015282 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 4.60312e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 28.750954389572144
Epoch 1/9
	 Logging train Loss: 3.95338e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 4.28758e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 28.578359127044678
Epoch 2/9
	 Logging train Loss: 2.574e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 3.03951e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 29.004672527313232
Epoch 3/9
	 Logging train Loss: 1.69209e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.33838e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 28.961103677749634
Epoch 4/9
	 Logging train Loss: 1.3855e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 9.7679e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 29.209486484527588
Epoch 5/9
	 Logging train Loss: 1.16953e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 8.7249e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 29.33784556388855
Epoch 6/9
	 Logging train Loss: 1.12036e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.13474e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 29.492235898971558
Epoch 7/9
	 Logging train Loss: 1.00858e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 9.629e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 29.131490230560303
Epoch 8/9
	 Logging train Loss: 9.6246e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 8.1829e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 29.42676281929016
Epoch 9/9
	 Logging train Loss: 9.4304e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 8.0334e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 29.06141424179077
Saved model in  trained_models/gru/data_tennis_pNone_gNone_tennisEffect/'rot_mat_1'_'True'.pth
It took  376.0637276172638  seconds.
----- ITERATION 6/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 57.488911390304565 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 14.372333526611328 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (pre_hidden_lin_layer): Sequential(
    (0): Linear(in_features=3, out_features=96, bias=True)
    (1): ReLU()
    (2): Linear(in_features=96, out_features=96, bias=True)
    (3): ReLU()
  )
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0010492217 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 4.91434e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 29.60045289993286
Epoch 1/9
	 Logging train Loss: 4.12327e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 3.59081e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 29.485809087753296
Epoch 2/9
	 Logging train Loss: 2.53323e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.14569e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 29.30284810066223
Epoch 3/9
	 Logging train Loss: 1.67826e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.95057e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 29.53448510169983
Epoch 4/9
	 Logging train Loss: 1.36204e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.05506e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 29.342849493026733
Epoch 5/9
	 Logging train Loss: 1.1517e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.06222e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 29.508033275604248
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                     Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb: Test loss tennis_pNone_gNone_tennisEffect â–ˆâ–†â–ƒâ–ƒâ–â–â–‚â–â–â–
wandb:                                Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                     Epoch 9
wandb: Test loss tennis_pNone_gNone_tennisEffect 1e-05
wandb:                                Train loss 1e-05
wandb: 
wandb: ðŸš€ View run logical-deluge-1328 at: https://wandb.ai/nreints/ThesisFinal2/runs/blhbn9ml
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230710_173207-blhbn9ml/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230710_173826-pdwx3lqd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run earthy-sunset-1344
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/pdwx3lqd
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                     Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb: Test loss tennis_pNone_gNone_tennisEffect â–ˆâ–ƒâ–‚â–‚â–â–‚â–‚â–â–â–
wandb:                                Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                     Epoch 9
wandb: Test loss tennis_pNone_gNone_tennisEffect 1e-05
wandb:                                Train loss 1e-05
wandb: 
wandb: ðŸš€ View run earthy-sunset-1344 at: https://wandb.ai/nreints/ThesisFinal2/runs/pdwx3lqd
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230710_173826-pdwx3lqd/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230710_174442-rhun8039
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run iconic-haze-1360
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/rhun8039
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                     Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb: Test loss tennis_pNone_gNone_tennisEffect â–ˆâ–†â–‚â–…â–â–‚â–â–â–â–
wandb:                                Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                     Epoch 9
wandb: Test loss tennis_pNone_gNone_tennisEffect 1e-05
wandb:                                Train loss 1e-05
wandb: 
wandb: ðŸš€ View run iconic-haze-1360 at: https://wandb.ai/nreints/ThesisFinal2/runs/rhun8039
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230710_174442-rhun8039/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230710_175100-5nnx36c3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run crisp-dragon-1367
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/5nnx36c3
Epoch 6/9
	 Logging train Loss: 1.06053e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.13437e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 29.10717487335205
Epoch 7/9
	 Logging train Loss: 9.9975e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 8.4932e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 29.155460596084595
Epoch 8/9
	 Logging train Loss: 9.5378e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 8.322e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 29.20580554008484
Epoch 9/9
	 Logging train Loss: 9.159e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 9.5374e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 29.64547610282898
Saved model in  trained_models/gru/data_tennis_pNone_gNone_tennisEffect/'rot_mat_1'_'True'.pth
It took  378.4249186515808  seconds.
----- ITERATION 7/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 57.37894082069397 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 14.292607545852661 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (pre_hidden_lin_layer): Sequential(
    (0): Linear(in_features=3, out_features=96, bias=True)
    (1): ReLU()
    (2): Linear(in_features=96, out_features=96, bias=True)
    (3): ReLU()
  )
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.001102798 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 7.27371e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 29.22810196876526
Epoch 1/9
	 Logging train Loss: 4.035e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.81564e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 29.658039331436157
Epoch 2/9
	 Logging train Loss: 2.4878e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.56053e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 29.436050176620483
Epoch 3/9
	 Logging train Loss: 1.68819e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.66306e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 29.75407648086548
Epoch 4/9
	 Logging train Loss: 1.35432e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 9.5947e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 29.644987106323242
Epoch 5/9
	 Logging train Loss: 1.18453e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.69361e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 29.440291166305542
Epoch 6/9
	 Logging train Loss: 1.08463e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.84804e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 29.034656763076782
Epoch 7/9
	 Logging train Loss: 9.9197e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 9.4415e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 28.79104995727539
Epoch 8/9
	 Logging train Loss: 9.6224e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 8.5967e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 28.839199542999268
Epoch 9/9
	 Logging train Loss: 9.3759e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 8.4352e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 28.668957710266113
Saved model in  trained_models/gru/data_tennis_pNone_gNone_tennisEffect/'rot_mat_1'_'True'.pth
It took  376.26307702064514  seconds.
----- ITERATION 8/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 57.311317920684814 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 14.383135318756104 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (pre_hidden_lin_layer): Sequential(
    (0): Linear(in_features=3, out_features=96, bias=True)
    (1): ReLU()
    (2): Linear(in_features=96, out_features=96, bias=True)
    (3): ReLU()
  )
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.001305225 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 4.78237e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 29.881428241729736
Epoch 1/9
	 Logging train Loss: 4.28952e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 3.73296e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 29.5655574798584
Epoch 2/9
	 Logging train Loss: 2.68846e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.65892e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 29.63928747177124
Epoch 3/9
	 Logging train Loss: 1.732e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 3.12664e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 29.419588327407837
Epoch 4/9
	 Logging train Loss: 1.39628e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.1161e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 29.468971014022827
Epoch 5/9
	 Logging train Loss: 1.24311e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.23133e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 29.57330083847046
Epoch 6/9
	 Logging train Loss: 1.12165e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 9.2048e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 29.3881413936615
Epoch 7/9
	 Logging train Loss: 1.03813e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 8.45e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 29.172590970993042
Epoch 8/9
	 Logging train Loss: 9.8763e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.02283e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 29.38955855369568
Epoch 9/9
	 Logging train Loss: 9.6123e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 8.4526e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 29.124324083328247
Saved model in  trained_models/gru/data_tennis_pNone_gNone_tennisEffect/'rot_mat_1'_'True'.pth
It took  377.9736785888672  seconds.
----- ITERATION 9/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 57.39916253089905 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 14.371954202651978 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (pre_hidden_lin_layer): Sequential(
    (0): Linear(in_features=3, out_features=96, bias=True)
    (1): ReLU()
    (2): Linear(in_features=96, out_features=96, bias=True)
    (3): ReLU()
  )
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0010402944 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 6.26478e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 29.481096267700195
Epoch 1/9
	 Logging train Loss: 4.12646e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.96058e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 29.56341004371643
Epoch 2/9
	 Logging train Loss: 2.65698e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.94639e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 29.57220458984375
Epoch 3/9
	 Logging train Loss: 1.76054e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.66725e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 29.90541386604309
Epoch 4/9
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                     Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb: Test loss tennis_pNone_gNone_tennisEffect â–ˆâ–„â–‚â–‚â–â–‚â–â–â–â–
wandb:                                Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                     Epoch 9
wandb: Test loss tennis_pNone_gNone_tennisEffect 1e-05
wandb:                                Train loss 1e-05
wandb: 
wandb: ðŸš€ View run crisp-dragon-1367 at: https://wandb.ai/nreints/ThesisFinal2/runs/5nnx36c3
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230710_175100-5nnx36c3/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230710_175719-ybgo5toh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run woven-pond-1371
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/ybgo5toh
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                     Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb: Test loss tennis_pNone_gNone_tennisEffect â–ˆâ–…â–‚â–‚â–â–â–ƒâ–â–â–
wandb:                                Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                     Epoch 9
wandb: Test loss tennis_pNone_gNone_tennisEffect 1e-05
wandb:                                Train loss 1e-05
wandb: 
wandb: ðŸš€ View run woven-pond-1371 at: https://wandb.ai/nreints/ThesisFinal2/runs/ybgo5toh
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230710_175719-ybgo5toh/logs
	 Logging train Loss: 1.32992e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.03849e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 29.407922744750977
Epoch 5/9
	 Logging train Loss: 1.20376e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.34119e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 29.393126487731934
Epoch 6/9
	 Logging train Loss: 1.06005e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.13045e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 29.15979552268982
Epoch 7/9
	 Logging train Loss: 9.9703e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 9.2028e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 29.102132320404053
Epoch 8/9
	 Logging train Loss: 9.4804e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 9.4092e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 29.056196212768555
Epoch 9/9
	 Logging train Loss: 9.17e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 9.6739e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 29.157212734222412
Saved model in  trained_models/gru/data_tennis_pNone_gNone_tennisEffect/'rot_mat_1'_'True'.pth
It took  379.03667664527893  seconds.
----- ITERATION 10/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 57.430978536605835 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 14.322265148162842 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (pre_hidden_lin_layer): Sequential(
    (0): Linear(in_features=3, out_features=96, bias=True)
    (1): ReLU()
    (2): Linear(in_features=96, out_features=96, bias=True)
    (3): ReLU()
  )
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0009608205 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 5.23811e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 29.29185128211975
Epoch 1/9
	 Logging train Loss: 4.33256e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 3.23739e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 29.572613954544067
Epoch 2/9
	 Logging train Loss: 2.70611e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.64997e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 29.467161893844604
Epoch 3/9
	 Logging train Loss: 1.77805e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.1849e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 29.460359573364258
Epoch 4/9
	 Logging train Loss: 1.41228e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.14891e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 29.422388792037964
Epoch 5/9
	 Logging train Loss: 1.23467e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 9.4463e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 29.423099040985107
Epoch 6/9
	 Logging train Loss: 1.13013e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.83006e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 29.388882637023926
Epoch 7/9
	 Logging train Loss: 1.0273e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.09629e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 29.232422351837158
Epoch 8/9
	 Logging train Loss: 9.7794e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.00871e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 29.371622323989868
Epoch 9/9
	 Logging train Loss: 9.5076e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 8.4185e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 29.081547498703003
Saved model in  trained_models/gru/data_tennis_pNone_gNone_tennisEffect/'rot_mat_1'_'True'.pth
It took  378.21006059646606  seconds.

JOB STATISTICS
==============
Job ID: 3043760
Array Job ID: 3043750_49
Cluster: snellius
User/Group: nreints/nreints
State: COMPLETED (exit code 0)
Nodes: 1
Cores per node: 18
CPU Utilized: 01:05:18
CPU Efficiency: 5.73% of 19:00:00 core-walltime
Job Wall-clock time: 01:03:20
Memory Utilized: 6.52 GB
Memory Efficiency: 0.00% of 0.00 MB
