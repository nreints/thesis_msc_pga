wandb: Currently logged in as: nreints. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230329_133618-hc9a3fk3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run soft-paper-508
wandb: ⭐️ View project at https://wandb.ai/nreints/test
wandb: 🚀 View run at https://wandb.ai/nreints/test/runs/hc9a3fk3
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.031 MB of 0.031 MB uploaded (0.000 MB deduped)wandb: \ 0.031 MB of 0.079 MB uploaded (0.000 MB deduped)wandb: | 0.031 MB of 0.079 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:                                                    Epoch ▁▂▃▃▄▅▆▆▇█
wandb: Test loss t(0, 0)_r(5, 20)_tennis_pNone_gNone, MSELoss() █▇▅▂▂▁▁▁▁▁▁
wandb:                                               Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                                    Epoch 9
wandb: Test loss t(0, 0)_r(5, 20)_tennis_pNone_gNone, MSELoss() 0.0367
wandb:                                               Train loss 0.03373
wandb: 
wandb: 🚀 View run soft-paper-508 at: https://wandb.ai/nreints/test/runs/hc9a3fk3
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230329_133618-hc9a3fk3/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230329_134359-9p8fmh5n
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run magic-valley-521
wandb: ⭐️ View project at https://wandb.ai/nreints/test
wandb: 🚀 View run at https://wandb.ai/nreints/test/runs/9p8fmh5n
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.031 MB of 0.031 MB uploaded (0.000 MB deduped)wandb: \ 0.031 MB of 0.079 MB uploaded (0.000 MB deduped)wandb: | 0.031 MB of 0.079 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:                                                    Epoch ▁▂▃▃▄▅▆▆▇█
wandb: Test loss t(0, 0)_r(5, 20)_tennis_pNone_gNone, MSELoss() █▇▆▃▂▁▁▁▁▁▁
wandb:                                               Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                                    Epoch 9
wandb: Test loss t(0, 0)_r(5, 20)_tennis_pNone_gNone, MSELoss() 0.03428
wandb:                                               Train loss 0.03531
wandb: 
wandb: 🚀 View run magic-valley-521 at: https://wandb.ai/nreints/test/runs/9p8fmh5n
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230329_134359-9p8fmh5n/logs
Running for data type: eucl_motion
----- ITERATION 1/2 ------
Number of train simulations: 1600
Number of test simulations: 400
-- Finished Train Dataloader --
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
-- Started Training --
Epoch 0
	 Logging train Loss: 14.0568661862 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss: 0.6413739919662476 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 41.346858739852905
Epoch 1
	 Logging train Loss: 0.5153067453 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss: 0.547218382358551 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 39.05998635292053
Epoch 2
	 Logging train Loss: 0.4387921689 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss: 0.39577716588974 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 39.137474060058594
Epoch 3
	 Logging train Loss: 0.2346630224 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss: 0.16518594324588776 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 39.312642335891724
Epoch 4
	 Logging train Loss: 0.1066219905 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss: 0.08845339715480804 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 38.686078786849976
Epoch 5
	 Logging train Loss: 0.0622175341 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss: 0.05939603969454765 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 39.098339557647705
Epoch 6
	 Logging train Loss: 0.0460730783 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss: 0.04640235751867294 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 39.35545563697815
Epoch 7
	 Logging train Loss: 0.0395776166 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss: 0.04418930783867836 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 39.13571047782898
Epoch 8
	 Logging train Loss: 0.0361803587 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss: 0.042816683650016785 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 39.70811367034912
Epoch 9
	 Logging train Loss: 0.0337294717 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss: 0.03670636937022209 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 39.957632541656494
	 Logging test loss: 0.036703772842884064 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
It took  462.65664625167847  seconds.
----- ITERATION 2/2 ------
Number of train simulations: 1600
Number of test simulations: 400
-- Finished Train Dataloader --
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
-- Started Training --
Epoch 0
	 Logging train Loss: 14.0937095815 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss: 0.5795802474021912 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 39.08151865005493
Epoch 1
	 Logging train Loss: 0.5266600992 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss: 0.49713894724845886 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 38.556663036346436
Epoch 2
	 Logging train Loss: 0.4686704261 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss: 0.40431272983551025 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 38.41509175300598
Epoch 3
	 Logging train Loss: 0.2855320359 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss: 0.18520709872245789 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 38.273051023483276
Epoch 4
	 Logging train Loss: 0.1259804128 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss: 0.0869518369436264 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 40.621357440948486
Epoch 5
	 Logging train Loss: 0.0698315578 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss: 0.05510299280285835 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 42.79681468009949
Epoch 6
	 Logging train Loss: 0.0494704966 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss: 0.04518604278564453 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 41.238635778427124
Epoch 7
	 Logging train Loss: 0.0417689972 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss: 0.0400698259472847 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 43.17719268798828
Epoch 8
	 Logging train Loss: 0.0378397087 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss: 0.035408154129981995 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 38.81551265716553
Epoch 9
	 Logging train Loss: 0.0353054408 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss: 0.03426099568605423 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 38.86645269393921
	 Logging test loss: 0.034282196313142776 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
It took  462.5237789154053  seconds.

JOB STATISTICS
==============
Job ID: 2514794
Array Job ID: 2514792_2
Cluster: snellius
User/Group: nreints/nreints
State: RUNNING
Nodes: 1
Cores per node: 18
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 04:41:42 core-walltime
Job Wall-clock time: 00:15:39
Memory Utilized: 0.00 MB (estimated maximum)
Memory Efficiency: 0.00% of 31.25 GB (31.25 GB/node)
WARNING: Efficiency statistics may be misleading for RUNNING jobs.
