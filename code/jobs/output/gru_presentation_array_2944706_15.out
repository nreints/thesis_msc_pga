wandb: Currently logged in as: nreints. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230620_141158-d9ajkrqd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run silver-mountain-269
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal/runs/d9ajkrqd
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone â–ˆâ–‚â–‚â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone â–ˆâ–‚â–‚â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–
wandb:                                   Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone 0.00169
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 0.00055
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone 0.00053
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 0.00261
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 0.00271
wandb:                                   Train loss 0.00152
wandb: 
wandb: ðŸš€ View run silver-mountain-269 at: https://wandb.ai/nreints/ThesisFinal/runs/d9ajkrqd
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230620_141158-d9ajkrqd/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230620_142652-88inqnfo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ancient-valley-317
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal/runs/88inqnfo
Training on dataset: data_t(5,20)_r(5,20)_combi_pNone_gNone
Testing on 5 datasets: ['data_t(5,20)_r(5,20)_full_pNone_gNone', 'data_t(5,20)_r(5,20)_semi_pNone_gNone', 'data_t(5,20)_r(5,20)_tennis_pNone_gNone', 'data_t(5,20)_r(5,20)_combi_pNone_gNone', 'data_t(5,20)_r(5,20)_none_pNone_gNone']
Focussing on identity: False
Using extra input: None
Using start-fr as reference point.
----- ITERATION 1/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 78.61240243911743 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 19.988027572631836 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 19.975292921066284 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 20.405680418014526 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 20.16529130935669 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_none_pNone_gNone took 20.08928370475769 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 3.6905362606 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.139859274 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.1551651061 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.1519498527 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.1527249068 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.1332083046 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 72.58802342414856
Epoch 1/9
	 Logging train Loss: 0.0649483129 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0245633423 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0369225331 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0365032479 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0326570459 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0241405014 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 71.06267714500427
Epoch 2/9
	 Logging train Loss: 0.0204740949 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0101370504 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0188972801 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.018787954 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0154629052 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.010130709 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 70.83806586265564
Epoch 3/9
	 Logging train Loss: 0.0107046152 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0052750311 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0120116109 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0120448973 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0092677847 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0052490737 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 69.83554863929749
Epoch 4/9
	 Logging train Loss: 0.0066400408 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0029641872 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0079910681 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0080505693 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0058893706 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0029406014 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 69.71653866767883
Epoch 5/9
	 Logging train Loss: 0.0045081978 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0018670853 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0059351213 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0059521152 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.004155383 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0018122717 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 69.46413779258728
Epoch 6/9
	 Logging train Loss: 0.0033033867 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.001228397 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0045732432 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0046826093 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.003090156 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0011782083 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 69.4454927444458
Epoch 7/9
	 Logging train Loss: 0.0024568823 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0008580913 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0033856519 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0034887188 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0022888093 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0008116638 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 69.58587980270386
Epoch 8/9
	 Logging train Loss: 0.0018862123 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0007292897 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0026586154 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0026678643 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0017854274 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0007096214 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 69.89136791229248
Epoch 9/9
	 Logging train Loss: 0.0015197488 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0005462738 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0026125892 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0027148856 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0016862195 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.000526321 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 69.2710530757904
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gNone/'rot_mat'_'None'.pth
It took  894.4352304935455  seconds.
----- ITERATION 2/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 78.99525380134583 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 19.94264817237854 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 19.871276378631592 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 19.930465936660767 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 19.695462942123413 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_none_pNone_gNone took 19.921882152557373 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 3.9573221207 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.1153253168 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.1898357868 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.1781770289 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.167003721 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone â–ˆâ–‚â–‚â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–
wandb:                                   Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone 0.00195
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 0.00043
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone 0.00043
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 0.00293
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 0.00306
wandb:                                   Train loss 0.00161
wandb: 
wandb: ðŸš€ View run ancient-valley-317 at: https://wandb.ai/nreints/ThesisFinal/runs/88inqnfo
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230620_142652-88inqnfo/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230620_144144-ljfmdkdl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glamorous-plant-349
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal/runs/ljfmdkdl
	 Logging test loss: 0.1130181029 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 74.31010699272156
Epoch 1/9
	 Logging train Loss: 0.0628822893 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0194390211 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.044823505 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0433320664 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0366685688 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0194232669 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 70.95451664924622
Epoch 2/9
	 Logging train Loss: 0.0196814016 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0078781024 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0225648396 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0223186687 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0177851599 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0079070944 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 69.99971771240234
Epoch 3/9
	 Logging train Loss: 0.0101477755 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0039097816 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0134505574 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.013508698 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0102488073 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0038960031 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 69.59768176078796
Epoch 4/9
	 Logging train Loss: 0.0062172441 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0023647652 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0089262091 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0090856254 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0067111994 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0023407841 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 69.61037397384644
Epoch 5/9
	 Logging train Loss: 0.0042642173 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0017253789 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0068360567 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0070709139 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0049968832 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0016698767 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 69.82194447517395
Epoch 6/9
	 Logging train Loss: 0.0031363154 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0012054009 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0052407798 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0055020507 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.003800588 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0011811443 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 69.83032274246216
Epoch 7/9
	 Logging train Loss: 0.0024067806 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0007383826 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0037502993 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0038618511 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0026386657 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0007302117 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 69.39154720306396
Epoch 8/9
	 Logging train Loss: 0.0019259247 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.000534201 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0029999306 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0031160191 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0020643775 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0005242304 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 69.51123023033142
Epoch 9/9
	 Logging train Loss: 0.0016067867 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0004317993 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0029260258 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.003062919 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0019540822 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0004283014 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 69.59567260742188
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gNone/'rot_mat'_'None'.pth
It took  892.4017524719238  seconds.
----- ITERATION 3/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 79.20942187309265 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 19.95981240272522 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 19.909745693206787 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 19.867547750473022 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 19.861145973205566 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_none_pNone_gNone took 19.852864503860474 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 3.6601653099 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.1304357052 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.1625689417 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.1604593694 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.1559665799 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.1286885589 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 71.35625338554382
Epoch 1/9
	 Logging train Loss: 0.0627000406 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0229774266 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0389179066 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0388828218 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0340022519 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0235672016 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 72.67603373527527
Epoch 2/9
	 Logging train Loss: 0.0197159853 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.00862619 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0199861471 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0196135622 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0156835355 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0091735609 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 69.75980353355408
Epoch 3/9
	 Logging train Loss: 0.0102341333 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0043948325 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.01216581 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0120240189 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0090383505 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0047132387 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 69.88357281684875
Epoch 4/9
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone â–ˆâ–‚â–‚â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–
wandb:                                   Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone 0.0016
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 0.00048
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone 0.0005
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 0.00256
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 0.00266
wandb:                                   Train loss 0.00167
wandb: 
wandb: ðŸš€ View run glamorous-plant-349 at: https://wandb.ai/nreints/ThesisFinal/runs/ljfmdkdl
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230620_144144-ljfmdkdl/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230620_145639-jfqkchvj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eternal-resonance-378
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal/runs/jfqkchvj
	 Logging train Loss: 0.0064459313 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0025782054 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0082431631 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0082052639 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0058433912 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0027505856 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 70.11036252975464
Epoch 5/9
	 Logging train Loss: 0.0044741207 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0016911509 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0061279479 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0062078927 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0041789412 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0017845047 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 70.18274784088135
Epoch 6/9
	 Logging train Loss: 0.0033117081 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0010956895 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0046538096 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.004693856 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0030391233 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0011445453 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 69.77091789245605
Epoch 7/9
	 Logging train Loss: 0.0025234504 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0009295979 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0041358415 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0042750663 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0027056336 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0009618279 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 69.83483672142029
Epoch 8/9
	 Logging train Loss: 0.0020344546 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0006383318 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0034238854 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0035117052 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0021568083 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0006633938 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 69.59949660301208
Epoch 9/9
	 Logging train Loss: 0.0016707763 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0004791933 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0025646458 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0026620142 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0015984093 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0005006848 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 70.23083090782166
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gNone/'rot_mat'_'None'.pth
It took  894.4261457920074  seconds.
----- ITERATION 4/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 78.88893747329712 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 19.989571809768677 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 19.79570436477661 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 19.83372211456299 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 19.845735788345337 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_none_pNone_gNone took 19.84905505180359 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 4.0965180397 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.1452201456 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.1902309805 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.1915109456 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.1570255309 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.1482797414 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 71.9039056301117
Epoch 1/9
	 Logging train Loss: 0.0723950192 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0260711741 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0456501022 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0475363061 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0343182869 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.027943762 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 70.63472747802734
Epoch 2/9
	 Logging train Loss: 0.0229670126 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0099639306 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0218293797 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0230695214 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0153778112 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0110188359 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 72.77871322631836
Epoch 3/9
	 Logging train Loss: 0.0116245039 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0049708472 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0134550342 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0144037986 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0090371482 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.005597923 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 69.88847064971924
Epoch 4/9
	 Logging train Loss: 0.0070849666 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0028687355 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0089458618 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0095455553 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.005818428 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0032654167 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 69.72195029258728
Epoch 5/9
	 Logging train Loss: 0.0048114001 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0018108472 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0061529595 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0066984422 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0039486173 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0020737976 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 69.92691802978516
Epoch 6/9
	 Logging train Loss: 0.0034686944 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0017902689 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0052829995 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0056591369 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0035015715 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0019909742 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 69.9118161201477
Epoch 7/9
	 Logging train Loss: 0.0026012014 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0015116709 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone â–ˆâ–‚â–‚â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–
wandb:                                   Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone 0.0015
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 0.00064
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone 0.00069
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 0.00245
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 0.00259
wandb:                                   Train loss 0.00168
wandb: 
wandb: ðŸš€ View run eternal-resonance-378 at: https://wandb.ai/nreints/ThesisFinal/runs/jfqkchvj
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230620_145639-jfqkchvj/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230620_151139-4avr3li3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run warm-darkness-406
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal/runs/4avr3li3
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone â–ˆâ–‚â–‚â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–
wandb:                                   Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone 0.00193
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 0.0008
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone 0.00085
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 0.00312
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 0.00309
wandb:                                   Train loss 0.00173
wandb: 
wandb: ðŸš€ View run warm-darkness-406 at: https://wandb.ai/nreints/ThesisFinal/runs/4avr3li3
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230620_151139-4avr3li3/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230620_152632-fel5hig8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sweet-surf-435
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal/runs/fel5hig8
	 Logging test loss: 0.0044271355 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0047305375 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0029352058 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0016214758 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 70.06216311454773
Epoch 8/9
	 Logging train Loss: 0.0020709243 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0010448081 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0029801319 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0032072139 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0019995046 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0011306559 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 70.18838739395142
Epoch 9/9
	 Logging train Loss: 0.0016836305 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0006367924 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0024459353 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.002590572 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0014975276 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0006867104 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 69.7286856174469
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gNone/'rot_mat'_'None'.pth
It took  900.0101945400238  seconds.
----- ITERATION 5/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 78.29796123504639 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 19.861334800720215 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 19.770771741867065 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 19.847368001937866 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 20.001646757125854 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_none_pNone_gNone took 19.886339902877808 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 3.7673580647 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.1242164671 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.1741362959 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.1788152009 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.1601531357 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.1498226374 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 71.37013554573059
Epoch 1/9
	 Logging train Loss: 0.0624925718 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0202955063 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0401412807 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0420427099 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0328365676 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0252368189 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 70.41577982902527
Epoch 2/9
	 Logging train Loss: 0.0200612657 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0084599713 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0213139243 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.021958204 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.016050918 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0104884263 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 69.83275580406189
Epoch 3/9
	 Logging train Loss: 0.0106762061 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0042635361 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0128632616 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0133050401 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0091351913 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0052952575 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 72.57630372047424
Epoch 4/9
	 Logging train Loss: 0.006707618 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0027430041 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0097127231 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0099126929 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0064898585 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0032794476 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 69.86881947517395
Epoch 5/9
	 Logging train Loss: 0.0046395175 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0019487637 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0067431121 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.006895313 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0044539077 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.002278968 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 69.55188202857971
Epoch 6/9
	 Logging train Loss: 0.0034354168 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0010734459 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0049248165 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0050300891 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0030366543 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0012685917 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 69.73395133018494
Epoch 7/9
	 Logging train Loss: 0.002663234 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0008367277 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0038182384 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0038382642 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0023145473 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0009653449 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 70.10162997245789
Epoch 8/9
	 Logging train Loss: 0.0021573764 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.000578875 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.003045338 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0030684979 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0018002829 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0006848303 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 69.63834691047668
Epoch 9/9
	 Logging train Loss: 0.0017251906 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0007978791 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0031180975 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0030946573 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0019296672 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0008538432 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 69.74240446090698
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gNone/'rot_mat'_'None'.pth
It took  893.3537693023682  seconds.
----- ITERATION 6/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone â–ˆâ–‚â–‚â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–
wandb:                                   Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone 0.00224
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 0.00097
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone 0.00103
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 0.00331
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 0.00346
wandb:                                   Train loss 0.00165
wandb: 
wandb: ðŸš€ View run sweet-surf-435 at: https://wandb.ai/nreints/ThesisFinal/runs/fel5hig8
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230620_152632-fel5hig8/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230620_154128-c8y2p32x
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run upbeat-firebrand-457
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal/runs/c8y2p32x
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 79.02739787101746 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 19.988701820373535 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 19.850940465927124 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 19.871569395065308 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 19.48733139038086 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_none_pNone_gNone took 19.911967992782593 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 3.8195486069 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.1236825883 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.1647055596 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.166090861 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.1523861438 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.1251855344 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 71.44355821609497
Epoch 1/9
	 Logging train Loss: 0.0663580149 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0202228148 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0382781923 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0397837013 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.031272985 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0211663079 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 70.8044331073761
Epoch 2/9
	 Logging train Loss: 0.0206830669 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0081157694 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0193003472 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.020303037 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0148667675 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0087817386 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 70.40063071250916
Epoch 3/9
	 Logging train Loss: 0.0108230207 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0042752032 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0121785561 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0129161282 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0089607267 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0047233123 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 72.96128606796265
Epoch 4/9
	 Logging train Loss: 0.0066893194 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0024666314 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0080875289 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0084637264 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0057538375 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0027663496 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 70.12411093711853
Epoch 5/9
	 Logging train Loss: 0.0045302319 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0015710442 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0058896621 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0061465702 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0040079392 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0017691312 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 70.3483989238739
Epoch 6/9
	 Logging train Loss: 0.0033212428 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0012521968 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0046654711 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.004898712 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0031786109 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0013944189 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 69.98853921890259
Epoch 7/9
	 Logging train Loss: 0.002542078 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0008866741 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0038602361 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0040775635 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0025415851 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.001000974 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 69.89154529571533
Epoch 8/9
	 Logging train Loss: 0.0020750614 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0006214196 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.003240007 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0034027621 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0020217476 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0007147417 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 69.81991219520569
Epoch 9/9
	 Logging train Loss: 0.0016498691 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0009731518 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0033133444 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0034646487 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0022372482 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0010256775 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 69.64107322692871
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gNone/'rot_mat'_'None'.pth
It took  895.7885565757751  seconds.
----- ITERATION 7/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 79.17131400108337 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 19.878232955932617 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 19.812038898468018 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 19.818883657455444 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 19.791224479675293 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_none_pNone_gNone took 19.824535131454468 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 3.3829343319 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.1109829769 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.1471828222 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.1450704485 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.137612164 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.1029282063 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 71.80740451812744
Epoch 1/9
	 Logging train Loss: 0.0562294684 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0202578735 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0378574729 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0377348475 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0315364301 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–
wandb:                                   Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone 0.00164
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 0.00042
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone 0.00043
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 0.00254
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 0.00273
wandb:                                   Train loss 0.00158
wandb: 
wandb: ðŸš€ View run upbeat-firebrand-457 at: https://wandb.ai/nreints/ThesisFinal/runs/c8y2p32x
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230620_154128-c8y2p32x/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230620_155628-5a44o3de
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run earthy-yogurt-463
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal/runs/5a44o3de
	 Logging test loss: 0.01870743 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 72.31606698036194
Epoch 2/9
	 Logging train Loss: 0.0189020615 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0082666036 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0192709677 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0196079724 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0150923086 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0076698875 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 71.1381323337555
Epoch 3/9
	 Logging train Loss: 0.0099829454 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0041711018 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0120936194 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0125063313 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0088989986 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0038957486 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 73.21798372268677
Epoch 4/9
	 Logging train Loss: 0.0061497027 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.002353122 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0083536888 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0088029951 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0059148506 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0022189687 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 70.36523175239563
Epoch 5/9
	 Logging train Loss: 0.0042107645 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0014507073 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0058473148 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0061565097 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0040351236 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0013891798 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 70.09968090057373
Epoch 6/9
	 Logging train Loss: 0.0031161422 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0010019558 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0046931659 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0049637454 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0032100328 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0009702031 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 70.32752466201782
Epoch 7/9
	 Logging train Loss: 0.0024598048 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0007556736 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0041238056 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0045011877 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0027488852 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0007418229 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 70.06048846244812
Epoch 8/9
	 Logging train Loss: 0.0019382598 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0005890095 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0031918625 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0034799809 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0021323848 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0005790981 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 70.03793478012085
Epoch 9/9
	 Logging train Loss: 0.001582611 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0004183804 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0025387472 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0027287831 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0016377096 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0004260526 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 69.80999779701233
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gNone/'rot_mat'_'None'.pth
It took  900.4182658195496  seconds.
----- ITERATION 8/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 78.44379043579102 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 19.83664846420288 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 19.8245210647583 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 19.86779475212097 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 19.832905292510986 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_none_pNone_gNone took 19.868902444839478 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 3.7650110722 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.1228919402 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.1549578756 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.1598109603 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.1449201852 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.1168140396 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 71.27221846580505
Epoch 1/9
	 Logging train Loss: 0.063349016 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0205546375 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.037354432 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0407128111 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0311951246 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0199119169 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 70.4771146774292
Epoch 2/9
	 Logging train Loss: 0.0205868557 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0084621189 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0189175922 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0209003147 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0148334261 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0081424015 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 69.60756254196167
Epoch 3/9
	 Logging train Loss: 0.010883159 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0043692379 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0115160039 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0127313463 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0085513014 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.004213254 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 70.66725707054138
Epoch 4/9
	 Logging train Loss: 0.0066506243 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0024773141 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0082213758 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0090153562 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.005596499 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0023952993 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 72.28512525558472
Epoch 5/9
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone â–ˆâ–‚â–‚â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–
wandb:                                   Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone 0.00153
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 0.00056
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone 0.00056
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 0.0025
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 0.00277
wandb:                                   Train loss 0.0016
wandb: 
wandb: ðŸš€ View run earthy-yogurt-463 at: https://wandb.ai/nreints/ThesisFinal/runs/5a44o3de
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230620_155628-5a44o3de/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230620_161124-78xtypz1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run frosty-universe-468
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal/runs/78xtypz1
	 Logging train Loss: 0.0044370741 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0015286212 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.005624597 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0062202956 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.003729526 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0014903385 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 69.72284245491028
Epoch 6/9
	 Logging train Loss: 0.0031818375 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0011249376 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0050371289 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0055748485 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0031068947 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0011240442 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 69.496009349823
Epoch 7/9
	 Logging train Loss: 0.0024522715 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0007259431 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0036774657 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0040695705 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0021985408 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0007171116 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 69.72624826431274
Epoch 8/9
	 Logging train Loss: 0.0019554191 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0006130834 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0028273738 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0030763911 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0017422272 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.000604196 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 69.58479356765747
Epoch 9/9
	 Logging train Loss: 0.001597318 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0005612464 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0024973608 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0027736465 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0015334056 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0005586496 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 69.41131806373596
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gNone/'rot_mat'_'None'.pth
It took  895.4406747817993  seconds.
----- ITERATION 9/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 79.37085580825806 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 19.905558586120605 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 19.86628484725952 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 19.914252758026123 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 20.004981756210327 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_none_pNone_gNone took 19.882774353027344 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 3.8000264168 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.1454865783 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.1989694387 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.1755599529 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.1569290012 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.1435071081 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 71.82388925552368
Epoch 1/9
	 Logging train Loss: 0.0665199608 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0233149212 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0438356437 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0399922691 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0308341011 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0229106881 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 71.257985830307
Epoch 2/9
	 Logging train Loss: 0.0201550685 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0089467941 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0218915604 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0203700382 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0144559387 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0090605961 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 70.4425756931305
Epoch 3/9
	 Logging train Loss: 0.0104098413 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0045309803 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0139845628 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0129389502 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0088849673 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0046585244 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 69.83014297485352
Epoch 4/9
	 Logging train Loss: 0.0065244744 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.002586415 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0094861742 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0088522742 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0058938325 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0026936487 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 72.42583751678467
Epoch 5/9
	 Logging train Loss: 0.0045403922 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0016379356 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0074276682 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0069219843 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0044076298 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0017071265 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 70.10242319107056
Epoch 6/9
	 Logging train Loss: 0.0033509636 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0011621744 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0056236442 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0052685644 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0033643283 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0012203328 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 70.10498404502869
Epoch 7/9
	 Logging train Loss: 0.0025497165 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0010499136 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0043878462 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0041015865 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0027126935 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0011030599 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 69.89222764968872
Epoch 8/9
	 Logging train Loss: 0.0020267558 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0006578802 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone â–ˆâ–‚â–‚â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone â–ˆâ–‚â–‚â–â–â–â–â–â–â–
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–
wandb:                                   Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone 0.00159
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 0.00048
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone 0.00051
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 0.00266
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 0.00252
wandb:                                   Train loss 0.00165
wandb: 
wandb: ðŸš€ View run frosty-universe-468 at: https://wandb.ai/nreints/ThesisFinal/runs/78xtypz1
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230620_161124-78xtypz1/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230620_162625-2jomwhjt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rosy-glitter-472
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal/runs/2jomwhjt
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone â–ˆâ–‚â–‚â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone â–ˆâ–‚â–‚â–â–â–â–â–â–â–
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–
wandb:                                   Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone 0.00167
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 0.00042
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone 0.00048
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 0.00258
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 0.00297
wandb:                                   Train loss 0.00166
wandb: 
wandb: ðŸš€ View run rosy-glitter-472 at: https://wandb.ai/nreints/ThesisFinal/runs/2jomwhjt
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230620_162625-2jomwhjt/logs
	 Logging test loss: 0.0035793481 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0033641888 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0021195244 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0006891713 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 70.03456711769104
Epoch 9/9
	 Logging train Loss: 0.0016473602 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.000480455 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0026554153 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0025180422 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0015877263 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0005051467 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 69.86907029151917
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gNone/'rot_mat'_'None'.pth
It took  901.2537825107574  seconds.
----- ITERATION 10/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 78.3700749874115 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 19.95931839942932 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 19.985894203186035 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 20.09553623199463 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 19.88872790336609 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_none_pNone_gNone took 20.039516925811768 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 3.8765659332 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.1241595075 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.1558207572 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.1703175604 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.1658887565 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.1348748952 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 71.72214531898499
Epoch 1/9
	 Logging train Loss: 0.0646951497 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0177013576 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0332002342 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0397301055 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0307549927 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0202718079 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 70.88375639915466
Epoch 2/9
	 Logging train Loss: 0.019788146 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0069933748 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0169502422 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0203591045 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0142236548 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0081025539 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 70.41155934333801
Epoch 3/9
	 Logging train Loss: 0.0103362799 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.003497595 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0105363373 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0126432786 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0082895933 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0040808488 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 69.81685662269592
Epoch 4/9
	 Logging train Loss: 0.0064685168 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0021473102 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0075553618 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0090102693 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0056833797 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.002479428 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 69.59210801124573
Epoch 5/9
	 Logging train Loss: 0.0044973623 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0013197458 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0053075184 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0062589552 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.003792207 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0015279176 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 71.80715346336365
Epoch 6/9
	 Logging train Loss: 0.0033203706 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0009562187 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.004124708 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0047996994 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0028986132 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0010927559 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 69.44930052757263
Epoch 7/9
	 Logging train Loss: 0.0025647641 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0006837192 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0033403679 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0039267289 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.002270988 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0007751609 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 69.19094252586365
Epoch 8/9
	 Logging train Loss: 0.0020514445 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0005343683 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0027148821 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0031158309 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0018170322 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0005962069 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 69.62567448616028
Epoch 9/9
	 Logging train Loss: 0.0016633599 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0004209826 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.00257694 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0029678459 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0016714251 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0004795128 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 69.46441793441772
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gNone/'rot_mat'_'None'.pth
It took  893.708304643631  seconds.

JOB STATISTICS
==============
Job ID: 2944784
Array Job ID: 2944706_15
Cluster: snellius
User/Group: nreints/nreints
State: RUNNING
Nodes: 1
Cores per node: 18
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 1-20:52:12 core-walltime
Job Wall-clock time: 02:29:34
Memory Utilized: 0.00 MB (estimated maximum)
Memory Efficiency: 0.00% of 0.00 MB (0.00 MB/node)
WARNING: Efficiency statistics may be misleading for RUNNING jobs.
