wandb: Currently logged in as: nreints. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_164025-q0bfoiu8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run young-sponge-3
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal1/runs/q0bfoiu8
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone â–ˆâ–…â–‚â–â–‚â–â–â–â–â–
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone â–ˆâ–ƒâ–‚â–‚â–„â–â–â–â–â–
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone â–ˆâ–„â–‚â–‚â–ƒâ–â–â–â–â–
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone â–ˆâ–…â–‚â–â–â–â–â–â–â–
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone â–ˆâ–…â–‚â–â–â–â–â–â–â–
wandb:                                  Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone 0.0
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: ðŸš€ View run young-sponge-3 at: https://wandb.ai/nreints/ThesisFinal1/runs/q0bfoiu8
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_164025-q0bfoiu8/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_164934-v4ddzz5t
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fearless-grass-41
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal1/runs/v4ddzz5t
Training on dataset: data_t(0,0)_r(5,20)_combi_pNone_gNone
Testing on 5 datasets: ['data_t(0,0)_r(5,20)_semi_pNone_gNone', 'data_t(0,0)_r(5,20)_tennis_pNone_gNone', 'data_t(0,0)_r(5,20)_combi_pNone_gNone', 'data_t(0,0)_r(5,20)_none_pNone_gNone', 'data_t(0,0)_r(5,20)_full_pNone_gNone']
Focussing on identity: False
Using extra input: False
Using fr-fr as reference point.
----- ITERATION 1/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 63.77553057670593 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(5,20)_semi_pNone_gNone took 16.43594193458557 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_tennis_pNone_gNone took 16.401854515075684 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 15.68149209022522 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_none_pNone_gNone took 16.482137441635132 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_full_pNone_gNone took 16.364291429519653 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(24, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=24, bias=True)
)
Datatype: pos_diff_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0001483095 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.3492e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.51053e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 7.8641e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.8334e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.1685e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 39.610334157943726
Epoch 1/9
	 Logging train Loss: 6.2837e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 9.3838e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 9.2694e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.9078e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.501e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 5.064e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 38.76235318183899
Epoch 2/9
	 Logging train Loss: 3.9809e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.8986e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 5.3333e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.7716e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.634e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.499e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 38.214449882507324
Epoch 3/9
	 Logging train Loss: 2.3053e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.2432e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.7979e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.9552e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.92e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.24e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 38.39161705970764
Epoch 4/9
	 Logging train Loss: 1.8752e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.2839e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.8099e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.046e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.32e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 5.8e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 38.74832367897034
Epoch 5/9
	 Logging train Loss: 1.7609e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.8833e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.3387e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.6514e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.7e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.239e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 38.365745067596436
Epoch 6/9
	 Logging train Loss: 1.7013e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.784e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.2186e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.5616e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.991e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.622e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 38.67583346366882
Epoch 7/9
	 Logging train Loss: 1.6596e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.7726e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.1272e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.5413e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.985e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.695e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 38.93649673461914
Epoch 8/9
	 Logging train Loss: 1.6103e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.802e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.1316e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.5571e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.157e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.977e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 38.73910427093506
Epoch 9/9
	 Logging train Loss: 1.5704e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.7516e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.9697e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.501e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.909e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.866e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 38.499369859695435
Saved model in  trained_models/gru/data_t(0,0)_r(5,20)_combi_pNone_gNone/'pos_diff_1'_'False'.pth
It took  549.567544221878  seconds.
----- ITERATION 2/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 63.67383599281311 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(5,20)_semi_pNone_gNone took 16.140867233276367 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_tennis_pNone_gNone took 16.184699058532715 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 15.930798053741455 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_none_pNone_gNone took 16.274735689163208 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_full_pNone_gNone took 16.24549674987793 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(24, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=24, bias=True)
)
Datatype: pos_diff_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0001440365 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.27805e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.35961e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 8.6651e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.6851e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.1948e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 38.82136917114258
Epoch 1/9
	 Logging train Loss: 6.3063e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone â–ˆâ–…â–ƒâ–‚â–â–â–â–â–â–
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone â–ˆâ–ƒâ–ƒâ–„â–â–‚â–â–â–‚â–‚
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone â–ˆâ–„â–ƒâ–ƒâ–â–â–â–â–‚â–
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone â–ˆâ–†â–ƒâ–‚â–â–â–â–â–â–
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone â–ˆâ–…â–ƒâ–‚â–â–â–â–â–â–
wandb:                                  Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone 0.0
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: ðŸš€ View run fearless-grass-41 at: https://wandb.ai/nreints/ThesisFinal1/runs/v4ddzz5t
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_164934-v4ddzz5t/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_165838-qvc4zthi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rose-waterfall-74
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal1/runs/qvc4zthi
	 Logging test loss: 9.1497e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 8.5557e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 5.57e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.761e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 4.993e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 38.327085733413696
Epoch 2/9
	 Logging train Loss: 4.2151e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.451e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 5.361e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.5051e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.204e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 4.336e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 38.51614260673523
Epoch 3/9
	 Logging train Loss: 2.5159e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.4726e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.7888e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.4703e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.46e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 6.069e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 38.096007347106934
Epoch 4/9
	 Logging train Loss: 1.8769e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.8088e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.1255e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.894e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.576e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.267e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 37.95316982269287
Epoch 5/9
	 Logging train Loss: 1.7324e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.7452e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.0508e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.8696e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.642e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.416e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 40.36615180969238
Epoch 6/9
	 Logging train Loss: 1.6628e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.6283e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.9055e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.7405e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.898e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.722e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 39.71294379234314
Epoch 7/9
	 Logging train Loss: 1.6145e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.6011e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.8195e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.7079e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.693e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.631e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 38.70664644241333
Epoch 8/9
	 Logging train Loss: 1.5747e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.7679e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.9458e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.8567e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.489e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.493e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 38.63199067115784
Epoch 9/9
	 Logging train Loss: 1.5409e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.6607e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.7953e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.7369e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.308e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.429e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 38.53376889228821
Saved model in  trained_models/gru/data_t(0,0)_r(5,20)_combi_pNone_gNone/'pos_diff_1'_'False'.pth
It took  544.251856803894  seconds.
----- ITERATION 3/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 62.1862473487854 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(5,20)_semi_pNone_gNone took 15.922101736068726 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_tennis_pNone_gNone took 15.920889616012573 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 15.771477460861206 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_none_pNone_gNone took 15.937972784042358 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_full_pNone_gNone took 15.983133792877197 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(24, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=24, bias=True)
)
Datatype: pos_diff_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0001538057 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.29715e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.43142e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 7.1127e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.537e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.0339e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 38.98146939277649
Epoch 1/9
	 Logging train Loss: 6.5001e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 9.1681e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 9.2039e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.5643e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.671e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 4.751e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 38.90878486633301
Epoch 2/9
	 Logging train Loss: 4.2126e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.6673e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 5.1721e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.5273e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.141e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.305e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 38.552196979522705
Epoch 3/9
	 Logging train Loss: 2.3725e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.9745e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.5947e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.7214e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.144e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.748e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 38.74681329727173
Epoch 4/9
	 Logging train Loss: 1.8996e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.6987e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.2936e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.4982e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.947e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.586e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 39.153613328933716
Epoch 5/9
wandb: Waiting for W&B process to finish... (success).
wandb: ERROR Error while calling W&B API: An internal error occurred. Please contact support. (<Response [500]>)
wandb: 
wandb: Run history:
wandb:                                       Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone â–ˆâ–…â–‚â–â–â–â–â–â–â–
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone â–ˆâ–„â–ƒâ–‚â–â–â–â–‚â–â–
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone â–ˆâ–„â–ƒâ–‚â–â–â–â–‚â–â–
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone â–ˆâ–…â–‚â–â–â–â–â–â–â–
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone â–ˆâ–…â–‚â–â–â–â–â–â–â–
wandb:                                  Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone 0.0
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: ðŸš€ View run rose-waterfall-74 at: https://wandb.ai/nreints/ThesisFinal1/runs/qvc4zthi
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_165838-qvc4zthi/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_170740-5lm95f76
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ruby-flower-102
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal1/runs/5lm95f76
	 Logging train Loss: 1.8013e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.629e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.2467e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.4559e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.849e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.663e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 38.724923610687256
Epoch 6/9
	 Logging train Loss: 1.7401e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.6498e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.1855e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.4466e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.999e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.825e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 38.823861837387085
Epoch 7/9
	 Logging train Loss: 1.6888e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.6898e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.1634e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.4836e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.492e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.446e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 38.87683939933777
Epoch 8/9
	 Logging train Loss: 1.646e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.5805e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.9341e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.3517e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.307e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.353e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 39.039889097213745
Epoch 9/9
	 Logging train Loss: 1.6026e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.6222e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.8973e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.3642e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.462e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.627e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 38.35113215446472
Saved model in  trained_models/gru/data_t(0,0)_r(5,20)_combi_pNone_gNone/'pos_diff_1'_'False'.pth
It took  542.4206845760345  seconds.
----- ITERATION 4/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 62.29633855819702 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(5,20)_semi_pNone_gNone took 15.909198522567749 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_tennis_pNone_gNone took 15.91489028930664 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 15.77965235710144 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_none_pNone_gNone took 15.915972232818604 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_full_pNone_gNone took 15.854640483856201 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(24, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=24, bias=True)
)
Datatype: pos_diff_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0001445251 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.27277e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.5248e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 7.9587e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.7215e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.1366e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 39.76374650001526
Epoch 1/9
	 Logging train Loss: 6.4868e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 9.0834e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 9.7576e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 5.1684e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.552e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 5.38e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 40.39248180389404
Epoch 2/9
	 Logging train Loss: 4.1708e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.6908e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 5.508e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.8318e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.399e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.372e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 38.65675115585327
Epoch 3/9
	 Logging train Loss: 2.3477e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.1076e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.9047e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.0707e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.092e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 4.564e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 38.44439888000488
Epoch 4/9
	 Logging train Loss: 1.8412e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.6654e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.43e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.6813e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.554e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.106e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 38.70736861228943
Epoch 5/9
	 Logging train Loss: 1.7421e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.6125e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.2679e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.62e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.794e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.47e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 38.57753014564514
Epoch 6/9
	 Logging train Loss: 1.6831e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.8496e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.5359e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.8453e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.494e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 4.261e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 38.73631286621094
Epoch 7/9
	 Logging train Loss: 1.6328e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.606e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.2217e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.6043e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.528e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.428e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 38.80930542945862
Epoch 8/9
	 Logging train Loss: 1.5933e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.6133e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.1364e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.5895e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.496e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone â–ˆâ–…â–‚â–‚â–â–â–â–â–â–
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone â–ˆâ–„â–‚â–ƒâ–â–â–ƒâ–‚â–‚â–
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone â–ˆâ–„â–‚â–ƒâ–‚â–â–‚â–â–â–
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone â–ˆâ–†â–‚â–â–â–â–â–â–â–
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone â–ˆâ–…â–‚â–‚â–â–â–â–â–â–
wandb:                                  Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone 0.0
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: ðŸš€ View run ruby-flower-102 at: https://wandb.ai/nreints/ThesisFinal1/runs/5lm95f76
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_170740-5lm95f76/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_171644-ndve3hs9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fresh-water-135
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal1/runs/ndve3hs9
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone â–ˆâ–…â–ƒâ–â–â–â–â–â–â–
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone â–ˆâ–…â–„â–â–â–â–‚â–â–â–
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone â–ˆâ–…â–„â–‚â–â–â–‚â–â–â–
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone â–ˆâ–…â–‚â–â–â–â–â–â–â–
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone â–ˆâ–…â–‚â–â–â–â–â–â–â–
wandb:                                  Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone 0.0
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: ðŸš€ View run fresh-water-135 at: https://wandb.ai/nreints/ThesisFinal1/runs/ndve3hs9
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_171644-ndve3hs9/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_172546-i8mqws9b
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run jolly-firebrand-169
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal1/runs/i8mqws9b
	 Logging test loss: 2.534e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 38.690250635147095
Epoch 9/9
	 Logging train Loss: 1.552e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.5127e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.9579e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.4758e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.501e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.603e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 38.85377645492554
Saved model in  trained_models/gru/data_t(0,0)_r(5,20)_combi_pNone_gNone/'pos_diff_1'_'False'.pth
It took  543.3547501564026  seconds.
----- ITERATION 5/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 62.43697953224182 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(5,20)_semi_pNone_gNone took 15.793877840042114 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_tennis_pNone_gNone took 15.843277931213379 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 15.762221813201904 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_none_pNone_gNone took 15.887457132339478 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_full_pNone_gNone took 15.932207345962524 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(24, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=24, bias=True)
)
Datatype: pos_diff_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0001340959 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.3305e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.33599e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 7.6964e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.6386e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.178e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 38.555612087249756
Epoch 1/9
	 Logging train Loss: 6.219e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 9.3756e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 8.7083e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 5.0958e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.0018e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 7.161e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 39.112412214279175
Epoch 2/9
	 Logging train Loss: 3.905e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.765e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.8486e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.8264e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.591e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 5.657e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 39.05810618400574
Epoch 3/9
	 Logging train Loss: 2.23e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.0312e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.3638e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.7983e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.792e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.191e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 38.72389340400696
Epoch 4/9
	 Logging train Loss: 1.8536e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.835e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.1369e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.6745e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.589e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.074e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 38.60924816131592
Epoch 5/9
	 Logging train Loss: 1.7471e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.7813e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.0325e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.6076e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.223e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.852e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 38.96286702156067
Epoch 6/9
	 Logging train Loss: 1.6909e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.83e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.0071e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.6573e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.904e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.644e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 38.906131982803345
Epoch 7/9
	 Logging train Loss: 1.6423e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.7123e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.888e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.5415e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.923e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.791e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 38.632567167282104
Epoch 8/9
	 Logging train Loss: 1.6025e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.7574e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.8095e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.544e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.074e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.057e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 38.787946462631226
Epoch 9/9
	 Logging train Loss: 1.5604e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.7148e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.7276e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.4949e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.633e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.735e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 39.08525991439819
Saved model in  trained_models/gru/data_t(0,0)_r(5,20)_combi_pNone_gNone/'pos_diff_1'_'False'.pth
It took  542.6357862949371  seconds.
----- ITERATION 6/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 62.291815757751465 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(5,20)_semi_pNone_gNone took 15.835397005081177 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_tennis_pNone_gNone took 15.869292974472046 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 15.740293502807617 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_none_pNone_gNone took 15.844327926635742 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_full_pNone_gNone took 15.841470956802368 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(24, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=24, bias=True)
)
Datatype: pos_diff_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0001382972 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.40597e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone â–ˆâ–…â–ƒâ–â–â–â–â–â–â–
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone â–ˆâ–ƒâ–…â–â–‚â–‚â–â–â–‚â–
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone â–ˆâ–ƒâ–„â–‚â–‚â–‚â–â–â–‚â–
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone â–ˆâ–…â–ƒâ–â–â–â–â–â–â–
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone â–ˆâ–…â–ƒâ–â–â–â–â–â–â–
wandb:                                  Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone 0.0
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: ðŸš€ View run jolly-firebrand-169 at: https://wandb.ai/nreints/ThesisFinal1/runs/i8mqws9b
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_172546-i8mqws9b/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_173446-g0b5c6jo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run twilight-water-199
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal1/runs/g0b5c6jo
	 Logging test loss: 1.49053e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 8.2966e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.8245e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.1763e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 38.65184450149536
Epoch 1/9
	 Logging train Loss: 6.3304e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 9.8973e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 9.4816e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 5.2885e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.738e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 4.461e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 38.878336906433105
Epoch 2/9
	 Logging train Loss: 4.1672e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.9572e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 6.0729e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.5677e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 9.992e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 7.877e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 38.85885691642761
Epoch 3/9
	 Logging train Loss: 2.4063e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.2125e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.698e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.9183e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.473e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.867e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 38.63997006416321
Epoch 4/9
	 Logging train Loss: 1.8698e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.055e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.4705e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.7927e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.669e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.161e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 38.486231088638306
Epoch 5/9
	 Logging train Loss: 1.752e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.9703e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.4325e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.7608e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.917e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.552e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 38.44968795776367
Epoch 6/9
	 Logging train Loss: 1.6875e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.94e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.2779e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.6808e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.217e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.933e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 38.294578552246094
Epoch 7/9
	 Logging train Loss: 1.6405e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.8298e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.1057e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.5885e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.594e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.393e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 38.22630429267883
Epoch 8/9
	 Logging train Loss: 1.5938e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.9497e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.2076e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.7111e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.616e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.556e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 38.119505643844604
Epoch 9/9
	 Logging train Loss: 1.5525e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.7772e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.9637e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.5455e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.219e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.297e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 38.3755407333374
Saved model in  trained_models/gru/data_t(0,0)_r(5,20)_combi_pNone_gNone/'pos_diff_1'_'False'.pth
It took  539.5247983932495  seconds.
----- ITERATION 7/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 62.43452429771423 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(5,20)_semi_pNone_gNone took 15.859230756759644 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_tennis_pNone_gNone took 16.183204412460327 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 16.02389359474182 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_none_pNone_gNone took 15.844119787216187 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_full_pNone_gNone took 16.01293444633484 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(24, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=24, bias=True)
)
Datatype: pos_diff_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0001557547 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.39492e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.54446e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 8.4223e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.7093e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.2143e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 38.749653339385986
Epoch 1/9
	 Logging train Loss: 6.4647e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.01369e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 9.9206e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 5.3688e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.468e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 5.443e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 38.94721221923828
Epoch 2/9
	 Logging train Loss: 4.3044e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.9583e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 6.0988e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.3817e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.28e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 5.311e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 38.857818603515625
Epoch 3/9
	 Logging train Loss: 2.5192e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.38e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.9179e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.0354e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.424e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.897e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 38.53159189224243
Epoch 4/9
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone â–ˆâ–…â–ƒâ–‚â–â–â–â–â–â–
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone â–ˆâ–„â–„â–‚â–â–‚â–ƒâ–â–â–
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone â–ˆâ–„â–ƒâ–‚â–‚â–‚â–ƒâ–â–â–
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone â–ˆâ–†â–ƒâ–â–â–â–â–â–â–
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone â–ˆâ–…â–ƒâ–‚â–â–â–â–â–â–
wandb:                                  Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone 0.0
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: ðŸš€ View run twilight-water-199 at: https://wandb.ai/nreints/ThesisFinal1/runs/g0b5c6jo
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_173446-g0b5c6jo/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_174349-ndga72g7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run peachy-breeze-229
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal1/runs/ndga72g7
	 Logging train Loss: 1.8952e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.9906e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.5011e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.7726e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.479e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.084e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 38.70568799972534
Epoch 5/9
	 Logging train Loss: 1.761e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.0377e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.5326e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.8566e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.72e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.432e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 38.82766556739807
Epoch 6/9
	 Logging train Loss: 1.6971e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.128e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.6108e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.9691e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.105e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 4.899e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 38.910022497177124
Epoch 7/9
	 Logging train Loss: 1.656e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.7719e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.1869e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.5957e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.64e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.522e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 40.42161464691162
Epoch 8/9
	 Logging train Loss: 1.6124e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.8379e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.1568e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.6227e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.881e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.88e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 39.40788292884827
Epoch 9/9
	 Logging train Loss: 1.5685e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.7673e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.9984e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.5386e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.288e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.35e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 38.5523042678833
Saved model in  trained_models/gru/data_t(0,0)_r(5,20)_combi_pNone_gNone/'pos_diff_1'_'False'.pth
It took  543.5149610042572  seconds.
----- ITERATION 8/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 62.52331590652466 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(5,20)_semi_pNone_gNone took 15.786958932876587 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_tennis_pNone_gNone took 15.83036994934082 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 15.725103855133057 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_none_pNone_gNone took 15.833448648452759 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_full_pNone_gNone took 15.909770727157593 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(24, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=24, bias=True)
)
Datatype: pos_diff_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0001654686 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.22691e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.52297e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 8.2716e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.9864e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.3954e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 38.626599073410034
Epoch 1/9
	 Logging train Loss: 6.8927e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.9607e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 9.4248e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 5.0907e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 9.037e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 5.761e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 38.91251039505005
Epoch 2/9
	 Logging train Loss: 4.6545e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.509e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 5.9496e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.2585e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.406e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 5.263e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 38.462316274642944
Epoch 3/9
	 Logging train Loss: 2.7659e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.328e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.0018e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.2519e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.52e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 5.972e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 38.32856893539429
Epoch 4/9
	 Logging train Loss: 2.0071e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.2344e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.8271e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.2635e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 9.679e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 8.217e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 38.435232639312744
Epoch 5/9
	 Logging train Loss: 1.834e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.5841e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.1614e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.6034e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.597e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.18e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 38.78943157196045
Epoch 6/9
	 Logging train Loss: 1.7546e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.634e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.2294e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.6926e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.673e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.43e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 38.14145493507385
Epoch 7/9
	 Logging train Loss: 1.7053e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.5581e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.0182e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.5617e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.526e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone â–ˆâ–…â–ƒâ–‚â–‚â–â–â–â–â–
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone â–ˆâ–ƒâ–ƒâ–ƒâ–…â–â–‚â–â–‚â–
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone â–ˆâ–ƒâ–ƒâ–ƒâ–„â–â–‚â–â–â–
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone â–ˆâ–†â–ƒâ–‚â–‚â–â–â–â–â–
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone â–ˆâ–…â–ƒâ–‚â–‚â–â–â–â–â–
wandb:                                  Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone 0.0
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: ðŸš€ View run peachy-breeze-229 at: https://wandb.ai/nreints/ThesisFinal1/runs/ndga72g7
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_174349-ndga72g7/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_175247-qgynzo3v
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run true-elevator-266
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal1/runs/qgynzo3v
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone â–ˆâ–…â–‚â–â–â–â–â–â–â–
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone â–ˆâ–„â–ƒâ–â–‚â–â–‚â–‚â–‚â–
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone â–ˆâ–„â–ƒâ–â–‚â–â–‚â–â–‚â–
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone â–ˆâ–…â–‚â–â–â–â–â–â–â–
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone â–ˆâ–…â–‚â–â–â–â–â–â–â–
wandb:                                  Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone 0.0
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: ðŸš€ View run true-elevator-266 at: https://wandb.ai/nreints/ThesisFinal1/runs/qgynzo3v
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_175247-qgynzo3v/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_180148-0x36qh50
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run grateful-terrain-293
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal1/runs/0x36qh50
	 Logging test loss: 2.327e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 37.807822942733765
Epoch 8/9
	 Logging train Loss: 1.6639e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.5672e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.0338e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.5921e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.165e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.053e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 37.946125984191895
Epoch 9/9
	 Logging train Loss: 1.6144e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.458e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.8608e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.4707e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.058e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.062e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 37.890806913375854
Saved model in  trained_models/gru/data_t(0,0)_r(5,20)_combi_pNone_gNone/'pos_diff_1'_'False'.pth
It took  537.3853130340576  seconds.
----- ITERATION 9/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 62.23489236831665 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(5,20)_semi_pNone_gNone took 15.763951778411865 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_tennis_pNone_gNone took 15.826005458831787 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 15.704537630081177 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_none_pNone_gNone took 15.78573751449585 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_full_pNone_gNone took 15.948764085769653 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(24, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=24, bias=True)
)
Datatype: pos_diff_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0001344567 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.26636e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.3785e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 7.9564e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.5734e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.1304e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 38.397332191467285
Epoch 1/9
	 Logging train Loss: 6.0688e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.4456e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 8.4436e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.9171e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.021e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 5.539e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 38.490997552871704
Epoch 2/9
	 Logging train Loss: 3.7259e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.2503e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.7882e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.7318e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.46e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 4.827e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 38.47943091392517
Epoch 3/9
	 Logging train Loss: 2.2282e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.9283e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.5666e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.8831e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.386e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.968e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 40.49825596809387
Epoch 4/9
	 Logging train Loss: 1.8676e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.8692e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.4355e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.8459e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.274e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.99e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 39.30598282814026
Epoch 5/9
	 Logging train Loss: 1.7567e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.7061e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.2431e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.6807e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.007e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.734e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 38.77056264877319
Epoch 6/9
	 Logging train Loss: 1.6907e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.8682e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.3621e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.8357e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.726e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.555e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 38.493818044662476
Epoch 7/9
	 Logging train Loss: 1.6413e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.7424e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.1983e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.7237e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.73e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.65e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 38.630922079086304
Epoch 8/9
	 Logging train Loss: 1.5984e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.7578e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.1308e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.7157e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.934e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.944e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 38.4563250541687
Epoch 9/9
	 Logging train Loss: 1.5586e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.6514e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.9595e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.5937e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.013e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.136e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 38.4085328578949
Saved model in  trained_models/gru/data_t(0,0)_r(5,20)_combi_pNone_gNone/'pos_diff_1'_'False'.pth
It took  541.4579050540924  seconds.
----- ITERATION 10/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 62.03012681007385 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(5,20)_semi_pNone_gNone took 15.775077819824219 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_tennis_pNone_gNone took 15.832300901412964 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 15.532345533370972 seconds.
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone â–ˆâ–…â–ƒâ–â–â–â–â–â–â–
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone â–ˆâ–ƒâ–„â–‚â–‚â–‚â–â–â–â–‚
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone â–ˆâ–ƒâ–„â–‚â–‚â–â–â–â–â–‚
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone â–ˆâ–…â–ƒâ–â–â–â–â–â–â–
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone â–ˆâ–…â–‚â–â–â–â–â–â–â–
wandb:                                  Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone 0.0
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: ðŸš€ View run grateful-terrain-293 at: https://wandb.ai/nreints/ThesisFinal1/runs/0x36qh50
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_180148-0x36qh50/logs
The dataloader for data/data_t(0,0)_r(5,20)_none_pNone_gNone took 15.810929536819458 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_full_pNone_gNone took 15.919323921203613 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(24, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=24, bias=True)
)
Datatype: pos_diff_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0001434102 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.39858e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.51285e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 7.9572e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.6744e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.1386e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 38.3212366104126
Epoch 1/9
	 Logging train Loss: 6.3312e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 9.5832e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 9.2354e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.9109e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.918e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 4.2e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 38.83842849731445
Epoch 2/9
	 Logging train Loss: 4.0505e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.4458e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 5.6034e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.1191e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.736e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 5.978e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 38.45266652107239
Epoch 3/9
	 Logging train Loss: 2.3906e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.1908e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.6388e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.8574e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.489e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.154e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 38.39606547355652
Epoch 4/9
	 Logging train Loss: 1.8718e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.0044e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.4241e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.7431e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.588e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.362e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 38.46311140060425
Epoch 5/9
	 Logging train Loss: 1.7481e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.9011e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.261e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.6604e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.147e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.019e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 38.68749690055847
Epoch 6/9
	 Logging train Loss: 1.6804e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.817e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.1282e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.5483e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.308e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.216e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 38.602657318115234
Epoch 7/9
	 Logging train Loss: 1.639e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.8527e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.1129e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.5829e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.887e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.893e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 38.49008107185364
Epoch 8/9
	 Logging train Loss: 1.5974e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.8223e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.0864e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.5521e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.671e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.758e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 38.65778112411499
Epoch 9/9
	 Logging train Loss: 1.5583e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.9209e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.0868e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.6425e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.663e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.824e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 37.833580493927
Saved model in  trained_models/gru/data_t(0,0)_r(5,20)_combi_pNone_gNone/'pos_diff_1'_'False'.pth
It took  537.7970306873322  seconds.

JOB STATISTICS
==============
Job ID: 2971265
Array Job ID: 2971258_7
Cluster: snellius
User/Group: nreints/nreints
State: COMPLETED (exit code 0)
Nodes: 1
Cores per node: 18
CPU Utilized: 05:30:42
CPU Efficiency: 20.27% of 1-03:11:06 core-walltime
Job Wall-clock time: 01:30:37
Memory Utilized: 10.58 GB
Memory Efficiency: 0.00% of 0.00 MB
