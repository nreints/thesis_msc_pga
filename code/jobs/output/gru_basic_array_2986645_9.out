wandb: Currently logged in as: nreints. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230629_111856-qzm67lc3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run clean-capybara-22
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/qzm67lc3
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone â–ˆâ–„â–‚â–‚â–ƒâ–ƒâ–†â–‚â–â–ƒ
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone â–ˆâ–„â–‚â–‚â–‚â–‚â–ƒâ–â–â–‚
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone â–ˆâ–„â–‚â–‚â–‚â–‚â–ƒâ–â–â–‚
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone â–ˆâ–ƒâ–‚â–‚â–ƒâ–…â–ˆâ–‚â–â–„
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone â–ˆâ–ƒâ–‚â–‚â–ƒâ–„â–ˆâ–‚â–â–„
wandb:                                  Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone 1e-05
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone 2e-05
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone 3e-05
wandb:                                  Train loss 1e-05
wandb: 
wandb: ðŸš€ View run clean-capybara-22 at: https://wandb.ai/nreints/ThesisFinal2/runs/qzm67lc3
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230629_111856-qzm67lc3/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230629_112638-lvu48zog
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run young-butterfly-39
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/lvu48zog
Training on dataset: data_t(0,0)_r(5,20)_combi_pNone_gNone
Testing on 5 datasets: ['data_t(0,0)_r(5,20)_semi_pNone_gNone', 'data_t(0,0)_r(5,20)_full_pNone_gNone', 'data_t(0,0)_r(5,20)_combi_pNone_gNone', 'data_t(0,0)_r(5,20)_tennis_pNone_gNone', 'data_t(0,0)_r(5,20)_none_pNone_gNone']
Focussing on identity: False
Using extra input: False
Using fr-fr as reference point.
----- ITERATION 1/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 51.658353328704834 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(5,20)_semi_pNone_gNone took 13.553755283355713 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_full_pNone_gNone took 12.287929773330688 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 12.347756624221802 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_tennis_pNone_gNone took 13.25789499282837 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_none_pNone_gNone took 12.362557888031006 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0166423433 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.40361e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.4391e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.66874e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.6923e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.7986e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 34.500651836395264
Epoch 1/9
	 Logging train Loss: 2.53814e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.04742e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.4504e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.75036e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.12218e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.5672e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 32.970306396484375
Epoch 2/9
	 Logging train Loss: 1.38342e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.70813e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 8.295e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.18279e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.75562e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 9.346e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 32.75416088104248
Epoch 3/9
	 Logging train Loss: 1.00747e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.52556e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.897e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 9.6824e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.56231e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 5.927e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 32.62703323364258
Epoch 4/9
	 Logging train Loss: 1.02088e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.16332e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 5.319e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.299e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.25329e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 6.316e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 33.05574154853821
Epoch 5/9
	 Logging train Loss: 1.41623e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.84204e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 6.736e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.6798e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.92428e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 7.772e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 32.941641330718994
Epoch 6/9
	 Logging train Loss: 1.99696e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.54901e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.2828e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.64588e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.85779e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.3818e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 32.97585463523865
Epoch 7/9
	 Logging train Loss: 1.81171e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.65321e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.511e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 9.7223e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.71926e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.335e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 32.75671362876892
Epoch 8/9
	 Logging train Loss: 1.9304e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.11474e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.545e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 6.462e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.13984e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.282e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 32.835813760757446
Epoch 9/9
	 Logging train Loss: 1.37545e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.34129e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 5.779e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.36391e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.53354e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 6.491e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 32.90260720252991
Saved model in  trained_models/gru/data_t(0,0)_r(5,20)_combi_pNone_gNone/'quat_1'_'False'.pth
It took  463.1850583553314  seconds.
----- ITERATION 2/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 51.119003772735596 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(5,20)_semi_pNone_gNone took 13.071678161621094 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_full_pNone_gNone took 13.115847110748291 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 12.78253436088562 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_tennis_pNone_gNone took 13.077554702758789 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_none_pNone_gNone took 13.081168413162231 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0058247652 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.39793e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.673e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.69631e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.42598e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.8573e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 33.3246636390686
Epoch 1/9
	 Logging train Loss: 1.92513e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.76174e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.2134e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone â–ˆâ–„â–‚â–‚â–‚â–ƒâ–â–â–†â–
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone â–ˆâ–ƒâ–‚â–â–â–‚â–â–â–ƒâ–
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone â–ˆâ–ƒâ–‚â–â–â–‚â–â–â–ƒâ–
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone â–…â–ƒâ–‚â–‚â–ƒâ–„â–‚â–â–ˆâ–
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone â–„â–ƒâ–‚â–‚â–‚â–„â–â–â–ˆâ–
wandb:                                  Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone 1e-05
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone 1e-05
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone 1e-05
wandb:                                  Train loss 1e-05
wandb: 
wandb: ðŸš€ View run young-butterfly-39 at: https://wandb.ai/nreints/ThesisFinal2/runs/lvu48zog
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230629_112638-lvu48zog/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230629_113419-hd5hzr30
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run super-sponge-56
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/hd5hzr30
	 Logging test loss: 1.52147e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.77721e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.3198e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 33.09657526016235
Epoch 2/9
	 Logging train Loss: 1.21279e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.56035e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 7.471e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.0058e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.56516e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 8.44e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 33.284523725509644
Epoch 3/9
	 Logging train Loss: 9.4029e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.45492e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.956e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 8.4979e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.4658e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.898e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 33.28820252418518
Epoch 4/9
	 Logging train Loss: 1.07943e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.67604e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.525e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 9.0978e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.7056e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.358e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 33.14663290977478
Epoch 5/9
	 Logging train Loss: 2.07008e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.16411e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.804e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.15293e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.29677e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 5.503e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 32.979820013046265
Epoch 6/9
	 Logging train Loss: 2.50339e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.30188e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.502e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 7.1057e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.3212e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.258e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 33.185030460357666
Epoch 7/9
	 Logging train Loss: 1.40715e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.16789e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.044e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 6.2552e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.18786e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.741e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 32.996676206588745
Epoch 8/9
	 Logging train Loss: 1.60202e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.69506e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.0882e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.94494e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.08169e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.1141e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 32.991166830062866
Epoch 9/9
	 Logging train Loss: 1.38628e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.0819e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.755e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 5.6605e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.11452e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.33e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 33.07883882522583
Saved model in  trained_models/gru/data_t(0,0)_r(5,20)_combi_pNone_gNone/'quat_1'_'False'.pth
It took  460.64979887008667  seconds.
----- ITERATION 3/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 49.07022666931152 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(5,20)_semi_pNone_gNone took 12.95534062385559 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_full_pNone_gNone took 13.011912822723389 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 12.513862371444702 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_tennis_pNone_gNone took 13.017912864685059 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_none_pNone_gNone took 13.055253505706787 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0174485706 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.14569e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.0756e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.46641e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.12737e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.2595e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 33.856337785720825
Epoch 1/9
	 Logging train Loss: 2.47065e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.12319e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.331e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.82247e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.03361e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.4325e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 32.98824381828308
Epoch 2/9
	 Logging train Loss: 1.47296e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.839e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 8.885e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.24825e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.75046e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 9.946e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 33.0168251991272
Epoch 3/9
	 Logging train Loss: 1.03748e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.71777e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 5.327e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.01032e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.63074e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 6.344e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 33.22250723838806
Epoch 4/9
	 Logging train Loss: 8.8876e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.61136e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.882e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 9.0913e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.52581e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.873e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 33.244404792785645
Epoch 5/9
	 Logging train Loss: 1.21822e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.73211e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone â–ˆâ–„â–‚â–‚â–‚â–‚â–†â–â–â–
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone â–ˆâ–„â–ƒâ–‚â–â–â–„â–â–â–
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone â–ˆâ–„â–ƒâ–‚â–â–â–„â–â–â–
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone â–‡â–ƒâ–‚â–‚â–‚â–‚â–ˆâ–â–â–
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone â–†â–‚â–‚â–‚â–â–‚â–ˆâ–â–â–
wandb:                                  Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone 1e-05
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone 1e-05
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone 1e-05
wandb:                                  Train loss 2e-05
wandb: 
wandb: ðŸš€ View run super-sponge-56 at: https://wandb.ai/nreints/ThesisFinal2/runs/hd5hzr30
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230629_113419-hd5hzr30/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230629_114158-b0m6qftt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run distinctive-bush-72
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/b0m6qftt
	 Logging test loss: 2.591e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 9.509e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.65106e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.49e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 33.27078700065613
Epoch 6/9
	 Logging train Loss: 1.88499e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.88201e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.3355e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.72616e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.20184e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.3609e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 33.30124092102051
Epoch 7/9
	 Logging train Loss: 2.19927e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.46428e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.251e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 8.0066e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.40889e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.016e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 33.1207058429718
Epoch 8/9
	 Logging train Loss: 1.98975e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.36584e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.958e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 7.4678e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.33288e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.66e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 33.32267928123474
Epoch 9/9
	 Logging train Loss: 1.60915e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.30221e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.778e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 7.0691e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.27306e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.402e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 33.42388415336609
Saved model in  trained_models/gru/data_t(0,0)_r(5,20)_combi_pNone_gNone/'quat_1'_'False'.pth
It took  458.94712495803833  seconds.
----- ITERATION 4/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 49.37299633026123 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(5,20)_semi_pNone_gNone took 12.916667699813843 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_full_pNone_gNone took 12.887611865997314 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 12.585115194320679 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_tennis_pNone_gNone took 12.888758182525635 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_none_pNone_gNone took 12.876730918884277 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0095525011 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.51768e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.5382e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.22849e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.47655e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.7476e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 33.29262852668762
Epoch 1/9
	 Logging train Loss: 2.40669e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.00727e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.3635e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.86165e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.91186e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.4874e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 33.15292930603027
Epoch 2/9
	 Logging train Loss: 1.52656e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.73294e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 8.714e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.19317e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.63169e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 9.843e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 33.203155279159546
Epoch 3/9
	 Logging train Loss: 1.06236e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.93517e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 6.1e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.0426e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.84798e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 7.238e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 33.03737783432007
Epoch 4/9
	 Logging train Loss: 9.0869e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.53629e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.213e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 7.8694e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.4403e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.257e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 33.09089636802673
Epoch 5/9
	 Logging train Loss: 1.74053e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.32321e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.072e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 6.6051e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.22987e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.019e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 33.41000843048096
Epoch 6/9
	 Logging train Loss: 2.64152e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.07376e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 6.759e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.47931e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.10005e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 7.977e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 33.257781744003296
Epoch 7/9
	 Logging train Loss: 2.45718e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.70166e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.115e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 8.12e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.63566e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.025e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 33.16919445991516
Epoch 8/9
	 Logging train Loss: 2.06885e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.06806e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.713e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 5.2114e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 9.9804e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.486e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 33.3205189704895
Epoch 9/9
	 Logging train Loss: 1.80467e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone â–‡â–„â–ƒâ–‚â–‚â–â–ƒâ–‚â–â–ˆ
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone â–ˆâ–ƒâ–‚â–‚â–â–â–‚â–â–â–…
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone â–ˆâ–ƒâ–‚â–‚â–â–â–‚â–â–â–…
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone â–„â–‚â–‚â–‚â–‚â–â–ƒâ–‚â–â–ˆ
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone â–„â–‚â–‚â–‚â–â–â–ƒâ–‚â–â–ˆ
wandb:                                  Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone 3e-05
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone 7e-05
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone 8e-05
wandb:                                  Train loss 2e-05
wandb: 
wandb: ðŸš€ View run distinctive-bush-72 at: https://wandb.ai/nreints/ThesisFinal2/runs/b0m6qftt
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230629_114158-b0m6qftt/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230629_114937-495j37kw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run usual-moon-87
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/495j37kw
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone â–ˆâ–ƒâ–‚â–â–‚â–‚â–‡â–â–â–
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone â–ˆâ–ƒâ–‚â–â–â–‚â–„â–â–â–
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone â–ˆâ–ƒâ–‚â–â–â–‚â–„â–â–â–
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone â–†â–‚â–‚â–â–‚â–ƒâ–ˆâ–â–â–
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone â–†â–‚â–â–â–‚â–ƒâ–ˆâ–â–â–
wandb:                                  Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone 1e-05
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone 1e-05
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone 1e-05
wandb:                                  Train loss 2e-05
wandb: 
wandb: ðŸš€ View run usual-moon-87 at: https://wandb.ai/nreints/ThesisFinal2/runs/495j37kw
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230629_114937-495j37kw/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230629_115715-p8fmoy8u
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run distinctive-dragon-102
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/p8fmoy8u
	 Logging test loss: 7.35657e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.894e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.48665e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.71713e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.0596e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 33.11896109580994
Saved model in  trained_models/gru/data_t(0,0)_r(5,20)_combi_pNone_gNone/'quat_1'_'False'.pth
It took  459.08704447746277  seconds.
----- ITERATION 5/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 49.40532302856445 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(5,20)_semi_pNone_gNone took 12.874455451965332 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_full_pNone_gNone took 12.926474332809448 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 12.615696430206299 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_tennis_pNone_gNone took 12.85541558265686 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_none_pNone_gNone took 12.860013961791992 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0122102508 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.3613e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.1286e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.07735e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.6127e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.5103e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 33.45603537559509
Epoch 1/9
	 Logging train Loss: 2.77671e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.08628e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.39e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.65385e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.04776e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.5466e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 34.122119426727295
Epoch 2/9
	 Logging train Loss: 1.42205e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.70494e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 6.71e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.03238e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.63825e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 7.897e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 33.10797190666199
Epoch 3/9
	 Logging train Loss: 1.02382e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.56817e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.032e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 8.2174e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.50597e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 5.166e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 33.04246234893799
Epoch 4/9
	 Logging train Loss: 9.3504e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.80124e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.641e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 8.8965e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.75196e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.718e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 32.847105979919434
Epoch 5/9
	 Logging train Loss: 1.57513e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.71916e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 6.193e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.31279e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.73975e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 7.302e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 33.22113108634949
Epoch 6/9
	 Logging train Loss: 1.94822e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.18304e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.0897e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.42905e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.46513e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.1877e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 33.306410789489746
Epoch 7/9
	 Logging train Loss: 2.0757e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.265e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.959e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 6.0876e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.21463e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.843e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 33.18964219093323
Epoch 8/9
	 Logging train Loss: 2.08616e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.50973e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.892e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 7.1571e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.49556e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.702e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 33.20490908622742
Epoch 9/9
	 Logging train Loss: 1.5592e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.26622e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.957e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 6.0145e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.24965e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.702e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 33.151443004608154
Saved model in  trained_models/gru/data_t(0,0)_r(5,20)_combi_pNone_gNone/'quat_1'_'False'.pth
It took  457.99986124038696  seconds.
----- ITERATION 6/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 50.004645586013794 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(5,20)_semi_pNone_gNone took 12.955923795700073 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_full_pNone_gNone took 12.954416513442993 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 12.518186569213867 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_tennis_pNone_gNone took 12.90824818611145 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_none_pNone_gNone took 12.958159685134888 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0278455392 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.64914e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.7415e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.41128e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.97358e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 5.0516e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 33.14728903770447
Epoch 1/9
	 Logging train Loss: 2.34319e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone â–ˆâ–ƒâ–‚â–‚â–‡â–„â–â–‚â–…â–‚
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone â–ˆâ–ƒâ–‚â–‚â–ƒâ–‚â–â–â–‚â–‚
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone â–ˆâ–ƒâ–‚â–‚â–ƒâ–‚â–â–â–‚â–‚
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone â–†â–‚â–‚â–‚â–ˆâ–„â–â–ƒâ–…â–ƒ
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone â–†â–‚â–‚â–‚â–ˆâ–„â–â–ƒâ–†â–ƒ
wandb:                                  Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone 1e-05
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone 2e-05
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone 2e-05
wandb:                                  Train loss 1e-05
wandb: 
wandb: ðŸš€ View run distinctive-dragon-102 at: https://wandb.ai/nreints/ThesisFinal2/runs/p8fmoy8u
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230629_115715-p8fmoy8u/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230629_120454-yh0vp7ge
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run leafy-forest-117
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/yh0vp7ge
	 Logging test loss: 1.84316e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.659e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.70589e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.98417e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.8027e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 33.35043168067932
Epoch 2/9
	 Logging train Loss: 1.31858e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.77423e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.0246e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.35387e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.90916e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.1496e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 33.27532124519348
Epoch 3/9
	 Logging train Loss: 1.03255e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.5731e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 6.141e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.12842e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.70517e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 7.303e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 33.12837743759155
Epoch 4/9
	 Logging train Loss: 1.10026e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.6597e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.6474e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.06542e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.31333e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.8162e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 33.09773540496826
Epoch 5/9
	 Logging train Loss: 1.16175e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.67205e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 7.142e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.79114e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.97964e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 8.447e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 33.231905460357666
Epoch 6/9
	 Logging train Loss: 1.62407e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.22487e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.154e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 8.3912e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.31836e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.105e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 33.098459005355835
Epoch 7/9
	 Logging train Loss: 1.64748e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.97761e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.683e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.29765e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.21212e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 5.716e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 33.079578161239624
Epoch 8/9
	 Logging train Loss: 1.54619e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.42347e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 9.762e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.20187e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.96137e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.1069e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 33.316529512405396
Epoch 9/9
	 Logging train Loss: 1.30759e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.08796e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 6.411e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.36073e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.36084e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 7.315e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 33.08596968650818
Saved model in  trained_models/gru/data_t(0,0)_r(5,20)_combi_pNone_gNone/'quat_1'_'False'.pth
It took  458.9829914569855  seconds.
----- ITERATION 7/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 50.16845631599426 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(5,20)_semi_pNone_gNone took 12.823743343353271 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_full_pNone_gNone took 12.837993860244751 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 12.710791110992432 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_tennis_pNone_gNone took 12.843508243560791 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_none_pNone_gNone took 12.860209941864014 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0143734151 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.89959e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.782e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.82384e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.08398e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.9604e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 33.45702528953552
Epoch 1/9
	 Logging train Loss: 2.05772e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.06241e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.2071e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.60663e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.17713e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.314e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 34.2424213886261
Epoch 2/9
	 Logging train Loss: 1.26959e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.81441e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 6.661e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.14203e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.91708e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 7.701e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 33.21014213562012
Epoch 3/9
	 Logging train Loss: 1.04072e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.66597e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 5.782e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 9.9417e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.74378e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 6.793e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 33.14664554595947
Epoch 4/9
	 Logging train Loss: 1.25321e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.74878e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.526e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 9.988e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.84573e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.468e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 33.09568214416504
Epoch 5/9
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone â–‡â–ƒâ–â–â–â–ƒâ–ˆâ–‚â–ƒâ–„
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone â–ˆâ–ƒâ–‚â–‚â–â–‚â–…â–â–‚â–ƒ
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone â–ˆâ–ƒâ–‚â–‚â–â–‚â–„â–â–‚â–ƒ
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone â–ƒâ–‚â–â–â–â–ƒâ–ˆâ–‚â–ƒâ–„
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone â–ƒâ–‚â–â–â–â–ƒâ–ˆâ–‚â–ƒâ–„
wandb:                                  Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone 2e-05
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone 3e-05
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone 4e-05
wandb:                                  Train loss 1e-05
wandb: 
wandb: ðŸš€ View run leafy-forest-117 at: https://wandb.ai/nreints/ThesisFinal2/runs/yh0vp7ge
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230629_120454-yh0vp7ge/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230629_121235-xq926bhq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run misunderstood-waterfall-134
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/xq926bhq
	 Logging train Loss: 1.52826e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.90366e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 7.298e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.60866e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.21128e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 7.985e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 33.444007873535156
Epoch 6/9
	 Logging train Loss: 1.81968e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.85613e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.6664e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.16227e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.72532e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.6993e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 33.20868110656738
Epoch 7/9
	 Logging train Loss: 1.84728e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.14488e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.331e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.16543e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.30924e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 5.002e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 33.41131806373596
Epoch 8/9
	 Logging train Loss: 1.97275e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.11221e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 8.177e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.69207e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.44471e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 8.657e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 33.57668495178223
Epoch 9/9
	 Logging train Loss: 1.33542e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.35136e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 9.673e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.82047e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.68333e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.0044e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 33.52830624580383
Saved model in  trained_models/gru/data_t(0,0)_r(5,20)_combi_pNone_gNone/'quat_1'_'False'.pth
It took  461.11639738082886  seconds.
----- ITERATION 8/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 49.66033601760864 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(5,20)_semi_pNone_gNone took 12.858963012695312 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_full_pNone_gNone took 12.942982912063599 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 12.65293025970459 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_tennis_pNone_gNone took 12.854326963424683 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_none_pNone_gNone took 12.872654676437378 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0218547955 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.66983e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.9636e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.43875e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.76484e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.1324e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 33.07540774345398
Epoch 1/9
	 Logging train Loss: 2.05766e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.97371e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 9.947e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.46478e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.99041e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.1207e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 33.24799156188965
Epoch 2/9
	 Logging train Loss: 1.29167e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.76464e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 5.978e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 9.9734e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.75837e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 7.111e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 33.13283157348633
Epoch 3/9
	 Logging train Loss: 9.889e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.6148e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.834e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 8.292e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.59682e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.911e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 33.00152230262756
Epoch 4/9
	 Logging train Loss: 8.8439e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.54768e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.412e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 7.7911e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.54909e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.423e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 33.154919147491455
Epoch 5/9
	 Logging train Loss: 1.02351e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.34606e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.768e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.20388e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.55408e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 5.961e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 33.32035446166992
Epoch 6/9
	 Logging train Loss: 1.84145e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.46764e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.121e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 7.3496e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.48914e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.034e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 33.14637589454651
Epoch 7/9
	 Logging train Loss: 1.85648e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.44894e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.6393e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.41994e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.40063e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.8327e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 33.153237104415894
Epoch 8/9
	 Logging train Loss: 1.98453e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.61009e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.978e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 8.0583e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.68058e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.834e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone â–…â–ƒâ–‚â–â–â–‚â–â–ˆâ–â–‚
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone â–ˆâ–„â–ƒâ–‚â–‚â–‚â–â–‡â–â–‚
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone â–ˆâ–„â–ƒâ–‚â–‚â–‚â–â–‡â–â–‚
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone â–ƒâ–‚â–â–â–â–‚â–â–ˆâ–â–‚
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone â–ƒâ–‚â–â–â–â–‚â–â–ˆâ–â–‚
wandb:                                  Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone 1e-05
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone 2e-05
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone 2e-05
wandb:                                  Train loss 1e-05
wandb: 
wandb: ðŸš€ View run misunderstood-waterfall-134 at: https://wandb.ai/nreints/ThesisFinal2/runs/xq926bhq
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230629_121235-xq926bhq/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230629_122012-7eim2t4s
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run exalted-lion-147
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/7eim2t4s
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone â–ˆâ–…â–ƒâ–‚â–‚â–â–â–†â–â–
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone â–ˆâ–„â–ƒâ–‚â–‚â–â–â–…â–â–
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone â–ˆâ–„â–ƒâ–‚â–‚â–â–â–…â–â–
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone â–„â–ƒâ–‚â–‚â–‚â–â–‚â–ˆâ–â–‚
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone â–„â–ƒâ–‚â–‚â–‚â–â–‚â–ˆâ–â–‚
wandb:                                  Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone 1e-05
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone 1e-05
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone 1e-05
wandb:                                  Train loss 2e-05
wandb: 
wandb: ðŸš€ View run exalted-lion-147 at: https://wandb.ai/nreints/ThesisFinal2/runs/7eim2t4s
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230629_122012-7eim2t4s/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230629_122751-143u4hbr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stilted-butterfly-163
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/143u4hbr
		--> Epoch time; 33.473347425460815
Epoch 9/9
	 Logging train Loss: 1.24256e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.90252e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.853e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 9.866e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.14969e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.698e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 33.21841073036194
Saved model in  trained_models/gru/data_t(0,0)_r(5,20)_combi_pNone_gNone/'quat_1'_'False'.pth
It took  457.43763542175293  seconds.
----- ITERATION 9/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 50.028318643569946 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(5,20)_semi_pNone_gNone took 12.860137462615967 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_full_pNone_gNone took 12.83116602897644 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 12.712854385375977 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_tennis_pNone_gNone took 12.83978271484375 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_none_pNone_gNone took 12.746731758117676 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0077809077 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.5728e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.1261e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.79698e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.73916e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.2627e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 33.1460325717926
Epoch 1/9
	 Logging train Loss: 2.13017e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.89807e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.111e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.66987e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.97947e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.2266e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 33.87668013572693
Epoch 2/9
	 Logging train Loss: 1.42312e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.6685e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 6.546e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.11948e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.7248e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 7.642e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 33.410916328430176
Epoch 3/9
	 Logging train Loss: 1.09722e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.56438e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.7e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 8.7928e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.61109e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 5.75e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 32.987035512924194
Epoch 4/9
	 Logging train Loss: 9.9414e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.53482e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.706e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 8.0311e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.59916e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.68e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 33.225433111190796
Epoch 5/9
	 Logging train Loss: 2.56519e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.25792e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.167e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 6.4902e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.28572e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.074e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 33.2271568775177
Epoch 6/9
	 Logging train Loss: 2.56318e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.31259e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.18e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 6.6345e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.34862e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.051e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 33.246829986572266
Epoch 7/9
	 Logging train Loss: 1.85265e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.13183e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.143e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.05433e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.7358e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.2547e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 32.964722871780396
Epoch 8/9
	 Logging train Loss: 2.03758e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.0474e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.542e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 5.1982e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.07591e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.267e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 33.13018321990967
Epoch 9/9
	 Logging train Loss: 1.61453e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.36579e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.419e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 6.6741e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.4665e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.123e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 33.12367248535156
Saved model in  trained_models/gru/data_t(0,0)_r(5,20)_combi_pNone_gNone/'quat_1'_'False'.pth
It took  458.96160888671875  seconds.
----- ITERATION 10/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 49.88879060745239 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(5,20)_semi_pNone_gNone took 12.770121574401855 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_full_pNone_gNone took 12.902905464172363 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 12.675282716751099 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_tennis_pNone_gNone took 12.812193155288696 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_none_pNone_gNone took 12.853991270065308 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0113862194 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.17741e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.1717e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.51435e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.84034e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.4046e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone â–‚â–â–â–â–â–â–ˆâ–â–â–‚
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone â–„â–‚â–â–â–â–‚â–ˆâ–â–â–‚
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone â–„â–‚â–â–â–â–‚â–ˆâ–â–â–‚
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone â–‚â–â–â–â–â–â–ˆâ–â–â–‚
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone â–‚â–â–â–â–â–â–ˆâ–â–â–‚
wandb:                                  Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone 3e-05
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone 6e-05
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone 7e-05
wandb:                                  Train loss 2e-05
wandb: 
wandb: ðŸš€ View run stilted-butterfly-163 at: https://wandb.ai/nreints/ThesisFinal2/runs/143u4hbr
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230629_122751-143u4hbr/logs
		--> Epoch time; 33.06120491027832
Epoch 1/9
	 Logging train Loss: 2.53609e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.97127e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.3585e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.75786e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.15827e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.5115e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 33.228251934051514
Epoch 2/9
	 Logging train Loss: 1.51952e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.77506e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 8.386e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.18124e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.93186e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 9.749e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 33.30341196060181
Epoch 3/9
	 Logging train Loss: 1.11087e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.6361e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 5.353e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 9.3538e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.77961e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 6.655e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 33.07522511482239
Epoch 4/9
	 Logging train Loss: 1.0131e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.35041e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 6.083e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.27276e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.64763e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 7.273e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 33.00289702415466
Epoch 5/9
	 Logging train Loss: 1.58757e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.0858e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.0994e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.70406e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.67254e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.1921e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 33.33560824394226
Epoch 6/9
	 Logging train Loss: 2.0246e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0003087949 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 9.4441e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0001729972 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0003806104 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 9.4453e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 33.13128852844238
Epoch 7/9
	 Logging train Loss: 2.19247e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.71032e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.483e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 9.0563e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.91443e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.395e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 33.199610471725464
Epoch 8/9
	 Logging train Loss: 1.9756e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.85781e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.485e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 9.8128e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.0952e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.388e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 33.288474798202515
Epoch 9/9
	 Logging train Loss: 1.79585e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.53909e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.7213e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.00901e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.71976e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.7628e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 33.15182590484619
Saved model in  trained_models/gru/data_t(0,0)_r(5,20)_combi_pNone_gNone/'quat_1'_'False'.pth
It took  458.42161655426025  seconds.

JOB STATISTICS
==============
Job ID: 2986690
Array Job ID: 2986645_9
Cluster: snellius
User/Group: nreints/nreints
State: RUNNING
Nodes: 1
Cores per node: 18
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 23:04:12 core-walltime
Job Wall-clock time: 01:16:54
Memory Utilized: 0.00 MB (estimated maximum)
Memory Efficiency: 0.00% of 0.00 MB (0.00 MB/node)
WARNING: Efficiency statistics may be misleading for RUNNING jobs.
