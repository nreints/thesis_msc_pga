wandb: Currently logged in as: nreints. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230329_135636-vyv5ta8i
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run jolly-pyramid-530
wandb: ⭐️ View project at https://wandb.ai/nreints/test
wandb: 🚀 View run at https://wandb.ai/nreints/test/runs/vyv5ta8i
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.031 MB of 0.031 MB uploaded (0.000 MB deduped)wandb: \ 0.031 MB of 0.031 MB uploaded (0.000 MB deduped)wandb: | 0.031 MB of 0.031 MB uploaded (0.000 MB deduped)wandb: / 0.031 MB of 0.031 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:                                                  Epoch ▁▂▃▃▄▅▆▆▇█
wandb: Test loss t(5, 20)_r(0, 0)_semi_pNone_gNone, MSELoss() █▃▂▃▂▂▁▁▁▁▁
wandb:                                             Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                                  Epoch 9
wandb: Test loss t(5, 20)_r(0, 0)_semi_pNone_gNone, MSELoss() 0.0007
wandb:                                             Train loss 0.00981
wandb: 
wandb: 🚀 View run jolly-pyramid-530 at: https://wandb.ai/nreints/test/runs/vyv5ta8i
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230329_135636-vyv5ta8i/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230329_140600-pa0m2j8o
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fresh-terrain-556
wandb: ⭐️ View project at https://wandb.ai/nreints/test
wandb: 🚀 View run at https://wandb.ai/nreints/test/runs/pa0m2j8o
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                                  Epoch ▁▂▃▃▄▅▆▆▇█
wandb: Test loss t(5, 20)_r(0, 0)_semi_pNone_gNone, MSELoss() █▃▂▁▁▁▁▂▁▁▁
wandb:                                             Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                                  Epoch 9
wandb: Test loss t(5, 20)_r(0, 0)_semi_pNone_gNone, MSELoss() 0.00148
wandb:                                             Train loss 0.0086
wandb: 
wandb: 🚀 View run fresh-terrain-556 at: https://wandb.ai/nreints/test/runs/pa0m2j8o
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230329_140600-pa0m2j8o/logs
Running for data type: log_dualQ
----- ITERATION 1/2 ------
Number of train simulations: 1600
Number of test simulations: 400
-- Finished Train Dataloader --
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(6, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=6, bias=True)
)
-- Started Training --
Epoch 0
	 Logging train Loss: 4.3267299107 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss: 0.14995792508125305 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 51.3487229347229
Epoch 1
	 Logging train Loss: 0.0871390634 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss: 0.047773219645023346 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 48.959824323654175
Epoch 2
	 Logging train Loss: 0.037080533 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss: 0.026381056755781174 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 48.95515036582947
Epoch 3
	 Logging train Loss: 0.0235133356 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss: 0.034633830189704895 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 49.54221868515015
Epoch 4
	 Logging train Loss: 0.0169647405 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss: 0.013790751807391644 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 49.36305022239685
Epoch 5
	 Logging train Loss: 0.0156328 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss: 0.013961332850158215 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 49.69261431694031
Epoch 6
	 Logging train Loss: 0.0092701899 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss: 0.0014685159549117088 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 49.590699672698975
Epoch 7
	 Logging train Loss: 0.0104364222 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss: 0.002379960147663951 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 49.38642883300781
Epoch 8
	 Logging train Loss: 0.0092969043 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss: 0.0008282755152322352 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 49.532655239105225
Epoch 9
	 Logging train Loss: 0.0098112823 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss: 0.0007033772417344153 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 49.56464743614197
	 Logging test loss: 0.0007037236937321723 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
It took  565.1748712062836  seconds.
----- ITERATION 2/2 ------
Number of train simulations: 1600
Number of test simulations: 400
-- Finished Train Dataloader --
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(6, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=6, bias=True)
)
-- Started Training --
Epoch 0
	 Logging train Loss: 4.0524133089 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss: 0.14892995357513428 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 50.164649963378906
Epoch 1
	 Logging train Loss: 0.0903502542 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss: 0.051046788692474365 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 49.590336084365845
Epoch 2
	 Logging train Loss: 0.0395439769 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss: 0.01627778261899948 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 49.17134976387024
Epoch 3
	 Logging train Loss: 0.0235327732 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss: 0.008794453926384449 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 49.592002630233765
Epoch 4
	 Logging train Loss: 0.0155225316 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss: 0.010249053128063679 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 49.64402413368225
Epoch 5
	 Logging train Loss: 0.0129068792 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss: 0.004192403517663479 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 49.48483610153198
Epoch 6
	 Logging train Loss: 0.0140256525 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss: 0.00212736870162189 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 49.82004499435425
Epoch 7
	 Logging train Loss: 0.009805058 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss: 0.029729526489973068 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 49.558562994003296
Epoch 8
	 Logging train Loss: 0.0085062452 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss: 0.007114862557500601 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 49.38114857673645
Epoch 9
	 Logging train Loss: 0.0085953826 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss: 0.0014819945208728313 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 49.798269510269165
	 Logging test loss: 0.0014829954598098993 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
It took  561.162248134613  seconds.

JOB STATISTICS
==============
Job ID: 2514861
Array Job ID: 2514848_13
Cluster: snellius
User/Group: nreints/nreints
State: COMPLETED (exit code 0)
Nodes: 1
Cores per node: 18
CPU Utilized: 03:59:48
CPU Efficiency: 70.24% of 05:41:24 core-walltime
Job Wall-clock time: 00:18:58
Memory Utilized: 24.77 GB
Memory Efficiency: 79.26% of 31.25 GB
