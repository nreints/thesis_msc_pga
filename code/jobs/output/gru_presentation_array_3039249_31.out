wandb: Currently logged in as: nreints. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_231701-3tsfk0zm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run electric-field-1148
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/3tsfk0zm
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue █▃▂▂▁▁▂▁▁▁
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue █▄▂▁▁▁▂▁▁▁
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue █▃▂▂▁▁▂▁▁▁
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue █▄▂▃▂▁▂▁▁▁
wandb:                                 Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue 0.00088
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 6e-05
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.00038
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.00145
wandb:                                 Train loss 0.00082
wandb: 
wandb: 🚀 View run electric-field-1148 at: https://wandb.ai/nreints/ThesisFinal2/runs/3tsfk0zm
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_231701-3tsfk0zm/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_232520-ohcjle0i
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run charmed-dream-1159
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/ohcjle0i
Training on dataset: data_t(0,0)_r(0,0)_combi_pTrue_gTrue
Testing on 4 datasets: ['data_t(0,0)_r(0,0)_semi_pTrue_gTrue', 'data_t(0,0)_r(0,0)_combi_pTrue_gTrue', 'data_t(0,0)_r(0,0)_full_pTrue_gTrue', 'data_t(0,0)_r(0,0)_tennis_pTrue_gTrue']
Focussing on identity: False
Using extra input: False
Using start-fr as reference point.
----- ITERATION 1/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 78.29817175865173 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 19.586742639541626 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 19.607821702957153 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 19.62790060043335 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 19.853754997253418 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.1055657864 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0073499647 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0141920829 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0010659836 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0191912726 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 34.52525305747986
Epoch 1/9
	 Logging train Loss: 0.0030682916 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.002701794 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0048238286 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0004294605 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.007926276 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 32.91533660888672
Epoch 2/9
	 Logging train Loss: 0.0026105749 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0013018212 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0034221821 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0001351868 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0050577167 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 32.383466720581055
Epoch 3/9
	 Logging train Loss: 0.0021956598 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0012249798 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0022937912 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 9.8032e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0056884093 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 32.078245878219604
Epoch 4/9
	 Logging train Loss: 0.0014003455 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0007566763 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0016465776 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 5.87624e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0027383871 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 32.13876795768738
Epoch 5/9
	 Logging train Loss: 0.0010680783 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0004344645 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0014072515 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 4.04609e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0019267861 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 32.19408988952637
Epoch 6/9
	 Logging train Loss: 0.0016782903 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0010334448 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0020263789 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0001121953 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0032281163 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 32.30932092666626
Epoch 7/9
	 Logging train Loss: 0.000503329 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0003434659 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0009631335 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 3.1005e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0013731475 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 32.28402066230774
Epoch 8/9
	 Logging train Loss: 0.000626438 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.000297657 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0008915549 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.66583e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0014974851 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 32.02871060371399
Epoch 9/9
	 Logging train Loss: 0.0008151428 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0003778241 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.000876417 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 5.63432e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0014513482 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 32.206265926361084
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pTrue_gTrue/'dual_quat'_'False'.pth
It took  499.3870368003845  seconds.
----- ITERATION 2/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 72.18879532814026 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 18.204067945480347 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 18.069687843322754 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 18.195653915405273 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 18.234798431396484 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0782378316 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0144166248 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0113863861 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0006199833 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0235509705 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 32.598037242889404
Epoch 1/9
	 Logging train Loss: 0.005078529 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0126956571 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0100691449 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0009680795 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0209217239 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 32.332127809524536
Epoch 2/9
	 Logging train Loss: 0.0017169208 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0045384886 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0040649432 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.000114623 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0076988982 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 32.47147560119629
Epoch 3/9
	 Logging train Loss: 0.003751378 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0066773905 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0047368417 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0003772489 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0096756257 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 32.31599402427673
Epoch 4/9
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue █▇▃▄▁▂▁▂▁▂
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue ▅█▂▄▁▃▁▂▁▄
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue █▇▂▄▂▃▁▂▁▂
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue █▇▃▃▂▄▁▂▁▄
wandb:                                 Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue 0.00246
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 0.00041
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.00382
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.01071
wandb:                                 Train loss 0.00041
wandb: 
wandb: 🚀 View run charmed-dream-1159 at: https://wandb.ai/nreints/ThesisFinal2/runs/ohcjle0i
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_232520-ohcjle0i/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_233333-l3ht3thk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vital-galaxy-1170
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/l3ht3thk
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue ▃▆█▇▅▅▄▂▁▁
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue █▃▂▂▁▁▃▁▄▁
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue ▄▇██▅▆▅▂▁▁
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue ▅█▆▆▃▁▄▂▁▂
wandb:                                 Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue 0.06022
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 3e-05
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.05623
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.04084
wandb:                                 Train loss 0.00021
wandb: 
wandb: 🚀 View run vital-galaxy-1170 at: https://wandb.ai/nreints/ThesisFinal2/runs/l3ht3thk
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_233333-l3ht3thk/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_234200-s0e9tyg6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run floral-capybara-1179
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/s0e9tyg6
	 Logging train Loss: 0.0012423059 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0038534508 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0015106499 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 8.49671e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.005709521 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 32.3491747379303
Epoch 5/9
	 Logging train Loss: 0.0016858584 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0047197463 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0022450434 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0003336572 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0101954853 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 32.30717658996582
Epoch 6/9
	 Logging train Loss: 0.0007903937 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0022460374 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0007674102 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 3.82508e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0029624316 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 32.37865614891052
Epoch 7/9
	 Logging train Loss: 0.0015325827 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.003332298 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0020637657 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0002233603 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0042317747 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 32.31767392158508
Epoch 8/9
	 Logging train Loss: 0.0010535611 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0019778369 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0008594149 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.79683e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0027395757 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 32.335583209991455
Epoch 9/9
	 Logging train Loss: 0.0004083418 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.00381741 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0024572024 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0004059847 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0107120993 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 32.45246720314026
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pTrue_gTrue/'dual_quat'_'False'.pth
It took  492.9769184589386  seconds.
----- ITERATION 3/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 70.49512052536011 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 18.091132402420044 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 17.850266456604004 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 18.061444997787476 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 18.102349042892456 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0353883021 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0734463558 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0778612271 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0002877981 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0785491168 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 32.819985151290894
Epoch 1/9
	 Logging train Loss: 0.0003858797 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0903552547 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.1023909822 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0001099191 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.111781925 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 32.322993755340576
Epoch 2/9
	 Logging train Loss: 0.0002082132 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0971261635 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.1168187112 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 6.20087e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0928254202 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 32.27784252166748
Epoch 3/9
	 Logging train Loss: 0.000286605 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.094270736 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.1101216003 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 7.47492e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0898802727 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 32.016992807388306
Epoch 4/9
	 Logging train Loss: 0.0002293305 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0814090744 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.093883723 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 4.5189e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0605434477 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 32.01908469200134
Epoch 5/9
	 Logging train Loss: 0.0004179312 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0857377946 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.091470547 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 4.24815e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0352837257 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 32.46854782104492
Epoch 6/9
	 Logging train Loss: 6.52172e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.079934977 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0877484754 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0001168665 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.062651664 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 32.22690176963806
Epoch 7/9
	 Logging train Loss: 0.0003352967 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0646956638 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0696556792 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.88311e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0489062779 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 32.46371388435364
Epoch 8/9
	 Logging train Loss: 6.76498e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0572727211 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0606989264 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.000124298 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0387532935 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 32.45053553581238
Epoch 9/9
	 Logging train Loss: 0.0002086435 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0562302135 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0602199845 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.81077e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0408413298 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 32.348637104034424
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pTrue_gTrue/'dual_quat'_'False'.pth
It took  507.71651792526245  seconds.
----- ITERATION 4/10 ------
Number of train simulations:  1920
Number of test simulations:  480
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue █▇▂▃▁▂▂▁▂▁
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue ▆█▁▂▁▁▂▁▁▁
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue █▆▂▃▂▂▂▁▂▁
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue █▅▂▃▁▁▂▁▂▁
wandb:                                 Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue 0.0002
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 4e-05
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.00109
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.0013
wandb:                                 Train loss 0.00039
wandb: 
wandb: 🚀 View run floral-capybara-1179 at: https://wandb.ai/nreints/ThesisFinal2/runs/s0e9tyg6
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_234200-s0e9tyg6/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_234959-orhcfgj1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run peachy-sun-1188
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/orhcfgj1
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 70.9717469215393 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 18.077168703079224 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 17.85903000831604 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 18.08114218711853 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 18.07962918281555 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0571588166 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0130225606 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0021107269 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0007869104 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0128640998 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 32.410507678985596
Epoch 1/9
	 Logging train Loss: 0.0041847518 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.009019319 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0019238347 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0011247144 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0085738692 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 32.058894872665405
Epoch 2/9
	 Logging train Loss: 0.0029112464 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0031113792 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0005075884 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 7.36599e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0033051083 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 32.48147702217102
Epoch 3/9
	 Logging train Loss: 0.0014073487 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0043335916 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0008337976 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0002185421 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0039200177 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 32.2885639667511
Epoch 4/9
	 Logging train Loss: 0.002314535 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0022342564 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0003312679 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 5.2998e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0016358788 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 32.354172468185425
Epoch 5/9
	 Logging train Loss: 0.000539627 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0020672902 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0003659866 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 9.70568e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0016349932 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 32.03096032142639
Epoch 6/9
	 Logging train Loss: 0.0010029678 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.003139555 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0005258646 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0001317959 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0018376644 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 32.22630858421326
Epoch 7/9
	 Logging train Loss: 0.0006415927 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0010339677 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.000201882 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 3.3485e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0009862047 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 32.38367486000061
Epoch 8/9
	 Logging train Loss: 0.0011893648 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.003377697 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0005109572 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 7.32469e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0023910548 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 32.410290479660034
Epoch 9/9
	 Logging train Loss: 0.0003887323 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0010903584 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.000203676 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 4.21564e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.001303441 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 32.491119623184204
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pTrue_gTrue/'dual_quat'_'False'.pth
It took  479.0628716945648  seconds.
----- ITERATION 5/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 70.36792373657227 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 18.094386339187622 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 17.798418045043945 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 18.060715436935425 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 18.037740230560303 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0454978533 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0423506834 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0339870602 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0003341176 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0021537701 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 32.383750438690186
Epoch 1/9
	 Logging train Loss: 0.0210507251 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0288970824 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0125263343 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0005531638 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0103042806 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 31.987574577331543
Epoch 2/9
	 Logging train Loss: 0.0011796252 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.033593677 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0162627362 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0011736398 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0105374241 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 32.20560383796692
Epoch 3/9
	 Logging train Loss: 0.0009607552 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0197161753 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0173737407 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 5.65276e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0014486969 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 31.79689335823059
Epoch 4/9
	 Logging train Loss: 0.0012582557 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0147593822 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0126840919 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 4.62687e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0014110981 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 31.761312246322632
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue █▂▃▄▂▃▂▁▁▁
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue ▃▄█▁▁▁▁▁▁▁
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue █▅▆▃▂▂▂▁▁▁
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue ▂██▂▂▁▁▂▁▁
wandb:                                 Train loss █▄▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue 0.00726
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 2e-05
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.00848
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.00054
wandb:                                 Train loss 0.0003
wandb: 
wandb: 🚀 View run peachy-sun-1188 at: https://wandb.ai/nreints/ThesisFinal2/runs/orhcfgj1
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_234959-orhcfgj1/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_235755-pd6hd8wc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run snowy-moon-1198
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/pd6hd8wc
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue █▂▁▁▁▂▁▁▁▁
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue █▃▁▁▁▁▁▁▁▁
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue █▃▂▁▁▁▁▁▁▁
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue █▂▁▁▁▁▁▁▁▁
wandb:                                 Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue 0.00159
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 5e-05
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.0017
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.00296
wandb:                                 Train loss 0.00091
wandb: 
wandb: 🚀 View run snowy-moon-1198 at: https://wandb.ai/nreints/ThesisFinal2/runs/pd6hd8wc
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_235755-pd6hd8wc/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230710_000548-u12koi72
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run leafy-totem-1206
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/u12koi72
Epoch 5/9
	 Logging train Loss: 0.0014795619 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0148331793 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0133435437 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 4.16704e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0007875288 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 31.969311237335205
Epoch 6/9
	 Logging train Loss: 0.0003472355 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0123164915 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0103882523 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 4.71193e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.000874766 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 31.984214067459106
Epoch 7/9
	 Logging train Loss: 0.0016691794 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0095981015 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0074635795 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 3.71414e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0014591686 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 32.11886239051819
Epoch 8/9
	 Logging train Loss: 0.0002989509 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0096407691 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0079893628 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 6.12972e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0010384065 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 31.79391074180603
Epoch 9/9
	 Logging train Loss: 0.0003009401 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0084790168 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0072595952 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.17857e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0005399288 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 32.19307589530945
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pTrue_gTrue/'dual_quat'_'False'.pth
It took  475.08914375305176  seconds.
----- ITERATION 6/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 70.31857895851135 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 17.96253800392151 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 17.72708511352539 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 17.971367120742798 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 17.9959454536438 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.094554916 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.039969068 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0245876461 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0010622488 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0400782265 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 31.6052987575531
Epoch 1/9
	 Logging train Loss: 0.0037538642 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0101672392 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0031561055 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0003526832 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0067356247 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 31.91379976272583
Epoch 2/9
	 Logging train Loss: 0.0026575325 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0046862513 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0021376226 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 7.19978e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0038534016 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 31.788726329803467
Epoch 3/9
	 Logging train Loss: 0.001714937 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0031312702 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.00187543 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 5.00909e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0031518831 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 31.899895191192627
Epoch 4/9
	 Logging train Loss: 0.0029961546 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0032915785 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0020618811 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 4.47883e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0033089784 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 31.706939935684204
Epoch 5/9
	 Logging train Loss: 0.0009720942 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0041742306 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.003857088 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0001004926 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0055137738 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 31.954158067703247
Epoch 6/9
	 Logging train Loss: 0.0011264221 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0021252078 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0017469929 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 3.23095e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0030726912 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 31.49242854118347
Epoch 7/9
	 Logging train Loss: 0.0004474987 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0023679261 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0015830783 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 4.02953e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0035331817 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 31.634860277175903
Epoch 8/9
	 Logging train Loss: 0.0005039044 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0016701596 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.001379867 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 3.20488e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0029421852 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 31.888651847839355
Epoch 9/9
	 Logging train Loss: 0.0009078864 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0016981898 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0015947449 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 4.5726e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0029551084 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 31.9093918800354
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pTrue_gTrue/'dual_quat'_'False'.pth
It took  472.96252059936523  seconds.
----- ITERATION 7/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 70.2914366722107 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 17.959959506988525 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 17.768282413482666 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 17.964527368545532 seconds.
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue ▃█▂▁▁▁▁▁▁▁
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue ▅█▂▁▁▁▁▁▁▁
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue ▆█▃▂▂▁▁▁▁▁
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue ██▄▃▂▁▁▁▁▁
wandb:                                 Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue 0.0002
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 3e-05
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.0023
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.00111
wandb:                                 Train loss 0.00067
wandb: 
wandb: 🚀 View run leafy-totem-1206 at: https://wandb.ai/nreints/ThesisFinal2/runs/u12koi72
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230710_000548-u12koi72/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230710_001338-bttlwgi2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fine-water-1216
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/bttlwgi2
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 17.92807388305664 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.1243174076 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0233010855 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0011620752 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0003826286 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0114793424 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 31.447198629379272
Epoch 1/9
	 Logging train Loss: 0.0027127343 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0319278389 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0041810302 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0006848775 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0120250108 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 31.734912157058716
Epoch 2/9
	 Logging train Loss: 0.0032678384 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.012184062 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0006420198 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 9.73601e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0060785101 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 31.6013445854187
Epoch 3/9
	 Logging train Loss: 0.0029570127 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0072897435 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0003067373 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 5.61654e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0044697016 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 31.549365997314453
Epoch 4/9
	 Logging train Loss: 0.0002070102 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0065745665 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0002540002 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 4.19114e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0028803276 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 31.64404559135437
Epoch 5/9
	 Logging train Loss: 0.0018456805 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0041038683 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0001506216 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 3.4777e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0018265096 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 31.703468322753906
Epoch 6/9
	 Logging train Loss: 0.000777159 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0035415951 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0002431761 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 5.3741e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0018641939 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 31.710514307022095
Epoch 7/9
	 Logging train Loss: 0.0010324735 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0026928443 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0001226209 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 3.20185e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0013578179 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 31.66522479057312
Epoch 8/9
	 Logging train Loss: 0.0011945699 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0029165535 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.000227198 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 3.62875e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.001360279 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 31.699979782104492
Epoch 9/9
	 Logging train Loss: 0.0006741914 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.002298461 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0002023655 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.79978e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0011067918 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 31.586077213287354
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pTrue_gTrue/'dual_quat'_'False'.pth
It took  470.9367790222168  seconds.
----- ITERATION 8/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 71.64743661880493 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 18.05887222290039 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 17.94905972480774 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 18.014155387878418 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 18.01930284500122 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0501798876 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0164931566 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0104920492 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.000303487 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.02287337 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 31.58034658432007
Epoch 1/9
	 Logging train Loss: 0.0045608599 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0038916606 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0027087301 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0001128433 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0082295453 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 31.651705026626587
Epoch 2/9
	 Logging train Loss: 0.0015406494 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0032233095 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0035432512 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0002396066 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0095510194 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 31.362662076950073
Epoch 3/9
	 Logging train Loss: 0.001668899 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0028388968 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0015554139 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 5.92806e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0119614294 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 31.63775110244751
Epoch 4/9
	 Logging train Loss: 0.0013109073 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0030317758 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0028307075 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0001170861 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.011629058 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 31.64824151992798
Epoch 5/9
	 Logging train Loss: 0.0010560789 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0038678707 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0014204286 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 4.62993e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0111170197 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue █▂▃▁▂▁▁▁▁▁
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue █▃▆▂▃▂▁▁▂▁
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue █▂▁▁▁▂▁▁▁▁
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue █▂▃▄▃▃▂▂▁▂
wandb:                                 Train loss █▂▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue 0.00171
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 3e-05
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.0029
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.00795
wandb:                                 Train loss 0.00068
wandb: 
wandb: 🚀 View run fine-water-1216 at: https://wandb.ai/nreints/ThesisFinal2/runs/bttlwgi2
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230710_001338-bttlwgi2/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230710_002130-appf1pze
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run woven-sunset-1226
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/appf1pze
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue █▆▅▄▃▂▂▁▁▁
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue █▂▆▅▄▁▁▁▁▁
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue █▆▅▄▃▂▂▁▁▁
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue █▅▄▄▃▂▂▁▁▁
wandb:                                 Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue 0.0119
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 2e-05
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.01215
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.00961
wandb:                                 Train loss 0.00039
wandb: 
wandb: 🚀 View run woven-sunset-1226 at: https://wandb.ai/nreints/ThesisFinal2/runs/appf1pze
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230710_002130-appf1pze/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230710_002921-9wi58amm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run balmy-music-1234
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/9wi58amm
		--> Epoch time; 31.723450422286987
Epoch 6/9
	 Logging train Loss: 0.0014895231 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0027954162 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.001056782 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.57249e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0088832155 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 31.66269564628601
Epoch 7/9
	 Logging train Loss: 0.0005302022 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0029354156 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0014288778 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.18361e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0084503274 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 31.694022178649902
Epoch 8/9
	 Logging train Loss: 0.0007136471 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0028371604 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0013320075 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 5.07623e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0054843719 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 31.681277751922607
Epoch 9/9
	 Logging train Loss: 0.000683488 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0028988277 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0017080123 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 3.21028e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0079489984 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 31.40543270111084
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pTrue_gTrue/'dual_quat'_'False'.pth
It took  471.96479415893555  seconds.
----- ITERATION 9/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 70.40875434875488 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 17.967534065246582 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 17.685117959976196 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 17.959084272384644 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 17.913329124450684 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0723472163 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.1050026417 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0992141217 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0004021244 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0779378787 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 31.513275146484375
Epoch 1/9
	 Logging train Loss: 0.0009345554 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.078880921 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0760059357 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0001019243 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0504143387 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 31.810158491134644
Epoch 2/9
	 Logging train Loss: 0.0005928347 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0638608858 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0629800558 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0003024556 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0388924144 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 31.500667810440063
Epoch 3/9
	 Logging train Loss: 0.000630101 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0467508286 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0450314805 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0002161407 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0342079028 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 31.681645154953003
Epoch 4/9
	 Logging train Loss: 0.0004736035 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.033640489 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0332963131 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0001884252 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0293174367 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 31.604192972183228
Epoch 5/9
	 Logging train Loss: 0.0006026247 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0273029376 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0266478583 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 3.50194e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0219292492 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 31.591495275497437
Epoch 6/9
	 Logging train Loss: 0.0001652111 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0226537846 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0224204585 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.49045e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0174632743 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 31.320465803146362
Epoch 7/9
	 Logging train Loss: 0.0002923275 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0183085054 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0180711355 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.05934e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0118958205 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 31.505507230758667
Epoch 8/9
	 Logging train Loss: 0.0003518638 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.014146328 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0137817254 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.70958e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0117389997 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 31.731263160705566
Epoch 9/9
	 Logging train Loss: 0.0003945172 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0121461488 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0118988017 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.38269e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0096110739 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 31.666734218597412
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pTrue_gTrue/'dual_quat'_'False'.pth
It took  470.96216225624084  seconds.
----- ITERATION 10/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 70.12310743331909 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 17.92397904396057 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 17.76245617866516 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 17.94803476333618 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 17.984066247940063 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0885295793 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue █▃▂▂▁▁▁▃▁▁
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue █▂▁▁▂▁▁▂▁▁
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue █▃▂▂▁▂▁▃▁▁
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue █▃▂▁▂▁▃▄▃▁
wandb:                                 Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue 6e-05
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 3e-05
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.00106
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.00993
wandb:                                 Train loss 0.00026
wandb: 
wandb: 🚀 View run balmy-music-1234 at: https://wandb.ai/nreints/ThesisFinal2/runs/9wi58amm
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230710_002921-9wi58amm/logs
	 Logging test loss: 0.0167698525 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0018586982 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0009823506 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0338969156 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 31.50568151473999
Epoch 1/9
	 Logging train Loss: 0.0052840039 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0048315329 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0004486915 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0002012543 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0164713524 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 31.824121475219727
Epoch 2/9
	 Logging train Loss: 0.0019026675 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0025797542 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0002157731 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 7.49057e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0130523024 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 31.514201641082764
Epoch 3/9
	 Logging train Loss: 0.0025511612 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0022605367 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0002017332 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 7.1535e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0089365961 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 31.74130892753601
Epoch 4/9
	 Logging train Loss: 0.0011881179 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.001051388 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0001702833 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 9.49907e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0140005257 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 31.608129501342773
Epoch 5/9
	 Logging train Loss: 0.0019445433 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0025247305 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0001321507 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 5.10448e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0086190309 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 31.76225519180298
Epoch 6/9
	 Logging train Loss: 0.0005353291 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0016106913 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0001283121 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 4.30206e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0147542683 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 31.44565773010254
Epoch 7/9
	 Logging train Loss: 0.0014955503 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0064904932 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0005849783 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0001819245 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.018521402 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 31.68463397026062
Epoch 8/9
	 Logging train Loss: 0.0010334577 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0014898053 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0001070108 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 4.67048e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0141932992 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 31.765074491500854
Epoch 9/9
	 Logging train Loss: 0.000263624 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0010599904 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 6.16573e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.53344e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0099330554 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 31.45161199569702
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pTrue_gTrue/'dual_quat'_'False'.pth
It took  469.88944244384766  seconds.

JOB STATISTICS
==============
Job ID: 3039256
Array Job ID: 3039249_31
Cluster: snellius
User/Group: nreints/nreints
State: COMPLETED (exit code 0)
Nodes: 1
Cores per node: 18
CPU Utilized: 01:27:25
CPU Efficiency: 6.04% of 1-00:07:48 core-walltime
Job Wall-clock time: 01:20:26
Memory Utilized: 8.84 GB
Memory Efficiency: 0.00% of 0.00 MB
