wandb: Currently logged in as: nreints. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_164027-wcpc4svk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run magic-salad-8
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal1/runs/wcpc4svk
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone â–ˆâ–†â–„â–‚â–â–…â–â–â–„â–
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone â–ˆâ–†â–„â–‚â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone â–ˆâ–†â–„â–‚â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone â–ˆâ–†â–„â–‚â–â–ˆâ–â–â–…â–
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone â–ˆâ–†â–„â–‚â–â–ˆâ–â–â–†â–
wandb:                                  Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone 0.0
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone 0.0
wandb:                                  Train loss 1e-05
wandb: 
wandb: ðŸš€ View run magic-salad-8 at: https://wandb.ai/nreints/ThesisFinal1/runs/wcpc4svk
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_164027-wcpc4svk/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_165000-y9j96435
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run polar-morning-43
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal1/runs/y9j96435
Training on dataset: data_t(5,20)_r(0,0)_combi_pNone_gNone
Testing on 5 datasets: ['data_t(5,20)_r(0,0)_combi_pNone_gNone', 'data_t(5,20)_r(0,0)_full_pNone_gNone', 'data_t(5,20)_r(0,0)_semi_pNone_gNone', 'data_t(5,20)_r(0,0)_none_pNone_gNone', 'data_t(5,20)_r(0,0)_tennis_pNone_gNone']
Focussing on identity: False
Using extra input: False
Using fr-fr as reference point.
----- ITERATION 1/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 65.39986062049866 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 16.30789828300476 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_full_pNone_gNone took 16.411696672439575 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_semi_pNone_gNone took 16.646127939224243 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_none_pNone_gNone took 16.798835277557373 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_tennis_pNone_gNone took 16.853623390197754 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0414447188 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 7.44474e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 6.70909e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 8.25002e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 6.72478e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 8.14084e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 41.22223520278931
Epoch 1/9
	 Logging train Loss: 6.53599e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 5.43603e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 5.12753e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 5.72142e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 5.15263e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 5.71691e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 40.64617371559143
Epoch 2/9
	 Logging train Loss: 4.33184e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.22536e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.09116e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 3.25522e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 3.10203e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 3.27871e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 40.58584547042847
Epoch 3/9
	 Logging train Loss: 2.2334e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.47186e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.39046e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.45233e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.40579e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.44385e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 40.21941304206848
Epoch 4/9
	 Logging train Loss: 9.1456e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 5.2416e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 4.8676e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 5.2688e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 4.8932e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 5.1417e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 40.494598627090454
Epoch 5/9
	 Logging train Loss: 4.2897e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 4.08472e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 5.4676e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 7.87939e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 5.342e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 8.2129e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 40.56569051742554
Epoch 6/9
	 Logging train Loss: 1.31131e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.2396e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.0377e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.3051e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.0222e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 2.3094e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 40.419559955596924
Epoch 7/9
	 Logging train Loss: 9.3063e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.8835e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.7516e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.885e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.737e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.8553e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 40.92084074020386
Epoch 8/9
	 Logging train Loss: 9.5452e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.83931e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 4.569e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 5.27405e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 4.4907e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 5.48018e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 43.92497515678406
Epoch 9/9
	 Logging train Loss: 9.8609e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.4727e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.245e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.5562e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.2299e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.5503e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 40.71480584144592
Saved model in  trained_models/gru/data_t(5,20)_r(0,0)_combi_pNone_gNone/'quat_1'_'False'.pth
It took  574.4800615310669  seconds.
----- ITERATION 2/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 64.48443603515625 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 16.15162754058838 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_full_pNone_gNone took 16.369431972503662 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_semi_pNone_gNone took 16.339244604110718 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_none_pNone_gNone took 16.337130546569824 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_tennis_pNone_gNone took 16.30260419845581 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0121678961 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 6.56052e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 5.89477e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 7.70756e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 5.74126e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 8.03298e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 40.79309701919556
Epoch 1/9
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone â–ˆâ–„â–‚â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone â–ˆâ–„â–‚â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone â–ˆâ–„â–‚â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone â–ˆâ–„â–‚â–â–â–â–â–â–â–
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone â–ˆâ–„â–‚â–â–â–â–â–â–â–
wandb:                                  Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone 0.0
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone 0.0
wandb:                                  Train loss 1e-05
wandb: 
wandb: ðŸš€ View run polar-morning-43 at: https://wandb.ai/nreints/ThesisFinal1/runs/y9j96435
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_165000-y9j96435/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_165926-3v225sv9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run classic-brook-77
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal1/runs/3v225sv9
	 Logging train Loss: 4.7515e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.03662e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.96548e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 3.30292e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.88368e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 3.52086e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 40.52723813056946
Epoch 2/9
	 Logging train Loss: 1.92892e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 9.9126e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 9.8465e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.04572e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 9.4357e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.1596e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 40.48884439468384
Epoch 3/9
	 Logging train Loss: 5.975e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.4412e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.3002e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 3.702e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 3.2081e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 3.9236e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 40.71127414703369
Epoch 4/9
	 Logging train Loss: 2.9543e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.5997e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.5459e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.7886e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.5014e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 2.8666e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 40.80586075782776
Epoch 5/9
	 Logging train Loss: 7.408e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.3337e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.3332e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.4543e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.287e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 2.521e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 40.60601878166199
Epoch 6/9
	 Logging train Loss: 9.9163e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.0713e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.0832e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.159e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.0472e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 2.2119e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 40.84823489189148
Epoch 7/9
	 Logging train Loss: 1.00354e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.7882e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.7981e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.8507e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.7643e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.8957e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 40.67060565948486
Epoch 8/9
	 Logging train Loss: 1.13205e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.7497e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.5013e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.9638e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.4713e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 2.0666e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 40.95157766342163
Epoch 9/9
	 Logging train Loss: 1.19447e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.2837e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.1942e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.3405e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.1676e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.387e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 41.0562264919281
Saved model in  trained_models/gru/data_t(5,20)_r(0,0)_combi_pNone_gNone/'quat_1'_'False'.pth
It took  565.794326543808  seconds.
----- ITERATION 3/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 64.24912214279175 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 16.051056623458862 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_full_pNone_gNone took 16.271899223327637 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_semi_pNone_gNone took 16.22101640701294 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_none_pNone_gNone took 16.242270708084106 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_tennis_pNone_gNone took 16.250601530075073 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0137164388 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 8.28948e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 6.71093e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 8.82208e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 6.84561e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 9.51932e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 40.67465019226074
Epoch 1/9
	 Logging train Loss: 6.41816e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 5.1855e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 4.81275e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 5.10261e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 4.88312e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 5.28861e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 40.59827542304993
Epoch 2/9
	 Logging train Loss: 4.08267e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.22475e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.0321e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 3.14563e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 3.06873e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 3.2184e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 43.29092502593994
Epoch 3/9
	 Logging train Loss: 2.32525e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.56884e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.475e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.52399e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.47377e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.56357e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 41.21358251571655
Epoch 4/9
	 Logging train Loss: 1.0388e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.50993e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 5.0255e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.26846e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 4.933e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: ERROR Error while calling W&B API: An internal error occurred. Please contact support. (<Response [500]>)
wandb: ERROR Error while calling W&B API: An internal error occurred. Please contact support. (<Response [500]>)
wandb: 
wandb: Run history:
wandb:                                       Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone â–ˆâ–…â–„â–‚â–‚â–ƒâ–‚â–â–â–
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone â–ˆâ–†â–„â–‚â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone â–ˆâ–†â–„â–‚â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone â–ˆâ–…â–ƒâ–‚â–ƒâ–…â–ƒâ–â–â–
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone â–ˆâ–…â–ƒâ–‚â–ƒâ–…â–ƒâ–â–â–
wandb:                                  Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone 0.0
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone 0.0
wandb:                                  Train loss 1e-05
wandb: 
wandb: ðŸš€ View run classic-brook-77 at: https://wandb.ai/nreints/ThesisFinal1/runs/3v225sv9
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_165926-3v225sv9/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_170910-5xn1o4lf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run woven-bush-110
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal1/runs/5xn1o4lf
	 Logging test loss: 2.52925e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 40.9589421749115
Epoch 5/9
	 Logging train Loss: 1.35253e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.67655e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.6995e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 4.73866e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 3.6151e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 5.27781e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 40.94051003456116
Epoch 6/9
	 Logging train Loss: 1.03581e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.44831e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.763e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.3466e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.7326e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 2.64695e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 40.93293857574463
Epoch 7/9
	 Logging train Loss: 1.32316e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.081e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.8485e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.0268e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.8852e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 2.1147e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 40.67051148414612
Epoch 8/9
	 Logging train Loss: 1.39348e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.775e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.6113e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.6803e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.641e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.7414e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 40.95007634162903
Epoch 9/9
	 Logging train Loss: 1.26196e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.314e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.7654e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.5054e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.7874e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 2.6424e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 40.816394090652466
Saved model in  trained_models/gru/data_t(5,20)_r(0,0)_combi_pNone_gNone/'quat_1'_'False'.pth
It took  584.535905122757  seconds.
----- ITERATION 4/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 64.1461935043335 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 16.09309983253479 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_full_pNone_gNone took 16.222349882125854 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_semi_pNone_gNone took 16.200012683868408 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_none_pNone_gNone took 16.223223447799683 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_tennis_pNone_gNone took 16.188179969787598 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0067077731 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 9.71596e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 7.21104e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 0.000108293 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 7.09722e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 0.0001191695 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 40.49084210395813
Epoch 1/9
	 Logging train Loss: 6.93738e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 5.62943e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 5.10963e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 5.74396e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 4.98504e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 6.13674e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 40.80020999908447
Epoch 2/9
	 Logging train Loss: 4.3893e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.60355e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.46049e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 3.5934e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 3.37255e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 3.77314e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 40.64888334274292
Epoch 3/9
	 Logging train Loss: 2.78598e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.08279e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.99318e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.08382e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.96954e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 2.16867e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 40.76518893241882
Epoch 4/9
	 Logging train Loss: 1.75995e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 8.5213e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 7.9749e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 8.7433e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 7.9962e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 8.9771e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 40.82206177711487
Epoch 5/9
	 Logging train Loss: 2.40004e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.0482e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.8509e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 3.0072e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.8302e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 3.1692e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 40.81377696990967
Epoch 6/9
	 Logging train Loss: 1.4351e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.3474e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.1363e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.3253e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.1044e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 2.485e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 40.97302508354187
Epoch 7/9
	 Logging train Loss: 1.24209e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.1628e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.9583e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 3.915e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.9309e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 4.147e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 40.997870445251465
Epoch 8/9
	 Logging train Loss: 1.5643e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.7287e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.6223e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: ERROR Error while calling W&B API: An internal error occurred. Please contact support. (<Response [500]>)
wandb: 
wandb: Run history:
wandb:                                       Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone â–ˆâ–…â–„â–‚â–‚â–â–â–â–â–
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone â–ˆâ–†â–„â–ƒâ–‚â–â–â–â–â–
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone â–ˆâ–†â–„â–ƒâ–‚â–â–â–â–â–
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone â–ˆâ–…â–ƒâ–‚â–â–â–â–â–â–
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone â–ˆâ–…â–ƒâ–‚â–â–â–â–â–â–
wandb:                                  Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone 0.0
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone 0.0
wandb:                                  Train loss 2e-05
wandb: 
wandb: ðŸš€ View run woven-bush-110 at: https://wandb.ai/nreints/ThesisFinal1/runs/5xn1o4lf
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_170910-5xn1o4lf/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_171838-633d1xes
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hardy-darkness-143
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal1/runs/633d1xes
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone â–ˆâ–†â–„â–ƒâ–‚â–â–â–â–â–
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone â–ˆâ–†â–„â–ƒâ–‚â–â–â–â–â–
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone â–ˆâ–†â–„â–‚â–‚â–â–â–â–â–
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone â–ˆâ–†â–„â–ƒâ–‚â–â–â–â–â–
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone â–ˆâ–†â–„â–ƒâ–‚â–â–â–â–â–
wandb:                                  Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone 0.0
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone 0.0
wandb:                                  Train loss 1e-05
wandb: 
wandb: ðŸš€ View run hardy-darkness-143 at: https://wandb.ai/nreints/ThesisFinal1/runs/633d1xes
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_171838-633d1xes/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_172804-4ttbomtf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run clean-galaxy-177
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal1/runs/4ttbomtf
	 Logging test loss: 1.6571e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.5987e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.758e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 40.92812967300415
Epoch 9/9
	 Logging train Loss: 1.5374e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.4364e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.3326e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.364e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.3146e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.4434e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 40.75087642669678
Saved model in  trained_models/gru/data_t(5,20)_r(0,0)_combi_pNone_gNone/'quat_1'_'False'.pth
It took  567.5118355751038  seconds.
----- ITERATION 5/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 64.2206437587738 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 16.080689191818237 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_full_pNone_gNone took 16.183183193206787 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_semi_pNone_gNone took 16.175578355789185 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_none_pNone_gNone took 16.24973964691162 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_tennis_pNone_gNone took 16.313913345336914 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0082654543 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 6.64037e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 6.85132e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 6.81086e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 6.64777e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 7.07624e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 40.678654193878174
Epoch 1/9
	 Logging train Loss: 5.88354e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 4.6733e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 5.02428e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 4.65885e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 4.81321e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 4.87173e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 40.88530778884888
Epoch 2/9
	 Logging train Loss: 3.89759e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.81126e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.05983e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.73844e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.88473e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 2.92313e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 40.750712871551514
Epoch 3/9
	 Logging train Loss: 2.299e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.69054e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.68049e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.79832e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.54387e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.9063e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 40.49941396713257
Epoch 4/9
	 Logging train Loss: 1.49713e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 6.8435e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 7.4538e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 6.5729e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 6.932e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 7.0895e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 40.65203905105591
Epoch 5/9
	 Logging train Loss: 1.87285e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.9478e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.0609e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.918e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.9391e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 3.0478e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 40.7745099067688
Epoch 6/9
	 Logging train Loss: 6.2321e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.4301e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.5411e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.3763e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.4554e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 2.4795e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 40.62125301361084
Epoch 7/9
	 Logging train Loss: 1.28983e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.4561e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.3482e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 4.5544e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.2584e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 4.4175e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 40.54939866065979
Epoch 8/9
	 Logging train Loss: 1.11211e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 4.1066e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.0647e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 5.8456e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.9952e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 6.0304e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 40.71760272979736
Epoch 9/9
	 Logging train Loss: 1.4079e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.535e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.5919e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.4738e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.5347e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.5453e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 40.75229048728943
Saved model in  trained_models/gru/data_t(5,20)_r(0,0)_combi_pNone_gNone/'quat_1'_'False'.pth
It took  566.0237617492676  seconds.
----- ITERATION 6/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 64.03333902359009 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 16.10119366645813 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_full_pNone_gNone took 16.206092834472656 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_semi_pNone_gNone took 16.142361402511597 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_none_pNone_gNone took 16.123005628585815 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_tennis_pNone_gNone took 16.153696537017822 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: quat_1
-- Started Training --
Epoch 0/9
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone â–ˆâ–…â–ƒâ–‚â–‚â–â–â–â–â–
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone â–ˆâ–†â–„â–‚â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone â–ˆâ–†â–„â–‚â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone â–ˆâ–…â–ƒâ–‚â–ƒâ–â–â–â–â–
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone â–ˆâ–…â–ƒâ–‚â–ƒâ–â–â–â–â–
wandb:                                  Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone 0.0
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone 0.0
wandb:                                  Train loss 1e-05
wandb: 
wandb: ðŸš€ View run clean-galaxy-177 at: https://wandb.ai/nreints/ThesisFinal1/runs/4ttbomtf
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_172804-4ttbomtf/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_173732-a8hboelc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dutiful-plasma-214
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal1/runs/a8hboelc
	 Logging train Loss: 0.0087157739 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 7.49633e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 6.5503e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 8.19545e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 6.68024e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 8.50335e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 40.427820682525635
Epoch 1/9
	 Logging train Loss: 5.94958e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 4.85287e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 4.58336e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 4.97361e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 4.61154e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 5.15522e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 40.76754808425903
Epoch 2/9
	 Logging train Loss: 3.67509e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.67739e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.55905e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.72434e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.51041e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 2.76993e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 40.737568378448486
Epoch 3/9
	 Logging train Loss: 1.71252e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 9.8852e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 9.3184e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.00143e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 8.9811e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.03586e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 40.53956890106201
Epoch 4/9
	 Logging train Loss: 6.5871e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.60395e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 4.043e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.80279e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 4.0052e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 2.94568e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 40.80533242225647
Epoch 5/9
	 Logging train Loss: 8.5311e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.5847e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.3114e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.7051e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.3871e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 2.8147e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 43.336461544036865
Epoch 6/9
	 Logging train Loss: 1.71242e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.6013e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.1131e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.9014e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.1848e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 3.0385e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 40.68820357322693
Epoch 7/9
	 Logging train Loss: 2.10717e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.9709e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.8465e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.9365e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.9116e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.9972e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 40.388057470321655
Epoch 8/9
	 Logging train Loss: 9.9136e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.8017e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.5867e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.8618e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.6468e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.928e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 40.69693446159363
Epoch 9/9
	 Logging train Loss: 1.18379e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.3986e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.2874e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.3563e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.341e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.3986e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 40.94006609916687
Saved model in  trained_models/gru/data_t(5,20)_r(0,0)_combi_pNone_gNone/'quat_1'_'False'.pth
It took  567.888106584549  seconds.
----- ITERATION 7/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 64.36335301399231 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 16.257264375686646 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_full_pNone_gNone took 16.32658624649048 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_semi_pNone_gNone took 16.299620151519775 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_none_pNone_gNone took 16.38505220413208 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_tennis_pNone_gNone took 16.32351303100586 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0229063053 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 6.05895e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 5.73219e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 6.34284e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 5.84694e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 6.65889e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 40.468942403793335
Epoch 1/9
	 Logging train Loss: 4.85572e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.77251e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.63121e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 3.85945e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 3.71237e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 3.99333e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 40.90064573287964
Epoch 2/9
	 Logging train Loss: 2.73634e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.90143e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.79731e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.93987e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.85791e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.96898e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 40.580209732055664
Epoch 3/9
	 Logging train Loss: 1.20049e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 7.1161e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 6.6794e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 7.2203e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone â–ˆâ–…â–ƒâ–‚â–â–â–â–â–â–ƒ
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone â–ˆâ–…â–ƒâ–‚â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone â–ˆâ–…â–ƒâ–‚â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone â–ˆâ–…â–ƒâ–‚â–â–â–â–â–â–…
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone â–ˆâ–…â–ƒâ–‚â–â–â–â–â–â–„
wandb:                                  Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone 2e-05
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone 3e-05
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone 3e-05
wandb:                                  Train loss 1e-05
wandb: 
wandb: ðŸš€ View run dutiful-plasma-214 at: https://wandb.ai/nreints/ThesisFinal1/runs/a8hboelc
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_173732-a8hboelc/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_174700-ix2c9ojh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run efficient-silence-249
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal1/runs/ix2c9ojh
	 Logging test loss: 6.8895e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 7.3769e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 40.695916414260864
Epoch 4/9
	 Logging train Loss: 4.6325e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.3169e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.1566e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 3.3172e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 3.228e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 3.4895e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 40.814924240112305
Epoch 5/9
	 Logging train Loss: 8.308e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.81e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.7033e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.7719e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.7597e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 2.9367e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 41.04396677017212
Epoch 6/9
	 Logging train Loss: 9.5792e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.7103e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.516e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.7668e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.5718e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 2.9196e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 40.91218304634094
Epoch 7/9
	 Logging train Loss: 1.39738e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.1872e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.3521e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 3.9081e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.4005e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 4.0467e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 40.708457469940186
Epoch 8/9
	 Logging train Loss: 1.36255e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.4008e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.0923e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.5493e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.1338e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 2.6567e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 41.12059998512268
Epoch 9/9
	 Logging train Loss: 1.04307e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.86634e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.6102e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 3.47948e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 3.5953e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 3.43422e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 41.074902296066284
Saved model in  trained_models/gru/data_t(5,20)_r(0,0)_combi_pNone_gNone/'quat_1'_'False'.pth
It took  567.8016052246094  seconds.
----- ITERATION 8/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 64.16451382637024 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 16.104331493377686 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_full_pNone_gNone took 16.116429328918457 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_semi_pNone_gNone took 16.1894314289093 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_none_pNone_gNone took 16.185584545135498 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_tennis_pNone_gNone took 16.22677969932556 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0079878904 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 7.32891e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 6.1865e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 8.42196e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 6.47284e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 8.79619e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 43.195659160614014
Epoch 1/9
	 Logging train Loss: 6.10023e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 4.77283e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 4.53062e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 5.10805e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 4.79921e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 5.18977e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 40.741780281066895
Epoch 2/9
	 Logging train Loss: 3.84762e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.63528e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.56877e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.8478e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.7153e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 2.85415e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 40.51842403411865
Epoch 3/9
	 Logging train Loss: 1.93343e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.16109e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.1225e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.27018e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.21378e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.26149e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 40.481767654418945
Epoch 4/9
	 Logging train Loss: 7.3465e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.4688e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.2289e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 3.7171e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 3.4434e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 3.7364e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 40.47768783569336
Epoch 5/9
	 Logging train Loss: 1.37342e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.1669e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.0096e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.2618e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.1058e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 2.3004e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 41.26052236557007
Epoch 6/9
	 Logging train Loss: 9.0203e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.814e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.6836e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.8785e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.7585e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.9042e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 40.74398159980774
Epoch 7/9
	 Logging train Loss: 1.81639e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.0158e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone â–ˆâ–†â–ƒâ–‚â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone â–ˆâ–†â–„â–‚â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone â–ˆâ–†â–„â–‚â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone â–ˆâ–…â–ƒâ–‚â–â–â–â–â–â–
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone â–ˆâ–…â–ƒâ–‚â–â–â–â–â–â–
wandb:                                  Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone 1e-05
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone 1e-05
wandb:                                  Train loss 1e-05
wandb: 
wandb: ðŸš€ View run efficient-silence-249 at: https://wandb.ai/nreints/ThesisFinal1/runs/ix2c9ojh
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_174700-ix2c9ojh/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_175627-igfue91s
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run gentle-wildflower-278
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal1/runs/igfue91s
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone â–ˆâ–…â–„â–‚â–â–„â–â–‚â–â–
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone â–ˆâ–†â–„â–‚â–‚â–â–â–â–â–
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone â–ˆâ–†â–„â–‚â–‚â–â–â–â–â–
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone â–ˆâ–…â–ƒâ–‚â–â–†â–â–‚â–â–
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone â–ˆâ–…â–ƒâ–‚â–â–†â–â–‚â–â–
wandb:                                  Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone 0.0
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone 0.0
wandb:                                  Train loss 1e-05
wandb: 
wandb: ðŸš€ View run gentle-wildflower-278 at: https://wandb.ai/nreints/ThesisFinal1/runs/igfue91s
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_175627-igfue91s/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_180555-c1swr0pf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run robust-glitter-308
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal1/runs/c1swr0pf
	 Logging test loss: 1.5297e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 4.1398e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.5847e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 4.534e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 40.47461462020874
Epoch 8/9
	 Logging train Loss: 7.4422e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.1326e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.0378e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.1417e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.0764e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.1554e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 40.49238729476929
Epoch 9/9
	 Logging train Loss: 1.03165e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.3494e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.0038e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 5.2964e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.025e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 5.9175e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 40.863035440444946
Saved model in  trained_models/gru/data_t(5,20)_r(0,0)_combi_pNone_gNone/'quat_1'_'False'.pth
It took  567.4900808334351  seconds.
----- ITERATION 9/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 64.19034099578857 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 16.086429834365845 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_full_pNone_gNone took 16.173139572143555 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_semi_pNone_gNone took 16.158528566360474 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_none_pNone_gNone took 16.16418194770813 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_tennis_pNone_gNone took 16.28270936012268 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0131031452 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 7.1343e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 6.74794e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 7.79597e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 6.4283e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 8.07833e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 40.68470358848572
Epoch 1/9
	 Logging train Loss: 5.82411e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 4.5646e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 4.70352e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 4.674e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 4.49167e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 4.7533e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 40.69113636016846
Epoch 2/9
	 Logging train Loss: 3.62563e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.70014e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.80524e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.75512e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.69351e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 2.81352e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 40.65204858779907
Epoch 3/9
	 Logging train Loss: 2.04245e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.42992e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.47088e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.45916e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.40909e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.49032e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 40.627665758132935
Epoch 4/9
	 Logging train Loss: 1.06174e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 6.1916e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 6.2636e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 6.3708e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 5.9668e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 6.5004e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 40.538076877593994
Epoch 5/9
	 Logging train Loss: 1.08624e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.07934e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 4.2495e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 5.67533e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 4.0285e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 5.96658e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 40.74925971031189
Epoch 6/9
	 Logging train Loss: 1.53214e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.2021e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.1913e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.2034e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.0839e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 2.2397e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 41.08647847175598
Epoch 7/9
	 Logging train Loss: 1.53023e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 7.8365e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.5354e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.28752e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.4193e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.42102e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 40.544501304626465
Epoch 8/9
	 Logging train Loss: 1.66326e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.2357e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.7369e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.694e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.654e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 2.7787e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 41.56848430633545
Epoch 9/9
	 Logging train Loss: 1.287e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.4436e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.4179e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.4014e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.3499e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.4199e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 41.9671196937561
Saved model in  trained_models/gru/data_t(5,20)_r(0,0)_combi_pNone_gNone/'quat_1'_'False'.pth
It took  567.4462213516235  seconds.
----- ITERATION 10/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 64.31697940826416 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 16.155189037322998 seconds.
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone â–ˆâ–„â–‚â–â–â–‚â–â–â–â–
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone â–ˆâ–…â–‚â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone â–ˆâ–„â–‚â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone â–ˆâ–„â–‚â–â–â–ƒâ–â–â–â–
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone â–ˆâ–„â–‚â–â–â–ƒâ–â–â–â–
wandb:                                  Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone 0.0
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone 0.0
wandb:                                  Train loss 1e-05
wandb: 
wandb: ðŸš€ View run robust-glitter-308 at: https://wandb.ai/nreints/ThesisFinal1/runs/c1swr0pf
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_180555-c1swr0pf/logs
The dataloader for data/data_t(5,20)_r(0,0)_full_pNone_gNone took 16.171651124954224 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_semi_pNone_gNone took 16.118913173675537 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_none_pNone_gNone took 16.23839831352234 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_tennis_pNone_gNone took 16.201728343963623 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0047026221 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 5.38048e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 5.05401e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 5.45851e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 4.75783e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 5.71165e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 40.63715124130249
Epoch 1/9
	 Logging train Loss: 3.82935e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.65111e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.58129e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.62149e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.3793e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 2.68456e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 41.04905939102173
Epoch 2/9
	 Logging train Loss: 1.6512e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 9.2162e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 8.7979e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 9.1467e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 7.8717e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 9.3818e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 40.54947471618652
Epoch 3/9
	 Logging train Loss: 8.1189e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.2089e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.8559e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 3.2862e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.6617e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 3.464e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 40.58081412315369
Epoch 4/9
	 Logging train Loss: 1.39613e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.4596e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.2938e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.427e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.1697e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 2.5553e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 40.49683976173401
Epoch 5/9
	 Logging train Loss: 1.50203e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 8.7496e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.5531e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.26004e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.4335e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.40135e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 40.78199553489685
Epoch 6/9
	 Logging train Loss: 6.8664e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.954e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.8813e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.8831e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.7699e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.9564e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 40.962578773498535
Epoch 7/9
	 Logging train Loss: 1.22237e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.72e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.6186e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.666e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.5285e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.7364e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 40.8211190700531
Epoch 8/9
	 Logging train Loss: 8.0009e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.4151e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.3157e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.3747e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.2412e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.4275e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 40.734052896499634
Epoch 9/9
	 Logging train Loss: 9.3456e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.0703e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.0044e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.0017e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 9.482e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.0424e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 40.71990394592285
Saved model in  trained_models/gru/data_t(5,20)_r(0,0)_combi_pNone_gNone/'quat_1'_'False'.pth
It took  569.1070966720581  seconds.

JOB STATISTICS
==============
Job ID: 2971261
Array Job ID: 2971258_3
Cluster: snellius
User/Group: nreints/nreints
State: COMPLETED (exit code 0)
Nodes: 1
Cores per node: 18
CPU Utilized: 06:22:05
CPU Efficiency: 22.29% of 1-04:34:30 core-walltime
Job Wall-clock time: 01:35:15
Memory Utilized: 8.57 GB
Memory Efficiency: 0.00% of 0.00 MB
