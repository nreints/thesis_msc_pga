wandb: Currently logged in as: nreints. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_180834-iol58ev5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run silver-glitter-940
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/iol58ev5
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue ▂▂▂▂▁█▁▁▁▁
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue █▇▆▅▃▃▁▁▁▁
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue ▂▂▂▂▁█▁▁▁▁
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue ▂▂▂▁▁█▁▁▁▁
wandb:                                 Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.0
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 1e-05
wandb:                                 Train loss 1e-05
wandb: 
wandb: 🚀 View run silver-glitter-940 at: https://wandb.ai/nreints/ThesisFinal2/runs/iol58ev5
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_180834-iol58ev5/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_181600-jbxdp26l
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run generous-sea-957
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/jbxdp26l
Training on dataset: data_t(0,0)_r(0,0)_combi_pNone_gTrue
Testing on 4 datasets: ['data_t(0,0)_r(0,0)_semi_pTrue_gTrue', 'data_t(0,0)_r(0,0)_tennis_pTrue_gTrue', 'data_t(0,0)_r(0,0)_full_pTrue_gTrue', 'data_t(0,0)_r(0,0)_combi_pNone_gTrue']
Focussing on identity: False
Using extra input: True
Using fr-fr as reference point.
----- ITERATION 1/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 60.94568181037903 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 14.933770418167114 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 15.090351819992065 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 15.16886305809021 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 15.64859390258789 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (pre_hidden_lin_layer): Sequential(
    (0): Linear(in_features=3, out_features=96, bias=True)
    (1): ReLU()
    (2): Linear(in_features=96, out_features=96, bias=True)
    (3): ReLU()
  )
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0169634428 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.77366e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 3.66044e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.6024e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 1.59069e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 31.556997299194336
Epoch 1/9
	 Logging train Loss: 1.32293e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.10193e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 2.5752e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.40346e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 1.13454e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 30.973636627197266
Epoch 2/9
	 Logging train Loss: 1.02179e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.68227e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 2.0572e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.14072e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 9.2986e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 30.94749426841736
Epoch 3/9
	 Logging train Loss: 7.9077e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.332e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 1.59673e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 8.5198e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 6.2579e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 30.899104356765747
Epoch 4/9
	 Logging train Loss: 1.45444e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 9.1235e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 1.09554e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 4.5848e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 3.0589e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 31.065041065216064
Epoch 5/9
	 Logging train Loss: 1.59058e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0001191839 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0002157355 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 4.7254e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 8.22113e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 31.10490083694458
Epoch 6/9
	 Logging train Loss: 1.12276e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.9673e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 6.3038e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 9.427e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 5.547e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 31.239447593688965
Epoch 7/9
	 Logging train Loss: 1.32683e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.711e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 5.7672e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 8.888e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 3.058e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 31.124529361724854
Epoch 8/9
	 Logging train Loss: 1.26508e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.6015e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 5.7014e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 8.463e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 2.772e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 30.760313272476196
Epoch 9/9
	 Logging train Loss: 8.2897e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.4323e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 5.445e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 7.711e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 1.941e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 30.891947746276855
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'quat_1'_'True'.pth
It took  447.05086612701416  seconds.
----- ITERATION 2/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 58.37177276611328 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 14.986713409423828 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 14.956195831298828 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 15.00435757637024 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 14.433473110198975 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (pre_hidden_lin_layer): Sequential(
    (0): Linear(in_features=3, out_features=96, bias=True)
    (1): ReLU()
    (2): Linear(in_features=96, out_features=96, bias=True)
    (3): ReLU()
  )
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0273979381 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.62469e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0001659615 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.4873e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 7.32954e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 30.899597883224487
Epoch 1/9
	 Logging train Loss: 2.64624e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.20472e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 4.69363e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.2881e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 2.03632e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 31.183698415756226
Epoch 2/9
	 Logging train Loss: 1.37122e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.99546e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 2.86493e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 8.1992e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 1.2059e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 31.219019174575806
Epoch 3/9
	 Logging train Loss: 0.0009322371 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.9606e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue █▃▂▃▁▁▁▁▁▁
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue █▇▅▃▂▁▁▁▁▁
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue █▃▂▃▁▁▁▁▁▁
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue █▃▂▃▁▁▁▁▁▁
wandb:                                 Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.0
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 1e-05
wandb:                                 Train loss 0.0
wandb: 
wandb: 🚀 View run generous-sea-957 at: https://wandb.ai/nreints/ThesisFinal2/runs/jbxdp26l
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_181600-jbxdp26l/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_182321-cxzpy20j
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lunar-spaceship-976
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/cxzpy20j
	 Logging test loss: 4.92431e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 5.0141e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 1.87063e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 30.921947956085205
Epoch 4/9
	 Logging train Loss: 6.7517e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 9.436e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 1.29371e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 3.0741e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 3.1846e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 31.216609716415405
Epoch 5/9
	 Logging train Loss: 2.5282e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.3476e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 8.2895e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.4786e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 1.472e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 31.2599778175354
Epoch 6/9
	 Logging train Loss: 1.306e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.7995e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 7.2026e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.4014e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 1.3753e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 31.05865788459778
Epoch 7/9
	 Logging train Loss: 9.72e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.5137e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 6.8777e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.3855e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 1.1416e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 31.074270963668823
Epoch 8/9
	 Logging train Loss: 9.153e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.8893e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 5.9508e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 9.339e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 4.545e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 31.01915407180786
Epoch 9/9
	 Logging train Loss: 1.0236e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.9054e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 5.9677e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 9.532e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 4.392e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 31.133240699768066
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'quat_1'_'True'.pth
It took  440.9694809913635  seconds.
----- ITERATION 3/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 58.89663052558899 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 14.822587490081787 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 14.929667711257935 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 14.87198257446289 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 14.84275507926941 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (pre_hidden_lin_layer): Sequential(
    (0): Linear(in_features=3, out_features=96, bias=True)
    (1): ReLU()
    (2): Linear(in_features=96, out_features=96, bias=True)
    (3): ReLU()
  )
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0469001383 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0054029212 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0103855738 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.81794e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0006713506 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 31.0421781539917
Epoch 1/9
	 Logging train Loss: 0.0021075208 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0016648127 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0001490942 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.35259e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0002243526 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 31.24590229988098
Epoch 2/9
	 Logging train Loss: 2.10116e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0003569559 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 8.51273e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.38505e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 6.4714e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 30.858854055404663
Epoch 3/9
	 Logging train Loss: 1.33655e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0001237274 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0001720375 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.43613e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 1.25286e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 31.08389902114868
Epoch 4/9
	 Logging train Loss: 9.4965e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0026468437 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 3.77351e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 9.1886e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 1.18711e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 30.995518922805786
Epoch 5/9
	 Logging train Loss: 8.7601e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0002773046 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 2.12337e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 3.8912e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 1.89092e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 31.579798698425293
Epoch 6/9
	 Logging train Loss: 0.0030301558 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0007911689 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 5.33592e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.6862e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 1.86348e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 31.238722801208496
Epoch 7/9
	 Logging train Loss: 8.1659e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.000273259 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 1.31109e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.5669e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 3.0021e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 31.434504985809326
Epoch 8/9
	 Logging train Loss: 2.3561e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.47038e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 9.2449e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.194e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 1.5152e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 31.40840172767639
Epoch 9/9
	 Logging train Loss: 1.5335e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.26763e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 7.8543e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.2152e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue █▃▂▁▁▁▁▁▁▁
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue █▆▆▆▄▂▂▁▁▁
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue █▃▁▁▄▁▂▁▁▁
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue █▁▁▁▁▁▁▁▁▁
wandb:                                 Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 1e-05
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 1e-05
wandb:                                 Train loss 0.0
wandb: 
wandb: 🚀 View run lunar-spaceship-976 at: https://wandb.ai/nreints/ThesisFinal2/runs/cxzpy20j
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_182321-cxzpy20j/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_183044-e63cp13g
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run polished-cosmos-996
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/e63cp13g
wandb: Waiting for W&B process to finish... (success).
wandb: ERROR Error while calling W&B API: An internal error occurred. Please contact support. (<Response [500]>)
wandb: 
wandb: Run history:
wandb:                                      Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue ▂█▁▁▁▁▁▁▁▁
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue ██▅▅▃▂▂▁▁▁
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue ▄█▁▁▁▁▁▁▁▁
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue ▁█▁▁▁▁▁▁▁▁
wandb:                                 Train loss █▂▁▁▁▁▂▁▁▁
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 1e-05
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 1e-05
wandb:                                 Train loss 0.0
wandb: 
wandb: 🚀 View run polished-cosmos-996 at: https://wandb.ai/nreints/ThesisFinal2/runs/e63cp13g
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_183044-e63cp13g/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_183806-0xnz7bvg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run polar-wave-1018
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/0xnz7bvg
	 Logging test loss: 1.0963e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 31.31302523612976
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'quat_1'_'True'.pth
It took  443.15942430496216  seconds.
----- ITERATION 4/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 57.93231701850891 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 14.86809229850769 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 14.941192150115967 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 14.905280590057373 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 14.780988454818726 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (pre_hidden_lin_layer): Sequential(
    (0): Linear(in_features=3, out_features=96, bias=True)
    (1): ReLU()
    (2): Linear(in_features=96, out_features=96, bias=True)
    (3): ReLU()
  )
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0203092378 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0002029367 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.000143998 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.41492e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 9.12063e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 31.157277822494507
Epoch 1/9
	 Logging train Loss: 0.0017864502 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0005359044 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0274903476 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.43237e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.000882829 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 30.7856023311615
Epoch 2/9
	 Logging train Loss: 0.0008906273 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.12116e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 2.84158e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 9.2547e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 1.13152e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 31.134357929229736
Epoch 3/9
	 Logging train Loss: 8.5095e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.69035e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 2.10654e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 7.9859e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 7.1755e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 30.865220546722412
Epoch 4/9
	 Logging train Loss: 5.4993e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.163e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 1.56898e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 4.6927e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 4.2577e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 30.8502197265625
Epoch 5/9
	 Logging train Loss: 3.1281e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.6484e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 1.33952e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.0997e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 2.4838e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 31.004589319229126
Epoch 6/9
	 Logging train Loss: 0.0023222785 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.61983e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 2.67713e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.0767e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 8.8778e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 31.002652883529663
Epoch 7/9
	 Logging train Loss: 3.7452e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.7359e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 1.08453e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.3908e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 2.4834e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 31.07722568511963
Epoch 8/9
	 Logging train Loss: 1.7489e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.4358e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 8.2365e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.1097e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 1.4896e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 30.91941738128662
Epoch 9/9
	 Logging train Loss: 1.2512e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.8971e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 7.1893e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.1685e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 1.0657e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 31.073068380355835
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'quat_1'_'True'.pth
It took  442.0635461807251  seconds.
----- ITERATION 5/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 57.78504538536072 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 14.86126446723938 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 14.898585319519043 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 14.874199867248535 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 14.76278305053711 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (pre_hidden_lin_layer): Sequential(
    (0): Linear(in_features=3, out_features=96, bias=True)
    (1): ReLU()
    (2): Linear(in_features=96, out_features=96, bias=True)
    (3): ReLU()
  )
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0143719828 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.3451e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 3.68966e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.50085e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 1.81938e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 30.74069595336914
Epoch 1/9
	 Logging train Loss: 1.31812e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.83037e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 2.51925e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.27369e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 1.08915e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 31.17950463294983
Epoch 2/9
	 Logging train Loss: 9.4438e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.32783e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 2.03952e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.06098e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 8.325e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 30.883782148361206
Epoch 3/9
	 Logging train Loss: 6.9663e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.76224e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue █▅▄▃▂▁▂▅▁▆
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue █▇▆▄▂▁▁▁▁▁
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue █▅▄▃▂▁▂▄▁▅
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue █▅▄▃▂▁▂▆▁▇
wandb:                                 Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 1e-05
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 3e-05
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 3e-05
wandb:                                 Train loss 1e-05
wandb: 
wandb: 🚀 View run polar-wave-1018 at: https://wandb.ai/nreints/ThesisFinal2/runs/0xnz7bvg
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_183806-0xnz7bvg/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_184526-qdlm22su
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run effortless-sea-1034
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/qdlm22su
	 Logging test loss: 1.53508e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 7.3227e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 5.6969e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 30.92553973197937
Epoch 4/9
	 Logging train Loss: 4.2137e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.13928e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 1.01931e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 3.4446e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 2.8317e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 30.796834707260132
Epoch 5/9
	 Logging train Loss: 9.1602e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.6727e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 8.3365e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.7727e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 1.2211e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 31.0954430103302
Epoch 6/9
	 Logging train Loss: 1.32928e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.0045e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 1.09924e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.2153e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 2.453e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 30.85267400741577
Epoch 7/9
	 Logging train Loss: 1.39046e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.2621e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 2.68171e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.4775e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 1.0241e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 31.488866567611694
Epoch 8/9
	 Logging train Loss: 1.32629e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.7031e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 6.1657e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.028e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 4.111e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 31.299562454223633
Epoch 9/9
	 Logging train Loss: 7.6586e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.65559e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 3.2179e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.5209e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 1.24093e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 31.264710187911987
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'quat_1'_'True'.pth
It took  440.0448956489563  seconds.
----- ITERATION 6/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 58.00644135475159 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 14.883943796157837 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 14.812150239944458 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 14.892380714416504 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 14.574665546417236 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (pre_hidden_lin_layer): Sequential(
    (0): Linear(in_features=3, out_features=96, bias=True)
    (1): ReLU()
    (2): Linear(in_features=96, out_features=96, bias=True)
    (3): ReLU()
  )
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0107309278 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.35084e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 3.20135e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.45771e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 1.55801e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 31.208478689193726
Epoch 1/9
	 Logging train Loss: 1.25384e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.55845e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 2.53248e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.38153e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 1.08683e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 31.10913586616516
Epoch 2/9
	 Logging train Loss: 9.2949e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.03954e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 2.0115e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.12032e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 8.1995e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 31.15720510482788
Epoch 3/9
	 Logging train Loss: 6.8654e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.53018e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 1.50353e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 7.7418e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 5.6005e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 31.15494203567505
Epoch 4/9
	 Logging train Loss: 4.1333e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.17553e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 1.29778e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 3.8793e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 3.9143e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 31.008979558944702
Epoch 5/9
	 Logging train Loss: 1.00276e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.3952e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 6.3411e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.3139e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 8.816e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 30.975175619125366
Epoch 6/9
	 Logging train Loss: 9.2956e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.91306e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 5.08854e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.362e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 2.13925e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 31.059563636779785
Epoch 7/9
	 Logging train Loss: 1.03397e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.27925e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 1.29906e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.4168e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 4.2027e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 31.01422953605652
Epoch 8/9
	 Logging train Loss: 9.4872e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0001554634 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.000175719 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 5.4894e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 7.85916e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 31.25491976737976
Epoch 9/9
	 Logging train Loss: 1.00364e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0001288607 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0002014455 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 5.6724e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 7.96846e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue ▂▂▂▁▁▁▃▁██
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue ██▆▄▂▁▂▁▃▃
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue ▂▂▂▁▁▁▃▁█▇
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue ▂▂▁▁▁▁▃▁▇█
wandb:                                 Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 8e-05
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 1e-05
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.00013
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.0002
wandb:                                 Train loss 1e-05
wandb: 
wandb: 🚀 View run effortless-sea-1034 at: https://wandb.ai/nreints/ThesisFinal2/runs/qdlm22su
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_184526-qdlm22su/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_185248-uj7lgdin
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run zesty-wave-1049
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/uj7lgdin
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue █▅▄▃▂▁▂▁▂▁
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue ██▆▄▂▁▂▁▁▁
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue █▆▄▃▁▁▂▁▂▁
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue █▅▃▂▁▁▂▁▂▁
wandb:                                 Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.0
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.0
wandb:                                 Train loss 0.0
wandb: 
wandb: 🚀 View run zesty-wave-1049 at: https://wandb.ai/nreints/ThesisFinal2/runs/uj7lgdin
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_185248-uj7lgdin/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_190009-a7304dat
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stellar-fire-1066
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/a7304dat
		--> Epoch time; 31.107224702835083
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'quat_1'_'True'.pth
It took  441.68563580513  seconds.
----- ITERATION 7/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 58.55323147773743 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 14.867400407791138 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 14.998278856277466 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 14.893197298049927 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 14.856063604354858 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (pre_hidden_lin_layer): Sequential(
    (0): Linear(in_features=3, out_features=96, bias=True)
    (1): ReLU()
    (2): Linear(in_features=96, out_features=96, bias=True)
    (3): ReLU()
  )
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0079788715 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.42603e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 4.04254e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.32747e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 1.8641e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 31.05250334739685
Epoch 1/9
	 Logging train Loss: 1.37309e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.49191e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 2.34505e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.25495e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 1.13702e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 31.4425847530365
Epoch 2/9
	 Logging train Loss: 9.4272e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.90573e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 1.67877e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 9.862e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 8.0611e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 30.99742555618286
Epoch 3/9
	 Logging train Loss: 6.3115e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.3138e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 1.15233e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 6.2689e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 4.6572e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 30.983704328536987
Epoch 4/9
	 Logging train Loss: 2.8248e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.0469e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 6.6464e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.8201e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 1.6837e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 30.797723531723022
Epoch 5/9
	 Logging train Loss: 6.1433e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.5269e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 5.1527e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 9.86e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 7.664e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 31.165884971618652
Epoch 6/9
	 Logging train Loss: 1.8502e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.12596e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 1.05111e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.7e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 3.7431e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 31.112723112106323
Epoch 7/9
	 Logging train Loss: 6.4962e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.1099e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 4.6573e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 8.297e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 4.966e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 31.099626302719116
Epoch 8/9
	 Logging train Loss: 1.06836e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.01111e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 9.1381e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.1413e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 3.2385e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 31.209083318710327
Epoch 9/9
	 Logging train Loss: 4.5517e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.9956e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 4.3954e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 7.008e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 3.66e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 31.224586009979248
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'quat_1'_'True'.pth
It took  441.0240478515625  seconds.
----- ITERATION 8/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 57.8634569644928 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 14.868809700012207 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 14.867568254470825 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 14.86627721786499 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 14.728230714797974 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (pre_hidden_lin_layer): Sequential(
    (0): Linear(in_features=3, out_features=96, bias=True)
    (1): ReLU()
    (2): Linear(in_features=96, out_features=96, bias=True)
    (3): ReLU()
  )
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0102832299 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.52321e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 4.24464e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.26458e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 1.74816e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 30.781062841415405
Epoch 1/9
	 Logging train Loss: 1.3638e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.36797e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 2.87505e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.13855e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 1.05733e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 31.1034414768219
Epoch 2/9
	 Logging train Loss: 8.9214e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.59376e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 1.90561e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 7.527e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 7.363e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 30.791114330291748
Epoch 3/9
	 Logging train Loss: 5.6156e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.17761e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 1.42459e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 5.1337e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue █▅▄▂▁▁▁▁▄▁
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue █▇▅▄▂▁▁▁▂▁
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue █▅▄▃▂▁▁▁▄▁
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue █▅▃▃▂▁▁▁▄▁
wandb:                                 Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.0
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 1e-05
wandb:                                 Train loss 1e-05
wandb: 
wandb: 🚀 View run stellar-fire-1066 at: https://wandb.ai/nreints/ThesisFinal2/runs/a7304dat
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_190009-a7304dat/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_190727-7okzeg7a
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run amber-field-1082
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/7okzeg7a
	 Logging test loss: 3.9742e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 30.70455837249756
Epoch 4/9
	 Logging train Loss: 2.6768e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.5847e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 9.3353e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.1453e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 1.4982e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 30.76345181465149
Epoch 5/9
	 Logging train Loss: 1.24135e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.3896e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 8.0673e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.1683e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 9.661e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 31.222206354141235
Epoch 6/9
	 Logging train Loss: 1.95765e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.5583e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 6.942e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.0406e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 5.103e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 30.76865291595459
Epoch 7/9
	 Logging train Loss: 1.42678e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.4192e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 6.7253e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.0139e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 4.496e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 30.833926677703857
Epoch 8/9
	 Logging train Loss: 1.43324e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.68363e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 2.20717e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.867e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 7.2401e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 30.88947296142578
Epoch 9/9
	 Logging train Loss: 1.01021e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.9311e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 6.247e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 8.969e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 3.232e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 31.01184916496277
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'quat_1'_'True'.pth
It took  438.14109563827515  seconds.
----- ITERATION 9/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 57.81831765174866 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 14.791924238204956 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 14.914384365081787 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 14.873859643936157 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 14.743643045425415 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (pre_hidden_lin_layer): Sequential(
    (0): Linear(in_features=3, out_features=96, bias=True)
    (1): ReLU()
    (2): Linear(in_features=96, out_features=96, bias=True)
    (3): ReLU()
  )
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0051683434 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.28836e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 4.40253e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.53997e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 1.48627e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 30.966970443725586
Epoch 1/9
	 Logging train Loss: 1.11101e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.53126e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 2.708e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.16043e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 8.7756e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 30.753415822982788
Epoch 2/9
	 Logging train Loss: 6.5508e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.4815e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 1.61208e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 5.7652e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 4.5319e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 30.964924812316895
Epoch 3/9
	 Logging train Loss: 2.6918e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.1355e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 9.0333e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.8725e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 1.5498e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 31.081963539123535
Epoch 4/9
	 Logging train Loss: 1.03007e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.5985e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 7.2643e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.01e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 7.593e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 30.869163274765015
Epoch 5/9
	 Logging train Loss: 6.6127e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.491e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 7.0972e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 9.449e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 7.249e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 30.911742210388184
Epoch 6/9
	 Logging train Loss: 1.64238e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.77218e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 3.20656e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.6988e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 1.35661e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 30.668781757354736
Epoch 7/9
	 Logging train Loss: 9.4321e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.69473e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 2.47157e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.2532e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 8.6565e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 30.799994230270386
Epoch 8/9
	 Logging train Loss: 8.4211e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.4343e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 1.49822e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.4774e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 5.1386e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 30.886507987976074
Epoch 9/9
	 Logging train Loss: 7.1962e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0002118916 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0002930149 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.41617e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0001481479 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 31.191323041915894
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue ▂▁▁▁▁▁▂▁▁█
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue █▆▃▁▁▁▁▁▁▇
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue ▂▂▁▁▁▁▂▁▁█
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue ▂▁▁▁▁▁▂▁▁█
wandb:                                 Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 0.00015
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 1e-05
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.00021
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.00029
wandb:                                 Train loss 1e-05
wandb: 
wandb: 🚀 View run amber-field-1082 at: https://wandb.ai/nreints/ThesisFinal2/runs/7okzeg7a
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_190727-7okzeg7a/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_191446-iy7aj9wr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run solar-butterfly-1095
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/iy7aj9wr
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue ▂▂▂▂▁█▁▁▁▁
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue █▇▅▃▁▃▁▁▁▁
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue ▂▂▂▁▁█▁▁▁▁
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue ▃▂▂▂▁█▁▁▁▁
wandb:                                 Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.0
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 1e-05
wandb:                                 Train loss 1e-05
wandb: 
wandb: 🚀 View run solar-butterfly-1095 at: https://wandb.ai/nreints/ThesisFinal2/runs/iy7aj9wr
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_191446-iy7aj9wr/logs
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'quat_1'_'True'.pth
It took  439.01342511177063  seconds.
----- ITERATION 10/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 58.04894256591797 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 14.804126501083374 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 14.924068689346313 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 14.86669635772705 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 14.580635786056519 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (pre_hidden_lin_layer): Sequential(
    (0): Linear(in_features=3, out_features=96, bias=True)
    (1): ReLU()
    (2): Linear(in_features=96, out_features=96, bias=True)
    (3): ReLU()
  )
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0047362424 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.65412e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 3.49909e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.32056e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 1.17068e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 30.600264310836792
Epoch 1/9
	 Logging train Loss: 1.01511e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.06863e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 2.72392e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.15807e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 8.57e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 30.309786319732666
Epoch 2/9
	 Logging train Loss: 7.2129e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.45154e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 1.91897e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 7.6067e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 5.758e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 30.481186866760254
Epoch 3/9
	 Logging train Loss: 4.3395e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.12184e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 1.75578e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 3.6784e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 4.9044e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 30.47226643562317
Epoch 4/9
	 Logging train Loss: 1.74327e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.3606e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 9.6649e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.5602e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 1.4893e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 30.494017601013184
Epoch 5/9
	 Logging train Loss: 8.1967e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0001178023 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0001251194 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 5.1411e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 5.84993e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 30.65419602394104
Epoch 6/9
	 Logging train Loss: 1.44095e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.1309e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 8.6122e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.0268e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 1.2088e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 30.51472282409668
Epoch 7/9
	 Logging train Loss: 1.1723e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.9271e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 7.2396e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 9.479e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 6.554e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 30.361154317855835
Epoch 8/9
	 Logging train Loss: 1.11164e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.9353e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 7.5379e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.0571e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 6.781e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 30.396222591400146
Epoch 9/9
	 Logging train Loss: 9.3665e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.4857e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 6.5433e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 9.136e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 3.307e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 30.619571685791016
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'quat_1'_'True'.pth
It took  434.03376817703247  seconds.

JOB STATISTICS
==============
Job ID: 3037997
Array Job ID: 3037875_36
Cluster: snellius
User/Group: nreints/nreints
State: COMPLETED (exit code 0)
Nodes: 1
Cores per node: 18
CPU Utilized: 01:20:16
CPU Efficiency: 6.05% of 22:06:18 core-walltime
Job Wall-clock time: 01:13:41
Memory Utilized: 7.41 GB
Memory Efficiency: 0.00% of 0.00 MB
