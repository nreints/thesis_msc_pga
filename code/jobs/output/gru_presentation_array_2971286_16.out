wandb: Currently logged in as: nreints. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_164543-y0tcnm5j
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run avid-wind-25
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal1/runs/y0tcnm5j
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone â–ˆâ–‚â–‚â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone â–ˆâ–‚â–‚â–â–â–â–â–â–â–
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone â–ˆâ–‚â–‚â–â–â–â–â–â–â–
wandb:                                   Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone 0.00279
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 0.00055
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone 0.00057
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 0.00428
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 0.00483
wandb:                                   Train loss 0.00188
wandb: 
wandb: ðŸš€ View run avid-wind-25 at: https://wandb.ai/nreints/ThesisFinal1/runs/y0tcnm5j
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_164543-y0tcnm5j/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_165428-s5y8jyp6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run apricot-violet-56
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal1/runs/s5y8jyp6
Training on dataset: data_t(5,20)_r(5,20)_combi_pNone_gNone
Testing on 5 datasets: ['data_t(5,20)_r(5,20)_none_pNone_gNone', 'data_t(5,20)_r(5,20)_tennis_pNone_gNone', 'data_t(5,20)_r(5,20)_semi_pNone_gNone', 'data_t(5,20)_r(5,20)_combi_pNone_gNone', 'data_t(5,20)_r(5,20)_full_pNone_gNone']
Focussing on identity: False
Using extra input: False
Using start-fr as reference point.
----- ITERATION 1/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 77.66767644882202 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_none_pNone_gNone took 19.71104097366333 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 19.73538374900818 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 19.969111919403076 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 19.721498727798462 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 19.742000818252563 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: quat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 4.2519721985 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.1666058749 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.2124980241 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.1956023127 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.2060898095 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.161040172 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 34.27485752105713
Epoch 1/9
	 Logging train Loss: 0.0775425285 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0248841904 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0466077179 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0393812992 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0398463868 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0231061913 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 33.3979070186615
Epoch 2/9
	 Logging train Loss: 0.0223950502 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0100882724 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.022462992 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0191308353 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0182540417 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0092364186 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 33.19825053215027
Epoch 3/9
	 Logging train Loss: 0.0118105719 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0051037404 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0143323094 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0124526052 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0107644983 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.004698128 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 32.9645471572876
Epoch 4/9
	 Logging train Loss: 0.0074177063 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0028603533 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.009338202 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0082169846 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0067542852 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0026321069 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 33.3848180770874
Epoch 5/9
	 Logging train Loss: 0.0051819854 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0017659165 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0087826671 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0077915997 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0057085166 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0016439869 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 33.31043219566345
Epoch 6/9
	 Logging train Loss: 0.0037826838 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0011668536 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0066158366 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0058704102 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0042068418 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0011133348 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 34.1424446105957
Epoch 7/9
	 Logging train Loss: 0.0028981927 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0007954816 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0041202311 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0039040591 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0026526924 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0007504747 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 33.703184366226196
Epoch 8/9
	 Logging train Loss: 0.0023206226 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0006518393 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0035272243 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0033147756 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0022403719 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.000635868 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 33.359113454818726
Epoch 9/9
	 Logging train Loss: 0.0018776845 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0005747424 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0048346501 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0042786659 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0027853716 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0005536029 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 33.3750262260437
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gNone/'quat'_'False'.pth
It took  526.4541335105896  seconds.
----- ITERATION 2/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 77.85480546951294 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_none_pNone_gNone took 19.63555335998535 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 19.544013500213623 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 19.600170135498047 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 19.457335233688354 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 19.571852445602417 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: quat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 3.8533210754 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.1415163279 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.1852337718 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.1722114086 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.1624197811 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone â–ˆâ–‚â–‚â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone â–ˆâ–‚â–‚â–â–â–â–â–â–â–
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–
wandb:                                   Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone 0.00184
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 0.00045
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone 0.0005
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 0.00268
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 0.00307
wandb:                                   Train loss 0.00192
wandb: 
wandb: ðŸš€ View run apricot-violet-56 at: https://wandb.ai/nreints/ThesisFinal1/runs/s5y8jyp6
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_165428-s5y8jyp6/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_170314-d9shmfe7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run silvery-morning-91
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal1/runs/d9shmfe7
	 Logging test loss: 0.1332872808 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 33.236899614334106
Epoch 1/9
	 Logging train Loss: 0.0675379485 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.02325847 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.042926129 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0379954465 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0331069827 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0203941483 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 33.4861786365509
Epoch 2/9
	 Logging train Loss: 0.020412486 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0095304651 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0233756993 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0201492365 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0164202843 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0083024725 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 34.05296993255615
Epoch 3/9
	 Logging train Loss: 0.0108589586 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0048026028 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0143043473 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0122150658 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0096896393 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0042321947 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 33.674006938934326
Epoch 4/9
	 Logging train Loss: 0.0070015462 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0028138002 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0100842621 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.008739098 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0066267541 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0024972176 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 33.89488410949707
Epoch 5/9
	 Logging train Loss: 0.0048886104 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0017753533 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0081522623 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0071118609 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0051272293 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0015900561 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 33.94143509864807
Epoch 6/9
	 Logging train Loss: 0.0036669278 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.001203609 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0056688543 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.004934621 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0035370132 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0010844611 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 33.91439747810364
Epoch 7/9
	 Logging train Loss: 0.0028810867 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.000843826 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0042499756 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0038163562 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0026579241 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0007676487 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 33.67384934425354
Epoch 8/9
	 Logging train Loss: 0.0023362141 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0008342327 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0076043233 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0065570101 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0042926613 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0007862839 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 33.75999164581299
Epoch 9/9
	 Logging train Loss: 0.0019231951 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0004994237 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0030749892 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0026800376 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0018361089 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0004538563 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 33.878246784210205
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gNone/'quat'_'False'.pth
It took  525.1985034942627  seconds.
----- ITERATION 3/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 76.5406813621521 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_none_pNone_gNone took 19.51069164276123 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 19.499212980270386 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 19.59831428527832 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 19.354841709136963 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 19.594566106796265 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: quat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 4.0788989067 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.1758556664 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.2043538988 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.2137525976 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.2025736421 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.1660826504 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 33.55940055847168
Epoch 1/9
	 Logging train Loss: 0.0803740546 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0266795214 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0449510254 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0448241755 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0383147299 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0243875179 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 33.49370813369751
Epoch 2/9
	 Logging train Loss: 0.0228750072 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0103612579 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0220193826 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0217620675 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0171934813 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.009331163 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 34.320820331573486
Epoch 3/9
	 Logging train Loss: 0.0119347749 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0055239657 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0176348519 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0167889912 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0119102392 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0049384274 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 33.881906509399414
Epoch 4/9
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone â–ˆâ–‚â–‚â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone â–ˆâ–‚â–‚â–â–â–â–â–â–â–
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone â–ˆâ–‚â–‚â–â–â–â–â–â–â–
wandb:                                   Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone 0.00263
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 0.00057
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone 0.00061
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 0.00437
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 0.00457
wandb:                                   Train loss 0.00197
wandb: 
wandb: ðŸš€ View run silvery-morning-91 at: https://wandb.ai/nreints/ThesisFinal1/runs/d9shmfe7
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_170314-d9shmfe7/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_171155-ysk6qiyu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run solar-sound-121
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal1/runs/ysk6qiyu
	 Logging train Loss: 0.0075969771 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0030963973 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0103156716 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0101630818 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0069265594 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0027702681 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 33.42795944213867
Epoch 5/9
	 Logging train Loss: 0.0053792507 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0019592044 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0080809221 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0078297248 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0051385262 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0017721782 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 33.39409279823303
Epoch 6/9
	 Logging train Loss: 0.0039616679 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0012832308 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0054849773 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0052621625 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.003392627 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0011594364 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 33.3961443901062
Epoch 7/9
	 Logging train Loss: 0.0030601912 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0009106717 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0048969579 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.004741739 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0029377062 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0008304134 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 33.538177490234375
Epoch 8/9
	 Logging train Loss: 0.0024895163 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.000691399 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0035706039 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0034040567 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0021787232 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0006410819 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 33.5082893371582
Epoch 9/9
	 Logging train Loss: 0.0019671342 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0006100222 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0045720967 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0043682009 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0026307132 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0005687803 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 33.41899394989014
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gNone/'quat'_'False'.pth
It took  521.471155166626  seconds.
----- ITERATION 4/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 76.4271252155304 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_none_pNone_gNone took 19.37806010246277 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 19.442371129989624 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 19.41108775138855 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 19.18761420249939 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 19.371075868606567 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: quat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 3.9312169552 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.1424105316 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.1915077865 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.1991737336 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.1782426536 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.156290099 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 33.50455451011658
Epoch 1/9
	 Logging train Loss: 0.0741242468 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0216804259 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.044597771 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0455251522 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0348029956 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0249998756 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 33.802151679992676
Epoch 2/9
	 Logging train Loss: 0.0224637017 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0083875097 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0215088613 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0218002107 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0153239937 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0098376488 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 33.72196674346924
Epoch 3/9
	 Logging train Loss: 0.0114900218 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0041601183 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0131464023 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0135307591 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0088091008 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0049116327 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 33.447622776031494
Epoch 4/9
	 Logging train Loss: 0.0072237789 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0023766626 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0091921752 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0096039232 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0059033115 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0028335566 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 33.64318132400513
Epoch 5/9
	 Logging train Loss: 0.0051020305 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0015531862 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0066947313 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0068819998 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0042348518 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0018496318 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 33.565096378326416
Epoch 6/9
	 Logging train Loss: 0.0037097174 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0010754855 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0054324768 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0055902004 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0032576483 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0012656412 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 33.69016361236572
Epoch 7/9
	 Logging train Loss: 0.0028863854 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0008315233 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone â–ˆâ–‚â–‚â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–
wandb:                                   Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone 0.00154
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 0.0005
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone 0.00043
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 0.00268
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 0.00265
wandb:                                   Train loss 0.00184
wandb: 
wandb: ðŸš€ View run solar-sound-121 at: https://wandb.ai/nreints/ThesisFinal1/runs/ysk6qiyu
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_171155-ysk6qiyu/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_172036-gp59gbo8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run silver-snowflake-153
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal1/runs/gp59gbo8
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone â–ˆâ–‚â–‚â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone â–ˆâ–‚â–‚â–â–â–â–â–â–â–
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone â–ˆâ–‚â–‚â–â–â–â–â–â–â–
wandb:                                   Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone 0.00195
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 0.00046
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone 0.00055
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 0.00335
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 0.0033
wandb:                                   Train loss 0.00182
wandb: 
wandb: ðŸš€ View run silver-snowflake-153 at: https://wandb.ai/nreints/ThesisFinal1/runs/gp59gbo8
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_172036-gp59gbo8/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_172918-bu3nf0so
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run morning-gorge-183
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal1/runs/bu3nf0so
	 Logging test loss: 0.0057469774 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0055748397 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0033042196 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0009706863 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 33.31684684753418
Epoch 8/9
	 Logging train Loss: 0.0022683828 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0005906433 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0030463231 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0030560473 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0018194602 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0006836763 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 33.61637783050537
Epoch 9/9
	 Logging train Loss: 0.0018433352 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0004302644 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0026470982 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0026790369 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0015427433 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0005010401 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 33.40033769607544
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gNone/'quat'_'False'.pth
It took  521.4154050350189  seconds.
----- ITERATION 5/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 76.24365448951721 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_none_pNone_gNone took 19.30365777015686 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 19.28141140937805 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 19.414780616760254 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 19.31623888015747 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 19.454635858535767 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: quat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 4.1425027847 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.1751295775 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.2006006539 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.2085923702 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.2031704485 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.1657525897 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 33.47597050666809
Epoch 1/9
	 Logging train Loss: 0.0776413381 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0303494874 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0455073677 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0468959548 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0409959145 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0254883878 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 33.44602370262146
Epoch 2/9
	 Logging train Loss: 0.0234062206 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0128631573 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0229831636 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0238468647 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0191817898 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0103328815 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 33.39927625656128
Epoch 3/9
	 Logging train Loss: 0.0123350667 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0064155967 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0132613219 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0139284059 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0105840825 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0050773062 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 33.34227418899536
Epoch 4/9
	 Logging train Loss: 0.0075745312 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0036212197 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0111426841 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.011066813 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0077489899 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0029305632 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 33.484148025512695
Epoch 5/9
	 Logging train Loss: 0.0051563811 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0021715167 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0064977789 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0067218025 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0045623537 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0017742179 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 33.54093885421753
Epoch 6/9
	 Logging train Loss: 0.0038024979 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0014881184 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0072760028 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0074461624 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0046505053 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0012322835 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 33.64344358444214
Epoch 7/9
	 Logging train Loss: 0.0027998993 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0010480941 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0039478713 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0041046254 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0026444376 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0008760354 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 33.44659447669983
Epoch 8/9
	 Logging train Loss: 0.0022934289 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0007197981 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0033953688 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0035495751 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0021473481 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0006079229 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 33.53315877914429
Epoch 9/9
	 Logging train Loss: 0.0018247649 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0005453623 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0032952155 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0033514267 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0019546128 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0004635755 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 33.734821796417236
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gNone/'quat'_'False'.pth
It took  521.1876692771912  seconds.
----- ITERATION 6/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone â–ˆâ–‚â–‚â–â–â–â–â–â–â–
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone â–ˆâ–‚â–‚â–â–â–â–â–â–â–
wandb:                                   Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone 0.00177
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 0.00054
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone 0.00058
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 0.00302
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 0.003
wandb:                                   Train loss 0.00176
wandb: 
wandb: ðŸš€ View run morning-gorge-183 at: https://wandb.ai/nreints/ThesisFinal1/runs/bu3nf0so
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_172918-bu3nf0so/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_173757-m2fhqc3s
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run helpful-feather-215
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal1/runs/m2fhqc3s
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 76.08857941627502 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_none_pNone_gNone took 19.42479133605957 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 19.444886445999146 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 19.357274055480957 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 19.171175718307495 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 19.432457208633423 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: quat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 3.9440202713 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.1742303073 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.2017183602 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.2118482292 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.1949191391 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.1622409523 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 33.57345390319824
Epoch 1/9
	 Logging train Loss: 0.076888226 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0267392788 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0423300564 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0426332504 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0346272178 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0235129297 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 33.29056453704834
Epoch 2/9
	 Logging train Loss: 0.0223538447 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0107821738 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0207381602 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.020386545 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0155342948 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0093310233 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 33.13615369796753
Epoch 3/9
	 Logging train Loss: 0.0116766077 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0055097211 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0128139844 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0125986757 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.00910566 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0047835079 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 33.25843691825867
Epoch 4/9
	 Logging train Loss: 0.0073337061 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0032364037 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0099794697 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0100165755 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0065284297 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0028657368 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 33.12631177902222
Epoch 5/9
	 Logging train Loss: 0.0051073795 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0020488668 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0074395104 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0075031356 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0046965024 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0018476492 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 33.56156516075134
Epoch 6/9
	 Logging train Loss: 0.0036008202 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0013243168 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0047476655 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0048158197 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0030332978 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0012086196 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 33.3165500164032
Epoch 7/9
	 Logging train Loss: 0.0027657095 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0010362507 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0040199226 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0040154755 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0025078354 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0009650316 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 33.33934712409973
Epoch 8/9
	 Logging train Loss: 0.0021882888 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0006700417 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0031260536 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0031144184 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.001867373 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0006174516 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 33.40961527824402
Epoch 9/9
	 Logging train Loss: 0.0017567786 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0005831106 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0030041423 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0030208738 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0017713462 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0005428139 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 33.31202268600464
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gNone/'quat'_'False'.pth
It took  519.5206880569458  seconds.
----- ITERATION 7/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 76.72231531143188 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_none_pNone_gNone took 19.32949185371399 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 19.329124450683594 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 19.406614780426025 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 19.348514080047607 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 19.41159415245056 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: quat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 4.0663805008 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.1691284776 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.1940143853 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.2129960656 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.1753521264 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.146904394 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 32.86375069618225
Epoch 1/9
	 Logging train Loss: 0.0762950853 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0265274532 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0424106345 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0447189137 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0328204669 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone â–ˆâ–‚â–‚â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone â–ˆâ–‚â–‚â–â–â–â–â–â–â–
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone â–ˆâ–‚â–‚â–â–â–â–â–â–â–
wandb:                                   Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone 0.00168
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 0.00049
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone 0.00053
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 0.00283
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 0.00286
wandb:                                   Train loss 0.00181
wandb: 
wandb: ðŸš€ View run helpful-feather-215 at: https://wandb.ai/nreints/ThesisFinal1/runs/m2fhqc3s
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_173757-m2fhqc3s/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_174633-5hj1iq8b
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lively-mountain-246
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal1/runs/5hj1iq8b
	 Logging test loss: 0.0222839005 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 33.186240434646606
Epoch 2/9
	 Logging train Loss: 0.0226090606 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0105786519 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0230431072 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0236993954 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0161625259 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0089390818 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 33.153836250305176
Epoch 3/9
	 Logging train Loss: 0.011647691 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0052822172 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0124699092 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0126589788 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0085694157 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0045336392 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 32.89197111129761
Epoch 4/9
	 Logging train Loss: 0.0073124957 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0030864291 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0096304705 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0095864916 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0061600967 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0027101932 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 32.62864375114441
Epoch 5/9
	 Logging train Loss: 0.005056615 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0020303717 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0080420654 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0078707263 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0049401447 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.001814038 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 33.0640344619751
Epoch 6/9
	 Logging train Loss: 0.0037821247 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0014241614 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0053385687 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0052770283 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0033386163 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0012956016 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 32.80755567550659
Epoch 7/9
	 Logging train Loss: 0.0028431206 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0009232423 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0042582569 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0041207457 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0025313972 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0008465397 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 32.97755670547485
Epoch 8/9
	 Logging train Loss: 0.002266861 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0006509619 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.002894297 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0028879337 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0017544196 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0005973595 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 33.07785391807556
Epoch 9/9
	 Logging train Loss: 0.0018141196 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0005274666 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0028567214 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0028340383 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0016830632 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0004887768 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 32.88232064247131
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gNone/'quat'_'False'.pth
It took  515.5166103839874  seconds.
----- ITERATION 8/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 76.24949431419373 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_none_pNone_gNone took 19.32569193840027 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 19.35064148902893 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 19.389512538909912 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 19.248762845993042 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 19.3839910030365 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: quat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 3.8487656116 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.1545557529 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.2137025893 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.193652764 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.1904224455 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.154082343 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 32.775643825531006
Epoch 1/9
	 Logging train Loss: 0.0765211359 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0224386714 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0458985344 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0395529568 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0341671072 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0210962854 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 33.07182335853577
Epoch 2/9
	 Logging train Loss: 0.02231865 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0092268344 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0236500148 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0207353625 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0164850168 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0084138764 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 32.80713963508606
Epoch 3/9
	 Logging train Loss: 0.0116776302 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.004694635 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.014820979 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0131885344 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0095613115 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0042296518 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 32.985759258270264
Epoch 4/9
	 Logging train Loss: 0.0072066169 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0026828661 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0095339175 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0085553033 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.005980697 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0023993524 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 32.972267866134644
Epoch 5/9
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone â–ˆâ–‚â–‚â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone â–ˆâ–‚â–‚â–â–â–â–â–â–â–
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone â–ˆâ–‚â–‚â–â–â–â–â–â–â–
wandb:                                   Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone 0.00176
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 0.00051
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone 0.00055
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 0.00287
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 0.00309
wandb:                                   Train loss 0.00191
wandb: 
wandb: ðŸš€ View run lively-mountain-246 at: https://wandb.ai/nreints/ThesisFinal1/runs/5hj1iq8b
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_174633-5hj1iq8b/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_175508-vpbgmpzn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run mild-tree-273
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal1/runs/vpbgmpzn
	 Logging train Loss: 0.0050499239 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0016716972 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0068979901 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0065541044 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0042802976 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0014907226 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 32.982428550720215
Epoch 6/9
	 Logging train Loss: 0.0037635369 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0011528742 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0052233418 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0047452883 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0031100498 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0010392934 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 33.15602731704712
Epoch 7/9
	 Logging train Loss: 0.0029532784 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0007999472 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0038537278 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0036881312 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0022946862 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0007250028 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 33.76789903640747
Epoch 8/9
	 Logging train Loss: 0.0022259085 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0005994078 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0033009043 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0030756819 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0018736938 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0005494552 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 32.866838216781616
Epoch 9/9
	 Logging train Loss: 0.0019068918 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0005497959 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0030939281 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0028725166 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0017648239 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0005086185 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 33.06200838088989
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gNone/'quat'_'False'.pth
It took  515.594804763794  seconds.
----- ITERATION 9/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 76.19837594032288 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_none_pNone_gNone took 19.269367933273315 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 19.296785593032837 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 19.34391212463379 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 19.206259965896606 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 19.277387380599976 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: quat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 3.9912278652 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.196061343 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.2276025563 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.2121895105 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.2109637856 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.1814175099 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 32.81772303581238
Epoch 1/9
	 Logging train Loss: 0.0816466957 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.02944264 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0446451567 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0404856652 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0361706316 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0246506985 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 32.9681134223938
Epoch 2/9
	 Logging train Loss: 0.0218241047 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0117918579 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0257062372 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0235073883 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0183299165 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0095611932 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 32.84367108345032
Epoch 3/9
	 Logging train Loss: 0.0116473092 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0062287147 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0157804433 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0142476344 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0107132653 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.005004216 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 32.693000078201294
Epoch 4/9
	 Logging train Loss: 0.0075521837 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0035961403 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.010496743 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0096921269 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0070205438 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0028823726 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 32.77401638031006
Epoch 5/9
	 Logging train Loss: 0.0054449611 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.002266106 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0083283838 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0077940631 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.005384733 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.001816141 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 32.959057092666626
Epoch 6/9
	 Logging train Loss: 0.0040829759 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0015670026 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0076570427 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.006865338 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0045017418 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0012881076 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 32.799046993255615
Epoch 7/9
	 Logging train Loss: 0.0031822429 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0011626175 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.007736926 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0069322274 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0043637939 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0009596039 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 32.994028091430664
Epoch 8/9
	 Logging train Loss: 0.002600187 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0007689956 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: ERROR Error while calling W&B API: An internal error occurred. Please contact support. (<Response [500]>)
wandb: 
wandb: Run history:
wandb:                                        Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone â–ˆâ–‚â–‚â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone â–ˆâ–‚â–‚â–â–â–â–â–â–â–
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone â–ˆâ–‚â–‚â–â–â–â–â–â–â–
wandb:                                   Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone 0.00285
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 0.00056
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone 0.00066
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 0.00452
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 0.00514
wandb:                                   Train loss 0.00212
wandb: 
wandb: ðŸš€ View run mild-tree-273 at: https://wandb.ai/nreints/ThesisFinal1/runs/vpbgmpzn
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_175508-vpbgmpzn/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_180343-atvyr6fw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run breezy-salad-302
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal1/runs/atvyr6fw
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone â–ˆâ–‚â–‚â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone â–ˆâ–‚â–‚â–â–â–â–â–â–â–
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone â–ˆâ–‚â–‚â–â–â–â–â–â–â–
wandb:                                   Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone 0.00195
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 0.00045
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone 0.00048
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 0.0034
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 0.00351
wandb:                                   Train loss 0.00206
wandb: 
wandb: ðŸš€ View run breezy-salad-302 at: https://wandb.ai/nreints/ThesisFinal1/runs/atvyr6fw
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_180343-atvyr6fw/logs
	 Logging test loss: 0.0039897715 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0036097118 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0023783199 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0006353026 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 32.922931432724
Epoch 9/9
	 Logging train Loss: 0.0021195109 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0006559613 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0051388429 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0045180977 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0028541337 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.000559443 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 33.05660033226013
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gNone/'quat'_'False'.pth
It took  515.0772504806519  seconds.
----- ITERATION 10/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 76.45117235183716 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_none_pNone_gNone took 19.29348874092102 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 19.32820415496826 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 19.380199432373047 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 19.249411582946777 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 19.356478691101074 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: quat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 4.1800284386 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.16865924 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.2030676007 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.1997686476 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.1804176867 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.1519044489 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 33.060051918029785
Epoch 1/9
	 Logging train Loss: 0.0797589198 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.02630312 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0434528552 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0410421714 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0326900855 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0223539006 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 32.98569965362549
Epoch 2/9
	 Logging train Loss: 0.0227920376 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0098262131 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0216314476 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0202319697 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.014732141 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0083637219 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 33.218759298324585
Epoch 3/9
	 Logging train Loss: 0.0116907777 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0048467973 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0131766861 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.01252166 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0084474655 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0041620247 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 33.014121294021606
Epoch 4/9
	 Logging train Loss: 0.0075122514 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0028374419 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0108453194 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0105345063 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0064789131 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0024894669 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 33.52598810195923
Epoch 5/9
	 Logging train Loss: 0.0052437754 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0017316525 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0067017493 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.006467381 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0040546446 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0015560733 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 33.53847599029541
Epoch 6/9
	 Logging train Loss: 0.0040387921 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0011945199 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0051557687 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0050972379 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0031119364 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0010971499 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 33.22438073158264
Epoch 7/9
	 Logging train Loss: 0.0031161415 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0008474695 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0053064241 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.005044159 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0029660601 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0007858814 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 33.005521059036255
Epoch 8/9
	 Logging train Loss: 0.0024895493 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0006459855 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0046423334 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0044135866 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0026306869 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0006035817 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 33.208510875701904
Epoch 9/9
	 Logging train Loss: 0.0020624152 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0004845032 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0035051971 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0033973036 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0019512078 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0004502558 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 33.06305527687073
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gNone/'quat'_'False'.pth
It took  516.8924696445465  seconds.

JOB STATISTICS
==============
Job ID: 2971303
Array Job ID: 2971286_16
Cluster: snellius
User/Group: nreints/nreints
State: RUNNING
Nodes: 1
Cores per node: 18
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 1-02:04:12 core-walltime
Job Wall-clock time: 01:26:54
Memory Utilized: 0.00 MB (estimated maximum)
Memory Efficiency: 0.00% of 0.00 MB (0.00 MB/node)
WARNING: Efficiency statistics may be misleading for RUNNING jobs.
