wandb: Currently logged in as: nreints. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_125108-4k283rf5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fluent-blaze-6
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/4k283rf5
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue â–ˆâ–…â–„â–ƒâ–‚â–‚â–‚â–â–â–
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue â–ˆâ–…â–ƒâ–‚â–‚â–‚â–â–â–â–
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue â–ˆâ–„â–ƒâ–‚â–‚â–‚â–â–â–‚â–‚
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue â–ˆâ–…â–ƒâ–‚â–‚â–‚â–â–â–â–
wandb:                                 Train loss â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue 0.0046
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 0.00014
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.00883
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.01661
wandb:                                 Train loss 0.00266
wandb: 
wandb: ðŸš€ View run fluent-blaze-6 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/4k283rf5
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_125108-4k283rf5/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_125856-a95c8sae
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stellar-salad-60
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/a95c8sae
Training on dataset: data_t(0,0)_r(0,0)_combi_pTrue_gTrue
Testing on 4 datasets: ['data_t(0,0)_r(0,0)_full_pTrue_gTrue', 'data_t(0,0)_r(0,0)_combi_pTrue_gTrue', 'data_t(0,0)_r(0,0)_semi_pTrue_gTrue', 'data_t(0,0)_r(0,0)_tennis_pTrue_gTrue']
Focussing on identity: False
Using extra input: False
Using start-fr as reference point.
----- ITERATION 1/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 78.36813354492188 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 20.000215768814087 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 20.006656408309937 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 19.59737229347229 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 19.89247727394104 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: quat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.1794451326 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0019421611 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0402712785 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0353260897 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.1425980181 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 30.53476905822754
Epoch 1/9
	 Logging train Loss: 0.0210321471 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0011681764 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0232945587 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0184156448 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.084914811 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 29.673301219940186
Epoch 2/9
	 Logging train Loss: 0.0112564974 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0006856867 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0190825146 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.013945125 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0558433048 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 29.44747829437256
Epoch 3/9
	 Logging train Loss: 0.0084319133 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0003525101 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0133577595 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0089852316 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0431767255 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 29.59093403816223
Epoch 4/9
	 Logging train Loss: 0.0059726029 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.000353872 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0120176505 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0083283046 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0350902751 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 29.70480251312256
Epoch 5/9
	 Logging train Loss: 0.0058339755 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0004062789 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0096096378 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0100922622 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0322552621 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 29.751304149627686
Epoch 6/9
	 Logging train Loss: 0.0056477236 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0002186475 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0075106006 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0070619793 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0248049945 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 29.67318892478943
Epoch 7/9
	 Logging train Loss: 0.0048306733 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0001353556 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0047732918 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0052295523 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0166127421 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 29.514899015426636
Epoch 8/9
	 Logging train Loss: 0.0050850171 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0001419284 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0044966987 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.00785043 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0165730342 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 29.613422632217407
Epoch 9/9
	 Logging train Loss: 0.0026638466 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0001400866 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0045999009 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0088287219 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.01660873 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 29.695441007614136
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pTrue_gTrue/'quat'_'False'.pth
It took  469.1464922428131  seconds.
----- ITERATION 2/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 79.058598279953 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 19.910335779190063 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 19.73434042930603 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 19.969199180603027 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 20.005790948867798 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: quat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.117616646 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0001695308 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0181777626 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0104837213 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0751429349 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 30.1545307636261
Epoch 1/9
	 Logging train Loss: 0.0037715184 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 5.96601e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.007836841 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0039618565 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0373008661 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 30.089979648590088
Epoch 2/9
	 Logging train Loss: 0.001559569 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 4.91155e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0060558752 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0080081122 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0304716844 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 29.865833044052124
Epoch 3/9
	 Logging train Loss: 0.0008804338 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.67247e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0030740139 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0015448311 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0168792456 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 29.94921040534973
Epoch 4/9
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue â–ˆâ–„â–ƒâ–‚â–â–â–â–â–â–
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue â–ˆâ–ƒâ–ƒâ–‚â–‚â–‚â–â–â–â–
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue â–ˆâ–ƒâ–†â–‚â–‚â–‚â–â–â–â–
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue â–ˆâ–„â–„â–‚â–‚â–‚â–â–â–â–
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue 0.0005
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 1e-05
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.00059
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.00329
wandb:                                 Train loss 0.00014
wandb: 
wandb: ðŸš€ View run stellar-salad-60 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/a95c8sae
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_125856-a95c8sae/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_130646-bddbhi38
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run blooming-star-99
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/bddbhi38
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue â–ˆâ–‚â–‚â–â–â–â–â–â–â–
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue â–ˆâ–‚â–‚â–â–â–â–â–â–â–
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue â–ˆâ–„â–ƒâ–‚â–â–â–â–â–â–
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue 0.00095
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 3e-05
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.00095
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.00343
wandb:                                 Train loss 0.00021
wandb: 
wandb: ðŸš€ View run blooming-star-99 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/bddbhi38
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_130646-bddbhi38/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_131436-7rd3ixvv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wobbly-voice-136
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/7rd3ixvv
	 Logging train Loss: 0.000595752 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.50314e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0017083319 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0011915695 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0123914266 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 29.829583644866943
Epoch 5/9
	 Logging train Loss: 0.0003968136 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.27028e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0017136041 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0011730939 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0098410239 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 29.997607469558716
Epoch 6/9
	 Logging train Loss: 0.0004485458 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.31633e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0010890616 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0006493179 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0070106606 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 29.67646360397339
Epoch 7/9
	 Logging train Loss: 0.0002970939 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.27681e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0010337753 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0009072911 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0062846895 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 29.90426993370056
Epoch 8/9
	 Logging train Loss: 0.0001298519 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 9.8678e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0006567437 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0003836195 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0039011345 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 29.73258090019226
Epoch 9/9
	 Logging train Loss: 0.000141974 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 6.7079e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0005019 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0005897654 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.003285371 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 29.964361906051636
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pTrue_gTrue/'quat'_'False'.pth
It took  470.0229535102844  seconds.
----- ITERATION 3/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 77.82717037200928 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 19.815140962600708 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 19.51998019218445 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 19.811617612838745 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 19.867512226104736 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: quat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.1556507796 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0007898138 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.032303527 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0302192736 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.1083262265 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 29.841374397277832
Epoch 1/9
	 Logging train Loss: 0.0088949399 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0001616773 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0060152062 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0051813591 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0473775491 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 29.641300678253174
Epoch 2/9
	 Logging train Loss: 0.002254857 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 6.01844e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0053682928 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0055398019 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0279894378 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 30.01058030128479
Epoch 3/9
	 Logging train Loss: 0.0009793323 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 3.54593e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0013711421 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0010849953 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0106157558 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 29.70283341407776
Epoch 4/9
	 Logging train Loss: 0.0005661013 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.44792e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0009260513 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0007737848 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.007859109 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 29.673670530319214
Epoch 5/9
	 Logging train Loss: 0.0004737106 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.02498e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.000630563 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0008461648 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0062265247 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 29.732620000839233
Epoch 6/9
	 Logging train Loss: 0.0004284523 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.21559e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0005339514 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.000512922 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0045790928 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 30.011242866516113
Epoch 7/9
	 Logging train Loss: 0.0001944386 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.23932e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0003425065 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0003375815 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0032111849 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 29.665125131607056
Epoch 8/9
	 Logging train Loss: 0.000253132 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 9.1706e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0002834822 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0002709434 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0025743828 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 30.0059757232666
Epoch 9/9
	 Logging train Loss: 0.0002105487 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 3.46284e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0009505315 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0009489455 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.003434873 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 29.81543278694153
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pTrue_gTrue/'quat'_'False'.pth
It took  470.07619428634644  seconds.
----- ITERATION 4/10 ------
Number of train simulations:  1920
Number of test simulations:  480
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue â–ˆâ–„â–ƒâ–‚â–‚â–â–â–â–â–
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue â–ˆâ–„â–‚â–‚â–‚â–â–â–â–â–
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue â–ˆâ–„â–‚â–‚â–‚â–â–â–â–â–
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue 0.00046
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.00028
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.00085
wandb:                                 Train loss 0.00018
wandb: 
wandb: ðŸš€ View run wobbly-voice-136 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/7rd3ixvv
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_131436-7rd3ixvv/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_132223-tl3pupcl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run clear-sun-169
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/tl3pupcl
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 78.141930103302 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 19.8200786113739 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 19.420478343963623 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 19.810094118118286 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 19.81092667579651 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: quat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.145821169 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0002064817 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0152686648 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.011133044 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0237237532 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 30.171510457992554
Epoch 1/9
	 Logging train Loss: 0.0047145761 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 8.96463e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0063879234 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0038831639 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0091115916 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 29.61784052848816
Epoch 2/9
	 Logging train Loss: 0.0016288547 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 4.30202e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0038080837 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0019351013 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0052772034 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 29.82483673095703
Epoch 3/9
	 Logging train Loss: 0.0008276771 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.6656e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0020884741 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0012128663 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0030197285 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 29.727933406829834
Epoch 4/9
	 Logging train Loss: 0.0006412614 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.04918e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.001631479 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0009501156 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0025394489 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 29.832509517669678
Epoch 5/9
	 Logging train Loss: 0.0005447472 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.43243e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0014256255 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0008366954 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0022346789 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 29.60005259513855
Epoch 6/9
	 Logging train Loss: 0.000356666 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.10774e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0009438932 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0006020952 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0018508619 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 29.865997076034546
Epoch 7/9
	 Logging train Loss: 0.0001965917 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 9.8094e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0007798648 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0004448254 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0013974141 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 29.775270462036133
Epoch 8/9
	 Logging train Loss: 0.0002110568 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 6.6865e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0005088557 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0002504196 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.000900962 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 29.99454092979431
Epoch 9/9
	 Logging train Loss: 0.0001750945 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.833e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.00045948 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0002811388 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0008497011 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 29.998576879501343
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pTrue_gTrue/'quat'_'False'.pth
It took  467.0236747264862  seconds.
----- ITERATION 5/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 78.03069162368774 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 19.741009950637817 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 19.619860649108887 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 19.79653787612915 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 19.823221445083618 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: quat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.1199095845 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0001588132 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0051755644 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.020495547 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0444102027 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 30.03254008293152
Epoch 1/9
	 Logging train Loss: 0.0037407482 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 6.25879e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0015964844 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0076167271 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0189946964 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 29.588629722595215
Epoch 2/9
	 Logging train Loss: 0.0014941701 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 3.49794e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0009562835 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0044341553 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0111863557 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 29.784645080566406
Epoch 3/9
	 Logging train Loss: 0.0008684761 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.49575e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0005174896 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0028289964 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0065174177 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 29.752254962921143
Epoch 4/9
	 Logging train Loss: 0.0006437389 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.08221e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.000407313 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0019598538 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0053239604 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 29.754791736602783
Epoch 5/9
wandb: Waiting for W&B process to finish... (success).
wandb: ERROR Error while calling W&B API: An internal error occurred. Please contact support. (<Response [500]>)
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue â–ˆâ–ƒâ–‚â–‚â–â–â–‚â–â–â–
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue â–ˆâ–„â–‚â–‚â–‚â–â–â–â–â–
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue â–ˆâ–„â–ƒâ–‚â–‚â–â–â–â–â–
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue 0.00039
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 2e-05
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.00102
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.00234
wandb:                                 Train loss 0.00013
wandb: 
wandb: ðŸš€ View run clear-sun-169 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/tl3pupcl
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_132223-tl3pupcl/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_133014-vt161eyg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run worldly-leaf-211
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/vt161eyg
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue â–ˆâ–ƒâ–‚â–‚â–‚â–â–â–‚â–â–
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue â–ˆâ–„â–ƒâ–‚â–‚â–â–â–â–â–
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue â–ˆâ–ƒâ–‚â–‚â–‚â–â–â–‚â–â–
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue â–ˆâ–„â–ƒâ–‚â–‚â–â–â–â–â–
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue 6e-05
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 1e-05
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.00015
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.00171
wandb:                                 Train loss 0.00016
wandb: 
wandb: ðŸš€ View run worldly-leaf-211 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/vt161eyg
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_133014-vt161eyg/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_133802-spplut6u
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rose-moon-248
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/spplut6u
	 Logging train Loss: 0.0004996831 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.51295e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0003180224 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.001603255 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0037447577 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 29.76759386062622
Epoch 6/9
	 Logging train Loss: 0.0004204293 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.60969e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0006205065 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0016425444 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0046638893 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 29.626863718032837
Epoch 7/9
	 Logging train Loss: 0.0002256028 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.58557e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0002429954 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0011919618 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0025399656 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 29.914215803146362
Epoch 8/9
	 Logging train Loss: 0.0003287389 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 8.5547e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0001461846 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0006398965 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0017584861 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 29.62630033493042
Epoch 9/9
	 Logging train Loss: 0.0001338181 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.51487e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.000392609 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0010183993 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0023433885 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 29.78855037689209
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pTrue_gTrue/'quat'_'False'.pth
It took  471.04512572288513  seconds.
----- ITERATION 6/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 77.96287775039673 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 19.726975202560425 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 19.585655689239502 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 19.753432512283325 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 19.772674083709717 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: quat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.1534318477 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0001489453 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.003100246 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0086935274 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0593283214 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 29.764585733413696
Epoch 1/9
	 Logging train Loss: 0.0042415303 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 6.22836e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0009739288 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0029238225 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0243639704 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 29.89883065223694
Epoch 2/9
	 Logging train Loss: 0.0017349094 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 4.25945e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0006175055 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0018122442 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0160469338 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 29.916635274887085
Epoch 3/9
	 Logging train Loss: 0.000872849 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 3.01746e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0004186043 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0012261133 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0094788112 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 29.856839179992676
Epoch 4/9
	 Logging train Loss: 0.0006930947 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.26234e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0003070454 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.000907366 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0071481592 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 30.046834230422974
Epoch 5/9
	 Logging train Loss: 0.0004275361 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.86234e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0001685482 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0006208412 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0046242448 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 29.999921560287476
Epoch 6/9
	 Logging train Loss: 0.0003726472 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.10419e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0001533165 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0005206959 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0037554577 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 30.073500156402588
Epoch 7/9
	 Logging train Loss: 0.0002078667 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.38671e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0004000627 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0012287291 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0044230684 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 29.904826879501343
Epoch 8/9
	 Logging train Loss: 0.0001823382 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 9.3633e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 7.59117e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.000267445 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0018251777 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 30.138349056243896
Epoch 9/9
	 Logging train Loss: 0.0001624647 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 9.571e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 5.90959e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0001513489 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0017088926 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 29.78102684020996
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pTrue_gTrue/'quat'_'False'.pth
It took  468.1828262805939  seconds.
----- ITERATION 7/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 78.59342098236084 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 19.800163984298706 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 19.681995153427124 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 19.759926557540894 seconds.
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue â–ˆâ–„â–‚â–‚â–‚â–â–â–â–â–
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue â–ˆâ–ƒâ–ƒâ–‚â–‚â–â–â–â–â–
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue â–ˆâ–„â–‚â–‚â–â–â–â–â–â–
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue 0.00053
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 1e-05
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.00028
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.00108
wandb:                                 Train loss 0.00034
wandb: 
wandb: ðŸš€ View run rose-moon-248 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/spplut6u
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_133802-spplut6u/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_134552-yazp32xp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fresh-plant-284
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/yazp32xp
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 19.751058101654053 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: quat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.1574538201 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0002781077 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.026636485 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.013929639 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0543747395 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 29.953659772872925
Epoch 1/9
	 Logging train Loss: 0.0051752813 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 8.47897e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0106525309 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0051532583 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0210597254 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 30.1378812789917
Epoch 2/9
	 Logging train Loss: 0.0017666357 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 4.11247e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0060573001 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0032062377 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0115388008 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 29.72697377204895
Epoch 3/9
	 Logging train Loss: 0.001039176 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.58489e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0037578552 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0016909543 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.006780684 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 29.92848801612854
Epoch 4/9
	 Logging train Loss: 0.0005969133 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.27584e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0024751816 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0013145783 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0047013597 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 29.843029260635376
Epoch 5/9
	 Logging train Loss: 0.0005547373 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.95926e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0023022087 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0008034665 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0040743398 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 30.043760776519775
Epoch 6/9
	 Logging train Loss: 0.0003952209 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.41615e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.001362929 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0006784246 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0026637493 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 30.040037631988525
Epoch 7/9
	 Logging train Loss: 0.0003909067 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.03834e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0009800452 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0005292129 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0019739885 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 30.003217697143555
Epoch 8/9
	 Logging train Loss: 0.0001910257 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.00445e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0014958292 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0009456869 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.003322911 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 29.897127866744995
Epoch 9/9
	 Logging train Loss: 0.0003425418 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 6.6375e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.000526946 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0002792588 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0010832924 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 30.04166889190674
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pTrue_gTrue/'quat'_'False'.pth
It took  469.3950369358063  seconds.
----- ITERATION 8/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 77.88393807411194 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 19.71227264404297 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 19.608519792556763 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 19.758626699447632 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 19.813907384872437 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: quat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.135293588 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0001724145 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0166004691 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0107196001 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0489879027 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 29.86210823059082
Epoch 1/9
	 Logging train Loss: 0.0040448783 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 6.84882e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0055208448 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0034447038 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0197165404 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 29.83952045440674
Epoch 2/9
	 Logging train Loss: 0.0016306582 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 3.92726e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0031162095 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0019586554 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0128138522 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 29.989141941070557
Epoch 3/9
	 Logging train Loss: 0.0009086889 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.65099e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0020466896 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0012063025 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0082031349 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 29.88771653175354
Epoch 4/9
	 Logging train Loss: 0.0005234195 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.77394e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0014996004 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0008539935 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0056965784 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 29.865002155303955
Epoch 5/9
	 Logging train Loss: 0.0004876731 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 6.06273e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0045079482 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0056242687 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0156357344 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue â–ˆâ–ƒâ–‚â–‚â–‚â–ƒâ–â–â–â–
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue â–ˆâ–„â–‚â–‚â–‚â–ƒâ–â–â–â–
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue â–ˆâ–ƒâ–‚â–‚â–â–…â–â–‚â–â–
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue â–ˆâ–„â–ƒâ–‚â–‚â–ƒâ–â–â–â–
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue 0.00028
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.00018
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.00114
wandb:                                 Train loss 0.00015
wandb: 
wandb: ðŸš€ View run fresh-plant-284 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/yazp32xp
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_134552-yazp32xp/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_135341-q7sxumku
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vital-feather-324
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/q7sxumku
wandb: Waiting for W&B process to finish... (success).
wandb: ERROR Error while calling W&B API: An internal error occurred. Please contact support. (<Response [500]>)
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue â–ˆâ–…â–„â–‚â–‚â–â–â–â–â–
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue â–ˆâ–‚â–‚â–â–â–â–â–â–â–
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue â–ˆâ–ƒâ–ƒâ–‚â–‚â–â–â–â–â–
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue â–ˆâ–…â–„â–‚â–ƒâ–â–â–â–â–
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue 0.00033
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 1e-05
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.00024
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.00213
wandb:                                 Train loss 0.00014
wandb: 
wandb: ðŸš€ View run vital-feather-324 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/q7sxumku
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_135341-q7sxumku/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_140142-yd7z2o6o
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run breezy-music-351
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/yd7z2o6o
		--> Epoch time; 29.690698862075806
Epoch 6/9
	 Logging train Loss: 0.0003897196 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.14682e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0007667921 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0004600448 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0030313092 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 30.002910614013672
Epoch 7/9
	 Logging train Loss: 0.0002683163 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.50148e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0012661256 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0013366129 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0044046962 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 29.659782648086548
Epoch 8/9
	 Logging train Loss: 0.0001670706 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 6.9089e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0003930683 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0002791039 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.001646257 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 29.90195393562317
Epoch 9/9
	 Logging train Loss: 0.000151709 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 3.4324e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0002751324 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.000182159 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0011357862 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 29.600928783416748
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pTrue_gTrue/'quat'_'False'.pth
It took  469.04783821105957  seconds.
----- ITERATION 9/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 77.40782833099365 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 19.59097385406494 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 19.461071968078613 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 19.645793676376343 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 19.694138050079346 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: quat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.1675286889 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0006608075 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0264161155 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0158307478 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.1006545201 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 30.083773612976074
Epoch 1/9
	 Logging train Loss: 0.0086044911 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0001324944 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0138861546 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0052661803 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0547349565 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 29.936150074005127
Epoch 2/9
	 Logging train Loss: 0.0038328115 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 7.0869e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0128395855 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.003864306 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0404593498 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 29.675358295440674
Epoch 3/9
	 Logging train Loss: 0.0023264752 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 4.48572e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0046221307 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0025709174 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0213331748 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 29.83281922340393
Epoch 4/9
	 Logging train Loss: 0.0021495703 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 3.44249e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0055667502 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0018825724 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0239946004 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 30.108506679534912
Epoch 5/9
	 Logging train Loss: 0.0010832259 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.23927e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0007856017 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0007698359 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0057754801 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 29.905535221099854
Epoch 6/9
	 Logging train Loss: 0.0002947071 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.40704e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0005146674 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0004401047 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0042596627 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 29.73054528236389
Epoch 7/9
	 Logging train Loss: 0.0001778767 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.5786e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0003439287 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0002881096 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0029080815 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 29.869933128356934
Epoch 8/9
	 Logging train Loss: 0.0001532942 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.85697e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0003347715 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0003498762 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.002375165 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 30.07064437866211
Epoch 9/9
	 Logging train Loss: 0.0001448632 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 7.4871e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.00032537 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0002370335 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0021277294 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 29.742170333862305
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pTrue_gTrue/'quat'_'False'.pth
It took  480.78415608406067  seconds.
----- ITERATION 10/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 78.2679545879364 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 19.715083599090576 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 19.588498830795288 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 19.677436351776123 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 19.701223850250244 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: quat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.1723040789 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0010423244 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue â–ˆâ–†â–„â–‚â–ƒâ–…â–ƒâ–‚â–‚â–
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue â–ƒâ–‚â–â–â–â–…â–ˆâ–‡â–…â–‚
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue â–ˆâ–„â–ƒâ–â–‚â–…â–ƒâ–‚â–‚â–
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue â–ˆâ–…â–ƒâ–‚â–‚â–ƒâ–‚â–‚â–‚â–
wandb:                                 Train loss â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue 0.0064
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 0.00043
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.01086
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.01876
wandb:                                 Train loss 0.00763
wandb: 
wandb: ðŸš€ View run breezy-music-351 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/yd7z2o6o
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_140142-yd7z2o6o/logs
	 Logging test loss: 0.0319563933 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.049291987 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.140624404 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 30.01926827430725
Epoch 1/9
	 Logging train Loss: 0.023845451 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0004137807 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0249643363 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0288193487 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0917215049 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 30.052165508270264
Epoch 2/9
	 Logging train Loss: 0.0152739119 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0002699505 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0174231566 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0208072737 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.052320268 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 29.838448762893677
Epoch 3/9
	 Logging train Loss: 0.0100570526 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0001770048 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.009644541 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0126195084 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0335683897 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 29.682653188705444
Epoch 4/9
	 Logging train Loss: 0.0087456098 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0002361588 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0121272458 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0147583382 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.039651107 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 29.873433828353882
Epoch 5/9
	 Logging train Loss: 0.0117477803 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0019013362 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0210318081 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0327413008 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0568736196 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 29.74929141998291
Epoch 6/9
	 Logging train Loss: 0.0131412325 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0033862879 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0122993411 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.020471232 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0354678445 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 29.87247133255005
Epoch 7/9
	 Logging train Loss: 0.0118115572 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.002926206 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0112714311 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.017862903 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0328292176 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 30.068044900894165
Epoch 8/9
	 Logging train Loss: 0.0118477503 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0020081266 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0105786053 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0183921903 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0306405313 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 30.062888145446777
Epoch 9/9
	 Logging train Loss: 0.0076314732 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0004319861 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0064031999 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0108599206 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0187601373 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 29.83043074607849
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pTrue_gTrue/'quat'_'False'.pth
It took  471.0393660068512  seconds.

JOB STATISTICS
==============
Job ID: 3081638
Array Job ID: 3081615_25
Cluster: snellius
User/Group: nreints/nreints
State: COMPLETED (exit code 0)
Nodes: 1
Cores per node: 18
CPU Utilized: 01:24:25
CPU Efficiency: 5.96% of 23:36:18 core-walltime
Job Wall-clock time: 01:18:41
Memory Utilized: 7.81 GB
Memory Efficiency: 0.00% of 0.00 MB
