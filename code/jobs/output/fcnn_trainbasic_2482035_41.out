wandb: Currently logged in as: nreints. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home/nreints/.netrc
/gpfs/home2/nreints/MScThesis/code/fcnn.py:521: DeprecationWarning: Sampling from a set deprecated
since Python 3.9 and will be removed in a subsequent version.
  train_sims = set(random.sample(sims_train, int(0.8 * n_sims_train)))
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230321_162902-56zja6nt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run graceful-eon-242
wandb: ⭐️ View project at https://wandb.ai/nreints/test
wandb: 🚀 View run at https://wandb.ai/nreints/test/runs/56zja6nt
['data_t(0,', '0)_r(5,', '20)_semi_pNone_gNone']
data/data_t(0, 0)_r(5, 20)_semi_pNone_gNone
Testing on datasets: ['data_t(0, 0)_r(5, 20)_semi_pNone_gNone', 'data_tennis_pNone_gNone_tennisEffect']
----- ITERATION 1/2 ------
Number of train simulations: 3200
Number of test simulations: 800
The dataloader took 80.28405475616455 seconds.
-- Finished Train Dataloader --
The dataloader took 20.194514751434326 seconds.
The dataloader took 20.862380027770996 seconds.
-- Finished Test Dataloader(s) --
Datatype: quat
--- Started Training ---
Epoch 0
	 Logging train Loss: 77.1877706291 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 6.989518165588379 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 1.961961269378662 (L1Loss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 141.69740295410156 (MSELoss(): tennis_pNone_gNone_tennisEffect)
	 Logging test loss 7.683940410614014 (L1Loss(): tennis_pNone_gNone_tennisEffect)
     --> Epoch_time; 82.55021691322327
Epoch 1
	 Logging train Loss: 4.1037597656 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 2.6058220863342285 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 1.1451338529586792 (L1Loss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 111.21980285644531 (MSELoss(): tennis_pNone_gNone_tennisEffect)
	 Logging test loss 6.397621154785156 (L1Loss(): tennis_pNone_gNone_tennisEffect)
     --> Epoch_time; 90.79466032981873
Epoch 2
	 Logging train Loss: 1.9648836423 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 1.5909777879714966 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 0.8940922617912292 (L1Loss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 88.8515625 (MSELoss(): tennis_pNone_gNone_tennisEffect)
	 Logging test loss 5.5093584060668945 (L1Loss(): tennis_pNone_gNone_tennisEffect)
     --> Epoch_time; 88.15682697296143
Epoch 3
	 Logging train Loss: 1.1952708525 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 0.9160224795341492 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 0.6755891442298889 (L1Loss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 68.00636291503906 (MSELoss(): tennis_pNone_gNone_tennisEffect)
	 Logging test loss 4.61586332321167 (L1Loss(): tennis_pNone_gNone_tennisEffect)
     --> Epoch_time; 85.1186375617981
Epoch 4
	 Logging train Loss: 0.7248503242 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 0.53263920545578 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 0.5117456912994385 (L1Loss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 51.51318359375 (MSELoss(): tennis_pNone_gNone_tennisEffect)
	 Logging test loss 3.8491568565368652 (L1Loss(): tennis_pNone_gNone_tennisEffect)
     --> Epoch_time; 88.95732712745667
Epoch 5
	 Logging train Loss: 0.4193739947 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 0.31694096326828003 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 0.3910600244998932 (L1Loss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 43.471866607666016 (MSELoss(): tennis_pNone_gNone_tennisEffect)
	 Logging test loss 3.459568977355957 (L1Loss(): tennis_pNone_gNone_tennisEffect)
     --> Epoch_time; 91.07397699356079
Epoch 6
	 Logging train Loss: 0.2636986028 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 0.21793551743030548 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 0.323259174823761 (L1Loss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 41.19347381591797 (MSELoss(): tennis_pNone_gNone_tennisEffect)
	 Logging test loss 3.3713395595550537 (L1Loss(): tennis_pNone_gNone_tennisEffect)
     --> Epoch_time; 91.16249823570251
Epoch 7
	 Logging train Loss: 0.1912147871 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 0.19552487134933472 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 0.30953511595726013 (L1Loss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 39.749141693115234 (MSELoss(): tennis_pNone_gNone_tennisEffect)
	 Logging test loss 3.3119568824768066 (L1Loss(): tennis_pNone_gNone_tennisEffect)
     --> Epoch_time; 88.2055037021637
Epoch 8
	 Logging train Loss: 0.1504858478 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 0.12807127833366394 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 0.24919357895851135 (L1Loss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 38.21925735473633 (MSELoss(): tennis_pNone_gNone_tennisEffect)
	 Logging test loss 3.2329282760620117 (L1Loss(): tennis_pNone_gNone_tennisEffect)
     --> Epoch_time; 88.22444772720337
Epoch 9
	 Logging train Loss: 0.1265713461 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 0.11712139844894409 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 0.2394917607307434 (L1Loss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 36.824459075927734 (MSELoss(): tennis_pNone_gNone_tennisEffect)
	 Logging test loss 3.157250165939331 (L1Loss(): tennis_pNone_gNone_tennisEffect)
     --> Epoch_time; 83.99768018722534
Epoch 10
	 Logging train Loss: 0.1062356288 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 0.09479673951864243 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 0.21483421325683594 (L1Loss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 35.76183319091797 (MSELoss(): tennis_pNone_gNone_tennisEffect)
	 Logging test loss 3.101313829421997 (L1Loss(): tennis_pNone_gNone_tennisEffect)
     --> Epoch_time; 85.13273692131042
Epoch 11
	 Logging train Loss: 0.0933849659 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 0.07312764972448349 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 0.18583828210830688 (L1Loss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 34.824825286865234 (MSELoss(): tennis_pNone_gNone_tennisEffect)
	 Logging test loss 3.0489063262939453 (L1Loss(): tennis_pNone_gNone_tennisEffect)
     --> Epoch_time; 83.65976524353027
Epoch 12
	 Logging train Loss: 0.0838540171 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 0.07961951196193695 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 0.19474932551383972 (L1Loss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 33.84975051879883 (MSELoss(): tennis_pNone_gNone_tennisEffect)
	 Logging test loss 2.9910967350006104 (L1Loss(): tennis_pNone_gNone_tennisEffect)
     --> Epoch_time; 88.97845220565796
Epoch 13
	 Logging train Loss: 0.0759759292 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 0.13377679884433746 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 0.2456490695476532 (L1Loss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 33.081825256347656 (MSELoss(): tennis_pNone_gNone_tennisEffect)
	 Logging test loss 2.952084541320801 (L1Loss(): tennis_pNone_gNone_tennisEffect)
     --> Epoch_time; 88.73863768577576
Epoch 14
	 Logging train Loss: 0.0696121465 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 0.058740150183439255 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 0.16896694898605347 (L1Loss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 32.260841369628906 (MSELoss(): tennis_pNone_gNone_tennisEffect)
	 Logging test loss 2.89296293258667 (L1Loss(): tennis_pNone_gNone_tennisEffect)
     --> Epoch_time; 88.0188262462616
Epoch 15
	 Logging train Loss: 0.0644206627 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 0.06666095554828644 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 0.17993159592151642 (L1Loss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 31.57599639892578 (MSELoss(): tennis_pNone_gNone_tennisEffect)
	 Logging test loss 2.8504786491394043 (L1Loss(): tennis_pNone_gNone_tennisEffect)
     --> Epoch_time; 87.62265682220459
Epoch 16
	 Logging train Loss: 0.0612002703 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.028 MB of 0.097 MB uploaded (0.000 MB deduped)wandb: \ 0.028 MB of 0.097 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  Test loss t(0, 0)_r(5, 20)_semi L1Loss() █▅▄▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: Test loss t(0, 0)_r(5, 20)_semi MSELoss() █▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:           Test loss tennisEffect L1Loss() █▆▅▄▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁
wandb:          Test loss tennisEffect MSELoss() █▆▅▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     Train loss data_t(0, 0)_r(5, 20)_semi █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:  Test loss t(0, 0)_r(5, 20)_semi L1Loss() 0.18055
wandb: Test loss t(0, 0)_r(5, 20)_semi MSELoss() 0.07157
wandb:           Test loss tennisEffect L1Loss() 2.67865
wandb:          Test loss tennisEffect MSELoss() 29.11728
wandb:     Train loss data_t(0, 0)_r(5, 20)_semi 0.05151
wandb: 
wandb: 🚀 View run graceful-eon-242 at: https://wandb.ai/nreints/test/runs/56zja6nt
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230321_162902-56zja6nt/logs
/gpfs/home2/nreints/MScThesis/code/fcnn.py:521: DeprecationWarning: Sampling from a set deprecated
since Python 3.9 and will be removed in a subsequent version.
  train_sims = set(random.sample(sims_train, int(0.8 * n_sims_train)))
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230321_170042-ryok4yb3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sleek-frog-300
wandb: ⭐️ View project at https://wandb.ai/nreints/test
wandb: 🚀 View run at https://wandb.ai/nreints/test/runs/ryok4yb3
	 Logging test loss 0.06654868274927139 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 0.1774321049451828 (L1Loss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 30.87839126586914 (MSELoss(): tennis_pNone_gNone_tennisEffect)
	 Logging test loss 2.80446195602417 (L1Loss(): tennis_pNone_gNone_tennisEffect)
     --> Epoch_time; 89.75021195411682
Epoch 17
	 Logging train Loss: 0.057639941 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 0.05885247141122818 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 0.16861198842525482 (L1Loss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 30.260072708129883 (MSELoss(): tennis_pNone_gNone_tennisEffect)
	 Logging test loss 2.76037859916687 (L1Loss(): tennis_pNone_gNone_tennisEffect)
     --> Epoch_time; 83.08978128433228
Epoch 18
	 Logging train Loss: 0.0542358299 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 0.048033539205789566 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 0.1537856161594391 (L1Loss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 29.71942710876465 (MSELoss(): tennis_pNone_gNone_tennisEffect)
	 Logging test loss 2.7238593101501465 (L1Loss(): tennis_pNone_gNone_tennisEffect)
     --> Epoch_time; 85.17496681213379
Epoch 19
	 Logging train Loss: 0.0515112734 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 0.07156957685947418 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 0.18054893612861633 (L1Loss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 29.118854522705078 (MSELoss(): tennis_pNone_gNone_tennisEffect)
	 Logging test loss 2.6786575317382812 (L1Loss(): tennis_pNone_gNone_tennisEffect)
     --> Epoch_time; 80.82650709152222
	 Logging test loss 0.0715692937374115 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 0.18054836988449097 (L1Loss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 29.117277145385742 (MSELoss(): tennis_pNone_gNone_tennisEffect)
	 Logging test loss 2.6786534786224365 (L1Loss(): tennis_pNone_gNone_tennisEffect)
It took 1899.7666692733765 seconds to train & eval the model.
----- ITERATION 2/2 ------
Number of train simulations: 3200
Number of test simulations: 800
The dataloader took 73.82903361320496 seconds.
-- Finished Train Dataloader --
The dataloader took 19.447789907455444 seconds.
The dataloader took 20.555501222610474 seconds.
-- Finished Test Dataloader(s) --
Datatype: quat
--- Started Training ---
Epoch 0
	 Logging train Loss: 94.0574244281 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 7.12655782699585 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 1.9721523523330688 (L1Loss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 137.75665283203125 (MSELoss(): tennis_pNone_gNone_tennisEffect)
	 Logging test loss 7.630680561065674 (L1Loss(): tennis_pNone_gNone_tennisEffect)
     --> Epoch_time; 88.16733431816101
Epoch 1
	 Logging train Loss: 3.9932562934 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 2.7190704345703125 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 1.1695075035095215 (L1Loss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 105.77462005615234 (MSELoss(): tennis_pNone_gNone_tennisEffect)
	 Logging test loss 6.295772075653076 (L1Loss(): tennis_pNone_gNone_tennisEffect)
     --> Epoch_time; 88.14746022224426
Epoch 2
	 Logging train Loss: 1.920728656 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 1.625104308128357 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 0.902379035949707 (L1Loss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 83.78509521484375 (MSELoss(): tennis_pNone_gNone_tennisEffect)
	 Logging test loss 5.382462024688721 (L1Loss(): tennis_pNone_gNone_tennisEffect)
     --> Epoch_time; 88.01644277572632
Epoch 3
	 Logging train Loss: 1.1585828195 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 0.9548518657684326 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 0.6869637966156006 (L1Loss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 62.8892822265625 (MSELoss(): tennis_pNone_gNone_tennisEffect)
	 Logging test loss 4.431127548217773 (L1Loss(): tennis_pNone_gNone_tennisEffect)
     --> Epoch_time; 82.33723473548889
Epoch 4
	 Logging train Loss: 0.6850084891 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 0.5188008546829224 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 0.5032650828361511 (L1Loss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 47.0999641418457 (MSELoss(): tennis_pNone_gNone_tennisEffect)
	 Logging test loss 3.633653163909912 (L1Loss(): tennis_pNone_gNone_tennisEffect)
     --> Epoch_time; 91.55117130279541
Epoch 5
	 Logging train Loss: 0.3898202934 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 0.31716814637184143 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 0.39451295137405396 (L1Loss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 40.308837890625 (MSELoss(): tennis_pNone_gNone_tennisEffect)
	 Logging test loss 3.2714154720306396 (L1Loss(): tennis_pNone_gNone_tennisEffect)
     --> Epoch_time; 88.33003044128418
Epoch 6
	 Logging train Loss: 0.2404192756 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 0.25893786549568176 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 0.35923364758491516 (L1Loss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 38.736515045166016 (MSELoss(): tennis_pNone_gNone_tennisEffect)
	 Logging test loss 3.2001121044158936 (L1Loss(): tennis_pNone_gNone_tennisEffect)
     --> Epoch_time; 87.73698997497559
Epoch 7
	 Logging train Loss: 0.1743818694 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 0.15170501172542572 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 0.2736639976501465 (L1Loss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 37.748897552490234 (MSELoss(): tennis_pNone_gNone_tennisEffect)
	 Logging test loss 3.1513614654541016 (L1Loss(): tennis_pNone_gNone_tennisEffect)
     --> Epoch_time; 88.59372544288635
Epoch 8
	 Logging train Loss: 0.1373478709 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 0.14842228591442108 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 0.2703092396259308 (L1Loss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 36.74720764160156 (MSELoss(): tennis_pNone_gNone_tennisEffect)
	 Logging test loss 3.1036500930786133 (L1Loss(): tennis_pNone_gNone_tennisEffect)
     --> Epoch_time; 89.55177664756775
Epoch 9
	 Logging train Loss: 0.1144941342 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 0.10427578538656235 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 0.22756940126419067 (L1Loss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 35.8205680847168 (MSELoss(): tennis_pNone_gNone_tennisEffect)
	 Logging test loss 3.0487492084503174 (L1Loss(): tennis_pNone_gNone_tennisEffect)
     --> Epoch_time; 88.04380297660828
Epoch 10
	 Logging train Loss: 0.0977391062 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 0.09472597390413284 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 0.21657611429691315 (L1Loss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 35.00165557861328 (MSELoss(): tennis_pNone_gNone_tennisEffect)
	 Logging test loss 2.998405933380127 (L1Loss(): tennis_pNone_gNone_tennisEffect)
     --> Epoch_time; 88.15298652648926
Epoch 11
	 Logging train Loss: 0.0865887312 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 0.09244897216558456 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 0.21535508334636688 (L1Loss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 34.24030303955078 (MSELoss(): tennis_pNone_gNone_tennisEffect)
	 Logging test loss 2.9527406692504883 (L1Loss(): tennis_pNone_gNone_tennisEffect)
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.028 MB of 0.097 MB uploaded (0.000 MB deduped)wandb: \ 0.028 MB of 0.097 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  Test loss t(0, 0)_r(5, 20)_semi L1Loss() █▅▄▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: Test loss t(0, 0)_r(5, 20)_semi MSELoss() █▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:           Test loss tennisEffect L1Loss() █▆▅▄▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁
wandb:          Test loss tennisEffect MSELoss() █▆▅▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     Train loss data_t(0, 0)_r(5, 20)_semi █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:  Test loss t(0, 0)_r(5, 20)_semi L1Loss() 0.15374
wandb: Test loss t(0, 0)_r(5, 20)_semi MSELoss() 0.04717
wandb:           Test loss tennisEffect L1Loss() 2.65075
wandb:          Test loss tennisEffect MSELoss() 29.68122
wandb:     Train loss data_t(0, 0)_r(5, 20)_semi 0.04521
wandb: 
wandb: 🚀 View run sleek-frog-300 at: https://wandb.ai/nreints/test/runs/ryok4yb3
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230321_170042-ryok4yb3/logs
     --> Epoch_time; 87.69271731376648
Epoch 12
	 Logging train Loss: 0.0762340172 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 0.07796751707792282 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 0.1977626234292984 (L1Loss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 33.59291076660156 (MSELoss(): tennis_pNone_gNone_tennisEffect)
	 Logging test loss 2.9138145446777344 (L1Loss(): tennis_pNone_gNone_tennisEffect)
     --> Epoch_time; 88.14108347892761
Epoch 13
	 Logging train Loss: 0.0695067911 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 0.057843271642923355 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 0.16887927055358887 (L1Loss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 32.92879104614258 (MSELoss(): tennis_pNone_gNone_tennisEffect)
	 Logging test loss 2.867274045944214 (L1Loss(): tennis_pNone_gNone_tennisEffect)
     --> Epoch_time; 88.63238096237183
Epoch 14
	 Logging train Loss: 0.0637227227 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 0.05430213734507561 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 0.16318568587303162 (L1Loss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 32.34584426879883 (MSELoss(): tennis_pNone_gNone_tennisEffect)
	 Logging test loss 2.831239700317383 (L1Loss(): tennis_pNone_gNone_tennisEffect)
     --> Epoch_time; 89.01935052871704
Epoch 15
	 Logging train Loss: 0.0590499878 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 0.06198810413479805 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 0.17111730575561523 (L1Loss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 31.791715621948242 (MSELoss(): tennis_pNone_gNone_tennisEffect)
	 Logging test loss 2.7979748249053955 (L1Loss(): tennis_pNone_gNone_tennisEffect)
     --> Epoch_time; 89.43887591362
Epoch 16
	 Logging train Loss: 0.055341748 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 0.05539761111140251 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 0.16474436223506927 (L1Loss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 31.17154884338379 (MSELoss(): tennis_pNone_gNone_tennisEffect)
	 Logging test loss 2.7534027099609375 (L1Loss(): tennis_pNone_gNone_tennisEffect)
     --> Epoch_time; 86.60914540290833
Epoch 17
	 Logging train Loss: 0.0513222888 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 0.05423752963542938 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 0.16469717025756836 (L1Loss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 30.671777725219727 (MSELoss(): tennis_pNone_gNone_tennisEffect)
	 Logging test loss 2.7219576835632324 (L1Loss(): tennis_pNone_gNone_tennisEffect)
     --> Epoch_time; 88.15991401672363
Epoch 18
	 Logging train Loss: 0.0491319993 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 0.05156349763274193 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 0.1592421531677246 (L1Loss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 30.14112091064453 (MSELoss(): tennis_pNone_gNone_tennisEffect)
	 Logging test loss 2.6823768615722656 (L1Loss(): tennis_pNone_gNone_tennisEffect)
     --> Epoch_time; 83.55282664299011
Epoch 19
	 Logging train Loss: 0.0452070598 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 0.04717205837368965 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 0.15373897552490234 (L1Loss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 29.681045532226562 (MSELoss(): tennis_pNone_gNone_tennisEffect)
	 Logging test loss 2.6507728099823 (L1Loss(): tennis_pNone_gNone_tennisEffect)
     --> Epoch_time; 81.21396899223328
	 Logging test loss 0.047172099351882935 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 0.15373829007148743 (L1Loss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 29.681217193603516 (MSELoss(): tennis_pNone_gNone_tennisEffect)
	 Logging test loss 2.6507456302642822 (L1Loss(): tennis_pNone_gNone_tennisEffect)
It took 1902.9834787845612 seconds to train & eval the model.

JOB STATISTICS
==============
Job ID: 2482077
Array Job ID: 2482035_41
Cluster: snellius
User/Group: nreints/nreints
State: RUNNING
Nodes: 1
Cores per node: 18
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 19:05:06 core-walltime
Job Wall-clock time: 01:03:37
Memory Utilized: 0.00 MB (estimated maximum)
Memory Efficiency: 0.00% of 29.30 GB (29.30 GB/node)
WARNING: Efficiency statistics may be misleading for RUNNING jobs.
