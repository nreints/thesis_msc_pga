wandb: Currently logged in as: nreints. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230629_111855-pjxf27lz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run northern-totem-20
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/pjxf27lz
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone █▂▂▁▁▁▃▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone █▂▂▁▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone █▂▂▁▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone █▂▁▁▁▁▄▁▁▁
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone █▂▁▁▁▁▄▁▁▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone 0.0
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: 🚀 View run northern-totem-20 at: https://wandb.ai/nreints/ThesisFinal2/runs/pjxf27lz
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230629_111855-pjxf27lz/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230629_112705-w5dkm2h5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glad-sea-41
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/w5dkm2h5
Training on dataset: data_t(5,20)_r(0,0)_combi_pNone_gNone
Testing on 5 datasets: ['data_t(5,20)_r(0,0)_full_pNone_gNone', 'data_t(5,20)_r(0,0)_none_pNone_gNone', 'data_t(5,20)_r(0,0)_tennis_pNone_gNone', 'data_t(5,20)_r(0,0)_semi_pNone_gNone', 'data_t(5,20)_r(0,0)_combi_pNone_gNone']
Focussing on identity: False
Using extra input: False
Using fr-fr as reference point.
----- ITERATION 1/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 48.01509690284729 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(0,0)_full_pNone_gNone took 11.818488121032715 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_none_pNone_gNone took 12.085700511932373 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_tennis_pNone_gNone took 11.690192461013794 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_semi_pNone_gNone took 11.888028144836426 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 12.114309787750244 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(6, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=6, bias=True)
)
Datatype: log_dualQ_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0005425864 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.35969e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.35143e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 2.65557e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 2.55331e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.66048e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
		--> Epoch time; 37.734893798828125
Epoch 1/9
	 Logging train Loss: 8.984e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.746e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.7262e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 3.0893e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 2.9445e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 3.7432e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
		--> Epoch time; 36.97762417793274
Epoch 2/9
	 Logging train Loss: 3.0764e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.861e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.8442e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 2.0726e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.9678e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.5316e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
		--> Epoch time; 37.048661947250366
Epoch 3/9
	 Logging train Loss: 2.2649e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.1139e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.0977e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.2607e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.1883e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.5357e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
		--> Epoch time; 36.37067985534668
Epoch 4/9
	 Logging train Loss: 2.5454e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 5.892e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 5.829e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 6.818e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 6.376e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 8.433e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
		--> Epoch time; 36.5871696472168
Epoch 5/9
	 Logging train Loss: 1.5172e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.152e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 3.101e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 3.721e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 3.49e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 4.791e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
		--> Epoch time; 36.50665307044983
Epoch 6/9
	 Logging train Loss: 1.5985e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 7.515e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 7.308e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.25959e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.22322e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 6.8838e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
		--> Epoch time; 36.45564126968384
Epoch 7/9
	 Logging train Loss: 1.5224e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.299e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.264e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 7.322e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 7.12e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 5.575e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
		--> Epoch time; 36.549293518066406
Epoch 8/9
	 Logging train Loss: 1.5801e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.526e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.516e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 3.412e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 3.332e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 3.094e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
		--> Epoch time; 36.547213554382324
Epoch 9/9
	 Logging train Loss: 1.3282e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.831e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.812e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 2.047e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 2.009e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.41e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
		--> Epoch time; 36.658308029174805
Saved model in  trained_models/gru/data_t(5,20)_r(0,0)_combi_pNone_gNone/'log_dualQ_1'_'False'.pth
It took  491.1389057636261  seconds.
----- ITERATION 2/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 42.01120042800903 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(0,0)_full_pNone_gNone took 10.931338787078857 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_none_pNone_gNone took 11.032283306121826 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_tennis_pNone_gNone took 10.959713697433472 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_semi_pNone_gNone took 11.113131284713745 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 10.561641693115234 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(6, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=6, bias=True)
)
Datatype: log_dualQ_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0003471068 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.8784e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.94346e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 3.0726e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 2.87839e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 3.03332e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
		--> Epoch time; 36.798683643341064
Epoch 1/9
	 Logging train Loss: 1.45357e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 4.3715e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 4.403e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone █▂▂▁▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone █▂▂▁▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone █▂▂▁▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone █▂▂▁▁▁▁▁▂▁
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone █▂▂▁▁▁▁▁▂▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone 0.0
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: 🚀 View run glad-sea-41 at: https://wandb.ai/nreints/ThesisFinal2/runs/w5dkm2h5
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230629_112705-w5dkm2h5/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230629_113502-psxlyx19
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ethereal-snowflake-58
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/psxlyx19
	 Logging test loss: 4.7341e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 4.4617e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 5.2334e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
		--> Epoch time; 36.945392370224
Epoch 2/9
	 Logging train Loss: 3.9164e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.283e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.2699e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 2.5862e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 2.4923e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.8891e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
		--> Epoch time; 36.709129333496094
Epoch 3/9
	 Logging train Loss: 3.4305e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.5387e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.5423e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.826e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.7346e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.9278e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
		--> Epoch time; 36.6851327419281
Epoch 4/9
	 Logging train Loss: 2.9871e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 9.528e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 9.586e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.0254e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 9.537e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.1088e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
		--> Epoch time; 36.6990282535553
Epoch 5/9
	 Logging train Loss: 1.9536e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 5.555e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 5.618e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 6.829e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 6.251e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 6.813e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
		--> Epoch time; 36.514867067337036
Epoch 6/9
	 Logging train Loss: 2.1751e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.899e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 3.959e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.1061e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.0514e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 7.882e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
		--> Epoch time; 36.50987935066223
Epoch 7/9
	 Logging train Loss: 1.5369e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.047e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.058e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 2.3e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 2.147e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.441e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
		--> Epoch time; 36.73942542076111
Epoch 8/9
	 Logging train Loss: 1.2216e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 4.859e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 4.839e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 3.9594e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 3.723e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.3167e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
		--> Epoch time; 36.972025632858276
Epoch 9/9
	 Logging train Loss: 1.4934e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.803e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.785e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 3.753e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 3.674e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.976e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
		--> Epoch time; 36.6139931678772
Saved model in  trained_models/gru/data_t(5,20)_r(0,0)_combi_pNone_gNone/'log_dualQ_1'_'False'.pth
It took  476.3015775680542  seconds.
----- ITERATION 3/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 41.825849771499634 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(0,0)_full_pNone_gNone took 10.965856790542603 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_none_pNone_gNone took 11.22966480255127 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_tennis_pNone_gNone took 10.893165826797485 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_semi_pNone_gNone took 10.88657832145691 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 10.59719967842102 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(6, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=6, bias=True)
)
Datatype: log_dualQ_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0006189529 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.56874e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 3.54971e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 3.70564e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 3.65107e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 3.65789e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
		--> Epoch time; 36.39244747161865
Epoch 1/9
	 Logging train Loss: 2.04697e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 8.0387e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 7.7533e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 8.2691e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 8.1931e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 8.5403e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
		--> Epoch time; 36.99753785133362
Epoch 2/9
	 Logging train Loss: 4.9418e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.3653e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.3723e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 2.4628e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 2.4439e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.8811e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
		--> Epoch time; 37.10131549835205
Epoch 3/9
	 Logging train Loss: 2.7967e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.4902e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.4845e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.5274e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.5207e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.7963e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
		--> Epoch time; 36.963414430618286
Epoch 4/9
	 Logging train Loss: 2.3287e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 9.209e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 9.1e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.0029e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.0066e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.1202e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
		--> Epoch time; 36.86454248428345
Epoch 5/9
	 Logging train Loss: 1.8954e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 5.922e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 5.807e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone █▃▂▁▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone █▃▁▁▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone █▂▁▁▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone █▃▁▁▁▁▁▁▁▁
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone █▃▁▁▁▁▁▁▁▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone 0.0
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: 🚀 View run ethereal-snowflake-58 at: https://wandb.ai/nreints/ThesisFinal2/runs/psxlyx19
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230629_113502-psxlyx19/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230629_114300-jgcre5f6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run winter-smoke-74
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/jgcre5f6
	 Logging test loss: 6.699e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 6.749e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 7.204e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
		--> Epoch time; 36.9650764465332
Epoch 6/9
	 Logging train Loss: 1.7358e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.249e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 3.191e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 6.057e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 6.028e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 5.297e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
		--> Epoch time; 36.858057260513306
Epoch 7/9
	 Logging train Loss: 1.7817e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.975e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.944e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 2.069e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 2.04e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.461e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
		--> Epoch time; 36.824907064437866
Epoch 8/9
	 Logging train Loss: 1.355e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 5.907e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 5.884e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.036e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.0105e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 8.516e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
		--> Epoch time; 36.678637742996216
Epoch 9/9
	 Logging train Loss: 1.2386e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 5.866e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 5.854e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 5.965e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 5.912e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 6.182e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
		--> Epoch time; 36.588544607162476
Saved model in  trained_models/gru/data_t(5,20)_r(0,0)_combi_pNone_gNone/'log_dualQ_1'_'False'.pth
It took  478.1220979690552  seconds.
----- ITERATION 4/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 41.83641242980957 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(0,0)_full_pNone_gNone took 10.925435066223145 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_none_pNone_gNone took 10.931542158126831 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_tennis_pNone_gNone took 10.799745559692383 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_semi_pNone_gNone took 10.911291599273682 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 10.569197177886963 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(6, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=6, bias=True)
)
Datatype: log_dualQ_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0005396003 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.96822e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 3.08414e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 3.2624e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 3.1816e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 3.13007e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
		--> Epoch time; 36.607749223709106
Epoch 1/9
	 Logging train Loss: 1.389e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.973e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 4.1229e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 4.3822e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 4.2373e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 4.7939e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
		--> Epoch time; 36.9583523273468
Epoch 2/9
	 Logging train Loss: 3.7308e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.4307e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.5044e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 2.6513e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 2.5524e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.9773e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
		--> Epoch time; 36.78309679031372
Epoch 3/9
	 Logging train Loss: 2.8132e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.5597e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.6066e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.7297e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.6575e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.9075e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
		--> Epoch time; 36.4977707862854
Epoch 4/9
	 Logging train Loss: 2.0601e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 9.004e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 9.246e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.1999e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.1501e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.1931e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
		--> Epoch time; 36.88265800476074
Epoch 5/9
	 Logging train Loss: 1.6933e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 4.913e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 5e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.0347e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.0257e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 8.527e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
		--> Epoch time; 36.8455286026001
Epoch 6/9
	 Logging train Loss: 1.478e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.145e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 3.149e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 5.855e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 5.738e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 5.026e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
		--> Epoch time; 36.790411710739136
Epoch 7/9
	 Logging train Loss: 1.6615e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.445e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.447e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 2.86e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 2.834e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.985e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
		--> Epoch time; 36.89661693572998
Epoch 8/9
	 Logging train Loss: 1.1868e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.656e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.634e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.999e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 2.008e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.101e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
		--> Epoch time; 36.603724241256714
Epoch 9/9
	 Logging train Loss: 1.4198e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.437e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.431e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone █▂▂▁▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone █▂▂▁▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone █▂▂▁▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone █▂▂▁▁▁▁▁▁▁
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone █▂▂▁▁▁▁▁▁▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone 0.0
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: 🚀 View run winter-smoke-74 at: https://wandb.ai/nreints/ThesisFinal2/runs/jgcre5f6
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230629_114300-jgcre5f6/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230629_115056-9u1s7eff
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lucky-field-90
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/9u1s7eff
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone █▂▂▁▅▁▃▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone █▂▁▁▃▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone █▂▁▁▃▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone █▂▁▁▇▁▄▁▁▁
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone █▂▁▁▇▁▄▁▁▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone 0.0
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: 🚀 View run lucky-field-90 at: https://wandb.ai/nreints/ThesisFinal2/runs/9u1s7eff
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230629_115056-9u1s7eff/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230629_115852-r0204tfx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run golden-leaf-107
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/r0204tfx
	 Logging test loss: 1.518e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.517e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.7e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
		--> Epoch time; 36.78719902038574
Saved model in  trained_models/gru/data_t(5,20)_r(0,0)_combi_pNone_gNone/'log_dualQ_1'_'False'.pth
It took  475.9980409145355  seconds.
----- ITERATION 5/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 41.96462917327881 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(0,0)_full_pNone_gNone took 10.972267627716064 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_none_pNone_gNone took 10.934741258621216 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_tennis_pNone_gNone took 10.860686302185059 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_semi_pNone_gNone took 10.955733299255371 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 10.714801788330078 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(6, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=6, bias=True)
)
Datatype: log_dualQ_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0002547006 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.57224e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.4785e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 2.89026e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 2.68418e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.80735e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
		--> Epoch time; 37.06464505195618
Epoch 1/9
	 Logging train Loss: 1.11315e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.1521e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 3.0604e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 3.4072e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 3.1925e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 3.9087e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
		--> Epoch time; 37.12224316596985
Epoch 2/9
	 Logging train Loss: 3.3246e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.8725e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.8157e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 2.0242e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.8921e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.3449e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
		--> Epoch time; 36.83175086975098
Epoch 3/9
	 Logging train Loss: 2.4072e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.0531e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.0291e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.1541e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.0839e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.3147e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
		--> Epoch time; 36.563788175582886
Epoch 4/9
	 Logging train Loss: 2.3419e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 7.7481e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 7.7319e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 2.29171e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 2.32606e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.59139e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
		--> Epoch time; 36.615413665771484
Epoch 5/9
	 Logging train Loss: 1.2993e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.781e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.74e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 3.106e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 2.939e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 3.512e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
		--> Epoch time; 36.75247859954834
Epoch 6/9
	 Logging train Loss: 1.6788e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.1664e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.1514e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.08651e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.07989e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 6.3555e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
		--> Epoch time; 36.76924967765808
Epoch 7/9
	 Logging train Loss: 1.096e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.639e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.635e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 2.552e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 2.421e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.396e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
		--> Epoch time; 36.81688213348389
Epoch 8/9
	 Logging train Loss: 1.0965e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.721e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.721e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 4.467e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 4.375e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 3.366e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
		--> Epoch time; 36.98801875114441
Epoch 9/9
	 Logging train Loss: 1.5437e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.386e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.388e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.571e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.487e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.652e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
		--> Epoch time; 36.62699580192566
Saved model in  trained_models/gru/data_t(5,20)_r(0,0)_combi_pNone_gNone/'log_dualQ_1'_'False'.pth
It took  475.97469544410706  seconds.
----- ITERATION 6/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 42.431756019592285 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(0,0)_full_pNone_gNone took 10.951701641082764 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_none_pNone_gNone took 10.89033818244934 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_tennis_pNone_gNone took 10.90445065498352 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_semi_pNone_gNone took 10.907513856887817 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 10.705354452133179 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(6, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=6, bias=True)
)
Datatype: log_dualQ_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.000652514 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.99236e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 4.1111e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 4.42349e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 4.18125e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 4.31076e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
		--> Epoch time; 36.79197716712952
Epoch 1/9
	 Logging train Loss: 2.31783e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 8.2966e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 8.3132e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone █▃▂▁▂▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone █▂▁▁▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone █▂▁▁▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone █▂▁▁▂▁▁▁▁▁
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone █▂▁▁▂▁▁▁▁▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone 0.0
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: 🚀 View run golden-leaf-107 at: https://wandb.ai/nreints/ThesisFinal2/runs/r0204tfx
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230629_115852-r0204tfx/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230629_120649-yoxlm0j6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run divine-gorge-121
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/yoxlm0j6
	 Logging test loss: 9.2468e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 8.4587e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 9.3985e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
		--> Epoch time; 37.085769176483154
Epoch 2/9
	 Logging train Loss: 5.2561e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.7838e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.864e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 3.2944e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 3.122e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 3.5096e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
		--> Epoch time; 36.87173271179199
Epoch 3/9
	 Logging train Loss: 3.0923e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.9664e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.0177e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 2.2528e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 2.1262e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.379e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
		--> Epoch time; 36.685786962509155
Epoch 4/9
	 Logging train Loss: 2.5827e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.5346e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.563e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 7.8941e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 8.0955e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 5.184e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
		--> Epoch time; 36.71180844306946
Epoch 5/9
	 Logging train Loss: 2.2207e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 7.294e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 7.429e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 8.195e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 7.698e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 8.321e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
		--> Epoch time; 36.801488161087036
Epoch 6/9
	 Logging train Loss: 1.7991e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 4.218e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 4.253e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 9.428e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 9.35e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 7.361e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
		--> Epoch time; 36.91523766517639
Epoch 7/9
	 Logging train Loss: 1.9824e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.393e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.426e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 2.836e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 2.71e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.842e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
		--> Epoch time; 36.73991823196411
Epoch 8/9
	 Logging train Loss: 1.1065e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.339e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.358e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.875e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.909e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.1238e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
		--> Epoch time; 36.80189371109009
Epoch 9/9
	 Logging train Loss: 1.2149e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.592e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.597e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.803e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.774e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.851e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
		--> Epoch time; 36.56354308128357
Saved model in  trained_models/gru/data_t(5,20)_r(0,0)_combi_pNone_gNone/'log_dualQ_1'_'False'.pth
It took  476.9357318878174  seconds.
----- ITERATION 7/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 42.28344464302063 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(0,0)_full_pNone_gNone took 10.768180131912231 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_none_pNone_gNone took 10.836693048477173 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_tennis_pNone_gNone took 10.872617483139038 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_semi_pNone_gNone took 10.99663496017456 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 10.862064599990845 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(6, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=6, bias=True)
)
Datatype: log_dualQ_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0001759418 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.73417e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.79157e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.85388e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.87443e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.90051e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
		--> Epoch time; 36.71549963951111
Epoch 1/9
	 Logging train Loss: 8.7777e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.652e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.7387e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 2.9094e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 2.8987e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 3.5364e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
		--> Epoch time; 36.63705062866211
Epoch 2/9
	 Logging train Loss: 3.741e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.6344e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.6894e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 2.8187e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 2.8045e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 3.1942e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
		--> Epoch time; 36.70292806625366
Epoch 3/9
	 Logging train Loss: 3.1247e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 9.396e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 9.681e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.0393e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.0272e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.2277e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
		--> Epoch time; 36.76298809051514
Epoch 4/9
	 Logging train Loss: 2.3338e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.2741e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 3.0889e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 6.63224e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 6.54511e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 3.57505e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
		--> Epoch time; 36.502076864242554
Epoch 5/9
	 Logging train Loss: 1.5499e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.39e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.41e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone ▅▂▂▁█▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone █▂▂▁▂▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone █▂▂▁▂▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone ▃▁▁▁█▁▁▁▁▁
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone ▃▁▁▁█▁▁▁▁▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone 0.0
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: 🚀 View run divine-gorge-121 at: https://wandb.ai/nreints/ThesisFinal2/runs/yoxlm0j6
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230629_120649-yoxlm0j6/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230629_121450-5milwebr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run peach-plasma-139
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/5milwebr
	 Logging test loss: 2.858e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 2.825e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 3.215e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
		--> Epoch time; 36.906317472457886
Epoch 6/9
	 Logging train Loss: 1.5082e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.625e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.621e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.716e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.697e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.049e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
		--> Epoch time; 36.695204973220825
Epoch 7/9
	 Logging train Loss: 1.2336e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 4.919e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 4.893e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 6.909e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 6.964e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 6.421e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
		--> Epoch time; 36.655296325683594
Epoch 8/9
	 Logging train Loss: 1.0927e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.546e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.548e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.851e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.849e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.975e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
		--> Epoch time; 37.00038123130798
Epoch 9/9
	 Logging train Loss: 1.185e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.421e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.418e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.437e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.427e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.63e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
		--> Epoch time; 36.94051003456116
Saved model in  trained_models/gru/data_t(5,20)_r(0,0)_combi_pNone_gNone/'log_dualQ_1'_'False'.pth
It took  480.9423451423645  seconds.
----- ITERATION 8/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 42.61209201812744 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(0,0)_full_pNone_gNone took 10.934717416763306 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_none_pNone_gNone took 10.88908863067627 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_tennis_pNone_gNone took 10.872202157974243 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_semi_pNone_gNone took 10.97667407989502 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 10.706977844238281 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(6, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=6, bias=True)
)
Datatype: log_dualQ_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0002277821 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.4e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.42929e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.54801e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.5119e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.58401e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
		--> Epoch time; 36.54507756233215
Epoch 1/9
	 Logging train Loss: 6.5661e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.8627e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.9583e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 2.9831e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 3.0361e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 3.5871e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
		--> Epoch time; 36.74295353889465
Epoch 2/9
	 Logging train Loss: 3.2874e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.7392e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.8007e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.8826e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.901e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.2027e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
		--> Epoch time; 36.4444534778595
Epoch 3/9
	 Logging train Loss: 2.525e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 9.407e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 9.75e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 9.755e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 9.871e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.156e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
		--> Epoch time; 36.47497797012329
Epoch 4/9
	 Logging train Loss: 2.3926e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 5.093e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 5.206e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 5.652e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 5.609e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 6.405e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
		--> Epoch time; 36.495561361312866
Epoch 5/9
	 Logging train Loss: 1.2422e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.59e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.618e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 3.132e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 3.093e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 3.479e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
		--> Epoch time; 36.82763195037842
Epoch 6/9
	 Logging train Loss: 1.273e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.92e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 3.903e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.7657e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.6729e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.1739e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
		--> Epoch time; 36.67172646522522
Epoch 7/9
	 Logging train Loss: 1.2168e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 7.372e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 7.355e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 4.2971e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 4.0547e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.675e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
		--> Epoch time; 36.76696586608887
Epoch 8/9
	 Logging train Loss: 9.622e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.769e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.718e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.829e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.827e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.032e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
		--> Epoch time; 36.83607816696167
Epoch 9/9
	 Logging train Loss: 9.503e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.725e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.701e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone █▃▂▁▁▁▁▂▁▁
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone █▂▂▁▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone █▂▂▁▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone █▂▂▁▁▁▂▃▁▁
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone █▂▂▁▁▁▂▃▁▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone 0.0
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: 🚀 View run peach-plasma-139 at: https://wandb.ai/nreints/ThesisFinal2/runs/5milwebr
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230629_121450-5milwebr/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230629_122247-1ngmyxal
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run devoted-river-153
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/1ngmyxal
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone █▃▂▁▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone █▂▂▁▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone █▂▂▁▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone █▂▁▁▂▁▁▁▁▁
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone █▂▁▁▂▁▁▁▁▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone 0.0
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: 🚀 View run devoted-river-153 at: https://wandb.ai/nreints/ThesisFinal2/runs/1ngmyxal
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230629_122247-1ngmyxal/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230629_123050-rn8giv74
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run easy-sunset-168
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/rn8giv74
	 Logging test loss: 3.429e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 3.283e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.855e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
		--> Epoch time; 36.83032512664795
Saved model in  trained_models/gru/data_t(5,20)_r(0,0)_combi_pNone_gNone/'log_dualQ_1'_'False'.pth
It took  477.0104012489319  seconds.
----- ITERATION 9/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 42.30214595794678 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(0,0)_full_pNone_gNone took 10.755179643630981 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_none_pNone_gNone took 10.794216632843018 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_tennis_pNone_gNone took 10.95897388458252 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_semi_pNone_gNone took 11.009528398513794 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 10.828893899917603 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(6, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=6, bias=True)
)
Datatype: log_dualQ_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0006665537 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.85453e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 3.7669e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 4.04317e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 4.05086e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 4.12269e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
		--> Epoch time; 36.77225041389465
Epoch 1/9
	 Logging train Loss: 2.16018e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 8.1502e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 8.08e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 8.4391e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 8.3836e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 9.3078e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
		--> Epoch time; 36.82679605484009
Epoch 2/9
	 Logging train Loss: 5.3579e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.0028e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.9306e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 3.0555e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 3.0768e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 3.7496e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
		--> Epoch time; 36.59984469413757
Epoch 3/9
	 Logging train Loss: 2.9907e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.0993e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.0496e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 2.1226e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 2.1362e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.568e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
		--> Epoch time; 36.338845014572144
Epoch 4/9
	 Logging train Loss: 2.6162e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.5145e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.4945e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 3.9796e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 3.6463e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.9098e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
		--> Epoch time; 36.594197034835815
Epoch 5/9
	 Logging train Loss: 2.1285e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 8.057e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 8.006e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 9.043e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 8.91e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 9.67e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
		--> Epoch time; 37.20045042037964
Epoch 6/9
	 Logging train Loss: 2.2093e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 5.133e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 5.106e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.1651e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.0523e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 8.911e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
		--> Epoch time; 36.506083488464355
Epoch 7/9
	 Logging train Loss: 1.8296e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 5.891e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 5.861e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.0087e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 9.636e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 8.343e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
		--> Epoch time; 36.53716325759888
Epoch 8/9
	 Logging train Loss: 1.7046e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.333e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 3.3e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.0546e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 9.858e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 7.076e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
		--> Epoch time; 36.608646392822266
Epoch 9/9
	 Logging train Loss: 1.0743e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.029e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.014e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 6.238e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 5.846e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 4.257e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
		--> Epoch time; 36.56561875343323
Saved model in  trained_models/gru/data_t(5,20)_r(0,0)_combi_pNone_gNone/'log_dualQ_1'_'False'.pth
It took  482.973557472229  seconds.
----- ITERATION 10/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 41.50081467628479 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(0,0)_full_pNone_gNone took 10.880828857421875 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_none_pNone_gNone took 10.92736291885376 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_tennis_pNone_gNone took 10.887007474899292 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_semi_pNone_gNone took 10.886468410491943 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 10.488332509994507 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(6, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=6, bias=True)
)
Datatype: log_dualQ_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0007005177 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.99713e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 3.80319e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 4.16415e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 4.12427e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 4.12186e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
		--> Epoch time; 36.512856006622314
Epoch 1/9
	 Logging train Loss: 1.99537e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 4.7648e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 4.5504e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone █▂▁▁▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone █▂▁▁▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone █▂▁▁▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone █▂▁▁▁▁▁▁▁▁
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone █▂▁▁▁▁▁▁▁▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone 0.0
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: 🚀 View run easy-sunset-168 at: https://wandb.ai/nreints/ThesisFinal2/runs/rn8giv74
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230629_123050-rn8giv74/logs
	 Logging test loss: 5.2209e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 5.1139e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 5.7341e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
		--> Epoch time; 36.84332036972046
Epoch 2/9
	 Logging train Loss: 3.7778e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.5002e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.3934e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 2.6139e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 2.5751e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 3.1001e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
		--> Epoch time; 36.71808981895447
Epoch 3/9
	 Logging train Loss: 2.4521e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.5954e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.5293e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.6881e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.6549e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.9788e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
		--> Epoch time; 36.54729437828064
Epoch 4/9
	 Logging train Loss: 1.7829e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 8.786e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 8.425e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 9.46e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 9.253e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.0803e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
		--> Epoch time; 36.61832642555237
Epoch 5/9
	 Logging train Loss: 1.4565e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 4.346e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 4.217e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 5.591e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 5.464e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 5.779e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
		--> Epoch time; 36.670987606048584
Epoch 6/9
	 Logging train Loss: 1.3579e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.823e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.764e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.3668e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.3501e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 8.732e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
		--> Epoch time; 36.65329694747925
Epoch 7/9
	 Logging train Loss: 1.4681e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.597e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.577e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.904e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.886e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.135e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
		--> Epoch time; 36.39021110534668
Epoch 8/9
	 Logging train Loss: 1.1807e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.346e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.323e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 6.84e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 6.619e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 4.851e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
		--> Epoch time; 36.28139638900757
Epoch 9/9
	 Logging train Loss: 1.1969e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 5.612e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 5.585e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 8.112e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 7.998e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 7.09e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
		--> Epoch time; 35.828391551971436
Saved model in  trained_models/gru/data_t(5,20)_r(0,0)_combi_pNone_gNone/'log_dualQ_1'_'False'.pth
It took  483.07882809638977  seconds.

JOB STATISTICS
==============
Job ID: 2986687
Array Job ID: 2986645_6
Cluster: snellius
User/Group: nreints/nreints
State: COMPLETED (exit code 0)
Nodes: 1
Cores per node: 18
CPU Utilized: 01:26:23
CPU Efficiency: 5.98% of 1-00:04:48 core-walltime
Job Wall-clock time: 01:20:16
Memory Utilized: 8.09 GB
Memory Efficiency: 0.00% of 0.00 MB
