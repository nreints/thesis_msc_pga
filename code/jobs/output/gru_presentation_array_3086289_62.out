wandb: Currently logged in as: nreints. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_211346-832cd7n3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stoic-resonance-458
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/832cd7n3
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gTrue â–ˆâ–‚â–â–‚â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gTrue â–ˆâ–‚â–â–‚â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gTrue â–ˆâ–‚â–â–‚â–â–â–â–â–â–
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gTrue â–ˆâ–‚â–â–‚â–â–â–â–â–â–
wandb:                                  Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gTrue 0.0
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gTrue 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: ðŸš€ View run stoic-resonance-458 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/832cd7n3
wandb: Synced 7 W&B file(s), 0 media file(s), 1 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_211346-832cd7n3/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_212010-7ptvn9ov
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run generous-dragon-464
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/7ptvn9ov
Training on dataset: data_t(5,20)_r(0,0)_combi_pNone_gTrue
Testing on 4 datasets: ['data_t(5,20)_r(0,0)_tennis_pNone_gTrue', 'data_t(5,20)_r(0,0)_semi_pNone_gTrue', 'data_t(5,20)_r(0,0)_combi_pNone_gTrue', 'data_t(5,20)_r(0,0)_full_pNone_gTrue']
Focussing on identity: False
Using extra input: False
Using fr-fr as reference point.
----- ITERATION 1/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gTrue took 50.361703634262085 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(0,0)_tennis_pNone_gTrue took 12.598069429397583 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_semi_pNone_gTrue took 12.54418396949768 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gTrue took 12.685709476470947 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_full_pNone_gTrue took 12.670403003692627 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(24, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=24, bias=True)
)
Datatype: pos_diff_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 4.09623e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.192e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 8.054e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 8.282e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.371e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 27.40793752670288
Epoch 1/9
	 Logging train Loss: 3.798e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.97e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.942e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.001e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.002e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 27.174863815307617
Epoch 2/9
	 Logging train Loss: 1.664e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.487e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.492e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.527e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.523e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 27.218750953674316
Epoch 3/9
	 Logging train Loss: 1.544e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.002e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.029e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.09e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.054e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 26.95574402809143
Epoch 4/9
	 Logging train Loss: 1.63e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.506e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.522e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.549e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.548e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 26.979517459869385
Epoch 5/9
	 Logging train Loss: 1.744e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.531e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.536e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.574e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.556e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 27.182526350021362
Epoch 6/9
	 Logging train Loss: 1.807e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.388e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.419e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.461e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.43e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 26.97518563270569
Epoch 7/9
	 Logging train Loss: 1.797e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.446e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.462e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.489e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.489e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 26.734316110610962
Epoch 8/9
	 Logging train Loss: 1.807e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.613e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.628e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.681e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.655e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 26.863529682159424
Epoch 9/9
	 Logging train Loss: 1.746e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.787e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.823e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.835e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.861e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 26.998348712921143
Saved model in  trained_models/gru/data_t(5,20)_r(0,0)_combi_pNone_gTrue/'pos_diff_1'_'False'.pth
It took  385.5337293148041  seconds.
----- ITERATION 2/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gTrue took 50.119588136672974 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(0,0)_tennis_pNone_gTrue took 12.704939842224121 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_semi_pNone_gTrue took 12.688250303268433 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gTrue took 12.589040994644165 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_full_pNone_gTrue took 12.604507207870483 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(24, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=24, bias=True)
)
Datatype: pos_diff_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 4.21604e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.611e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 8.181e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 8.354e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.637e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 26.985383987426758
Epoch 1/9
	 Logging train Loss: 4.145e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.191e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.109e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.139e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.173e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 26.927523612976074
Epoch 2/9
	 Logging train Loss: 1.788e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.616e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.566e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.59e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.583e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 26.901387214660645
Epoch 3/9
	 Logging train Loss: 1.598e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.469e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.426e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.462e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.435e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 26.861761331558228
Epoch 4/9
	 Logging train Loss: 1.68e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gTrue â–ˆâ–‚â–â–â–â–‚â–â–â–â–
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gTrue â–ˆâ–‚â–â–â–â–‚â–â–â–â–
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gTrue â–ˆâ–‚â–â–â–â–‚â–â–â–â–
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gTrue â–ˆâ–‚â–â–â–â–‚â–â–â–â–
wandb:                                  Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gTrue 0.0
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gTrue 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: ðŸš€ View run generous-dragon-464 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/7ptvn9ov
wandb: Synced 7 W&B file(s), 0 media file(s), 1 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_212010-7ptvn9ov/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_212631-8bok2i5f
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run kind-dew-474
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/8bok2i5f
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gTrue â–ˆâ–â–â–â–â–‚â–â–‚â–‚â–
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gTrue â–ˆâ–â–â–â–â–‚â–â–‚â–‚â–
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gTrue â–ˆâ–â–â–â–â–‚â–â–‚â–‚â–
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gTrue â–ˆâ–â–â–â–â–‚â–â–‚â–‚â–
wandb:                                  Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gTrue 0.0
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gTrue 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: ðŸš€ View run kind-dew-474 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/8bok2i5f
wandb: Synced 7 W&B file(s), 0 media file(s), 1 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_212631-8bok2i5f/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_213252-6oxg3upg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run noble-paper-482
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/6oxg3upg
	 Logging test loss: 1.692e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.666e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.687e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.682e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 27.039485454559326
Epoch 5/9
	 Logging train Loss: 1.782e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.119e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.095e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.117e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.108e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 27.05231499671936
Epoch 6/9
	 Logging train Loss: 1.814e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.651e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.627e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.648e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.637e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 27.03548002243042
Epoch 7/9
	 Logging train Loss: 1.787e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.65e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.624e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.648e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.63e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 26.931430101394653
Epoch 8/9
	 Logging train Loss: 1.763e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.718e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.683e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.708e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.696e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 26.83330512046814
Epoch 9/9
	 Logging train Loss: 1.747e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.437e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.413e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.433e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.419e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 27.051093816757202
Saved model in  trained_models/gru/data_t(5,20)_r(0,0)_combi_pNone_gTrue/'pos_diff_1'_'False'.pth
It took  380.97351145744324  seconds.
----- ITERATION 3/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gTrue took 50.16274380683899 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(0,0)_tennis_pNone_gTrue took 12.614904880523682 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_semi_pNone_gTrue took 12.616656303405762 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gTrue took 12.566407442092896 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_full_pNone_gTrue took 12.639787673950195 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(24, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=24, bias=True)
)
Datatype: pos_diff_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 3.69767e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.525e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 7.551e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 7.642e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.599e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 26.821125030517578
Epoch 1/9
	 Logging train Loss: 3.384e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.753e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.809e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.755e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.756e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 27.06546640396118
Epoch 2/9
	 Logging train Loss: 1.585e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.414e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.454e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.401e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.424e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 27.08412528038025
Epoch 3/9
	 Logging train Loss: 1.534e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.375e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.415e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.362e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.374e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 26.9845609664917
Epoch 4/9
	 Logging train Loss: 1.66e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.381e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.42e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.367e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.387e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 26.802640199661255
Epoch 5/9
	 Logging train Loss: 1.789e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.205e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.248e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.2e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.205e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 26.964169025421143
Epoch 6/9
	 Logging train Loss: 1.806e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.59e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.628e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.576e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.588e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 27.205911874771118
Epoch 7/9
	 Logging train Loss: 1.833e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.067e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.099e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.06e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.066e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 26.996214866638184
Epoch 8/9
	 Logging train Loss: 1.794e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.27e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.317e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.258e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.271e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 27.130346298217773
Epoch 9/9
	 Logging train Loss: 1.785e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.458e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.496e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.455e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.468e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 27.006097316741943
Saved model in  trained_models/gru/data_t(5,20)_r(0,0)_combi_pNone_gTrue/'pos_diff_1'_'False'.pth
It took  381.13777685165405  seconds.
----- ITERATION 4/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gTrue took 50.14793658256531 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(0,0)_tennis_pNone_gTrue took 12.597538471221924 seconds.
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gTrue â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gTrue â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gTrue â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gTrue â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb:                                  Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gTrue 0.0
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gTrue 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: ðŸš€ View run noble-paper-482 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/6oxg3upg
wandb: Synced 7 W&B file(s), 0 media file(s), 1 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_213252-6oxg3upg/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_213913-463cbixh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run bright-breeze-492
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/463cbixh
The dataloader for data/data_t(5,20)_r(0,0)_semi_pNone_gTrue took 12.566250324249268 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gTrue took 12.577593803405762 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_full_pNone_gTrue took 12.570709228515625 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(24, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=24, bias=True)
)
Datatype: pos_diff_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 4.21e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.756e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 7.583e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 7.788e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.143e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 26.969262838363647
Epoch 1/9
	 Logging train Loss: 3.791e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.935e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.92e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.943e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.956e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 26.787624835968018
Epoch 2/9
	 Logging train Loss: 1.641e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.487e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.517e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.522e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.478e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 27.117648124694824
Epoch 3/9
	 Logging train Loss: 1.539e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.415e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.43e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.448e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.405e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 26.995283126831055
Epoch 4/9
	 Logging train Loss: 1.668e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.411e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.437e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.427e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.397e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 26.828447580337524
Epoch 5/9
	 Logging train Loss: 1.768e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.475e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.491e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.499e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.46e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 26.789324283599854
Epoch 6/9
	 Logging train Loss: 1.842e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.688e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.701e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.688e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.659e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 27.044109582901
Epoch 7/9
	 Logging train Loss: 1.813e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.471e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.488e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.487e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.455e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 26.95114278793335
Epoch 8/9
	 Logging train Loss: 1.779e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.78e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.785e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.766e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.732e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 26.95842432975769
Epoch 9/9
	 Logging train Loss: 1.745e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.698e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.717e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.72e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.684e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 27.018786907196045
Saved model in  trained_models/gru/data_t(5,20)_r(0,0)_combi_pNone_gTrue/'pos_diff_1'_'False'.pth
It took  381.0471456050873  seconds.
----- ITERATION 5/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gTrue took 50.24911427497864 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(0,0)_tennis_pNone_gTrue took 12.55825662612915 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_semi_pNone_gTrue took 12.571846961975098 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gTrue took 12.538959980010986 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_full_pNone_gTrue took 12.63375735282898 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(24, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=24, bias=True)
)
Datatype: pos_diff_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 3.89435e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.023e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 7.901e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 8.081e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.055e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 26.981475591659546
Epoch 1/9
	 Logging train Loss: 3.649e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.884e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.89e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.914e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.891e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 26.78364849090576
Epoch 2/9
	 Logging train Loss: 1.677e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.526e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.537e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.545e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.538e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 26.985187530517578
Epoch 3/9
	 Logging train Loss: 1.604e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.841e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.856e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.853e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.857e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 26.916681051254272
Epoch 4/9
	 Logging train Loss: 1.757e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.466e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.476e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.476e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.475e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 26.971782445907593
Epoch 5/9
	 Logging train Loss: 1.878e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.656e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.67e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.667e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gTrue â–ˆâ–â–â–â–‚â–â–â–‚â–â–
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gTrue â–ˆâ–â–â–â–‚â–â–â–‚â–â–
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gTrue â–ˆâ–â–â–â–‚â–â–â–‚â–â–
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gTrue â–ˆâ–â–â–â–‚â–â–â–‚â–â–
wandb:                                  Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gTrue 0.0
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gTrue 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: ðŸš€ View run bright-breeze-492 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/463cbixh
wandb: Synced 7 W&B file(s), 0 media file(s), 1 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_213913-463cbixh/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_214534-o3jlo5pg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run copper-durian-500
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/o3jlo5pg
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gTrue â–ˆâ–‚â–â–â–‚â–â–â–â–â–
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gTrue â–ˆâ–‚â–â–â–‚â–â–â–â–â–
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gTrue â–ˆâ–‚â–â–â–‚â–â–â–â–â–
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gTrue â–ˆâ–‚â–â–â–‚â–â–â–â–â–
wandb:                                  Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gTrue 0.0
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gTrue 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: ðŸš€ View run copper-durian-500 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/o3jlo5pg
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_214534-o3jlo5pg/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_215158-5mgq3cdy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run charmed-breeze-508
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/5mgq3cdy
	 Logging test loss: 1.681e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 26.88926124572754
Epoch 6/9
	 Logging train Loss: 1.909e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.873e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.896e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.883e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.886e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 27.012855529785156
Epoch 7/9
	 Logging train Loss: 1.924e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.933e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.955e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.945e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.968e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 26.971972465515137
Epoch 8/9
	 Logging train Loss: 1.836e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.475e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.496e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.485e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.5e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 26.95184588432312
Epoch 9/9
	 Logging train Loss: 1.827e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.46e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.483e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.47e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.475e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 27.03463578224182
Saved model in  trained_models/gru/data_t(5,20)_r(0,0)_combi_pNone_gTrue/'pos_diff_1'_'False'.pth
It took  381.17258310317993  seconds.
----- ITERATION 6/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gTrue took 50.14042568206787 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(0,0)_tennis_pNone_gTrue took 12.546020984649658 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_semi_pNone_gTrue took 12.576078653335571 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gTrue took 12.632815599441528 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_full_pNone_gTrue took 12.574668645858765 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(24, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=24, bias=True)
)
Datatype: pos_diff_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 5.28703e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.2697e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.2085e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.2431e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.2514e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 26.99345564842224
Epoch 1/9
	 Logging train Loss: 6.447e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.041e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.902e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.989e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.937e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 27.104714155197144
Epoch 2/9
	 Logging train Loss: 2.136e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.743e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.681e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.721e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.654e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 27.09648823738098
Epoch 3/9
	 Logging train Loss: 1.64e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.48e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.445e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.479e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.413e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 26.963284254074097
Epoch 4/9
	 Logging train Loss: 1.764e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.675e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.621e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.655e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.577e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 27.21035075187683
Epoch 5/9
	 Logging train Loss: 1.859e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.704e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.652e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.686e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.617e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 27.219013929367065
Epoch 6/9
	 Logging train Loss: 1.921e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.451e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.417e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.461e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.383e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 26.89708161354065
Epoch 7/9
	 Logging train Loss: 1.927e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.526e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.493e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.517e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.446e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 27.144450664520264
Epoch 8/9
	 Logging train Loss: 1.89e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.804e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.751e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.785e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.715e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 27.043428659439087
Epoch 9/9
	 Logging train Loss: 1.858e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.505e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.497e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.508e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.444e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 27.07766079902649
Saved model in  trained_models/gru/data_t(5,20)_r(0,0)_combi_pNone_gTrue/'pos_diff_1'_'False'.pth
It took  383.10196685791016  seconds.
----- ITERATION 7/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gTrue took 50.153167486190796 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(0,0)_tennis_pNone_gTrue took 12.686969757080078 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_semi_pNone_gTrue took 12.698145627975464 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gTrue took 12.560588359832764 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_full_pNone_gTrue took 12.73240065574646 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(24, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=24, bias=True)
)
Datatype: pos_diff_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 2.46364e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.215e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gTrue â–ˆâ–‚â–â–â–â–‚â–â–â–â–†
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gTrue â–ˆâ–‚â–â–â–â–‚â–â–â–â–…
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gTrue â–ˆâ–â–â–â–â–‚â–â–â–â–†
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gTrue â–ˆâ–â–â–â–â–‚â–â–â–â–†
wandb:                                  Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gTrue 0.0
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gTrue 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: ðŸš€ View run charmed-breeze-508 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/5mgq3cdy
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_215158-5mgq3cdy/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_215823-gwue7sq9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pious-cloud-517
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/gwue7sq9
	 Logging test loss: 4.073e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 4.143e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.292e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 26.910367488861084
Epoch 1/9
	 Logging train Loss: 2.301e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.57e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.523e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.562e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.568e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 27.16557240486145
Epoch 2/9
	 Logging train Loss: 1.561e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.421e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.381e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.409e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.412e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 26.83912968635559
Epoch 3/9
	 Logging train Loss: 1.652e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.441e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.407e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.429e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.442e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 27.05305814743042
Epoch 4/9
	 Logging train Loss: 1.714e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.444e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.399e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.426e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.428e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 27.019895792007446
Epoch 5/9
	 Logging train Loss: 1.763e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.614e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.589e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.603e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.604e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 27.162935972213745
Epoch 6/9
	 Logging train Loss: 1.776e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.402e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.365e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.39e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.392e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 26.893380403518677
Epoch 7/9
	 Logging train Loss: 1.766e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.453e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.39e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.416e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.417e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 27.19559144973755
Epoch 8/9
	 Logging train Loss: 1.716e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.367e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.338e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.356e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.357e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 27.210397958755493
Epoch 9/9
	 Logging train Loss: 1.685e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.24e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.204e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 3.219e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.22e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 26.95063304901123
Saved model in  trained_models/gru/data_t(5,20)_r(0,0)_combi_pNone_gTrue/'pos_diff_1'_'False'.pth
It took  385.1810042858124  seconds.
----- ITERATION 8/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gTrue took 50.393600940704346 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(0,0)_tennis_pNone_gTrue took 12.669779539108276 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_semi_pNone_gTrue took 12.729880571365356 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gTrue took 12.595371961593628 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_full_pNone_gTrue took 12.79032301902771 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(24, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=24, bias=True)
)
Datatype: pos_diff_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 3.08829e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.681e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 8.496e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 8.472e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.86e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 27.122061252593994
Epoch 1/9
	 Logging train Loss: 3.94e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.852e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.877e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.863e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.891e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 27.219401359558105
Epoch 2/9
	 Logging train Loss: 1.651e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.442e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.479e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.469e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.479e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 27.053311824798584
Epoch 3/9
	 Logging train Loss: 1.616e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.423e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.462e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.464e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.462e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 27.16209101676941
Epoch 4/9
	 Logging train Loss: 1.748e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.511e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.557e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.547e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.548e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 26.97291898727417
Epoch 5/9
	 Logging train Loss: 1.878e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.486e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.519e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.512e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.53e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 27.141347646713257
Epoch 6/9
	 Logging train Loss: 1.872e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.212e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.24e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.232e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.238e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 27.13844609260559
Epoch 7/9
	 Logging train Loss: 1.855e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gTrue â–ˆâ–â–â–â–â–â–‚â–ƒâ–â–
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gTrue â–ˆâ–â–â–â–â–â–‚â–ƒâ–â–
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gTrue â–ˆâ–â–â–â–â–â–‚â–ƒâ–â–
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gTrue â–ˆâ–â–â–â–â–â–‚â–ƒâ–â–
wandb:                                  Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gTrue 0.0
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gTrue 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: ðŸš€ View run pious-cloud-517 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/gwue7sq9
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_215823-gwue7sq9/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_220446-valh6d8l
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run resilient-snowflake-526
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/valh6d8l
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gTrue â–ˆâ–â–â–â–â–â–â–‚â–‚â–
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gTrue â–ˆâ–â–â–â–â–â–â–‚â–‚â–
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gTrue â–ˆâ–â–â–â–â–â–â–‚â–‚â–
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gTrue â–ˆâ–â–â–â–â–â–â–‚â–‚â–
wandb:                                  Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gTrue 0.0
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gTrue 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: ðŸš€ View run resilient-snowflake-526 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/valh6d8l
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_220446-valh6d8l/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_221105-rgmoa08x
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vague-sun-535
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/rgmoa08x
	 Logging test loss: 3.473e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.503e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 3.523e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.499e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 27.015257120132446
Epoch 8/9
	 Logging train Loss: 1.819e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.422e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.461e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.453e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.46e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 26.789154052734375
Epoch 9/9
	 Logging train Loss: 1.777e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.776e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.782e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.774e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.792e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 26.917656421661377
Saved model in  trained_models/gru/data_t(5,20)_r(0,0)_combi_pNone_gTrue/'pos_diff_1'_'False'.pth
It took  383.2189373970032  seconds.
----- ITERATION 9/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gTrue took 48.41904330253601 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(0,0)_tennis_pNone_gTrue took 12.59433650970459 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_semi_pNone_gTrue took 12.553535461425781 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gTrue took 12.267821073532104 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_full_pNone_gTrue took 12.5779709815979 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(24, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=24, bias=True)
)
Datatype: pos_diff_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 3.23976e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.583e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 5.355e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 5.301e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.48e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 26.74325966835022
Epoch 1/9
	 Logging train Loss: 2.798e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.639e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.629e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.623e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.616e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 27.106385231018066
Epoch 2/9
	 Logging train Loss: 1.555e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.405e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.408e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.426e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.405e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 26.816757202148438
Epoch 3/9
	 Logging train Loss: 1.573e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.417e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.42e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.421e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.4e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 26.972957372665405
Epoch 4/9
	 Logging train Loss: 1.674e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.561e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.576e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.58e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.553e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 27.07956624031067
Epoch 5/9
	 Logging train Loss: 1.765e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.525e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.531e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.537e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.528e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 26.818355321884155
Epoch 6/9
	 Logging train Loss: 1.795e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.598e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.605e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.642e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.589e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 26.861836910247803
Epoch 7/9
	 Logging train Loss: 1.751e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.043e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.031e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.061e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.017e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 26.912291288375854
Epoch 8/9
	 Logging train Loss: 1.743e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.841e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.834e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.842e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.828e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 26.907161235809326
Epoch 9/9
	 Logging train Loss: 1.722e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.623e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.62e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.643e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.607e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 27.049876928329468
Saved model in  trained_models/gru/data_t(5,20)_r(0,0)_combi_pNone_gTrue/'pos_diff_1'_'False'.pth
It took  379.1311848163605  seconds.
----- ITERATION 10/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gTrue took 48.790322065353394 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(0,0)_tennis_pNone_gTrue took 12.552422523498535 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_semi_pNone_gTrue took 12.530550479888916 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gTrue took 12.269017934799194 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_full_pNone_gTrue took 12.575215578079224 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(24, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=24, bias=True)
)
Datatype: pos_diff_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 3.15925e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.455e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 8.06e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 8.42e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.5e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 27.074238538742065
Epoch 1/9
	 Logging train Loss: 3.957e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.063e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.047e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.092e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.103e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gTrue â–ˆâ–‚â–â–â–â–ƒâ–â–‚â–â–
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gTrue â–ˆâ–‚â–â–â–â–ƒâ–â–‚â–â–
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gTrue â–ˆâ–‚â–â–â–â–ƒâ–â–‚â–â–
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gTrue â–ˆâ–‚â–â–â–â–ƒâ–â–‚â–â–
wandb:                                  Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gTrue 0.0
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gTrue 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: ðŸš€ View run vague-sun-535 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/rgmoa08x
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_221105-rgmoa08x/logs
		--> Epoch time; 26.905789375305176
Epoch 2/9
	 Logging train Loss: 1.71e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.451e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.452e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.505e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.48e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 26.7725887298584
Epoch 3/9
	 Logging train Loss: 1.569e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.59e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.6e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.627e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.613e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 26.888655185699463
Epoch 4/9
	 Logging train Loss: 1.671e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.724e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.73e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.766e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.75e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 27.035727977752686
Epoch 5/9
	 Logging train Loss: 1.786e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.208e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.239e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 3.285e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.255e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 27.142853021621704
Epoch 6/9
	 Logging train Loss: 1.819e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.894e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.902e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.939e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.927e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 26.896971464157104
Epoch 7/9
	 Logging train Loss: 1.807e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.043e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.05e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.087e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.083e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 27.08460283279419
Epoch 8/9
	 Logging train Loss: 1.801e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.59e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.615e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.652e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.639e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 27.07320213317871
Epoch 9/9
	 Logging train Loss: 1.746e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.435e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.445e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.484e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.458e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 26.84307885169983
Saved model in  trained_models/gru/data_t(5,20)_r(0,0)_combi_pNone_gTrue/'pos_diff_1'_'False'.pth
It took  381.13185930252075  seconds.

JOB STATISTICS
==============
Job ID: 3086310
Array Job ID: 3086289_62
Cluster: snellius
User/Group: nreints/nreints
State: RUNNING
Nodes: 1
Cores per node: 18
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 19:11:06 core-walltime
Job Wall-clock time: 01:03:57
Memory Utilized: 0.00 MB (estimated maximum)
Memory Efficiency: 0.00% of 0.00 MB (0.00 MB/node)
WARNING: Efficiency statistics may be misleading for RUNNING jobs.
