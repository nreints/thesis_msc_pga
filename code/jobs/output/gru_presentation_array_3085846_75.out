wandb: Currently logged in as: nreints. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_203638-gcxda93j
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sunny-puddle-401
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/gcxda93j
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gTrue █▂▂▁▁▁▁▂▁▁
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gTrue █▁▁▁▁▁▁▁▁▁
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gTrue █▂▂▁▁▁▁▂▁▁
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gTrue █▂▂▁▁▁▁▂▁▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gTrue 0.0
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gTrue 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: 🚀 View run sunny-puddle-401 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/gcxda93j
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_203638-gcxda93j/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_204329-yi1jxwdc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wise-eon-413
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/yi1jxwdc
Training on dataset: data_t(0,0)_r(5,20)_combi_pNone_gTrue
Testing on 4 datasets: ['data_t(0,0)_r(5,20)_tennis_pNone_gTrue', 'data_t(0,0)_r(5,20)_full_pNone_gTrue', 'data_t(0,0)_r(5,20)_combi_pNone_gTrue', 'data_t(0,0)_r(5,20)_semi_pNone_gTrue']
Focussing on identity: False
Using extra input: False
Using fr-fr as reference point.
----- ITERATION 1/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gTrue took 52.59202742576599 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(5,20)_tennis_pNone_gTrue took 13.017285823822021 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_full_pNone_gTrue took 13.049590587615967 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gTrue took 13.1591956615448 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_semi_pNone_gTrue took 13.325381994247437 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: log_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0006179589 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 6.00254e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 6.6037e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 3.11995e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 5.33136e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 31.084566354751587
Epoch 1/9
	 Logging train Loss: 1.19307e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 9.5497e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 4.253e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 4.8459e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 8.9545e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 28.884855031967163
Epoch 2/9
	 Logging train Loss: 4.293e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 1.31465e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 3.984e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 6.8239e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 1.2433e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 28.613794803619385
Epoch 3/9
	 Logging train Loss: 4.2223e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 6.1495e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 1.468e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 3.1428e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 5.9324e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 28.64014434814453
Epoch 4/9
	 Logging train Loss: 4.2892e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 6.717e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 1.35e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 3.4004e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 6.3447e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 28.642407417297363
Epoch 5/9
	 Logging train Loss: 4.0222e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 5.99e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 9.56e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 3.0205e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 5.691e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 28.96647834777832
Epoch 6/9
	 Logging train Loss: 4.0308e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 6.6473e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 1.212e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 3.3339e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 6.2625e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 29.060956478118896
Epoch 7/9
	 Logging train Loss: 3.6103e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 9.0908e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 2.72e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 4.6524e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 8.5442e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 28.920851707458496
Epoch 8/9
	 Logging train Loss: 3.2832e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 4.3481e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 5.91e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 2.1989e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 4.1458e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 28.91400408744812
Epoch 9/9
	 Logging train Loss: 2.9797e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 4.1639e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 9.9e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 2.0789e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 3.9099e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 29.00524353981018
Saved model in  trained_models/gru/data_t(0,0)_r(5,20)_combi_pNone_gTrue/'log_quat_1'_'False'.pth
It took  412.12830877304077  seconds.
----- ITERATION 2/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gTrue took 47.97381281852722 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(5,20)_tennis_pNone_gTrue took 12.099557876586914 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_full_pNone_gTrue took 12.155209302902222 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gTrue took 12.007623672485352 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_semi_pNone_gTrue took 12.126666069030762 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: log_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0004786475 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 3.76192e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 5.8425e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 2.16125e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 3.76993e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 29.444219827651978
Epoch 1/9
	 Logging train Loss: 8.3267e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 7.022e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 5.051e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 3.8852e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 7.5068e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 29.084413051605225
Epoch 2/9
	 Logging train Loss: 4.1344e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 8.0124e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 3.753e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 4.3928e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 8.4824e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 29.02671766281128
Epoch 3/9
	 Logging train Loss: 4.5782e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 5.5763e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 2.427e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 3.0624e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 6.0782e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 29.208114624023438
Epoch 4/9
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gTrue █▂▂▁▁▂▂▂▁▁
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gTrue █▂▁▁▁▁▁▁▁▁
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gTrue █▂▂▁▂▂▂▂▁▁
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gTrue █▂▂▁▁▂▂▂▁▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gTrue 0.0
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gTrue 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: 🚀 View run wise-eon-413 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/yi1jxwdc
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_204329-yi1jxwdc/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_205010-gm0za8m8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run spring-dream-423
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/gm0za8m8
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gTrue █▂▂▅▂▂▁▁▁▁
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gTrue █▁▁▂▁▁▁▁▁▁
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gTrue █▂▃▅▂▂▁▁▁▁
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gTrue █▂▃▅▂▂▁▁▁▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gTrue 0.0
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gTrue 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: 🚀 View run spring-dream-423 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/gm0za8m8
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_205010-gm0za8m8/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_205650-vzhhofnh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run curious-shape-434
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/vzhhofnh
	 Logging train Loss: 4.3585e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 6.1866e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 2.197e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 3.3395e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 6.6077e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 29.110305786132812
Epoch 5/9
	 Logging train Loss: 4.233e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 7.5672e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 2.243e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 4.0385e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 7.7922e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 29.189549922943115
Epoch 6/9
	 Logging train Loss: 3.9367e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 6.8525e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 1.896e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 3.6701e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 7.0785e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 29.082329511642456
Epoch 7/9
	 Logging train Loss: 3.5847e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 7.1663e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 1.784e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 3.7537e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 7.1794e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 28.987993717193604
Epoch 8/9
	 Logging train Loss: 3.2314e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 3.9348e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 7.96e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 2.0609e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 4.1833e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 28.99591898918152
Epoch 9/9
	 Logging train Loss: 2.7514e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 4.5894e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 9.25e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 2.393e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 4.6715e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 29.117420434951782
Saved model in  trained_models/gru/data_t(0,0)_r(5,20)_combi_pNone_gTrue/'log_quat_1'_'False'.pth
It took  401.09603571891785  seconds.
----- ITERATION 3/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gTrue took 47.92587089538574 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(5,20)_tennis_pNone_gTrue took 12.12949514389038 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_full_pNone_gTrue took 12.075212955474854 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gTrue took 11.97576093673706 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_semi_pNone_gTrue took 12.104678869247437 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: log_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0003897667 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 3.93307e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 4.8546e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 2.0571e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 3.6419e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 29.19453191757202
Epoch 1/9
	 Logging train Loss: 7.7638e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 9.7202e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 3.793e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 4.7498e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 9.5062e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 29.148155689239502
Epoch 2/9
	 Logging train Loss: 4.7066e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 1.14336e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 3.635e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 5.5324e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 1.10188e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 28.986172914505005
Epoch 3/9
	 Logging train Loss: 4.8926e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 2.58325e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 7.933e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 1.25322e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 2.30236e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 29.18632936477661
Epoch 4/9
	 Logging train Loss: 4.4249e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 6.845e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 1.733e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 3.3195e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 6.7534e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 29.4400417804718
Epoch 5/9
	 Logging train Loss: 4.3199e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 8.445e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 2.11e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 4.1048e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 8.1526e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 29.216792106628418
Epoch 6/9
	 Logging train Loss: 3.993e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 4.6947e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 9.53e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 2.2624e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 4.6694e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 29.36758017539978
Epoch 7/9
	 Logging train Loss: 3.3322e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 5.6064e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 1.307e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 2.6884e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 5.2585e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 29.093735456466675
Epoch 8/9
	 Logging train Loss: 3.0792e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 4.0603e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 7.46e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 1.9494e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 3.9314e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 29.233439922332764
Epoch 9/9
	 Logging train Loss: 2.5602e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 3.2418e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 5.13e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 1.5466e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 3.1161e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 29.158657789230347
Saved model in  trained_models/gru/data_t(0,0)_r(5,20)_combi_pNone_gTrue/'log_quat_1'_'False'.pth
It took  400.14092803001404  seconds.
----- ITERATION 4/10 ------
Number of train simulations:  1920
Number of test simulations:  480
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gTrue █▂▁▁▂▁▂▃▁▁
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gTrue █▂▁▁▁▁▁▁▁▁
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gTrue █▂▂▂▂▁▂▃▁▁
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gTrue █▂▁▂▂▁▂▃▁▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gTrue 0.0
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gTrue 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: 🚀 View run curious-shape-434 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/vzhhofnh
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_205650-vzhhofnh/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_210335-u63oajde
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cosmic-water-444
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/u63oajde
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gTrue took 47.992435693740845 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(5,20)_tennis_pNone_gTrue took 12.131797790527344 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_full_pNone_gTrue took 12.112972736358643 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gTrue took 12.066014528274536 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_semi_pNone_gTrue took 12.147560358047485 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: log_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0004186926 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 3.13519e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 5.2083e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 1.88231e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 2.97428e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 29.53282356262207
Epoch 1/9
	 Logging train Loss: 7.972e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 9.0188e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 5.839e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 5.1354e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 8.906e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 29.648505687713623
Epoch 2/9
	 Logging train Loss: 5.0756e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 6.0166e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 2.588e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 3.4616e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 5.9952e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 30.244044065475464
Epoch 3/9
	 Logging train Loss: 5.0513e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 6.1619e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 2.199e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 3.4698e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 6.074e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 29.01809072494507
Epoch 4/9
	 Logging train Loss: 4.7932e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 9.0909e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 2.686e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 4.9678e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 8.8507e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 29.231054067611694
Epoch 5/9
	 Logging train Loss: 4.1582e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 5.2948e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 1.508e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 2.9907e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 5.2478e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 29.732366800308228
Epoch 6/9
	 Logging train Loss: 3.7363e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 6.7476e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 1.738e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 3.738e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 6.6455e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 29.385839700698853
Epoch 7/9
	 Logging train Loss: 3.6084e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 1.10333e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 2.894e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 5.8926e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 1.04807e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 29.197521448135376
Epoch 8/9
	 Logging train Loss: 3.1122e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 4.1405e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 7.94e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 2.3e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 4.049e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 29.2635715007782
Epoch 9/9
	 Logging train Loss: 2.7573e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 4.1878e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 1.018e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 2.3144e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 4.0407e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 29.11277747154236
Saved model in  trained_models/gru/data_t(0,0)_r(5,20)_combi_pNone_gTrue/'log_quat_1'_'False'.pth
It took  405.0845937728882  seconds.
----- ITERATION 5/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gTrue took 49.47571873664856 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(5,20)_tennis_pNone_gTrue took 12.31264591217041 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_full_pNone_gTrue took 12.255829572677612 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gTrue took 12.332093954086304 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_semi_pNone_gTrue took 12.21715235710144 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: log_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0007877115 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 6.21082e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 6.8968e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 3.46409e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 6.03448e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 29.113964080810547
Epoch 1/9
	 Logging train Loss: 1.46971e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 1.0194e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 8.778e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 5.6943e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 1.02669e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 28.855862379074097
Epoch 2/9
	 Logging train Loss: 4.9007e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 6.6261e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 3.195e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 3.62e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 7.0408e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 29.02784276008606
Epoch 3/9
	 Logging train Loss: 4.3485e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 1.3145e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 4.192e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 6.8361e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 1.27369e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 29.233357906341553
Epoch 4/9
	 Logging train Loss: 4.6532e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 5.4815e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 1.748e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 2.9455e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 5.8012e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 29.17724347114563
Epoch 5/9
slurmstepd: error: *** JOB 3085905 ON gcn20 CANCELLED AT 2023-07-16T21:09:10 ***
slurmstepd: error: *** STEP 3085905.0 ON gcn20 CANCELLED AT 2023-07-16T21:09:10 ***

JOB STATISTICS
==============
Job ID: 3085905
Array Job ID: 3085846_75
Cluster: snellius
User/Group: nreints/nreints
State: CANCELLED (exit code 0)
Nodes: 1
Cores per node: 18
CPU Utilized: 00:00:01
CPU Efficiency: 0.00% of 09:49:30 core-walltime
Job Wall-clock time: 00:32:45
Memory Utilized: 7.54 MB
Memory Efficiency: 0.00% of 0.00 MB
