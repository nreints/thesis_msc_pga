wandb: Currently logged in as: nreints. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home/nreints/.netrc
/gpfs/home2/nreints/MScThesis/code/fcnn.py:566: DeprecationWarning: Sampling from a set deprecated
since Python 3.9 and will be removed in a subsequent version.
  train_sims = set(random.sample(sims_train, int(0.8 * n_sims_train)))
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230330_123650-q4uzu817
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dazzling-puddle-569
wandb: â­ï¸ View project at https://wandb.ai/nreints/test
wandb: ðŸš€ View run at https://wandb.ai/nreints/test/runs/q4uzu817
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:  Test loss t(0, 0)_r(5, 20)_semi L1Loss() â–ˆâ–ƒâ–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: Test loss t(0, 0)_r(5, 20)_semi MSELoss() â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:     Train loss data_t(0, 0)_r(5, 20)_semi â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:  Test loss t(0, 0)_r(5, 20)_semi L1Loss() 0.72607
wandb: Test loss t(0, 0)_r(5, 20)_semi MSELoss() 1.649
wandb:     Train loss data_t(0, 0)_r(5, 20)_semi 1.58973
wandb: 
wandb: ðŸš€ View run dazzling-puddle-569 at: https://wandb.ai/nreints/test/runs/q4uzu817
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230330_123650-q4uzu817/logs
/gpfs/home2/nreints/MScThesis/code/fcnn.py:566: DeprecationWarning: Sampling from a set deprecated
since Python 3.9 and will be removed in a subsequent version.
  train_sims = set(random.sample(sims_train, int(0.8 * n_sims_train)))
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230330_124938-580dqk1x
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lilac-donkey-640
wandb: â­ï¸ View project at https://wandb.ai/nreints/test
wandb: ðŸš€ View run at https://wandb.ai/nreints/test/runs/580dqk1x
Training on dataset: data/data_t(0, 0)_r(5, 20)_semi_pNone_gNone
Testing on datasets: ['data_t(0, 0)_r(5, 20)_semi_pNone_gNone']
----- ITERATION 1/2 ------
Number of train simulations: 1600
Number of test simulations: 400
The dataloader took 60.680251359939575 seconds.
-- Finished Train Dataloader --
The dataloader took 14.997666835784912 seconds.
-- Finished Test Dataloader(s) --
Datatype: log_dualQ
--- Started Training ---
Epoch 0
	 Logging train Loss: 276.2811478758 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 52.47954177856445 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 4.593836784362793 (L1Loss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
     --> Epoch time; 35.38525581359863
Epoch 1
	 Logging train Loss: 21.0638378268 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 10.413717269897461 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 1.7370668649673462 (L1Loss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
     --> Epoch time; 34.77706718444824
Epoch 2
	 Logging train Loss: 8.6897390727 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 6.799045562744141 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 1.3800158500671387 (L1Loss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
     --> Epoch time; 34.40226149559021
Epoch 3
	 Logging train Loss: 6.0750702104 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 5.224934101104736 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 1.2079578638076782 (L1Loss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
     --> Epoch time; 34.41320848464966
Epoch 4
	 Logging train Loss: 4.7912674249 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 4.329447269439697 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 1.1059978008270264 (L1Loss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
     --> Epoch time; 34.28357195854187
Epoch 5
	 Logging train Loss: 4.0244520399 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 3.7073323726654053 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 1.0265415906906128 (L1Loss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
     --> Epoch time; 34.508591651916504
Epoch 6
	 Logging train Loss: 3.5129053054 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 3.382132053375244 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 1.0002851486206055 (L1Loss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
     --> Epoch time; 34.64890241622925
Epoch 7
	 Logging train Loss: 3.1482485703 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 3.037323236465454 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 0.9448145627975464 (L1Loss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
     --> Epoch time; 34.56567096710205
Epoch 8
	 Logging train Loss: 2.8768892974 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 2.862895965576172 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 0.9349988102912903 (L1Loss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
     --> Epoch time; 34.330848932266235
Epoch 9
	 Logging train Loss: 2.6565485537 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 2.6260976791381836 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 0.8919490575790405 (L1Loss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
     --> Epoch time; 32.845184326171875
Epoch 10
	 Logging train Loss: 2.4760836333 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 2.5161590576171875 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 0.8821619749069214 (L1Loss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
     --> Epoch time; 32.672157764434814
Epoch 11
	 Logging train Loss: 2.3190367456 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 2.5142922401428223 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 0.9001857042312622 (L1Loss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
     --> Epoch time; 32.755573987960815
Epoch 12
	 Logging train Loss: 2.1929910897 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 2.193899393081665 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 0.8284245133399963 (L1Loss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
     --> Epoch time; 32.487085580825806
Epoch 13
	 Logging train Loss: 2.0749909046 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 2.0622310638427734 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 0.802239179611206 (L1Loss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
     --> Epoch time; 34.38831377029419
Epoch 14
	 Logging train Loss: 1.9640152676 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 1.9637587070465088 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 0.783224880695343 (L1Loss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
     --> Epoch time; 33.35581016540527
Epoch 15
	 Logging train Loss: 1.8791285297 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 1.91200590133667 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 0.7791960835456848 (L1Loss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
     --> Epoch time; 32.90625715255737
Epoch 16
	 Logging train Loss: 1.7954174964 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 1.7943263053894043 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 0.7521026730537415 (L1Loss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
     --> Epoch time; 32.733168601989746
Epoch 17
	 Logging train Loss: 1.7167290582 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 1.7523002624511719 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 0.7520340085029602 (L1Loss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
     --> Epoch time; 32.76142454147339
Epoch 18
	 Logging train Loss: 1.6551312615 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 1.6764296293258667 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 0.7330697774887085 (L1Loss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
     --> Epoch time; 33.10010242462158
Epoch 19
	 Logging train Loss: 1.589731573 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 1.6531219482421875 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 0.7260567545890808 (L1Loss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
     --> Epoch time; 34.984044551849365
	 Logging test loss 1.6490000486373901 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 0.7260661721229553 (L1Loss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
It took 767.3937294483185 seconds to train & eval the model.
----- ITERATION 2/2 ------
Number of train simulations: 1600
Number of test simulations: 400
The dataloader took 54.72875261306763 seconds.
-- Finished Train Dataloader --
The dataloader took 13.64769196510315 seconds.
-- Finished Test Dataloader(s) --
Datatype: log_dualQ
--- Started Training ---
Epoch 0
	 Logging train Loss: 255.5258374183 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 39.9346809387207 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 3.844226837158203 (L1Loss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
     --> Epoch time; 34.55690145492554
Epoch 1
	 Logging train Loss: 19.0052555658 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 11.640339851379395 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 1.84576416015625 (L1Loss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
     --> Epoch time; 32.855974197387695
Epoch 2
	 Logging train Loss: 9.4689733967 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 7.914957046508789 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 1.5025619268417358 (L1Loss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
     --> Epoch time; 32.66288876533508
Epoch 3
	 Logging train Loss: 7.0037383834 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 6.320545196533203 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:  Test loss t(0, 0)_r(5, 20)_semi L1Loss() â–ˆâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–
wandb: Test loss t(0, 0)_r(5, 20)_semi MSELoss() â–ˆâ–ƒâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:     Train loss data_t(0, 0)_r(5, 20)_semi â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:  Test loss t(0, 0)_r(5, 20)_semi L1Loss() 0.74907
wandb: Test loss t(0, 0)_r(5, 20)_semi MSELoss() 1.81175
wandb:     Train loss data_t(0, 0)_r(5, 20)_semi 1.73607
wandb: 
wandb: ðŸš€ View run lilac-donkey-640 at: https://wandb.ai/nreints/test/runs/580dqk1x
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230330_124938-580dqk1x/logs
	 Logging test loss 1.347515344619751 (L1Loss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
     --> Epoch time; 32.51249384880066
Epoch 4
	 Logging train Loss: 5.6433625664 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 5.204442501068115 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 1.227112054824829 (L1Loss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
     --> Epoch time; 34.55390667915344
Epoch 5
	 Logging train Loss: 4.7598706214 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 4.415562629699707 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 1.1235809326171875 (L1Loss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
     --> Epoch time; 34.31609916687012
Epoch 6
	 Logging train Loss: 4.1334370532 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 3.942782163619995 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 1.0741336345672607 (L1Loss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
     --> Epoch time; 34.71704292297363
Epoch 7
	 Logging train Loss: 3.6540916692 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 3.4885478019714355 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 1.0130311250686646 (L1Loss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
     --> Epoch time; 33.01327061653137
Epoch 8
	 Logging train Loss: 3.2983988843 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 3.186048746109009 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 0.9735100865364075 (L1Loss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
     --> Epoch time; 32.76874852180481
Epoch 9
	 Logging train Loss: 3.0094346788 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 2.932732582092285 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 0.9324981570243835 (L1Loss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
     --> Epoch time; 33.0466685295105
Epoch 10
	 Logging train Loss: 2.7783235039 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 2.7436447143554688 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 0.9065447449684143 (L1Loss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
     --> Epoch time; 32.86933994293213
Epoch 11
	 Logging train Loss: 2.5915152357 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 2.602565288543701 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 0.890694260597229 (L1Loss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
     --> Epoch time; 34.40609955787659
Epoch 12
	 Logging train Loss: 2.4327826606 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 2.448775291442871 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 0.8672263026237488 (L1Loss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
     --> Epoch time; 33.101847648620605
Epoch 13
	 Logging train Loss: 2.2903522965 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 2.360194206237793 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 0.8567854762077332 (L1Loss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
     --> Epoch time; 33.27063989639282
Epoch 14
	 Logging train Loss: 2.1717487809 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 2.2704455852508545 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 0.841773271560669 (L1Loss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
     --> Epoch time; 33.260281562805176
Epoch 15
	 Logging train Loss: 2.0645491856 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 2.1456429958343506 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 0.8193625211715698 (L1Loss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
     --> Epoch time; 32.56603121757507
Epoch 16
	 Logging train Loss: 1.9725016276 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 2.047597885131836 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 0.800809383392334 (L1Loss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
     --> Epoch time; 34.72969198226929
Epoch 17
	 Logging train Loss: 1.887321921 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 2.0095880031585693 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 0.7948669195175171 (L1Loss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
     --> Epoch time; 34.34917616844177
Epoch 18
	 Logging train Loss: 1.8129555696 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 1.936524748802185 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 0.7831538319587708 (L1Loss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
     --> Epoch time; 34.420318603515625
Epoch 19
	 Logging train Loss: 1.7360675488 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 1.8112125396728516 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 0.749231219291687 (L1Loss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
     --> Epoch time; 32.960989475250244
	 Logging test loss 1.811745285987854 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 0.7490716576576233 (L1Loss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
It took 754.532511472702 seconds to train & eval the model.

JOB STATISTICS
==============
Job ID: 2523374
Array Job ID: 2523368_6
Cluster: snellius
User/Group: nreints/nreints
State: COMPLETED (exit code 0)
Nodes: 1
Cores per node: 18
CPU Utilized: 04:02:44
CPU Efficiency: 52.57% of 07:41:42 core-walltime
Job Wall-clock time: 00:25:39
Memory Utilized: 3.41 GB
Memory Efficiency: 11.62% of 29.30 GB
