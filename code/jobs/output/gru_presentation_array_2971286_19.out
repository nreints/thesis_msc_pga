wandb: Currently logged in as: nreints. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_164542-blzjg6q6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run gentle-surf-19
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal1/runs/blzjg6q6
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone â–ˆâ–„â–ƒâ–‚â–‚â–‚â–‚â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone â–ˆâ–…â–„â–ƒâ–‚â–‚â–‚â–‚â–‚â–
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone â–ˆâ–„â–ƒâ–‚â–‚â–‚â–‚â–â–‚â–
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone â–ˆâ–„â–ƒâ–‚â–‚â–â–â–â–â–
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone â–ˆâ–„â–ƒâ–‚â–‚â–‚â–â–â–â–
wandb:                                   Train loss â–ˆâ–‚â–‚â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone 0.37101
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 0.88035
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone 0.17652
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 0.15943
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 0.32153
wandb:                                   Train loss 0.38219
wandb: 
wandb: ðŸš€ View run gentle-surf-19 at: https://wandb.ai/nreints/ThesisFinal1/runs/blzjg6q6
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_164542-blzjg6q6/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_165533-3rtwf4no
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fiery-field-57
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal1/runs/3rtwf4no
Training on dataset: data_t(5,20)_r(5,20)_combi_pNone_gNone
Testing on 5 datasets: ['data_t(5,20)_r(5,20)_tennis_pNone_gNone', 'data_t(5,20)_r(5,20)_semi_pNone_gNone', 'data_t(5,20)_r(5,20)_none_pNone_gNone', 'data_t(5,20)_r(5,20)_combi_pNone_gNone', 'data_t(5,20)_r(5,20)_full_pNone_gNone']
Focussing on identity: False
Using extra input: False
Using start-fr as reference point.
----- ITERATION 1/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 78.86400508880615 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 19.775020599365234 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 19.792067289352417 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_none_pNone_gNone took 20.07379460334778 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 20.19828224182129 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 19.766733646392822 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(6, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=6, bias=True)
)
Datatype: log_dualQ
-- Started Training --
Epoch 0/9
	 Logging train Loss: 6.5733942986 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.9043422937 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.2520468235 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.0689971447 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.6585600376 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.4779965878 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 40.957414627075195
Epoch 1/9
	 Logging train Loss: 1.2353612185 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.0275599957 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.5992679596 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.5993127823 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.994713068 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.8171223402 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 40.62167763710022
Epoch 2/9
	 Logging train Loss: 0.8538137674 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.7442220449 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.4025738835 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.4252853394 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.751249969 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.5265525579 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 39.22453212738037
Epoch 3/9
	 Logging train Loss: 0.678291142 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.5775077343 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.3026103079 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.3236247301 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.6111028194 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.3245865107 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 38.9906268119812
Epoch 4/9
	 Logging train Loss: 0.5731605887 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.5149337649 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.273437649 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.3188094199 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.5590161085 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.2134611607 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 39.09679818153381
Epoch 5/9
	 Logging train Loss: 0.510633707 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.446156323 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.2305056304 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.2565003037 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.4939689338 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.115457654 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 39.378434896469116
Epoch 6/9
	 Logging train Loss: 0.4622550011 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.4236312211 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.2233411372 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.2477523685 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.483705461 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.1068366766 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 39.35827088356018
Epoch 7/9
	 Logging train Loss: 0.4321559072 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.3904767334 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.2041350007 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.2319038063 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.4423268437 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.9987001419 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 40.11744809150696
Epoch 8/9
	 Logging train Loss: 0.4079239666 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.3856048882 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.2095317543 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.2428354323 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.4470892847 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.0108448267 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 39.42024564743042
Epoch 9/9
	 Logging train Loss: 0.3821929693 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.3215280175 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.159433797 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.1765180379 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.3710134029 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.8803461194 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 39.48279047012329
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gNone/'log_dualQ'_'False'.pth
It took  592.4448854923248  seconds.
----- ITERATION 2/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 71.95343732833862 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 18.246875762939453 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 18.203545570373535 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_none_pNone_gNone took 18.190036058425903 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 18.036250114440918 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 18.216797351837158 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(6, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=6, bias=True)
)
Datatype: log_dualQ
-- Started Training --
Epoch 0/9
	 Logging train Loss: 6.2485685349 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.6034562588 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.132517457 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.9585992694 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone â–ˆâ–„â–ƒâ–ƒâ–‚â–‚â–‚â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone â–ˆâ–…â–„â–ƒâ–ƒâ–‚â–‚â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone â–ˆâ–„â–ƒâ–‚â–‚â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone â–ˆâ–„â–ƒâ–‚â–‚â–â–â–â–â–
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone â–ˆâ–„â–ƒâ–‚â–‚â–‚â–â–â–â–
wandb:                                   Train loss â–ˆâ–‚â–‚â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone 0.43131
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 0.98963
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone 0.18622
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 0.186
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 0.31433
wandb:                                   Train loss 0.36898
wandb: 
wandb: ðŸš€ View run fiery-field-57 at: https://wandb.ai/nreints/ThesisFinal1/runs/3rtwf4no
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_165533-3rtwf4no/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_170504-obt5pq12
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run playful-fog-96
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal1/runs/obt5pq12
	 Logging test loss: 1.5637367964 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.4298415184 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 39.639403343200684
Epoch 1/9
	 Logging train Loss: 1.1409558058 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.8947999477 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.566275835 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.5465285778 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.9956553578 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.8672114611 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 40.05682301521301
Epoch 2/9
	 Logging train Loss: 0.8046468496 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.6723598838 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.4032560587 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.3970426023 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.7974982262 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.620341897 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 39.611621379852295
Epoch 3/9
	 Logging train Loss: 0.6638456583 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.5690565109 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.3389363587 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.3268592358 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.6856576204 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.4126884937 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 39.503299951553345
Epoch 4/9
	 Logging train Loss: 0.5689755082 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.4860850573 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.2789804637 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.2785492837 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.6074029207 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.315064311 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 39.60193347930908
Epoch 5/9
	 Logging train Loss: 0.5019062161 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.4281346202 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.2464938313 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.2397014499 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.5408559442 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.1844944954 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 39.38171434402466
Epoch 6/9
	 Logging train Loss: 0.4586852491 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.4002099633 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.2306156754 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.2319425493 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.5261054635 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.1763772964 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 39.22948122024536
Epoch 7/9
	 Logging train Loss: 0.4241064489 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.3417969644 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.1952302456 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.1970798522 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.4541432559 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.0401844978 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 39.50971221923828
Epoch 8/9
	 Logging train Loss: 0.3928306997 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.3805556893 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.2304994017 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.2369439006 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.4866150022 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.0687265396 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 39.66168022155762
Epoch 9/9
	 Logging train Loss: 0.3689831495 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.3143301606 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.1860001534 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.186224401 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.4313099682 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.9896343946 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 39.437148332595825
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gNone/'log_dualQ'_'False'.pth
It took  570.4487221240997  seconds.
----- ITERATION 3/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 71.93552279472351 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 18.216068744659424 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 18.227834463119507 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_none_pNone_gNone took 18.23590111732483 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 18.057483434677124 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 18.236374378204346 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(6, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=6, bias=True)
)
Datatype: log_dualQ
-- Started Training --
Epoch 0/9
	 Logging train Loss: 6.5461611748 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.8102291822 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.151817441 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.0512189865 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.6067409515 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.5903258324 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 39.537530183792114
Epoch 1/9
	 Logging train Loss: 1.1908432245 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.9743053317 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.533960402 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.5461493731 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.9255020618 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.8454072475 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 39.15520405769348
Epoch 2/9
	 Logging train Loss: 0.8130044341 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.7073528171 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.3694013655 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.3890057802 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.7169672251 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.5642397404 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 38.793511390686035
Epoch 3/9
	 Logging train Loss: 0.6538760066 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.6142067313 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.3271967769 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.3308851421 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.6386648417 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.4333641529 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone â–ˆâ–„â–ƒâ–ƒâ–‚â–‚â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone â–ˆâ–…â–„â–ƒâ–ƒâ–‚â–‚â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone â–ˆâ–„â–ƒâ–‚â–‚â–‚â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone â–ˆâ–„â–‚â–‚â–‚â–‚â–â–â–â–
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone â–ˆâ–„â–ƒâ–‚â–‚â–‚â–â–â–â–
wandb:                                   Train loss â–ˆâ–‚â–‚â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone 0.37339
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 0.93137
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone 0.18177
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 0.1676
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 0.33571
wandb:                                   Train loss 0.36971
wandb: 
wandb: ðŸš€ View run playful-fog-96 at: https://wandb.ai/nreints/ThesisFinal1/runs/obt5pq12
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_170504-obt5pq12/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_171432-wkcr0j6e
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run young-star-129
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal1/runs/wkcr0j6e
		--> Epoch time; 39.06835317611694
Epoch 4/9
	 Logging train Loss: 0.5573809147 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.5304859877 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.2723923028 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.2878814638 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.5750724673 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.3729636669 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 39.46416187286377
Epoch 5/9
	 Logging train Loss: 0.4972425699 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.4597658217 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.2387978733 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.2563416064 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.489669323 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.1595458984 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 39.371694803237915
Epoch 6/9
	 Logging train Loss: 0.4512605071 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.4211120903 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.2040224969 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.2066391706 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.4466662407 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.100055337 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 39.32015061378479
Epoch 7/9
	 Logging train Loss: 0.4173929393 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.3610696197 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.1749503613 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.1709259003 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.3869622946 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.0010960102 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 39.21988129615784
Epoch 8/9
	 Logging train Loss: 0.390592128 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.3630441427 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.182756409 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.1862758845 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.3876803219 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.9630170465 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 39.54999327659607
Epoch 9/9
	 Logging train Loss: 0.3697122931 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.3357132077 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.1676018983 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.1817665696 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.3733929396 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.93137151 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 39.14060020446777
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gNone/'log_dualQ'_'False'.pth
It took  568.3857481479645  seconds.
----- ITERATION 4/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 71.26475405693054 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 18.17924976348877 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 18.167417764663696 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_none_pNone_gNone took 18.160629510879517 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 18.02136731147766 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 18.177552461624146 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(6, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=6, bias=True)
)
Datatype: log_dualQ
-- Started Training --
Epoch 0/9
	 Logging train Loss: 6.1732430458 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.9267772436 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.3834476471 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.1145454645 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.7485685349 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.5681760311 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 39.229671478271484
Epoch 1/9
	 Logging train Loss: 1.1692044735 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.0493485928 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.6480368376 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.589405477 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.0292600393 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.8342649937 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 39.18537211418152
Epoch 2/9
	 Logging train Loss: 0.8100942373 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.7773840427 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.4507712722 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.4215195775 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.7996128201 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.5926835537 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 39.070505142211914
Epoch 3/9
	 Logging train Loss: 0.6620678306 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.6373714805 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.3600952625 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.328963846 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.6706166267 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.4059073925 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 39.393213987350464
Epoch 4/9
	 Logging train Loss: 0.5719974041 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.5552957654 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.3172170222 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.3149675429 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.6021409035 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.3061280251 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 39.2371551990509
Epoch 5/9
	 Logging train Loss: 0.5136855245 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.5325856805 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.2970476449 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.295936197 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.5849522352 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.3000022173 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 40.07584857940674
Epoch 6/9
	 Logging train Loss: 0.465312928 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.4837773144 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.2763871551 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.2671556175 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.5234892368 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.1591868401 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 39.107590436935425
Epoch 7/9
	 Logging train Loss: 0.434264183 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone â–ˆâ–„â–ƒâ–‚â–‚â–‚â–‚â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone â–ˆâ–…â–„â–ƒâ–ƒâ–ƒâ–‚â–‚â–â–
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone â–ˆâ–„â–ƒâ–‚â–‚â–‚â–‚â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone â–ˆâ–„â–ƒâ–‚â–‚â–‚â–‚â–â–â–
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone â–ˆâ–„â–ƒâ–‚â–‚â–‚â–‚â–â–â–
wandb:                                   Train loss â–ˆâ–‚â–‚â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone 0.38583
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 0.92419
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone 0.17428
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 0.18923
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 0.34412
wandb:                                   Train loss 0.38131
wandb: 
wandb: ðŸš€ View run young-star-129 at: https://wandb.ai/nreints/ThesisFinal1/runs/wkcr0j6e
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_171432-wkcr0j6e/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_172401-tu1pc15l
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wobbly-cosmos-162
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal1/runs/tu1pc15l
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone â–ˆâ–„â–ƒâ–‚â–‚â–‚â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone â–ˆâ–…â–„â–ƒâ–‚â–‚â–‚â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone â–ˆâ–„â–ƒâ–‚â–‚â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone â–ˆâ–„â–‚â–‚â–‚â–â–â–â–â–
wandb:                                   Train loss â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone 0.38356
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 0.87734
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone 0.18435
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 0.16457
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 0.30536
wandb:                                   Train loss 0.35032
wandb: 
wandb: ðŸš€ View run wobbly-cosmos-162 at: https://wandb.ai/nreints/ThesisFinal1/runs/tu1pc15l
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_172401-tu1pc15l/logs
	 Logging test loss: 0.4284063578 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.2372263372 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.2272268087 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.4710226953 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.0686349869 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 39.04231834411621
Epoch 8/9
	 Logging train Loss: 0.4080150425 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.3892738223 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.2138664424 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.2016168088 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.4279718697 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.0089601278 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 39.37921142578125
Epoch 9/9
	 Logging train Loss: 0.3813079298 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.3441177309 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.1892296076 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.1742767692 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.385825336 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.9241885543 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 39.030813217163086
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gNone/'log_dualQ'_'False'.pth
It took  568.5401072502136  seconds.
----- ITERATION 5/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 71.28970170021057 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 18.100910663604736 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 18.097458839416504 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_none_pNone_gNone took 18.102548122406006 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 17.92515230178833 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 18.10601782798767 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(6, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=6, bias=True)
)
Datatype: log_dualQ
-- Started Training --
Epoch 0/9
	 Logging train Loss: 7.7369618416 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.5322327614 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.8022766113 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.293171525 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.161261797 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.846408844 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 39.26101541519165
Epoch 1/9
	 Logging train Loss: 1.4047033787 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.132371664 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.6776960492 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.6575583816 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.124591589 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.9387305975 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 39.30310320854187
Epoch 2/9
	 Logging train Loss: 0.8587144017 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.7623938322 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.4208730161 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.4271902144 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.8212734461 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.5903527737 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 39.27197623252869
Epoch 3/9
	 Logging train Loss: 0.6707757115 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.590923667 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.3115075827 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.3281206787 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.658362031 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.3521295786 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 39.14274048805237
Epoch 4/9
	 Logging train Loss: 0.5636613369 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.4987763762 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.2593429983 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.2824440598 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.5684300065 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.2000473738 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 38.91470146179199
Epoch 5/9
	 Logging train Loss: 0.4961467087 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.4527872205 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.2393132448 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.261344105 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.522398293 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.1185802221 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 38.76246643066406
Epoch 6/9
	 Logging train Loss: 0.4402349293 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.3936064541 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.2027792037 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.2273204029 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.4655852616 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.0254001617 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 38.75559401512146
Epoch 7/9
	 Logging train Loss: 0.4032435715 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.3547079265 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.1828116328 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.2009046525 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.4411751032 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.9896849394 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 38.89260125160217
Epoch 8/9
	 Logging train Loss: 0.3718811572 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.3298073709 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.1782007962 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.1999192685 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.3998198211 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.8936223388 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 39.040287017822266
Epoch 9/9
	 Logging train Loss: 0.3503249288 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.3053561151 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.164568305 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.1843524873 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.3835633099 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.8773430586 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 38.899550914764404
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gNone/'log_dualQ'_'False'.pth
It took  564.5334005355835  seconds.
----- ITERATION 6/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_173325-hlg91iaq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cool-universe-195
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal1/runs/hlg91iaq
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone â–ˆâ–„â–ƒâ–ƒâ–‚â–‚â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone â–ˆâ–…â–„â–ƒâ–‚â–‚â–‚â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone â–ˆâ–„â–ƒâ–‚â–‚â–‚â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone â–ˆâ–„â–ƒâ–‚â–‚â–â–â–â–â–
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone â–ˆâ–„â–ƒâ–‚â–‚â–‚â–â–â–â–
wandb:                                   Train loss â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone 0.36861
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 0.94501
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone 0.1642
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 0.17009
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 0.27801
wandb:                                   Train loss 0.36042
wandb: 
wandb: ðŸš€ View run cool-universe-195 at: https://wandb.ai/nreints/ThesisFinal1/runs/hlg91iaq
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_173325-hlg91iaq/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_174242-d12sr5q7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dark-jazz-227
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal1/runs/d12sr5q7
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 71.39249515533447 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 18.135108709335327 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 18.14125967025757 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_none_pNone_gNone took 18.11063313484192 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 18.000383138656616 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 18.15949320793152 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(6, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=6, bias=True)
)
Datatype: log_dualQ
-- Started Training --
Epoch 0/9
	 Logging train Loss: 6.7202525139 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.7963432074 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.3208216429 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.0592820644 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.6493643522 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.46033144 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 38.567073822021484
Epoch 1/9
	 Logging train Loss: 1.206325531 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.9510310292 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.6285477877 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.5542111397 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.9916409254 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.8702659607 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 38.306889057159424
Epoch 2/9
	 Logging train Loss: 0.8144193292 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.7003031969 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.4499382079 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.4184415042 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.7615548968 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.5396151543 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 38.35332226753235
Epoch 3/9
	 Logging train Loss: 0.6534969807 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.5703985691 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.3511874378 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.33914572 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.6449507475 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.3884930611 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 38.07658314704895
Epoch 4/9
	 Logging train Loss: 0.5610912442 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.4573551416 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.2777782977 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.2725516558 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.5419310331 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.2274672985 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 37.90095019340515
Epoch 5/9
	 Logging train Loss: 0.4969093204 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.4068551362 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.2448402345 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.2473042011 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.4995990396 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.1634819508 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 38.15486788749695
Epoch 6/9
	 Logging train Loss: 0.4527704418 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.3728723824 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.2271110713 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.2138621658 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.4592202306 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.0840438604 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 38.30385375022888
Epoch 7/9
	 Logging train Loss: 0.4151954353 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.3311034739 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.2008106858 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.1955423802 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.4127905369 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.9927212 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 38.34736394882202
Epoch 8/9
	 Logging train Loss: 0.3790182471 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.3153726459 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.1953297853 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.1930177212 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.4020632505 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.9855442047 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 38.24631881713867
Epoch 9/9
	 Logging train Loss: 0.3604235947 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.2780112326 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.1700915843 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.16419819 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.3686114252 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.9450131655 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 38.022135972976685
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gNone/'log_dualQ'_'False'.pth
It took  556.7703771591187  seconds.
----- ITERATION 7/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 71.10155749320984 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 18.043851137161255 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 18.074298620224 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_none_pNone_gNone took 18.046054363250732 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 17.896660566329956 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 18.02752447128296 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(6, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=6, bias=True)
)
Datatype: log_dualQ
-- Started Training --
Epoch 0/9
	 Logging train Loss: 7.5272293091 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.9307243824 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.3545818329 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.1041363478 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.8412123919 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.7336914539 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 38.2834575176239
Epoch 1/9
	 Logging train Loss: 1.2635346651 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.9759326577 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.6091629863 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.5702310205 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone â–ˆâ–„â–ƒâ–‚â–‚â–‚â–â–‚â–â–
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone â–ˆâ–…â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–â–
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone â–ˆâ–„â–ƒâ–‚â–‚â–‚â–â–‚â–â–
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone â–ˆâ–„â–‚â–‚â–‚â–â–â–â–â–
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone â–ˆâ–„â–ƒâ–‚â–‚â–‚â–â–â–â–
wandb:                                   Train loss â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone 0.39345
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 0.90522
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone 0.17702
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 0.18067
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 0.28702
wandb:                                   Train loss 0.35948
wandb: 
wandb: ðŸš€ View run dark-jazz-227 at: https://wandb.ai/nreints/ThesisFinal1/runs/d12sr5q7
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_174242-d12sr5q7/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_175201-7rubelnr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stellar-snow-259
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal1/runs/7rubelnr
	 Logging test loss: 1.0469485521 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.8665087223 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 38.188496351242065
Epoch 2/9
	 Logging train Loss: 0.8388771415 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.6951284409 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.4148172438 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.406275183 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.7901218534 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.5340261459 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 38.090229749679565
Epoch 3/9
	 Logging train Loss: 0.663417697 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.5662863851 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.3335238695 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.3192088902 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.6538398862 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.339709878 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 38.62081575393677
Epoch 4/9
	 Logging train Loss: 0.5593455434 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.4810473919 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.2909833193 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.2870615721 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.5921182632 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.2419910431 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 38.33406400680542
Epoch 5/9
	 Logging train Loss: 0.4972636104 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.4215019643 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.2544231117 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.2433089316 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.5295206904 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.1443420649 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 38.57387399673462
Epoch 6/9
	 Logging train Loss: 0.450101167 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.357560128 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.2162583768 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.2160756886 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.469237715 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.0471783876 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 38.598265647888184
Epoch 7/9
	 Logging train Loss: 0.4137526155 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.3907066882 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.2581425607 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.2543272972 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.5322387218 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.1733993292 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 38.927003383636475
Epoch 8/9
	 Logging train Loss: 0.3843633533 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.2993209958 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.1839349121 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.1775082648 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.4050119519 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.940520823 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 39.27239632606506
Epoch 9/9
	 Logging train Loss: 0.3594755828 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.2870217264 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.1806735694 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.1770247221 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.3934464157 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.9052214622 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 38.64617562294006
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gNone/'log_dualQ'_'False'.pth
It took  559.3293936252594  seconds.
----- ITERATION 8/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 71.32280850410461 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 18.052594900131226 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 18.04773449897766 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_none_pNone_gNone took 18.04016900062561 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 17.9549822807312 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 18.185195446014404 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(6, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=6, bias=True)
)
Datatype: log_dualQ
-- Started Training --
Epoch 0/9
	 Logging train Loss: 8.1713523865 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.8481447697 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.1557002068 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.4314272404 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.410241127 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.0779182911 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 38.21984815597534
Epoch 1/9
	 Logging train Loss: 1.5144380331 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.0574809313 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.6580780149 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.6257020831 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.0539770126 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.8549473286 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 38.63676881790161
Epoch 2/9
	 Logging train Loss: 0.8548629284 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.7064971328 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.4027070403 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.4427666068 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.7849474549 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.5828473568 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 38.50908374786377
Epoch 3/9
	 Logging train Loss: 0.6549700499 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.546353817 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.3040491939 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.3365283012 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.637778461 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.3561362028 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 38.46708345413208
Epoch 4/9
	 Logging train Loss: 0.5555642843 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.4728274345 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.26009655 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.2857855856 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.5719672441 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.2645076513 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone â–ˆâ–ƒâ–‚â–‚â–‚â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone â–ˆâ–„â–ƒâ–‚â–‚â–‚â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone â–ˆâ–„â–ƒâ–‚â–‚â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone â–ˆâ–ƒâ–‚â–‚â–‚â–â–â–â–â–
wandb:                                   Train loss â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone 0.36629
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 0.88859
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone 0.1696
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 0.14058
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 0.27646
wandb:                                   Train loss 0.35161
wandb: 
wandb: ðŸš€ View run stellar-snow-259 at: https://wandb.ai/nreints/ThesisFinal1/runs/7rubelnr
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_175201-7rubelnr/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_180120-sp0y30e5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run warm-fog-291
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal1/runs/sp0y30e5
		--> Epoch time; 38.34779906272888
Epoch 5/9
	 Logging train Loss: 0.4852232337 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.3974598944 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.2030036449 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.2358715385 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.4912769794 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.1184391975 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 38.73828196525574
Epoch 6/9
	 Logging train Loss: 0.4381830096 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.3639884591 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.198555246 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.2223491669 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.4618919492 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.0427926779 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 38.292604207992554
Epoch 7/9
	 Logging train Loss: 0.403108865 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.3333022296 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.1791107804 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.2158762962 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.427544266 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.9912520647 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 38.34765982627869
Epoch 8/9
	 Logging train Loss: 0.369433701 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.2909634113 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.1435941011 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.1664126664 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.377679944 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.9110512733 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 38.57993721961975
Epoch 9/9
	 Logging train Loss: 0.3516102135 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.2764571607 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.1405836195 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.1695954502 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.3662854433 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.888586998 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 38.70646786689758
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gNone/'log_dualQ'_'False'.pth
It took  558.4111504554749  seconds.
----- ITERATION 9/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 71.16898131370544 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 18.03195285797119 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 18.051847219467163 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_none_pNone_gNone took 18.031747102737427 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 17.9565532207489 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 18.115644931793213 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(6, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=6, bias=True)
)
Datatype: log_dualQ
-- Started Training --
Epoch 0/9
	 Logging train Loss: 7.1516637802 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.1848304272 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.5884045362 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.1386523247 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.9158018827 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.5561032295 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 38.407219648361206
Epoch 1/9
	 Logging train Loss: 1.2812157869 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.0728628635 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.6680448055 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.6060881019 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.0676362514 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.8442679644 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 38.65830135345459
Epoch 2/9
	 Logging train Loss: 0.8422827721 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.7426854968 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.4126728475 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.4130355716 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.7933417559 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.5385383368 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 38.5156672000885
Epoch 3/9
	 Logging train Loss: 0.6634190679 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.608019352 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.3259886503 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.3440746367 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.6635078192 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.3499299288 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 39.01666069030762
Epoch 4/9
	 Logging train Loss: 0.5641305447 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.5265784264 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.2727236152 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.2888718843 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.5811320543 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.2476606369 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 38.7479350566864
Epoch 5/9
	 Logging train Loss: 0.4936744869 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.4449275434 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.2283530682 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.2483655959 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.5068805218 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.1057591438 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 38.41244554519653
Epoch 6/9
	 Logging train Loss: 0.445146054 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.398145467 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.2031740695 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.2257914394 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.4539978504 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.020244956 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 38.538644313812256
Epoch 7/9
	 Logging train Loss: 0.4083151817 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.3742891848 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.191246137 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.2083240151 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.4300244749 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.9735992551 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 38.39492154121399
Epoch 8/9
	 Logging train Loss: 0.381891638 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone â–ˆâ–„â–ƒâ–‚â–‚â–‚â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone â–ˆâ–…â–„â–ƒâ–ƒâ–‚â–‚â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone â–ˆâ–„â–ƒâ–‚â–‚â–‚â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone â–ˆâ–„â–‚â–‚â–‚â–â–â–â–â–
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone â–ˆâ–„â–ƒâ–‚â–‚â–â–â–â–â–
wandb:                                   Train loss â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone 0.37463
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 0.87925
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone 0.17016
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 0.15599
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 0.31443
wandb:                                   Train loss 0.35781
wandb: 
wandb: ðŸš€ View run warm-fog-291 at: https://wandb.ai/nreints/ThesisFinal1/runs/sp0y30e5
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_180120-sp0y30e5/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_181040-h0ys3it0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run confused-frog-318
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal1/runs/h0ys3it0
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone â–ˆâ–„â–ƒâ–ƒâ–‚â–‚â–‚â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone â–ˆâ–…â–„â–ƒâ–‚â–‚â–‚â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone â–ˆâ–„â–ƒâ–‚â–‚â–‚â–‚â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone â–ˆâ–„â–ƒâ–‚â–‚â–â–â–â–â–
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone â–ˆâ–„â–ƒâ–‚â–‚â–‚â–â–â–â–
wandb:                                   Train loss â–ˆâ–‚â–‚â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone 0.38075
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 0.92434
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone 0.18409
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 0.14358
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 0.3066
wandb:                                   Train loss 0.35146
wandb: 
wandb: ðŸš€ View run confused-frog-318 at: https://wandb.ai/nreints/ThesisFinal1/runs/h0ys3it0
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_181040-h0ys3it0/logs
	 Logging test loss: 0.3487091064 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.1790092289 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.202799961 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.4166162908 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.9553713799 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 38.261460065841675
Epoch 9/9
	 Logging train Loss: 0.3578124046 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.3144289851 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.1559866518 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.1701559573 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.3746328354 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.8792489767 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 38.37990379333496
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gNone/'log_dualQ'_'False'.pth
It took  560.3248052597046  seconds.
----- ITERATION 10/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 71.11041522026062 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 18.008593559265137 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 18.062113046646118 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_none_pNone_gNone took 18.08303713798523 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 18.023592233657837 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 18.101404666900635 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(6, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=6, bias=True)
)
Datatype: log_dualQ
-- Started Training --
Epoch 0/9
	 Logging train Loss: 6.3730711937 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.6314615011 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.035879612 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.0425752401 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.5575574636 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.604186058 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 38.08741235733032
Epoch 1/9
	 Logging train Loss: 1.1379671097 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.9006516933 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.5031106472 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.5720847249 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.9544590116 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.8955234289 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 38.391589641571045
Epoch 2/9
	 Logging train Loss: 0.782461822 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.6668711901 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.3529214263 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.4351074994 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.7513468862 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.5747971535 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 38.44630813598633
Epoch 3/9
	 Logging train Loss: 0.6293210983 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.5572123528 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.2928865552 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.3588047624 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.6473776102 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.4151850939 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 38.51941633224487
Epoch 4/9
	 Logging train Loss: 0.5386457443 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.4777782559 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.2356351316 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.2973588705 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.5582898855 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.2569426298 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 38.248674154281616
Epoch 5/9
	 Logging train Loss: 0.4744069576 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.4192624092 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.2032671869 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.2593548 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.4982492626 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.1599117517 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 38.51121258735657
Epoch 6/9
	 Logging train Loss: 0.4340359569 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.3958679438 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.2002081871 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.2652142644 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.4864401221 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.121207118 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 38.2100465297699
Epoch 7/9
	 Logging train Loss: 0.3999875188 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.3506953716 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.1744206101 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.2200856209 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.4273491204 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.030356288 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 38.69403696060181
Epoch 8/9
	 Logging train Loss: 0.3720511198 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.3600557745 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.1738422662 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.2367182523 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.44908306 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.0401365757 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 38.21519994735718
Epoch 9/9
	 Logging train Loss: 0.3514613509 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.3065951169 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.1435777545 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.184085235 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.3807526529 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.9243394136 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 38.492509603500366
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gNone/'log_dualQ'_'False'.pth
It took  558.6381642818451  seconds.
