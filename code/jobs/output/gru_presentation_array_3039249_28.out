wandb: Currently logged in as: nreints. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_231701-l113n1eh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run daily-moon-1145
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/l113n1eh
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue â–ˆâ–‚â–‚â–â–â–â–â–â–â–‚
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue â–ˆâ–‚â–‚â–â–â–â–â–â–â–
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue â–ˆâ–‚â–‚â–â–‚â–â–‚â–‚â–â–ƒ
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue â–ˆâ–‚â–‚â–â–‚â–â–‚â–‚â–â–ƒ
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 3e-05
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue 1e-05
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue 6e-05
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue 7e-05
wandb:                                 Train loss 2e-05
wandb: 
wandb: ðŸš€ View run daily-moon-1145 at: https://wandb.ai/nreints/ThesisFinal2/runs/l113n1eh
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_231701-l113n1eh/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_232451-ytyt65h3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run denim-firebrand-1157
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/ytyt65h3
Training on dataset: data_t(0,0)_r(0,0)_combi_pNone_gTrue
Testing on 4 datasets: ['data_t(0,0)_r(0,0)_full_pNone_gTrue', 'data_t(0,0)_r(0,0)_tennis_pNone_gTrue', 'data_t(0,0)_r(0,0)_combi_pNone_gTrue', 'data_t(0,0)_r(0,0)_semi_pNone_gTrue']
Focussing on identity: False
Using extra input: False
Using start-fr as reference point.
----- ITERATION 1/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 78.57326054573059 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_full_pNone_gTrue took 19.710792303085327 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pNone_gTrue took 19.92427110671997 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 19.73964214324951 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pNone_gTrue took 19.573614835739136 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: quat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0913570002 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0001921551 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 0.0002220192 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 0.0002058917 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0002203765 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 30.580284595489502
Epoch 1/9
	 Logging train Loss: 6.2306e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.32512e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 4.22696e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.74856e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.20302e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 29.551080226898193
Epoch 2/9
	 Logging train Loss: 2.87928e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.89865e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.40705e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.1306e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.37199e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 29.632120609283447
Epoch 3/9
	 Logging train Loss: 1.70348e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.20238e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.49592e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.33457e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.46898e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 29.699125051498413
Epoch 4/9
	 Logging train Loss: 1.32948e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 9.1999e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.53308e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.69622e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.36483e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 29.549569129943848
Epoch 5/9
	 Logging train Loss: 2.00413e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.451e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 7.0872e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 6.7525e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.0704e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 29.758136987686157
Epoch 6/9
	 Logging train Loss: 1.62092e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.0617e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.53868e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.48692e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.35183e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 29.81803798675537
Epoch 7/9
	 Logging train Loss: 1.87626e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.0991e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.04283e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.70528e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.87461e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 29.758546590805054
Epoch 8/9
	 Logging train Loss: 1.64224e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.6182e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.8789e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.7331e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.8553e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 29.423211097717285
Epoch 9/9
	 Logging train Loss: 1.50574e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.2156e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 6.52368e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.27389e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.00564e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 29.819791555404663
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'quat'_'False'.pth
It took  471.1411838531494  seconds.
----- ITERATION 2/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 78.0249400138855 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_full_pNone_gTrue took 19.59584927558899 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pNone_gTrue took 19.62148118019104 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 19.509467840194702 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pNone_gTrue took 19.60197162628174 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: quat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0801842362 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0006016401 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 0.0006290717 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 0.0006150056 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.000627658 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 29.78896141052246
Epoch 1/9
	 Logging train Loss: 0.0001024034 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.2656e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.95971e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.59393e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.93275e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 29.881101369857788
Epoch 2/9
	 Logging train Loss: 2.94377e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.24156e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.52375e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.37689e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.50846e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 29.932167768478394
Epoch 3/9
	 Logging train Loss: 1.9997e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.73655e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 0.0001104569 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 5.9825e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0001020246 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 29.826558113098145
Epoch 4/9
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue â–ˆâ–â–â–‚â–‚â–â–‚â–ƒâ–â–
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue â–ˆâ–â–â–â–â–â–â–â–â–
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue â–ˆâ–â–â–‚â–‚â–â–‚â–„â–â–
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue â–ˆâ–â–â–‚â–‚â–â–‚â–„â–â–
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue 0.0
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue 0.0
wandb:                                 Train loss 2e-05
wandb: 
wandb: ðŸš€ View run denim-firebrand-1157 at: https://wandb.ai/nreints/ThesisFinal2/runs/ytyt65h3
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_232451-ytyt65h3/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_233240-p8lp9711
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run major-leaf-1168
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/p8lp9711
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue â–ˆâ–â–â–â–â–â–â–â–â–
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue â–ˆâ–â–â–â–â–â–â–â–â–
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue â–ˆâ–â–â–â–â–â–â–â–â–
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue â–ˆâ–â–â–â–â–â–â–â–â–
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 1e-05
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue 1e-05
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue 2e-05
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue 2e-05
wandb:                                 Train loss 1e-05
wandb: 
wandb: ðŸš€ View run major-leaf-1168 at: https://wandb.ai/nreints/ThesisFinal2/runs/p8lp9711
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_233240-p8lp9711/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_234024-jbu6chhl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run golden-mountain-1176
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/jbu6chhl
	 Logging train Loss: 2.81308e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.28019e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 0.0001131648 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 5.8409e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0001043107 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 29.966727256774902
Epoch 5/9
	 Logging train Loss: 2.80112e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.9657e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 7.9456e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 7.4295e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.8785e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 29.934244394302368
Epoch 6/9
	 Logging train Loss: 2.78694e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 9.4739e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 0.0001381033 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 7.01089e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.00012945 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 29.936878204345703
Epoch 7/9
	 Logging train Loss: 1.41186e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.34064e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 0.0002859244 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 0.00013823 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0002841541 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 29.77883005142212
Epoch 8/9
	 Logging train Loss: 1.55828e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.2919e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.50301e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 9.8981e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.42566e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 29.847907304763794
Epoch 9/9
	 Logging train Loss: 1.54923e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.1631e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 4.3661e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 4.2574e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.353e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 30.011349201202393
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'quat'_'False'.pth
It took  469.45162320137024  seconds.
----- ITERATION 3/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 75.9755585193634 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_full_pNone_gTrue took 19.473485469818115 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pNone_gTrue took 19.425246715545654 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 19.24994397163391 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pNone_gTrue took 19.477821111679077 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: quat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0969876945 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0004444 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 0.0004692533 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 0.0004548503 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0004674511 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 30.206912994384766
Epoch 1/9
	 Logging train Loss: 7.85516e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.30598e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.64909e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.45214e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.62496e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 29.83444333076477
Epoch 2/9
	 Logging train Loss: 2.09043e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.70224e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.86253e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.77013e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.85197e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 29.845447301864624
Epoch 3/9
	 Logging train Loss: 1.81928e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.1628e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.31925e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.2271e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.3082e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 29.901320934295654
Epoch 4/9
	 Logging train Loss: 1.70151e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.5512e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.13586e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 9.6575e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.11512e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 29.812683582305908
Epoch 5/9
	 Logging train Loss: 2.4594e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.7959e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 7.2729e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 7.0045e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.2502e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 30.123519897460938
Epoch 6/9
	 Logging train Loss: 1.59901e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.0649e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 6.8532e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 6.3876e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.7899e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 29.796340703964233
Epoch 7/9
	 Logging train Loss: 1.86474e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.5791e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 6.3836e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 5.9251e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.3304e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 30.01947784423828
Epoch 8/9
	 Logging train Loss: 1.62778e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.2943e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.13942e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 8.1614e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.11111e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 29.98097062110901
Epoch 9/9
	 Logging train Loss: 1.27864e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.01097e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.59483e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.24309e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.55718e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 29.96464252471924
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'quat'_'False'.pth
It took  464.1224100589752  seconds.
----- ITERATION 4/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 76.46576237678528 seconds.
-- Finished Train Dataloader --
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue â–ˆâ–‚â–‚â–â–â–â–â–â–â–
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue â–ˆâ–‚â–‚â–â–â–â–â–â–â–
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue â–ˆâ–‚â–‚â–â–â–â–â–â–â–
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue â–ˆâ–‚â–‚â–â–â–â–â–â–â–
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 2e-05
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue 2e-05
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue 2e-05
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue 2e-05
wandb:                                 Train loss 1e-05
wandb: 
wandb: ðŸš€ View run golden-mountain-1176 at: https://wandb.ai/nreints/ThesisFinal2/runs/jbu6chhl
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_234024-jbu6chhl/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_234809-h6qs0ubi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run skilled-forest-1186
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/h6qs0ubi
The dataloader for data/data_t(0,0)_r(0,0)_full_pNone_gTrue took 19.47807002067566 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pNone_gTrue took 19.458664417266846 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 19.18560552597046 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pNone_gTrue took 19.479181051254272 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: quat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0770150796 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.000194503 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 0.0002158955 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 0.0002049234 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0002147232 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 30.224562168121338
Epoch 1/9
	 Logging train Loss: 6.11705e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.38208e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.83783e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.61343e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.81474e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 29.512558698654175
Epoch 2/9
	 Logging train Loss: 2.75426e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.97012e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.18966e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.07935e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.17674e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 30.07219409942627
Epoch 3/9
	 Logging train Loss: 1.65292e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.23856e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.35872e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.29966e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.35284e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 30.09972882270813
Epoch 4/9
	 Logging train Loss: 1.26817e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.6058e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 9.3097e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 8.9469e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 9.2525e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 29.882675647735596
Epoch 5/9
	 Logging train Loss: 1.80644e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.1324e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.32229e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.01753e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.29563e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 29.750795125961304
Epoch 6/9
	 Logging train Loss: 2.04627e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.1691e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 7.0904e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 6.6254e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.0304e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 29.703874826431274
Epoch 7/9
	 Logging train Loss: 1.72927e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.5642e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 5.7992e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 5.6831e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.7878e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 29.978052139282227
Epoch 8/9
	 Logging train Loss: 1.79303e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.9483e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 5.0702e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 5.0082e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.0595e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 29.86134910583496
Epoch 9/9
	 Logging train Loss: 1.27702e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.75287e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.76851e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.76023e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.76746e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 29.915035724639893
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'quat'_'False'.pth
It took  464.9661674499512  seconds.
----- ITERATION 5/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 76.02435564994812 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_full_pNone_gTrue took 19.387975454330444 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pNone_gTrue took 19.354889392852783 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 19.13829231262207 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pNone_gTrue took 19.39183807373047 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: quat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0812226757 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0002220766 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 0.0002584239 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 0.0002395285 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0002557893 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 30.012977361679077
Epoch 1/9
	 Logging train Loss: 4.85955e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.87647e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.11413e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.46557e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.03759e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 29.738510847091675
Epoch 2/9
	 Logging train Loss: 1.89514e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.2273e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.67954e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.44479e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.65446e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 29.940696954727173
Epoch 3/9
	 Logging train Loss: 1.12782e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.1703e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 9.8992e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 9.0092e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 9.8163e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 29.8462815284729
Epoch 4/9
	 Logging train Loss: 7.6979e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.323e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 7.2464e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 6.7768e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.2025e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 29.75948214530945
Epoch 5/9
	 Logging train Loss: 1.18296e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.2853e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 1e-05
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue 1e-05
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue 1e-05
wandb:                                 Train loss 2e-05
wandb: 
wandb: ðŸš€ View run skilled-forest-1186 at: https://wandb.ai/nreints/ThesisFinal2/runs/h6qs0ubi
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_234809-h6qs0ubi/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_235554-8y6x6w7d
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run elated-plant-1197
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/8y6x6w7d
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue â–ˆâ–‚â–‚â–â–â–…â–â–â–â–
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue â–ˆâ–‚â–‚â–â–â–â–â–â–â–
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue â–ˆâ–‚â–‚â–â–â–ˆâ–‚â–â–â–
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue â–‡â–‚â–‚â–â–â–ˆâ–‚â–â–â–
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 1e-05
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue 1e-05
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue 1e-05
wandb:                                 Train loss 2e-05
wandb: 
wandb: ðŸš€ View run elated-plant-1197 at: https://wandb.ai/nreints/ThesisFinal2/runs/8y6x6w7d
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_235554-8y6x6w7d/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230710_000337-s288u590
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run exalted-firefly-1205
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/s288u590
	 Logging test loss: 5.9609e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 5.611e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.9262e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 30.05036973953247
Epoch 6/9
	 Logging train Loss: 1.72155e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.6848e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 8.0095e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 6.3175e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.8641e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 30.000569105148315
Epoch 7/9
	 Logging train Loss: 2.32109e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.147e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 5.3946e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 4.757e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.3616e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 29.893244743347168
Epoch 8/9
	 Logging train Loss: 1.19529e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.1581e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 4.4769e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.8142e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.4003e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 30.004711151123047
Epoch 9/9
	 Logging train Loss: 1.58346e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.6669e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 8.8752e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 5.7735e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.6557e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 29.930920839309692
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'quat'_'False'.pth
It took  464.11400628089905  seconds.
----- ITERATION 6/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 75.9453809261322 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_full_pNone_gTrue took 19.36471676826477 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pNone_gTrue took 19.389627695083618 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 19.101438999176025 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pNone_gTrue took 19.334822177886963 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: quat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0910992548 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0001247522 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 0.0001561399 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 0.0001389882 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0001515176 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 29.78450083732605
Epoch 1/9
	 Logging train Loss: 4.63215e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.52797e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.46042e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.95071e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.32987e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 29.888930082321167
Epoch 2/9
	 Logging train Loss: 2.32533e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.18396e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.49567e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.32452e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.44941e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 30.126294374465942
Epoch 3/9
	 Logging train Loss: 1.6267e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.21058e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.34973e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.27382e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.32745e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 29.7903835773468
Epoch 4/9
	 Logging train Loss: 1.51072e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.842e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 9.6086e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 9.1775e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 9.469e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 29.847697257995605
Epoch 5/9
	 Logging train Loss: 1.43243e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.18765e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 0.0001823672 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 8.45528e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0001463047 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 30.006248474121094
Epoch 6/9
	 Logging train Loss: 1.85796e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.6307e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.17221e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.30875e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.86525e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 29.571210622787476
Epoch 7/9
	 Logging train Loss: 1.77041e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.5488e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 5.7877e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 5.6577e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.7578e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 30.08798384666443
Epoch 8/9
	 Logging train Loss: 1.55378e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.935e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 7.0387e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 5.9029e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.6637e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 29.976182222366333
Epoch 9/9
	 Logging train Loss: 1.60364e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.5369e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 8.924e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 6.5514e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.3453e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 29.895716428756714
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'quat'_'False'.pth
It took  463.87956976890564  seconds.
----- ITERATION 7/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 76.5319013595581 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_full_pNone_gTrue took 19.402632236480713 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pNone_gTrue took 19.396540880203247 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 19.26492667198181 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pNone_gTrue took 19.351387977600098 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: quat
-- Started Training --
Epoch 0/9
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue â–ˆâ–â–â–â–â–â–â–â–â–
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue â–ˆâ–â–â–â–â–â–â–â–â–
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue â–ˆâ–â–â–â–â–â–â–â–â–
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue â–ˆâ–â–â–â–â–â–â–â–â–
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 1e-05
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue 1e-05
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue 1e-05
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue 1e-05
wandb:                                 Train loss 1e-05
wandb: 
wandb: ðŸš€ View run exalted-firefly-1205 at: https://wandb.ai/nreints/ThesisFinal2/runs/s288u590
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230710_000337-s288u590/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230710_001124-k0r66jm2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run frosty-water-1215
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/k0r66jm2
	 Logging train Loss: 0.1440458596 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0031697184 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 0.0032414745 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 0.003203471 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0032308949 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 30.158560276031494
Epoch 1/9
	 Logging train Loss: 0.0008299399 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0001420819 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 0.0001657774 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 0.0001531992 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0001623649 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 29.902745485305786
Epoch 2/9
	 Logging train Loss: 8.70655e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.22143e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 6.31678e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 5.72987e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.14967e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 29.924932718276978
Epoch 3/9
	 Logging train Loss: 4.80348e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.71232e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 4.33275e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 4.00105e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.23713e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 29.90541958808899
Epoch 4/9
	 Logging train Loss: 3.26472e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.37674e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.75637e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.55419e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.69873e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 30.10793662071228
Epoch 5/9
	 Logging train Loss: 1.98092e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.35254e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.58065e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.45952e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.5455e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 30.189671754837036
Epoch 6/9
	 Logging train Loss: 1.13365e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.9603e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 9.3097e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 8.5948e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 9.1013e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 29.93779754638672
Epoch 7/9
	 Logging train Loss: 7.9938e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.6555e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 7.469e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 7.0337e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.3375e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 30.107403993606567
Epoch 8/9
	 Logging train Loss: 8.1329e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.9136e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 9.4574e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 9.1641e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 9.371e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 30.109031200408936
Epoch 9/9
	 Logging train Loss: 7.8149e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.3776e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 5.7535e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 5.5512e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.6901e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 30.098727703094482
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'quat'_'False'.pth
It took  466.94122314453125  seconds.
----- ITERATION 8/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 77.09107708930969 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_full_pNone_gTrue took 19.566243410110474 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pNone_gTrue took 19.501137733459473 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 19.42097759246826 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pNone_gTrue took 19.716277360916138 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: quat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0874463916 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0002250198 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 0.0002358889 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 0.0002297029 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0002347349 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 29.938145875930786
Epoch 1/9
	 Logging train Loss: 5.87698e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.11334e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.59628e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.31936e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.54179e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 30.135974407196045
Epoch 2/9
	 Logging train Loss: 2.58007e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.87361e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.09402e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.96852e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.0718e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 29.872223138809204
Epoch 3/9
	 Logging train Loss: 1.55537e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.1539e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.25745e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.19835e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.24699e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 29.820587158203125
Epoch 4/9
	 Logging train Loss: 1.01944e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.9643e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 9.0078e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 8.4125e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.9218e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 29.877726316452026
Epoch 5/9
	 Logging train Loss: 1.82632e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.36317e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 0.0003611545 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 0.0001698668 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0003370508 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 30.063459157943726
Epoch 6/9
	 Logging train Loss: 2.26648e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.3447e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 5.6152e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 5.4628e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue â–ˆâ–‚â–â–â–â–†â–â–â–‚â–
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue â–ˆâ–‚â–â–â–â–‚â–â–â–â–
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue â–†â–‚â–â–â–â–ˆâ–â–â–‚â–
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue â–†â–‚â–â–â–â–ˆâ–â–â–‚â–
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue 0.0
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue 0.0
wandb:                                 Train loss 2e-05
wandb: 
wandb: ðŸš€ View run frosty-water-1215 at: https://wandb.ai/nreints/ThesisFinal2/runs/k0r66jm2
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230710_001124-k0r66jm2/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230710_001911-fyte7ex3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run smooth-lake-1225
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/fyte7ex3
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 1e-05
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue 1e-05
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue 1e-05
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue 1e-05
wandb:                                 Train loss 1e-05
wandb: 
wandb: ðŸš€ View run smooth-lake-1225 at: https://wandb.ai/nreints/ThesisFinal2/runs/fyte7ex3
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230710_001911-fyte7ex3/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230710_002656-1nuovaja
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dark-snow-1233
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/1nuovaja
	 Logging test loss: 5.5946e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 30.007786989212036
Epoch 7/9
	 Logging train Loss: 1.91027e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.9281e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 5.5621e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 5.2062e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.5162e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 29.90637969970703
Epoch 8/9
	 Logging train Loss: 1.38147e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.1944e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 4.26628e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.17067e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.88804e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 29.85072159767151
Epoch 9/9
	 Logging train Loss: 1.68891e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.026e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 4.0974e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 4.0561e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.0906e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 29.744117498397827
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'quat'_'False'.pth
It took  466.8379764556885  seconds.
----- ITERATION 9/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 78.08228874206543 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_full_pNone_gTrue took 19.560468196868896 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pNone_gTrue took 19.53138303756714 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 19.461854457855225 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pNone_gTrue took 19.60096001625061 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: quat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0864114165 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0003008268 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 0.0003252513 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 0.0003138418 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0003253886 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 29.7424898147583
Epoch 1/9
	 Logging train Loss: 6.88412e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.33322e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.65436e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.50751e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.66136e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 29.728814125061035
Epoch 2/9
	 Logging train Loss: 2.90934e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.30545e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.50938e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.41742e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.51276e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 29.56295156478882
Epoch 3/9
	 Logging train Loss: 2.84784e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.63012e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.7683e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.7041e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.76871e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 29.77884602546692
Epoch 4/9
	 Logging train Loss: 2.55028e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.16568e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.25717e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.21414e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.25803e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 29.546076774597168
Epoch 5/9
	 Logging train Loss: 3.84205e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 9.3317e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.06681e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.00647e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.06918e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 29.89206075668335
Epoch 6/9
	 Logging train Loss: 1.13222e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.0736e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.12128e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 9.8046e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.12425e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 29.456637144088745
Epoch 7/9
	 Logging train Loss: 2.98866e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.2376e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 7.3888e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 7.3183e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.3868e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 29.68785285949707
Epoch 8/9
	 Logging train Loss: 9.3626e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.3165e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 6.4537e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 6.3918e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.457e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 29.920799732208252
Epoch 9/9
	 Logging train Loss: 1.21259e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.4141e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 5.5261e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 5.4763e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.527e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 29.861019611358643
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'quat'_'False'.pth
It took  465.1089553833008  seconds.
----- ITERATION 10/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 76.0558922290802 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_full_pNone_gTrue took 19.450929164886475 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pNone_gTrue took 19.42598795890808 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 19.151025772094727 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pNone_gTrue took 19.482316732406616 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: quat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0865746662 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0002488369 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 0.0002777238 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 0.0002621317 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.000276179 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 29.785064697265625
Epoch 1/9
	 Logging train Loss: 5.46076e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.30135e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 1e-05
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue 1e-05
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue 1e-05
wandb:                                 Train loss 2e-05
wandb: 
wandb: ðŸš€ View run dark-snow-1233 at: https://wandb.ai/nreints/ThesisFinal2/runs/1nuovaja
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230710_002656-1nuovaja/logs
	 Logging test loss: 2.82539e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.54461e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.79403e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 29.961769580841064
Epoch 2/9
	 Logging train Loss: 2.08285e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.56298e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.78369e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.66733e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.77002e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 29.730505228042603
Epoch 3/9
	 Logging train Loss: 1.39909e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.15438e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.29164e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.21832e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.28125e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 29.859230756759644
Epoch 4/9
	 Logging train Loss: 1.03933e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.6557e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 9.9883e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 9.2626e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 9.8608e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 29.787923574447632
Epoch 5/9
	 Logging train Loss: 2.50854e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.4447e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 7.933e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 7.6701e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.9027e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 29.973617792129517
Epoch 6/9
	 Logging train Loss: 1.91181e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.6165e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 9.9495e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 8.1351e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 9.5484e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 29.97160315513611
Epoch 7/9
	 Logging train Loss: 2.39832e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.5968e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 6.7746e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 6.1576e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.7628e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 29.936192750930786
Epoch 8/9
	 Logging train Loss: 1.6546e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.4345e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 7.888e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 6.6214e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.8637e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 29.933300733566284
Epoch 9/9
	 Logging train Loss: 1.75813e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.9199e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.05113e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 7.4963e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 9.9578e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 30.24874234199524
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'quat'_'False'.pth
It took  464.97746205329895  seconds.

JOB STATISTICS
==============
Job ID: 3039253
Array Job ID: 3039249_28
Cluster: snellius
User/Group: nreints/nreints
State: RUNNING
Nodes: 1
Cores per node: 18
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 23:23:06 core-walltime
Job Wall-clock time: 01:17:57
Memory Utilized: 0.00 MB (estimated maximum)
Memory Efficiency: 0.00% of 0.00 MB (0.00 MB/node)
WARNING: Efficiency statistics may be misleading for RUNNING jobs.
