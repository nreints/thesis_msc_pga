wandb: Currently logged in as: nreints. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_211344-cthwj32d
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run zany-rain-454
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/cthwj32d
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gTrue █▂▂▁▁▃▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gTrue █▂▁▁▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gTrue █▂▂▁▁▄▂▁▂▁
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gTrue █▂▂▁▁▄▂▁▂▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gTrue 0.0
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gTrue 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: 🚀 View run zany-rain-454 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/cthwj32d
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_211344-cthwj32d/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_212107-8p5avxao
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cosmic-cosmos-469
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/8p5avxao
Training on dataset: data_t(5,20)_r(0,0)_combi_pNone_gTrue
Testing on 4 datasets: ['data_t(5,20)_r(0,0)_combi_pNone_gTrue', 'data_t(5,20)_r(0,0)_full_pNone_gTrue', 'data_t(5,20)_r(0,0)_tennis_pNone_gTrue', 'data_t(5,20)_r(0,0)_semi_pNone_gTrue']
Focussing on identity: True
Using extra input: False
Using fr-fr as reference point.
----- ITERATION 1/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gTrue took 51.29083967208862 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gTrue took 12.836738348007202 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_full_pNone_gTrue took 12.749667406082153 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_tennis_pNone_gTrue took 12.83981704711914 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_semi_pNone_gTrue took 12.87999176979065 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0003078327 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.83663e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.84794e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.81093e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.84742e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 34.099817514419556
Epoch 1/9
	 Logging train Loss: 1.27312e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.3523e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.2501e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 4.4142e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 4.4881e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 32.34641361236572
Epoch 2/9
	 Logging train Loss: 3.864e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.8896e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.1385e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.4039e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.5105e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 32.48410654067993
Epoch 3/9
	 Logging train Loss: 3.0755e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.3442e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.3105e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.3489e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.3539e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 32.26785922050476
Epoch 4/9
	 Logging train Loss: 4.3232e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.928e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.794e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 7.87e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 7.987e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 32.57692909240723
Epoch 5/9
	 Logging train Loss: 1.7827e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.5043e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.494e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.07116e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.15532e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 32.54354906082153
Epoch 6/9
	 Logging train Loss: 1.7233e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.1918e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.42e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.3755e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.6096e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 32.659576416015625
Epoch 7/9
	 Logging train Loss: 1.55e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.106e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.996e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.857e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 4.104e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 32.61223077774048
Epoch 8/9
	 Logging train Loss: 1.1837e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.5658e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.585e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.263e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.4068e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 32.26198148727417
Epoch 9/9
	 Logging train Loss: 1.0321e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.499e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.459e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.485e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.546e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 32.74423623085022
Saved model in  trained_models/gru/data_t(5,20)_r(0,0)_combi_pNone_gTrue/'dual_quat_1'_'False'.pth
It took  444.0478732585907  seconds.
----- ITERATION 2/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gTrue took 47.271742820739746 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gTrue took 11.784501075744629 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_full_pNone_gTrue took 11.963517665863037 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_tennis_pNone_gTrue took 11.937491178512573 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_semi_pNone_gTrue took 11.91999864578247 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.000140571 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 9.2098e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 9.1427e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 9.9519e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 9.0232e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 32.92161822319031
Epoch 1/9
	 Logging train Loss: 5.2497e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.9964e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.0646e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.1059e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.9755e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 32.77241897583008
Epoch 2/9
	 Logging train Loss: 3.2825e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 9.496e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 9.761e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.0076e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 9.346e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 32.82018065452576
Epoch 3/9
	 Logging train Loss: 2.144e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.5496e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.0946e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.1131e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.0703e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 32.61778664588928
Epoch 4/9
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gTrue ▆▂▁▂▁▇▁█▂▁
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gTrue █▂▂▂▁▂▁▂▂▁
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gTrue ▄▂▁▂▁▇▁█▂▁
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gTrue ▄▂▁▂▁▇▁█▂▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gTrue 0.0
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gTrue 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: 🚀 View run cosmic-cosmos-469 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/8p5avxao
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_212107-8p5avxao/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_212823-8x4v5bod
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run zany-cloud-479
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/8x4v5bod
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gTrue █▂▁▂▂▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gTrue █▂▁▂▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gTrue █▂▁▃▂▁▁▁▁▁
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gTrue █▂▁▃▂▁▂▁▁▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gTrue 0.0
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gTrue 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: 🚀 View run zany-cloud-479 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/8x4v5bod
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_212823-8x4v5bod/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_213541-o2qjaa37
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run polar-sea-487
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/o2qjaa37
	 Logging train Loss: 1.8217e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.949e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.667e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.457e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.263e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 32.65563702583313
Epoch 5/9
	 Logging train Loss: 1.3487e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.06143e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.9313e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.04621e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.91268e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 32.77584910392761
Epoch 6/9
	 Logging train Loss: 1.1315e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.814e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.723e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.925e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.881e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 32.83484196662903
Epoch 7/9
	 Logging train Loss: 1.0419e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.18142e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.12e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.41988e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.24933e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 32.84727072715759
Epoch 8/9
	 Logging train Loss: 9.228e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.3554e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.0636e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.7886e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.8056e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 32.90439462661743
Epoch 9/9
	 Logging train Loss: 7.114e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.485e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.109e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.918e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.835e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 32.990983724594116
Saved model in  trained_models/gru/data_t(5,20)_r(0,0)_combi_pNone_gTrue/'dual_quat_1'_'False'.pth
It took  436.00942635536194  seconds.
----- ITERATION 3/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gTrue took 45.56661248207092 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gTrue took 11.571101665496826 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_full_pNone_gTrue took 11.807363748550415 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_tennis_pNone_gTrue took 11.802098512649536 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_semi_pNone_gTrue took 11.802217960357666 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0004223408 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.79717e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.68796e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.77743e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.81761e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 32.654399394989014
Epoch 1/9
	 Logging train Loss: 1.8544e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.0006e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.7757e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 7.0782e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 7.0499e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 32.7712299823761
Epoch 2/9
	 Logging train Loss: 4.3122e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.58e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.5137e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.5425e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.5784e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 32.67171096801758
Epoch 3/9
	 Logging train Loss: 3.6613e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.5277e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.9901e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 9.9877e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 9.6918e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 32.6104257106781
Epoch 4/9
	 Logging train Loss: 3.3496e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.409e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.7588e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 6.6204e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 6.6936e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 32.65574669837952
Epoch 5/9
	 Logging train Loss: 2.2492e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.0264e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.026e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.3657e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.3693e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 32.965277910232544
Epoch 6/9
	 Logging train Loss: 2.4606e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.2533e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.5514e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.0278e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.8767e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 32.92576217651367
Epoch 7/9
	 Logging train Loss: 1.2724e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.182e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.097e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.244e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.296e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 32.77539134025574
Epoch 8/9
	 Logging train Loss: 1.5008e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.916e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.792e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.037e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.074e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 32.62454152107239
Epoch 9/9
	 Logging train Loss: 1.4144e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.645e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.602e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.708e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.768e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 32.6948139667511
Saved model in  trained_models/gru/data_t(5,20)_r(0,0)_combi_pNone_gTrue/'dual_quat_1'_'False'.pth
It took  437.57933378219604  seconds.
----- ITERATION 4/10 ------
Number of train simulations:  1920
Number of test simulations:  480
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gTrue █▂▂▁▁▁▁▂▁▁
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gTrue █▂▂▁▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gTrue █▂▂▁▁▁▁▂▁▁
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gTrue █▂▂▁▁▁▁▂▁▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gTrue 0.0
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gTrue 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: 🚀 View run polar-sea-487 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/o2qjaa37
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_213541-o2qjaa37/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_214255-ndtiagkr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fiery-dust-497
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/ndtiagkr
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gTrue took 45.951831102371216 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gTrue took 11.545466661453247 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_full_pNone_gTrue took 11.772871017456055 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_tennis_pNone_gTrue took 11.820152044296265 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_semi_pNone_gTrue took 11.835748672485352 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0004355474 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.46758e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.5122e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.58837e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.4995e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 32.72200322151184
Epoch 1/9
	 Logging train Loss: 1.03336e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.2919e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.2955e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.5043e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.3764e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 32.52989721298218
Epoch 2/9
	 Logging train Loss: 2.759e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.3436e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.2981e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.5285e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.4443e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 33.11406874656677
Epoch 3/9
	 Logging train Loss: 2.3792e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.2405e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.2457e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.3209e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.2687e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 33.0160813331604
Epoch 4/9
	 Logging train Loss: 2.3075e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 9.082e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.84e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.1008e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.048e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 32.46954107284546
Epoch 5/9
	 Logging train Loss: 1.6804e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.03e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.854e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 4.36e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 4.234e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 32.830568075180054
Epoch 6/9
	 Logging train Loss: 1.5842e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.687e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.389e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 4.014e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.941e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 32.72020959854126
Epoch 7/9
	 Logging train Loss: 1.7766e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.4908e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.3964e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.6123e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.5084e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 32.52203679084778
Epoch 8/9
	 Logging train Loss: 9.759e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.456e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.776e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.204e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.123e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 32.634620904922485
Epoch 9/9
	 Logging train Loss: 1.1316e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.766e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.943e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.814e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.797e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 32.91656804084778
Saved model in  trained_models/gru/data_t(5,20)_r(0,0)_combi_pNone_gTrue/'dual_quat_1'_'False'.pth
It took  434.08308458328247  seconds.
----- ITERATION 5/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gTrue took 45.91978335380554 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gTrue took 11.450481176376343 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_full_pNone_gTrue took 11.73534870147705 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_tennis_pNone_gTrue took 11.751833438873291 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_semi_pNone_gTrue took 11.735185384750366 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0004169056 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.202e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.25198e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.26639e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.18579e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 32.92755174636841
Epoch 1/9
	 Logging train Loss: 1.25603e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.4749e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.4707e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.5342e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.4263e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 32.3957953453064
Epoch 2/9
	 Logging train Loss: 2.8758e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.1149e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.1154e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.1314e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.0716e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 32.39410614967346
Epoch 3/9
	 Logging train Loss: 2.5854e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.5613e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.5634e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.48026e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.35276e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 32.21887469291687
Epoch 4/9
	 Logging train Loss: 2.0052e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.93621e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.0585e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 6.21026e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 5.64387e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 31.98459529876709
Epoch 5/9
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gTrue █▂▁▃▇▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gTrue █▂▁▁▂▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gTrue ▅▁▁▃█▁▁▁▁▁
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gTrue ▅▁▁▃█▁▁▁▁▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gTrue 0.0
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gTrue 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: 🚀 View run fiery-dust-497 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/ndtiagkr
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_214255-ndtiagkr/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_215002-g97emwas
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run light-donkey-507
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/g97emwas
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gTrue █▂▂▅▁▂▁▁▁▂
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gTrue █▂▂▃▁▁▁▁▁▂
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gTrue █▂▁▇▁▂▁▂▁▂
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gTrue █▂▂▇▁▂▁▁▁▂
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gTrue 0.0
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gTrue 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: 🚀 View run light-donkey-507 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/g97emwas
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_215002-g97emwas/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_215708-tzhlgden
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run treasured-paper-515
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/tzhlgden
	 Logging train Loss: 2.3515e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.742e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.701e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.805e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.773e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 31.96363854408264
Epoch 6/9
	 Logging train Loss: 2.3584e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.704e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.471e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 5.159e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 4.653e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 32.15464186668396
Epoch 7/9
	 Logging train Loss: 7.225e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 9.311e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.604e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.005e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 9.963e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 32.21196222305298
Epoch 8/9
	 Logging train Loss: 1.2317e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.9e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.418e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.509e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.365e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 31.83312153816223
Epoch 9/9
	 Logging train Loss: 1.1813e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.875e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.861e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.896e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.898e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 32.14669990539551
Saved model in  trained_models/gru/data_t(5,20)_r(0,0)_combi_pNone_gTrue/'dual_quat_1'_'False'.pth
It took  426.7151527404785  seconds.
----- ITERATION 6/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gTrue took 45.52381181716919 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gTrue took 11.418252944946289 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_full_pNone_gTrue took 11.756677627563477 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_tennis_pNone_gTrue took 11.749024152755737 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_semi_pNone_gTrue took 11.782164573669434 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.000371941 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 9.4286e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.8767e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.02423e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 9.7171e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 31.95480227470398
Epoch 1/9
	 Logging train Loss: 3.5275e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.9638e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.9247e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.0657e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.9499e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 32.11801481246948
Epoch 2/9
	 Logging train Loss: 1.7092e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.0061e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 9.574e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.0883e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.016e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 32.02479362487793
Epoch 3/9
	 Logging train Loss: 1.317e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.333e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.3944e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 8.4343e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 8.0598e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 31.94248342514038
Epoch 4/9
	 Logging train Loss: 1.5211e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.44e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.101e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.761e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.52e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 32.23368859291077
Epoch 5/9
	 Logging train Loss: 1.3178e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.0466e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.347e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.7051e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.6965e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 32.18531250953674
Epoch 6/9
	 Logging train Loss: 1.4037e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.438e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.646e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 9.181e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 9.024e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 31.976144790649414
Epoch 7/9
	 Logging train Loss: 1.4709e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.272e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.646e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.0807e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.0745e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 31.904335498809814
Epoch 8/9
	 Logging train Loss: 1.2668e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.512e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.344e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 6.611e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 6.544e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 32.09524965286255
Epoch 9/9
	 Logging train Loss: 1.0068e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.3743e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.1424e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.6275e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.6119e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 32.12435293197632
Saved model in  trained_models/gru/data_t(5,20)_r(0,0)_combi_pNone_gTrue/'dual_quat_1'_'False'.pth
It took  426.0211589336395  seconds.
----- ITERATION 7/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gTrue took 45.70233178138733 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gTrue took 11.48346471786499 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_full_pNone_gTrue took 11.725813865661621 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_tennis_pNone_gTrue took 11.723918914794922 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_semi_pNone_gTrue took 11.756863594055176 seconds.
-- Finished Test Dataloader(s) --
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gTrue █▂▁▁▁▁▄▁▄▁
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gTrue █▂▁▁▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gTrue █▂▁▁▁▁▇▁▆▁
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gTrue █▂▁▁▁▁▆▁▅▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gTrue 0.0
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gTrue 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: 🚀 View run treasured-paper-515 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/tzhlgden
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_215708-tzhlgden/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_220414-9ep7gbn0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run restful-frost-525
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/9ep7gbn0
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0003712412 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.19883e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.31335e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.3265e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.2093e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 32.01345777511597
Epoch 1/9
	 Logging train Loss: 7.6862e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.5811e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.6748e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.6914e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.5576e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 32.08780765533447
Epoch 2/9
	 Logging train Loss: 2.4545e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.4901e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.5432e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.5672e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.4856e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 32.043018102645874
Epoch 3/9
	 Logging train Loss: 2.2543e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.059e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.232e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 8.611e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 8.151e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 31.802404403686523
Epoch 4/9
	 Logging train Loss: 2.6903e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.3e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.291e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 4.622e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 4.391e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 32.36121845245361
Epoch 5/9
	 Logging train Loss: 1.4001e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.687e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.571e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.913e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.821e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 32.10096836090088
Epoch 6/9
	 Logging train Loss: 1.9029e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 9.8221e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.0523e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.62018e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.7461e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 32.048259019851685
Epoch 7/9
	 Logging train Loss: 1.7846e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.76e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.677e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.82e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.778e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 32.04782223701477
Epoch 8/9
	 Logging train Loss: 1.2774e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.271e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.3408e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.35621e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.48213e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 32.00540256500244
Epoch 9/9
	 Logging train Loss: 1.3007e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.668e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.547e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.782e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.741e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 31.95756721496582
Saved model in  trained_models/gru/data_t(5,20)_r(0,0)_combi_pNone_gTrue/'dual_quat_1'_'False'.pth
It took  426.02516984939575  seconds.
----- ITERATION 8/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gTrue took 45.56748008728027 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gTrue took 11.4976327419281 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_full_pNone_gTrue took 11.756046533584595 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_tennis_pNone_gTrue took 11.729547500610352 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_semi_pNone_gTrue took 11.7586088180542 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0003979112 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.03121e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.15209e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.118e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.16957e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 32.16218829154968
Epoch 1/9
	 Logging train Loss: 1.304e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.7832e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.7834e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 4.0688e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 4.057e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 32.18269348144531
Epoch 2/9
	 Logging train Loss: 2.7269e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.24492e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.134e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.24009e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.08407e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 32.192102670669556
Epoch 3/9
	 Logging train Loss: 2.6918e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.2395e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.2205e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.329e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.3406e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 31.73172903060913
Epoch 4/9
	 Logging train Loss: 2.5163e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.1384e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.934e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 7.5729e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 7.5559e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 32.041812896728516
Epoch 5/9
	 Logging train Loss: 2.8151e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.649e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.594e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.853e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.999e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 32.314550161361694
Epoch 6/9
	 Logging train Loss: 2.0564e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.387e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gTrue █▂▄▁▂▁▁▁▁▂
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gTrue █▂▂▁▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gTrue █▂▆▁▃▁▁▁▁▂
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gTrue █▂▆▁▃▁▁▁▁▂
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gTrue 1e-05
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gTrue 1e-05
wandb:                                  Train loss 0.0
wandb: 
wandb: 🚀 View run restful-frost-525 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/9ep7gbn0
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_220414-9ep7gbn0/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_221120-yjubcenh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run devout-microwave-536
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/yjubcenh
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gTrue █▂▁▂▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gTrue █▂▁▁▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gTrue █▃▁▂▁▁▁▁▁▁
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gTrue █▃▁▂▁▁▁▁▁▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gTrue 0.0
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gTrue 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: 🚀 View run devout-microwave-536 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/yjubcenh
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_221120-yjubcenh/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_221828-98p5itj6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run tough-flower-543
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/98p5itj6
	 Logging test loss: 2.344e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.497e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.57e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 32.1969940662384
Epoch 7/9
	 Logging train Loss: 2.1193e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.932e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.115e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 8.803e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 8.742e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 32.098961353302
Epoch 8/9
	 Logging train Loss: 1.4601e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.28e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.841e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 4.726e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 4.674e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 32.09760046005249
Epoch 9/9
	 Logging train Loss: 1.3204e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.7229e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.944e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 6.8165e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 6.5296e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 31.943400382995605
Saved model in  trained_models/gru/data_t(5,20)_r(0,0)_combi_pNone_gTrue/'dual_quat_1'_'False'.pth
It took  425.9281475543976  seconds.
----- ITERATION 9/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gTrue took 47.47096109390259 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gTrue took 11.819146394729614 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_full_pNone_gTrue took 11.883780002593994 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_tennis_pNone_gTrue took 11.890437602996826 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_semi_pNone_gTrue took 11.958868265151978 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0007994559 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.9933e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.06601e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 5.22564e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 5.17244e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 31.81480097770691
Epoch 1/9
	 Logging train Loss: 3.02821e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.06601e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.0802e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.15772e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.13185e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 31.895053148269653
Epoch 2/9
	 Logging train Loss: 5.1439e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.6463e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.6238e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.8372e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.8129e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 31.813539266586304
Epoch 3/9
	 Logging train Loss: 2.4523e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.2459e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.8863e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 7.6212e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 7.871e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 32.06575107574463
Epoch 4/9
	 Logging train Loss: 2.8519e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.5056e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.2463e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.8281e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.8545e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 32.198145627975464
Epoch 5/9
	 Logging train Loss: 2.9192e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.308e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.104e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 7.915e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 7.926e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 32.107036113739014
Epoch 6/9
	 Logging train Loss: 2.7326e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.239e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.076e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 4.563e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 4.586e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 31.748457670211792
Epoch 7/9
	 Logging train Loss: 1.8491e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.655e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.502e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.834e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.859e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 31.95117974281311
Epoch 8/9
	 Logging train Loss: 1.7853e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.442e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.395e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.0183e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.073e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 32.035629749298096
Epoch 9/9
	 Logging train Loss: 1.6139e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.157e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.965e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.307e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.329e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 31.99605679512024
Saved model in  trained_models/gru/data_t(5,20)_r(0,0)_combi_pNone_gTrue/'dual_quat_1'_'False'.pth
It took  427.9698164463043  seconds.
----- ITERATION 10/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gTrue took 47.31003284454346 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gTrue took 11.857383728027344 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_full_pNone_gTrue took 11.904420137405396 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_tennis_pNone_gTrue took 11.966116428375244 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_semi_pNone_gTrue took 11.952952861785889 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0002835343 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.04612e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.01291e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.14724e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.98907e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gTrue █▂▂▁▁▁▁▁▁▃
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gTrue █▂▂▁▁▁▁▁▁▂
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gTrue █▂▂▁▁▁▁▁▁▄
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gTrue █▂▂▁▁▁▁▁▁▃
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gTrue 1e-05
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gTrue 1e-05
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gTrue 1e-05
wandb:                                  Train loss 0.0
wandb: 
wandb: 🚀 View run tough-flower-543 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/98p5itj6
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_221828-98p5itj6/logs
		--> Epoch time; 32.02952837944031
Epoch 1/9
	 Logging train Loss: 7.3019e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.7769e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.7688e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.9298e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.6986e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 32.225794076919556
Epoch 2/9
	 Logging train Loss: 3.1468e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.0668e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.0407e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 4.128e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 4.0057e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 31.989312648773193
Epoch 3/9
	 Logging train Loss: 3.4749e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.2036e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.1982e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.2418e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.1617e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 32.22066402435303
Epoch 4/9
	 Logging train Loss: 3.0651e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.391e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.155e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 6.806e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 6.455e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 32.28872752189636
Epoch 5/9
	 Logging train Loss: 2.2765e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.081e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.988e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.207e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.082e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 32.236061334609985
Epoch 6/9
	 Logging train Loss: 1.8474e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.343e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.016e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.726e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.739e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 32.147825717926025
Epoch 7/9
	 Logging train Loss: 1.5919e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.226e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.126e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 4.267e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 4.294e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 32.20418047904968
Epoch 8/9
	 Logging train Loss: 1.4257e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.035e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.053e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 4.467e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 4.416e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 32.00754427909851
Epoch 9/9
	 Logging train Loss: 1.1395e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.0042e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.1036e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 7.7001e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 7.7552e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 32.11418318748474
Saved model in  trained_models/gru/data_t(5,20)_r(0,0)_combi_pNone_gTrue/'dual_quat_1'_'False'.pth
It took  429.1931617259979  seconds.

JOB STATISTICS
==============
Job ID: 3086315
Array Job ID: 3086289_67
Cluster: snellius
User/Group: nreints/nreints
State: COMPLETED (exit code 0)
Nodes: 1
Cores per node: 18
CPU Utilized: 01:20:03
CPU Efficiency: 6.17% of 21:38:06 core-walltime
Job Wall-clock time: 01:12:07
Memory Utilized: 7.96 GB
Memory Efficiency: 0.00% of 0.00 MB
