wandb: Currently logged in as: nreints. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home/nreints/.netrc
/gpfs/home2/nreints/MScThesis/code/fcnn.py:566: DeprecationWarning: Sampling from a set deprecated
since Python 3.9 and will be removed in a subsequent version.
  train_sims = set(random.sample(sims_train, int(0.8 * n_sims_train)))
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230330_123651-zrvhbq9g
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run polar-waterfall-590
wandb: â­ï¸ View project at https://wandb.ai/nreints/test
wandb: ðŸš€ View run at https://wandb.ai/nreints/test/runs/zrvhbq9g
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.029 MB of 0.029 MB uploaded (0.000 MB deduped)wandb: \ 0.029 MB of 0.078 MB uploaded (0.000 MB deduped)wandb: | 0.057 MB of 0.078 MB uploaded (0.000 MB deduped)wandb: / 0.057 MB of 0.078 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  Test loss t(0, 0)_r(5, 20)_tennis L1Loss() â–ˆâ–„â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–
wandb: Test loss t(0, 0)_r(5, 20)_tennis MSELoss() â–ˆâ–ƒâ–ƒâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:     Train loss data_t(0, 0)_r(5, 20)_tennis â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:  Test loss t(0, 0)_r(5, 20)_tennis L1Loss() 0.84893
wandb: Test loss t(0, 0)_r(5, 20)_tennis MSELoss() 2.09508
wandb:     Train loss data_t(0, 0)_r(5, 20)_tennis 1.97113
wandb: 
wandb: ðŸš€ View run polar-waterfall-590 at: https://wandb.ai/nreints/test/runs/zrvhbq9g
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230330_123651-zrvhbq9g/logs
/gpfs/home2/nreints/MScThesis/code/fcnn.py:566: DeprecationWarning: Sampling from a set deprecated
since Python 3.9 and will be removed in a subsequent version.
  train_sims = set(random.sample(sims_train, int(0.8 * n_sims_train)))
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230330_124943-94eeqgaf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sparkling-sky-641
wandb: â­ï¸ View project at https://wandb.ai/nreints/test
wandb: ðŸš€ View run at https://wandb.ai/nreints/test/runs/94eeqgaf
Training on dataset: data/data_t(0, 0)_r(5, 20)_tennis_pNone_gNone
Testing on datasets: ['data_t(0, 0)_r(5, 20)_tennis_pNone_gNone']
----- ITERATION 1/2 ------
Number of train simulations: 1600
Number of test simulations: 400
The dataloader took 60.49449419975281 seconds.
-- Finished Train Dataloader --
The dataloader took 14.771108150482178 seconds.
-- Finished Test Dataloader(s) --
Datatype: log_dualQ
--- Started Training ---
Epoch 0
	 Logging train Loss: 292.7039011438 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 39.441795349121094 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 3.6675913333892822 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 35.001720666885376
Epoch 1
	 Logging train Loss: 21.964379085 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 15.180973052978516 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 2.127530813217163 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 34.81882286071777
Epoch 2
	 Logging train Loss: 12.1427019506 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 10.508368492126465 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 1.7446337938308716 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 34.64322209358215
Epoch 3
	 Logging train Loss: 8.7726179534 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 7.964859485626221 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 1.4993144273757935 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 34.46024131774902
Epoch 4
	 Logging train Loss: 6.812347452 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 6.371964931488037 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 1.3493478298187256 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 34.396743059158325
Epoch 5
	 Logging train Loss: 5.5331233405 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 5.336915016174316 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 1.241468906402588 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 35.03849673271179
Epoch 6
	 Logging train Loss: 4.6962999132 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 4.570032119750977 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 1.1601576805114746 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 35.21613574028015
Epoch 7
	 Logging train Loss: 4.1006590201 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 3.987473726272583 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 1.0920110940933228 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 34.98206686973572
Epoch 8
	 Logging train Loss: 3.6666682624 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 3.6591796875 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 1.061882734298706 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 34.72586178779602
Epoch 9
	 Logging train Loss: 3.3287316815 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 3.316128730773926 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 1.0192586183547974 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 32.925944089889526
Epoch 10
	 Logging train Loss: 3.0669376149 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 2.986513614654541 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.9714601635932922 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 33.2307448387146
Epoch 11
	 Logging train Loss: 2.85535769 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 3.041855812072754 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 1.003698706626892 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 32.8482346534729
Epoch 12
	 Logging train Loss: 2.6762869243 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 2.67155122756958 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.9305386543273926 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 32.585325956344604
Epoch 13
	 Logging train Loss: 2.5296605328 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 2.6030116081237793 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.9251382350921631 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 34.70205497741699
Epoch 14
	 Logging train Loss: 2.4069972618 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 2.4321212768554688 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.8972964882850647 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 33.353989124298096
Epoch 15
	 Logging train Loss: 2.2986031327 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 2.3284409046173096 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.8805577158927917 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 33.072885513305664
Epoch 16
	 Logging train Loss: 2.2037768395 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 2.16774320602417 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.8459572196006775 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 33.28439450263977
Epoch 17
	 Logging train Loss: 2.1194878472 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 2.099990129470825 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.8366885781288147 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 33.21663761138916
Epoch 18
	 Logging train Loss: 2.04189868 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 2.1246752738952637 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.8514561057090759 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 33.75083041191101
Epoch 19
	 Logging train Loss: 1.9711328444 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 2.095144748687744 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.8488900065422058 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 34.69484043121338
	 Logging test loss 2.0950818061828613 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.8489338159561157 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
It took 772.4082412719727 seconds to train & eval the model.
----- ITERATION 2/2 ------
Number of train simulations: 1600
Number of test simulations: 400
The dataloader took 54.388314723968506 seconds.
-- Finished Train Dataloader --
The dataloader took 13.543953895568848 seconds.
-- Finished Test Dataloader(s) --
Datatype: log_dualQ
--- Started Training ---
Epoch 0
	 Logging train Loss: 326.0323120915 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 57.04289245605469 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 4.657516002655029 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 34.770373821258545
Epoch 1
	 Logging train Loss: 25.8190767974 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 17.819047927856445 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 2.3801815509796143 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 33.5904438495636
Epoch 2
	 Logging train Loss: 13.1976256127 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 11.843321800231934 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 1.883360743522644 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 33.23998236656189
Epoch 3
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.029 MB of 0.078 MB uploaded (0.000 MB deduped)wandb: \ 0.078 MB of 0.078 MB uploaded (0.000 MB deduped)wandb: | 0.078 MB of 0.078 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  Test loss t(0, 0)_r(5, 20)_tennis L1Loss() â–ˆâ–„â–ƒâ–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: Test loss t(0, 0)_r(5, 20)_tennis MSELoss() â–ˆâ–ƒâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:     Train loss data_t(0, 0)_r(5, 20)_tennis â–ˆâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:  Test loss t(0, 0)_r(5, 20)_tennis L1Loss() 0.83863
wandb: Test loss t(0, 0)_r(5, 20)_tennis MSELoss() 2.04691
wandb:     Train loss data_t(0, 0)_r(5, 20)_tennis 1.87666
wandb: 
wandb: ðŸš€ View run sparkling-sky-641 at: https://wandb.ai/nreints/test/runs/94eeqgaf
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230330_124943-94eeqgaf/logs
	 Logging train Loss: 9.3809480954 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 8.840269088745117 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 1.6224417686462402 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 32.9509174823761
Epoch 4
	 Logging train Loss: 7.2034058415 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 6.979613304138184 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 1.4349043369293213 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 35.1928346157074
Epoch 5
	 Logging train Loss: 5.7991319444 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 5.904646396636963 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 1.3497787714004517 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 34.79781413078308
Epoch 6
	 Logging train Loss: 4.8375788271 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 4.93257999420166 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 1.2274380922317505 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 34.75659203529358
Epoch 7
	 Logging train Loss: 4.1710436453 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 4.243939399719238 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 1.1401418447494507 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 33.05992555618286
Epoch 8
	 Logging train Loss: 3.6805695976 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 3.8648650646209717 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 1.1022977828979492 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 33.040948152542114
Epoch 9
	 Logging train Loss: 3.3258623111 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 3.500394821166992 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 1.0585722923278809 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 33.21196126937866
Epoch 10
	 Logging train Loss: 3.0359154795 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 3.162642478942871 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 1.0065101385116577 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 32.72869253158569
Epoch 11
	 Logging train Loss: 2.8049099392 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 3.02067232131958 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.9985635280609131 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 34.865885972976685
Epoch 12
	 Logging train Loss: 2.6173556858 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 2.8516011238098145 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.9770105481147766 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 34.13792848587036
Epoch 13
	 Logging train Loss: 2.4602953942 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 2.6670875549316406 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.9483762979507446 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 33.21485185623169
Epoch 14
	 Logging train Loss: 2.3298170701 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 2.5896122455596924 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.9455611109733582 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 33.293323278427124
Epoch 15
	 Logging train Loss: 2.2139822368 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 2.3855137825012207 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.8971567749977112 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 32.931710958480835
Epoch 16
	 Logging train Loss: 2.1143221188 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 2.27695369720459 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.8807929754257202 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 35.02190828323364
Epoch 17
	 Logging train Loss: 2.0307376238 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 2.206305980682373 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.8680239915847778 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 34.774001359939575
Epoch 18
	 Logging train Loss: 1.9464783114 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 2.2025763988494873 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.8773496150970459 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 34.94417190551758
Epoch 19
	 Logging train Loss: 1.8766614328 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 2.047841787338257 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.8386768102645874 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 33.27251148223877
	 Logging test loss 2.046905994415283 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.8386338949203491 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
It took 760.9156384468079 seconds to train & eval the model.

JOB STATISTICS
==============
Job ID: 2523388
Array Job ID: 2523368_20
Cluster: snellius
User/Group: nreints/nreints
State: COMPLETED (exit code 0)
Nodes: 1
Cores per node: 18
CPU Utilized: 04:03:28
CPU Efficiency: 52.29% of 07:45:36 core-walltime
Job Wall-clock time: 00:25:52
Memory Utilized: 3.43 GB
Memory Efficiency: 11.69% of 29.30 GB
