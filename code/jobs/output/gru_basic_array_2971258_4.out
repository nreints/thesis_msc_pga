wandb: Currently logged in as: nreints. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_164023-hn3qntw0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run expert-tree-2
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal1/runs/hn3qntw0
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone █▂▂▂▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone █▂▁▁▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone █▂▁▁▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone █▂▁▂▁▂▁▁▁▁
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone █▂▁▂▁▂▁▁▁▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone 0.0
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: 🚀 View run expert-tree-2 at: https://wandb.ai/nreints/ThesisFinal1/runs/hn3qntw0
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_164023-hn3qntw0/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_164803-9gmi4565
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run golden-snowflake-38
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal1/runs/9gmi4565
Training on dataset: data_t(5,20)_r(0,0)_combi_pNone_gNone
Testing on 5 datasets: ['data_t(5,20)_r(0,0)_semi_pNone_gNone', 'data_t(5,20)_r(0,0)_full_pNone_gNone', 'data_t(5,20)_r(0,0)_combi_pNone_gNone', 'data_t(5,20)_r(0,0)_tennis_pNone_gNone', 'data_t(5,20)_r(0,0)_none_pNone_gNone']
Focussing on identity: False
Using extra input: False
Using fr-fr as reference point.
----- ITERATION 1/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 52.07197165489197 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(0,0)_semi_pNone_gNone took 13.208097219467163 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_full_pNone_gNone took 13.149232864379883 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 13.062792778015137 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_tennis_pNone_gNone took 13.44767713546753 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_none_pNone_gNone took 13.424742221832275 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: log_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0002525513 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.96942e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.96997e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.11318e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.09438e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.9492e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 34.23590540885925
Epoch 1/9
	 Logging train Loss: 7.1616e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.899e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.9257e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 3.5911e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.1542e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 2.8056e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 32.78115963935852
Epoch 2/9
	 Logging train Loss: 2.6235e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.4814e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.4971e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.8695e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.6119e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.435e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 32.559412240982056
Epoch 3/9
	 Logging train Loss: 1.8882e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.4479e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 6.876e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.7496e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.5502e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 6.573e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 32.60503649711609
Epoch 4/9
	 Logging train Loss: 1.2402e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.596e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.557e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 3.467e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.758e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 2.451e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 32.52186703681946
Epoch 5/9
	 Logging train Loss: 1.1832e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.2062e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.173e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.2368e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.2496e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 2.104e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 32.762574672698975
Epoch 6/9
	 Logging train Loss: 1.4194e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.463e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.402e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.841e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.478e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.378e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 32.74204087257385
Epoch 7/9
	 Logging train Loss: 1.3338e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.439e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.39e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.735e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.454e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.361e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 32.615912199020386
Epoch 8/9
	 Logging train Loss: 1.1085e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.45e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.377e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.639e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.437e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.357e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 32.594138860702515
Epoch 9/9
	 Logging train Loss: 9.414e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.466e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.405e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.616e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.464e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.386e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 32.712973833084106
Saved model in  trained_models/gru/data_t(5,20)_r(0,0)_combi_pNone_gNone/'log_quat_1'_'False'.pth
It took  461.2715754508972  seconds.
----- ITERATION 2/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 47.63290977478027 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(0,0)_semi_pNone_gNone took 12.161863803863525 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_full_pNone_gNone took 12.151767253875732 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 11.9096999168396 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_tennis_pNone_gNone took 12.172325372695923 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_none_pNone_gNone took 12.204368114471436 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: log_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0004490791 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.69288e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.6309e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.68743e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.83372e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.62222e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 32.85186767578125
Epoch 1/9
	 Logging train Loss: 6.6348e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone █▂▂▁▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone █▂▂▁▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone █▂▂▁▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone █▂▂▁▁▁▁▁▁▁
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone █▂▂▁▁▁▁▁▁▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone 0.0
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: 🚀 View run golden-snowflake-38 at: https://wandb.ai/nreints/ThesisFinal1/runs/9gmi4565
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_164803-9gmi4565/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_165536-dln3ind7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wise-dawn-58
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal1/runs/dln3ind7
	 Logging test loss: 2.5684e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.5192e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 3.0776e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.7924e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 2.4248e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 35.291730880737305
Epoch 2/9
	 Logging train Loss: 2.5156e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.5191e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.4781e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.8239e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.6603e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.4186e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 33.195107221603394
Epoch 3/9
	 Logging train Loss: 1.5469e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 7.214e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 6.853e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 8.833e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 7.872e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 6.634e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 33.10846447944641
Epoch 4/9
	 Logging train Loss: 1.7192e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.273e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 3.074e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 4.235e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.548e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 2.906e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 33.09081268310547
Epoch 5/9
	 Logging train Loss: 7.815e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.963e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.924e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 3.172e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.108e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.831e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 33.070000410079956
Epoch 6/9
	 Logging train Loss: 1.6424e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.557e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.515e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.108e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.663e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.422e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 33.02017569541931
Epoch 7/9
	 Logging train Loss: 1.4417e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.631e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.607e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.05e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.708e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.491e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 32.815425395965576
Epoch 8/9
	 Logging train Loss: 1.6753e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.587e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.472e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.852e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.678e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.369e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 33.05190443992615
Epoch 9/9
	 Logging train Loss: 1.0193e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.512e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.455e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.731e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.596e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.362e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 33.06306576728821
Saved model in  trained_models/gru/data_t(5,20)_r(0,0)_combi_pNone_gNone/'log_quat_1'_'False'.pth
It took  452.64218950271606  seconds.
----- ITERATION 3/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 46.6639289855957 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(0,0)_semi_pNone_gNone took 12.079926490783691 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_full_pNone_gNone took 12.08887767791748 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 11.798272609710693 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_tennis_pNone_gNone took 12.067829608917236 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_none_pNone_gNone took 12.028208494186401 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: log_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0004536317 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.60131e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.49888e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.67575e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.60166e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 2.57559e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 32.89703989028931
Epoch 1/9
	 Logging train Loss: 1.05212e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.7826e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.5888e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 3.4003e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.7261e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 2.6174e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 32.675158977508545
Epoch 2/9
	 Logging train Loss: 2.5714e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.4751e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.3735e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.8839e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.4447e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.3815e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 32.90004897117615
Epoch 3/9
	 Logging train Loss: 1.3629e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 6.834e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 6.283e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 9.194e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 6.71e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 6.265e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 32.742998123168945
Epoch 4/9
	 Logging train Loss: 1.9497e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.203e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.963e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 4.587e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.193e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 2.941e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 32.9971022605896
Epoch 5/9
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone █▂▁▁▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone █▂▁▁▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone █▂▁▁▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone █▂▁▁▁▁▁▁▁▁
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone █▂▁▁▁▁▁▁▁▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone 0.0
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: 🚀 View run wise-dawn-58 at: https://wandb.ai/nreints/ThesisFinal1/runs/dln3ind7
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_165536-dln3ind7/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_170303-kf6i7nbi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run graceful-dust-90
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal1/runs/kf6i7nbi
	 Logging train Loss: 1.2977e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.919e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.825e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.867e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.939e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.781e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 32.74732279777527
Epoch 6/9
	 Logging train Loss: 1.5457e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.886e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.675e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.521e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.897e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.636e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 33.093218088150024
Epoch 7/9
	 Logging train Loss: 1.1383e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.54e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.46e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.079e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.562e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.443e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 32.990402936935425
Epoch 8/9
	 Logging train Loss: 1.5234e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.633e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.417e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.967e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.654e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.397e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 33.152066469192505
Epoch 9/9
	 Logging train Loss: 1.3099e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.487e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.484e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.835e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.514e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.458e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 33.21991944313049
Saved model in  trained_models/gru/data_t(5,20)_r(0,0)_combi_pNone_gNone/'log_quat_1'_'False'.pth
It took  447.3225018978119  seconds.
----- ITERATION 4/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 46.19425988197327 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(0,0)_semi_pNone_gNone took 11.952604293823242 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_full_pNone_gNone took 11.99629545211792 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 11.699741125106812 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_tennis_pNone_gNone took 11.960673332214355 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_none_pNone_gNone took 11.94650650024414 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: log_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0003186783 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.43439e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.33209e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.52886e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.5088e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 2.32115e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 32.93029046058655
Epoch 1/9
	 Logging train Loss: 8.0121e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.0936e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.8233e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 3.6538e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.1591e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 2.8157e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 32.92207717895508
Epoch 2/9
	 Logging train Loss: 3.0513e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.6259e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.5073e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.9915e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.6772e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.5077e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 35.17699599266052
Epoch 3/9
	 Logging train Loss: 2.0259e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 7.583e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 7.077e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 9.536e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 7.918e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 7.096e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 32.902276277542114
Epoch 4/9
	 Logging train Loss: 1.9469e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.4019e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 3.53e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.0503e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.5075e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 3.489e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 33.04441428184509
Epoch 5/9
	 Logging train Loss: 1.0551e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.89e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.747e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.45e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.924e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.722e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 32.94876050949097
Epoch 6/9
	 Logging train Loss: 1.5918e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 9.495e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.877e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 6.54e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 9.65e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.82e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 33.38780879974365
Epoch 7/9
	 Logging train Loss: 1.1585e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.1926e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 7.779e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.2369e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.956e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 33.20137882232666
Epoch 8/9
	 Logging train Loss: 8.778e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.363e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.438e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.211e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.418e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone █▂▂▁▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone █▂▁▁▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone █▂▁▁▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone █▂▁▁▁▁▁▁▁▁
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone █▂▁▁▁▁▁▁▁▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone 0.0
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: 🚀 View run graceful-dust-90 at: https://wandb.ai/nreints/ThesisFinal1/runs/kf6i7nbi
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_170303-kf6i7nbi/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_171035-rt10m5b1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rosy-lake-117
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal1/runs/rt10m5b1
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone █▂▂▁▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone █▂▁▁▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone █▂▁▁▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone █▂▁▁▁▁▁▁▁▁
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone █▂▁▁▁▁▁▁▁▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone 0.0
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: 🚀 View run rosy-lake-117 at: https://wandb.ai/nreints/ThesisFinal1/runs/rt10m5b1
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_171035-rt10m5b1/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_171803-1pag4tyd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run laced-voice-139
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal1/runs/1pag4tyd
	 Logging test loss: 1.425e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 33.25366020202637
Epoch 9/9
	 Logging train Loss: 9.284e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.545e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.471e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.698e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.539e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.409e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 32.890665769577026
Saved model in  trained_models/gru/data_t(5,20)_r(0,0)_combi_pNone_gNone/'log_quat_1'_'False'.pth
It took  452.25608587265015  seconds.
----- ITERATION 5/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 46.43591904640198 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(0,0)_semi_pNone_gNone took 11.957659244537354 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_full_pNone_gNone took 11.963652849197388 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 11.785408973693848 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_tennis_pNone_gNone took 11.955725193023682 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_none_pNone_gNone took 11.930085897445679 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: log_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0004650043 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.85142e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.98413e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.00212e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.93079e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.87561e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 33.060572385787964
Epoch 1/9
	 Logging train Loss: 6.7559e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.4316e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.4198e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 3.1418e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.5256e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 2.341e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 32.93765330314636
Epoch 2/9
	 Logging train Loss: 2.3857e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.3537e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.3641e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.8118e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.4124e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.3084e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 32.888792753219604
Epoch 3/9
	 Logging train Loss: 1.6254e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 6.731e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 6.701e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 9.19e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 7.032e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 6.377e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 32.81368589401245
Epoch 4/9
	 Logging train Loss: 1.6934e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.488e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 3.377e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 4.768e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.626e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 3.224e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 33.05931997299194
Epoch 5/9
	 Logging train Loss: 1.7297e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.02e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.022e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.89e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.089e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.963e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 33.36129927635193
Epoch 6/9
	 Logging train Loss: 1.1377e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 4.667e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.964e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 3.915e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 4.871e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.919e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 32.95335817337036
Epoch 7/9
	 Logging train Loss: 1.2107e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 5.629e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.921e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 4.771e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 5.779e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 2.915e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 32.95777654647827
Epoch 8/9
	 Logging train Loss: 1.1428e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.453e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.408e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.888e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.461e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.407e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 32.93637681007385
Epoch 9/9
	 Logging train Loss: 1.4305e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.427e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.417e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.782e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.434e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.422e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 32.95898938179016
Saved model in  trained_models/gru/data_t(5,20)_r(0,0)_combi_pNone_gNone/'log_quat_1'_'False'.pth
It took  447.49168491363525  seconds.
----- ITERATION 6/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 46.31563663482666 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(0,0)_semi_pNone_gNone took 11.913785219192505 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_full_pNone_gNone took 11.912490367889404 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 11.733815908432007 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_tennis_pNone_gNone took 11.92271089553833 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_none_pNone_gNone took 11.903223514556885 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: log_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0001746027 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.54483e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone █▂▂▁▁▁▁▄▁▁
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone █▂▂▁▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone █▂▂▁▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone █▂▃▁▁▁▁▇▁▁
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone █▂▃▁▁▁▁▆▁▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone 0.0
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: 🚀 View run laced-voice-139 at: https://wandb.ai/nreints/ThesisFinal1/runs/1pag4tyd
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_171803-1pag4tyd/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_172535-iaalcm4d
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run unique-bush-167
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal1/runs/iaalcm4d
	 Logging test loss: 1.48345e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.66271e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.66507e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.57496e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 32.72052526473999
Epoch 1/9
	 Logging train Loss: 7.1324e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.9583e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.8526e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 3.5632e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.2004e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 2.9814e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 33.2126727104187
Epoch 2/9
	 Logging train Loss: 4.1623e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 4.0207e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.6524e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 3.1939e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 4.1644e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.742e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 32.92482662200928
Epoch 3/9
	 Logging train Loss: 2.9207e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 8.621e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 7.944e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.0262e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 9.38e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 8.524e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 34.98885989189148
Epoch 4/9
	 Logging train Loss: 2.099e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 4.465e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 3.892e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 5.159e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 4.815e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 4.167e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 33.05073356628418
Epoch 5/9
	 Logging train Loss: 1.9211e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.315e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.17e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.792e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.444e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 2.271e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 33.121769189834595
Epoch 6/9
	 Logging train Loss: 1.0066e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.156e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.568e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.249e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.215e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.603e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 33.15388607978821
Epoch 7/9
	 Logging train Loss: 1.1865e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.25396e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 6.463e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 6.712e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.30124e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 6.324e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 33.29397511482239
Epoch 8/9
	 Logging train Loss: 1.3028e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.413e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.395e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.604e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.438e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.401e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 33.30233192443848
Epoch 9/9
	 Logging train Loss: 8.201e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.174e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.52e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.475e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.179e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.491e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 33.00807857513428
Saved model in  trained_models/gru/data_t(5,20)_r(0,0)_combi_pNone_gNone/'log_quat_1'_'False'.pth
It took  451.86553716659546  seconds.
----- ITERATION 7/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 46.295135259628296 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(0,0)_semi_pNone_gNone took 11.858878135681152 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_full_pNone_gNone took 11.853054285049438 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 11.696088790893555 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_tennis_pNone_gNone took 11.85866379737854 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_none_pNone_gNone took 11.874924898147583 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: log_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0004629407 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.44754e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.37589e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.44863e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.39777e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 2.32236e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 33.070902585983276
Epoch 1/9
	 Logging train Loss: 1.0039e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.7824e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.6796e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 3.3557e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.7445e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 2.6852e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 33.0881552696228
Epoch 2/9
	 Logging train Loss: 2.8703e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.61e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.549e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.9442e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.5808e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.5456e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 33.12496376037598
Epoch 3/9
	 Logging train Loss: 1.7776e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 8.014e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 7.687e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 9.773e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 7.951e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 7.626e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 32.737683057785034
Epoch 4/9
	 Logging train Loss: 1.1935e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone █▂▂▁▁▁▁▁▁▂
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone █▂▁▁▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone █▂▁▁▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone █▂▁▁▁▁▁▁▁▃
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone █▂▁▁▁▁▁▁▁▄
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone 1e-05
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone 1e-05
wandb:                                  Train loss 0.0
wandb: 
wandb: 🚀 View run unique-bush-167 at: https://wandb.ai/nreints/ThesisFinal1/runs/iaalcm4d
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_172535-iaalcm4d/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_173302-6eylmn24
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run deep-valley-193
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal1/runs/6eylmn24
	 Logging test loss: 3.646e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 3.463e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 4.64e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.678e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 3.401e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 32.99001121520996
Epoch 5/9
	 Logging train Loss: 1.336e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.035e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.936e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.695e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.085e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.876e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 32.786242961883545
Epoch 6/9
	 Logging train Loss: 1.0671e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.58e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.527e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.093e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.629e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.455e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 32.85253596305847
Epoch 7/9
	 Logging train Loss: 1.1192e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 5.942e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.673e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 4.39e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 6.379e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.614e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 33.042887926101685
Epoch 8/9
	 Logging train Loss: 1.1735e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.414e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.393e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.733e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.459e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.334e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 33.00034260749817
Epoch 9/9
	 Logging train Loss: 9.661e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 8.4565e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 8.154e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 4.8704e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 9.2458e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 8.06e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 33.07075262069702
Saved model in  trained_models/gru/data_t(5,20)_r(0,0)_combi_pNone_gNone/'log_quat_1'_'False'.pth
It took  447.4243326187134  seconds.
----- ITERATION 8/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 46.35657811164856 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(0,0)_semi_pNone_gNone took 11.91462516784668 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_full_pNone_gNone took 11.893220663070679 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 11.75847840309143 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_tennis_pNone_gNone took 11.903579711914062 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_none_pNone_gNone took 11.878066062927246 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: log_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0002874075 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.85514e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.87749e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.97568e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.99e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 2.07494e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 32.8091881275177
Epoch 1/9
	 Logging train Loss: 8.6735e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.6362e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.6479e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 3.2414e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.7632e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 2.7276e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 33.55057978630066
Epoch 2/9
	 Logging train Loss: 2.4978e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.3282e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.3252e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.7057e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.3935e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.3947e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 32.8072235584259
Epoch 3/9
	 Logging train Loss: 2.0191e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.4683e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 6.938e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.3184e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.5284e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 7.384e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 34.22413182258606
Epoch 4/9
	 Logging train Loss: 1.7724e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.8208e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.0912e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.12159e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.9204e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 2.1397e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 34.19705605506897
Epoch 5/9
	 Logging train Loss: 1.3169e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.016e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.923e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.731e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.035e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.963e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 32.95498275756836
Epoch 6/9
	 Logging train Loss: 1.32e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.807e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.541e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.757e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.839e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.548e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 33.31809616088867
Epoch 7/9
	 Logging train Loss: 1.4837e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.474e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.423e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.862e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.475e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.405e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 33.3658504486084
Epoch 8/9
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone █▂▂▁█▁▁▁▅▁
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone █▂▁▁▂▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone █▂▁▁▂▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone ▄▁▁▁█▁▁▁▅▁
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone ▅▁▁▁█▁▁▁▅▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone 0.0
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: 🚀 View run deep-valley-193 at: https://wandb.ai/nreints/ThesisFinal1/runs/6eylmn24
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_173302-6eylmn24/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_174033-s1uoosl7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run clean-river-220
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal1/runs/s1uoosl7
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone █▂▂▁▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone █▂▁▁▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone █▂▁▁▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone █▂▂▁▁▂▁▁▁▁
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone █▂▂▁▁▂▁▁▁▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone 0.0
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: 🚀 View run clean-river-220 at: https://wandb.ai/nreints/ThesisFinal1/runs/s1uoosl7
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_174033-s1uoosl7/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_174803-rh1x4k6x
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run winter-forest-252
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal1/runs/rh1x4k6x
	 Logging train Loss: 9.573e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.22684e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.4531e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.23416e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.44574e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.4567e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 33.05789494514465
Epoch 9/9
	 Logging train Loss: 8.925e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 6.923e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.241e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 5.001e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 7.235e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 2.233e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 32.986090898513794
Saved model in  trained_models/gru/data_t(5,20)_r(0,0)_combi_pNone_gNone/'log_quat_1'_'False'.pth
It took  451.341760635376  seconds.
----- ITERATION 9/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 46.418622732162476 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(0,0)_semi_pNone_gNone took 11.880030870437622 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_full_pNone_gNone took 11.859142541885376 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 11.772199630737305 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_tennis_pNone_gNone took 11.868436574935913 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_none_pNone_gNone took 11.871864318847656 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: log_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0003620681 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.04249e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.01683e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.19834e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.17491e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.97856e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 33.36537766456604
Epoch 1/9
	 Logging train Loss: 7.5959e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.0255e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.9649e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 3.7552e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.2573e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 2.9075e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 33.29631209373474
Epoch 2/9
	 Logging train Loss: 2.6546e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.6037e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.5575e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.0233e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.7325e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.527e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 33.0716917514801
Epoch 3/9
	 Logging train Loss: 1.9331e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 7.679e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 7.302e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 9.833e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 8.318e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 7.177e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 32.99567198753357
Epoch 4/9
	 Logging train Loss: 1.7538e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.698e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 3.36e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 4.813e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.983e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 3.303e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 33.16149878501892
Epoch 5/9
	 Logging train Loss: 1.4562e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.896e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.775e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.2184e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.9987e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 2.709e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 33.01891303062439
Epoch 6/9
	 Logging train Loss: 1.3195e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.614e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.512e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.168e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.635e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.471e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 32.97955322265625
Epoch 7/9
	 Logging train Loss: 1.4399e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.533e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.419e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.935e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.566e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.392e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 32.96919298171997
Epoch 8/9
	 Logging train Loss: 1.3455e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.0475e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.651e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 6.209e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.0281e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.627e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 33.41812300682068
Epoch 9/9
	 Logging train Loss: 1.2129e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.406e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.398e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.686e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.433e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.375e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 33.20355939865112
Saved model in  trained_models/gru/data_t(5,20)_r(0,0)_combi_pNone_gNone/'log_quat_1'_'False'.pth
It took  449.8691780567169  seconds.
----- ITERATION 10/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 46.495851278305054 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(0,0)_semi_pNone_gNone took 11.882019758224487 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_full_pNone_gNone took 11.900794506072998 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 11.735961437225342 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_tennis_pNone_gNone took 11.870447635650635 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_none_pNone_gNone took 11.899807929992676 seconds.
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone █▂▂▁▁▄▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone █▂▁▁▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone █▂▁▁▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone █▂▁▁▁▇▁▁▁▁
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone █▂▁▁▁▇▁▁▁▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone 0.0
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: 🚀 View run winter-forest-252 at: https://wandb.ai/nreints/ThesisFinal1/runs/rh1x4k6x
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_174803-rh1x4k6x/logs
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: log_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0004771986 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.25918e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.25741e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.39416e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.3523e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 2.27761e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 33.06109929084778
Epoch 1/9
	 Logging train Loss: 8.4512e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.7012e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.6084e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 3.2931e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.7583e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 2.647e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 33.25122308731079
Epoch 2/9
	 Logging train Loss: 2.5272e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.5467e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.4894e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.9269e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.5762e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.5041e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 32.87979316711426
Epoch 3/9
	 Logging train Loss: 1.6439e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 7.522e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 7.042e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 9.648e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 7.667e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 7.065e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 33.82262134552002
Epoch 4/9
	 Logging train Loss: 1.2217e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.764e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 3.222e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 4.864e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.843e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 3.203e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 34.338372468948364
Epoch 5/9
	 Logging train Loss: 1.1639e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.08218e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.1997e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.12643e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.15513e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.1644e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 33.33513903617859
Epoch 6/9
	 Logging train Loss: 1.2739e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.408e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.549e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.682e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.495e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.519e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 32.94933557510376
Epoch 7/9
	 Logging train Loss: 1.1497e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.595e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.676e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 9.943e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.6074e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 2.598e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 33.01932239532471
Epoch 8/9
	 Logging train Loss: 1.078e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.706e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.457e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.511e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.794e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.419e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 32.82309079170227
Epoch 9/9
	 Logging train Loss: 1.1078e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.459e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.415e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.74e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.476e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.368e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 32.87589764595032
Saved model in  trained_models/gru/data_t(5,20)_r(0,0)_combi_pNone_gNone/'log_quat_1'_'False'.pth
It took  451.55487275123596  seconds.

JOB STATISTICS
==============
Job ID: 2971262
Array Job ID: 2971258_4
Cluster: snellius
User/Group: nreints/nreints
State: RUNNING
Nodes: 1
Cores per node: 18
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 22:37:48 core-walltime
Job Wall-clock time: 01:15:26
Memory Utilized: 0.00 MB (estimated maximum)
Memory Efficiency: 0.00% of 0.00 MB (0.00 MB/node)
WARNING: Efficiency statistics may be misleading for RUNNING jobs.
