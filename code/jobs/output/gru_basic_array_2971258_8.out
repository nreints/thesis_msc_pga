wandb: Currently logged in as: nreints. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_164025-h4dkv98g
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rose-thunder-3
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal1/runs/h4dkv98g
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone █▃▂▂▁▁▃▁▃▁
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone █▄▃▂▁▁▃▁▃▁
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone █▄▃▂▁▁▃▁▂▁
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone █▃▂▂▁▁▄▁▄▁
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone █▃▂▂▁▁▄▁▄▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone 1e-05
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone 1e-05
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone 1e-05
wandb:                                  Train loss 1e-05
wandb: 
wandb: 🚀 View run rose-thunder-3 at: https://wandb.ai/nreints/ThesisFinal1/runs/h4dkv98g
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_164025-h4dkv98g/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_165650-gpdgldyb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run chocolate-valley-67
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal1/runs/gpdgldyb
Training on dataset: data_t(0,0)_r(5,20)_combi_pNone_gNone
Testing on 5 datasets: ['data_t(0,0)_r(5,20)_combi_pNone_gNone', 'data_t(0,0)_r(5,20)_full_pNone_gNone', 'data_t(0,0)_r(5,20)_tennis_pNone_gNone', 'data_t(0,0)_r(5,20)_none_pNone_gNone', 'data_t(0,0)_r(5,20)_semi_pNone_gNone']
Focussing on identity: False
Using extra input: False
Using fr-fr as reference point.
----- ITERATION 1/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 65.18646335601807 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 15.826549530029297 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_full_pNone_gNone took 16.872053623199463 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_tennis_pNone_gNone took 16.49858593940735 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_none_pNone_gNone took 16.593332767486572 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_semi_pNone_gNone took 16.4813871383667 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0149623351 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.91167e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.7042e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.77439e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.8807e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 4.48596e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 81.974858045578
Epoch 1/9
	 Logging train Loss: 2.46541e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.7703e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.4346e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.90519e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.5652e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.90096e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 82.1489315032959
Epoch 2/9
	 Logging train Loss: 1.32973e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.14951e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.555e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.55509e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 9.784e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.56127e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 82.1536180973053
Epoch 3/9
	 Logging train Loss: 9.5014e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 9.4867e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.208e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.41486e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 6.389e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.43546e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 81.78450298309326
Epoch 4/9
	 Logging train Loss: 7.985e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.1202e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.752e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.2492e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.795e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.27082e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 82.01501536369324
Epoch 5/9
	 Logging train Loss: 7.2003e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.1959e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.561e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.12394e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.527e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.14272e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 82.05057549476624
Epoch 6/9
	 Logging train Loss: 7.233e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.42007e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.0739e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.49278e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.1698e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.35177e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 82.25767612457275
Epoch 7/9
	 Logging train Loss: 9.618e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.8494e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.022e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.11742e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.786e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.11298e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 82.01203346252441
Epoch 8/9
	 Logging train Loss: 8.8245e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.57071e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.917e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.83781e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 8.564e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.63713e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 82.08455419540405
Epoch 9/9
	 Logging train Loss: 9.465e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.7844e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.097e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.16384e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.683e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.12589e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 83.96382904052734
Saved model in  trained_models/gru/data_t(0,0)_r(5,20)_combi_pNone_gNone/'rot_mat_1'_'False'.pth
It took  986.0703659057617  seconds.
----- ITERATION 2/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 63.58008670806885 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 16.113451719284058 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_full_pNone_gNone took 16.431909561157227 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_tennis_pNone_gNone took 16.372453212738037 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_none_pNone_gNone took 16.285699605941772 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_semi_pNone_gNone took 16.388630151748657 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0279358476 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.50135e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.2282e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.63487e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 5.3539e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 4.42547e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 85.24825143814087
Epoch 1/9
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone █▃▂▂▃▁▁▁▂▁
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone █▃▁▁▂▁▁▁▂▁
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone █▃▂▂▂▁▁▁▂▁
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone █▃▂▃▄▁▁▂▂▁
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone █▃▂▃▅▁▁▂▂▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone 1e-05
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone 1e-05
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone 1e-05
wandb:                                  Train loss 1e-05
wandb: 
wandb: 🚀 View run chocolate-valley-67 at: https://wandb.ai/nreints/ThesisFinal1/runs/gpdgldyb
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_165650-gpdgldyb/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_171330-bicf4i8d
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run major-firebrand-127
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal1/runs/bicf4i8d
	 Logging train Loss: 2.02341e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.35085e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.2913e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.93155e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.3921e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.89656e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 85.23970913887024
Epoch 2/9
	 Logging train Loss: 9.904e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.8948e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.066e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.39092e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 6.054e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.40269e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 85.08177709579468
Epoch 3/9
	 Logging train Loss: 8.1816e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.10342e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.126e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.93107e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 6.074e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.80921e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 84.82161903381348
Epoch 4/9
	 Logging train Loss: 9.8468e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.57624e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.904e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.87021e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 7.721e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.59775e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 84.74082636833191
Epoch 5/9
	 Logging train Loss: 1.1009e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.992e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.621e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.02258e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.411e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.02646e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 83.06843900680542
Epoch 6/9
	 Logging train Loss: 1.00526e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.3897e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.641e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.12644e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.327e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.09088e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 82.88667559623718
Epoch 7/9
	 Logging train Loss: 9.6175e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.4673e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.822e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.33915e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.427e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.28107e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 82.89495825767517
Epoch 8/9
	 Logging train Loss: 9.6988e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 9.4215e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.766e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.69321e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 8.323e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.5557e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 85.94001507759094
Epoch 9/9
	 Logging train Loss: 6.8731e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.4826e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.793e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 9.8732e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.259e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 9.2689e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 82.79683256149292
Saved model in  trained_models/gru/data_t(0,0)_r(5,20)_combi_pNone_gNone/'rot_mat_1'_'False'.pth
It took  999.997659444809  seconds.
----- ITERATION 3/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 63.70007300376892 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 16.00703239440918 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_full_pNone_gNone took 16.340851306915283 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_tennis_pNone_gNone took 16.33249545097351 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_none_pNone_gNone took 16.230225563049316 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_semi_pNone_gNone took 16.473767518997192 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0858158469 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.20242e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.829e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 6.80281e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.102e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 6.21809e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 84.22548174858093
Epoch 1/9
	 Logging train Loss: 2.29139e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.37877e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.0089e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.21401e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.148e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.15598e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 84.37802243232727
Epoch 2/9
	 Logging train Loss: 1.10059e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.7992e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.231e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.51283e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 8.32e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.51924e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 84.43527817726135
Epoch 3/9
	 Logging train Loss: 8.4399e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.5125e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.206e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.34187e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 6.136e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.34737e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 84.7219603061676
Epoch 4/9
	 Logging train Loss: 9.2204e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.71069e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.6503e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 7.659e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.751e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone █▃▂▁▇▃▁▁▂▁
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone █▃▂▂█▇▁▄▂▃
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone █▃▂▂▇▆▁▃▂▃
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone ▇▂▂▁█▄▁▁▂▁
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone ▇▂▂▁█▄▁▁▂▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone 1e-05
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone 1e-05
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone 1e-05
wandb:                                  Train loss 1e-05
wandb: 
wandb: 🚀 View run major-firebrand-127 at: https://wandb.ai/nreints/ThesisFinal1/runs/bicf4i8d
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_171330-bicf4i8d/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_173013-sbwzq859
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pretty-terrain-186
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal1/runs/sbwzq859
	 Logging test loss: 6.97848e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 85.12794589996338
Epoch 5/9
	 Logging train Loss: 1.08066e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.78005e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.3783e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.45584e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.4525e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.24602e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 83.04518127441406
Epoch 6/9
	 Logging train Loss: 1.04122e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.3063e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.484e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 9.9012e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.177e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 9.9083e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 83.38230752944946
Epoch 7/9
	 Logging train Loss: 1.08e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.7836e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.1999e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.00283e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.2643e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.0054e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 86.37133240699768
Epoch 8/9
	 Logging train Loss: 9.2474e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.501e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.033e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.70847e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 5.613e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.62135e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 84.30012345314026
Epoch 9/9
	 Logging train Loss: 6.8066e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.566e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.764e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.04125e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 9.256e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.00982e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 83.43445539474487
Saved model in  trained_models/gru/data_t(0,0)_r(5,20)_combi_pNone_gNone/'rot_mat_1'_'False'.pth
It took  1002.8875348567963  seconds.
----- ITERATION 4/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 63.4102509021759 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 15.963783502578735 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_full_pNone_gNone took 16.10391902923584 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_tennis_pNone_gNone took 16.14334511756897 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_none_pNone_gNone took 16.148743391036987 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_semi_pNone_gNone took 16.26430583000183 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0245341416 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.34055e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.6967e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.2223e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.8265e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 4.31094e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 82.55892968177795
Epoch 1/9
	 Logging train Loss: 2.30452e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.55507e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.018e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.8927e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.1213e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.07231e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 82.99341106414795
Epoch 2/9
	 Logging train Loss: 1.27169e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.05274e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.0469e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.50845e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.1409e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.69482e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 82.52569818496704
Epoch 3/9
	 Logging train Loss: 9.2199e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.6219e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.76e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.34071e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 6.634e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.52454e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 82.68868851661682
Epoch 4/9
	 Logging train Loss: 7.7817e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.7311e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.507e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.26033e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.326e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.42765e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 82.82379627227783
Epoch 5/9
	 Logging train Loss: 6.9892e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.6551e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.575e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.09836e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.308e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.2531e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 82.91955280303955
Epoch 6/9
	 Logging train Loss: 8.2713e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.5391e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.489e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.1106e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.163e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.24251e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 83.93235540390015
Epoch 7/9
	 Logging train Loss: 8.1211e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.46548e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.9352e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.54643e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.9937e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.55921e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 83.02942824363708
Epoch 8/9
	 Logging train Loss: 8.7693e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.9225e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.754e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone █▄▂▂▂▁▁▃▂▁
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone █▄▂▂▁▁▁▄▁▂
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone █▄▂▂▁▁▁▄▁▂
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone █▃▃▂▂▂▂▄▂▁
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone █▃▂▂▂▁▁▄▂▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone 1e-05
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone 1e-05
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone 1e-05
wandb:                                  Train loss 1e-05
wandb: 
wandb: 🚀 View run pretty-terrain-186 at: https://wandb.ai/nreints/ThesisFinal1/runs/sbwzq859
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_173013-sbwzq859/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_174638-29gtv4wx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run magic-voice-247
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal1/runs/29gtv4wx
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone █▄▃▆▄▂▂▂▁▁
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone █▄▂▄▄▁▁▁▁▁
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone █▄▃▄▄▁▁▁▁▁
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone ▆▅▄█▅▂▂▂▁▁
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone ▆▅▄█▅▂▂▂▁▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone 1e-05
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone 1e-05
wandb:                                  Train loss 1e-05
wandb: 
wandb: 🚀 View run magic-voice-247 at: https://wandb.ai/nreints/ThesisFinal1/runs/29gtv4wx
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_174638-29gtv4wx/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_180300-6a4ars34
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cerulean-wood-298
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal1/runs/6a4ars34
	 Logging test loss: 1.43542e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 5.343e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.4809e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 82.54499244689941
Epoch 9/9
	 Logging train Loss: 8.3298e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.2737e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.038e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 8.9759e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 6.457e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 9.774e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 82.38718557357788
Saved model in  trained_models/gru/data_t(0,0)_r(5,20)_combi_pNone_gNone/'rot_mat_1'_'False'.pth
It took  985.0627472400665  seconds.
----- ITERATION 5/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 63.69749736785889 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 16.03019666671753 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_full_pNone_gNone took 16.16695284843445 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_tennis_pNone_gNone took 16.14580750465393 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_none_pNone_gNone took 16.206825017929077 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_semi_pNone_gNone took 16.277021408081055 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0020897912 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.48643e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.3354e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.86647e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.482e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.73501e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 82.52619504928589
Epoch 1/9
	 Logging train Loss: 1.20461e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.4564e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.817e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.44109e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 7.97e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.35467e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 82.50752592086792
Epoch 2/9
	 Logging train Loss: 8.4926e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.7029e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.376e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.25285e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.353e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.17726e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 82.43848466873169
Epoch 3/9
	 Logging train Loss: 7.3218e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.18152e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.911e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.28514e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 7.904e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.18586e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 81.88312125205994
Epoch 4/9
	 Logging train Loss: 8.0834e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.7656e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.962e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.48029e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 7.844e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.38823e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 82.06374502182007
Epoch 5/9
	 Logging train Loss: 7.3881e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.4112e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.392e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 8.8341e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.051e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 8.2595e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 82.9414792060852
Epoch 6/9
	 Logging train Loss: 6.8311e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.0753e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.553e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 8.2322e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.103e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 7.8382e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 83.66326570510864
Epoch 7/9
	 Logging train Loss: 7.1854e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.7382e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.717e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 7.6636e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.216e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 7.21e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 81.99668765068054
Epoch 8/9
	 Logging train Loss: 6.5958e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.8101e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.055e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 5.7861e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.453e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 5.3922e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 82.17204213142395
Epoch 9/9
	 Logging train Loss: 5.3121e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.6441e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.559e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 5.3951e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.908e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 5.0452e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 82.00930595397949
Saved model in  trained_models/gru/data_t(0,0)_r(5,20)_combi_pNone_gNone/'rot_mat_1'_'False'.pth
It took  981.7360153198242  seconds.
----- ITERATION 6/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 63.456507205963135 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 15.98653531074524 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_full_pNone_gNone took 16.179320812225342 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_tennis_pNone_gNone took 16.231340885162354 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_none_pNone_gNone took 16.16244602203369 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_semi_pNone_gNone took 16.37340235710144 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat_1
-- Started Training --
Epoch 0/9
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone █▄▂▂▂▂▂▁▁▆
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone █▄▃▂▁▂▂▁▁▇
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone █▄▃▂▁▂▂▁▁▇
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone ▅▃▂▂▂▂▃▁▁█
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone ▅▃▂▂▂▂▃▁▁█
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone 2e-05
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone 4e-05
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone 4e-05
wandb:                                  Train loss 1e-05
wandb: 
wandb: 🚀 View run cerulean-wood-298 at: https://wandb.ai/nreints/ThesisFinal1/runs/6a4ars34
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_180300-6a4ars34/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_181936-u5ha510h
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run honest-leaf-337
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal1/runs/u5ha510h
	 Logging train Loss: 0.0174590163 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.50284e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.3193e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.80315e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.4101e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.67914e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 83.49825501441956
Epoch 1/9
	 Logging train Loss: 1.92308e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.34808e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.1424e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.64589e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.2375e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.60515e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 83.65241622924805
Epoch 2/9
	 Logging train Loss: 1.12151e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.7838e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.217e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.40303e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 7.136e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.37893e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 83.8296685218811
Epoch 3/9
	 Logging train Loss: 8.2747e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.2373e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.34e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.29412e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.207e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.2688e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 83.21674084663391
Epoch 4/9
	 Logging train Loss: 7.281e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.7667e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.626e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.26911e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.419e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.23595e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 83.05601763725281
Epoch 5/9
	 Logging train Loss: 7.2973e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.6173e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.258e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.24587e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.971e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.20963e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 85.59855818748474
Epoch 6/9
	 Logging train Loss: 9.4555e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.6139e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.449e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.69567e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 5.041e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.62341e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 83.32134461402893
Epoch 7/9
	 Logging train Loss: 1.06696e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.2728e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.552e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.03093e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.1e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 9.9733e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 84.54989337921143
Epoch 8/9
	 Logging train Loss: 9.7586e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.8588e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.723e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 9.5278e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.191e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 9.1506e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 84.66988205909729
Epoch 9/9
	 Logging train Loss: 9.0828e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.00049e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.9411e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.06311e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.9473e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.75795e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 84.50059795379639
Saved model in  trained_models/gru/data_t(0,0)_r(5,20)_combi_pNone_gNone/'rot_mat_1'_'False'.pth
It took  996.2347691059113  seconds.
----- ITERATION 7/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 64.22892379760742 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 16.135860681533813 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_full_pNone_gNone took 16.27277684211731 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_tennis_pNone_gNone took 16.220988035202026 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_none_pNone_gNone took 16.228268146514893 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_semi_pNone_gNone took 16.202120780944824 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0042983643 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.6619e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.442e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.0065e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.5381e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.56578e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 82.01268672943115
Epoch 1/9
	 Logging train Loss: 1.88987e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.42288e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 9.568e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.82095e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.0627e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.60575e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 82.32530522346497
Epoch 2/9
	 Logging train Loss: 1.11513e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.00941e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.791e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.67764e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 6.776e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.47429e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 82.07784008979797
Epoch 3/9
	 Logging train Loss: 8.4917e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.2768e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.43e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.48918e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.319e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone █▄▃▂▂▂▁▁▁▁
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone █▃▂▂▂▂▁▁▁▁
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone █▄▂▂▂▂▁▁▁▁
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone █▄▄▃▃▃▂▂▁▂
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone █▄▄▃▃▃▂▂▁▂
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone 1e-05
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone 1e-05
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone 1e-05
wandb:                                  Train loss 1e-05
wandb: 
wandb: 🚀 View run honest-leaf-337 at: https://wandb.ai/nreints/ThesisFinal1/runs/u5ha510h
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_181936-u5ha510h/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_183559-o0kobvnw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sandy-firebrand-353
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal1/runs/o0kobvnw
	 Logging test loss: 1.30614e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 81.90695214271545
Epoch 4/9
	 Logging train Loss: 7.4316e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.6152e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.461e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.40937e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.239e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.24536e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 83.68669843673706
Epoch 5/9
	 Logging train Loss: 6.8553e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.0695e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.238e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.31827e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.919e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.15767e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 82.01675271987915
Epoch 6/9
	 Logging train Loss: 8.2417e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.4121e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.463e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.00937e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.064e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 8.9439e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 82.26708054542542
Epoch 7/9
	 Logging train Loss: 1.13954e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.4968e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.58e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.0642e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.131e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 9.2624e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 82.7823224067688
Epoch 8/9
	 Logging train Loss: 1.05327e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.1049e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.911e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 7.7524e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.382e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 6.8211e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 83.28998732566833
Epoch 9/9
	 Logging train Loss: 9.6061e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.3698e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.846e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.08285e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.165e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 9.0542e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 82.8310375213623
Saved model in  trained_models/gru/data_t(0,0)_r(5,20)_combi_pNone_gNone/'rot_mat_1'_'False'.pth
It took  982.6035761833191  seconds.
----- ITERATION 8/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 63.88819718360901 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 16.092110872268677 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_full_pNone_gNone took 16.19455647468567 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_tennis_pNone_gNone took 16.217951774597168 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_none_pNone_gNone took 16.13783288002014 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_semi_pNone_gNone took 16.10040283203125 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0101520661 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.19775e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.9038e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.47322e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.0357e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.34718e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 84.95556282997131
Epoch 1/9
	 Logging train Loss: 1.59911e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.14785e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.717e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.72335e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 9.888e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.6211e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 85.36117696762085
Epoch 2/9
	 Logging train Loss: 9.9683e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.4517e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.058e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.48319e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 6.107e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.40191e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 84.93927049636841
Epoch 3/9
	 Logging train Loss: 8.348e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.2017e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.54e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.47808e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 7.468e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.38482e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 86.05815315246582
Epoch 4/9
	 Logging train Loss: 9.1447e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.347e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.112e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.55736e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.948e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.43678e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 85.53913307189941
Epoch 5/9
	 Logging train Loss: 1.0268e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.9902e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.225e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.14274e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.959e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.06623e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 83.0502712726593
Epoch 6/9
	 Logging train Loss: 1.11572e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.30908e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.52e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.62802e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 8.096e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.40413e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 82.13916516304016
Epoch 7/9
	 Logging train Loss: 1.0085e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.9509e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.047e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone █▄▂▂▂▁▄▁▄▁
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone █▄▂▃▂▁▃▁▄▃
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone █▄▂▃▂▁▃▁▄▃
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone █▄▃▃▃▂█▁▆▂
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone ▇▄▃▃▃▂█▁▆▂
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone 1e-05
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone 1e-05
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone 1e-05
wandb:                                  Train loss 1e-05
wandb: 
wandb: 🚀 View run sandy-firebrand-353 at: https://wandb.ai/nreints/ThesisFinal1/runs/o0kobvnw
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_183559-o0kobvnw/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_185234-0swc18nh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rare-aardvark-360
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal1/runs/0swc18nh
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone ▆▃▂▂▂▂▁█▁▁
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone █▄▃▂▂▂▁█▁▂
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone █▄▃▂▂▂▁█▁▁
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone ▄▂▂▂▁▂▁█▁▁
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone ▄▂▂▂▁▂▁█▁▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone 1e-05
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone 1e-05
wandb:                                  Train loss 1e-05
wandb: 
wandb: 🚀 View run rare-aardvark-360 at: https://wandb.ai/nreints/ThesisFinal1/runs/0swc18nh
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_185234-0swc18nh/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_190902-ouan5mfq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vital-dragon-366
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal1/runs/ouan5mfq
slurmstepd: error: *** STEP 2971266.0 ON gcn24 CANCELLED AT 2023-06-26T19:10:19 DUE TO TIME LIMIT ***
srun: Job step aborted: Waiting up to 32 seconds for job step to finish.
slurmstepd: error: *** JOB 2971266 ON gcn24 CANCELLED AT 2023-06-26T19:10:19 DUE TO TIME LIMIT ***

JOB STATISTICS
==============
Job ID: 2971266
Array Job ID: 2971258_8
Cluster: snellius
User/Group: nreints/nreints
State: TIMEOUT (exit code 0)
Nodes: 1
Cores per node: 18
CPU Utilized: 00:00:01
CPU Efficiency: 0.00% of 1-21:02:06 core-walltime
Job Wall-clock time: 02:30:07
Memory Utilized: 6.50 MB
Memory Efficiency: 0.00% of 0.00 MB
