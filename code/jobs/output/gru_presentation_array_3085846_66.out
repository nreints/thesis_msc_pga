wandb: Currently logged in as: nreints. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_203203-du864o04
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run swift-brook-390
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: ğŸš€ View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/du864o04
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gTrue â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gTrue â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gTrue â–ˆâ–‚â–â–â–â–â–â–â–â–‚
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gTrue â–ˆâ–‚â–â–â–â–â–â–â–â–‚
wandb:                                  Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gTrue 0.0
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gTrue 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: ğŸš€ View run swift-brook-390 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/du864o04
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_203203-du864o04/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_203901-qmmmx97x
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pretty-spaceship-407
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: ğŸš€ View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/qmmmx97x
Training on dataset: data_t(5,20)_r(0,0)_combi_pNone_gTrue
Testing on 4 datasets: ['data_t(5,20)_r(0,0)_tennis_pNone_gTrue', 'data_t(5,20)_r(0,0)_semi_pNone_gTrue', 'data_t(5,20)_r(0,0)_combi_pNone_gTrue', 'data_t(5,20)_r(0,0)_full_pNone_gTrue']
Focussing on identity: True
Using extra input: False
Using fr-fr as reference point.
----- ITERATION 1/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gTrue took 52.050562143325806 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(0,0)_tennis_pNone_gTrue took 13.188247203826904 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_semi_pNone_gTrue took 13.52162218093872 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gTrue took 12.506576776504517 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_full_pNone_gTrue took 12.70613980293274 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0003170999 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.31687e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.38286e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.26903e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.30221e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 30.78979468345642
Epoch 1/9
	 Logging train Loss: 7.6765e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.5251e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.6014e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 3.1944e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.9563e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 29.657275676727295
Epoch 2/9
	 Logging train Loss: 3.1022e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.6179e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.6453e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.5757e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.5754e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 29.8495135307312
Epoch 3/9
	 Logging train Loss: 2.4099e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.2e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 8.379e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 7.986e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.944e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 29.949023723602295
Epoch 4/9
	 Logging train Loss: 1.7215e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.332e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 4.432e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 4.063e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.937e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 30.107078313827515
Epoch 5/9
	 Logging train Loss: 1.582e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.381e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.416e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.272e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.256e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 29.94803214073181
Epoch 6/9
	 Logging train Loss: 1.6159e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.663e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.704e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.642e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.635e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 29.828049898147583
Epoch 7/9
	 Logging train Loss: 1.3058e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.48e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.502e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.456e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.492e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 29.930295705795288
Epoch 8/9
	 Logging train Loss: 1.183e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.489e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.537e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.124e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.821e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 29.794931173324585
Epoch 9/9
	 Logging train Loss: 5.956e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.413e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.5468e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.3472e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.577e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 29.883710384368896
Saved model in  trained_models/gru/data_t(5,20)_r(0,0)_combi_pNone_gTrue/'quat_1'_'False'.pth
It took  418.94105315208435  seconds.
----- ITERATION 2/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gTrue took 51.355851888656616 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(0,0)_tennis_pNone_gTrue took 12.94798231124878 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_semi_pNone_gTrue took 12.913594245910645 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gTrue took 12.824715614318848 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_full_pNone_gTrue took 12.942287921905518 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0002598017 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.37924e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.2078e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.29172e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.3157e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 30.48889970779419
Epoch 1/9
	 Logging train Loss: 8.418e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.5459e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.371e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 3.403e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.4053e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 30.24851131439209
Epoch 2/9
	 Logging train Loss: 2.9316e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.1004e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.9974e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.0368e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.0555e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 30.253456115722656
Epoch 3/9
	 Logging train Loss: 3.832e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.1199e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.0618e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.0868e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.0945e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 30.271247386932373
Epoch 4/9
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gTrue â–ˆâ–‚â–‚â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gTrue â–ˆâ–‚â–‚â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gTrue â–ˆâ–‚â–‚â–â–â–â–‚â–â–â–
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gTrue â–ˆâ–‚â–‚â–â–â–â–‚â–â–â–
wandb:                                  Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gTrue 0.0
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gTrue 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: ğŸš€ View run pretty-spaceship-407 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/qmmmx97x
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_203901-qmmmx97x/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_204611-ecx8tbyy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run avid-lion-418
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: ğŸš€ View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/ecx8tbyy
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gTrue â–ˆâ–‚â–‚â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gTrue â–ˆâ–‚â–‚â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gTrue â–ˆâ–‚â–‚â–â–â–â–â–â–â–
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gTrue â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb:                                  Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gTrue 0.0
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gTrue 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: ğŸš€ View run avid-lion-418 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/ecx8tbyy
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_204611-ecx8tbyy/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_205307-m0jhkqiq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run crimson-elevator-429
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: ğŸš€ View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/m0jhkqiq
	 Logging train Loss: 2.0491e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.4776e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.4347e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 9.505e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.404e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 30.089895486831665
Epoch 5/9
	 Logging train Loss: 1.4621e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.558e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.451e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.466e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.422e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 30.324846267700195
Epoch 6/9
	 Logging train Loss: 1.4461e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.1704e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.0815e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.0648e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.625e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 30.157145023345947
Epoch 7/9
	 Logging train Loss: 1.3684e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.556e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.522e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.536e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.483e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 30.20692276954651
Epoch 8/9
	 Logging train Loss: 1.423e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.486e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.448e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.474e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.437e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 30.058571815490723
Epoch 9/9
	 Logging train Loss: 6.363e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.217e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 7.995e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 4.697e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.05e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 30.39513659477234
Saved model in  trained_models/gru/data_t(5,20)_r(0,0)_combi_pNone_gTrue/'quat_1'_'False'.pth
It took  430.3199577331543  seconds.
----- ITERATION 3/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gTrue took 49.62938189506531 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(0,0)_tennis_pNone_gTrue took 12.875809669494629 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_semi_pNone_gTrue took 12.861320734024048 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gTrue took 12.660017728805542 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_full_pNone_gTrue took 12.77543568611145 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0002428081 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.61785e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.69229e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.71255e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.60234e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 30.391539335250854
Epoch 1/9
	 Logging train Loss: 8.452e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.6148e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.7425e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 3.7698e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.6029e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 30.4051411151886
Epoch 2/9
	 Logging train Loss: 3.4054e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.0253e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.0932e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.125e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.0338e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 30.216160774230957
Epoch 3/9
	 Logging train Loss: 2.745e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.0095e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.0343e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.0547e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.0053e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 30.3268084526062
Epoch 4/9
	 Logging train Loss: 2.0398e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.454e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 4.565e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 4.625e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.382e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 30.075885772705078
Epoch 5/9
	 Logging train Loss: 1.6956e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.166e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.223e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.227e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.092e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 30.337501049041748
Epoch 6/9
	 Logging train Loss: 1.2941e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.677e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.718e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.652e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.515e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 30.2631516456604
Epoch 7/9
	 Logging train Loss: 1.1665e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.324e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 6.549e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 4.162e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.891e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 30.134298086166382
Epoch 8/9
	 Logging train Loss: 1.5273e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.1354e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.1142e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 7.578e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.093e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 30.526583671569824
Epoch 9/9
	 Logging train Loss: 4.863e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.434e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 7.477e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 4.83e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.235e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 30.364527463912964
Saved model in  trained_models/gru/data_t(5,20)_r(0,0)_combi_pNone_gTrue/'quat_1'_'False'.pth
It took  415.9948151111603  seconds.
----- ITERATION 4/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gTrue took 49.8529109954834 seconds.
-- Finished Train Dataloader --
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gTrue â–ˆâ–‚â–‚â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gTrue â–ˆâ–‚â–‚â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gTrue â–ˆâ–‚â–‚â–â–â–â–‚â–â–â–
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gTrue â–ˆâ–‚â–‚â–â–â–â–‚â–â–â–
wandb:                                  Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gTrue 0.0
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gTrue 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: ğŸš€ View run crimson-elevator-429 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/m0jhkqiq
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_205307-m0jhkqiq/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_210006-op2qjre9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run effortless-resonance-441
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: ğŸš€ View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/op2qjre9
The dataloader for data/data_t(5,20)_r(0,0)_tennis_pNone_gTrue took 12.808927297592163 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_semi_pNone_gTrue took 12.779696941375732 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gTrue took 12.632293701171875 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_full_pNone_gTrue took 12.803224802017212 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0002340074 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.73279e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.70413e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.73844e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.75172e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 30.40149998664856
Epoch 1/9
	 Logging train Loss: 1.13827e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.7532e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.6967e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 3.7488e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.7451e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 29.907712936401367
Epoch 2/9
	 Logging train Loss: 3.7509e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.1993e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.1646e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.192e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.1928e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 30.249325275421143
Epoch 3/9
	 Logging train Loss: 3.5459e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.276e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.2642e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.2674e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.2645e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 30.358609676361084
Epoch 4/9
	 Logging train Loss: 2.8549e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.93e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 6.935e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 6.827e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.749e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 30.22078251838684
Epoch 5/9
	 Logging train Loss: 2.0428e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.616e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.645e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 3.54e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.461e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 30.43900752067566
Epoch 6/9
	 Logging train Loss: 9.34e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.5983e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.3818e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.9876e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.146e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 30.232967853546143
Epoch 7/9
	 Logging train Loss: 1.3299e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.0459e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.9215e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.1499e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.013e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 30.519043445587158
Epoch 8/9
	 Logging train Loss: 9.159e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.1843e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.1486e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.0198e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.71e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 30.50091791152954
Epoch 9/9
	 Logging train Loss: 9.318e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.625e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.642e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.623e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.587e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 31.697104930877686
Saved model in  trained_models/gru/data_t(5,20)_r(0,0)_combi_pNone_gTrue/'quat_1'_'False'.pth
It took  418.17063426971436  seconds.
----- ITERATION 5/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gTrue took 51.36963987350464 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(0,0)_tennis_pNone_gTrue took 12.932196855545044 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_semi_pNone_gTrue took 12.940622091293335 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gTrue took 12.865348815917969 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_full_pNone_gTrue took 12.961631059646606 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.000334289 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.13026e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.06192e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 3.16733e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.1088e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 30.51210641860962
Epoch 1/9
	 Logging train Loss: 1.16716e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.1805e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 4.0622e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 4.1665e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.1168e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 30.361570119857788
Epoch 2/9
	 Logging train Loss: 3.4094e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.3168e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 5.0355e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 4.1573e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.6868e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 30.3897807598114
Epoch 3/9
	 Logging train Loss: 3.958e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.5295e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.4957e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.5155e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.5412e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 30.19165873527527
Epoch 4/9
	 Logging train Loss: 1.8589e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.989e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 7.817e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 7.78e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.053e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 30.398657083511353
Epoch 5/9
	 Logging train Loss: 2.757e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.66e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gTrue â–‡â–‚â–‚â–â–â–â–â–ˆâ–â–
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gTrue â–ˆâ–‚â–‚â–â–â–â–â–‚â–â–
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gTrue â–…â–â–‚â–â–â–â–â–ˆâ–â–
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gTrue â–„â–â–‚â–â–â–â–â–ˆâ–â–
wandb:                                  Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gTrue 0.0
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gTrue 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: ğŸš€ View run effortless-resonance-441 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/op2qjre9
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_210006-op2qjre9/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_210708-r5o9djsr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rosy-donkey-451
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: ğŸš€ View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/r5o9djsr
slurmstepd: error: *** STEP 3085869.0 ON gcn29 CANCELLED AT 2023-07-16T21:09:10 ***
slurmstepd: error: *** JOB 3085869 ON gcn29 CANCELLED AT 2023-07-16T21:09:10 ***

JOB STATISTICS
==============
Job ID: 3085869
Array Job ID: 3085846_66
Cluster: snellius
User/Group: nreints/nreints
State: CANCELLED (exit code 0)
Nodes: 1
Cores per node: 18
CPU Utilized: 00:39:49
CPU Efficiency: 5.93% of 11:11:42 core-walltime
Job Wall-clock time: 00:37:19
Memory Utilized: 8.04 GB
Memory Efficiency: 0.00% of 0.00 MB
