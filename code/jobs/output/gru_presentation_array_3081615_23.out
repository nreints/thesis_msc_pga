wandb: Currently logged in as: nreints. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_125106-hizu4gx7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run valiant-fog-1
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/hizu4gx7
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue â–ˆâ–„â–‚â–‚â–â–â–â–â–â–
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue â–ˆâ–ƒâ–‚â–‚â–â–â–‚â–â–â–
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue â–ˆâ–„â–‚â–‚â–‚â–â–â–â–â–
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue 0.00148
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 2e-05
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.00125
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.0083
wandb:                                 Train loss 0.00012
wandb: 
wandb: ðŸš€ View run valiant-fog-1 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/hizu4gx7
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_125106-hizu4gx7/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_125832-s4f23d6a
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run scarlet-voice-52
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/s4f23d6a
Training on dataset: data_t(0,0)_r(0,0)_combi_pTrue_gTrue
Testing on 4 datasets: ['data_t(0,0)_r(0,0)_combi_pTrue_gTrue', 'data_t(0,0)_r(0,0)_semi_pTrue_gTrue', 'data_t(0,0)_r(0,0)_tennis_pTrue_gTrue', 'data_t(0,0)_r(0,0)_full_pTrue_gTrue']
Focussing on identity: False
Using extra input: False
Using start-fr as reference point.
----- ITERATION 1/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 77.5527286529541 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 19.40120792388916 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 19.37321376800537 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 19.752206802368164 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 19.968968868255615 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(24, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=24, bias=True)
)
Datatype: pos_diff_start
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.1156367958 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0179047156 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.015516568 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0764563084 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.000380557 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 28.316940307617188
Epoch 1/9
	 Logging train Loss: 0.0048097139 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0073631145 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0063141361 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.032707803 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0001200297 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 27.794833421707153
Epoch 2/9
	 Logging train Loss: 0.0012715507 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0045941146 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0041423272 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0212538783 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 4.91308e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 27.774511575698853
Epoch 3/9
	 Logging train Loss: 0.0005466178 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0032103145 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0030352087 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0162189975 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 5.12737e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 27.263142824172974
Epoch 4/9
	 Logging train Loss: 0.0003181629 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0025627955 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0022521662 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0133079281 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.17745e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 27.377608060836792
Epoch 5/9
	 Logging train Loss: 0.0002322217 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0022433402 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0019729245 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0114599885 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.86627e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 27.633487701416016
Epoch 6/9
	 Logging train Loss: 0.0001836717 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0020552671 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0018189321 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0104293907 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 6.36989e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 27.55023455619812
Epoch 7/9
	 Logging train Loss: 0.0001605919 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0017493555 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0016406813 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0094093671 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.54444e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 27.377365827560425
Epoch 8/9
	 Logging train Loss: 0.0001347686 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0016517842 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0014321007 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0090524983 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.52781e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 27.283926486968994
Epoch 9/9
	 Logging train Loss: 0.0001160394 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0014801369 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0012541619 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0082952771 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.28868e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 27.71791696548462
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pTrue_gTrue/'pos_diff_start'_'False'.pth
It took  447.1708016395569  seconds.
----- ITERATION 2/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 76.61847686767578 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 19.188969612121582 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 19.32749605178833 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 19.418737411499023 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 19.360082149505615 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(24, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=24, bias=True)
)
Datatype: pos_diff_start
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.1217634231 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0224821717 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0118832057 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.1115358993 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0004132629 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 27.613818645477295
Epoch 1/9
	 Logging train Loss: 0.0052655777 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0090581197 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0039431914 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.05325903 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0001527409 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 27.545737266540527
Epoch 2/9
	 Logging train Loss: 0.0013060482 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0051596728 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0023173077 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0362506583 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 7.17187e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 27.610228776931763
Epoch 3/9
	 Logging train Loss: 0.0005537851 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0036515784 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0016718702 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0286743529 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 5.92585e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue â–ˆâ–„â–‚â–‚â–â–â–â–â–â–
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue â–ˆâ–ƒâ–‚â–‚â–â–‚â–â–â–â–
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue â–ˆâ–„â–‚â–‚â–‚â–â–â–â–â–
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue 0.00155
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 3e-05
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.00076
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.01771
wandb:                                 Train loss 0.00012
wandb: 
wandb: ðŸš€ View run scarlet-voice-52 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/s4f23d6a
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_125832-s4f23d6a/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_130553-t5v43vqw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run peach-disco-91
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/t5v43vqw
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue â–ˆâ–„â–‚â–‚â–‚â–â–â–â–â–
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue â–ˆâ–ƒâ–ƒâ–‚â–â–â–â–â–â–
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue â–ˆâ–ƒâ–‚â–‚â–‚â–â–â–â–â–
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue 0.00412
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 1e-05
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.00102
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.01619
wandb:                                 Train loss 0.00011
wandb: 
wandb: ðŸš€ View run peach-disco-91 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/t5v43vqw
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_130553-t5v43vqw/logs
		--> Epoch time; 27.58035945892334
Epoch 4/9
	 Logging train Loss: 0.0003219839 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0028322842 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0013558895 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0244822055 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 3.02531e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 27.537498950958252
Epoch 5/9
	 Logging train Loss: 0.0002270488 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0023362068 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0011773085 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0223604031 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 4.72899e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 27.674482822418213
Epoch 6/9
	 Logging train Loss: 0.0001922961 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0020397536 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0010135261 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0209003426 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.70539e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 27.518964529037476
Epoch 7/9
	 Logging train Loss: 0.0001459237 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0018396883 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0009653363 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0194692668 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 3.64392e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 27.73209500312805
Epoch 8/9
	 Logging train Loss: 0.00013848 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0016266974 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0007700758 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0185122862 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.73304e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 27.42069697380066
Epoch 9/9
	 Logging train Loss: 0.0001186417 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0015469651 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0007561889 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0177060757 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.63934e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 27.495545625686646
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pTrue_gTrue/'pos_diff_start'_'False'.pth
It took  440.96012330055237  seconds.
----- ITERATION 3/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 76.75214099884033 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 19.19621706008911 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 19.318090200424194 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 19.303104400634766 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 19.320316314697266 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(24, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=24, bias=True)
)
Datatype: pos_diff_start
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.1064183339 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0262474753 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0153403133 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.101837039 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0003792274 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 27.522663593292236
Epoch 1/9
	 Logging train Loss: 0.0046822 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0123016965 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0052054008 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0461656041 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0001432013 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 27.90260338783264
Epoch 2/9
	 Logging train Loss: 0.0011206919 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0086012483 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0031025759 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0316981636 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 9.60867e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 27.829836130142212
Epoch 3/9
	 Logging train Loss: 0.0004905792 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0069315392 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0021987422 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0252466146 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 4.00999e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 27.450448989868164
Epoch 4/9
	 Logging train Loss: 0.0002932505 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0060112411 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0018039985 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0228728931 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 3.03547e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 27.39163637161255
Epoch 5/9
	 Logging train Loss: 0.0002091593 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0052669635 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0015259596 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0208745599 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.17563e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 27.531070232391357
Epoch 6/9
	 Logging train Loss: 0.0001701656 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.004966361 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0014154278 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0193140637 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.64555e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 27.598819255828857
Epoch 7/9
	 Logging train Loss: 0.0001448714 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.004679611 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0013242377 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0188574083 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.88863e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 27.72366213798523
Epoch 8/9
	 Logging train Loss: 0.0001316165 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0044940221 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0011662963 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0175128337 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.31387e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 27.587157726287842
Epoch 9/9
	 Logging train Loss: 0.0001115905 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0041150535 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0010151729 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0161915962 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.31374e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 27.59337306022644
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pTrue_gTrue/'pos_diff_start'_'False'.pth
It took  441.0933780670166  seconds.
----- ITERATION 4/10 ------
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_131314-kxe7r7qv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fanciful-snow-122
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/kxe7r7qv
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue â–ˆâ–„â–‚â–‚â–‚â–â–â–â–â–
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue â–ˆâ–ƒâ–‚â–â–â–â–â–â–‚â–
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue â–ˆâ–„â–‚â–‚â–‚â–â–â–â–â–
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue 0.00486
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 1e-05
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.00071
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.00617
wandb:                                 Train loss 0.00012
wandb: 
wandb: ðŸš€ View run fanciful-snow-122 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/kxe7r7qv
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_131314-kxe7r7qv/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_132037-1qpj8e14
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wise-river-160
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/1qpj8e14
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 76.74093747138977 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 19.14955997467041 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 19.210483074188232 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 19.258710145950317 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 19.248868703842163 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(24, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=24, bias=True)
)
Datatype: pos_diff_start
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.1208651364 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0246631149 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0090230079 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0360472798 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0004118878 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 27.77107334136963
Epoch 1/9
	 Logging train Loss: 0.0053109447 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0125633543 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0032977066 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0174551904 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.00013703 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 27.35127902030945
Epoch 2/9
	 Logging train Loss: 0.0013598991 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0087846993 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0020692935 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0120778903 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 6.40904e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 27.746943473815918
Epoch 3/9
	 Logging train Loss: 0.0005676366 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0075832577 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0015178773 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0100030592 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 3.49831e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 27.635645389556885
Epoch 4/9
	 Logging train Loss: 0.0003434875 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.00669702 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0011971658 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.008914317 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 3.20755e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 27.712215423583984
Epoch 5/9
	 Logging train Loss: 0.0002282188 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.005985559 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0010830867 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.007847351 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.9236e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 27.527997970581055
Epoch 6/9
	 Logging train Loss: 0.0001897653 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0056987698 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0010303948 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0074082711 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.92817e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 27.572020292282104
Epoch 7/9
	 Logging train Loss: 0.0001569193 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0054190815 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0008905166 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0069115213 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.20634e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 27.682265996932983
Epoch 8/9
	 Logging train Loss: 0.0001504716 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0048682056 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.000857171 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0062820818 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 5.75649e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 27.821574926376343
Epoch 9/9
	 Logging train Loss: 0.0001213607 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.004864824 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0007075454 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.006170976 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.15914e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 27.529217958450317
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pTrue_gTrue/'pos_diff_start'_'False'.pth
It took  442.64644479751587  seconds.
----- ITERATION 5/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 76.7182366847992 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 19.20133376121521 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 19.30835747718811 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 19.326195001602173 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 19.301968097686768 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(24, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=24, bias=True)
)
Datatype: pos_diff_start
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.1249054521 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0062726648 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0254361872 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0831031799 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0004101215 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 27.849979162216187
Epoch 1/9
	 Logging train Loss: 0.0053553507 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0026636429 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0102120107 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0369645469 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0001466336 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 27.680800676345825
Epoch 2/9
	 Logging train Loss: 0.001361619 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0017034824 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0061367094 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0252569746 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 6.70398e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 27.592263221740723
Epoch 3/9
	 Logging train Loss: 0.0005957621 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0014136974 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0045372001 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0206035525 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 3.38022e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 27.5928373336792
Epoch 4/9
	 Logging train Loss: 0.0003542735 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0011145948 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0035133653 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0174893737 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue â–ˆâ–ƒâ–‚â–‚â–‚â–â–â–â–â–
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue â–ˆâ–ƒâ–‚â–â–‚â–â–â–â–â–
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue 0.00075
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 3e-05
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.00215
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.01253
wandb:                                 Train loss 0.00015
wandb: 
wandb: ðŸš€ View run wise-river-160 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/1qpj8e14
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_132037-1qpj8e14/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_132800-2n6u0tq5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run blooming-armadillo-197
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/2n6u0tq5
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue â–ˆâ–„â–ƒâ–‚â–‚â–‚â–â–â–â–
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue â–ˆâ–„â–„â–ƒâ–â–â–â–â–â–
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue â–ˆâ–„â–‚â–‚â–‚â–â–â–â–â–
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue 0.00113
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 1e-05
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.00096
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.01784
wandb:                                 Train loss 0.00014
wandb: 
wandb: ðŸš€ View run blooming-armadillo-197 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/2n6u0tq5
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_132800-2n6u0tq5/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_133523-k1guh5iw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sandy-sky-230
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/k1guh5iw
	 Logging test loss: 5.01362e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 27.50420379638672
Epoch 5/9
	 Logging train Loss: 0.0002545331 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.000948838 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0030205052 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0159810819 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.68277e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 27.710726976394653
Epoch 6/9
	 Logging train Loss: 0.000206401 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0008381124 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0026556668 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0146798436 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.5527e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 27.742218732833862
Epoch 7/9
	 Logging train Loss: 0.0001750925 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0008310761 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0024553277 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0138296923 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 3.06133e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 27.85800576210022
Epoch 8/9
	 Logging train Loss: 0.0001526023 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0007125913 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0022654235 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.012552673 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.59733e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 27.431009769439697
Epoch 9/9
	 Logging train Loss: 0.0001466752 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0007453123 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0021508762 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0125347041 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 3.1236e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 27.74600338935852
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pTrue_gTrue/'pos_diff_start'_'False'.pth
It took  443.03477478027344  seconds.
----- ITERATION 6/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 76.8944890499115 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 19.25080394744873 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 19.284457445144653 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 19.273092031478882 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 19.27928400039673 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(24, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=24, bias=True)
)
Datatype: pos_diff_start
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.1304984689 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0086011747 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0144631583 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.1058558449 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0003292225 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 27.584102869033813
Epoch 1/9
	 Logging train Loss: 0.0057226112 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0042599854 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0047230511 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0513646789 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0001368689 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 27.821845531463623
Epoch 2/9
	 Logging train Loss: 0.0014713978 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0029609937 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0029053763 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0356218256 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0001440251 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 27.6944580078125
Epoch 3/9
	 Logging train Loss: 0.0006185927 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0024001373 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0021961951 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0285645239 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0001078816 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 27.730793237686157
Epoch 4/9
	 Logging train Loss: 0.0003637677 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.001996628 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0016737018 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0253872611 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.13856e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 27.60589075088501
Epoch 5/9
	 Logging train Loss: 0.0002520881 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0017897097 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0013944521 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0227806047 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.93834e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 27.914644718170166
Epoch 6/9
	 Logging train Loss: 0.000201046 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0015719258 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0013648184 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0214788336 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.17766e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 27.510329723358154
Epoch 7/9
	 Logging train Loss: 0.0001836641 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0013515234 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0012125267 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0193193182 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.84693e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 27.64613914489746
Epoch 8/9
	 Logging train Loss: 0.0001430434 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0012800469 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0010990028 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0189627577 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 3.23559e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 27.74250340461731
Epoch 9/9
	 Logging train Loss: 0.0001407472 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0011304974 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.000959671 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0178448651 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 9.8618e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 27.656408548355103
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pTrue_gTrue/'pos_diff_start'_'False'.pth
It took  443.001531124115  seconds.
----- ITERATION 7/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 76.87552690505981 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 19.169424295425415 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 19.22689127922058 seconds.
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue â–ˆâ–„â–‚â–‚â–‚â–â–â–â–â–
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue 0.00274
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 2e-05
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.00065
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.00643
wandb:                                 Train loss 0.00011
wandb: 
wandb: ðŸš€ View run sandy-sky-230 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/k1guh5iw
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_133523-k1guh5iw/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_134244-dzoy4t2q
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run whole-paper-267
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/dzoy4t2q
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 19.21215033531189 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 19.332256078720093 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(24, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=24, bias=True)
)
Datatype: pos_diff_start
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.1127115563 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0305853393 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0088906223 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0654475391 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0004130255 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 27.408998727798462
Epoch 1/9
	 Logging train Loss: 0.0049853348 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0125728939 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0029830243 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0275759082 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0001062222 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 27.828304290771484
Epoch 2/9
	 Logging train Loss: 0.001238481 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.007599439 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0019068317 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0174774267 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 4.84637e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 27.57776379585266
Epoch 3/9
	 Logging train Loss: 0.0004980863 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0056259045 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0014251601 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0131094186 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 5.8776e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 27.526769876480103
Epoch 4/9
	 Logging train Loss: 0.0002894147 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0046250359 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0011436652 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0110714883 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.16266e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 27.431509017944336
Epoch 5/9
	 Logging train Loss: 0.0002079723 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0040270081 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0010051895 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0094360951 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.76541e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 27.57370638847351
Epoch 6/9
	 Logging train Loss: 0.0001775402 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0036256816 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0008820412 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0086352825 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.52803e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 27.49966287612915
Epoch 7/9
	 Logging train Loss: 0.0001375522 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0031964842 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0008139446 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0077065038 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 3.60575e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 27.786659240722656
Epoch 8/9
	 Logging train Loss: 0.0001241288 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0030877565 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0008059443 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0074067903 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.36717e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 27.64461660385132
Epoch 9/9
	 Logging train Loss: 0.0001147124 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0027370965 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0006544304 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0064313351 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.25851e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 27.567042589187622
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pTrue_gTrue/'pos_diff_start'_'False'.pth
It took  441.30338287353516  seconds.
----- ITERATION 8/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 76.92235565185547 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 19.192196130752563 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 19.201116800308228 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 19.227778434753418 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 19.238415479660034 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(24, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=24, bias=True)
)
Datatype: pos_diff_start
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.1167009175 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.033278279 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.023015881 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0964635387 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0004464074 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 28.18617033958435
Epoch 1/9
	 Logging train Loss: 0.0049069244 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0145728067 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0097299386 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0466019511 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.000165139 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 28.153992176055908
Epoch 2/9
	 Logging train Loss: 0.0011893228 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0096493624 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0065834569 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0324665084 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 7.25984e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 27.640354871749878
Epoch 3/9
	 Logging train Loss: 0.0004889762 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0075346869 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0053314189 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0272179563 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 4.70659e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 27.467565298080444
Epoch 4/9
	 Logging train Loss: 0.0002959706 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0063030664 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0048302962 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0243437532 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 4.54166e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 27.40475821495056
Epoch 5/9
	 Logging train Loss: 0.000208751 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0057159336 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0044806176 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue â–ˆâ–„â–‚â–‚â–‚â–â–â–â–â–
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue â–ˆâ–ƒâ–‚â–‚â–â–„â–â–â–â–
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue â–ˆâ–ƒâ–‚â–‚â–‚â–â–â–â–â–
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue â–ˆâ–„â–‚â–‚â–‚â–â–â–â–â–
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue 0.00411
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 2e-05
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.00314
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.01756
wandb:                                 Train loss 0.00011
wandb: 
wandb: ðŸš€ View run whole-paper-267 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/dzoy4t2q
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_134244-dzoy4t2q/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_135005-0l3vxcy7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run flowing-pond-305
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/0l3vxcy7
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue â–ˆâ–„â–‚â–‚â–‚â–‚â–â–â–â–
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue â–ˆâ–ƒâ–‚â–‚â–â–â–â–‚â–â–
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue â–ˆâ–„â–‚â–‚â–‚â–â–â–â–â–
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue 0.00437
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 1e-05
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.00129
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.0198
wandb:                                 Train loss 0.00012
wandb: 
wandb: ðŸš€ View run flowing-pond-305 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/0l3vxcy7
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_135005-0l3vxcy7/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_135726-phscrab0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run icy-lion-336
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/phscrab0
	 Logging test loss: 0.0221187044 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0001884281 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 27.59166383743286
Epoch 6/9
	 Logging train Loss: 0.0001717205 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0050872155 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0039595268 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.020719802 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 3.96946e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 27.679226875305176
Epoch 7/9
	 Logging train Loss: 0.0001526076 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0044882391 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0034757974 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0193871874 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.30939e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 27.470667362213135
Epoch 8/9
	 Logging train Loss: 0.0001270509 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0045201257 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0032821151 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0185615364 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.89123e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 27.36739230155945
Epoch 9/9
	 Logging train Loss: 0.0001097719 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0041141454 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0031396255 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0175587945 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.59837e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 27.285778999328613
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pTrue_gTrue/'pos_diff_start'_'False'.pth
It took  440.9844739437103  seconds.
----- ITERATION 9/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 76.48308229446411 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 19.126487016677856 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 19.211302280426025 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 19.179189205169678 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 19.172233819961548 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(24, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=24, bias=True)
)
Datatype: pos_diff_start
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.118009299 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0186177343 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0130310897 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0936475694 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0003460193 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 27.38143539428711
Epoch 1/9
	 Logging train Loss: 0.0052979416 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0096719386 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0046422589 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0475259311 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0001147114 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 27.69813561439514
Epoch 2/9
	 Logging train Loss: 0.0012748919 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0072096302 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0030227771 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.034195587 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 7.24984e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 27.47973108291626
Epoch 3/9
	 Logging train Loss: 0.0005153571 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.00651892 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0025490925 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0307280477 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 4.23298e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 27.56957173347473
Epoch 4/9
	 Logging train Loss: 0.000327525 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0059915134 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0020584557 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0273412298 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 3.1364e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 27.683069944381714
Epoch 5/9
	 Logging train Loss: 0.0002257424 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0055378061 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0018788916 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0246327948 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.72205e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 27.290669202804565
Epoch 6/9
	 Logging train Loss: 0.0001818325 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0051781824 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0016735289 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0228486992 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.72612e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 27.35820245742798
Epoch 7/9
	 Logging train Loss: 0.0001587453 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.004894916 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0015002774 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.021412652 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 4.43678e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 27.647075653076172
Epoch 8/9
	 Logging train Loss: 0.0001435412 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.004735074 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0014784398 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0205200147 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.84731e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 27.654673099517822
Epoch 9/9
	 Logging train Loss: 0.0001218746 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0043669231 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0012942626 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0198015198 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.46795e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 27.439660787582397
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pTrue_gTrue/'pos_diff_start'_'False'.pth
It took  441.12122201919556  seconds.
----- ITERATION 10/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 76.03848814964294 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 19.15293526649475 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 19.176183700561523 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 19.213430881500244 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 19.203580856323242 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(24, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=24, bias=True)
)
Datatype: pos_diff_start
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue â–ˆâ–ƒâ–ƒâ–‚â–‚â–‚â–â–â–â–
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue â–ˆâ–ƒâ–‚â–â–‚â–‚â–â–â–â–
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue â–ˆâ–ƒâ–‚â–‚â–‚â–‚â–â–â–â–
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue â–ˆâ–„â–‚â–‚â–‚â–â–â–â–â–
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue 0.00125
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 1e-05
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.00223
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.00916
wandb:                                 Train loss 0.00011
wandb: 
wandb: ðŸš€ View run icy-lion-336 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/phscrab0
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_135726-phscrab0/logs
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.1209747493 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0070604919 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0142381685 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.065195404 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0004411374 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 27.34752345085144
Epoch 1/9
	 Logging train Loss: 0.0052549695 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.003297946 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.006160228 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0295094326 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0001634762 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 28.09911584854126
Epoch 2/9
	 Logging train Loss: 0.001341152 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0027014758 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0045245285 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0202551764 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 6.85776e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 28.150866508483887
Epoch 3/9
	 Logging train Loss: 0.0005650047 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0020572764 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0036239054 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0151646743 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 4.20081e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 27.621386528015137
Epoch 4/9
	 Logging train Loss: 0.0003341227 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0018794927 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0036034449 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0133967465 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 6.2878e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 27.42156171798706
Epoch 5/9
	 Logging train Loss: 0.0002415015 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0018495026 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.003455952 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.012850319 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 5.75957e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 27.580567836761475
Epoch 6/9
	 Logging train Loss: 0.000201658 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0014514129 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0028373045 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0108359717 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 3.21774e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 27.430716514587402
Epoch 7/9
	 Logging train Loss: 0.0001726071 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0013535756 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0026638412 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0100528188 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.43177e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 27.56471562385559
Epoch 8/9
	 Logging train Loss: 0.0001570119 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0012971418 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0024286734 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0096462546 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.34446e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 27.62458300590515
Epoch 9/9
	 Logging train Loss: 0.0001104484 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0012495815 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0022308039 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0091612404 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.23007e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 27.445605278015137
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pTrue_gTrue/'pos_diff_start'_'False'.pth
It took  440.04989671707153  seconds.

JOB STATISTICS
==============
Job ID: 3081636
Array Job ID: 3081615_23
Cluster: snellius
User/Group: nreints/nreints
State: RUNNING
Nodes: 1
Cores per node: 18
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 22:10:12 core-walltime
Job Wall-clock time: 01:13:54
Memory Utilized: 0.00 MB (estimated maximum)
Memory Efficiency: 0.00% of 0.00 MB (0.00 MB/node)
WARNING: Efficiency statistics may be misleading for RUNNING jobs.
