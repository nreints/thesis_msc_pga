wandb: Currently logged in as: nreints. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_231701-h68g5kr5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run generous-serenity-1147
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/h68g5kr5
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–‚â–
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–‚â–
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–‚â–
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue 0.0
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue 0.0
wandb:                                 Train loss 1e-05
wandb: 
wandb: ðŸš€ View run generous-serenity-1147 at: https://wandb.ai/nreints/ThesisFinal2/runs/h68g5kr5
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_231701-h68g5kr5/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_232934-bvsxn5x2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run azure-yogurt-1164
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/bvsxn5x2
Training on dataset: data_t(0,0)_r(0,0)_combi_pNone_gTrue
Testing on 4 datasets: ['data_t(0,0)_r(0,0)_semi_pNone_gTrue', 'data_t(0,0)_r(0,0)_full_pNone_gTrue', 'data_t(0,0)_r(0,0)_combi_pNone_gTrue', 'data_t(0,0)_r(0,0)_tennis_pNone_gTrue']
Focussing on identity: False
Using extra input: False
Using start-fr as reference point.
----- ITERATION 1/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 79.07906913757324 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_semi_pNone_gTrue took 19.719996452331543 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pNone_gTrue took 19.812384605407715 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 20.07261610031128 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pNone_gTrue took 20.188788890838623 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0745993406 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.17155e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 7.17356e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 7.65858e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.24766e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 57.77516222000122
Epoch 1/9
	 Logging train Loss: 2.9918e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.23057e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.94441e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.08373e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.24819e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 56.61969828605652
Epoch 2/9
	 Logging train Loss: 1.71807e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.45663e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.28997e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.3721e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.46568e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 56.87958097457886
Epoch 3/9
	 Logging train Loss: 1.1337e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 9.6805e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 8.5259e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 9.1008e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 9.7112e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 56.515878200531006
Epoch 4/9
	 Logging train Loss: 1.07173e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.9757e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 6.1057e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 6.55e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.0251e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 56.9234414100647
Epoch 5/9
	 Logging train Loss: 1.2366e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.2273e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 4.9032e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 5.0676e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.2435e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 56.86520028114319
Epoch 6/9
	 Logging train Loss: 1.20411e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.5734e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 4.399e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 4.4846e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.5799e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 56.740373849868774
Epoch 7/9
	 Logging train Loss: 9.9192e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.9669e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 5.9501e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 6.4574e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.0636e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 56.63904809951782
Epoch 8/9
	 Logging train Loss: 1.26479e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.98526e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 4.5132e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.2612e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.02855e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 56.618183612823486
Epoch 9/9
	 Logging train Loss: 1.4022e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.4982e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 3.4377e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.467e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.4992e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 56.69591236114502
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'rot_mat'_'False'.pth
It took  754.0568809509277  seconds.
----- ITERATION 2/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 78.34819412231445 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_semi_pNone_gTrue took 19.598173141479492 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pNone_gTrue took 19.589786767959595 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 19.593297481536865 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pNone_gTrue took 19.64393186569214 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0651538 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.47324e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 5.77036e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 6.65358e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.60306e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 56.0797381401062
Epoch 1/9
	 Logging train Loss: 3.96411e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.26411e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.81866e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.04723e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.2966e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 56.019522190093994
Epoch 2/9
	 Logging train Loss: 2.49173e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.10149e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.89322e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.00348e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.12218e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 56.004817485809326
Epoch 3/9
	 Logging train Loss: 1.66347e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.38884e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.28443e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.33863e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.40053e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 56.03860259056091
Epoch 4/9
	 Logging train Loss: 1.48481e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue â–…â–ƒâ–‚â–‚â–â–â–ˆâ–â–â–
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue â–ˆâ–„â–ƒâ–‚â–‚â–â–†â–â–â–
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue â–„â–‚â–‚â–â–â–â–ˆâ–â–â–
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue â–„â–‚â–‚â–â–â–â–ˆâ–â–â–
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue 0.0
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue 0.0
wandb:                                 Train loss 1e-05
wandb: 
wandb: ðŸš€ View run azure-yogurt-1164 at: https://wandb.ai/nreints/ThesisFinal2/runs/bvsxn5x2
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_232934-bvsxn5x2/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_234201-8w35uu15
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vivid-tree-1180
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/8w35uu15
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue â–ˆâ–â–â–â–â–â–â–â–â–‚
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue â–ˆâ–â–â–â–â–â–â–â–â–‚
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue â–ˆâ–â–â–â–â–â–â–â–â–‚
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue â–ˆâ–â–â–â–â–â–â–â–â–‚
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 7e-05
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue 6e-05
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue 8e-05
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue 8e-05
wandb:                                 Train loss 1e-05
wandb: 
wandb: ðŸš€ View run vivid-tree-1180 at: https://wandb.ai/nreints/ThesisFinal2/runs/8w35uu15
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_234201-8w35uu15/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_235407-5bq1maoj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run youthful-voice-1192
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/5bq1maoj
	 Logging test loss: 9.3883e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 8.9388e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 9.1783e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 9.4327e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 56.03234386444092
Epoch 5/9
	 Logging train Loss: 1.37223e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.233e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 7.0532e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 7.1446e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.2457e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 56.24125695228577
Epoch 6/9
	 Logging train Loss: 1.93959e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.000179799 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 4.00312e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 0.0001173663 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0001977159 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 55.92140054702759
Epoch 7/9
	 Logging train Loss: 8.1809e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.6002e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 6.4186e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 6.5127e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.6157e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 55.61245918273926
Epoch 8/9
	 Logging train Loss: 1.24357e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 9.2096e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 5.6242e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 7.312e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 9.2392e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 55.30708646774292
Epoch 9/9
	 Logging train Loss: 1.2596e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.8467e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 3.803e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.8244e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.8545e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 55.18812108039856
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'rot_mat'_'False'.pth
It took  746.5043694972992  seconds.
----- ITERATION 3/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 75.9422492980957 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_semi_pNone_gTrue took 19.511032342910767 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pNone_gTrue took 19.502057790756226 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 19.433343410491943 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pNone_gTrue took 19.539217710494995 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.099900268 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0006196767 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 0.0005946921 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 0.0006060493 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.000621497 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 56.572725772857666
Epoch 1/9
	 Logging train Loss: 9.26781e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.34105e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.75007e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.01745e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.37564e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 56.5818727016449
Epoch 2/9
	 Logging train Loss: 2.4839e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.19128e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.82382e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.98801e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.21518e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 56.23888945579529
Epoch 3/9
	 Logging train Loss: 1.70073e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.51526e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.31778e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.40487e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.52697e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 56.39769768714905
Epoch 4/9
	 Logging train Loss: 1.23737e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.08711e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 9.9933e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.0372e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.09238e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 55.948769330978394
Epoch 5/9
	 Logging train Loss: 9.4325e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.9137e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 8.0145e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 8.4169e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.9606e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 56.42872166633606
Epoch 6/9
	 Logging train Loss: 1.18365e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.9712e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 6.6213e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 6.7788e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.9919e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 56.63262677192688
Epoch 7/9
	 Logging train Loss: 1.5915e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.8316e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 5.6217e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 5.7104e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.8412e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 55.60731101036072
Epoch 8/9
	 Logging train Loss: 1.02341e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.9086e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 4.6955e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 4.7902e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.9197e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 55.77416229248047
Epoch 9/9
	 Logging train Loss: 1.333e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.63323e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 5.93673e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 6.65801e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.75509e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 55.687989473342896
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'rot_mat'_'False'.pth
It took  726.5064158439636  seconds.
----- ITERATION 4/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 77.17858386039734 seconds.
-- Finished Train Dataloader --
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue â–ˆâ–â–â–â–â–â–â–â–â–
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 1e-05
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue 1e-05
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue 2e-05
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue 2e-05
wandb:                                 Train loss 1e-05
wandb: 
wandb: ðŸš€ View run youthful-voice-1192 at: https://wandb.ai/nreints/ThesisFinal2/runs/5bq1maoj
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_235407-5bq1maoj/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230710_000617-dda4pli0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run curious-deluge-1207
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/dda4pli0
The dataloader for data/data_t(0,0)_r(0,0)_semi_pNone_gTrue took 19.612364768981934 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pNone_gTrue took 19.540891885757446 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 19.540725708007812 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pNone_gTrue took 19.539875268936157 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0821476653 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0002580855 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 0.0002367571 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 0.0002478199 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0002593772 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 56.40188503265381
Epoch 1/9
	 Logging train Loss: 5.3807e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.87598e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.2335e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.57452e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.91384e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 56.02905535697937
Epoch 2/9
	 Logging train Loss: 2.05881e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.81415e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.50999e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.67237e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.83314e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 56.320220947265625
Epoch 3/9
	 Logging train Loss: 1.39411e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.24535e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.12174e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.19021e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.25431e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 56.526381731033325
Epoch 4/9
	 Logging train Loss: 1.06529e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.27966e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.22813e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.25535e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.28249e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 56.58001971244812
Epoch 5/9
	 Logging train Loss: 1.07995e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.00503e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 8.347e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 9.2056e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.01328e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 56.24174356460571
Epoch 6/9
	 Logging train Loss: 1.18962e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.34086e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 7.7691e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.06323e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.37709e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 56.08044505119324
Epoch 7/9
	 Logging train Loss: 1.22251e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.28733e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 7.7245e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.57296e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.42981e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 56.330299377441406
Epoch 8/9
	 Logging train Loss: 1.42601e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.1717e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 6.2166e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 6.6905e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.205e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 55.734588861465454
Epoch 9/9
	 Logging train Loss: 1.39919e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.8997e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 8.2171e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.39139e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.00336e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 55.812527894973755
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'rot_mat'_'False'.pth
It took  729.9423532485962  seconds.
----- ITERATION 5/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 76.07634425163269 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_semi_pNone_gTrue took 19.53375220298767 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pNone_gTrue took 19.560024738311768 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 19.26827311515808 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pNone_gTrue took 19.54337191581726 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0741056502 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.3668e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 7.4778e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 7.93113e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.43482e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 57.33201026916504
Epoch 1/9
	 Logging train Loss: 4.7306e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.37757e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 3.18461e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.28314e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.39167e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 56.901902198791504
Epoch 2/9
	 Logging train Loss: 2.90113e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.12487e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.04792e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.08807e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.13047e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 56.64817500114441
Epoch 3/9
	 Logging train Loss: 2.24344e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.44691e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.40796e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.42771e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.44983e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 57.003259897232056
Epoch 4/9
	 Logging train Loss: 1.866e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.0378e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.01281e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.02647e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.04002e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 56.65318155288696
Epoch 5/9
	 Logging train Loss: 1.39877e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.5814e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue â–ˆâ–„â–‚â–‚â–â–â–â–â–â–
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue â–ˆâ–„â–‚â–‚â–â–â–â–â–â–
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 1e-05
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue 1e-05
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue 1e-05
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue 1e-05
wandb:                                 Train loss 1e-05
wandb: 
wandb: ðŸš€ View run curious-deluge-1207 at: https://wandb.ai/nreints/ThesisFinal2/runs/dda4pli0
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230710_000617-dda4pli0/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230710_001830-6e7m8otk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run royal-armadillo-1222
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/6e7m8otk
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue â–ˆâ–„â–ƒâ–‚â–‚â–â–ƒâ–…â–â–†
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue â–ˆâ–„â–ƒâ–‚â–‚â–â–‚â–ƒâ–â–†
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue â–ˆâ–„â–ƒâ–‚â–‚â–â–…â–†â–â–†
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue â–ˆâ–„â–‚â–‚â–‚â–â–…â–†â–â–†
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 4e-05
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue 4e-05
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue 4e-05
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue 4e-05
wandb:                                 Train loss 1e-05
wandb: 
wandb: ðŸš€ View run royal-armadillo-1222 at: https://wandb.ai/nreints/ThesisFinal2/runs/6e7m8otk
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230710_001830-6e7m8otk/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230710_003035-trxiy3ml
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fresh-dust-1235
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/trxiy3ml
	 Logging test loss: 8.4289e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 8.5039e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.5898e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 56.54843068122864
Epoch 6/9
	 Logging train Loss: 1.83464e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.7013e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 7.6078e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 7.6502e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.7025e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 56.372227907180786
Epoch 7/9
	 Logging train Loss: 1.06832e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.1716e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 7.0083e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 7.0933e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.1811e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 56.523019313812256
Epoch 8/9
	 Logging train Loss: 1.29024e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.7704e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 6.1492e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 6.9791e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.9288e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 56.838173151016235
Epoch 9/9
	 Logging train Loss: 1.26018e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.2683e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 7.0692e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 7.169e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.2841e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 56.483848094940186
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'rot_mat'_'False'.pth
It took  732.9622254371643  seconds.
----- ITERATION 6/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 76.11884498596191 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_semi_pNone_gTrue took 19.514123916625977 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pNone_gTrue took 19.520702362060547 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 19.26850390434265 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pNone_gTrue took 19.509751081466675 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0589554459 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.39278e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 4.53223e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 5.0011e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.56573e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 55.617793560028076
Epoch 1/9
	 Logging train Loss: 2.89717e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.30479e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.0695e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.20091e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.3659e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 55.84239077568054
Epoch 2/9
	 Logging train Loss: 1.84046e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.5898e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.49423e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.54661e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.61405e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 55.73868131637573
Epoch 3/9
	 Logging train Loss: 1.33385e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.15983e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.11149e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.13841e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.17232e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 55.528522968292236
Epoch 4/9
	 Logging train Loss: 1.1584e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.44007e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 9.0462e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.19182e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.55383e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 55.26244902610779
Epoch 5/9
	 Logging train Loss: 1.30761e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.898e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 7.6873e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 7.8033e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.9499e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 54.859310150146484
Epoch 6/9
	 Logging train Loss: 1.29927e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.05411e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.00673e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.06821e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.36817e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 54.808955669403076
Epoch 7/9
	 Logging train Loss: 1.56758e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.96794e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.74768e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.00715e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.44383e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 55.00156545639038
Epoch 8/9
	 Logging train Loss: 1.24354e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.4204e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 5.3579e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 5.3907e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.4293e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 55.16706204414368
Epoch 9/9
	 Logging train Loss: 1.30367e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.0815e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 3.57509e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.8489e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.19863e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 55.19588661193848
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'rot_mat'_'False'.pth
It took  724.8117694854736  seconds.
----- ITERATION 7/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 76.22336983680725 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_semi_pNone_gTrue took 19.480817556381226 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pNone_gTrue took 19.420134782791138 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 19.213376998901367 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pNone_gTrue took 19.520408868789673 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat
-- Started Training --
Epoch 0/9
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue â–ˆâ–‚â–‚â–ƒâ–â–â–â–„â–„â–
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue â–ˆâ–‚â–‚â–â–â–â–â–„â–â–
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue â–ˆâ–‚â–‚â–„â–â–‚â–â–„â–†â–
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue â–ˆâ–‚â–‚â–…â–â–‚â–â–„â–‡â–
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 1e-05
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue 1e-05
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue 1e-05
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue 1e-05
wandb:                                 Train loss 1e-05
wandb: 
wandb: ðŸš€ View run fresh-dust-1235 at: https://wandb.ai/nreints/ThesisFinal2/runs/trxiy3ml
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230710_003035-trxiy3ml/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230710_004241-dk7q2555
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run comic-breeze-1240
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/dk7q2555
	 Logging train Loss: 0.0642900169 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 9.19078e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 8.05259e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 8.64213e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 9.35087e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 55.87104034423828
Epoch 1/9
	 Logging train Loss: 3.22628e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.29408e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.11202e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.20726e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.32038e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 56.23956298828125
Epoch 2/9
	 Logging train Loss: 1.78839e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.49513e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.41671e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.45904e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.50745e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 56.311659812927246
Epoch 3/9
	 Logging train Loss: 1.32028e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.6164e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.13302e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.91947e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.09322e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 56.14452815055847
Epoch 4/9
	 Logging train Loss: 1.24455e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.2143e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 7.8767e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 8.0471e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.2649e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 56.50696897506714
Epoch 5/9
	 Logging train Loss: 1.06606e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.49899e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 7.4927e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.15199e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.6403e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 56.32564115524292
Epoch 6/9
	 Logging train Loss: 1.24583e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.2874e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 6.172e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 6.2353e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.3051e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 55.55791878700256
Epoch 7/9
	 Logging train Loss: 1.03122e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.00095e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 3.95988e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.98234e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.00685e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 55.74521541595459
Epoch 8/9
	 Logging train Loss: 1.29813e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.30927e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 7.0421e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.94105e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.04127e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 56.183966875076294
Epoch 9/9
	 Logging train Loss: 1.25687e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.2289e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 6.0237e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 6.1246e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.2522e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 55.7145791053772
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'rot_mat'_'False'.pth
It took  726.4690818786621  seconds.
----- ITERATION 8/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 76.240469455719 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_semi_pNone_gTrue took 19.519474744796753 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pNone_gTrue took 19.485316276550293 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 19.2876558303833 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pNone_gTrue took 19.461997032165527 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0823707804 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0002299065 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 0.000216444 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 0.0002228463 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0002310595 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 56.3279755115509
Epoch 1/9
	 Logging train Loss: 5.35042e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.39418e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 3.11884e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.24847e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.42248e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 56.92612314224243
Epoch 2/9
	 Logging train Loss: 2.70165e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.31374e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.17524e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.24124e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.32976e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 56.64460754394531
Epoch 3/9
	 Logging train Loss: 1.87392e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.53964e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.47435e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.5052e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.54531e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 56.23237919807434
Epoch 4/9
	 Logging train Loss: 1.25583e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.03515e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.00226e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.01779e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.03898e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 56.40478873252869
Epoch 5/9
	 Logging train Loss: 9.5167e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.0286e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 7.8444e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 7.9278e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.042e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 56.793471574783325
Epoch 6/9
	 Logging train Loss: 1.09506e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.05377e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 7.8514e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 9.1197e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue â–ˆâ–‚â–‚â–â–â–â–â–â–â–‚
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue â–ˆâ–‚â–‚â–â–â–â–â–â–â–‚
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue â–ˆâ–‚â–‚â–â–â–â–â–â–â–‚
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue â–ˆâ–‚â–‚â–â–â–â–â–â–â–‚
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 4e-05
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue 4e-05
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue 4e-05
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue 4e-05
wandb:                                 Train loss 1e-05
wandb: 
wandb: ðŸš€ View run comic-breeze-1240 at: https://wandb.ai/nreints/ThesisFinal2/runs/dk7q2555
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230710_004241-dk7q2555/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230710_005459-mffo31ys
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dainty-oath-1242
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/mffo31ys
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue â–ˆâ–„â–‚â–‚â–â–â–â–â–â–„
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–ƒ
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue â–ˆâ–„â–‚â–‚â–â–â–â–â–â–„
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue â–ˆâ–„â–‚â–‚â–â–â–â–â–â–„
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 3e-05
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue 3e-05
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue 4e-05
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue 4e-05
wandb:                                 Train loss 1e-05
wandb: 
wandb: ðŸš€ View run dainty-oath-1242 at: https://wandb.ai/nreints/ThesisFinal2/runs/mffo31ys
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230710_005459-mffo31ys/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230710_010706-q2hhofwa
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stellar-eon-1244
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/q2hhofwa
	 Logging test loss: 1.0809e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 56.51569581031799
Epoch 7/9
	 Logging train Loss: 1.07335e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.3478e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 6.0801e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 6.2151e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.3885e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 56.594021797180176
Epoch 8/9
	 Logging train Loss: 1.18378e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.65905e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 7.5143e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.19079e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.78641e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 56.46226406097412
Epoch 9/9
	 Logging train Loss: 1.20855e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.18183e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 4.0862e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 4.13436e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.20123e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 56.265400886535645
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'rot_mat'_'False'.pth
It took  737.8805928230286  seconds.
----- ITERATION 9/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 76.14794301986694 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_semi_pNone_gTrue took 19.443620920181274 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pNone_gTrue took 19.40688943862915 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 19.281705379486084 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pNone_gTrue took 19.437161207199097 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0735496059 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.74244e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 7.43422e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 8.1415e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.73488e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 55.90506935119629
Epoch 1/9
	 Logging train Loss: 4.40231e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.53562e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.90608e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.24696e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.53499e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 56.323086977005005
Epoch 2/9
	 Logging train Loss: 2.5185e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.11173e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.76698e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.95528e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.11473e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 56.0430588722229
Epoch 3/9
	 Logging train Loss: 1.59725e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.42415e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.24339e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.34093e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.42563e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 56.202948570251465
Epoch 4/9
	 Logging train Loss: 1.41445e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.02899e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 9.439e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 9.8912e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.02889e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 56.48199462890625
Epoch 5/9
	 Logging train Loss: 1.20945e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 9.5646e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 8.3693e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 8.9992e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 9.5541e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 56.251062870025635
Epoch 6/9
	 Logging train Loss: 1.28431e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.29e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 7.9243e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 8.1191e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.281e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 55.2526433467865
Epoch 7/9
	 Logging train Loss: 1.28394e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.9218e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 7.7738e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 8.3978e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.9025e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 55.49777150154114
Epoch 8/9
	 Logging train Loss: 1.28734e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.8829e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 4.6485e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 4.7723e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.8784e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 56.33146262168884
Epoch 9/9
	 Logging train Loss: 1.13568e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.75488e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.94062e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.38717e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.72806e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 56.10879325866699
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'rot_mat'_'False'.pth
It took  726.9487228393555  seconds.
----- ITERATION 10/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 76.19142031669617 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_semi_pNone_gTrue took 19.431095600128174 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pNone_gTrue took 19.3839213848114 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 19.265974044799805 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pNone_gTrue took 19.47065830230713 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0714858398 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0001324279 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 0.0001153116 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 0.0001237211 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0001333309 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 56.58184099197388
Epoch 1/9
	 Logging train Loss: 4.27861e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.9093e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue â–ˆâ–‚â–‚â–â–â–â–â–â–â–‚
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue â–ˆâ–‚â–‚â–â–â–â–â–â–â–‚
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue â–ˆâ–‚â–‚â–â–â–â–â–â–â–‚
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue â–ˆâ–‚â–‚â–â–â–â–â–â–â–‚
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 2e-05
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue 2e-05
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue 2e-05
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue 2e-05
wandb:                                 Train loss 2e-05
wandb: 
wandb: ðŸš€ View run stellar-eon-1244 at: https://wandb.ai/nreints/ThesisFinal2/runs/q2hhofwa
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230710_010706-q2hhofwa/logs
	 Logging test loss: 2.65879e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.78563e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.93455e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 56.883410930633545
Epoch 2/9
	 Logging train Loss: 2.32397e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.96378e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.85161e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.91148e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.97453e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 56.70735430717468
Epoch 3/9
	 Logging train Loss: 1.60841e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.38022e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.30711e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.34489e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.38537e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 56.76660633087158
Epoch 4/9
	 Logging train Loss: 1.16773e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.05379e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.00961e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.03142e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.05699e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 56.434664726257324
Epoch 5/9
	 Logging train Loss: 1.0827e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.6079e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 8.3924e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 8.5017e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.6335e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 56.971275806427
Epoch 6/9
	 Logging train Loss: 1.44144e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.5091e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 7.3884e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 7.4505e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.5204e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 56.75663900375366
Epoch 7/9
	 Logging train Loss: 1.18453e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.6606e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 6.4337e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 6.5506e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.6911e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 56.96393632888794
Epoch 8/9
	 Logging train Loss: 1.40567e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 9.2682e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 9.1044e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 9.1847e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 9.2773e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 57.271896839141846
Epoch 9/9
	 Logging train Loss: 1.54398e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.75672e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.71949e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.73905e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.76166e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 56.69923257827759
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'rot_mat'_'False'.pth
It took  744.9627294540405  seconds.

JOB STATISTICS
==============
Job ID: 3039251
Array Job ID: 3039249_26
Cluster: snellius
User/Group: nreints/nreints
State: RUNNING
Nodes: 1
Cores per node: 18
CPU Utilized: 02:08:58
CPU Efficiency: 5.84% of 1-12:49:48 core-walltime
Job Wall-clock time: 02:02:46
Memory Utilized: 8.61 GB
Memory Efficiency: 0.00% of 0.00 MB
WARNING: Efficiency statistics may be misleading for RUNNING jobs.
