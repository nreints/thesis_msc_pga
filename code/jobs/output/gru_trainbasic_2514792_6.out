wandb: Currently logged in as: nreints. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230329_133618-zt54lw89
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run daily-durian-510
wandb: â­ï¸ View project at https://wandb.ai/nreints/test
wandb: ðŸš€ View run at https://wandb.ai/nreints/test/runs/zt54lw89
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.031 MB of 0.078 MB uploaded (0.000 MB deduped)wandb: \ 0.031 MB of 0.078 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:                                                    Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb: Test loss t(0, 0)_r(5, 20)_tennis_pNone_gNone, MSELoss() â–ˆâ–†â–„â–‚â–‚â–‚â–â–â–â–â–
wandb:                                               Train loss â–ˆâ–‚â–‚â–‚â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                                    Epoch 9
wandb: Test loss t(0, 0)_r(5, 20)_tennis_pNone_gNone, MSELoss() 3.55482
wandb:                                               Train loss 3.60658
wandb: 
wandb: ðŸš€ View run daily-durian-510 at: https://wandb.ai/nreints/test/runs/zt54lw89
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230329_133618-zt54lw89/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230329_134535-d2ukrifp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run chocolate-haze-528
wandb: â­ï¸ View project at https://wandb.ai/nreints/test
wandb: ðŸš€ View run at https://wandb.ai/nreints/test/runs/d2ukrifp
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.031 MB of 0.078 MB uploaded (0.000 MB deduped)wandb: \ 0.078 MB of 0.078 MB uploaded (0.000 MB deduped)wandb: | 0.078 MB of 0.078 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:                                                    Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb: Test loss t(0, 0)_r(5, 20)_tennis_pNone_gNone, MSELoss() â–ˆâ–†â–…â–ƒâ–‚â–‚â–â–â–â–â–
wandb:                                               Train loss â–ˆâ–‚â–‚â–‚â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                                    Epoch 9
wandb: Test loss t(0, 0)_r(5, 20)_tennis_pNone_gNone, MSELoss() 3.71623
wandb:                                               Train loss 3.70267
wandb: 
wandb: ðŸš€ View run chocolate-haze-528 at: https://wandb.ai/nreints/test/runs/d2ukrifp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230329_134535-d2ukrifp/logs
Running for data type: log_dualQ
----- ITERATION 1/2 ------
Number of train simulations: 1600
Number of test simulations: 400
-- Finished Train Dataloader --
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(6, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=6, bias=True)
)
-- Started Training --
Epoch 0
	 Logging train Loss: 143.1803029039 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss: 35.730552673339844 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 50.86352181434631
Epoch 1
	 Logging train Loss: 28.5878228263 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss: 25.27268409729004 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 48.81951642036438
Epoch 2
	 Logging train Loss: 21.5992495202 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss: 18.237977981567383 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 48.82681751251221
Epoch 3
	 Logging train Loss: 13.7740646383 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss: 10.239303588867188 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 49.108723640441895
Epoch 4
	 Logging train Loss: 8.1806497205 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss: 7.074423789978027 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 49.03008723258972
Epoch 5
	 Logging train Loss: 6.2688676047 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss: 5.8797101974487305 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 48.74411153793335
Epoch 6
	 Logging train Loss: 5.2894507129 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss: 5.2107319831848145 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 48.9119188785553
Epoch 7
	 Logging train Loss: 4.6574817856 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss: 4.378448009490967 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 48.975594997406006
Epoch 8
	 Logging train Loss: 4.0206020136 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss: 3.855025291442871 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 48.909499406814575
Epoch 9
	 Logging train Loss: 3.6065822138 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss: 3.5631747245788574 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 48.71698975563049
	 Logging test loss: 3.5548219680786133 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
It took  558.2087607383728  seconds.
----- ITERATION 2/2 ------
Number of train simulations: 1600
Number of test simulations: 400
-- Finished Train Dataloader --
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(6, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=6, bias=True)
)
-- Started Training --
Epoch 0
	 Logging train Loss: 144.9281124833 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss: 36.030670166015625 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 49.305346727371216
Epoch 1
	 Logging train Loss: 28.2804259846 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss: 26.541767120361328 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 49.134613275527954
Epoch 2
	 Logging train Loss: 22.3248367615 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss: 20.62265396118164 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 49.08542561531067
Epoch 3
	 Logging train Loss: 15.0910706463 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss: 11.406429290771484 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 48.86983942985535
Epoch 4
	 Logging train Loss: 8.5458847474 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss: 7.382659912109375 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 49.425392627716064
Epoch 5
	 Logging train Loss: 6.3599617198 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss: 6.094174861907959 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 49.87582039833069
Epoch 6
	 Logging train Loss: 5.3631231616 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss: 5.278931140899658 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 49.03628993034363
Epoch 7
	 Logging train Loss: 4.6706927596 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss: 4.58449649810791 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 49.04062461853027
Epoch 8
	 Logging train Loss: 4.0968827577 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss: 4.136367321014404 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 49.08847641944885
Epoch 9
	 Logging train Loss: 3.7026699662 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss: 3.7148475646972656 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 48.93537425994873
	 Logging test loss: 3.716231346130371 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
It took  554.1882617473602  seconds.

JOB STATISTICS
==============
Job ID: 2514798
Array Job ID: 2514792_6
Cluster: snellius
User/Group: nreints/nreints
State: COMPLETED (exit code 0)
Nodes: 1
Cores per node: 18
CPU Utilized: 03:56:51
CPU Efficiency: 70.05% of 05:38:06 core-walltime
Job Wall-clock time: 00:18:47
Memory Utilized: 24.75 GB
Memory Efficiency: 79.21% of 31.25 GB
