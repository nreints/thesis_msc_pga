wandb: Currently logged in as: nreints. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_203204-9e2vqpoy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sandy-field-392
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/9e2vqpoy
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gTrue █▃▂▁▁▂▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gTrue █▃▂▁▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gTrue █▃▂▁▁▂▁▁▁▁
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gTrue █▃▂▁▁▂▁▁▁▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gTrue 0.0
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gTrue 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: 🚀 View run sandy-field-392 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/9e2vqpoy
wandb: Synced 7 W&B file(s), 0 media file(s), 1 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_203204-9e2vqpoy/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_204318-u6lf41k5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hearty-wave-411
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/u6lf41k5
Training on dataset: data_t(5,20)_r(0,0)_combi_pNone_gTrue
Testing on 4 datasets: ['data_t(5,20)_r(0,0)_tennis_pNone_gTrue', 'data_t(5,20)_r(0,0)_combi_pNone_gTrue', 'data_t(5,20)_r(0,0)_full_pNone_gTrue', 'data_t(5,20)_r(0,0)_semi_pNone_gTrue']
Focussing on identity: True
Using extra input: False
Using fr-fr as reference point.
----- ITERATION 1/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gTrue took 51.694167613983154 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(0,0)_tennis_pNone_gTrue took 13.181318998336792 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gTrue took 12.89585542678833 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_full_pNone_gTrue took 12.260689496994019 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_semi_pNone_gTrue took 12.975270986557007 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0001480973 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.1553e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 5.693e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.2069e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 6.5202e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 56.20390486717224
Epoch 1/9
	 Logging train Loss: 2.9632e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.7855e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.7649e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.789e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.8167e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 55.83777117729187
Epoch 2/9
	 Logging train Loss: 1.6951e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.852e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 7.602e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.522e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 8.092e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 56.23382353782654
Epoch 3/9
	 Logging train Loss: 8.784e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.457e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.31e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.252e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.572e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 55.905195236206055
Epoch 4/9
	 Logging train Loss: 7.223e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.115e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.822e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.258e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 5.467e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 56.427985429763794
Epoch 5/9
	 Logging train Loss: 7.546e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.564e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 6.048e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.965e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 9.161e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 56.22034788131714
Epoch 6/9
	 Logging train Loss: 7.02e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.461e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.132e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.811e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 4.773e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 55.707751512527466
Epoch 7/9
	 Logging train Loss: 6.51e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.551e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.522e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.55e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.574e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 55.64272594451904
Epoch 8/9
	 Logging train Loss: 6.127e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.295e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 4.042e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.87e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 4.37e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 55.50962686538696
Epoch 9/9
	 Logging train Loss: 5.706e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.322e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.099e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.879e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.378e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 55.60477375984192
Saved model in  trained_models/gru/data_t(5,20)_r(0,0)_combi_pNone_gTrue/'rot_mat_1'_'False'.pth
It took  674.962414264679  seconds.
----- ITERATION 2/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gTrue took 50.30985403060913 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(0,0)_tennis_pNone_gTrue took 12.261624336242676 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gTrue took 12.58337688446045 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_full_pNone_gTrue took 12.642161846160889 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_semi_pNone_gTrue took 12.644162893295288 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 8.15149e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.4087e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.7657e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.5226e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 4.1726e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 55.9999566078186
Epoch 1/9
	 Logging train Loss: 2.4003e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.6164e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.561e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.5813e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.553e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 56.235360622406006
Epoch 2/9
	 Logging train Loss: 1.2598e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.7744e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 4.6663e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.5923e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 4.7492e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 55.981226205825806
Epoch 3/9
	 Logging train Loss: 8.868e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.066e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 4.753e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.737e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 6.972e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 56.171874046325684
Epoch 4/9
	 Logging train Loss: 1.0461e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gTrue ▇▃█▂▄▁▂▁▁▃
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gTrue ▆▃█▁▄▁▁▁▁▂
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gTrue ▇▃█▂▄▂▂▁▁▃
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gTrue ▇▃█▂▄▂▂▁▁▃
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gTrue 0.0
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gTrue 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: 🚀 View run hearty-wave-411 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/u6lf41k5
wandb: Synced 7 W&B file(s), 0 media file(s), 1 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_204318-u6lf41k5/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_205430-x0ghmoyq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run decent-disco-431
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/x0ghmoyq
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gTrue █▃▂▆▃▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gTrue █▃▂▂▃▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gTrue ▆▃▂█▃▂▁▁▁▁
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gTrue ▆▃▂█▃▂▁▁▁▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gTrue 0.0
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gTrue 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: 🚀 View run decent-disco-431 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/x0ghmoyq
wandb: Synced 7 W&B file(s), 0 media file(s), 1 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_205430-x0ghmoyq/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_210602-n7tpyr03
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run daily-grass-450
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/n7tpyr03
	 Logging test loss: 2.4397e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.4028e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.3675e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.4319e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 56.357290267944336
Epoch 5/9
	 Logging train Loss: 8.975e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.565e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 4.662e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.971e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 7.48e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 56.11208939552307
Epoch 6/9
	 Logging train Loss: 6.573e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.328e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 5.615e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.261e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 7.163e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 55.84040284156799
Epoch 7/9
	 Logging train Loss: 6.637e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.533e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.528e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.478e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.507e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 55.726712226867676
Epoch 8/9
	 Logging train Loss: 6.266e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.468e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.446e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.4e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.448e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 55.662741899490356
Epoch 9/9
	 Logging train Loss: 5.505e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.6521e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.1972e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.963e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.6304e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 55.81945252418518
Saved model in  trained_models/gru/data_t(5,20)_r(0,0)_combi_pNone_gTrue/'rot_mat_1'_'False'.pth
It took  672.0799880027771  seconds.
----- ITERATION 3/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gTrue took 50.44384789466858 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(0,0)_tennis_pNone_gTrue took 12.325687885284424 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gTrue took 12.607269048690796 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_full_pNone_gTrue took 12.680553674697876 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_semi_pNone_gTrue took 12.659526824951172 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0001315303 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.0275e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 4.8992e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.4394e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 5.1642e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 58.71457648277283
Epoch 1/9
	 Logging train Loss: 2.7863e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.7064e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.7583e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.692e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.7532e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 58.46741437911987
Epoch 2/9
	 Logging train Loss: 1.1951e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.646e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 7.33e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.608e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 7.835e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 57.35539507865906
Epoch 3/9
	 Logging train Loss: 8.749e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.6989e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.5717e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.485e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 6.6691e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 58.20136070251465
Epoch 4/9
	 Logging train Loss: 8.164e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.6481e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.408e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.1613e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.6781e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 57.27272152900696
Epoch 5/9
	 Logging train Loss: 6.966e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.922e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 4.887e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.871e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 6.9e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 59.463226556777954
Epoch 6/9
	 Logging train Loss: 6.989e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.577e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.336e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.095e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 4.531e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 58.57906532287598
Epoch 7/9
	 Logging train Loss: 6.21e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.698e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.714e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.659e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.736e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 57.94474387168884
Epoch 8/9
	 Logging train Loss: 7.424e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.951e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.855e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.662e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.961e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 57.2192702293396
Epoch 9/9
	 Logging train Loss: 4.168e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.34e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.107e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.801e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.383e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 56.75798201560974
Saved model in  trained_models/gru/data_t(5,20)_r(0,0)_combi_pNone_gTrue/'rot_mat_1'_'False'.pth
It took  692.0358345508575  seconds.
----- ITERATION 4/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gTrue took 50.31973671913147 seconds.
-- Finished Train Dataloader --
slurmstepd: error: *** JOB 3085868 ON gcn28 CANCELLED AT 2023-07-16T21:09:10 ***
slurmstepd: error: *** STEP 3085868.0 ON gcn28 CANCELLED AT 2023-07-16T21:09:10 ***

JOB STATISTICS
==============
Job ID: 3085868
Array Job ID: 3085846_65
Cluster: snellius
User/Group: nreints/nreints
State: CANCELLED (exit code 0)
Nodes: 1
Cores per node: 18
CPU Utilized: 00:39:21
CPU Efficiency: 5.86% of 11:11:42 core-walltime
Job Wall-clock time: 00:37:19
Memory Utilized: 8.36 GB
Memory Efficiency: 0.00% of 0.00 MB
