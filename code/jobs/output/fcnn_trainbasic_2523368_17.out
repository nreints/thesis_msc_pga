wandb: Currently logged in as: nreints. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home/nreints/.netrc
/gpfs/home2/nreints/MScThesis/code/fcnn.py:566: DeprecationWarning: Sampling from a set deprecated
since Python 3.9 and will be removed in a subsequent version.
  train_sims = set(random.sample(sims_train, int(0.8 * n_sims_train)))
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230330_123650-1tyjozs2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run royal-sky-567
wandb: ⭐️ View project at https://wandb.ai/nreints/test
wandb: 🚀 View run at https://wandb.ai/nreints/test/runs/1tyjozs2
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.029 MB of 0.029 MB uploaded (0.000 MB deduped)wandb: \ 0.029 MB of 0.078 MB uploaded (0.000 MB deduped)wandb: | 0.029 MB of 0.078 MB uploaded (0.000 MB deduped)wandb: / 0.029 MB of 0.078 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  Test loss t(0, 0)_r(5, 20)_tennis L1Loss() █▆▅▄▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁
wandb: Test loss t(0, 0)_r(5, 20)_tennis MSELoss() █▅▄▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     Train loss data_t(0, 0)_r(5, 20)_tennis █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:  Test loss t(0, 0)_r(5, 20)_tennis L1Loss() 0.0973
wandb: Test loss t(0, 0)_r(5, 20)_tennis MSELoss() 0.02173
wandb:     Train loss data_t(0, 0)_r(5, 20)_tennis 0.02157
wandb: 
wandb: 🚀 View run royal-sky-567 at: https://wandb.ai/nreints/test/runs/1tyjozs2
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230330_123650-1tyjozs2/logs
/gpfs/home2/nreints/MScThesis/code/fcnn.py:566: DeprecationWarning: Sampling from a set deprecated
since Python 3.9 and will be removed in a subsequent version.
  train_sims = set(random.sample(sims_train, int(0.8 * n_sims_train)))
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230330_124802-zf8pvhvz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rich-cherry-622
wandb: ⭐️ View project at https://wandb.ai/nreints/test
wandb: 🚀 View run at https://wandb.ai/nreints/test/runs/zf8pvhvz
Training on dataset: data/data_t(0, 0)_r(5, 20)_tennis_pNone_gNone
Testing on datasets: ['data_t(0, 0)_r(5, 20)_tennis_pNone_gNone']
----- ITERATION 1/2 ------
Number of train simulations: 1600
Number of test simulations: 400
The dataloader took 61.84653949737549 seconds.
-- Finished Train Dataloader --
The dataloader took 15.387703895568848 seconds.
-- Finished Test Dataloader(s) --
Datatype: quat
--- Started Training ---
Epoch 0
	 Logging train Loss: 33.973999183 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 2.138463258743286 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.9815987944602966 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 29.74173641204834
Epoch 1
	 Logging train Loss: 1.6560942606 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 1.3327995538711548 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.7700549364089966 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 29.685693740844727
Epoch 2
	 Logging train Loss: 1.0393372779 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.8277572989463806 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.6055644154548645 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 29.72016668319702
Epoch 3
	 Logging train Loss: 0.5931321088 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.44183349609375 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.4443531930446625 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 29.379942417144775
Epoch 4
	 Logging train Loss: 0.305891209 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.2377268373966217 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.32850345969200134 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 29.433610677719116
Epoch 5
	 Logging train Loss: 0.1754463944 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.15379013121128082 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.2655220031738281 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 29.18662166595459
Epoch 6
	 Logging train Loss: 0.1172247394 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.1056259423494339 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.21895338594913483 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 29.727043867111206
Epoch 7
	 Logging train Loss: 0.0867534263 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.08004040271043777 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.18957169353961945 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 30.63370132446289
Epoch 8
	 Logging train Loss: 0.0678430694 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.07065869122743607 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.17973363399505615 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 30.988423347473145
Epoch 9
	 Logging train Loss: 0.0560176974 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.059810686856508255 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.1656349152326584 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 27.817097663879395
Epoch 10
	 Logging train Loss: 0.0474687614 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.04461391642689705 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.14076483249664307 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 28.002275228500366
Epoch 11
	 Logging train Loss: 0.0416502485 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.03885671868920326 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.13083992898464203 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 27.831851482391357
Epoch 12
	 Logging train Loss: 0.0369765986 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.03448404371738434 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.12251251935958862 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 28.03994846343994
Epoch 13
	 Logging train Loss: 0.0331897262 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.03127568960189819 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.11737939715385437 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 29.24063730239868
Epoch 14
	 Logging train Loss: 0.030427287 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.03228775039315224 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.1205386072397232 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 28.11348605155945
Epoch 15
	 Logging train Loss: 0.0279207816 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.031877193599939346 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.12071608752012253 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 27.95739245414734
Epoch 16
	 Logging train Loss: 0.0261355755 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.02847515605390072 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.11330124735832214 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 27.929269075393677
Epoch 17
	 Logging train Loss: 0.0244507534 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.02342575415968895 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.10128407925367355 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 28.17729091644287
Epoch 18
	 Logging train Loss: 0.0230040955 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.022518081590533257 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.09949515014886856 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 28.205110549926758
Epoch 19
	 Logging train Loss: 0.02156585 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.021739747375249863 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.09730745106935501 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 29.410797357559204
	 Logging test loss 0.02173275128006935 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.09730162471532822 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
It took 671.9067227840424 seconds to train & eval the model.
----- ITERATION 2/2 ------
Number of train simulations: 1600
Number of test simulations: 400
The dataloader took 56.33321928977966 seconds.
-- Finished Train Dataloader --
The dataloader took 14.1026771068573 seconds.
-- Finished Test Dataloader(s) --
Datatype: quat
--- Started Training ---
Epoch 0
	 Logging train Loss: 38.3038271038 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 14.694218635559082 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 1.736412763595581 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 29.595184087753296
Epoch 1
	 Logging train Loss: 11.4345013787 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 10.628223419189453 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 1.606101393699646 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 28.367969751358032
Epoch 2
	 Logging train Loss: 8.8978145425 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 8.457881927490234 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 1.3094947338104248 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 27.88545060157776
Epoch 3
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.029 MB of 0.078 MB uploaded (0.000 MB deduped)wandb: \ 0.029 MB of 0.078 MB uploaded (0.000 MB deduped)wandb: | 0.029 MB of 0.078 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  Test loss t(0, 0)_r(5, 20)_tennis L1Loss() █▇▅▄▅▄▃▄▃▃▃▃▂▂▄▂▂▂▁▂▂
wandb: Test loss t(0, 0)_r(5, 20)_tennis MSELoss() █▆▅▃▄▃▂▃▂▂▂▂▂▂▃▁▁▁▁▁▁
wandb:     Train loss data_t(0, 0)_r(5, 20)_tennis █▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:  Test loss t(0, 0)_r(5, 20)_tennis L1Loss() 0.75806
wandb: Test loss t(0, 0)_r(5, 20)_tennis MSELoss() 2.96117
wandb:     Train loss data_t(0, 0)_r(5, 20)_tennis 2.84811
wandb: 
wandb: 🚀 View run rich-cherry-622 at: https://wandb.ai/nreints/test/runs/zf8pvhvz
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230330_124802-zf8pvhvz/logs
	 Logging train Loss: 7.5160481771 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 6.4012250900268555 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 1.1546326875686646 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 28.053884029388428
Epoch 4
	 Logging train Loss: 6.8636354933 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 7.555908203125 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 1.2429895401000977 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 29.9294011592865
Epoch 5
	 Logging train Loss: 6.0668498519 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 6.253243446350098 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 1.1419330835342407 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 29.1553316116333
Epoch 6
	 Logging train Loss: 5.5493310866 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 4.710851669311523 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.9994401931762695 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 29.065672159194946
Epoch 7
	 Logging train Loss: 5.2322147544 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 5.799679279327393 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 1.0585194826126099 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 27.704318046569824
Epoch 8
	 Logging train Loss: 5.169533484 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 4.139925003051758 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.9228324294090271 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 28.11552405357361
Epoch 9
	 Logging train Loss: 4.1774988511 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 4.042187213897705 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.9149958491325378 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 27.97250008583069
Epoch 10
	 Logging train Loss: 3.8790674147 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 3.7481985092163086 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.8719208240509033 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 27.686578512191772
Epoch 11
	 Logging train Loss: 3.7300774867 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 3.8433375358581543 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.9611179232597351 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 29.419357299804688
Epoch 12
	 Logging train Loss: 3.3797376047 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 3.2368693351745605 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.7921598553657532 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 28.139290809631348
Epoch 13
	 Logging train Loss: 3.689890025 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 3.546515464782715 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.8349626660346985 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 28.438408136367798
Epoch 14
	 Logging train Loss: 3.2369009778 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 4.898072719573975 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 1.0860745906829834 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 28.215134620666504
Epoch 15
	 Logging train Loss: 2.9790744358 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 2.748286485671997 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.7478278279304504 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 27.734503984451294
Epoch 16
	 Logging train Loss: 3.1548939823 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 2.5568888187408447 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.720844566822052 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 32.33232522010803
Epoch 17
	 Logging train Loss: 2.9248413884 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 2.7697272300720215 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.7757663130760193 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 29.167749166488647
Epoch 18
	 Logging train Loss: 2.7209223729 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 2.201826810836792 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.6138212084770203 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 29.764029264450073
Epoch 19
	 Logging train Loss: 2.8481052773 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 2.9622294902801514 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.7581813931465149 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 28.358671188354492
	 Logging test loss 2.9611740112304688 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss 0.7580599188804626 (L1Loss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
It took 660.5676662921906 seconds to train & eval the model.

JOB STATISTICS
==============
Job ID: 2523385
Array Job ID: 2523368_17
Cluster: snellius
User/Group: nreints/nreints
State: COMPLETED (exit code 0)
Nodes: 1
Cores per node: 18
CPU Utilized: 03:28:19
CPU Efficiency: 51.47% of 06:44:42 core-walltime
Job Wall-clock time: 00:22:29
Memory Utilized: 3.67 GB
Memory Efficiency: 12.53% of 29.30 GB
