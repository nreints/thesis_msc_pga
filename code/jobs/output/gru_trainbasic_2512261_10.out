/gpfs/home2/nreints/MScThesis/code/gru.py:583: DeprecationWarning: Sampling from a set deprecated
since Python 3.9 and will be removed in a subsequent version.
  train_sims = set(random.sample(sims_train, int(0.8 * n_sims_train_total)))
wandb: Currently logged in as: nreints. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230329_100832-yz78i6mw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ethereal-river-451
wandb: â­ï¸ View project at https://wandb.ai/nreints/test
wandb: ðŸš€ View run at https://wandb.ai/nreints/test/runs/yz78i6mw
/home/nreints/.conda/envs/thesis/lib/python3.10/site-packages/torch/nn/init.py:405: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                                  Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb: Test loss t(5, 20)_r(0, 0)_full_pNone_gNone, MSELoss() â–ˆâ–‡â–…â–„â–ƒâ–‚â–‚â–‚â–â–â–
wandb:                                             Train loss â–ˆâ–†â–…â–„â–ƒâ–‚â–‚â–â–â–
wandb: 
wandb: Run summary:
wandb:                                                  Epoch 9
wandb: Test loss t(5, 20)_r(0, 0)_full_pNone_gNone, MSELoss() 10.99472
wandb:                                             Train loss 12.28953
wandb: 
wandb: ðŸš€ View run ethereal-river-451 at: https://wandb.ai/nreints/test/runs/yz78i6mw
wandb: Synced 6 W&B file(s), 0 media file(s), 2 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230329_100832-yz78i6mw/logs
Running for data type: quat
----- ITERATION 1/2 ------
Number of train simulations: 160
Number of test simulations: 40
-- Finished Train Dataloader --
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (pre_hidden_lin_layer): Sequential(
    (0): Linear(in_features=0, out_features=96, bias=True)
  )
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
-- Started Training --
Epoch 0
	 Logging train Loss: 63.0943229167 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss: 52.97034454345703 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
     --> Epoch time; 4.294806003570557
Epoch 1
	 Logging train Loss: 50.2581217448 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss: 45.016571044921875 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
     --> Epoch time; 4.047979354858398
Epoch 2
	 Logging train Loss: 42.2124967448 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss: 36.723968505859375 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
     --> Epoch time; 4.111506462097168
Epoch 3
	 Logging train Loss: 33.5983300781 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss: 28.304080963134766 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
     --> Epoch time; 4.072567701339722
Epoch 4
	 Logging train Loss: 26.145016276 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss: 22.43303108215332 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
     --> Epoch time; 4.093763113021851
Epoch 5
	 Logging train Loss: 21.4151611328 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss: 18.819705963134766 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
     --> Epoch time; 4.1436567306518555
Epoch 6
	 Logging train Loss: 18.2643619792 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss: 16.202669143676758 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
     --> Epoch time; 4.0663909912109375
Epoch 7
	 Logging train Loss: 15.8719222005 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss: 14.1613130569458 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
     --> Epoch time; 4.094529390335083
Epoch 8
	 Logging train Loss: 13.9283398438 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss: 12.436887741088867 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
     --> Epoch time; 4.158178806304932
Epoch 9
	 Logging train Loss: 12.2895304362 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss: 10.990193367004395 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
     --> Epoch time; 4.0798115730285645
	 Logging test loss: 10.994717597961426 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
It took  57.4231698513031  seconds.
Traceback (most recent call last):
  File "/gpfs/home2/nreints/MScThesis/code/gru.py", line 642, in <module>
    torch.save(
  File "/home/nreints/.conda/envs/thesis/lib/python3.10/site-packages/torch/serialization.py", line 422, in save
    with _open_zipfile_writer(f) as opened_zipfile:
  File "/home/nreints/.conda/envs/thesis/lib/python3.10/site-packages/torch/serialization.py", line 309, in _open_zipfile_writer
    return container(name_or_buffer)
  File "/home/nreints/.conda/envs/thesis/lib/python3.10/site-packages/torch/serialization.py", line 287, in __init__
    super(_open_zipfile_writer_file, self).__init__(torch._C.PyTorchFileWriter(str(name)))
RuntimeError: Parent directory models/gru does not exist.
srun: error: gcn10: task 0: Exited with exit code 1
srun: launch/slurm: _step_signal: Terminating StepId=2512261.0
