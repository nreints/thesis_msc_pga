wandb: Currently logged in as: nreints. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home/nreints/.netrc
/gpfs/home2/nreints/MScThesis/code/fcnn.py:566: DeprecationWarning: Sampling from a set deprecated
since Python 3.9 and will be removed in a subsequent version.
  train_sims = set(random.sample(sims_train, int(0.8 * n_sims_train)))
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230330_123649-rtdhjkvo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run good-sunset-558
wandb: ⭐️ View project at https://wandb.ai/nreints/test
wandb: 🚀 View run at https://wandb.ai/nreints/test/runs/rtdhjkvo
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.029 MB of 0.029 MB uploaded (0.000 MB deduped)wandb: \ 0.029 MB of 0.029 MB uploaded (0.000 MB deduped)wandb: | 0.029 MB of 0.029 MB uploaded (0.000 MB deduped)wandb: / 0.029 MB of 0.029 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  Test loss t(5, 20)_r(0, 0)_full L1Loss() ▃█▂▂▁▂▂▁▂▄▂▁▁▁▁▁▁▁▅▁▁
wandb: Test loss t(5, 20)_r(0, 0)_full MSELoss() ▂█▁▁▁▁▁▁▁▃▁▁▁▁▁▁▁▁▃▁▁
wandb:     Train loss data_t(5, 20)_r(0, 0)_full █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:  Test loss t(5, 20)_r(0, 0)_full L1Loss() 0.03134
wandb: Test loss t(5, 20)_r(0, 0)_full MSELoss() 0.00219
wandb:     Train loss data_t(5, 20)_r(0, 0)_full 0.0159
wandb: 
wandb: 🚀 View run good-sunset-558 at: https://wandb.ai/nreints/test/runs/rtdhjkvo
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230330_123649-rtdhjkvo/logs
/gpfs/home2/nreints/MScThesis/code/fcnn.py:566: DeprecationWarning: Sampling from a set deprecated
since Python 3.9 and will be removed in a subsequent version.
  train_sims = set(random.sample(sims_train, int(0.8 * n_sims_train)))
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230330_124846-s7hsoyg2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run deep-donkey-633
wandb: ⭐️ View project at https://wandb.ai/nreints/test
wandb: 🚀 View run at https://wandb.ai/nreints/test/runs/s7hsoyg2
Training on dataset: data/data_t(5, 20)_r(0, 0)_full_pNone_gNone
Testing on datasets: ['data_t(5, 20)_r(0, 0)_full_pNone_gNone']
----- ITERATION 1/2 ------
Number of train simulations: 1600
Number of test simulations: 400
The dataloader took 54.60093712806702 seconds.
-- Finished Train Dataloader --
The dataloader took 13.446786165237427 seconds.
-- Finished Test Dataloader(s) --
Datatype: log_dualQ
--- Started Training ---
Epoch 0
	 Logging train Loss: 6.0950354882 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.04713400453329086 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.1581716686487198 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
     --> Epoch time; 30.74120306968689
Epoch 1
	 Logging train Loss: 0.0387003157 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.5034944415092468 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.4453411400318146 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
     --> Epoch time; 32.06004762649536
Epoch 2
	 Logging train Loss: 0.0337543238 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.011528060771524906 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.07886023819446564 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
     --> Epoch time; 32.44515514373779
Epoch 3
	 Logging train Loss: 0.028385287 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.018270259723067284 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.09596303105354309 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
     --> Epoch time; 32.41248369216919
Epoch 4
	 Logging train Loss: 0.0260923996 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.0038636981043964624 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.04768899455666542 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
     --> Epoch time; 32.52583575248718
Epoch 5
	 Logging train Loss: 0.0275287504 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.014948545955121517 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.0830787792801857 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
     --> Epoch time; 32.162970542907715
Epoch 6
	 Logging train Loss: 0.0237383973 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.011609157547354698 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.07663625478744507 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
     --> Epoch time; 32.272446155548096
Epoch 7
	 Logging train Loss: 0.0249925501 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.005135265178978443 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.05188099667429924 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
     --> Epoch time; 32.22015571594238
Epoch 8
	 Logging train Loss: 0.019523117 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.008332549594342709 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.06313212960958481 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
     --> Epoch time; 32.56597876548767
Epoch 9
	 Logging train Loss: 0.0214131224 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.1285078078508377 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.22577588260173798 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
     --> Epoch time; 32.34143042564392
Epoch 10
	 Logging train Loss: 0.0201914631 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.0067482138983905315 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.05681644380092621 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
     --> Epoch time; 31.914618730545044
Epoch 11
	 Logging train Loss: 0.0188959221 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.0063290223479270935 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.054347120225429535 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
     --> Epoch time; 32.49844670295715
Epoch 12
	 Logging train Loss: 0.0191226884 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.00202155951410532 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.03145305812358856 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
     --> Epoch time; 31.007001876831055
Epoch 13
	 Logging train Loss: 0.0236998315 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.003229706548154354 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.03864892199635506 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
     --> Epoch time; 30.684786558151245
Epoch 14
	 Logging train Loss: 0.0154119242 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.0012313836487010121 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.024886813014745712 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
     --> Epoch time; 30.686100959777832
Epoch 15
	 Logging train Loss: 0.0147515191 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.006079725921154022 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.050293244421482086 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
     --> Epoch time; 30.471558332443237
Epoch 16
	 Logging train Loss: 0.0160340652 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.0012567079393193126 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.025268349796533585 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
     --> Epoch time; 32.11074638366699
Epoch 17
	 Logging train Loss: 0.0170351864 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.001346491975709796 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.025671569630503654 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
     --> Epoch time; 30.538610458374023
Epoch 18
	 Logging train Loss: 0.0131483464 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.15976779162883759 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.24932661652565002 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
     --> Epoch time; 30.675331830978394
Epoch 19
	 Logging train Loss: 0.0159017575 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.0021884553134441376 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.031341128051280975 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
     --> Epoch time; 30.784041166305542
	 Logging test loss 0.002188717946410179 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.0313413180410862 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
It took 717.0628089904785 seconds to train & eval the model.
----- ITERATION 2/2 ------
Number of train simulations: 1600
Number of test simulations: 400
The dataloader took 48.25077748298645 seconds.
-- Finished Train Dataloader --
The dataloader took 12.027671337127686 seconds.
-- Finished Test Dataloader(s) --
Datatype: log_dualQ
--- Started Training ---
Epoch 0
	 Logging train Loss: 6.4656409569 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.03267364576458931 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.12642037868499756 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
     --> Epoch time; 32.94585871696472
Epoch 1
	 Logging train Loss: 0.049904094 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.013985545374453068 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.08881650120019913 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
     --> Epoch time; 30.939026594161987
Epoch 2
	 Logging train Loss: 0.0390755323 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.009636102244257927 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.07488633692264557 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
     --> Epoch time; 30.664159774780273
Epoch 3
	 Logging train Loss: 0.0385826809 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:  Test loss t(5, 20)_r(0, 0)_full L1Loss() ▃▂▂▂▁▃▂█▃▂▁▃▁▁▁▂▃▁▂▁▁
wandb: Test loss t(5, 20)_r(0, 0)_full MSELoss() ▁▁▁▁▁▂▁█▂▁▁▂▁▁▁▁▂▁▁▁▁
wandb:     Train loss data_t(5, 20)_r(0, 0)_full █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:  Test loss t(5, 20)_r(0, 0)_full L1Loss() 0.02577
wandb: Test loss t(5, 20)_r(0, 0)_full MSELoss() 0.00134
wandb:     Train loss data_t(5, 20)_r(0, 0)_full 0.01783
wandb: 
wandb: 🚀 View run deep-donkey-633 at: https://wandb.ai/nreints/test/runs/s7hsoyg2
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230330_124846-s7hsoyg2/logs
	 Logging test loss 0.006806209217756987 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.06348996609449387 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
     --> Epoch time; 30.674862384796143
Epoch 4
	 Logging train Loss: 0.0432697271 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.005280804820358753 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.05631942301988602 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
     --> Epoch time; 32.825220823287964
Epoch 5
	 Logging train Loss: 0.0285182978 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.054885778576135635 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.15705329179763794 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
     --> Epoch time; 32.54455089569092
Epoch 6
	 Logging train Loss: 0.0346693276 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.005801790859550238 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.05856044963002205 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
     --> Epoch time; 32.65193724632263
Epoch 7
	 Logging train Loss: 0.0300974952 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.5288138389587402 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.4784603416919708 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
     --> Epoch time; 30.685755729675293
Epoch 8
	 Logging train Loss: 0.0280702329 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.05907212570309639 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.1594502329826355 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
     --> Epoch time; 30.581074476242065
Epoch 9
	 Logging train Loss: 0.0259920183 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.007471725810319185 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.0633588656783104 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
     --> Epoch time; 31.08824849128723
Epoch 10
	 Logging train Loss: 0.0257393507 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.0027698285412043333 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.040813397616147995 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
     --> Epoch time; 30.134859800338745
Epoch 11
	 Logging train Loss: 0.024976501 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.03949323296546936 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.13034771382808685 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
     --> Epoch time; 32.201122760772705
Epoch 12
	 Logging train Loss: 0.0227950726 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.0030509065836668015 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.0412299819290638 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
     --> Epoch time; 31.316208362579346
Epoch 13
	 Logging train Loss: 0.0245203305 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.002243496710434556 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.035250891000032425 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
     --> Epoch time; 31.158199787139893
Epoch 14
	 Logging train Loss: 0.0207120222 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.003998973872512579 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.04405422881245613 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
     --> Epoch time; 31.278822422027588
Epoch 15
	 Logging train Loss: 0.0226940255 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.014258930459618568 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.07827942818403244 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
     --> Epoch time; 30.905449390411377
Epoch 16
	 Logging train Loss: 0.0225749321 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.07216516137123108 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.16879193484783173 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
     --> Epoch time; 33.10016369819641
Epoch 17
	 Logging train Loss: 0.0183362936 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.0014081159606575966 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.026658907532691956 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
     --> Epoch time; 33.19649028778076
Epoch 18
	 Logging train Loss: 0.0186689265 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.026120761409401894 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.10010548681020737 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
     --> Epoch time; 32.3631865978241
Epoch 19
	 Logging train Loss: 0.0178349052 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.00133550597820431 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.02576892264187336 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
     --> Epoch time; 30.585640907287598
	 Logging test loss 0.0013350930530577898 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.025768529623746872 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
It took 706.7422227859497 seconds to train & eval the model.

JOB STATISTICS
==============
Job ID: 2523409
Array Job ID: 2523368_41
Cluster: snellius
User/Group: nreints/nreints
State: COMPLETED (exit code 0)
Nodes: 1
Cores per node: 18
CPU Utilized: 03:46:01
CPU Efficiency: 52.36% of 07:11:42 core-walltime
Job Wall-clock time: 00:23:59
Memory Utilized: 3.38 GB
Memory Efficiency: 11.54% of 29.30 GB
