wandb: Currently logged in as: nreints. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_164030-yxxnca7v
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stoic-dawn-9
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal1/runs/yxxnca7v
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone █▄▃▂▂▇▂▃▃▁
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone █▄▃▂▁▃▁▂▂▁
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone █▄▃▂▁▃▁▂▂▁
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone ▆▃▃▂▂█▂▃▃▁
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone ▅▃▂▂▂█▂▃▃▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone 1e-05
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone 1e-05
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone 1e-05
wandb:                                  Train loss 2e-05
wandb: 
wandb: 🚀 View run stoic-dawn-9 at: https://wandb.ai/nreints/ThesisFinal1/runs/yxxnca7v
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_164030-yxxnca7v/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_165008-ernzbpd9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run misunderstood-dragon-45
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal1/runs/ernzbpd9
Training on dataset: data_t(0,0)_r(5,20)_combi_pNone_gNone
Testing on 5 datasets: ['data_t(0,0)_r(5,20)_semi_pNone_gNone', 'data_t(0,0)_r(5,20)_tennis_pNone_gNone', 'data_t(0,0)_r(5,20)_none_pNone_gNone', 'data_t(0,0)_r(5,20)_combi_pNone_gNone', 'data_t(0,0)_r(5,20)_full_pNone_gNone']
Focussing on identity: False
Using extra input: False
Using fr-fr as reference point.
----- ITERATION 1/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 64.84716963768005 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(5,20)_semi_pNone_gNone took 16.518036365509033 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_tennis_pNone_gNone took 16.44227147102356 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_none_pNone_gNone took 16.591359615325928 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 16.407186031341553 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_full_pNone_gNone took 16.674465656280518 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0122838542 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.76479e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.76897e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.0822e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.35352e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.8677e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 42.17145276069641
Epoch 1/9
	 Logging train Loss: 2.43784e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.31996e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.20977e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.767e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.89178e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.6544e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 41.52969455718994
Epoch 2/9
	 Logging train Loss: 1.56466e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.04095e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.92536e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.0811e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.32901e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 9.838e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 41.14081907272339
Epoch 3/9
	 Logging train Loss: 1.14447e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.76272e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.64221e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 7.031e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.00091e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.062e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 41.15043115615845
Epoch 4/9
	 Logging train Loss: 9.3741e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.56836e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.45328e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.418e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 8.3771e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.476e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 41.33952331542969
Epoch 5/9
	 Logging train Loss: 9.4298e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.15335e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 5.44357e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.4992e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.80343e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.4402e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 41.31749391555786
Epoch 6/9
	 Logging train Loss: 1.58485e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.86013e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.8198e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.199e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 9.6115e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.416e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 41.27047657966614
Epoch 7/9
	 Logging train Loss: 1.85793e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.23804e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.26261e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 5.33e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.16918e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.666e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 41.689847230911255
Epoch 8/9
	 Logging train Loss: 1.85813e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.28714e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.34841e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 5.597e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.22134e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.062e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 41.90206241607666
Epoch 9/9
	 Logging train Loss: 1.57707e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.12828e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.06994e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.056e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 5.7048e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.455e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 42.05528688430786
Saved model in  trained_models/gru/data_t(0,0)_r(5,20)_combi_pNone_gNone/'quat_1'_'False'.pth
It took  578.5697920322418  seconds.
----- ITERATION 2/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 63.78244400024414 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(5,20)_semi_pNone_gNone took 16.29443669319153 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_tennis_pNone_gNone took 16.26942014694214 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_none_pNone_gNone took 16.2975070476532 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 16.005412340164185 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_full_pNone_gNone took 16.224700212478638 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0051335208 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.39351e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.47504e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.7052e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.23017e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.4946e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 42.434887170791626
Epoch 1/9
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone █▄▃▂█▃▁▁▁▁
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone █▄▂▂▄▂▁▁▁▁
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone █▄▂▂▄▂▁▁▁▁
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone ▄▃▂▂█▃▁▁▁▁
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone ▄▂▂▂█▃▁▁▁▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone 1e-05
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone 1e-05
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone 1e-05
wandb:                                  Train loss 1e-05
wandb: 
wandb: 🚀 View run misunderstood-dragon-45 at: https://wandb.ai/nreints/ThesisFinal1/runs/ernzbpd9
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_165008-ernzbpd9/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_165945-jv9bniyz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run zany-surf-80
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal1/runs/jv9bniyz
	 Logging train Loss: 1.71036e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.91689e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.95408e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.1545e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.33396e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.026e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 41.858386516571045
Epoch 2/9
	 Logging train Loss: 1.16336e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.67504e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.69681e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 7.511e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 9.6257e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.312e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 41.83322238922119
Epoch 3/9
	 Logging train Loss: 1.22254e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.54616e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.56596e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.867e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 8.3175e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.734e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 41.76786017417908
Epoch 4/9
	 Logging train Loss: 1.63589e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.26455e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.63948e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.2203e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.19909e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.106e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 41.69443869590759
Epoch 5/9
	 Logging train Loss: 1.61902e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.05591e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.15509e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 5.032e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.07394e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.016e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 41.76358771324158
Epoch 6/9
	 Logging train Loss: 1.8876e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.2408e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.25532e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.941e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 6.3554e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.045e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 41.884859561920166
Epoch 7/9
	 Logging train Loss: 1.61936e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.21638e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.23552e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.427e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 6.1768e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.593e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 41.54299235343933
Epoch 8/9
	 Logging train Loss: 1.42488e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.23585e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.28649e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.813e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 6.3112e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.068e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 42.04964900016785
Epoch 9/9
	 Logging train Loss: 1.24335e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.17297e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.22212e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.709e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 5.9153e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.015e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 41.781275510787964
Saved model in  trained_models/gru/data_t(0,0)_r(5,20)_combi_pNone_gNone/'quat_1'_'False'.pth
It took  577.3644280433655  seconds.
----- ITERATION 3/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 63.66790413856506 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(5,20)_semi_pNone_gNone took 16.247305631637573 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_tennis_pNone_gNone took 16.17615818977356 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_none_pNone_gNone took 16.23188853263855 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 16.034669637680054 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_full_pNone_gNone took 16.234091997146606 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0129643753 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.90056e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.92507e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.1424e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.28129e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.0181e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 41.6413471698761
Epoch 1/9
	 Logging train Loss: 2.28689e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.24665e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.18306e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.8134e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.75906e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.6922e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 41.583120346069336
Epoch 2/9
	 Logging train Loss: 1.40145e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.91808e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.82951e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.1092e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.19085e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 9.957e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 41.72337031364441
Epoch 3/9
	 Logging train Loss: 1.20418e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.80601e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.69403e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 6.74e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.0187e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.656e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 42.75625777244568
Epoch 4/9
	 Logging train Loss: 1.38337e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.6554e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.54753e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.407e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 8.9984e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone ▅▃▂▂▁▇▂▂█▁
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone █▄▃▂▁▆▂▂▇▁
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone █▄▃▂▁▆▂▂▇▁
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone ▃▂▂▂▁▇▂▂█▁
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone ▃▂▂▁▁▆▂▂█▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone 1e-05
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone 1e-05
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone 1e-05
wandb:                                  Train loss 1e-05
wandb: 
wandb: 🚀 View run zany-surf-80 at: https://wandb.ai/nreints/ThesisFinal1/runs/jv9bniyz
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_165945-jv9bniyz/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_170924-z5o262zx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run helpful-waterfall-113
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal1/runs/z5o262zx
	 Logging test loss: 3.389e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 42.607441663742065
Epoch 5/9
	 Logging train Loss: 1.4587e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 9.53363e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0001013976 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.906e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 4.95852e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.7935e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 42.58821129798889
Epoch 6/9
	 Logging train Loss: 1.60134e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.70856e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.71169e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 8.112e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.4232e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.173e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 42.43751120567322
Epoch 7/9
	 Logging train Loss: 1.52213e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.85472e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.07365e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 8.007e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.5334e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.252e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 42.56256294250488
Epoch 8/9
	 Logging train Loss: 1.57638e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.00011592 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0001267597 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.3293e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 6.00744e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.2435e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 42.51231932640076
Epoch 9/9
	 Logging train Loss: 1.46379e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 9.9942e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 9.4444e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.625e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 5.2362e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 9.92e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 41.654133319854736
Saved model in  trained_models/gru/data_t(0,0)_r(5,20)_combi_pNone_gNone/'quat_1'_'False'.pth
It took  578.7179608345032  seconds.
----- ITERATION 4/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 63.85873055458069 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(5,20)_semi_pNone_gNone took 16.21509027481079 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_tennis_pNone_gNone took 16.20447278022766 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_none_pNone_gNone took 16.15825319290161 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 16.054489612579346 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_full_pNone_gNone took 16.131474256515503 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0056444476 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.20058e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.17884e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.4611e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.23185e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.2912e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 41.842862129211426
Epoch 1/9
	 Logging train Loss: 1.83432e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.81967e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.76959e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.3254e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.32671e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.2159e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 41.78999876976013
Epoch 2/9
	 Logging train Loss: 1.14456e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.56693e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.50889e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 7.887e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 9.3749e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.832e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 41.81675410270691
Epoch 3/9
	 Logging train Loss: 8.9999e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.44195e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.38801e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 5.537e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 8.0348e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.523e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 41.48036527633667
Epoch 4/9
	 Logging train Loss: 9.9136e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.50876e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.48657e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.534e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 8.0819e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.538e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 41.66957664489746
Epoch 5/9
	 Logging train Loss: 1.59318e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.49894e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.51872e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.19e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 7.9805e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.241e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 41.91722917556763
Epoch 6/9
	 Logging train Loss: 1.78588e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.11204e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.23684e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 6.129e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.10033e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.137e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 41.555346727371216
Epoch 7/9
	 Logging train Loss: 1.73439e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.55491e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.53575e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.898e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 7.8947e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.044e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 41.674721479415894
Epoch 8/9
	 Logging train Loss: 1.41363e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.28648e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.30653e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone █▄▂▂▂▂▃▂▁▁
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone █▄▃▂▁▁▂▁▁▁
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone █▄▃▂▂▁▂▁▁▁
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone █▅▄▃▃▃▇▄▂▁
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone █▅▃▂▃▃█▃▂▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone 1e-05
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone 1e-05
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone 1e-05
wandb:                                  Train loss 1e-05
wandb: 
wandb: 🚀 View run helpful-waterfall-113 at: https://wandb.ai/nreints/ThesisFinal1/runs/z5o262zx
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_170924-z5o262zx/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_171859-zntel8dw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lively-shadow-144
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal1/runs/zntel8dw
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone █▃▂▁▁▁▂▁▄▃
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone █▃▂▁▁▁▁▁▂▂
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone █▃▂▁▁▁▁▁▂▂
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone █▂▂▁▁▂▂▁▇▆
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone █▂▂▁▁▂▂▁▇▆
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone 1e-05
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone 3e-05
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone 3e-05
wandb:                                  Train loss 2e-05
wandb: 
wandb: 🚀 View run lively-shadow-144 at: https://wandb.ai/nreints/ThesisFinal1/runs/zntel8dw
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_171859-zntel8dw/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_172835-tyk1ssw1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run expert-sponge-180
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal1/runs/tyk1ssw1
	 Logging test loss: 3.236e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 6.5217e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.485e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 41.94442534446716
Epoch 9/9
	 Logging train Loss: 1.33372e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.17042e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.1843e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.809e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 5.8899e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.125e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 41.49694871902466
Saved model in  trained_models/gru/data_t(0,0)_r(5,20)_combi_pNone_gNone/'quat_1'_'False'.pth
It took  575.2692091464996  seconds.
----- ITERATION 5/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 63.608551263809204 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(5,20)_semi_pNone_gNone took 16.085681676864624 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_tennis_pNone_gNone took 16.175495624542236 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_none_pNone_gNone took 16.204553365707397 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 16.189242124557495 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_full_pNone_gNone took 16.157958507537842 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0167543087 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.38234e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.23211e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.1067e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.09485e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.9461e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 42.15987753868103
Epoch 1/9
	 Logging train Loss: 2.18421e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.99404e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.82994e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.2383e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.65009e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.1098e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 42.36788010597229
Epoch 2/9
	 Logging train Loss: 1.26405e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.79628e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.64046e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 7.467e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.11487e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.239e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 42.21486139297485
Epoch 3/9
	 Logging train Loss: 9.5786e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.66077e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.50714e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.795e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 9.4263e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.625e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 41.87785840034485
Epoch 4/9
	 Logging train Loss: 1.1449e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.67464e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.53666e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.268e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 9.1333e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.159e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 41.68282151222229
Epoch 5/9
	 Logging train Loss: 1.59655e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.90365e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.78625e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.277e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.02243e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.212e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 41.74206233024597
Epoch 6/9
	 Logging train Loss: 2.12818e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.963e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.85356e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.03e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.03728e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.02e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 41.889397382736206
Epoch 7/9
	 Logging train Loss: 2.1513e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.6365e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.53999e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.046e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 8.6612e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.126e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 41.56313395500183
Epoch 8/9
	 Logging train Loss: 1.82339e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.20052e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.09895e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 8.781e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.6681e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.826e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 42.10540056228638
Epoch 9/9
	 Logging train Loss: 1.62543e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.82649e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.77794e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 7.587e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.48164e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.659e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 41.885247230529785
Saved model in  trained_models/gru/data_t(0,0)_r(5,20)_combi_pNone_gNone/'quat_1'_'False'.pth
It took  575.9839975833893  seconds.
----- ITERATION 6/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 63.34170174598694 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(5,20)_semi_pNone_gNone took 16.104361534118652 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_tennis_pNone_gNone took 16.00652503967285 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_none_pNone_gNone took 16.004905462265015 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 16.085578203201294 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_full_pNone_gNone took 16.067551136016846 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: quat_1
-- Started Training --
Epoch 0/9
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone █▅▃▁▁▄▃▂▁▁
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone █▃▂▁▁▂▂▁▁▁
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone █▃▂▁▁▂▂▁▁▁
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone ▇▃▂▁▁█▆▂▂▂
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone ▆▃▂▁▁█▆▂▂▂
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone 1e-05
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone 2e-05
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone 2e-05
wandb:                                  Train loss 2e-05
wandb: 
wandb: 🚀 View run expert-sponge-180 at: https://wandb.ai/nreints/ThesisFinal1/runs/tyk1ssw1
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_172835-tyk1ssw1/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_173822-u02uooq0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run confused-bush-216
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal1/runs/u02uooq0
	 Logging train Loss: 0.010217322 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.28745e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.57339e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 6.8369e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.42791e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.7092e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 41.9843053817749
Epoch 1/9
	 Logging train Loss: 2.62602e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.09054e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.26185e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.0253e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.14236e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.9024e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 41.79267382621765
Epoch 2/9
	 Logging train Loss: 1.81406e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.83603e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.98049e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.2616e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.47434e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.1484e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 41.599971771240234
Epoch 3/9
	 Logging train Loss: 1.26181e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.61811e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.73167e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 7.797e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.00244e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.666e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 41.52955913543701
Epoch 4/9
	 Logging train Loss: 1.01868e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.4856e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.60048e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.631e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 8.337e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.558e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 41.62675595283508
Epoch 5/9
	 Logging train Loss: 1.54672e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.72301e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.27266e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.115e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.03175e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.0238e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 41.9533052444458
Epoch 6/9
	 Logging train Loss: 2.22999e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.21253e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.64118e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 9.969e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.72555e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 9.021e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 42.48171544075012
Epoch 7/9
	 Logging train Loss: 2.25222e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.88924e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.13306e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.571e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.02732e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.792e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 42.4093291759491
Epoch 8/9
	 Logging train Loss: 2.06379e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.83668e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.06152e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.25e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 9.8943e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.446e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 42.311760663986206
Epoch 9/9
	 Logging train Loss: 1.76403e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.87234e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.11653e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.554e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 9.9436e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.74e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 42.19538593292236
Saved model in  trained_models/gru/data_t(0,0)_r(5,20)_combi_pNone_gNone/'quat_1'_'False'.pth
It took  587.0756115913391  seconds.
----- ITERATION 7/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 63.889596700668335 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(5,20)_semi_pNone_gNone took 16.174625158309937 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_tennis_pNone_gNone took 16.16936421394348 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_none_pNone_gNone took 16.146870613098145 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 16.172818183898926 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_full_pNone_gNone took 16.298681020736694 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0134263914 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.85969e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.65472e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.2355e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.89993e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.105e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 41.70461916923523
Epoch 1/9
	 Logging train Loss: 1.88754e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.94602e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.76423e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.2205e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.67054e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.1112e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 41.874890089035034
Epoch 2/9
	 Logging train Loss: 1.15577e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.72551e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.55358e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 8.123e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.14998e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.057e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 41.49719858169556
Epoch 3/9
	 Logging train Loss: 8.8876e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.70812e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.55166e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 5.446e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone █▄▂▂▂▂▂▁▄▂
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone █▄▃▂▁▂▂▁▃▃
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone █▄▃▂▂▂▂▁▃▃
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone █▄▃▃▂▄▄▁█▅
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone ▇▃▃▃▂▄▄▁█▅
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone 1e-05
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone 2e-05
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone 2e-05
wandb:                                  Train loss 2e-05
wandb: 
wandb: 🚀 View run confused-bush-216 at: https://wandb.ai/nreints/ThesisFinal1/runs/u02uooq0
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_173822-u02uooq0/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_174757-8qt8jkvw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run kind-cloud-251
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal1/runs/8qt8jkvw
	 Logging test loss: 1.03228e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.388e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 41.85648727416992
Epoch 4/9
	 Logging train Loss: 7.9206e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.49669e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.35441e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.69e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 8.7285e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.682e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 41.75329399108887
Epoch 5/9
	 Logging train Loss: 9.4303e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.99364e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.88661e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.57e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.12556e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.544e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 42.15536189079285
Epoch 6/9
	 Logging train Loss: 1.70659e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.91729e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.83079e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 5.041e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.07144e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.061e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 42.28275775909424
Epoch 7/9
	 Logging train Loss: 2.04124e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.27942e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.162e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.234e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 7.1344e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.408e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 41.90418457984924
Epoch 8/9
	 Logging train Loss: 1.53378e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.83996e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.89089e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 7.102e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.5444e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.058e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 41.8742880821228
Epoch 9/9
	 Logging train Loss: 1.55075e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.12839e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.07916e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 7.423e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.1569e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.512e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 41.79530048370361
Saved model in  trained_models/gru/data_t(0,0)_r(5,20)_combi_pNone_gNone/'quat_1'_'False'.pth
It took  574.5043594837189  seconds.
----- ITERATION 8/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 64.0225727558136 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(5,20)_semi_pNone_gNone took 16.134822130203247 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_tennis_pNone_gNone took 16.0885226726532 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_none_pNone_gNone took 16.116015911102295 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 16.15235686302185 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_full_pNone_gNone took 16.146589994430542 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.014968751 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.40684e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.75094e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.8457e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.45569e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.6684e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 41.81342625617981
Epoch 1/9
	 Logging train Loss: 2.45255e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.06754e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.23807e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.2857e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.04835e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.1744e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 42.52429723739624
Epoch 2/9
	 Logging train Loss: 1.57283e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.75526e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.8906e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 9.07e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.26191e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.981e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 42.22416543960571
Epoch 3/9
	 Logging train Loss: 1.1012e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.57387e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.68967e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 5.772e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 8.8747e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.715e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 42.062726736068726
Epoch 4/9
	 Logging train Loss: 9.2512e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.45952e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.56814e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.784e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 7.6443e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.753e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 42.28394818305969
Epoch 5/9
	 Logging train Loss: 1.15951e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.43948e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.66923e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 6.347e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.22224e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.549e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 42.72877097129822
Epoch 6/9
	 Logging train Loss: 2.14536e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.57104e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.70449e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.026e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 7.7731e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.189e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 42.166404247283936
Epoch 7/9
	 Logging train Loss: 2.33287e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.22798e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone █▄▂▂▁▂▁▂▄▁
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone █▄▃▂▁▂▁▂▃▁
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone █▄▃▂▁▂▁▂▃▁
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone ▇▃▂▂▁▄▂▄█▁
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone █▃▂▂▁▄▂▄█▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone 1e-05
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone 1e-05
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone 2e-05
wandb:                                  Train loss 2e-05
wandb: 
wandb: 🚀 View run kind-cloud-251 at: https://wandb.ai/nreints/ThesisFinal1/runs/8qt8jkvw
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_174757-8qt8jkvw/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_175736-uij1zaws
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wild-meadow-283
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal1/runs/uij1zaws
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone ▆▃▂▂▂▃▂▄▁█
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone █▄▃▂▂▃▃▄▁█
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone █▄▃▂▂▃▃▄▁█
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone ▃▂▂▁▁▃▂▄▁█
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone ▃▂▂▁▁▃▂▄▁█
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone 4e-05
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone 7e-05
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone 9e-05
wandb:                                  Train loss 2e-05
wandb: 
wandb: 🚀 View run wild-meadow-283 at: https://wandb.ai/nreints/ThesisFinal1/runs/uij1zaws
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_175736-uij1zaws/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_180713-252lh722
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fast-wildflower-311
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal1/runs/252lh722
	 Logging test loss: 2.44027e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 5.53e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.10738e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.866e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 41.81950259208679
Epoch 8/9
	 Logging train Loss: 1.83284e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.59365e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.88652e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 9.756e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.73841e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 9.238e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 41.762465715408325
Epoch 9/9
	 Logging train Loss: 1.76837e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.38989e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.51971e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.024e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 6.8055e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.406e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 42.19683241844177
Saved model in  trained_models/gru/data_t(0,0)_r(5,20)_combi_pNone_gNone/'quat_1'_'False'.pth
It took  579.5121417045593  seconds.
----- ITERATION 9/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 64.43170118331909 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(5,20)_semi_pNone_gNone took 16.17233109474182 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_tennis_pNone_gNone took 16.119216680526733 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_none_pNone_gNone took 16.114484310150146 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 16.17660689353943 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_full_pNone_gNone took 16.218160152435303 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0079088919 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.84501e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.07353e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.3118e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.9184e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.1458e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 41.64694786071777
Epoch 1/9
	 Logging train Loss: 2.05585e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.87801e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.99797e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.0757e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.64645e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 9.657e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 41.92369771003723
Epoch 2/9
	 Logging train Loss: 1.3423e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.79098e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.8922e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 8.276e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.21562e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.239e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 41.83337473869324
Epoch 3/9
	 Logging train Loss: 1.05648e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.54383e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.62837e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 6.037e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 9.2722e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.043e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 41.43022036552429
Epoch 4/9
	 Logging train Loss: 1.81796e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.53326e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.61272e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.074e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 8.7436e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.127e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 41.665247201919556
Epoch 5/9
	 Logging train Loss: 2.00783e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.58669e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.87816e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 6.755e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.40452e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.899e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 41.78801727294922
Epoch 6/9
	 Logging train Loss: 2.73957e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.98623e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.144e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 8.85e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.10105e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.998e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 41.91027021408081
Epoch 7/9
	 Logging train Loss: 2.28772e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.59999e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.11355e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.0362e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.88583e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 9.658e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 41.731534481048584
Epoch 8/9
	 Logging train Loss: 2.20537e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.17481e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.24102e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.058e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 6.295e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.346e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 42.11150097846985
Epoch 9/9
	 Logging train Loss: 1.77349e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.24546e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 8.58494e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.249e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.91118e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.2064e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 42.60019779205322
Saved model in  trained_models/gru/data_t(0,0)_r(5,20)_combi_pNone_gNone/'quat_1'_'False'.pth
It took  577.0940594673157  seconds.
----- ITERATION 10/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 64.54742455482483 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(5,20)_semi_pNone_gNone took 16.19925093650818 seconds.
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone █▄▂▂▂▂▁▃▃▁
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone █▃▂▂▁▁▁▂▂▁
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone █▃▂▂▁▁▁▂▂▁
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone █▃▂▂▂▃▁▅▆▂
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone █▃▂▂▂▃▁▅▇▂
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone 1e-05
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone 2e-05
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone 2e-05
wandb:                                  Train loss 2e-05
wandb: 
wandb: 🚀 View run fast-wildflower-311 at: https://wandb.ai/nreints/ThesisFinal1/runs/252lh722
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_180713-252lh722/logs
The dataloader for data/data_t(0,0)_r(5,20)_tennis_pNone_gNone took 16.235158681869507 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_none_pNone_gNone took 16.10626983642578 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 16.107300281524658 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_full_pNone_gNone took 16.189594507217407 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0118767349 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.80276e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.80951e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 5.2499e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.36733e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.1053e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 42.17850995063782
Epoch 1/9
	 Logging train Loss: 2.42711e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.04024e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.95906e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.7797e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.77666e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.6714e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 41.79406142234802
Epoch 2/9
	 Logging train Loss: 1.46854e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.82344e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.73061e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.183e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.15932e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.0788e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 41.51784420013428
Epoch 3/9
	 Logging train Loss: 1.0669e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.61611e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.52845e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 6.995e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 8.9038e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.987e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 41.466707944869995
Epoch 4/9
	 Logging train Loss: 9.687e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.71218e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.64237e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.865e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 8.8769e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.886e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 41.48307228088379
Epoch 5/9
	 Logging train Loss: 2.01177e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.09893e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.07403e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 5.42e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.07822e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.493e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 41.67560935020447
Epoch 6/9
	 Logging train Loss: 2.60595e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.37667e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.29835e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.93e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 6.8611e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.051e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 41.93007731437683
Epoch 7/9
	 Logging train Loss: 1.85803e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.84753e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.84096e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 7.818e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.40498e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.923e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 42.56517434120178
Epoch 8/9
	 Logging train Loss: 1.86638e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.23601e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.33625e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 8.827e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.63837e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.068e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 41.566954612731934
Epoch 9/9
	 Logging train Loss: 1.78184e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.71524e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.70514e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.218e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 8.4806e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.517e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 41.54364728927612
Saved model in  trained_models/gru/data_t(0,0)_r(5,20)_combi_pNone_gNone/'quat_1'_'False'.pth
It took  574.941326379776  seconds.

JOB STATISTICS
==============
Job ID: 2971267
Array Job ID: 2971258_9
Cluster: snellius
User/Group: nreints/nreints
State: COMPLETED (exit code 0)
Nodes: 1
Cores per node: 18
CPU Utilized: 06:23:32
CPU Efficiency: 22.05% of 1-04:59:42 core-walltime
Job Wall-clock time: 01:36:39
Memory Utilized: 8.36 GB
Memory Efficiency: 0.00% of 0.00 MB
