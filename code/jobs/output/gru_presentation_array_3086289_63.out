wandb: Currently logged in as: nreints. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_211345-186h1p5j
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run giddy-tree-456
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/186h1p5j
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gTrue █▂▂▁▁▁▁▁▃▁
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gTrue █▂▂▁▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gTrue █▂▂▁▁▁▁▁▅▂
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gTrue █▂▂▁▁▁▁▁▅▂
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gTrue 0.0
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gTrue 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: 🚀 View run giddy-tree-456 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/186h1p5j
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_211345-186h1p5j/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_212037-j2aedyr1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run apricot-bush-467
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/j2aedyr1
Training on dataset: data_t(5,20)_r(0,0)_combi_pNone_gTrue
Testing on 4 datasets: ['data_t(5,20)_r(0,0)_full_pNone_gTrue', 'data_t(5,20)_r(0,0)_tennis_pNone_gTrue', 'data_t(5,20)_r(0,0)_combi_pNone_gTrue', 'data_t(5,20)_r(0,0)_semi_pNone_gTrue']
Focussing on identity: False
Using extra input: False
Using fr-fr as reference point.
----- ITERATION 1/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gTrue took 52.14844584465027 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(0,0)_full_pNone_gTrue took 13.29135012626648 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_tennis_pNone_gTrue took 12.907702922821045 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gTrue took 12.983082294464111 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_semi_pNone_gTrue took 13.168006420135498 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: log_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0003444879 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.34058e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.38337e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.4408e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.46389e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 30.81435990333557
Epoch 1/9
	 Logging train Loss: 9.5899e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.389e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.7489e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.6518e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.7974e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 28.903335332870483
Epoch 2/9
	 Logging train Loss: 3.0777e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.9445e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.0965e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.0683e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.1298e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 28.988903284072876
Epoch 3/9
	 Logging train Loss: 2.2693e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.0264e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.0551e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.0729e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.0723e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 29.016364097595215
Epoch 4/9
	 Logging train Loss: 1.772e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.135e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 5.277e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 5.402e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.38e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 28.81234049797058
Epoch 5/9
	 Logging train Loss: 1.3909e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.58e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.1396e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 8.277e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.1974e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 29.135523796081543
Epoch 6/9
	 Logging train Loss: 1.3755e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.878e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.874e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.961e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.899e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 29.53029179573059
Epoch 7/9
	 Logging train Loss: 1.2603e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.97e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.09e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 7.14e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.1395e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 29.465636014938354
Epoch 8/9
	 Logging train Loss: 1.2463e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.455e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.30059e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 7.8236e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.38144e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 28.700743436813354
Epoch 9/9
	 Logging train Loss: 1.0043e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.167e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.6949e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.6866e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.8801e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 28.93821668624878
Saved model in  trained_models/gru/data_t(5,20)_r(0,0)_combi_pNone_gTrue/'log_quat_1'_'False'.pth
It took  413.0405385494232  seconds.
----- ITERATION 2/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gTrue took 47.5639910697937 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(0,0)_full_pNone_gTrue took 12.074277877807617 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_tennis_pNone_gTrue took 11.976612329483032 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gTrue took 11.828915119171143 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_semi_pNone_gTrue took 12.043968439102173 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: log_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0002472076 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.1814e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.22391e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.16866e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.14611e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 29.18075203895569
Epoch 1/9
	 Logging train Loss: 5.0161e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.2765e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.3387e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.2211e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.1931e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 29.168625593185425
Epoch 2/9
	 Logging train Loss: 2.5475e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.617e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.6446e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.5932e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.5717e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 29.062666416168213
Epoch 3/9
	 Logging train Loss: 2.3596e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.418e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 7.632e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 7.373e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.278e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 29.09216594696045
Epoch 4/9
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gTrue █▃▂▁▁▃▁▁▃▁
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gTrue █▃▂▁▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gTrue █▃▂▁▁▅▁▁▅▁
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gTrue █▃▂▁▁▅▁▁▅▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gTrue 0.0
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gTrue 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: 🚀 View run apricot-bush-467 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/j2aedyr1
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_212037-j2aedyr1/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_212717-sf7rrpr5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dulcet-shape-477
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/sf7rrpr5
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gTrue █▃▂▂▁▁▅▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gTrue █▃▂▁▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gTrue █▃▂▃▁▁█▁▁▁
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gTrue █▃▂▃▁▁█▁▁▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gTrue 0.0
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gTrue 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: 🚀 View run dulcet-shape-477 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/sf7rrpr5
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_212717-sf7rrpr5/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_213356-5nyelxw3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run visionary-meadow-485
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/5nyelxw3
	 Logging train Loss: 1.1597e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.283e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.463e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.312e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.325e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 29.095826387405396
Epoch 5/9
	 Logging train Loss: 1.6136e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.089e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 7.1211e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.4819e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.8659e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 29.116565465927124
Epoch 6/9
	 Logging train Loss: 1.1981e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.566e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.664e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.607e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.633e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 29.253328561782837
Epoch 7/9
	 Logging train Loss: 1.2245e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.489e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.552e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.52e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.519e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 29.22851538658142
Epoch 8/9
	 Logging train Loss: 1.3611e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.844e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 6.7097e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.4093e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.3401e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 29.12327265739441
Epoch 9/9
	 Logging train Loss: 9.105e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.951e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 4.634e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.231e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.561e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 29.132564544677734
Saved model in  trained_models/gru/data_t(5,20)_r(0,0)_combi_pNone_gTrue/'log_quat_1'_'False'.pth
It took  400.0706470012665  seconds.
----- ITERATION 3/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gTrue took 46.43386912345886 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(0,0)_full_pNone_gTrue took 11.947157144546509 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_tennis_pNone_gTrue took 11.908575057983398 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gTrue took 11.666756391525269 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_semi_pNone_gTrue took 11.941007852554321 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: log_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0001463681 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.2169e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 8.2097e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 8.3479e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.2369e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 29.14609384536743
Epoch 1/9
	 Logging train Loss: 3.8423e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.3708e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.3547e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.4391e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.4296e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 29.37065601348877
Epoch 2/9
	 Logging train Loss: 2.1924e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 9.955e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.0049e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.0283e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.0314e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 29.20302391052246
Epoch 3/9
	 Logging train Loss: 2.1355e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.954e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.7372e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.6581e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.794e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 29.354714155197144
Epoch 4/9
	 Logging train Loss: 1.2727e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.083e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.245e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.166e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.27e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 29.08388328552246
Epoch 5/9
	 Logging train Loss: 1.9044e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.54e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.888e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.716e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.908e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 29.238936185836792
Epoch 6/9
	 Logging train Loss: 1.2138e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.03e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 7.8936e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 4.5947e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.2164e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 29.096941471099854
Epoch 7/9
	 Logging train Loss: 1.1322e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.406e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.421e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.411e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.463e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 29.20466685295105
Epoch 8/9
	 Logging train Loss: 1.0375e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.414e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.899e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.643e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.924e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 29.41759204864502
Epoch 9/9
	 Logging train Loss: 9.139e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.403e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.683e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.545e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.744e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 29.822802543640137
Saved model in  trained_models/gru/data_t(5,20)_r(0,0)_combi_pNone_gTrue/'log_quat_1'_'False'.pth
It took  399.0352725982666  seconds.
----- ITERATION 4/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gTrue took 46.08048963546753 seconds.
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gTrue █▂▅▁▁▁▁▂▁▁
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gTrue █▂▂▁▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gTrue █▂█▁▁▁▁▃▁▁
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gTrue ▇▂█▁▁▁▁▃▁▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gTrue 0.0
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gTrue 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: 🚀 View run visionary-meadow-485 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/5nyelxw3
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_213356-5nyelxw3/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_214035-blyjt3e6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run revived-breeze-495
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/blyjt3e6
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(0,0)_full_pNone_gTrue took 11.935892581939697 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_tennis_pNone_gTrue took 11.909599542617798 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gTrue took 11.705852270126343 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_semi_pNone_gTrue took 11.918531894683838 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: log_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0002208777 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.09195e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.06769e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.08642e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.04306e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 29.41305136680603
Epoch 1/9
	 Logging train Loss: 9.2035e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.7573e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.7041e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.6861e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.633e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 29.05236005783081
Epoch 2/9
	 Logging train Loss: 4.8804e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.9707e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.22989e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.2454e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.09934e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 29.227875471115112
Epoch 3/9
	 Logging train Loss: 3.1228e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.4267e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.4752e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.4405e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.4413e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 29.01283073425293
Epoch 4/9
	 Logging train Loss: 2.3786e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.405e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 7.513e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 7.448e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.362e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 29.050395011901855
Epoch 5/9
	 Logging train Loss: 1.7626e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.595e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.778e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.714e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.711e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 29.377698183059692
Epoch 6/9
	 Logging train Loss: 1.6742e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.997e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.146e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.088e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.121e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 29.07573652267456
Epoch 7/9
	 Logging train Loss: 1.1217e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.794e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 4.9742e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.4424e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.8923e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 29.15712594985962
Epoch 8/9
	 Logging train Loss: 8.911e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.476e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.769e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.611e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.751e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 29.08326768875122
Epoch 9/9
	 Logging train Loss: 9.207e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.613e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.6718e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 9.324e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.5204e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 29.259395599365234
Saved model in  trained_models/gru/data_t(5,20)_r(0,0)_combi_pNone_gTrue/'log_quat_1'_'False'.pth
It took  399.0054850578308  seconds.
----- ITERATION 5/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gTrue took 46.266777992248535 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(0,0)_full_pNone_gTrue took 11.893676519393921 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_tennis_pNone_gTrue took 11.891278266906738 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gTrue took 11.692409992218018 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_semi_pNone_gTrue took 11.91362714767456 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: log_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0005574293 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.30563e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.36586e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.26257e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.27074e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 29.36500573158264
Epoch 1/9
	 Logging train Loss: 1.18599e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.6281e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.785e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.6684e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.6585e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 29.036651611328125
Epoch 2/9
	 Logging train Loss: 3.1189e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.8086e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.2656e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.9855e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.1716e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 29.27831530570984
Epoch 3/9
	 Logging train Loss: 2.0085e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.772e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 8.531e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 7.924e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.259e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 29.12939214706421
Epoch 4/9
	 Logging train Loss: 9.017e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.073e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.337e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.119e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.264e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 29.23567032814026
Epoch 5/9
	 Logging train Loss: 1.2266e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gTrue █▂▁▁▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gTrue █▂▁▁▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gTrue █▂▁▁▁▁▁▂▁▁
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gTrue █▂▁▁▁▁▁▂▁▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gTrue 0.0
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gTrue 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: 🚀 View run revived-breeze-495 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/blyjt3e6
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_214035-blyjt3e6/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_214712-clguqkpp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run electric-surf-504
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/clguqkpp
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gTrue █▂▁▁▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gTrue █▂▁▁▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gTrue █▂▁▁▁▁▁▁▁▁
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gTrue █▂▁▁▁▁▁▁▁▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gTrue 0.0
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gTrue 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: 🚀 View run electric-surf-504 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/clguqkpp
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_214712-clguqkpp/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_215351-dsim72wo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run honest-cherry-513
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/dsim72wo
	 Logging test loss: 2.717e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.2674e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.2364e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.1413e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 29.08135199546814
Epoch 6/9
	 Logging train Loss: 1.3904e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.454e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.535e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.487e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.525e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 29.144107580184937
Epoch 7/9
	 Logging train Loss: 1.2822e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.106e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.7878e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.3759e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.541e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 29.02244234085083
Epoch 8/9
	 Logging train Loss: 1.4559e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.412e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.478e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.437e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.467e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 29.03715229034424
Epoch 9/9
	 Logging train Loss: 1.4292e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.415e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.448e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.426e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.44e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 29.141849756240845
Saved model in  trained_models/gru/data_t(5,20)_r(0,0)_combi_pNone_gTrue/'log_quat_1'_'False'.pth
It took  396.516233921051  seconds.
----- ITERATION 6/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gTrue took 46.231818437576294 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(0,0)_full_pNone_gTrue took 11.888402223587036 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_tennis_pNone_gTrue took 11.858235359191895 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gTrue took 11.703025341033936 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_semi_pNone_gTrue took 11.872536659240723 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: log_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0007596186 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.30848e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.46063e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.34258e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.28625e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 29.67330312728882
Epoch 1/9
	 Logging train Loss: 1.38857e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.4883e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.8188e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.5993e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.5989e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 29.638736724853516
Epoch 2/9
	 Logging train Loss: 2.7851e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.9547e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.1651e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.0344e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.0337e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 29.322330713272095
Epoch 3/9
	 Logging train Loss: 2.0341e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.0122e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.1319e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.0556e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.0585e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 29.12290096282959
Epoch 4/9
	 Logging train Loss: 1.4764e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.732e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 5.397e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 4.994e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.064e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 28.88738751411438
Epoch 5/9
	 Logging train Loss: 1.2929e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.4e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.778e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.575e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.634e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 28.979907989501953
Epoch 6/9
	 Logging train Loss: 1.4277e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.616e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.843e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.753e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.771e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 29.10085678100586
Epoch 7/9
	 Logging train Loss: 1.1832e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.423e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.604e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.532e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.548e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 28.893524885177612
Epoch 8/9
	 Logging train Loss: 1.4679e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.407e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.491e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.466e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.452e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 29.208512544631958
Epoch 9/9
	 Logging train Loss: 8.063e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.395e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.561e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.504e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.515e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 29.19831132888794
Saved model in  trained_models/gru/data_t(5,20)_r(0,0)_combi_pNone_gTrue/'log_quat_1'_'False'.pth
It took  399.1466941833496  seconds.
----- ITERATION 7/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gTrue took 47.30360388755798 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(0,0)_full_pNone_gTrue took 11.843529224395752 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_tennis_pNone_gTrue took 11.829330444335938 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gTrue took 11.804853200912476 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_semi_pNone_gTrue took 11.896247625350952 seconds.
-- Finished Test Dataloader(s) --
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gTrue ▄▂▁▁▁▁▁▁█▁
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gTrue █▃▂▁▁▁▁▁▂▁
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gTrue ▃▁▁▁▁▁▁▁█▁
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gTrue ▃▁▁▁▁▁▁▁█▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gTrue 0.0
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gTrue 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: 🚀 View run honest-cherry-513 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/dsim72wo
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_215351-dsim72wo/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_220029-51xckgmx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dauntless-plant-523
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/51xckgmx
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: log_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0003068779 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 9.3832e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 9.2887e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 8.8304e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.9299e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 29.0447781085968
Epoch 1/9
	 Logging train Loss: 3.976e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.3883e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.4699e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.3388e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.3602e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 29.4056134223938
Epoch 2/9
	 Logging train Loss: 1.8822e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.315e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.3688e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.2846e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.3086e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 29.098363161087036
Epoch 3/9
	 Logging train Loss: 1.6901e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.362e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 6.66e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 6.218e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.361e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 28.943671941757202
Epoch 4/9
	 Logging train Loss: 1.8437e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.558e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 5.128e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 4.323e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.157e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 29.20657181739807
Epoch 5/9
	 Logging train Loss: 1.9243e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.058e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.383e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.18e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.311e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 29.443217039108276
Epoch 6/9
	 Logging train Loss: 1.5622e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.616e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.993e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.806e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.973e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 28.994948863983154
Epoch 7/9
	 Logging train Loss: 1.424e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.596e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.842e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.715e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.821e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 29.320375680923462
Epoch 8/9
	 Logging train Loss: 1.397e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.2439e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.33754e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.94911e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.59673e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 29.17640733718872
Epoch 9/9
	 Logging train Loss: 1.384e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.452e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.506e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.471e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.46e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 28.920363664627075
Saved model in  trained_models/gru/data_t(5,20)_r(0,0)_combi_pNone_gTrue/'log_quat_1'_'False'.pth
It took  398.0401933193207  seconds.
----- ITERATION 8/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gTrue took 47.407614946365356 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(0,0)_full_pNone_gTrue took 11.881878137588501 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_tennis_pNone_gTrue took 11.900798082351685 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gTrue took 11.875718593597412 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_semi_pNone_gTrue took 11.877481698989868 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: log_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0002815611 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.1129e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.10423e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.02237e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.16652e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 29.23347806930542
Epoch 1/9
	 Logging train Loss: 7.0652e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.7467e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.7776e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.6708e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.7489e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 29.246435403823853
Epoch 2/9
	 Logging train Loss: 2.0369e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.8047e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.39259e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 7.7187e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.28097e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 28.869649171829224
Epoch 3/9
	 Logging train Loss: 1.6566e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.983e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 6.179e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 5.919e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.261e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 29.14288353919983
Epoch 4/9
	 Logging train Loss: 1.5633e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.885e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.295e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.037e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.331e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 29.391923189163208
Epoch 5/9
	 Logging train Loss: 1.2273e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.785e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.828e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.797e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.885e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 29.831443548202515
Epoch 6/9
	 Logging train Loss: 8.976e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.522e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gTrue █▂▄▁▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gTrue █▂▂▁▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gTrue █▂▅▁▁▁▂▁▁▁
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gTrue █▂▆▁▁▁▂▁▁▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gTrue 0.0
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gTrue 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: 🚀 View run dauntless-plant-523 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/51xckgmx
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_220029-51xckgmx/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_220708-oz2ulwdp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rosy-elevator-529
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/oz2ulwdp
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gTrue █▂▂▁▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gTrue █▂▂▁▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gTrue █▂▂▁▁▁▁▁▁▁
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gTrue █▂▂▁▁▁▁▁▁▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gTrue 0.0
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gTrue 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: 🚀 View run rosy-elevator-529 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/oz2ulwdp
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_220708-oz2ulwdp/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_221344-bxmel5xv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run woven-frost-539
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/bxmel5xv
	 Logging test loss: 2.4033e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.3537e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.2979e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 29.38063335418701
Epoch 7/9
	 Logging train Loss: 1.334e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.529e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.279e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.438e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.236e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 29.03401803970337
Epoch 8/9
	 Logging train Loss: 9.558e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.555e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.825e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.724e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.888e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 28.89846110343933
Epoch 9/9
	 Logging train Loss: 9.799e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.675e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.461e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.607e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.454e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 28.786885499954224
Saved model in  trained_models/gru/data_t(5,20)_r(0,0)_combi_pNone_gTrue/'log_quat_1'_'False'.pth
It took  398.9948275089264  seconds.
----- ITERATION 9/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gTrue took 47.356783390045166 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(0,0)_full_pNone_gTrue took 11.929800748825073 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_tennis_pNone_gTrue took 11.902703285217285 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gTrue took 11.945696592330933 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_semi_pNone_gTrue took 11.949486255645752 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: log_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0002157308 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.84232e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.85033e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.79966e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.88039e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 29.23740816116333
Epoch 1/9
	 Logging train Loss: 7.1401e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.8748e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.9575e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.8065e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.9322e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 29.338959455490112
Epoch 2/9
	 Logging train Loss: 2.8572e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.4831e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.537e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.4546e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.5221e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 28.749414443969727
Epoch 3/9
	 Logging train Loss: 2.6803e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.154e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 7.529e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 7.043e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.431e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 29.078294277191162
Epoch 4/9
	 Logging train Loss: 1.2087e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.606e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.872e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.62e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.802e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 28.7293221950531
Epoch 5/9
	 Logging train Loss: 1.129e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.186e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.551e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.853e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.619e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 28.635738372802734
Epoch 6/9
	 Logging train Loss: 1.5567e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.615e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.743e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.704e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.733e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 28.389566898345947
Epoch 7/9
	 Logging train Loss: 1.1605e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.532e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.671e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.631e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.679e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 28.525370597839355
Epoch 8/9
	 Logging train Loss: 1.0243e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.528e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.578e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.57e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.597e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 28.806092023849487
Epoch 9/9
	 Logging train Loss: 1.1613e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.398e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.427e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.441e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.432e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 28.430895566940308
Saved model in  trained_models/gru/data_t(5,20)_r(0,0)_combi_pNone_gTrue/'log_quat_1'_'False'.pth
It took  395.9723279476166  seconds.
----- ITERATION 10/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gTrue took 47.31662106513977 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(0,0)_full_pNone_gTrue took 11.879472970962524 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_tennis_pNone_gTrue took 11.868411302566528 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gTrue took 11.873018264770508 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_semi_pNone_gTrue took 11.907654523849487 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: log_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0001973958 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.58778e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.64778e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.52946e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.46783e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 28.567639112472534
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gTrue █▂▂▁▁▁▁▁▃▁
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gTrue █▂▂▁▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gTrue █▂▂▁▁▁▁▁▆▂
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gTrue █▂▂▁▁▁▁▁▆▂
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gTrue 0.0
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gTrue 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: 🚀 View run woven-frost-539 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/bxmel5xv
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_221344-bxmel5xv/logs
Epoch 1/9
	 Logging train Loss: 6.3448e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.8426e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.9386e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.8296e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.7413e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 28.74190640449524
Epoch 2/9
	 Logging train Loss: 2.322e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.5653e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.8804e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.6556e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.7656e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 28.542261123657227
Epoch 3/9
	 Logging train Loss: 2.157e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.55e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 7.984e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 7.5e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.371e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 28.704355239868164
Epoch 4/9
	 Logging train Loss: 1.431e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.593e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.866e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.595e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.594e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 28.484453678131104
Epoch 5/9
	 Logging train Loss: 1.9181e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.275e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 7.59e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 4.43e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.314e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 28.52221179008484
Epoch 6/9
	 Logging train Loss: 8.87e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.62e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.262e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.89e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.261e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 28.608784198760986
Epoch 7/9
	 Logging train Loss: 1.1528e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.639e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.653e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.662e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.655e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 28.634294271469116
Epoch 8/9
	 Logging train Loss: 1.0235e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.686e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.15003e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 5.1389e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.14403e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 28.716357469558716
Epoch 9/9
	 Logging train Loss: 9.142e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.029e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.7067e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 8.33e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.6956e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 28.88094687461853
Saved model in  trained_models/gru/data_t(5,20)_r(0,0)_combi_pNone_gTrue/'log_quat_1'_'False'.pth
It took  396.4652280807495  seconds.

JOB STATISTICS
==============
Job ID: 3086311
Array Job ID: 3086289_63
Cluster: snellius
User/Group: nreints/nreints
State: RUNNING
Nodes: 1
Cores per node: 18
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 20:03:18 core-walltime
Job Wall-clock time: 01:06:51
Memory Utilized: 0.00 MB (estimated maximum)
Memory Efficiency: 0.00% of 0.00 MB (0.00 MB/node)
WARNING: Efficiency statistics may be misleading for RUNNING jobs.
