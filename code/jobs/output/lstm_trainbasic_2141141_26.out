/gpfs/home2/nreints/MScThesis/code/lstm.py:270: DeprecationWarning: Sampling from a set deprecated
since Python 3.9 and will be removed in a subsequent version.
  train_sims = set(random.sample(sims_train, int(0.8 * n_sims_train)))
wandb: Currently logged in as: nreints. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.13.9 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.8
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230127_110027-3e6k9pfy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dazzling-laughter-1658
wandb: ⭐️ View project at https://wandb.ai/nreints/thesis
wandb: 🚀 View run at https://wandb.ai/nreints/thesis/runs/3e6k9pfy
/home/nreints/.conda/envs/thesis/lib/python3.10/site-packages/torch/nn/modules/rnn.py:67: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  warnings.warn("dropout option adds dropout after all but last "
BEFORE ['data_t(-10,', '10)_r(-5,', '5)_none']
----- ITERATION 0/10 ------
[<torch.utils.data.dataloader.DataLoader object at 0x151f3450e8c0>, <torch.utils.data.dataloader.DataLoader object at 0x151f2d7e4a90>, <torch.utils.data.dataloader.DataLoader object at 0x151f2d7e43a0>, <torch.utils.data.dataloader.DataLoader object at 0x151f2d7e4610>]
LSTM(
  (lstm): LSTM(8, 96, batch_first=True, dropout=0.2)
  (layers): Sequential(
    (0): Linear(in_features=96, out_features=8, bias=True)
  )
)
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.027247976511716843
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.03506772965192795
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.02245214208960533
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.031497687101364136
0 2.132501826 	 0.0314976874
epoch_time;  43.478086948394775
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.017763357609510422
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.02538965456187725
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.023359138518571854
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.03163602948188782
1 0.0282765835 	 0.0316360307
epoch_time;  41.284695625305176
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.008434713818132877
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.01193996611982584
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.009089700877666473
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.01246385183185339
2 0.0221054632 	 0.012463852
epoch_time;  41.08869171142578
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.006705310195684433
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.009922601282596588
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.007865389809012413
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.01117508765310049
3 0.0182144041 	 0.0111750872
epoch_time;  40.669429779052734
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.006235979031771421
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.008796335197985172
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.00631012162193656
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.009120016358792782
4 0.0152690015 	 0.0091200163
epoch_time;  41.079421043395996
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.003522830316796899
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.006043917499482632
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.007108758203685284
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.010335373692214489
5 0.0127891523 	 0.0103353734
epoch_time;  40.92885971069336
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.015437989495694637
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.02397593855857849
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.026781465858221054
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.04064081236720085
6 0.0131136499 	 0.0406408108
epoch_time;  40.725682497024536
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.008552289567887783
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.011492693796753883
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.005981968250125647
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.007739986293017864
7 0.0089397929 	 0.0077399862
epoch_time;  41.391597509384155
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.011365087702870369
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.018366878852248192
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.019179200753569603
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.02825993485748768
8 0.0094133575 	 0.0282599343
epoch_time;  40.46738600730896
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.028418393805623055
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.037041887640953064
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.016007188707590103
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.020702563226222992
9 0.0081336089 	 0.0207025623
epoch_time;  41.26336598396301
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0033738468773663044
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.005232699681073427
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.006128681357949972
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.008488781750202179
10 0.00790669 	 0.0084887819
epoch_time;  41.16740703582764
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.020022153854370117
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.028608471155166626
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.018136152997612953
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.023793736472725868
11 0.007072848 	 0.0237937363
epoch_time;  41.57081723213196
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0011096614180132747
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0018010096391662955
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0016449436079710722
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.00233659241348505
12 0.0071325952 	 0.0023365925
epoch_time;  40.59158515930176
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0037991644348949194
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.005853225477039814
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.004620324820280075
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.00670805387198925
13 0.005899381 	 0.0067080537
epoch_time;  41.08245778083801
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.00105232500936836
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0015790120232850313
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0014003601390868425
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.0019425693899393082
14 0.0059680451 	 0.0019425694
epoch_time;  41.27524924278259
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0026184595189988613
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.00397128239274025
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0030467999167740345
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.004267346113920212
15 0.0056378699 	 0.0042673461
epoch_time;  41.170761585235596
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0016382739413529634
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.00237279268912971
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0023838269989937544
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.003207217436283827
16 0.0053698199 	 0.0032072175
epoch_time;  40.97541069984436
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.001485269283875823
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.003054088680073619
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.002517005195841193
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.0040424903854727745
17 0.0153123349 	 0.0040424904
epoch_time;  41.268287658691406
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.006592577788978815
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.008698702789843082
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.005416498985141516
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.007198871113359928
18 0.0026325232 	 0.0071988711
epoch_time;  41.035160303115845
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.00302443141117692
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.004398887045681477
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.003357592038810253
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.004653263837099075
19 0.0044329406 	 0.0046532637
epoch_time;  40.73010873794556
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0008839495130814612
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0013807419454678893
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.001427382230758667
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.001974676735699177
20 0.0045273468 	 0.0019746769
epoch_time;  40.79731750488281
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.004443445708602667
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.006346679758280516
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.003991189878433943
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.005467701703310013
21 0.0044329526 	 0.0054677015
epoch_time;  41.505939245224
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0010953235905617476
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.001718010287731886
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0019718974363058805
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.0026591685600578785
22 0.0043307221 	 0.0026591685
epoch_time;  41.20449209213257
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.022 MB of 0.022 MB uploaded (0.000 MB deduped)wandb: \ 0.022 MB of 0.143 MB uploaded (0.000 MB deduped)wandb: | 0.022 MB of 0.143 MB uploaded (0.000 MB deduped)wandb: / 0.022 MB of 0.143 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:                              Epoch ▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇███
wandb: Test loss t(-10, 10)_r(-5, 5)_none ▆▆▃▃▂▃█▂▆▄▂▅▁▂▁▁▁▁▂▂▁▂▁▂▁▁▂▁▃▂▂
wandb:  Test loss t(-10, 10)_r(0, 0)_none █▆▃▃▂▂▅▃▄█▂▆▁▂▁▂▁▁▂▂▁▂▁▂▁▁▁▁▃▂▂
wandb:    Test loss t(0, 0)_r(-5, 5)_none ▇▇▃▃▂▃█▂▆▅▂▆▁▂▁▁▁▁▂▂▁▂▁▂▁▁▂▁▃▂▂
wandb:     Test loss t(0, 0)_r(0, 0)_none █▅▃▂▂▂▅▃▄█▂▆▁▂▁▁▁▁▂▂▁▂▁▂▁▁▁▁▃▂▂
wandb:                         Train loss █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                              Epoch 29
wandb: Test loss t(-10, 10)_r(-5, 5)_none 0.00508
wandb:  Test loss t(-10, 10)_r(0, 0)_none 0.00468
wandb:    Test loss t(0, 0)_r(-5, 5)_none 0.00355
wandb:     Test loss t(0, 0)_r(0, 0)_none 0.00314
wandb:                         Train loss 0.00341
wandb: 
wandb: 🚀 View run dazzling-laughter-1658 at: https://wandb.ai/nreints/thesis/runs/3e6k9pfy
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230127_110027-3e6k9pfy/logs
/gpfs/home2/nreints/MScThesis/code/lstm.py:270: DeprecationWarning: Sampling from a set deprecated
since Python 3.9 and will be removed in a subsequent version.
  train_sims = set(random.sample(sims_train, int(0.8 * n_sims_train)))
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.13.9 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.8
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230127_112209-d5n85wez
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glistening-festival-1666
wandb: ⭐️ View project at https://wandb.ai/nreints/thesis
wandb: 🚀 View run at https://wandb.ai/nreints/thesis/runs/d5n85wez
/home/nreints/.conda/envs/thesis/lib/python3.10/site-packages/torch/nn/modules/rnn.py:67: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  warnings.warn("dropout option adds dropout after all but last "
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.006242768839001656
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.008362135849893093
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.006041619926691055
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.008257110603153706
23 0.0039940996 	 0.008257111
epoch_time;  41.126171588897705
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0012141395127400756
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0016532896552234888
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.001327343052253127
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.0017338978359475732
24 0.0041494994 	 0.0017338979
epoch_time;  41.20549726486206
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.001118843792937696
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0016510681016370654
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0013899521436542273
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.0018505397019907832
25 0.0037707322 	 0.0018505396
epoch_time;  40.800673961639404
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.002262265421450138
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.003435499267652631
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.004059315659105778
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.005552798043936491
26 0.0039590836 	 0.0055527982
epoch_time;  40.94983649253845
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0011261542094871402
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0015853306977078319
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0014443943509832025
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.0019200730603188276
27 0.0037369685 	 0.0019200731
epoch_time;  40.926857709884644
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.007597762160003185
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.011294430121779442
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.007954600267112255
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.011499271728098392
28 0.003563965 	 0.0114992717
epoch_time;  41.01332998275757
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0031405603513121605
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.004682191647589207
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0035496121272444725
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.005082986317574978
29 0.0034125322 	 0.0050829865
epoch_time;  41.45059657096863
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0031405221670866013
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.004680626094341278
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0035511807072907686
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.005082305055111647
It took  1302.7427520751953  seconds.
----- ITERATION 1/10 ------
[<torch.utils.data.dataloader.DataLoader object at 0x151f2d7e4220>, <torch.utils.data.dataloader.DataLoader object at 0x151f3442d090>, <torch.utils.data.dataloader.DataLoader object at 0x151f3442f2b0>, <torch.utils.data.dataloader.DataLoader object at 0x151f017e8220>]
LSTM(
  (lstm): LSTM(8, 96, batch_first=True, dropout=0.2)
  (layers): Sequential(
    (0): Linear(in_features=96, out_features=8, bias=True)
  )
)
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.014770516194403172
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.020619800314307213
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.01936635561287403
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.027143914252519608
0 2.221208594 	 0.0271439135
epoch_time;  41.423922061920166
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.009245877154171467
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.01309468038380146
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.011742892675101757
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.015593710355460644
1 0.0303953374 	 0.0155937103
epoch_time;  40.92638802528381
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.008088667877018452
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.012451366521418095
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.010178507305681705
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.01397432666271925
2 0.0234806861 	 0.0139743266
epoch_time;  41.05989360809326
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0189465694129467
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.02475762739777565
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.017109205946326256
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.02177148126065731
3 0.0169384817 	 0.0217714814
epoch_time;  41.23600435256958
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0036373354960232973
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.005787592846900225
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0056092082522809505
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.008164391852915287
4 0.0153346961 	 0.0081643921
epoch_time;  40.89076256752014
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.002146365586668253
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0034081561025232077
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.004406726453453302
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.006224395241588354
5 0.0141718906 	 0.0062243953
epoch_time;  41.387341022491455
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.041012123227119446
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.053093284368515015
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.04053327068686485
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.05329860374331474
6 0.0104157782 	 0.0532986045
epoch_time;  41.3221001625061
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.004295842722058296
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.006002223584800959
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.004636063706129789
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.006232397630810738
7 0.0096160555 	 0.0062323978
epoch_time;  40.8859543800354
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.009624063037335873
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.012024164199829102
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.008341977372765541
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.010501429438591003
8 0.0088265171 	 0.0105014294
epoch_time;  41.151047229766846
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0012451200745999813
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.001906061777845025
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.001782250008545816
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.002537634689360857
9 0.0081194965 	 0.0025376346
epoch_time;  41.27755427360535
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.004899431485682726
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.007198905572295189
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.006138686556369066
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.008455689996480942
10 0.0074362989 	 0.0084556899
epoch_time;  41.103819131851196
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0023013779427856207
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0037113528233021498
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.003242331789806485
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.00440487265586853
11 0.0072927937 	 0.0044048726
epoch_time;  43.31219005584717
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0027807974256575108
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.003782133338972926
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0031847392674535513
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.0043990882113575935
12 0.0061050866 	 0.0043990882
epoch_time;  41.89182734489441
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.015071861445903778
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.020024318248033524
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.010591879487037659
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.013360898941755295
13 0.0060798304 	 0.0133608994
epoch_time;  41.511178731918335
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.006578048691153526
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.009439344517886639
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.007510034833103418
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.01032690517604351
14 0.0056395704 	 0.0103269056
epoch_time;  41.38973116874695
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.001407151808962226
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                              Epoch ▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇███
wandb: Test loss t(-10, 10)_r(-5, 5)_none ▄▃▃▄▂▂█▂▂▁▂▁▁▃▂▁▂▁▁▁▂▁▂▁▂▁▁▅▁▁▁
wandb:  Test loss t(-10, 10)_r(0, 0)_none ▄▃▃▄▂▁█▂▂▁▂▁▁▄▂▁▂▁▁▁▂▁▂▁▂▁▁▄▁▁▁
wandb:    Test loss t(0, 0)_r(-5, 5)_none ▄▃▃▄▂▂█▂▂▁▂▁▁▃▂▁▂▁▁▁▂▁▂▁▂▁▁▄▁▁▁
wandb:     Test loss t(0, 0)_r(0, 0)_none ▃▂▂▄▂▁█▂▃▁▂▁▁▃▂▁▂▁▁▁▂▁▂▁▂▁▁▃▁▁▁
wandb:                         Train loss █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                              Epoch 29
wandb: Test loss t(-10, 10)_r(-5, 5)_none 0.00145
wandb:  Test loss t(-10, 10)_r(0, 0)_none 0.00109
wandb:    Test loss t(0, 0)_r(-5, 5)_none 0.00111
wandb:     Test loss t(0, 0)_r(0, 0)_none 0.00078
wandb:                         Train loss 0.00391
wandb: 
wandb: 🚀 View run glistening-festival-1666 at: https://wandb.ai/nreints/thesis/runs/d5n85wez
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230127_112209-d5n85wez/logs
/gpfs/home2/nreints/MScThesis/code/lstm.py:270: DeprecationWarning: Sampling from a set deprecated
since Python 3.9 and will be removed in a subsequent version.
  train_sims = set(random.sample(sims_train, int(0.8 * n_sims_train)))
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.13.9 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.8
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230127_114355-a19tx173
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run radiant-monkey-1673
wandb: ⭐️ View project at https://wandb.ai/nreints/thesis
wandb: 🚀 View run at https://wandb.ai/nreints/thesis/runs/a19tx173
/home/nreints/.conda/envs/thesis/lib/python3.10/site-packages/torch/nn/modules/rnn.py:67: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  warnings.warn("dropout option adds dropout after all but last "
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.002078637946397066
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0021791832987219095
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.003018749412149191
15 0.005651222 	 0.0030187494
epoch_time;  40.83277726173401
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.003804820589721203
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.005302400328218937
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.004458022769540548
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.006397523917257786
16 0.0049445977 	 0.0063975239
epoch_time;  41.08705973625183
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.001085862284526229
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.001567647559568286
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.001535039278678596
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.0020256731659173965
17 0.0050507281 	 0.0020256732
epoch_time;  41.04510545730591
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.000801519607193768
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0011555291712284088
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.001207082998007536
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.001634175656363368
18 0.0058366471 	 0.0016341757
epoch_time;  40.96658229827881
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.001784786581993103
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0023930512834340334
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.001818598248064518
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.0023516984656453133
19 0.0040481475 	 0.0023516984
epoch_time;  41.373679876327515
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.004896596539765596
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.006647917442023754
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.004294469952583313
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.005850430112332106
20 0.0043471627 	 0.0058504303
epoch_time;  41.26292681694031
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.001564734266139567
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.002242437796667218
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0024837853852659464
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.003476934041827917
21 0.0047754054 	 0.0034769341
epoch_time;  40.79306173324585
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.004012957215309143
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0058385333977639675
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.004645270761102438
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.00645259628072381
22 0.0042206463 	 0.0064525964
epoch_time;  40.85171723365784
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0007201458211056888
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.000997163588181138
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0011732140555977821
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.0015360723482444882
23 0.0040262126 	 0.0015360724
epoch_time;  41.353251457214355
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.008168622851371765
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.01151589211076498
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.00818094052374363
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.011115091852843761
24 0.0038851143 	 0.0111150922
epoch_time;  41.017985582351685
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.001170916948467493
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0017142039723694324
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.001573559595271945
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.002097799675539136
25 0.00367444 	 0.0020977997
epoch_time;  40.52215266227722
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.002667324850335717
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0036678242031484842
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.002860843203961849
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.0038239562418311834
26 0.0046042032 	 0.0038239563
epoch_time;  41.49572134017944
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.014492601156234741
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.021332938224077225
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.01965189352631569
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.02773515321314335
27 0.0039479464 	 0.0277351541
epoch_time;  41.42764377593994
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0019722962751984596
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0026646724436432123
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0020808978006243706
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.0027190716937184334
28 0.0032049998 	 0.0027190717
epoch_time;  40.84898352622986
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0007805308559909463
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0010942633962258697
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0011141850845888257
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.0014539518160745502
29 0.0039065074 	 0.0014539519
epoch_time;  40.93347406387329
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0007803186890669167
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0010941883083432913
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0011145815951749682
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.0014545406447723508
It took  1306.4160578250885  seconds.
----- ITERATION 2/10 ------
[<torch.utils.data.dataloader.DataLoader object at 0x151f0347a3e0>, <torch.utils.data.dataloader.DataLoader object at 0x151f344611e0>, <torch.utils.data.dataloader.DataLoader object at 0x151f2dfc79d0>, <torch.utils.data.dataloader.DataLoader object at 0x151f0347a410>]
LSTM(
  (lstm): LSTM(8, 96, batch_first=True, dropout=0.2)
  (layers): Sequential(
    (0): Linear(in_features=96, out_features=8, bias=True)
  )
)
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.013697327114641666
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.022580498829483986
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.021680407226085663
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.033941905945539474
0 3.0165453787 	 0.0339419057
epoch_time;  41.6122522354126
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.009137504734098911
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.01595035195350647
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.014388690702617168
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.022193320095539093
1 0.0300222421 	 0.0221933195
epoch_time;  43.26612854003906
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0089927539229393
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.014661059714853764
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.014844613149762154
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.02203119546175003
2 0.0210155571 	 0.0220311963
epoch_time;  42.0861713886261
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.002839217195287347
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.005290857516229153
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.005204188171774149
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.008454520255327225
3 0.018098463 	 0.0084545202
epoch_time;  40.99063539505005
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.02017989195883274
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.027035627514123917
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.014331807382404804
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.020229650661349297
4 0.0147588558 	 0.0202296508
epoch_time;  41.498159885406494
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.026832886040210724
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.042396482080221176
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.05949167162179947
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.08779743313789368
5 0.0137787067 	 0.0877974357
epoch_time;  41.5053596496582
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.011447339318692684
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.014343643561005592
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.008838952518999577
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.012201983481645584
6 0.0104236653 	 0.0122019834
epoch_time;  41.443055152893066
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0038543017581105232
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.005793334450572729
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                              Epoch ▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇███
wandb: Test loss t(-10, 10)_r(-5, 5)_none ▄▃▃▂▂█▂▁▁▁▂▂▁▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  Test loss t(-10, 10)_r(0, 0)_none ▅▃▃▂▅█▃▂▁▁▂▄▁▂▁▃▁▂▁▁▁▁▁▁▁▁▂▁▂▂▂
wandb:    Test loss t(0, 0)_r(-5, 5)_none ▃▃▃▁▃█▂▁▁▁▂▂▁▂▁▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     Test loss t(0, 0)_r(0, 0)_none ▄▃▃▂▆█▄▂▁▁▂▅▁▂▁▄▁▂▁▁▁▁▁▁▁▁▂▁▂▂▂
wandb:                         Train loss █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                              Epoch 29
wandb: Test loss t(-10, 10)_r(-5, 5)_none 0.0042
wandb:  Test loss t(-10, 10)_r(0, 0)_none 0.00595
wandb:    Test loss t(0, 0)_r(-5, 5)_none 0.00312
wandb:     Test loss t(0, 0)_r(0, 0)_none 0.00444
wandb:                         Train loss 0.00282
wandb: 
wandb: 🚀 View run radiant-monkey-1673 at: https://wandb.ai/nreints/thesis/runs/a19tx173
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230127_114355-a19tx173/logs
/gpfs/home2/nreints/MScThesis/code/lstm.py:270: DeprecationWarning: Sampling from a set deprecated
since Python 3.9 and will be removed in a subsequent version.
  train_sims = set(random.sample(sims_train, int(0.8 * n_sims_train)))
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.13.9 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.8
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230127_120546-056jywlz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run festive-rabbit-1681
wandb: ⭐️ View project at https://wandb.ai/nreints/thesis
wandb: 🚀 View run at https://wandb.ai/nreints/thesis/runs/056jywlz
/home/nreints/.conda/envs/thesis/lib/python3.10/site-packages/torch/nn/modules/rnn.py:67: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  warnings.warn("dropout option adds dropout after all but last "
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.004659464582800865
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.006877838633954525
7 0.0095522842 	 0.0068778387
epoch_time;  41.25058317184448
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0021565097849816084
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.003737429156899452
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.003539694007486105
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.005507881753146648
8 0.0090512479 	 0.0055078815
epoch_time;  41.44523787498474
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0016734059900045395
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.002736814320087433
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.002508028643205762
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.003819206263870001
9 0.00728766 	 0.0038192063
epoch_time;  41.40374159812927
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0030760793015360832
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.004853888414800167
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.007058010436594486
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.010407695546746254
10 0.0071217669 	 0.0104076956
epoch_time;  41.585787773132324
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.014520471915602684
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.021523313596844673
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.012413867749273777
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.017388135194778442
11 0.0070423621 	 0.0173881349
epoch_time;  40.76898813247681
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.001733815181069076
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.002773278160020709
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.002870546653866768
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.00429112184792757
12 0.0064297112 	 0.0042911217
epoch_time;  41.341309785842896
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.004688757937401533
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.007543131709098816
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.009603838436305523
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.014272600412368774
13 0.0058580896 	 0.0142726005
epoch_time;  41.26881718635559
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0007109650759957731
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0013218377716839314
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0012938875006511807
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.0020252708345651627
14 0.0069639197 	 0.0020252708
epoch_time;  41.44818615913391
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.010369271039962769
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.014206177555024624
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.014203849248588085
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.02039339393377304
15 0.0043328947 	 0.0203933946
epoch_time;  41.71770143508911
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0007572279428131878
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0013768182834610343
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0013797471765428782
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.0021724349353462458
16 0.0061521682 	 0.002172435
epoch_time;  41.62695097923279
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.002896350109949708
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.004405222367495298
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.002892344491556287
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.004217000678181648
17 0.004087072 	 0.0042170005
epoch_time;  41.347909450531006
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0015466294717043638
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.002549792407080531
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.002133228350430727
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.0031196018680930138
18 0.0043642923 	 0.0031196019
epoch_time;  41.58902931213379
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.000767761841416359
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0014023716794326901
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0013142129173502326
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.002039471874013543
19 0.0075946349 	 0.0020394718
epoch_time;  41.3246750831604
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.002150994725525379
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0031492176931351423
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0023867820855230093
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.0034545869566500187
20 0.0030583213 	 0.0034545869
epoch_time;  41.10600829124451
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.001756130252033472
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0024728565476834774
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0019016332225874066
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.0027237380854785442
21 0.0039585256 	 0.0027237381
epoch_time;  40.95915913581848
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0009974604472517967
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0015854265075176954
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0015742492396384478
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.002258486347272992
22 0.0044083231 	 0.0022584864
epoch_time;  40.87547826766968
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.001128807314671576
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0018165134824812412
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0018273235764354467
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.002698848955333233
23 0.0036518749 	 0.002698849
epoch_time;  43.26516890525818
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0009011909714899957
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0014573810622096062
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.00150264089461416
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.0021549975499510765
24 0.0038847219 	 0.0021549976
epoch_time;  41.85560750961304
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0010709575144574046
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0016480637714266777
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0014452760806307197
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.0020414101891219616
25 0.0038144915 	 0.0020414101
epoch_time;  41.1672477722168
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0030732492450624704
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.004425264894962311
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0032360053155571222
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.004647874739021063
26 0.0035679707 	 0.0046478748
epoch_time;  40.96823740005493
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0011376383481547236
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0017891344614326954
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.002602545078843832
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.003734012134373188
27 0.0036925894 	 0.003734012
epoch_time;  41.029147148132324
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.003494902281090617
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.004683574195951223
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.003636992536485195
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.005094888154417276
28 0.0039226881 	 0.0050948883
epoch_time;  41.2124388217926
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.004443695303052664
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.00594520615413785
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0031199257355183363
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.00419808691367507
29 0.0028217658 	 0.0041980869
epoch_time;  41.40019416809082
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.004443129524588585
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.005945267155766487
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.003118023509159684
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.00419885478913784
It took  1311.0513677597046  seconds.
----- ITERATION 3/10 ------
[<torch.utils.data.dataloader.DataLoader object at 0x151f0347aad0>, <torch.utils.data.dataloader.DataLoader object at 0x151f2df95240>, <torch.utils.data.dataloader.DataLoader object at 0x151f2df96c20>, <torch.utils.data.dataloader.DataLoader object at 0x151f2df96dd0>]
LSTM(
  (lstm): LSTM(8, 96, batch_first=True, dropout=0.2)
  (layers): Sequential(
    (0): Linear(in_features=96, out_features=8, bias=True)
  )
)
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.04209326580166817
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.05518229678273201
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.03690497204661369
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.04924686625599861
0 3.8260935134 	 0.0492468658
epoch_time;  40.87318778038025
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.008966278284788132
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.014303479343652725
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.016104478389024734
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.02208702452480793
1 0.0296949665 	 0.0220870251
epoch_time;  40.85060930252075
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.019605163484811783
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.02754146046936512
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.020323090255260468
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.027215683832764626
2 0.0226404853 	 0.0272156839
epoch_time;  40.69655966758728
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.01295730471611023
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.017905218526721
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.010470148175954819
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.014414442703127861
3 0.0183385218 	 0.014414443
epoch_time;  40.916505098342896
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.004019359592348337
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.006654144264757633
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.005890735890716314
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.00822196714580059
4 0.0170135989 	 0.008221967
epoch_time;  40.87382388114929
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0392632931470871
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.053919367492198944
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.03225664049386978
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.04459352046251297
5 0.013283261 	 0.04459352
epoch_time;  40.88725256919861
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0038571853656321764
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.005622293800115585
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0052197654731571674
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.007161958143115044
6 0.0116507641 	 0.007161958
epoch_time;  41.2171733379364
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0017271996475756168
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0030595334246754646
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0034155859611928463
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.00497619342058897
7 0.0109221901 	 0.0049761934
epoch_time;  41.25763702392578
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.004452034831047058
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.006976861506700516
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.005809654016047716
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.00885250698775053
8 0.0094122472 	 0.0088525071
epoch_time;  40.646071672439575
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.019731003791093826
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.026190336793661118
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.01352596003562212
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.017996735870838165
9 0.0085108134 	 0.0179967362
epoch_time;  41.109277963638306
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0054216766729950905
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.007709477096796036
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.005311976186931133
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.0071477992460131645
10 0.0076393341 	 0.0071477991
epoch_time;  40.82859921455383
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0018147605005651712
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0028094067238271236
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0026397304609417915
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.003797811223194003
11 0.0073049366 	 0.0037978113
epoch_time;  40.90154576301575
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.002202478237450123
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.00335740321315825
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0031439419835805893
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.004642345942556858
12 0.0067783777 	 0.0046423461
epoch_time;  40.54492449760437
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0009946328354999423
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.001669662189669907
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0017228913493454456
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.002451987937092781
13 0.00651684 	 0.002451988
epoch_time;  41.190885066986084
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.001813633949495852
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0028402896132320166
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.002394279232248664
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.0034323164727538824
14 0.006332692 	 0.0034323164
epoch_time;  41.42561340332031
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0008886429714038968
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0013806835049763322
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.001498233643360436
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.0021168089006096125
15 0.005950618 	 0.0021168089
epoch_time;  41.6975462436676
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0019787983037531376
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0028706458397209644
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0023091360926628113
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.003344631288200617
16 0.0050377608 	 0.0033446313
epoch_time;  40.94473433494568
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0008543655276298523
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.001354450243525207
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0016044535441324115
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.0022988079581409693
17 0.0055347193 	 0.002298808
epoch_time;  40.565452098846436
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0019381203455850482
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.002627966459840536
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.003029816783964634
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.004080446902662516
18 0.0048375133 	 0.0040804468
epoch_time;  41.0210964679718
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0016127127455547452
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.00252974103204906
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.002361318562179804
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.0034339551348239183
19 0.0046745029 	 0.003433955
epoch_time;  41.05113077163696
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0011600289726629853
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0016863938653841615
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0015261691296473145
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.0021071198862046003
20 0.0048118479 	 0.00210712
epoch_time;  40.56516790390015
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.006769679952412844
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.008821913041174412
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.006839551031589508
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.009106150828301907
21 0.0047997331 	 0.0091061506
epoch_time;  41.31006050109863
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0011508135357871652
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0018127673538401723
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0021373536437749863
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.0028554676100611687
22 0.0042489945 	 0.0028554677
epoch_time;  41.04149055480957
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.00097683968488127
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0014723432250320911
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0016363444738090038
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.0023158809635788202
23 0.0040389223 	 0.0023158808
epoch_time;  40.33990216255188
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                              Epoch ▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇███
wandb: Test loss t(-10, 10)_r(-5, 5)_none █▄▅▃▂▇▂▁▂▃▂▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁
wandb:  Test loss t(-10, 10)_r(0, 0)_none █▃▄▃▂█▂▁▂▄▂▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁
wandb:    Test loss t(0, 0)_r(-5, 5)_none █▄▅▃▂▇▂▁▂▃▂▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁
wandb:     Test loss t(0, 0)_r(0, 0)_none █▂▄▃▂█▂▁▂▄▂▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁
wandb:                         Train loss █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                              Epoch 29
wandb: Test loss t(-10, 10)_r(-5, 5)_none 0.00291
wandb:  Test loss t(-10, 10)_r(0, 0)_none 0.00278
wandb:    Test loss t(0, 0)_r(-5, 5)_none 0.00212
wandb:     Test loss t(0, 0)_r(0, 0)_none 0.00188
wandb:                         Train loss 0.0034
wandb: 
wandb: 🚀 View run festive-rabbit-1681 at: https://wandb.ai/nreints/thesis/runs/056jywlz
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230127_120546-056jywlz/logs
/gpfs/home2/nreints/MScThesis/code/lstm.py:270: DeprecationWarning: Sampling from a set deprecated
since Python 3.9 and will be removed in a subsequent version.
  train_sims = set(random.sample(sims_train, int(0.8 * n_sims_train)))
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.13.9 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.8
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230127_122721-ufc7502p
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run crimson-wish-1686
wandb: ⭐️ View project at https://wandb.ai/nreints/thesis
wandb: 🚀 View run at https://wandb.ai/nreints/thesis/runs/ufc7502p
/home/nreints/.conda/envs/thesis/lib/python3.10/site-packages/torch/nn/modules/rnn.py:67: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  warnings.warn("dropout option adds dropout after all but last "
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0007863042992539704
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0011929040774703026
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0012836068635806441
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.001746167428791523
24 0.0041469271 	 0.0017461674
epoch_time;  41.20099854469299
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0009820141131058335
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0014823009259998798
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0018624430522322655
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.0025193931069225073
25 0.00394428 	 0.0025193931
epoch_time;  40.83104944229126
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.000802184222266078
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.00125500385183841
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0013069299748167396
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.0018028590129688382
26 0.0040265718 	 0.001802859
epoch_time;  40.66108775138855
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.001424761489033699
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0019334095995873213
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.001758613041602075
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.0023387435358017683
27 0.0035142314 	 0.0023387436
epoch_time;  40.82418990135193
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0007379318121820688
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.001087181968614459
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0012263120152056217
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.001625532633624971
28 0.0040947646 	 0.0016255327
epoch_time;  41.110448598861694
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0018765662098303437
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.002780099166557193
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0021147215738892555
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.002907747868448496
29 0.0033998421 	 0.0029077478
epoch_time;  41.055569887161255
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0018758662045001984
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.00277863466180861
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0021154561545699835
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.002911084797233343
It took  1294.5381529331207  seconds.
----- ITERATION 4/10 ------
[<torch.utils.data.dataloader.DataLoader object at 0x151f344617e0>, <torch.utils.data.dataloader.DataLoader object at 0x151f2d80c730>, <torch.utils.data.dataloader.DataLoader object at 0x151f2d80ec50>, <torch.utils.data.dataloader.DataLoader object at 0x151f2d80edd0>]
LSTM(
  (lstm): LSTM(8, 96, batch_first=True, dropout=0.2)
  (layers): Sequential(
    (0): Linear(in_features=96, out_features=8, bias=True)
  )
)
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.02094607800245285
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.037041593343019485
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.025476893410086632
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.04087328165769577
0 3.7113962108 	 0.0408732826
epoch_time;  41.29730415344238
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.010275219567120075
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.017751023173332214
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.013609986752271652
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.020613914355635643
1 0.0322650993 	 0.0206139153
epoch_time;  41.203431129455566
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.02740912139415741
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.03886472061276436
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.030842676758766174
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.0422058030962944
2 0.0240268476 	 0.0422058019
epoch_time;  40.95189309120178
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.02559751830995083
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0326809324324131
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.017028843984007835
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.022984255105257034
3 0.0195735409 	 0.0229842555
epoch_time;  41.031907081604004
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.036223143339157104
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.05156347528100014
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.028403930366039276
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.03863532841205597
4 0.0158218439 	 0.0386353288
epoch_time;  41.63971018791199
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.015397823415696621
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.022450421005487442
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.01184089481830597
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.016363242641091347
5 0.0146587698 	 0.0163632433
epoch_time;  42.10153365135193
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.002604191657155752
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.004559959750622511
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.004001465626060963
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.0059730480425059795
6 0.0112194152 	 0.0059730481
epoch_time;  41.03581094741821
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.012575414963066578
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.018879925832152367
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.011930624954402447
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.017158756032586098
7 0.0108498061 	 0.0171587561
epoch_time;  41.354326009750366
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.00784334633499384
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.011592033319175243
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.009823322296142578
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.013912126421928406
8 0.0096558781 	 0.013912126
epoch_time;  40.95623302459717
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0025333117228001356
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.004399552009999752
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0051375520415604115
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.007925732992589474
9 0.0079771543 	 0.007925733
epoch_time;  41.251765966415405
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0028509299736469984
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.004262242931872606
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0030002885032445192
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.004335035569965839
10 0.008123862 	 0.0043350357
epoch_time;  41.342012882232666
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0024201623164117336
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0037200304213911295
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0031821993179619312
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.004772735759615898
11 0.0071053292 	 0.0047727359
epoch_time;  40.934711933135986
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.00486543495208025
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.007267509121447802
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.004669578280299902
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.006417007185518742
12 0.0068478617 	 0.0064170072
epoch_time;  40.834179162979126
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.002291659126058221
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.003713646437972784
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0027251834981143475
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.0040042344480752945
13 0.0062991293 	 0.0040042343
epoch_time;  41.225433588027954
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0027063325978815556
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.004064654465764761
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.003149456111714244
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.004704352002590895
14 0.0061076631 	 0.0047043519
epoch_time;  40.8046612739563
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0011753971921280026
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0019329710630699992
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0017560380510985851
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.0025433707050979137
15 0.0055819402 	 0.0025433707
epoch_time;  40.97298049926758
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.008443250320851803
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                              Epoch ▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇███
wandb: Test loss t(-10, 10)_r(-5, 5)_none █▄█▅▇▄▂▄▃▂▁▂▂▁▁▁▃▂▂▂▂▁▁▁▁▁▁▁▂▁▁
wandb:  Test loss t(-10, 10)_r(0, 0)_none ▆▃▆▅█▄▁▃▂▁▁▁▂▁▁▁▂▂▂▂▂▁▁▁▁▁▁▁▂▁▁
wandb:    Test loss t(0, 0)_r(-5, 5)_none ▇▄█▅▇▃▂▄▃▂▁▁▂▁▁▁▃▂▂▂▂▁▁▁▁▁▁▁▂▁▁
wandb:     Test loss t(0, 0)_r(0, 0)_none ▅▃▆▆█▄▁▃▂▁▁▁▂▁▁▁▂▂▂▂▂▁▁▁▁▁▁▁▂▁▁
wandb:                         Train loss █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                              Epoch 29
wandb: Test loss t(-10, 10)_r(-5, 5)_none 0.00244
wandb:  Test loss t(-10, 10)_r(0, 0)_none 0.00217
wandb:    Test loss t(0, 0)_r(-5, 5)_none 0.00173
wandb:     Test loss t(0, 0)_r(0, 0)_none 0.0015
wandb:                         Train loss 0.00348
wandb: 
wandb: 🚀 View run crimson-wish-1686 at: https://wandb.ai/nreints/thesis/runs/ufc7502p
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230127_122721-ufc7502p/logs
/gpfs/home2/nreints/MScThesis/code/lstm.py:270: DeprecationWarning: Sampling from a set deprecated
since Python 3.9 and will be removed in a subsequent version.
  train_sims = set(random.sample(sims_train, int(0.8 * n_sims_train)))
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.13.9 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.8
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230127_124905-phzwik19
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run beaming-wish-1691
wandb: ⭐️ View project at https://wandb.ai/nreints/thesis
wandb: 🚀 View run at https://wandb.ai/nreints/thesis/runs/phzwik19
/home/nreints/.conda/envs/thesis/lib/python3.10/site-packages/torch/nn/modules/rnn.py:67: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  warnings.warn("dropout option adds dropout after all but last "
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.011471464298665524
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.008735486306250095
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.012538712471723557
16 0.005516837 	 0.0125387126
epoch_time;  41.52623438835144
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.003973178565502167
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.005478542298078537
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0036005263682454824
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.005094343330711126
17 0.0055932775 	 0.0050943434
epoch_time;  41.09480333328247
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.004375239368528128
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.006696346681565046
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.004877416417002678
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.007213755510747433
18 0.0047600358 	 0.0072137553
epoch_time;  41.27961802482605
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.005975013133138418
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.009194868616759777
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.006879327353090048
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.010402512736618519
19 0.0050499076 	 0.0104025123
epoch_time;  41.05614256858826
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0037565187085419893
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.005968274082988501
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0055357925593853
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.008307124488055706
20 0.004396009 	 0.0083071242
epoch_time;  41.00145936012268
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0017330158734694123
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.002551359822973609
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.002324881264939904
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.003343054559081793
21 0.0047373172 	 0.0033430545
epoch_time;  41.27996253967285
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0009197497274726629
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0014712431002408266
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.001308963866904378
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.0018793789204210043
22 0.0048630539 	 0.0018793789
epoch_time;  41.16294574737549
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0014867710415273905
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.002271217992529273
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.002012750366702676
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.002853099722415209
23 0.0039792079 	 0.0028530997
epoch_time;  41.324796199798584
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0010013908613473177
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0015617277240380645
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0015295288758352399
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.002139777410775423
24 0.0042745524 	 0.0021397774
epoch_time;  41.29174852371216
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0010013715364038944
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0015377989038825035
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0014347098767757416
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.0019995486363768578
25 0.003910609 	 0.0019995486
epoch_time;  41.44942331314087
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0011013501789420843
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0017107389867305756
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.001449432224035263
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.0020536065567284822
26 0.0041338464 	 0.0020536065
epoch_time;  41.359301805496216
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0014826784608885646
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0023476688656955957
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.002397360047325492
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.0034325008746236563
27 0.0037004823 	 0.0034325008
epoch_time;  41.633113861083984
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0038553758058696985
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.005723962094634771
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.006923217326402664
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.00991083588451147
28 0.0039292562 	 0.0099108363
epoch_time;  41.017433643341064
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0014959760010242462
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.002171975327655673
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0017338095931336284
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.002439443953335285
29 0.0034816173 	 0.002439444
epoch_time;  41.347126960754395
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.001495475065894425
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.002168313367292285
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0017344974912703037
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.0024390737526118755
It took  1304.1702098846436  seconds.
----- ITERATION 5/10 ------
[<torch.utils.data.dataloader.DataLoader object at 0x151f2df95840>, <torch.utils.data.dataloader.DataLoader object at 0x151f3450e920>, <torch.utils.data.dataloader.DataLoader object at 0x151f03479de0>, <torch.utils.data.dataloader.DataLoader object at 0x151f017e9e40>]
LSTM(
  (lstm): LSTM(8, 96, batch_first=True, dropout=0.2)
  (layers): Sequential(
    (0): Linear(in_features=96, out_features=8, bias=True)
  )
)
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.05042661726474762
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0715864971280098
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.04704253375530243
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.06717963516712189
0 2.0991429019 	 0.0671796367
epoch_time;  41.05708312988281
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.008230414241552353
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.011596234515309334
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.009962256997823715
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.014604729600250721
1 0.0303446952 	 0.0146047298
epoch_time;  41.233158111572266
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.024318337440490723
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.03522501140832901
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.02300584316253662
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.03199617192149162
2 0.0219786108 	 0.0319961709
epoch_time;  41.22865390777588
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.009474309161305428
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.01450689509510994
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.009910526685416698
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.01430157944560051
3 0.0189045466 	 0.0143015795
epoch_time;  40.76646447181702
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.003377375192940235
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.005358324386179447
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0064644902013242245
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.009826412424445152
4 0.016881924 	 0.0098264124
epoch_time;  40.76099252700806
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.008461563847959042
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.01289449818432331
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.013284116052091122
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.018005743622779846
5 0.0141194536 	 0.0180057428
epoch_time;  40.65138006210327
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.009553766809403896
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.013791516423225403
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.00984241720288992
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.0140256742015481
6 0.0111091659 	 0.0140256738
epoch_time;  40.97855281829834
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.006796751171350479
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.009045117534697056
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.008603380061686039
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.011760422959923744
7 0.0103220055 	 0.0117604228
epoch_time;  40.99428725242615
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.02016288973391056
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.02788611687719822
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                              Epoch ▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇███
wandb: Test loss t(-10, 10)_r(-5, 5)_none █▂▄▂▂▃▂▂▃▂▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  Test loss t(-10, 10)_r(0, 0)_none █▂▄▂▁▂▂▂▄▂▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:    Test loss t(0, 0)_r(-5, 5)_none █▂▄▂▂▃▂▂▃▂▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     Test loss t(0, 0)_r(0, 0)_none █▂▄▂▁▂▂▂▄▂▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:                         Train loss █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                              Epoch 29
wandb: Test loss t(-10, 10)_r(-5, 5)_none 0.00251
wandb:  Test loss t(-10, 10)_r(0, 0)_none 0.00181
wandb:    Test loss t(0, 0)_r(-5, 5)_none 0.00174
wandb:     Test loss t(0, 0)_r(0, 0)_none 0.00116
wandb:                         Train loss 0.00354
wandb: 
wandb: 🚀 View run beaming-wish-1691 at: https://wandb.ai/nreints/thesis/runs/phzwik19
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230127_124905-phzwik19/logs
/gpfs/home2/nreints/MScThesis/code/lstm.py:270: DeprecationWarning: Sampling from a set deprecated
since Python 3.9 and will be removed in a subsequent version.
  train_sims = set(random.sample(sims_train, int(0.8 * n_sims_train)))
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.13.9 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.8
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230127_131041-d4npg1po
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lucky-snake-1696
wandb: ⭐️ View project at https://wandb.ai/nreints/thesis
wandb: 🚀 View run at https://wandb.ai/nreints/thesis/runs/d4npg1po
/home/nreints/.conda/envs/thesis/lib/python3.10/site-packages/torch/nn/modules/rnn.py:67: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  warnings.warn("dropout option adds dropout after all but last "
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.015313844196498394
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.02179848402738571
8 0.0091107352 	 0.0217984839
epoch_time;  41.00037932395935
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.005949389189481735
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.008789924904704094
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.007247996982187033
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.009822106920182705
9 0.0085424168 	 0.0098221072
epoch_time;  41.07949471473694
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.001825134502723813
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.002718345494940877
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0021791676990687847
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.0032135630026459694
10 0.0077669041 	 0.003213563
epoch_time;  41.16287088394165
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0009933129185810685
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0014995887177065015
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0014120186679065228
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.0021492717787623405
11 0.0083050197 	 0.0021492718
epoch_time;  40.65953969955444
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.009476791135966778
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.014231042005121708
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.009731344878673553
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.014033854939043522
12 0.0063738956 	 0.0140338549
epoch_time;  41.05822682380676
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0010531148873269558
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0015450617065653205
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.001475099241361022
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.002097886288538575
13 0.0060093318 	 0.0020978863
epoch_time;  41.029441595077515
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0010997540084645152
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0017998600378632545
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0017814553575590253
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.002812396502122283
14 0.0214874475 	 0.0028123965
epoch_time;  41.0289580821991
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.002389361383393407
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.00407377677038312
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.003942426759749651
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.0058868443593382835
15 0.0034894929 	 0.0058868443
epoch_time;  41.28275418281555
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0008791886502876878
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0014245944330468774
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0014292281121015549
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.002110439818352461
16 0.0053400203 	 0.0021104398
epoch_time;  41.675395011901855
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.001571516739204526
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0022334428504109383
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0018675659084692597
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.0025750696659088135
17 0.0051648976 	 0.0025750696
epoch_time;  41.51586604118347
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0012127957306802273
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0018529967637732625
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.001796217169612646
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.0026453989557921886
18 0.0052814451 	 0.0026453989
epoch_time;  40.868332624435425
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0017117636743932962
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0025514152366667986
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0033120273146778345
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.004622568842023611
19 0.0048145779 	 0.0046225689
epoch_time;  40.903462648391724
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0014180811122059822
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0022773356176912785
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0019281632266938686
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.002904473105445504
20 0.0045688486 	 0.0029044731
epoch_time;  41.18308734893799
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0009622822981327772
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0013970609288662672
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0014489188324660063
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.002057295525446534
21 0.0061211525 	 0.0020572956
epoch_time;  40.803948402404785
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0029124231077730656
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.003967583179473877
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0034746858291327953
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.004815856460481882
22 0.0041616488 	 0.0048158565
epoch_time;  40.95419788360596
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0015652459114789963
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.002251742873340845
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0020291118416935205
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.0028558385092765093
23 0.0041148285 	 0.0028558386
epoch_time;  40.855060338974
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0008769324631430209
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0013265270972624421
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0012744744308292866
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.001767766778357327
24 0.0042809415 	 0.0017677668
epoch_time;  40.47671675682068
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.000960395613219589
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0013571978779509664
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0013924280647188425
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.0019142264500260353
25 0.0038924546 	 0.0019142264
epoch_time;  40.98584032058716
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.002687780885025859
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.003541175276041031
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0021885016467422247
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.0029523861594498158
26 0.0040279175 	 0.0029523862
epoch_time;  41.4075870513916
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0012436360120773315
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.001720493077300489
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0016871885163709521
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.0022971301805227995
27 0.0038031554 	 0.0022971302
epoch_time;  40.911497592926025
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.002056475030258298
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0028155427426099777
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0020313523709774017
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.0027248745318502188
28 0.003452849 	 0.0027248744
epoch_time;  41.25714659690857
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0011603434104472399
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0018050980288535357
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.001743918051943183
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.0025101760402321815
29 0.0035356309 	 0.0025101761
epoch_time;  41.01581048965454
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.001159985433332622
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0018051585648208857
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.001744624343700707
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.0025100361090153456
It took  1295.7367250919342  seconds.
----- ITERATION 6/10 ------
[<torch.utils.data.dataloader.DataLoader object at 0x151f017e9bd0>, <torch.utils.data.dataloader.DataLoader object at 0x151f2d80c8e0>, <torch.utils.data.dataloader.DataLoader object at 0x151f2d80ef20>, <torch.utils.data.dataloader.DataLoader object at 0x151f2d80f970>]
LSTM(
  (lstm): LSTM(8, 96, batch_first=True, dropout=0.2)
  (layers): Sequential(
    (0): Linear(in_features=96, out_features=8, bias=True)
  )
)
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.1144370436668396
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.14337776601314545
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.06216750293970108
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.08096223324537277
0 2.7134613337 	 0.0809622358
epoch_time;  41.32036089897156
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.005453124642372131
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.011054765433073044
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.00963588897138834
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.01592753827571869
1 0.0307408375 	 0.0159275381
epoch_time;  40.98900890350342
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.007430018857121468
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.012084483169019222
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.013002095744013786
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.018420172855257988
2 0.0192457137 	 0.0184201733
epoch_time;  41.20817565917969
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.006352137308567762
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.010176491923630238
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.006543360650539398
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.010294439271092415
3 0.0188307275 	 0.0102944388
epoch_time;  40.916783571243286
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.008125192485749722
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.012480530887842178
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.013142011128365993
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.02029993198812008
4 0.0148908469 	 0.0202999317
epoch_time;  40.90560007095337
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0026808390393853188
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.005001456942409277
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.004619141574949026
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.007081460207700729
5 0.0129892738 	 0.0070814604
epoch_time;  41.16135048866272
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.009819453582167625
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.01388759445399046
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.008665557950735092
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.012578822672367096
6 0.0115216744 	 0.0125788231
epoch_time;  41.54758286476135
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.01422418374568224
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0211485605686903
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.009976574219763279
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.014914522878825665
7 0.010005455 	 0.0149145227
epoch_time;  42.215118646621704
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0037059157621115446
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0062834047712385654
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.006020043510943651
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.009129395708441734
8 0.0091847485 	 0.009129396
epoch_time;  40.798158407211304
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.010219424962997437
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.014759770594537258
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.008952132426202297
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.012362529523670673
9 0.0085905214 	 0.0123625291
epoch_time;  41.00110054016113
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.008405043743550777
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.012642160058021545
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0071834661066532135
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.010102231055498123
10 0.0074995143 	 0.010102231
epoch_time;  41.14905333518982
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0019731915090233088
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.003305043326690793
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.002737094648182392
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.004164404701441526
11 0.0070938418 	 0.0041644047
epoch_time;  41.30615592002869
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0009565979125909507
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0018604355864226818
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0015993299894034863
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.0025223232805728912
12 0.0071936325 	 0.0025223232
epoch_time;  41.13131785392761
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0008835333283059299
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0016117789782583714
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0014243009500205517
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.002176022855564952
13 0.0058766927 	 0.0021760228
epoch_time;  41.006598711013794
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.005838871002197266
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.008101832121610641
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.005369079299271107
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.007682745344936848
14 0.0056956762 	 0.0076827456
epoch_time;  41.03415393829346
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.005233460571616888
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.007787901908159256
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.005001996178179979
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.007250737398862839
15 0.0058305839 	 0.0072507376
epoch_time;  40.87794518470764
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.00102931575383991
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.001860813470557332
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0014341442147269845
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.002144628670066595
16 0.0052517874 	 0.0021446286
epoch_time;  40.87639808654785
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0042380690574646
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.006357972510159016
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.004832926671952009
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.007489713840186596
17 0.0055285796 	 0.0074897137
epoch_time;  41.22332143783569
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.001229872927069664
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0020435145124793053
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0018164202338084579
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.0026819652412086725
18 0.0044709393 	 0.0026819652
epoch_time;  40.87217426300049
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0011568048503249884
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0017700419994071126
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0015919290017336607
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.0023242130409926176
19 0.0047639346 	 0.0023242131
epoch_time;  40.8806414604187
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0014157298719510436
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0020546207670122385
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0017311470583081245
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.0024121396709233522
20 0.0052551039 	 0.0024121396
epoch_time;  41.161821603775024
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.002168424427509308
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0032441287767142057
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0024660455528646708
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.0037236257921904325
21 0.0042239008 	 0.0037236257
epoch_time;  41.22086143493652
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.003270648419857025
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.004607222508639097
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.003029811894521117
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.004330556374043226
22 0.0042792233 	 0.0043305566
epoch_time;  40.87376165390015
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0014189692446962
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0023165515158325434
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0021537705324590206
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.003161887638270855
23 0.0040013193 	 0.0031618877
epoch_time;  40.847498178482056
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0018451563082635403
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.002859508153051138
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.002937279175966978
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.004127716179937124
24 0.0053570937 	 0.004127716
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                              Epoch ▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇███
wandb: Test loss t(-10, 10)_r(-5, 5)_none █▂▂▂▃▁▂▂▂▂▂▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▂▂▁▁
wandb:  Test loss t(-10, 10)_r(0, 0)_none █▁▂▁▂▁▂▂▁▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:    Test loss t(0, 0)_r(-5, 5)_none █▂▂▂▂▁▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁
wandb:     Test loss t(0, 0)_r(0, 0)_none █▁▁▁▁▁▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:                         Train loss █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                              Epoch 29
wandb: Test loss t(-10, 10)_r(-5, 5)_none 0.00186
wandb:  Test loss t(-10, 10)_r(0, 0)_none 0.0018
wandb:    Test loss t(0, 0)_r(-5, 5)_none 0.00139
wandb:     Test loss t(0, 0)_r(0, 0)_none 0.00129
wandb:                         Train loss 0.00333
wandb: 
wandb: 🚀 View run lucky-snake-1696 at: https://wandb.ai/nreints/thesis/runs/d4npg1po
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230127_131041-d4npg1po/logs
/gpfs/home2/nreints/MScThesis/code/lstm.py:270: DeprecationWarning: Sampling from a set deprecated
since Python 3.9 and will be removed in a subsequent version.
  train_sims = set(random.sample(sims_train, int(0.8 * n_sims_train)))
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.13.9 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.8
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230127_133221-5bhgcv36
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cheerful-festival-1702
wandb: ⭐️ View project at https://wandb.ai/nreints/thesis
wandb: 🚀 View run at https://wandb.ai/nreints/thesis/runs/5bhgcv36
/home/nreints/.conda/envs/thesis/lib/python3.10/site-packages/torch/nn/modules/rnn.py:67: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  warnings.warn("dropout option adds dropout after all but last "
epoch_time;  41.121867418289185
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0019680019468069077
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.002817189786583185
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0020841865334659815
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.0028550776187330484
25 0.0036099912 	 0.0028550776
epoch_time;  41.16448783874512
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.001424618298187852
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0021129141096025705
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0018929513171315193
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.0025921512860804796
26 0.0037051045 	 0.0025921513
epoch_time;  40.653228998184204
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.008351881988346577
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.011651506647467613
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.009677615016698837
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.014368541538715363
27 0.0038412933 	 0.0143685413
epoch_time;  40.61617374420166
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.002437351271510124
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0039477101527154446
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.005213338416069746
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.008076357655227184
28 0.0035122374 	 0.0080763573
epoch_time;  41.26847434043884
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.001289712032303214
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0017998679541051388
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0013926820829510689
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.0018634578445926309
29 0.0033343894 	 0.0018634578
epoch_time;  42.14249062538147
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0012896440457552671
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0018000026466324925
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0013922668294981122
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.0018621693598106503
It took  1299.7397067546844  seconds.
----- ITERATION 7/10 ------
[<torch.utils.data.dataloader.DataLoader object at 0x151f034796c0>, <torch.utils.data.dataloader.DataLoader object at 0x151f2defd750>, <torch.utils.data.dataloader.DataLoader object at 0x151f2d80d090>, <torch.utils.data.dataloader.DataLoader object at 0x151f2d80ce20>]
LSTM(
  (lstm): LSTM(8, 96, batch_first=True, dropout=0.2)
  (layers): Sequential(
    (0): Linear(in_features=96, out_features=8, bias=True)
  )
)
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.020928628742694855
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.031075073406100273
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.02249329164624214
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.033799607306718826
0 2.584599809 	 0.0337996065
epoch_time;  41.33098649978638
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.012575027532875538
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.021363453939557076
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.019327662885189056
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.030892571434378624
1 0.0267778407 	 0.0308925709
epoch_time;  40.884244203567505
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.030425461009144783
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.04165088012814522
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.02120411954820156
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.0288383886218071
2 0.0204334721 	 0.0288383881
epoch_time;  41.099913358688354
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.005233336240053177
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.008980169892311096
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.00902436301112175
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.014472037553787231
3 0.0178284916 	 0.014472038
epoch_time;  41.19856858253479
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.04861043393611908
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.06797973066568375
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.03805694729089737
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.052982147783041
4 0.0142464692 	 0.0529821459
epoch_time;  41.51562786102295
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.010394410230219364
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.01549079455435276
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.009627857245504856
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.013786930590867996
5 0.0134453265 	 0.0137869311
epoch_time;  40.743714332580566
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0033807463478296995
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.005881205201148987
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.00652338657528162
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.009827441535890102
6 0.0105557518 	 0.0098274417
epoch_time;  41.336198568344116
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0034613970201462507
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.006145856808871031
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.00465533509850502
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.007216284051537514
7 0.009909536 	 0.0072162843
epoch_time;  41.143455266952515
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.05243880674242973
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.06782729178667068
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.027667976915836334
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.036113154143095016
8 0.0091030935 	 0.0361131541
epoch_time;  41.172144651412964
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0018337497022002935
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0032685447949916124
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.002687428379431367
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.004349608905613422
9 0.0080660915 	 0.0043496088
epoch_time;  41.26312780380249
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0027434180956333876
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.004415809642523527
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0035422893706709146
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.005373616237193346
10 0.007069735 	 0.0053736162
epoch_time;  41.32506275177002
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.007926300168037415
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.012004341930150986
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.014512493275105953
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.020933719351887703
11 0.0072634507 	 0.0209337188
epoch_time;  41.136160373687744
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0018539131851866841
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0032416139729321003
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.002902041422203183
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.0043996465392410755
12 0.006425433 	 0.0043996464
epoch_time;  40.763132095336914
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.00154254084918648
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.002330658957362175
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.001905521610751748
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.002790243597701192
13 0.0059258813 	 0.0027902436
epoch_time;  41.235464572906494
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0011637945426627994
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0019391030073165894
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0018188573885709047
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.002648918889462948
14 0.0056999082 	 0.0026489188
epoch_time;  40.93427348136902
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0010213596979156137
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0017560551641508937
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.001782647450454533
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.002735425950959325
15 0.005555202 	 0.0027354261
epoch_time;  40.92230987548828
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.017547909170389175
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.024096740409731865
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.013223020359873772
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.018001452088356018
16 0.0053626352 	 0.0180014512
epoch_time;  41.34657335281372
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                              Epoch ▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇███
wandb: Test loss t(-10, 10)_r(-5, 5)_none ▄▄▃▂▅▂▂▁▄▁▁▃▁▁▁▁▂▁▁▁▁█▁▂▁▁▁▁▁▁▁
wandb:  Test loss t(-10, 10)_r(0, 0)_none ▄▃▅▂█▂▁▂█▁▁▂▁▁▁▁▃▁▁▁▁█▁▂▁▁▁▁▁▁▁
wandb:    Test loss t(0, 0)_r(-5, 5)_none ▄▃▄▂▆▂▂▁▅▁▁▃▁▁▁▁▃▁▁▁▁█▁▂▁▁▁▁▁▁▁
wandb:     Test loss t(0, 0)_r(0, 0)_none ▄▃▅▂▇▂▁▁█▁▁▂▁▁▁▁▃▁▁▂▁▇▁▂▁▁▁▁▁▁▁
wandb:                         Train loss █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                              Epoch 29
wandb: Test loss t(-10, 10)_r(-5, 5)_none 0.0042
wandb:  Test loss t(-10, 10)_r(0, 0)_none 0.00393
wandb:    Test loss t(0, 0)_r(-5, 5)_none 0.00281
wandb:     Test loss t(0, 0)_r(0, 0)_none 0.00262
wandb:                         Train loss 0.00326
wandb: 
wandb: 🚀 View run cheerful-festival-1702 at: https://wandb.ai/nreints/thesis/runs/5bhgcv36
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230127_133221-5bhgcv36/logs
/gpfs/home2/nreints/MScThesis/code/lstm.py:270: DeprecationWarning: Sampling from a set deprecated
since Python 3.9 and will be removed in a subsequent version.
  train_sims = set(random.sample(sims_train, int(0.8 * n_sims_train)))
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.13.9 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.8
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230127_135404-77ar826h
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run auspicious-wonton-1706
wandb: ⭐️ View project at https://wandb.ai/nreints/thesis
wandb: 🚀 View run at https://wandb.ai/nreints/thesis/runs/77ar826h
/home/nreints/.conda/envs/thesis/lib/python3.10/site-packages/torch/nn/modules/rnn.py:67: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  warnings.warn("dropout option adds dropout after all but last "
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0033352666068822145
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.004751831758767366
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.003966320771723986
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.005846717394888401
17 0.0049272291 	 0.0058467176
epoch_time;  41.05721378326416
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0028824235778301954
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.004208073485642672
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0029335191939026117
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.0041857073083519936
18 0.004879697 	 0.0041857072
epoch_time;  41.96192121505737
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.004544143099337816
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.006056385114789009
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0036455055233091116
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.005051130894571543
19 0.0044098987 	 0.005051131
epoch_time;  42.38518738746643
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.001024548546411097
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0014775313902646303
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0014477522345259786
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.002092173555865884
20 0.0042839483 	 0.0020921736
epoch_time;  41.50698900222778
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.044184159487485886
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.07074034959077835
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.05202927812933922
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.08295775949954987
21 0.0088079021 	 0.0829577604
epoch_time;  41.37092733383179
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0007131175952963531
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0011229361407458782
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0011783107183873653
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.0017176358960568905
22 0.0031087325 	 0.0017176359
epoch_time;  40.74330472946167
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.00511862151324749
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0074961064383387566
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.007729056291282177
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.011672554537653923
23 0.0036898446 	 0.0116725544
epoch_time;  41.036049127578735
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.000723633449524641
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.001111988560296595
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0011761769419535995
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.0016890421975404024
24 0.0038674064 	 0.0016890422
epoch_time;  40.93696928024292
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0010356480488553643
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0015532601391896605
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0013403862249106169
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.0018834080547094345
25 0.0038660798 	 0.0018834081
epoch_time;  41.28927755355835
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0013356476556509733
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0019574344623833895
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0016968990676105022
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.0023946769069880247
26 0.0037510014 	 0.0023946769
epoch_time;  41.429595708847046
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0008266523364000022
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0012922348687425256
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0012840989511460066
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.0018741756211966276
27 0.0070199411 	 0.0018741757
epoch_time;  41.059159994125366
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0008678435115143657
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0013375915586948395
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0015347965527325869
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.0022647229488939047
28 0.0031827462 	 0.002264723
epoch_time;  40.685757637023926
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0026236684061586857
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.003932511899620295
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.002804806688800454
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.0042024040594697
29 0.0032600981 	 0.0042024041
epoch_time;  41.214436292648315
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.002623683772981167
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0039343456737697124
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0028050390537828207
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.004202751908451319
It took  1302.9965844154358  seconds.
----- ITERATION 8/10 ------
[<torch.utils.data.dataloader.DataLoader object at 0x151f2defdae0>, <torch.utils.data.dataloader.DataLoader object at 0x151f2d80fbb0>, <torch.utils.data.dataloader.DataLoader object at 0x151f2defefb0>, <torch.utils.data.dataloader.DataLoader object at 0x151f2d80eb30>]
LSTM(
  (lstm): LSTM(8, 96, batch_first=True, dropout=0.2)
  (layers): Sequential(
    (0): Linear(in_features=96, out_features=8, bias=True)
  )
)
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.03603649139404297
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.05217334255576134
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.04418547824025154
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.06239364296197891
0 2.3198216313 	 0.0623936437
epoch_time;  41.348482608795166
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.006162118166685104
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.010675313882529736
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.011058049276471138
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.015733694657683372
1 0.0291441918 	 0.0157336944
epoch_time;  40.88057518005371
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.007229003123939037
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.011710857041180134
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.009010822512209415
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.013191538862884045
2 0.0238475467 	 0.0131915386
epoch_time;  41.06636643409729
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.003741638269275427
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0062702372670173645
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.007099680136889219
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.009766191244125366
3 0.017920785 	 0.0097661912
epoch_time;  41.06347179412842
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.06982074677944183
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.09462802857160568
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.05029962584376335
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.06597885489463806
4 0.0145634457 	 0.0659788541
epoch_time;  41.17279863357544
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.00291314534842968
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.005024473648518324
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.003929998725652695
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.005859057884663343
5 0.0135191774 	 0.0058590577
epoch_time;  40.90688872337341
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.05067084729671478
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.07433826476335526
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.040154751390218735
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.056055646389722824
6 0.0113250233 	 0.0560556452
epoch_time;  40.95959711074829
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.026936925947666168
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.03631722182035446
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.01946614310145378
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.025644509121775627
7 0.0099589227 	 0.0256445098
epoch_time;  40.9171781539917
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0013115610927343369
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0023859513457864523
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0022973669692873955
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.003358597168698907
8 0.0106310545 	 0.0033585971
epoch_time;  41.36375975608826
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0021756410133093596
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                              Epoch ▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇███
wandb: Test loss t(-10, 10)_r(-5, 5)_none █▃▂▂█▁▇▄▁▁▁▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  Test loss t(-10, 10)_r(0, 0)_none ▅▂▂▁█▁▆▄▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:    Test loss t(0, 0)_r(-5, 5)_none ▇▂▂▂█▁▇▄▁▁▁▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     Test loss t(0, 0)_r(0, 0)_none ▅▂▂▁█▁▆▄▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:                         Train loss █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                              Epoch 29
wandb: Test loss t(-10, 10)_r(-5, 5)_none 0.0041
wandb:  Test loss t(-10, 10)_r(0, 0)_none 0.00559
wandb:    Test loss t(0, 0)_r(-5, 5)_none 0.00292
wandb:     Test loss t(0, 0)_r(0, 0)_none 0.00396
wandb:                         Train loss 0.00345
wandb: 
wandb: 🚀 View run auspicious-wonton-1706 at: https://wandb.ai/nreints/thesis/runs/77ar826h
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230127_135404-77ar826h/logs
/gpfs/home2/nreints/MScThesis/code/lstm.py:270: DeprecationWarning: Sampling from a set deprecated
since Python 3.9 and will be removed in a subsequent version.
  train_sims = set(random.sample(sims_train, int(0.8 * n_sims_train)))
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.13.9 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.8
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230127_141538-vp421s41
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dancing-springroll-1709
wandb: ⭐️ View project at https://wandb.ai/nreints/thesis
wandb: 🚀 View run at https://wandb.ai/nreints/thesis/runs/vp421s41
/home/nreints/.conda/envs/thesis/lib/python3.10/site-packages/torch/nn/modules/rnn.py:67: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  warnings.warn("dropout option adds dropout after all but last "
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0036552741657942533
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.002525078132748604
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.0036451939959079027
9 0.0074552627 	 0.0036451939
epoch_time;  41.76909875869751
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0012897267006337643
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0021255123429000378
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.002121557015925646
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.0030665271915495396
10 0.0074564416 	 0.0030665272
epoch_time;  41.89828276634216
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.010923467576503754
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.016688521951436996
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.015263606794178486
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.021212905645370483
11 0.0071180244 	 0.0212129063
epoch_time;  40.620484352111816
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0010606073774397373
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.001764977932907641
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0016177473589777946
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.0022586591076105833
12 0.0070561056 	 0.0022586591
epoch_time;  40.62079310417175
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0010717470431700349
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0017900493694469333
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0015868277987465262
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.0022641560062766075
13 0.0059632439 	 0.0022641561
epoch_time;  41.22747254371643
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0007664546137675643
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.001388726755976677
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0013424481730908155
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.0018819482065737247
14 0.0083123697 	 0.0018819482
epoch_time;  40.66274571418762
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0017300484469160438
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0026835412718355656
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0021699366625398397
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.002957720775157213
15 0.0045861635 	 0.0029577208
epoch_time;  40.427053451538086
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.001128872507251799
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0018614208092913032
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0016083312220871449
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.002175210742279887
16 0.0051021601 	 0.0021752106
epoch_time;  40.541911363601685
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0014188223285600543
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0022215128410607576
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0019079131307080388
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.0026441237423568964
17 0.0057540286 	 0.0026441236
epoch_time;  40.61907982826233
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0029461809899657965
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.004224231466650963
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.003875837894156575
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.005158674903213978
18 0.0045349163 	 0.0051586747
epoch_time;  40.66500997543335
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0008620028966106474
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0017862609820440412
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0016457863384857774
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.0023931926116347313
19 0.0172131991 	 0.0023931926
epoch_time;  40.69703793525696
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0010965131223201752
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0018266167026013136
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0018608629470691085
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.0025683941785246134
20 0.0030543416 	 0.0025683942
epoch_time;  40.684391498565674
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.000695202499628067
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0011831300798803568
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0012637322070077062
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.0016997262137010694
21 0.0044830335 	 0.0016997262
epoch_time;  41.028475522994995
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0021418225951492786
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.003291438100859523
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.002453993307426572
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.00347102340310812
22 0.0040742851 	 0.0034710234
epoch_time;  41.91312837600708
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0011715771397575736
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.001784427440725267
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0015652732690796256
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.00207606703042984
23 0.0041103836 	 0.0020760671
epoch_time;  40.99861931800842
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0008544175652787089
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0013155144406482577
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.001307131489738822
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.0017280360916629434
24 0.0043542632 	 0.0017280361
epoch_time;  40.66330361366272
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0018522542668506503
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0026983674615621567
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.002180216135457158
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.002845661947503686
25 0.0042067119 	 0.0028456619
epoch_time;  40.65347504615784
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0011393510503694415
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0016673313220962882
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.001392920734360814
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.001845223712734878
26 0.0035376617 	 0.0018452237
epoch_time;  40.55642104148865
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0015545741189271212
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0024184840731322765
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0027054017409682274
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.0037722066044807434
27 0.0041320853 	 0.0037722065
epoch_time;  40.612722873687744
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0010600927053019404
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.001841821358539164
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0018907354678958654
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.0026581548154354095
28 0.0046548417 	 0.0026581548
epoch_time;  40.664976358413696
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.003956769593060017
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.005585020408034325
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0029197323601692915
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.004100711550563574
29 0.0034503572 	 0.0041007113
epoch_time;  40.7437961101532
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.003956904169172049
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.005591973662376404
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.002918279729783535
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.004097367636859417
It took  1293.742623090744  seconds.
----- ITERATION 9/10 ------
[<torch.utils.data.dataloader.DataLoader object at 0x151f2defe140>, <torch.utils.data.dataloader.DataLoader object at 0x151f2d80dcf0>, <torch.utils.data.dataloader.DataLoader object at 0x151f2d80d600>, <torch.utils.data.dataloader.DataLoader object at 0x151f2d80ea10>]
LSTM(
  (lstm): LSTM(8, 96, batch_first=True, dropout=0.2)
  (layers): Sequential(
    (0): Linear(in_features=96, out_features=8, bias=True)
  )
)
	 Logging test loss: t(0, 0)_r(0, 0)_none => 1.4382030963897705
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 2.4529707431793213
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 1.5867640972137451
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 2.537785530090332
0 5.3941368548 	 2.537785556
epoch_time;  40.295632123947144
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.9696783423423767
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 1.3209460973739624
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 1.1573256254196167
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 1.6818004846572876
1 1.8943225939 	 1.6818004965
epoch_time;  40.004266023635864
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.6939965486526489
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.8912054896354675
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.5908014178276062
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.8004224896430969
2 1.2366321457 	 0.8004225071
epoch_time;  40.419580936431885
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.4446662962436676
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.5488852262496948
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.3751816749572754
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.4852631986141205
3 0.5653206004 	 0.4852631906
epoch_time;  40.416009187698364
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.5991171002388
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.7747650742530823
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.607314944267273
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.8764854669570923
4 0.7447644681 	 0.8764854961
epoch_time;  40.189133644104004
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.33041006326675415
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.37115371227264404
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.2783046066761017
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.35555729269981384
5 0.522078047 	 0.3555572832
epoch_time;  40.1579852104187
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.2284761369228363
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.256320983171463
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.2115638256072998
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.24638889729976654
6 0.3489357243 	 0.2463888992
epoch_time;  40.56326723098755
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.5329427123069763
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.7259335517883301
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.5365051031112671
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.7769116163253784
7 0.3683450657 	 0.7769116174
epoch_time;  40.72002410888672
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.21512456238269806
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.24778959155082703
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.18557927012443542
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.23224322497844696
8 0.2623250125 	 0.2322432181
epoch_time;  40.4109411239624
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.18801897764205933
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.30702418088912964
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.3367193639278412
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.5031902194023132
9 0.437290235 	 0.5031902394
epoch_time;  40.307798624038696
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.1670657843351364
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.25232410430908203
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.25171345472335815
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.3814045786857605
10 0.7264075788 	 0.3814045886
epoch_time;  40.26327300071716
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.11058822274208069
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.14701777696609497
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.14830107986927032
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.2009650468826294
11 0.2750528756 	 0.2009650516
epoch_time;  40.40583562850952
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.16044791042804718
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.22456292808055878
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.19111640751361847
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.267767995595932
12 0.3276396527 	 0.267767984
epoch_time;  40.374380588531494
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.28586599230766296
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.37746983766555786
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.2740752696990967
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.3677352964878082
13 0.3632211389 	 0.3677352951
epoch_time;  40.679760217666626
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.1922375112771988
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.28031647205352783
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.24969816207885742
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.4033869802951813
14 0.4128968255 	 0.4033869717
epoch_time;  40.566818714141846
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.11493348330259323
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.15513308346271515
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.14016839861869812
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.18622156977653503
15 0.2471695582 	 0.1862215693
epoch_time;  41.953028440475464
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.11881228536367416
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.15911945700645447
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.14847931265830994
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.20952792465686798
16 0.3689409324 	 0.209527929
epoch_time;  40.58949398994446
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.11772370338439941
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.16185535490512848
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.1400386244058609
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.2009786069393158
17 0.207539214 	 0.2009786047
epoch_time;  40.50075316429138
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.09516053646802902
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.11777017265558243
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.11672528833150864
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.15898597240447998
18 0.1661203343 	 0.1589859677
epoch_time;  40.03198051452637
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.10189230740070343
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.13948021829128265
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.12292412668466568
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.17692825198173523
19 0.3143849283 	 0.1769282523
epoch_time;  40.51482701301575
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.09127691388130188
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.12175513058900833
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.10953698307275772
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.15780387818813324
20 0.1885752191 	 0.1578038726
epoch_time;  40.45539593696594
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0933995470404625
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.14200395345687866
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.15211915969848633
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.2333785891532898
21 0.1801762086 	 0.2333785919
epoch_time;  42.81192946434021
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.07580896466970444
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.10956411063671112
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.10831822454929352
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.14947259426116943
22 0.1653842276 	 0.1494725968
epoch_time;  40.44759702682495
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.07044300436973572
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.09373754262924194
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.09857548773288727
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.12940308451652527
23 0.1672400475 	 0.1294030826
epoch_time;  40.019123554229736
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.12279265373945236
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.18750502169132233
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.17158028483390808
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.264254093170166
24 0.1489703794 	 0.2642541061
epoch_time;  39.99922227859497
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.06926052272319794
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.08812478929758072
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.09130268543958664
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.12090200185775757
25 0.1419658213 	 0.120902001
epoch_time;  40.058197021484375
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                              Epoch ▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇███
wandb: Test loss t(-10, 10)_r(-5, 5)_none █▆▃▂▃▂▁▃▁▂▂▁▁▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  Test loss t(-10, 10)_r(0, 0)_none █▅▃▂▃▂▁▃▁▂▁▁▁▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:    Test loss t(0, 0)_r(-5, 5)_none █▆▃▂▃▂▂▃▁▂▂▁▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     Test loss t(0, 0)_r(0, 0)_none █▆▄▃▄▂▂▃▂▂▂▁▁▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:                         Train loss █▃▂▂▂▂▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                              Epoch 29
wandb: Test loss t(-10, 10)_r(-5, 5)_none 0.11752
wandb:  Test loss t(-10, 10)_r(0, 0)_none 0.11324
wandb:    Test loss t(0, 0)_r(-5, 5)_none 0.09125
wandb:     Test loss t(0, 0)_r(0, 0)_none 0.08885
wandb:                         Train loss 0.12084
wandb: 
wandb: 🚀 View run dancing-springroll-1709 at: https://wandb.ai/nreints/thesis/runs/vp421s41
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230127_141538-vp421s41/logs
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.08317022025585175
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.09907110780477524
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0963960662484169
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.12900219857692719
26 0.1468263521 	 0.1290022052
epoch_time;  39.86992263793945
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.07373274117708206
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.09314487874507904
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.08306937664747238
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.11232995986938477
27 0.1282014464 	 0.1123299613
epoch_time;  40.39473509788513
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.08687864989042282
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.11730259656906128
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0968150794506073
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.1321651190519333
28 0.1359126562 	 0.1321651194
epoch_time;  40.02531290054321
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.08870922029018402
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.1132613942027092
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.09115931391716003
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.11751986294984818
29 0.1208354595 	 0.1175198627
epoch_time;  40.480544567108154
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.08885130286216736
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.11323968321084976
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.09125117212533951
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.11751797050237656
It took  1284.0389993190765  seconds.

JOB STATISTICS
==============
Job ID: 2142744
Array Job ID: 2141141_26
Cluster: snellius
User/Group: nreints/nreints
State: COMPLETED (exit code 0)
Nodes: 1
Cores per node: 18
CPU Utilized: 20:45:41
CPU Efficiency: 31.92% of 2-17:02:42 core-walltime
Job Wall-clock time: 03:36:49
Memory Utilized: 15.94 GB
Memory Efficiency: 51.01% of 31.25 GB
