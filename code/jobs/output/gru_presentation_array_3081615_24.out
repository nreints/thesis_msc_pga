wandb: Currently logged in as: nreints. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_125108-gn5qsust
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run efficient-silence-3
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/gn5qsust
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue â–ˆâ–„â–‚â–‚â–â–â–â–â–â–
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue â–ˆâ–ƒâ–‚â–â–â–â–â–ƒâ–â–
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue â–ˆâ–ƒâ–‚â–‚â–‚â–‚â–â–â–â–
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue â–ˆâ–„â–ƒâ–‚â–‚â–â–â–â–â–
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue 0.00043
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 2e-05
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.00043
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.00266
wandb:                                 Train loss 0.0001
wandb: 
wandb: ðŸš€ View run efficient-silence-3 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/gn5qsust
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_125108-gn5qsust/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_130324-w5fmusrt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run colorful-universe-76
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/w5fmusrt
Training on dataset: data_t(0,0)_r(0,0)_combi_pTrue_gTrue
Testing on 4 datasets: ['data_t(0,0)_r(0,0)_tennis_pTrue_gTrue', 'data_t(0,0)_r(0,0)_full_pTrue_gTrue', 'data_t(0,0)_r(0,0)_semi_pTrue_gTrue', 'data_t(0,0)_r(0,0)_combi_pTrue_gTrue']
Focussing on identity: False
Using extra input: False
Using start-fr as reference point.
----- ITERATION 1/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 78.36808753013611 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 19.68610119819641 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 19.01585030555725 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 20.101916074752808 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 19.382907390594482 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.1168020293 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0591137335 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0001856252 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0092874039 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0166226644 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 57.57862710952759
Epoch 1/9
	 Logging train Loss: 0.0028491912 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0306782704 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 5.61867e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0034765992 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0066861673 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 57.06486463546753
Epoch 2/9
	 Logging train Loss: 0.0010354216 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0169613957 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.75269e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0022636484 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0035856625 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 56.870076179504395
Epoch 3/9
	 Logging train Loss: 0.0005512533 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0111573609 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.76043e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0016296735 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0022376142 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 56.32699489593506
Epoch 4/9
	 Logging train Loss: 0.0004172301 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0078803105 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.47557e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0011907864 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0015451637 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 56.34390902519226
Epoch 5/9
	 Logging train Loss: 0.0002525442 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0064666728 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.1872e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0010489533 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0011857531 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 56.14997482299805
Epoch 6/9
	 Logging train Loss: 0.0002067251 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0045718323 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.3156e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0007286903 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0008189282 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 56.62955617904663
Epoch 7/9
	 Logging train Loss: 0.0001437629 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.003616991 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 4.68468e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0005560475 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0006479866 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 56.09681797027588
Epoch 8/9
	 Logging train Loss: 0.0001399635 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0031089995 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 7.2941e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0004124886 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0005112416 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 56.09880590438843
Epoch 9/9
	 Logging train Loss: 9.92529e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.00265743 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.83247e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0004304994 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0004337448 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 56.265034198760986
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pTrue_gTrue/'rot_mat'_'False'.pth
It took  737.1428484916687  seconds.
----- ITERATION 2/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 77.63787412643433 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 19.006639003753662 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 19.435359239578247 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 19.422473907470703 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 19.326618671417236 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.1102985442 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0950854048 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0002147967 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.010029776 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0203551948 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 58.478970766067505
Epoch 1/9
	 Logging train Loss: 0.003013313 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.043233525 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 6.14772e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0033331166 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0093309451 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 58.075557708740234
Epoch 2/9
	 Logging train Loss: 0.001047357 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0280308612 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 3.58081e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0020407594 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0060123969 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 57.6591522693634
Epoch 3/9
	 Logging train Loss: 0.0005454674 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0202462319 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.3266e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0013372941 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.004515212 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 57.15772366523743
Epoch 4/9
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue â–ˆâ–„â–ƒâ–‚â–‚â–â–â–â–â–
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue â–ˆâ–ƒâ–‚â–â–â–â–â–â–‚â–
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue â–ˆâ–„â–ƒâ–‚â–‚â–‚â–â–â–â–
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue 0.00077
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 1e-05
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.0003
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.00523
wandb:                                 Train loss 9e-05
wandb: 
wandb: ðŸš€ View run colorful-universe-76 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/w5fmusrt
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_130324-w5fmusrt/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_131541-unaanvmq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glorious-silence-143
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/unaanvmq
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue â–ˆâ–ƒâ–‚â–‚â–â–â–â–‚â–â–
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue â–ˆâ–ƒâ–‚â–‚â–â–â–â–‚â–â–
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue â–ˆâ–„â–ƒâ–‚â–‚â–â–â–‚â–â–
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue 0.00032
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 1e-05
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.00021
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.00291
wandb:                                 Train loss 0.0001
wandb: 
wandb: ðŸš€ View run glorious-silence-143 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/unaanvmq
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_131541-unaanvmq/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_132804-edsdwh5s
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run icy-durian-199
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/edsdwh5s
	 Logging train Loss: 0.0004231484 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0153522491 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.48463e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0009739833 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0031458237 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 56.46740770339966
Epoch 5/9
	 Logging train Loss: 0.0002686474 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0118703805 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.45446e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0006958246 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0020392023 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 56.22820496559143
Epoch 6/9
	 Logging train Loss: 0.0001964935 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0091744149 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.07908e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.000522638 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0014992693 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 56.0176796913147
Epoch 7/9
	 Logging train Loss: 0.0001534339 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0072150198 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.26699e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0003291021 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0012455595 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 56.07061147689819
Epoch 8/9
	 Logging train Loss: 0.0001256263 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.00604604 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.41069e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.000333844 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0008409076 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 56.09600806236267
Epoch 9/9
	 Logging train Loss: 8.75589e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0052294796 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 8.6151e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0002998328 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0007718612 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 56.36535024642944
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pTrue_gTrue/'rot_mat'_'False'.pth
It took  737.5245399475098  seconds.
----- ITERATION 3/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 76.68873715400696 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 19.40033793449402 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 19.42716932296753 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 19.408985137939453 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 19.420778274536133 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.1341226548 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0748234093 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0003968866 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0109004956 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0128801949 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 58.61332058906555
Epoch 1/9
	 Logging train Loss: 0.004160088 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0341622308 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.000131763 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.003636251 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0036389285 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 58.747047662734985
Epoch 2/9
	 Logging train Loss: 0.0014063374 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0198287368 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 6.33128e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0020145732 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0020798335 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 58.06396818161011
Epoch 3/9
	 Logging train Loss: 0.0006388148 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0133220078 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 3.88221e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0010997467 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0013218948 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 57.60170888900757
Epoch 4/9
	 Logging train Loss: 0.0004269334 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.009955124 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.48108e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0007573 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0009838927 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 57.54942512512207
Epoch 5/9
	 Logging train Loss: 0.0003107213 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0075906604 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.95366e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0005328896 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0008064416 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 57.61925148963928
Epoch 6/9
	 Logging train Loss: 0.0002607891 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0056440835 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.2235e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0004078191 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0005665242 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 57.30364632606506
Epoch 7/9
	 Logging train Loss: 0.0001606887 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0086538317 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.46761e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0009823161 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0013033727 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 56.91433048248291
Epoch 8/9
	 Logging train Loss: 0.0001498821 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0034629621 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.52072e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0002333391 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0003745937 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 57.000940561294556
Epoch 9/9
	 Logging train Loss: 0.0001042781 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0029099875 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.04531e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0002104185 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0003171558 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 56.740766763687134
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pTrue_gTrue/'rot_mat'_'False'.pth
It took  742.7908816337585  seconds.
----- ITERATION 4/10 ------
Number of train simulations:  1920
Number of test simulations:  480
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–‚
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue â–ˆâ–ƒâ–‚â–‚â–‚â–â–â–â–â–
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue 0.00038
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 3e-05
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.00027
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.00093
wandb:                                 Train loss 8e-05
wandb: 
wandb: ðŸš€ View run icy-durian-199 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/edsdwh5s
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_132804-edsdwh5s/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_134028-cqxt4epx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run elated-flower-261
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/cqxt4epx
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 77.06246256828308 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 19.372664213180542 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 19.384649753570557 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 19.390050649642944 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 19.328431129455566 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.1385520399 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0223352518 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0002326713 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0090025747 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.013039737 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 58.70622253417969
Epoch 1/9
	 Logging train Loss: 0.0036371571 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0072857519 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 7.58593e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0027981517 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0039355876 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 58.38458490371704
Epoch 2/9
	 Logging train Loss: 0.0012057259 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0043731732 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 3.49185e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0016550001 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0023362623 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 57.93511652946472
Epoch 3/9
	 Logging train Loss: 0.0006355552 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.003858862 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.50281e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0012874525 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0015334289 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 57.67229771614075
Epoch 4/9
	 Logging train Loss: 0.0004041109 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0024788245 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.4264e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0007412141 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0011416499 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 57.01280641555786
Epoch 5/9
	 Logging train Loss: 0.0002902024 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0018550027 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 8.0585e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0005495768 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.000782865 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 57.494261026382446
Epoch 6/9
	 Logging train Loss: 0.0002131417 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0015545557 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.16803e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0004771328 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0007238357 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 57.44601058959961
Epoch 7/9
	 Logging train Loss: 0.0001463842 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0013758851 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 6.8785e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0002850651 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0005712984 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 57.2314829826355
Epoch 8/9
	 Logging train Loss: 0.0001601311 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0010279322 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.62851e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0002661357 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0003948213 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 57.23422694206238
Epoch 9/9
	 Logging train Loss: 8.42684e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0009343726 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.7459e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.00026661 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0003825271 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 57.23253393173218
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pTrue_gTrue/'rot_mat'_'False'.pth
It took  744.0137689113617  seconds.
----- ITERATION 5/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 76.9436240196228 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 19.371376991271973 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 19.373070001602173 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 19.38242483139038 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 19.409440517425537 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.1280299276 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0587958694 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0001755997 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0214403216 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0042815604 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 57.584248781204224
Epoch 1/9
	 Logging train Loss: 0.0033830253 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0254503097 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 6.77105e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0083222315 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0015224927 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 57.66382932662964
Epoch 2/9
	 Logging train Loss: 0.0011202127 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0145699894 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 3.48263e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0043228376 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0008753431 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 57.23877930641174
Epoch 3/9
	 Logging train Loss: 0.0006074791 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0099403244 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.07348e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0031413084 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0008023076 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 57.80059361457825
Epoch 4/9
	 Logging train Loss: 0.0003733358 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0062294137 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.51068e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0024556054 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.000462625 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 57.27008819580078
Epoch 5/9
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue â–ˆâ–ƒâ–‚â–‚â–‚â–â–â–â–â–
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue â–ˆâ–„â–‚â–‚â–â–â–ƒâ–ƒâ–‚â–
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue â–ˆâ–„â–‚â–‚â–‚â–â–â–â–â–
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue â–ˆâ–„â–‚â–‚â–â–â–â–â–â–
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue 0.00016
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 1e-05
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.00069
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.00265
wandb:                                 Train loss 0.00011
wandb: 
wandb: ðŸš€ View run elated-flower-261 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/cqxt4epx
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_134028-cqxt4epx/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_135250-igrrkgrf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run earnest-rain-319
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/igrrkgrf
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue â–ˆâ–ƒâ–‚â–‚â–‚â–â–â–â–â–
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue â–ˆâ–ƒâ–‚â–‚â–‚â–â–‚â–â–ƒâ–
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue â–ˆâ–ƒâ–‚â–‚â–‚â–â–â–â–â–
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue â–ˆâ–„â–ƒâ–‚â–‚â–â–â–â–â–
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue 0.00012
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 1e-05
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.00051
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.00327
wandb:                                 Train loss 0.00011
wandb: 
wandb: ðŸš€ View run earnest-rain-319 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/igrrkgrf
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_135250-igrrkgrf/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_140505-c9w4a51k
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ancient-planet-358
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/c9w4a51k
	 Logging train Loss: 0.0002745855 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0052404166 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 8.81e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0014852323 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0003186883 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 57.31982231140137
Epoch 6/9
	 Logging train Loss: 0.0001867491 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0037277814 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 4.22293e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0012191454 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0002840098 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 57.280986070632935
Epoch 7/9
	 Logging train Loss: 0.0001260458 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0030553064 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 4.96998e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.000983727 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0002331304 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 57.18575096130371
Epoch 8/9
	 Logging train Loss: 0.0001220264 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.002906916 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.45746e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0007761092 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0001620721 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 57.04504942893982
Epoch 9/9
	 Logging train Loss: 0.0001066981 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0026527515 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 5.663e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0006910119 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0001613565 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 56.738104581832886
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pTrue_gTrue/'rot_mat'_'False'.pth
It took  742.0912146568298  seconds.
----- ITERATION 6/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 76.66264748573303 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 19.275243043899536 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 19.33425521850586 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 19.31631064414978 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 19.080024480819702 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.1144974753 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0572755747 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0001551148 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.006722501 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0018811157 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 57.78301382064819
Epoch 1/9
	 Logging train Loss: 0.0032189726 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0258636829 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 5.35331e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.002414997 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0006656184 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 56.382519245147705
Epoch 2/9
	 Logging train Loss: 0.0011325119 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0163471438 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 3.18549e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0015779204 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0004005407 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 56.02996253967285
Epoch 3/9
	 Logging train Loss: 0.0006299578 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0113324039 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.0154e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0011066929 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0002713068 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 56.04010486602783
Epoch 4/9
	 Logging train Loss: 0.0004244624 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0090790428 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.73943e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0009294088 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0002331271 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 57.40431594848633
Epoch 5/9
	 Logging train Loss: 0.000326322 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0059521366 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 8.1527e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0005619951 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.000134546 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 57.32756447792053
Epoch 6/9
	 Logging train Loss: 0.0002097425 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0045877835 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.64595e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0004917086 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0001511801 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 56.63819432258606
Epoch 7/9
	 Logging train Loss: 0.0001887728 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0035828038 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 5.848e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0003607385 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 7.82484e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 57.087639808654785
Epoch 8/9
	 Logging train Loss: 0.0001285713 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0031387492 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 5.15215e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0003397859 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.000111863 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 56.93591070175171
Epoch 9/9
	 Logging train Loss: 0.0001101805 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0032721281 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 6.2772e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0005124717 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0001150868 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 56.478506088256836
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pTrue_gTrue/'rot_mat'_'False'.pth
It took  734.5253434181213  seconds.
----- ITERATION 7/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 76.85021734237671 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 19.334208726882935 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 19.400859117507935 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 19.390778064727783 seconds.
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue â–ˆâ–„â–‚â–‚â–‚â–‚â–â–â–â–
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue â–ˆâ–ƒâ–‚â–‚â–‚â–‚â–â–â–â–
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue â–ˆâ–„â–‚â–‚â–â–â–â–â–â–
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue 0.00058
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.00019
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.00122
wandb:                                 Train loss 9e-05
wandb: 
wandb: ðŸš€ View run ancient-planet-358 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/c9w4a51k
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_140505-c9w4a51k/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_141725-yyge5clh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run laced-vortex-366
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/yyge5clh
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 19.44644045829773 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.1077057943 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0477887727 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0001536372 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0065953955 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0201908145 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 57.49948525428772
Epoch 1/9
	 Logging train Loss: 0.002754387 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0179191865 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 5.11789e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0020351354 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0077795568 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 57.80349111557007
Epoch 2/9
	 Logging train Loss: 0.0009674173 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0087507581 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.92098e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0013872371 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0041171177 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 57.82113480567932
Epoch 3/9
	 Logging train Loss: 0.0005122317 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0059339483 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.89736e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.000983283 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0028738824 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 57.52179741859436
Epoch 4/9
	 Logging train Loss: 0.0003540898 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.004508446 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.3e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.000679048 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0023706334 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 57.101826906204224
Epoch 5/9
	 Logging train Loss: 0.0002402018 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0044279825 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.08183e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.000766864 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0021841249 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 57.420738697052
Epoch 6/9
	 Logging train Loss: 0.0001942844 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0025719693 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.36145e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0003760473 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0012961227 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 57.46355414390564
Epoch 7/9
	 Logging train Loss: 0.0001963338 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0019119561 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 6.9964e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0002863774 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0009698228 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 57.15477895736694
Epoch 8/9
	 Logging train Loss: 9.49997e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0015071656 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 7.5161e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0002530646 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0006966444 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 57.085291624069214
Epoch 9/9
	 Logging train Loss: 9.43872e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0012160428 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 3.9505e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0001920467 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0005809303 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 56.83196568489075
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pTrue_gTrue/'rot_mat'_'False'.pth
It took  740.1316192150116  seconds.
----- ITERATION 8/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 77.02133655548096 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 19.398321628570557 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 19.367236852645874 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 19.35464835166931 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 19.3529794216156 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.1126493067 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0490552336 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0002290859 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0141462078 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.015851533 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 57.816306591033936
Epoch 1/9
	 Logging train Loss: 0.0032811619 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0210372843 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 6.36921e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0041060993 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0057308869 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 57.64760899543762
Epoch 2/9
	 Logging train Loss: 0.0011078656 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0120520992 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 3.61617e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0025852905 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0038775958 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 56.85963201522827
Epoch 3/9
	 Logging train Loss: 0.000600665 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.007349337 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.14912e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0016511868 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0028158573 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 56.97007513046265
Epoch 4/9
	 Logging train Loss: 0.0004283891 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0055091237 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.48908e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0012425961 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0021077516 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 56.61524772644043
Epoch 5/9
	 Logging train Loss: 0.0002722956 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0044230786 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.50766e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0012693385 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0017451829 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue â–ˆâ–ƒâ–‚â–‚â–‚â–â–â–â–â–
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–‚
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue â–ˆâ–„â–ƒâ–‚â–‚â–â–â–â–â–
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue 0.00067
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 2e-05
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.00057
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.0019
wandb:                                 Train loss 0.00011
wandb: 
wandb: ðŸš€ View run laced-vortex-366 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/yyge5clh
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_141725-yyge5clh/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_142939-otgu4bni
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wise-capybara-373
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/otgu4bni
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue â–ˆâ–„â–ƒâ–‚â–â–â–â–â–â–
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue â–ˆâ–ƒâ–‚â–â–â–â–‚â–â–‚â–
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue â–ˆâ–ƒâ–‚â–‚â–â–â–‚â–â–â–
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue â–ˆâ–„â–ƒâ–‚â–‚â–‚â–â–â–â–
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue 0.0002
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 2e-05
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.0002
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.00284
wandb:                                 Train loss 9e-05
wandb: 
wandb: ðŸš€ View run wise-capybara-373 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/otgu4bni
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_142939-otgu4bni/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_144151-icp2a8u3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run skilled-morning-380
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/icp2a8u3
		--> Epoch time; 56.57119297981262
Epoch 6/9
	 Logging train Loss: 0.0002033452 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0035813595 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.07982e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.000839878 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.001399151 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 56.32869577407837
Epoch 7/9
	 Logging train Loss: 0.0001866741 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0027929791 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 9.1698e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0007688762 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0011762446 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 56.30877900123596
Epoch 8/9
	 Logging train Loss: 0.0001148239 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0020247085 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 7.4702e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0005889267 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0007603411 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 56.273510217666626
Epoch 9/9
	 Logging train Loss: 0.0001145691 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0019017183 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.40222e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.000569791 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0006730687 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 56.11350440979004
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pTrue_gTrue/'rot_mat'_'False'.pth
It took  734.0815737247467  seconds.
----- ITERATION 9/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 76.7915780544281 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 19.370039701461792 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 19.39424967765808 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 19.414572954177856 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 19.329128742218018 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.1167137474 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0508826077 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0001888149 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0080138212 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0072055645 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 58.297006607055664
Epoch 1/9
	 Logging train Loss: 0.0032536085 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0223028809 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 5.84683e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0026669367 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0029417588 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 57.708842754364014
Epoch 2/9
	 Logging train Loss: 0.0010006475 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.015999293 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 3.47505e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0016609494 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0017999155 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 56.211292028427124
Epoch 3/9
	 Logging train Loss: 0.0005277873 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0115144625 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.94293e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.001337243 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0011843045 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 55.69208788871765
Epoch 4/9
	 Logging train Loss: 0.0003619388 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0077855848 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.40029e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0007557307 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0007003676 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 55.715726375579834
Epoch 5/9
	 Logging train Loss: 0.0002427894 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0064325407 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 8.7005e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0005955978 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0005873007 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 55.896458864212036
Epoch 6/9
	 Logging train Loss: 0.0001736889 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0047078864 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.3582e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0007980711 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0005454702 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 55.87267446517944
Epoch 7/9
	 Logging train Loss: 0.0001500797 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0043846755 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 8.446e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0003749756 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0004220181 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 56.275856256484985
Epoch 8/9
	 Logging train Loss: 0.0001234161 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0034627235 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 3.88641e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0002676189 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0003061152 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 56.95066237449646
Epoch 9/9
	 Logging train Loss: 9.0715e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0028402749 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.92084e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0002000285 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0002025632 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 56.37051033973694
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pTrue_gTrue/'rot_mat'_'False'.pth
It took  732.1322438716888  seconds.
----- ITERATION 10/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 76.63896989822388 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 19.361314058303833 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 19.37653613090515 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 19.340653657913208 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 19.346150875091553 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.1178291142 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0464970917 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue â–ˆâ–„â–‚â–‚â–â–â–â–â–â–
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue 0.0002
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 1e-05
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.00026
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.00148
wandb:                                 Train loss 0.00012
wandb: 
wandb: ðŸš€ View run skilled-morning-380 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/icp2a8u3
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_144151-icp2a8u3/logs
	 Logging test loss: 0.0002392195 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0083154207 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0071961968 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 57.9554398059845
Epoch 1/9
	 Logging train Loss: 0.0032799297 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.018882094 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 8.74443e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0027803821 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0022243592 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 57.93104362487793
Epoch 2/9
	 Logging train Loss: 0.0011257448 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0104517462 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 4.19922e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0015953698 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0010302062 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 57.32624888420105
Epoch 3/9
	 Logging train Loss: 0.0006389031 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0072546015 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.77108e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0011071601 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0007210809 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 57.0765905380249
Epoch 4/9
	 Logging train Loss: 0.0004191135 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0046674805 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.63331e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0006844257 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0004826038 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 57.7900288105011
Epoch 5/9
	 Logging train Loss: 0.0003036069 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0034501269 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.44986e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0005352061 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0003733197 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 57.094594955444336
Epoch 6/9
	 Logging train Loss: 0.0002171564 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0021491752 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.49304e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0003417644 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0002867199 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 57.237544298172
Epoch 7/9
	 Logging train Loss: 0.0001816217 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0017568533 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.4297e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0002674696 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0002202867 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 57.15279984474182
Epoch 8/9
	 Logging train Loss: 0.0001153961 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0021012949 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.32304e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0006811818 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0003621228 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 57.25428915023804
Epoch 9/9
	 Logging train Loss: 0.0001150943 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0014773302 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.31625e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0002590268 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0001960232 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 57.11930251121521
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pTrue_gTrue/'rot_mat'_'False'.pth
It took  740.1537685394287  seconds.

JOB STATISTICS
==============
Job ID: 3081637
Array Job ID: 3081615_24
Cluster: snellius
User/Group: nreints/nreints
State: RUNNING
Nodes: 1
Cores per node: 18
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 1-12:59:42 core-walltime
Job Wall-clock time: 02:03:19
Memory Utilized: 0.00 MB (estimated maximum)
Memory Efficiency: 0.00% of 0.00 MB (0.00 MB/node)
WARNING: Efficiency statistics may be misleading for RUNNING jobs.
