wandb: Currently logged in as: nreints. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230710_170033-sy6z9pf7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run bumbling-thunder-1252
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/sy6z9pf7
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                     Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb: Test loss tennis_pNone_gNone_tennisEffect â–…â–„â–ˆâ–ƒâ–ˆâ–‚â–â–â–â–‚
wandb:                                Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                     Epoch 9
wandb: Test loss tennis_pNone_gNone_tennisEffect 2e-05
wandb:                                Train loss 1e-05
wandb: 
wandb: ðŸš€ View run bumbling-thunder-1252 at: https://wandb.ai/nreints/ThesisFinal2/runs/sy6z9pf7
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230710_170033-sy6z9pf7/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230710_170540-47f97chw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run misty-sponge-1262
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/47f97chw
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                     Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb: Test loss tennis_pNone_gNone_tennisEffect â–ˆâ–†â–‡â–‡â–‡â–â–â–‚â–â–
wandb:                                Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                     Epoch 9
wandb: Test loss tennis_pNone_gNone_tennisEffect 1e-05
wandb:                                Train loss 1e-05
wandb: 
wandb: ðŸš€ View run misty-sponge-1262 at: https://wandb.ai/nreints/ThesisFinal2/runs/47f97chw
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230710_170540-47f97chw/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230710_171033-nz8r6gmg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run devout-breeze-1273
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/nz8r6gmg
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                     Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb: Test loss tennis_pNone_gNone_tennisEffect â–ˆâ–‡â–…â–ƒâ–…â–‚â–ƒâ–â–â–
wandb:                                Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                     Epoch 9
wandb: Test loss tennis_pNone_gNone_tennisEffect 1e-05
wandb:                                Train loss 1e-05
wandb: 
wandb: ðŸš€ View run devout-breeze-1273 at: https://wandb.ai/nreints/ThesisFinal2/runs/nz8r6gmg
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230710_171033-nz8r6gmg/logs
Training on dataset: data_tennis_pNone_gNone_tennisEffect
Testing on 1 datasets: ['data_tennis_pNone_gNone_tennisEffect']
Focussing on identity: True
Using extra input: False
Using fr-fr as reference point.
----- ITERATION 1/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 52.61254358291626 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 13.147351026535034 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0018952127 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 4.73303e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 23.963422775268555
Epoch 1/9
	 Logging train Loss: 4.96284e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 3.64208e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 22.032140970230103
Epoch 2/9
	 Logging train Loss: 4.14009e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 6.95476e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 21.93187165260315
Epoch 3/9
	 Logging train Loss: 3.44271e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 3.01142e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 22.06201720237732
Epoch 4/9
	 Logging train Loss: 2.79583e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 7.00685e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 22.148348331451416
Epoch 5/9
	 Logging train Loss: 2.15691e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.60237e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 21.982930421829224
Epoch 6/9
	 Logging train Loss: 1.68888e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.10656e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 22.212571144104004
Epoch 7/9
	 Logging train Loss: 1.3794e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.15991e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 22.06827402114868
Epoch 8/9
	 Logging train Loss: 1.2935e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.02161e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 22.149532318115234
Epoch 9/9
	 Logging train Loss: 1.16739e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.58753e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 22.02153968811035
Saved model in  trained_models/gru/data_tennis_pNone_gNone_tennisEffect/'dual_quat_1'_'False'.pth
It took  308.3435175418854  seconds.
----- ITERATION 2/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 47.840880393981934 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 11.97667908668518 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0015076436 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 4.72021e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 21.963662147521973
Epoch 1/9
	 Logging train Loss: 5.59542e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 3.55198e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 22.009702920913696
Epoch 2/9
	 Logging train Loss: 4.20152e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 4.05541e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 22.098361015319824
Epoch 3/9
	 Logging train Loss: 3.23316e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 4.39004e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 22.078750610351562
Epoch 4/9
	 Logging train Loss: 2.44091e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 4.42664e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 22.123628616333008
Epoch 5/9
	 Logging train Loss: 1.8054e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.0637e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 22.268309593200684
Epoch 6/9
	 Logging train Loss: 1.45253e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 9.637e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 21.861380338668823
Epoch 7/9
	 Logging train Loss: 1.36215e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.34838e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 22.145342350006104
Epoch 8/9
	 Logging train Loss: 1.21238e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 8.7791e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 22.02816677093506
Epoch 9/9
	 Logging train Loss: 1.14333e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 9.8573e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 22.16917324066162
Saved model in  trained_models/gru/data_tennis_pNone_gNone_tennisEffect/'dual_quat_1'_'False'.pth
It took  292.7371096611023  seconds.
----- ITERATION 3/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 45.49118947982788 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 11.355964422225952 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0025170064 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 5.60818e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 22.101199626922607
Epoch 1/9
	 Logging train Loss: 4.25623e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 4.67576e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 22.341010332107544
Epoch 2/9
	 Logging train Loss: 3.95201e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 3.36174e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 22.25326156616211
Epoch 3/9
	 Logging train Loss: 3.41822e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.45126e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 21.908355236053467
Epoch 4/9
	 Logging train Loss: 2.86486e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 3.50771e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 22.39539861679077
Epoch 5/9
	 Logging train Loss: 2.33246e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.56004e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 22.01952362060547
Epoch 6/9
	 Logging train Loss: 1.82344e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.46597e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 22.331101655960083
Epoch 7/9
	 Logging train Loss: 1.5135e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.02711e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 21.97583246231079
Epoch 8/9
	 Logging train Loss: 1.29843e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 9.419e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 21.96741485595703
Epoch 9/9
	 Logging train Loss: 1.2282e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 9.6836e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 22.071540594100952
Saved model in  trained_models/gru/data_tennis_pNone_gNone_tennisEffect/'dual_quat_1'_'False'.pth
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230710_171523-tibcvn0o
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sparkling-universe-1287
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/tibcvn0o
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                     Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb: Test loss tennis_pNone_gNone_tennisEffect â–ˆâ–ˆâ–…â–…â–ƒâ–‚â–‚â–â–â–ƒ
wandb:                                Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                     Epoch 9
wandb: Test loss tennis_pNone_gNone_tennisEffect 2e-05
wandb:                                Train loss 1e-05
wandb: 
wandb: ðŸš€ View run sparkling-universe-1287 at: https://wandb.ai/nreints/ThesisFinal2/runs/tibcvn0o
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230710_171523-tibcvn0o/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230710_172015-nfnc7ia5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run twilight-brook-1299
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/nfnc7ia5
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                     Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb: Test loss tennis_pNone_gNone_tennisEffect â–ˆâ–†â–…â–…â–…â–ƒâ–ƒâ–â–â–
wandb:                                Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                     Epoch 9
wandb: Test loss tennis_pNone_gNone_tennisEffect 1e-05
wandb:                                Train loss 1e-05
wandb: 
wandb: ðŸš€ View run twilight-brook-1299 at: https://wandb.ai/nreints/ThesisFinal2/runs/nfnc7ia5
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230710_172015-nfnc7ia5/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230710_172506-db6t4i3d
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vague-fire-1309
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/db6t4i3d
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                     Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb: Test loss tennis_pNone_gNone_tennisEffect â–ˆâ–†â–…â–‡â–‚â–â–‚â–â–â–
wandb:                                Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                     Epoch 9
wandb: Test loss tennis_pNone_gNone_tennisEffect 1e-05
wandb:                                Train loss 1e-05
wandb: 
wandb: ðŸš€ View run vague-fire-1309 at: https://wandb.ai/nreints/ThesisFinal2/runs/db6t4i3d
wandb: Synced 7 W&B file(s), 0 media file(s), 1 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230710_172506-db6t4i3d/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230710_172954-8bc7tqih
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run distinctive-sky-1323
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/8bc7tqih
It took  289.9403667449951  seconds.
----- ITERATION 4/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 45.28554344177246 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 11.311091423034668 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0025526967 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 5.19797e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 22.36337924003601
Epoch 1/9
	 Logging train Loss: 4.30712e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 5.06071e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 22.254749536514282
Epoch 2/9
	 Logging train Loss: 3.75207e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 3.58781e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 21.99118709564209
Epoch 3/9
	 Logging train Loss: 3.26557e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 3.24366e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 22.05798625946045
Epoch 4/9
	 Logging train Loss: 2.71445e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.27889e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 22.28929042816162
Epoch 5/9
	 Logging train Loss: 2.30809e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.53056e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 21.914292812347412
Epoch 6/9
	 Logging train Loss: 1.77226e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.39977e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 21.984554767608643
Epoch 7/9
	 Logging train Loss: 1.45825e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 9.8788e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 22.081090211868286
Epoch 8/9
	 Logging train Loss: 1.22557e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 9.8938e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 22.23161005973816
Epoch 9/9
	 Logging train Loss: 1.16551e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.12106e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 22.306748867034912
Saved model in  trained_models/gru/data_tennis_pNone_gNone_tennisEffect/'dual_quat_1'_'False'.pth
It took  292.01579880714417  seconds.
----- ITERATION 5/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 45.25573801994324 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 11.347213506698608 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0023971356 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 4.38245e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 22.038670301437378
Epoch 1/9
	 Logging train Loss: 4.13697e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 3.45762e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 22.758145093917847
Epoch 2/9
	 Logging train Loss: 3.62427e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.76158e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 22.446544647216797
Epoch 3/9
	 Logging train Loss: 3.10612e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 3.02816e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 22.664005994796753
Epoch 4/9
	 Logging train Loss: 2.66484e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 3.03887e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 22.274967432022095
Epoch 5/9
	 Logging train Loss: 2.08608e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.99193e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 22.09037947654724
Epoch 6/9
	 Logging train Loss: 1.6723e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.89432e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 22.321448802947998
Epoch 7/9
	 Logging train Loss: 1.39481e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.09519e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 21.866954565048218
Epoch 8/9
	 Logging train Loss: 1.29215e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 9.8448e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 22.070571899414062
Epoch 9/9
	 Logging train Loss: 1.13918e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 8.7474e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 21.877280473709106
Saved model in  trained_models/gru/data_tennis_pNone_gNone_tennisEffect/'dual_quat_1'_'False'.pth
It took  290.869259595871  seconds.
----- ITERATION 6/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 45.498077392578125 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 11.32146692276001 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0024224855 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 4.83788e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 22.130130290985107
Epoch 1/9
	 Logging train Loss: 4.38977e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 3.83767e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 22.01434302330017
Epoch 2/9
	 Logging train Loss: 3.78883e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 3.28285e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 22.036309242248535
Epoch 3/9
	 Logging train Loss: 3.25318e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 4.46578e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 21.83110761642456
Epoch 4/9
	 Logging train Loss: 2.71474e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.53877e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 22.16352415084839
Epoch 5/9
	 Logging train Loss: 2.14786e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.3721e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 22.334195613861084
Epoch 6/9
	 Logging train Loss: 1.68036e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.58575e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 21.853647232055664
Epoch 7/9
	 Logging train Loss: 1.41242e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.37483e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 22.0668888092041
Epoch 8/9
	 Logging train Loss: 1.29401e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.25008e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 21.83383536338806
Epoch 9/9
	 Logging train Loss: 1.1778e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.27898e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 22.159226179122925
Saved model in  trained_models/gru/data_tennis_pNone_gNone_tennisEffect/'dual_quat_1'_'False'.pth
It took  288.1060221195221  seconds.
----- ITERATION 7/10 ------
Number of train simulations:  1920
Number of test simulations:  480
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                     Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb: Test loss tennis_pNone_gNone_tennisEffect â–ˆâ–‡â–†â–…â–‚â–‚â–‚â–â–â–
wandb:                                Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                     Epoch 9
wandb: Test loss tennis_pNone_gNone_tennisEffect 1e-05
wandb:                                Train loss 1e-05
wandb: 
wandb: ðŸš€ View run distinctive-sky-1323 at: https://wandb.ai/nreints/ThesisFinal2/runs/8bc7tqih
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230710_172954-8bc7tqih/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230710_173447-bx14gf2r
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sunny-eon-1335
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/bx14gf2r
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                     Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb: Test loss tennis_pNone_gNone_tennisEffect â–ˆâ–†â–„â–ˆâ–†â–ƒâ–â–â–ƒâ–
wandb:                                Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                     Epoch 9
wandb: Test loss tennis_pNone_gNone_tennisEffect 1e-05
wandb:                                Train loss 1e-05
wandb: 
wandb: ðŸš€ View run sunny-eon-1335 at: https://wandb.ai/nreints/ThesisFinal2/runs/bx14gf2r
wandb: Synced 7 W&B file(s), 0 media file(s), 1 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230710_173447-bx14gf2r/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230710_173940-k74xwzrt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fanciful-shadow-1349
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/k74xwzrt
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                     Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb: Test loss tennis_pNone_gNone_tennisEffect â–ˆâ–„â–„â–ƒâ–ƒâ–ƒâ–„â–â–â–
wandb:                                Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                     Epoch 9
wandb: Test loss tennis_pNone_gNone_tennisEffect 1e-05
wandb:                                Train loss 1e-05
wandb: 
wandb: ðŸš€ View run fanciful-shadow-1349 at: https://wandb.ai/nreints/ThesisFinal2/runs/k74xwzrt
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230710_173940-k74xwzrt/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230710_174432-6l1wwxwq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dauntless-lion-1359
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/6l1wwxwq
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 45.37710905075073 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 11.347972869873047 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0024110251 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 4.51389e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 22.04655432701111
Epoch 1/9
	 Logging train Loss: 4.18609e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 3.77875e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 22.193617820739746
Epoch 2/9
	 Logging train Loss: 3.82932e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 3.50279e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 22.15297269821167
Epoch 3/9
	 Logging train Loss: 3.33001e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.79051e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 22.113593339920044
Epoch 4/9
	 Logging train Loss: 2.74637e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.59588e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 21.91902184486389
Epoch 5/9
	 Logging train Loss: 2.17997e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.36285e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 22.20688557624817
Epoch 6/9
	 Logging train Loss: 1.69157e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.39913e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 21.997601747512817
Epoch 7/9
	 Logging train Loss: 1.4935e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 9.8693e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 22.13758087158203
Epoch 8/9
	 Logging train Loss: 1.29573e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 9.1815e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 22.298335790634155
Epoch 9/9
	 Logging train Loss: 1.22645e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 9.3003e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 22.33171272277832
Saved model in  trained_models/gru/data_tennis_pNone_gNone_tennisEffect/'dual_quat_1'_'False'.pth
It took  293.02911734580994  seconds.
----- ITERATION 8/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 45.406036376953125 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 11.320563077926636 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.002424801 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 4.04419e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 22.216659545898438
Epoch 1/9
	 Logging train Loss: 4.35465e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 3.1326e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 21.90603256225586
Epoch 2/9
	 Logging train Loss: 4.00345e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.487e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 22.21404004096985
Epoch 3/9
	 Logging train Loss: 3.49137e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 4.14964e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 22.30098271369934
Epoch 4/9
	 Logging train Loss: 3.04032e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 3.33026e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 22.672335147857666
Epoch 5/9
	 Logging train Loss: 2.48254e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.82885e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 22.421072483062744
Epoch 6/9
	 Logging train Loss: 2.04278e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.03801e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 22.069674253463745
Epoch 7/9
	 Logging train Loss: 1.50778e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.07099e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 22.138121128082275
Epoch 8/9
	 Logging train Loss: 1.34131e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.9856e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 22.269408226013184
Epoch 9/9
	 Logging train Loss: 1.27416e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 8.9067e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 22.113380193710327
Saved model in  trained_models/gru/data_tennis_pNone_gNone_tennisEffect/'dual_quat_1'_'False'.pth
It took  293.17847299575806  seconds.
----- ITERATION 9/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 45.355308055877686 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 11.341416120529175 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0031449364 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 6.925e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 22.028140783309937
Epoch 1/9
	 Logging train Loss: 4.33125e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 3.88092e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 22.198219060897827
Epoch 2/9
	 Logging train Loss: 3.38067e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 3.32573e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 22.05791139602661
Epoch 3/9
	 Logging train Loss: 3.17903e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 3.03078e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 22.385247468948364
Epoch 4/9
	 Logging train Loss: 2.84659e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.38782e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 21.88301920890808
Epoch 5/9
	 Logging train Loss: 2.50361e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.44533e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 22.154903650283813
Epoch 6/9
	 Logging train Loss: 1.98947e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 3.12088e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 21.97578191757202
Epoch 7/9
	 Logging train Loss: 1.56965e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.05776e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 22.17289447784424
Epoch 8/9
	 Logging train Loss: 1.35146e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.1627e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 22.266627550125122
Epoch 9/9
	 Logging train Loss: 1.23757e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 9.3587e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 22.16731023788452
Saved model in  trained_models/gru/data_tennis_pNone_gNone_tennisEffect/'dual_quat_1'_'False'.pth
It took  292.1852967739105  seconds.
----- ITERATION 10/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 45.30029225349426 seconds.
-- Finished Train Dataloader --
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                     Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb: Test loss tennis_pNone_gNone_tennisEffect â–ˆâ–…â–„â–„â–‚â–â–‚â–â–â–
wandb:                                Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                     Epoch 9
wandb: Test loss tennis_pNone_gNone_tennisEffect 1e-05
wandb:                                Train loss 1e-05
wandb: 
wandb: ðŸš€ View run dauntless-lion-1359 at: https://wandb.ai/nreints/ThesisFinal2/runs/6l1wwxwq
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230710_174432-6l1wwxwq/logs
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 11.32547640800476 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.002129297 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 4.94233e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 22.2444109916687
Epoch 1/9
	 Logging train Loss: 4.45801e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 3.23501e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 22.198875427246094
Epoch 2/9
	 Logging train Loss: 3.88624e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.45484e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 22.378962755203247
Epoch 3/9
	 Logging train Loss: 3.25743e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.50295e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 21.865176916122437
Epoch 4/9
	 Logging train Loss: 2.53164e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.43043e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 22.232259511947632
Epoch 5/9
	 Logging train Loss: 1.9823e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.04153e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 22.092772006988525
Epoch 6/9
	 Logging train Loss: 1.53886e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.54407e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 22.02530312538147
Epoch 7/9
	 Logging train Loss: 1.35324e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 9.8147e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 22.206303358078003
Epoch 8/9
	 Logging train Loss: 1.25692e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 9.8721e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 22.183295011520386
Epoch 9/9
	 Logging train Loss: 1.15871e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.07361e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 22.332170486450195
Saved model in  trained_models/gru/data_tennis_pNone_gNone_tennisEffect/'dual_quat_1'_'False'.pth
It took  291.92336893081665  seconds.

JOB STATISTICS
==============
Job ID: 3043757
Array Job ID: 3043750_46
Cluster: snellius
User/Group: nreints/nreints
State: RUNNING
Nodes: 1
Cores per node: 18
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 14:44:24 core-walltime
Job Wall-clock time: 00:49:08
Memory Utilized: 0.00 MB (estimated maximum)
Memory Efficiency: 0.00% of 0.00 MB (0.00 MB/node)
WARNING: Efficiency statistics may be misleading for RUNNING jobs.
