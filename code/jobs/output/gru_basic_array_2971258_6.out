wandb: Currently logged in as: nreints. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_164026-zy9ouj48
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run proud-sunset-5
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal1/runs/zy9ouj48
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone â–ˆâ–‚â–‚â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone â–ˆâ–‚â–‚â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone â–ˆâ–‚â–‚â–â–â–â–â–â–â–
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone â–ˆâ–‚â–‚â–â–â–â–â–â–â–
wandb:                                  Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone 0.0
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: ðŸš€ View run proud-sunset-5 at: https://wandb.ai/nreints/ThesisFinal1/runs/zy9ouj48
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_164026-zy9ouj48/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_165056-09rmyinr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vivid-puddle-49
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal1/runs/09rmyinr
Training on dataset: data_t(5,20)_r(0,0)_combi_pNone_gNone
Testing on 5 datasets: ['data_t(5,20)_r(0,0)_full_pNone_gNone', 'data_t(5,20)_r(0,0)_semi_pNone_gNone', 'data_t(5,20)_r(0,0)_combi_pNone_gNone', 'data_t(5,20)_r(0,0)_none_pNone_gNone', 'data_t(5,20)_r(0,0)_tennis_pNone_gNone']
Focussing on identity: False
Using extra input: False
Using fr-fr as reference point.
----- ITERATION 1/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 64.98599028587341 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(0,0)_full_pNone_gNone took 16.369508743286133 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_semi_pNone_gNone took 16.401418924331665 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 16.34726572036743 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_none_pNone_gNone took 16.5716814994812 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_tennis_pNone_gNone took 16.536932468414307 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(6, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=6, bias=True)
)
Datatype: log_dualQ_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0003903966 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.70184e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.64308e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.765e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.49871e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 2.73271e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 48.13777160644531
Epoch 1/9
	 Logging train Loss: 1.33508e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 4.8045e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 4.7338e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 5.5219e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 4.5425e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 4.9595e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 46.321929931640625
Epoch 2/9
	 Logging train Loss: 4.2554e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.1117e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.1157e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.6271e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.9874e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 2.2357e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 46.34426403045654
Epoch 3/9
	 Logging train Loss: 2.7312e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.4219e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.4168e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.7309e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.339e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.4952e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 46.16468572616577
Epoch 4/9
	 Logging train Loss: 2.5002e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.0332e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.8465e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.6064e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 9.843e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.9077e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 46.715566635131836
Epoch 5/9
	 Logging train Loss: 2.3299e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 4.966e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 6.392e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 6.639e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 4.696e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 6.716e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 46.62196063995361
Epoch 6/9
	 Logging train Loss: 2.1659e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.978e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 3.095e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 3.654e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.854e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 3.241e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 46.56372404098511
Epoch 7/9
	 Logging train Loss: 1.5937e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.061e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.155e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.541e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.044e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 2.257e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 46.27296805381775
Epoch 8/9
	 Logging train Loss: 1.8427e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 7.998e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.0441e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.4877e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 7.991e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.9949e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 46.20211935043335
Epoch 9/9
	 Logging train Loss: 1.2287e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.278e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.0199e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 6.808e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.24e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.0218e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 46.43755030632019
Saved model in  trained_models/gru/data_t(5,20)_r(0,0)_combi_pNone_gNone/'log_dualQ_1'_'False'.pth
It took  630.9415843486786  seconds.
----- ITERATION 2/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 59.7562952041626 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(0,0)_full_pNone_gNone took 15.131412267684937 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_semi_pNone_gNone took 15.141956806182861 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 14.990671634674072 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_none_pNone_gNone took 15.134063243865967 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_tennis_pNone_gNone took 15.133610725402832 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(6, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=6, bias=True)
)
Datatype: log_dualQ_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0003956206 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.33788e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 3.44747e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 3.44532e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.32376e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 3.42969e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 46.98120427131653
Epoch 1/9
	 Logging train Loss: 1.63408e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone â–ˆâ–‚â–‚â–„â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone â–ˆâ–‚â–â–†â–‚â–â–â–â–â–
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone â–ˆâ–‚â–â–†â–‚â–â–â–â–â–
wandb:                                  Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone 0.0
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: ðŸš€ View run vivid-puddle-49 at: https://wandb.ai/nreints/ThesisFinal1/runs/09rmyinr
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_165056-09rmyinr/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_170115-9vdwq9ev
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run exalted-armadillo-83
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal1/runs/9vdwq9ev
	 Logging test loss: 5.0112e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 5.3018e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 5.7156e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 4.9528e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 5.094e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 46.545034646987915
Epoch 2/9
	 Logging train Loss: 4.0256e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.2361e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.3167e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.7443e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.2532e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 2.3451e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 47.05778479576111
Epoch 3/9
	 Logging train Loss: 3.3309e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.0921e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.27776e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.29261e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.0967e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 2.45921e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 48.16990375518799
Epoch 4/9
	 Logging train Loss: 2.874e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.1686e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.7528e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.1488e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.1598e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 2.8966e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 48.54269552230835
Epoch 5/9
	 Logging train Loss: 2.7983e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 5.177e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 5.464e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 6.202e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 5.092e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 5.462e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 46.426761627197266
Epoch 6/9
	 Logging train Loss: 1.509e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.392e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 4.571e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 4.685e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.325e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 4.694e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 46.69274663925171
Epoch 7/9
	 Logging train Loss: 2.0903e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.27e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 3.012e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 3.098e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.251e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 3.036e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 46.579973459243774
Epoch 8/9
	 Logging train Loss: 2.1329e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.822e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.098e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.331e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.816e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 2.125e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 46.647075176239014
Epoch 9/9
	 Logging train Loss: 9.269e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.601e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 3.148e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.765e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.606e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 3.296e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 46.660738468170166
Saved model in  trained_models/gru/data_t(5,20)_r(0,0)_combi_pNone_gNone/'log_dualQ_1'_'False'.pth
It took  619.8857357501984  seconds.
----- ITERATION 3/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 59.36868214607239 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(0,0)_full_pNone_gNone took 15.095959424972534 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_semi_pNone_gNone took 15.064612865447998 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 14.9100661277771 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_none_pNone_gNone took 15.110898733139038 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_tennis_pNone_gNone took 15.04955267906189 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(6, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=6, bias=True)
)
Datatype: log_dualQ_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.000270693 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.92138e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.16439e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.13351e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.95224e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 2.20105e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 46.5848343372345
Epoch 1/9
	 Logging train Loss: 7.5871e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.811e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 3.1115e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 3.5304e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.8554e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 3.1539e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 46.450955867767334
Epoch 2/9
	 Logging train Loss: 3.2993e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.7055e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.1316e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.2585e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.7282e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 2.1752e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 46.44258904457092
Epoch 3/9
	 Logging train Loss: 2.6304e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 8.929e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.0429e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.1392e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 9.06e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.068e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 46.86916899681091
Epoch 4/9
	 Logging train Loss: 2.4308e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 4.252e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 4.815e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 5.438e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 4.319e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 4.908e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 46.623435258865356
Epoch 5/9
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone â–ˆâ–‚â–‚â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone â–ˆâ–‚â–‚â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone â–ˆâ–‚â–‚â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone â–ˆâ–‚â–‚â–â–â–â–â–â–â–
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone â–ˆâ–‚â–‚â–â–â–â–â–â–â–
wandb:                                  Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone 0.0
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: ðŸš€ View run exalted-armadillo-83 at: https://wandb.ai/nreints/ThesisFinal1/runs/9vdwq9ev
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_170115-9vdwq9ev/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_171130-nu8hrp9v
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run zany-snowflake-120
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal1/runs/nu8hrp9v
	 Logging train Loss: 1.6312e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.288e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 3.311e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 3.354e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.3e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 3.433e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 46.91352868080139
Epoch 6/9
	 Logging train Loss: 1.2874e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.697e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.359e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.416e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.689e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 2.372e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 46.702468156814575
Epoch 7/9
	 Logging train Loss: 1.2991e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.86e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.289e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.384e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.868e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 2.313e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 46.63704180717468
Epoch 8/9
	 Logging train Loss: 1.4047e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.031e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 6.757e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 4.735e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.034e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 7.157e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 46.58143615722656
Epoch 9/9
	 Logging train Loss: 1.0255e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.49e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.676e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.76e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.49e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.682e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 46.79082942008972
Saved model in  trained_models/gru/data_t(5,20)_r(0,0)_combi_pNone_gNone/'log_dualQ_1'_'False'.pth
It took  614.7011027336121  seconds.
----- ITERATION 4/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 59.3119170665741 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(0,0)_full_pNone_gNone took 15.052793979644775 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_semi_pNone_gNone took 15.015668869018555 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 14.840813398361206 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_none_pNone_gNone took 15.012399196624756 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_tennis_pNone_gNone took 15.031118154525757 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(6, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=6, bias=True)
)
Datatype: log_dualQ_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0004869849 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.54564e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.66375e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.6909e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.59074e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 2.70612e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 46.929805517196655
Epoch 1/9
	 Logging train Loss: 1.12748e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.048e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 3.2251e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 3.8902e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.1489e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 3.3142e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 46.91199231147766
Epoch 2/9
	 Logging train Loss: 3.3308e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.9322e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.0513e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.4991e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.9955e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 2.1237e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 46.857330322265625
Epoch 3/9
	 Logging train Loss: 2.476e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.138e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.2176e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.4816e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.1686e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.2657e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 46.51701498031616
Epoch 4/9
	 Logging train Loss: 1.9114e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 6.204e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 7.669e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 8.658e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 6.34e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 7.918e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 46.498820781707764
Epoch 5/9
	 Logging train Loss: 1.5188e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.183e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 3.429e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 4.324e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.204e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 3.535e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 47.12419533729553
Epoch 6/9
	 Logging train Loss: 1.735e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 5.043e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.2818e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.4935e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 5.069e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 2.3136e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 47.12890601158142
Epoch 7/9
	 Logging train Loss: 1.3569e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.811e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 4.707e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 4.351e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.764e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 4.799e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 46.62139678001404
Epoch 8/9
	 Logging train Loss: 1.9831e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.547e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.833e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.629e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.521e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone â–ˆâ–‚â–‚â–â–â–â–â–â–â–‚
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone â–ˆâ–‚â–‚â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone â–ˆâ–‚â–â–â–â–â–‚â–â–â–‚
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone â–ˆâ–‚â–â–â–â–â–‚â–â–â–‚
wandb:                                  Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone 0.0
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: ðŸš€ View run zany-snowflake-120 at: https://wandb.ai/nreints/ThesisFinal1/runs/nu8hrp9v
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_171130-nu8hrp9v/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_172147-tnhgbpgv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run swept-totem-158
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal1/runs/tnhgbpgv
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone â–ˆâ–‚â–‚â–â–‚â–â–ƒâ–ˆâ–â–
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone â–ˆâ–‚â–‚â–â–â–â–‚â–‚â–â–
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone â–ˆâ–‚â–‚â–â–â–â–‚â–‚â–â–
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone â–…â–‚â–â–â–‚â–â–‚â–ˆâ–â–
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone â–…â–‚â–â–â–‚â–â–‚â–ˆâ–â–
wandb:                                  Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone 0.0
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: ðŸš€ View run swept-totem-158 at: https://wandb.ai/nreints/ThesisFinal1/runs/tnhgbpgv
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_172147-tnhgbpgv/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_173204-aup1vvib
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dry-jazz-189
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal1/runs/aup1vvib
	 Logging test loss: 2.833e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 46.7395122051239
Epoch 9/9
	 Logging train Loss: 8.761e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 4.914e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 4.4859e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.3933e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 4.87e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 4.5071e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 46.824299812316895
Saved model in  trained_models/gru/data_t(5,20)_r(0,0)_combi_pNone_gNone/'log_dualQ_1'_'False'.pth
It took  617.1715207099915  seconds.
----- ITERATION 5/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 59.270349740982056 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(0,0)_full_pNone_gNone took 14.968071460723877 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_semi_pNone_gNone took 14.959851741790771 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 14.87257194519043 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_none_pNone_gNone took 14.951720714569092 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_tennis_pNone_gNone took 15.111298322677612 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(6, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=6, bias=True)
)
Datatype: log_dualQ_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0003465447 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.21116e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.37725e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.39424e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.19864e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 2.34539e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 46.46623134613037
Epoch 1/9
	 Logging train Loss: 1.1067e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.7832e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 4.7715e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 5.0518e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.733e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 4.7451e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 46.776652574539185
Epoch 2/9
	 Logging train Loss: 4.4167e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.0092e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.0793e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.5501e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.9878e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 2.0709e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 46.468162059783936
Epoch 3/9
	 Logging train Loss: 3.1941e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.4006e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.4624e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.7119e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.3906e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.4506e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 46.483468770980835
Epoch 4/9
	 Logging train Loss: 2.7008e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.0223e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 6.589e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 4.2469e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.0102e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 6.6285e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 48.14703559875488
Epoch 5/9
	 Logging train Loss: 2.153e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 4.998e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 5.385e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 5.887e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 4.94e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 5.381e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 47.935604095458984
Epoch 6/9
	 Logging train Loss: 2.3701e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.2202e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 8.4369e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 5.6277e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.2165e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 8.5019e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 46.80637550354004
Epoch 7/9
	 Logging train Loss: 1.2117e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.8785e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 4.06596e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.43733e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.826e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 4.12129e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 46.93276286125183
Epoch 8/9
	 Logging train Loss: 1.6573e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.694e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 4.042e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 3.638e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.666e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 4.089e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 46.98261880874634
Epoch 9/9
	 Logging train Loss: 1.1837e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.544e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.556e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.765e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.507e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.603e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 46.46790099143982
Saved model in  trained_models/gru/data_t(5,20)_r(0,0)_combi_pNone_gNone/'log_dualQ_1'_'False'.pth
It took  616.612272977829  seconds.
----- ITERATION 6/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 59.539048194885254 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(0,0)_full_pNone_gNone took 15.02492618560791 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_semi_pNone_gNone took 15.005447387695312 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 14.893694162368774 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_none_pNone_gNone took 15.031522989273071 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_tennis_pNone_gNone took 14.995057821273804 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(6, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=6, bias=True)
)
Datatype: log_dualQ_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0007597901 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 4.42331e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone â–ˆâ–‚â–â–â–â–â–‚â–â–â–
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone â–ˆâ–‚â–â–â–â–â–‚â–â–â–
wandb:                                  Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone 0.0
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: ðŸš€ View run dry-jazz-189 at: https://wandb.ai/nreints/ThesisFinal1/runs/aup1vvib
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_173204-aup1vvib/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_174219-ha2rt3xv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run copper-resonance-224
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal1/runs/ha2rt3xv
	 Logging test loss: 4.42116e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 4.49708e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 4.41761e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 4.26324e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 46.521679401397705
Epoch 1/9
	 Logging train Loss: 2.24356e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 6.8255e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 7.3247e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 7.7696e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 6.9205e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 6.9641e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 46.663079261779785
Epoch 2/9
	 Logging train Loss: 4.2627e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.5682e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.5882e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 3.1205e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.561e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 2.4976e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 46.43122625350952
Epoch 3/9
	 Logging train Loss: 2.5896e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.8857e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.3655e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.4597e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.8756e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 2.3163e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 46.27323126792908
Epoch 4/9
	 Logging train Loss: 2.2831e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.1067e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.2654e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.3871e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.1045e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.2153e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 46.83572959899902
Epoch 5/9
	 Logging train Loss: 2.4124e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 5.962e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 6.474e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 7.335e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 5.903e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 6.144e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 46.68623328208923
Epoch 6/9
	 Logging train Loss: 1.4798e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 4.673e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 3.8052e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.1357e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 4.579e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 3.9134e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 46.60991954803467
Epoch 7/9
	 Logging train Loss: 1.7073e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.095e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.345e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.697e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.087e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 2.242e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 46.39884829521179
Epoch 8/9
	 Logging train Loss: 9.912e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.021e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 7.281e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 5.571e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.961e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 7.234e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 46.77337169647217
Epoch 9/9
	 Logging train Loss: 1.1824e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.774e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 7.092e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 4.61e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.727e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 7.117e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 46.49597907066345
Saved model in  trained_models/gru/data_t(5,20)_r(0,0)_combi_pNone_gNone/'log_dualQ_1'_'False'.pth
It took  614.648425579071  seconds.
----- ITERATION 7/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 59.50226354598999 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(0,0)_full_pNone_gNone took 15.02909803390503 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_semi_pNone_gNone took 14.987133026123047 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 14.906275510787964 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_none_pNone_gNone took 14.99709153175354 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_tennis_pNone_gNone took 14.933562994003296 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(6, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=6, bias=True)
)
Datatype: log_dualQ_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0001638911 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 8.0336e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 8.6512e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 9.3879e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 7.6872e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 8.7797e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 46.0618462562561
Epoch 1/9
	 Logging train Loss: 4.5723e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.5712e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.6187e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 3.1969e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.536e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 2.5995e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 46.21204686164856
Epoch 2/9
	 Logging train Loss: 2.8998e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.3074e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.308e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.188e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.29e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 2.3793e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 46.165985345840454
Epoch 3/9
	 Logging train Loss: 1.555e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.4275e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.85494e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.1863e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.3931e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 2.05358e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 45.74310040473938
Epoch 4/9
wandb: Waiting for W&B process to finish... (success).
wandb: ERROR Error while calling W&B API: An internal error occurred. Please contact support. (<Response [500]>)
wandb: 
wandb: Run history:
wandb:                                       Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone â–‡â–ƒâ–‚â–ˆâ–‚â–â–‚â–â–â–
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone â–ˆâ–ƒâ–‚â–ƒâ–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone â–ˆâ–ƒâ–‚â–ƒâ–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone â–„â–‚â–‚â–ˆâ–‚â–â–‚â–â–â–
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone â–„â–‚â–‚â–ˆâ–‚â–â–‚â–â–â–
wandb:                                  Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone 0.0
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: ðŸš€ View run copper-resonance-224 at: https://wandb.ai/nreints/ThesisFinal1/runs/ha2rt3xv
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_174219-ha2rt3xv/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_175227-wjp34hef
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stoic-yogurt-262
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal1/runs/wjp34hef
	 Logging train Loss: 1.5183e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 5.94e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 3.0027e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.113e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 5.851e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 3.3226e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 45.96974992752075
Epoch 5/9
	 Logging train Loss: 1.05e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.303e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.927e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 3.092e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.257e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 3.043e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 46.083786725997925
Epoch 6/9
	 Logging train Loss: 1.3342e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.025e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.7579e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.7514e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.953e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 3.0878e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 45.96944451332092
Epoch 7/9
	 Logging train Loss: 1.1079e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.128e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 4.55e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 4.225e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.101e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 4.71e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 45.608705282211304
Epoch 8/9
	 Logging train Loss: 9.126e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.821e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.462e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.429e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.797e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 2.581e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 45.876240491867065
Epoch 9/9
	 Logging train Loss: 8.325e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.504e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 7.324e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 5.55e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.456e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 8.093e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 45.69730734825134
Saved model in  trained_models/gru/data_t(5,20)_r(0,0)_combi_pNone_gNone/'log_dualQ_1'_'False'.pth
It took  608.1769602298737  seconds.
----- ITERATION 8/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 59.2188925743103 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(0,0)_full_pNone_gNone took 14.953677654266357 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_semi_pNone_gNone took 14.939692974090576 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 14.882225751876831 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_none_pNone_gNone took 14.970401287078857 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_tennis_pNone_gNone took 15.026754140853882 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(6, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=6, bias=True)
)
Datatype: log_dualQ_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0007184836 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.76929e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 3.90024e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 3.92025e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.67011e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 4.06133e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 45.650320529937744
Epoch 1/9
	 Logging train Loss: 1.80575e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 4.4566e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 4.7048e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 5.2321e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 4.3441e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 4.9167e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 45.82569408416748
Epoch 2/9
	 Logging train Loss: 3.9089e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.5938e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.6931e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 3.1145e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.5385e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 2.8173e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 45.64468598365784
Epoch 3/9
	 Logging train Loss: 2.5021e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.5676e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.6602e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.8984e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.5329e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.7456e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 45.328084230422974
Epoch 4/9
	 Logging train Loss: 1.5045e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 7.957e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 8.634e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 9.81e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 7.762e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 9.126e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 45.51341915130615
Epoch 5/9
	 Logging train Loss: 1.725e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.0251e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 4.12147e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.59033e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.9938e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 4.90565e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 48.57283616065979
Epoch 6/9
	 Logging train Loss: 1.4209e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.157e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 9.803e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 7.875e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.12e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.1351e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 45.80092453956604
Epoch 7/9
	 Logging train Loss: 1.7215e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.565e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.738e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.042e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.537e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone â–ˆâ–‚â–‚â–â–â–†â–â–â–â–
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone â–ˆâ–‚â–â–â–â–ˆâ–â–â–â–
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone â–‡â–‚â–â–â–â–ˆâ–â–â–â–
wandb:                                  Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone 0.0
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: ðŸš€ View run stoic-yogurt-262 at: https://wandb.ai/nreints/ThesisFinal1/runs/wjp34hef
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_175227-wjp34hef/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_180233-6z32mze0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run unique-cherry-295
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal1/runs/6z32mze0
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone â–ˆâ–‚â–‚â–‚â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone â–ˆâ–‚â–â–‚â–â–â–â–â–â–‚
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone â–ˆâ–‚â–â–‚â–â–â–â–â–â–‚
wandb:                                  Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone 0.0
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: ðŸš€ View run unique-cherry-295 at: https://wandb.ai/nreints/ThesisFinal1/runs/6z32mze0
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_180233-6z32mze0/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_181237-pc024wgx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run happy-planet-321
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal1/runs/pc024wgx
	 Logging test loss: 1.813e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 45.60369396209717
Epoch 8/9
	 Logging train Loss: 1.2306e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.483e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.69e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.462e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.468e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 2.893e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 45.51577711105347
Epoch 9/9
	 Logging train Loss: 1.1871e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.389e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 5.901e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 4.845e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.359e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 6.66e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 45.3764762878418
Saved model in  trained_models/gru/data_t(5,20)_r(0,0)_combi_pNone_gNone/'log_dualQ_1'_'False'.pth
It took  606.0812838077545  seconds.
----- ITERATION 9/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 59.104785680770874 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(0,0)_full_pNone_gNone took 14.930950164794922 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_semi_pNone_gNone took 14.894617557525635 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 14.900381088256836 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_none_pNone_gNone took 14.934689044952393 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_tennis_pNone_gNone took 15.018846273422241 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(6, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=6, bias=True)
)
Datatype: log_dualQ_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0004489353 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.66912e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 3.64632e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 3.87152e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.57487e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 3.72354e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 45.26992893218994
Epoch 1/9
	 Logging train Loss: 1.89762e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 6.7538e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 6.8708e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 7.8837e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 6.7217e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 6.9853e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 45.540985345840454
Epoch 2/9
	 Logging train Loss: 4.3658e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.5318e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.5094e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 3.1865e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.4585e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 2.5614e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 45.79297685623169
Epoch 3/9
	 Logging train Loss: 2.931e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.8125e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 4.6698e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 3.6423e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.762e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 4.7961e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 45.37484049797058
Epoch 4/9
	 Logging train Loss: 2.5616e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.0376e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.4569e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.4797e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.0106e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.4994e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 45.63297629356384
Epoch 5/9
	 Logging train Loss: 2.3878e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 5.648e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 6.925e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 7.435e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 5.52e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 7.163e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 45.76864457130432
Epoch 6/9
	 Logging train Loss: 2.0299e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.043e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 3.09e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 3.65e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.984e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 3.129e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 45.66410565376282
Epoch 7/9
	 Logging train Loss: 1.5796e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 5.382e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 6.831e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 6.491e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 5.368e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 6.91e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 45.61717963218689
Epoch 8/9
	 Logging train Loss: 1.5491e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.749e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.124e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.191e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.737e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 2.126e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 45.96533918380737
Epoch 9/9
	 Logging train Loss: 1.27e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 5.329e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 3.8306e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.2492e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 5.253e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 4.0357e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 45.88574457168579
Saved model in  trained_models/gru/data_t(5,20)_r(0,0)_combi_pNone_gNone/'log_dualQ_1'_'False'.pth
It took  604.605062007904  seconds.
----- ITERATION 10/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 59.29266047477722 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(0,0)_full_pNone_gNone took 14.906585454940796 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_semi_pNone_gNone took 14.932178974151611 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 14.90618085861206 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_none_pNone_gNone took 15.089036464691162 seconds.
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone â–ˆâ–‚â–â–â–â–‚â–â–â–â–
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone â–ˆâ–‚â–â–â–â–ƒâ–â–â–â–
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone â–ˆâ–‚â–â–â–â–ƒâ–â–â–â–
wandb:                                  Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone 0.0
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: ðŸš€ View run happy-planet-321 at: https://wandb.ai/nreints/ThesisFinal1/runs/pc024wgx
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_181237-pc024wgx/logs
The dataloader for data/data_t(5,20)_r(0,0)_tennis_pNone_gNone took 14.929682731628418 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(6, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=6, bias=True)
)
Datatype: log_dualQ_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.000607912 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.65452e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 3.67664e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 3.73612e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.78684e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 3.85517e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 45.76360368728638
Epoch 1/9
	 Logging train Loss: 1.64274e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.6079e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 3.6727e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 4.3165e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.7441e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 3.8043e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 45.54331851005554
Epoch 2/9
	 Logging train Loss: 3.5658e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.3243e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.3618e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.783e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.4117e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 2.437e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 45.576706886291504
Epoch 3/9
	 Logging train Loss: 2.2669e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.3704e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.4283e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.6393e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.4087e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.4733e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 45.36295509338379
Epoch 4/9
	 Logging train Loss: 2.0905e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 7.307e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 8.553e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 9.149e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 7.482e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 8.876e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 45.42668342590332
Epoch 5/9
	 Logging train Loss: 1.9938e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 7.915e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.04466e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 6.009e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 7.813e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.08375e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 45.89467978477478
Epoch 6/9
	 Logging train Loss: 1.5745e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.135e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 7.114e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 5.707e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.149e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 7.512e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 45.910417318344116
Epoch 7/9
	 Logging train Loss: 1.5033e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 7.976e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.5129e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.1998e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 7.995e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.5259e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 45.63812470436096
Epoch 8/9
	 Logging train Loss: 2.0132e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.486e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.401e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.226e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.506e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 2.408e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 45.58510208129883
Epoch 9/9
	 Logging train Loss: 8.852e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.237e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 6.477e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 4.694e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.231e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 6.807e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 45.54155445098877
Saved model in  trained_models/gru/data_t(5,20)_r(0,0)_combi_pNone_gNone/'log_dualQ_1'_'False'.pth
It took  602.7886526584625  seconds.

JOB STATISTICS
==============
Job ID: 2971264
Array Job ID: 2971258_6
Cluster: snellius
User/Group: nreints/nreints
State: COMPLETED (exit code 0)
Nodes: 1
Cores per node: 18
CPU Utilized: 07:03:51
CPU Efficiency: 22.97% of 1-06:45:18 core-walltime
Job Wall-clock time: 01:42:31
Memory Utilized: 8.63 GB
Memory Efficiency: 0.00% of 0.00 MB
