wandb: Currently logged in as: nreints. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_164030-o66o46d9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run icy-jazz-10
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal1/runs/o66o46d9
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone █▁▁▁▁▁▁▁▁▁
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone █▂▁▁▁▁▁▂▁▂
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone █▂▁▁▁▁▁▂▁▂
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone █▁▁▁▁▁▁▁▁▁
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone █▁▁▁▁▁▁▂▁▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone 1e-05
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone 1e-05
wandb:                                  Train loss 0.0
wandb: 
wandb: 🚀 View run icy-jazz-10 at: https://wandb.ai/nreints/ThesisFinal1/runs/o66o46d9
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_164030-o66o46d9/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_165016-sfln0ur3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run unique-planet-47
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal1/runs/sfln0ur3
Training on dataset: data_t(0,0)_r(5,20)_combi_pNone_gNone
Testing on 5 datasets: ['data_t(0,0)_r(5,20)_combi_pNone_gNone', 'data_t(0,0)_r(5,20)_semi_pNone_gNone', 'data_t(0,0)_r(5,20)_full_pNone_gNone', 'data_t(0,0)_r(5,20)_tennis_pNone_gNone', 'data_t(0,0)_r(5,20)_none_pNone_gNone']
Focussing on identity: False
Using extra input: False
Using fr-fr as reference point.
----- ITERATION 1/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 65.01380324363708 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 16.167877197265625 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_semi_pNone_gNone took 16.526731729507446 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_full_pNone_gNone took 16.77350926399231 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_tennis_pNone_gNone took 16.908904314041138 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_none_pNone_gNone took 16.496822118759155 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: log_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0006163135 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.97584e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.29255e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.7417e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 5.29982e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.9005e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 42.82378005981445
Epoch 1/9
	 Logging train Loss: 1.16093e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.8257e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.3741e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.878e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 7.0476e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.324e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 41.287718057632446
Epoch 2/9
	 Logging train Loss: 4.0809e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.2917e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.7619e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 9.79e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 6.4817e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.355e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 41.0241436958313
Epoch 3/9
	 Logging train Loss: 4.2191e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.9069e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.1138e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.239e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 8.0392e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.58e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 40.989816665649414
Epoch 4/9
	 Logging train Loss: 4.5033e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.5184e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.4511e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.86e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 5.1488e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 8.02e-08 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 41.083003520965576
Epoch 5/9
	 Logging train Loss: 4.3821e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.534e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.4574e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 5.72e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 5.2384e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 8.72e-08 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 41.1500883102417
Epoch 6/9
	 Logging train Loss: 3.9236e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.7866e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.9814e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 8.05e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 5.8374e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.073e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 41.1942937374115
Epoch 7/9
	 Logging train Loss: 3.7245e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.098e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.6639e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.271e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 8.6573e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.512e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 41.01957416534424
Epoch 8/9
	 Logging train Loss: 3.3711e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.8343e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.0955e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.153e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 6.026e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.358e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 41.309425830841064
Epoch 9/9
	 Logging train Loss: 3.1882e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.2642e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.8385e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.164e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 6.8877e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.311e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 41.28014636039734
Saved model in  trained_models/gru/data_t(0,0)_r(5,20)_combi_pNone_gNone/'log_quat_1'_'False'.pth
It took  587.1962239742279  seconds.
----- ITERATION 2/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 59.77961230278015 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 15.045398473739624 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_semi_pNone_gNone took 15.37521243095398 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_full_pNone_gNone took 15.385209321975708 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_tennis_pNone_gNone took 15.372232913970947 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_none_pNone_gNone took 15.360270977020264 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: log_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0007456548 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.24873e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.6028e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.8015e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 7.06221e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.0122e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 41.81015133857727
Epoch 1/9
	 Logging train Loss: 1.28226e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone █▁▁▁▁▃▁▂▂▁
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone █▁▁▁▁▃▁▂▂▁
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone █▁▁▁▁▃▁▁▂▁
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone █▁▁▁▁▃▁▂▂▁
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone █▁▁▁▁▃▁▂▂▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone 0.0
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: 🚀 View run unique-planet-47 at: https://wandb.ai/nreints/ThesisFinal1/runs/sfln0ur3
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_165016-sfln0ur3/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_165941-y1wuu2ds
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run warm-galaxy-79
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal1/runs/y1wuu2ds
	 Logging test loss: 4.0216e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.3359e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.742e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 8.4814e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.244e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 41.476431369781494
Epoch 2/9
	 Logging train Loss: 3.5283e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.8828e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.2096e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 6.52e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 6.2066e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.076e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 41.219178199768066
Epoch 3/9
	 Logging train Loss: 3.2987e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.8868e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.3081e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 6.53e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 6.3632e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.043e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 41.380237102508545
Epoch 4/9
	 Logging train Loss: 3.7724e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.7861e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.1231e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 5.82e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 6.2234e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 9.57e-08 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 41.28149962425232
Epoch 5/9
	 Logging train Loss: 3.8392e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 9.7399e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.11784e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 5.102e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.28548e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 5.536e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 41.23680901527405
Epoch 6/9
	 Logging train Loss: 3.8365e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.7765e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.2522e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.555e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 8.6007e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.896e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 41.4196515083313
Epoch 7/9
	 Logging train Loss: 3.5719e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.3714e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 9.3573e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.915e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.00614e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.262e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 41.42316198348999
Epoch 8/9
	 Logging train Loss: 3.3961e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.3091e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 9.1198e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.043e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 9.9561e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.348e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 41.05602216720581
Epoch 9/9
	 Logging train Loss: 2.988e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.1304e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.5861e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.002e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.7428e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.236e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 41.48991084098816
Saved model in  trained_models/gru/data_t(0,0)_r(5,20)_combi_pNone_gNone/'log_quat_1'_'False'.pth
It took  564.7322540283203  seconds.
----- ITERATION 3/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 59.737247943878174 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 14.868942022323608 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_semi_pNone_gNone took 15.134190797805786 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_full_pNone_gNone took 15.280279874801636 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_tennis_pNone_gNone took 15.200507164001465 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_none_pNone_gNone took 15.237662315368652 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: log_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0008503304 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.09471e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.93015e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.9171e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 7.40564e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.0988e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 41.377203702926636
Epoch 1/9
	 Logging train Loss: 1.45254e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.0445e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 9.0884e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.071e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 9.3217e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.588e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 41.59186244010925
Epoch 2/9
	 Logging train Loss: 3.9677e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.7371e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.0621e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.984e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.08987e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.376e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 41.32023882865906
Epoch 3/9
	 Logging train Loss: 3.7348e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.4465e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.5919e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 6.83e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 6.5408e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.054e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 41.648895263671875
Epoch 4/9
	 Logging train Loss: 4.0299e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.5423e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.7614e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 7.67e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 6.8224e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.109e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 41.80447959899902
wandb: Waiting for W&B process to finish... (success).
wandb: ERROR Error while calling W&B API: An internal error occurred. Please contact support. (<Response [500]>)
wandb: ERROR Error while calling W&B API: An internal error occurred. Please contact support. (<Response [500]>)
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone █▂▂▁▁▁▁▁▁▁
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone █▂▂▁▁▁▁▁▁▁
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone █▂▂▁▁▁▁▁▁▁
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone █▂▂▁▁▁▁▁▁▁
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone █▁▂▁▁▁▁▁▁▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone 0.0
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: 🚀 View run warm-galaxy-79 at: https://wandb.ai/nreints/ThesisFinal1/runs/y1wuu2ds
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_165941-y1wuu2ds/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_170913-sybs99r6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run misty-snow-112
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal1/runs/sybs99r6
Epoch 5/9
	 Logging train Loss: 4.3387e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.9651e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.7425e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 5.13e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 5.698e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 8.22e-08 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 42.03543949127197
Epoch 6/9
	 Logging train Loss: 3.9401e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.7941e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.4716e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 5.63e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 5.4367e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 8.47e-08 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 41.902740478515625
Epoch 7/9
	 Logging train Loss: 3.7041e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.28e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.2452e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 9.72e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 6.3616e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.234e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 41.712809324264526
Epoch 8/9
	 Logging train Loss: 3.3516e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.073e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.5971e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.509e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 7.8352e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.731e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 41.42408013343811
Epoch 9/9
	 Logging train Loss: 3.0519e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.2311e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.3312e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 5.85e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.3593e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 7.78e-08 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 41.61924982070923
Saved model in  trained_models/gru/data_t(0,0)_r(5,20)_combi_pNone_gNone/'log_quat_1'_'False'.pth
It took  571.7158980369568  seconds.
----- ITERATION 4/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 60.07989740371704 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 14.942514657974243 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_semi_pNone_gNone took 15.221942901611328 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_full_pNone_gNone took 15.205166578292847 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_tennis_pNone_gNone took 15.12834358215332 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_none_pNone_gNone took 15.137149810791016 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: log_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0005720643 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.74692e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.81125e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.7489e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.97762e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.8324e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 41.16269659996033
Epoch 1/9
	 Logging train Loss: 1.03816e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.1776e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.193e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.968e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 7.7214e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.403e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 41.28345465660095
Epoch 2/9
	 Logging train Loss: 4.6255e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.7945e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.7335e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.096e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 7.1293e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.534e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 41.223243713378906
Epoch 3/9
	 Logging train Loss: 4.6736e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.9483e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.111e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.08e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 7.591e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.503e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 41.383928298950195
Epoch 4/9
	 Logging train Loss: 4.6273e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.7738e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.9123e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.79e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 5.3768e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 8.71e-08 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 41.767239809036255
Epoch 5/9
	 Logging train Loss: 4.515e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.6654e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 9.7329e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.704e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 9.4809e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.11e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 41.473262548446655
Epoch 6/9
	 Logging train Loss: 4.0721e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.3383e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.9689e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.25e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.5634e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 7.43e-08 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 41.42016625404358
Epoch 7/9
	 Logging train Loss: 3.8583e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.9921e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.2248e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.55e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 7.9438e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.88e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 41.44768047332764
Epoch 8/9
	 Logging train Loss: 3.4395e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.3412e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.72682e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.48e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.73988e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone █▂▁▁▁▂▁▁▃▁
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone █▂▁▁▁▂▁▁▃▁
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone █▂▁▁▁▂▁▁▃▁
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone █▂▁▂▁▂▁▂▃▁
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone █▁▁▁▁▂▁▂▃▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone 1e-05
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone 1e-05
wandb:                                  Train loss 0.0
wandb: 
wandb: 🚀 View run misty-snow-112 at: https://wandb.ai/nreints/ThesisFinal1/runs/sybs99r6
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_170913-sybs99r6/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_171836-xgd2550n
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run denim-dream-142
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal1/runs/xgd2550n
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone █▁▁▁▁▁▁▁▁▁
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone █▂▁▁▁▁▂▁▁▁
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone █▂▁▁▁▁▁▁▁▁
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone █▁▁▁▁▁▁▁▁▁
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone █▁▁▁▁▁▂▁▁▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone 1e-05
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone 1e-05
wandb:                                  Train loss 0.0
wandb: 
wandb: 🚀 View run denim-dream-142 at: https://wandb.ai/nreints/ThesisFinal1/runs/xgd2550n
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_171836-xgd2550n/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_172800-az9pja78
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run smooth-armadillo-176
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal1/runs/az9pja78
	 Logging test loss: 4.859e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 41.46699357032776
Epoch 9/9
	 Logging train Loss: 3.0703e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.8045e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.8133e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.122e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 5.671e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.357e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 41.41856241226196
Saved model in  trained_models/gru/data_t(0,0)_r(5,20)_combi_pNone_gNone/'log_quat_1'_'False'.pth
It took  563.521341085434  seconds.
----- ITERATION 5/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 59.99930429458618 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 14.891538858413696 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_semi_pNone_gNone took 15.17277717590332 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_full_pNone_gNone took 15.120790958404541 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_tennis_pNone_gNone took 15.065291404724121 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_none_pNone_gNone took 15.098269939422607 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: log_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0006855573 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.62056e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.04706e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.8295e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 6.30246e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.02e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 41.25130486488342
Epoch 1/9
	 Logging train Loss: 1.1486e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.7762e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.4922e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.813e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 8.1866e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.271e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 41.732205629348755
Epoch 2/9
	 Logging train Loss: 3.6719e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.7734e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.9394e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 7.71e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 6.6427e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.194e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 41.571059703826904
Epoch 3/9
	 Logging train Loss: 3.655e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.5452e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.427e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.137e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 8.2504e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.57e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 41.538262128829956
Epoch 4/9
	 Logging train Loss: 3.925e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.1168e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.8865e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.57e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 5.5745e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 8.19e-08 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 41.64218330383301
Epoch 5/9
	 Logging train Loss: 3.8151e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.4145e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.0239e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.147e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 8.2087e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.538e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 41.689570903778076
Epoch 6/9
	 Logging train Loss: 3.8405e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.8816e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.9332e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.79e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 9.1936e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.164e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 41.46021795272827
Epoch 7/9
	 Logging train Loss: 3.7212e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.7184e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.0688e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 6.28e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.9927e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 9.05e-08 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 41.313212156295776
Epoch 8/9
	 Logging train Loss: 3.2805e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.5356e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.4761e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.193e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 6.6223e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.473e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 41.31983923912048
Epoch 9/9
	 Logging train Loss: 2.932e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.025e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.29e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.476e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 7.4763e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.764e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 40.9719774723053
Saved model in  trained_models/gru/data_t(0,0)_r(5,20)_combi_pNone_gNone/'log_quat_1'_'False'.pth
It took  563.4665458202362  seconds.
----- ITERATION 6/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 60.12097525596619 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 14.96704912185669 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_semi_pNone_gNone took 15.122245788574219 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_full_pNone_gNone took 15.113534212112427 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_tennis_pNone_gNone took 15.131434917449951 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_none_pNone_gNone took 15.153799533843994 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: log_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0005213756 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.98937e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone █▂▁▂▂▂▂▂▁▁
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone █▂▁▁▂▁▂▂▁▂
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone █▂▁▂▂▁▂▁▁▂
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone █▂▁▂▂▂▂▂▁▂
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone █▂▁▂▂▂▂▂▁▂
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone 1e-05
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone 1e-05
wandb:                                  Train loss 0.0
wandb: 
wandb: 🚀 View run smooth-armadillo-176 at: https://wandb.ai/nreints/ThesisFinal1/runs/az9pja78
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_172800-az9pja78/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_173723-bztqmwug
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rural-morning-213
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal1/runs/bztqmwug
	 Logging test loss: 3.10538e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.0517e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.46154e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.2169e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 41.00858426094055
Epoch 1/9
	 Logging train Loss: 6.7493e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.8743e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.7039e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.522e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 7.3387e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.069e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 41.6826376914978
Epoch 2/9
	 Logging train Loss: 3.72e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.2605e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.7824e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 7.17e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 6.2828e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.171e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 41.253472089767456
Epoch 3/9
	 Logging train Loss: 3.9031e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.6504e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.2902e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.343e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 9.1014e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.799e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 41.38856554031372
Epoch 4/9
	 Logging train Loss: 4.3177e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.2303e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 9.3578e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.695e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.02964e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.166e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 41.15932750701904
Epoch 5/9
	 Logging train Loss: 3.8608e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.53e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.0752e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.303e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 8.9761e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.72e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 41.19526672363281
Epoch 6/9
	 Logging train Loss: 3.7531e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.4067e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.902e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.414e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 8.827e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.788e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 41.49899220466614
Epoch 7/9
	 Logging train Loss: 3.3509e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.0439e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.2397e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.39e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 8.1649e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.719e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 41.63795828819275
Epoch 8/9
	 Logging train Loss: 3.0462e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.2961e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.2018e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 6.61e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.6192e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 9.35e-08 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 41.67236256599426
Epoch 9/9
	 Logging train Loss: 2.7951e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.469e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.1347e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.491e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 6.884e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.78e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 41.73025965690613
Saved model in  trained_models/gru/data_t(0,0)_r(5,20)_combi_pNone_gNone/'log_quat_1'_'False'.pth
It took  563.5375964641571  seconds.
----- ITERATION 7/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 60.12545084953308 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 15.02764368057251 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_semi_pNone_gNone took 15.088741302490234 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_full_pNone_gNone took 15.093698501586914 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_tennis_pNone_gNone took 15.159428596496582 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_none_pNone_gNone took 15.155166864395142 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: log_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0003046785 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.01505e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.7552e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 5.968e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.90814e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 6.37e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 40.87845420837402
Epoch 1/9
	 Logging train Loss: 5.2528e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.4682e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.267e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 9.41e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 6.5492e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.27e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 41.42473769187927
Epoch 2/9
	 Logging train Loss: 5.0785e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.4852e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.3337e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 7.61e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 6.6893e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.076e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 41.037477016448975
Epoch 3/9
	 Logging train Loss: 4.7277e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.2875e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.47546e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.041e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.69211e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.366e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 41.03964281082153
Epoch 4/9
	 Logging train Loss: 4.288e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone █▂▂▆▃▄▂▂▂▁
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone █▂▁▆▂▄▂▁▂▁
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone █▂▂▆▂▄▂▁▂▁
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone █▂▃▇▃▅▂▂▂▁
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone █▂▂▇▃▅▂▂▂▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone 0.0
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: 🚀 View run rural-morning-213 at: https://wandb.ai/nreints/ThesisFinal1/runs/bztqmwug
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_173723-bztqmwug/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_174643-7o1y5qpm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run scarlet-disco-248
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal1/runs/7o1y5qpm
	 Logging test loss: 3.7452e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.8758e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.23e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 7.569e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.501e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 40.9437837600708
Epoch 5/9
	 Logging train Loss: 4.0946e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.9582e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.09144e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.78e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.22925e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.052e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 41.63994765281677
Epoch 6/9
	 Logging train Loss: 3.7118e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.1421e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.7939e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 9.51e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 6.3184e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.183e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 41.207168102264404
Epoch 7/9
	 Logging train Loss: 3.2318e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.3767e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.4106e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 6.86e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.6987e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 8.82e-08 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 41.29231262207031
Epoch 8/9
	 Logging train Loss: 2.9401e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.6436e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.8348e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.177e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 5.2944e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.353e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 40.982258796691895
Epoch 9/9
	 Logging train Loss: 2.6411e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.7718e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.2534e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 5.06e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.513e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 6.37e-08 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 41.32244849205017
Saved model in  trained_models/gru/data_t(0,0)_r(5,20)_combi_pNone_gNone/'log_quat_1'_'False'.pth
It took  559.8749618530273  seconds.
----- ITERATION 8/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 59.948299407958984 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 15.052765130996704 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_semi_pNone_gNone took 15.098193407058716 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_full_pNone_gNone took 15.07802677154541 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_tennis_pNone_gNone took 15.13134217262268 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_none_pNone_gNone took 15.233018398284912 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: log_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0005775209 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.362e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.28377e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.2678e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.54908e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.4412e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 40.181421756744385
Epoch 1/9
	 Logging train Loss: 9.1949e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.1031e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.4701e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.51e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 7.9431e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.082e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 40.760056018829346
Epoch 2/9
	 Logging train Loss: 3.8984e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.0418e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.4862e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.113e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 8.1394e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.554e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 40.86702632904053
Epoch 3/9
	 Logging train Loss: 3.9703e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.3747e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.3233e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 7.67e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 6.7758e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.174e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 40.97171878814697
Epoch 4/9
	 Logging train Loss: 4.0309e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.234e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.1203e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 6.92e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 6.5781e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.071e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 40.637895584106445
Epoch 5/9
	 Logging train Loss: 3.9057e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.508e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.7508e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.805e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 9.6804e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.175e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 41.21308922767639
Epoch 6/9
	 Logging train Loss: 3.8412e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.5556e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.6768e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.976e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 9.5843e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.319e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 41.02367448806763
Epoch 7/9
	 Logging train Loss: 3.7404e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.2703e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.3218e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.68e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.6287e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 7.58e-08 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 41.117658376693726
Epoch 8/9
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone █▂▂▁▁▂▂▁▁▁
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone █▂▁▁▁▂▂▁▁▁
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone █▂▁▁▁▂▂▁▁▁
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone █▂▂▁▁▂▂▁▁▁
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone █▂▂▁▁▂▂▁▁▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone 0.0
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone 1e-05
wandb:                                  Train loss 0.0
wandb: 
wandb: 🚀 View run scarlet-disco-248 at: https://wandb.ai/nreints/ThesisFinal1/runs/7o1y5qpm
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_174643-7o1y5qpm/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_175601-w6byo8u1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run drawn-wildflower-276
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal1/runs/w6byo8u1
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone █▄▂▂▂▁▂▂▂▁
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone █▃▂▂▁▁▂▁▂▁
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone █▃▂▂▁▁▂▁▂▁
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone █▄▃▃▂▂▃▂▃▁
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone █▄▃▃▂▂▃▂▃▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone 0.0
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: 🚀 View run drawn-wildflower-276 at: https://wandb.ai/nreints/ThesisFinal1/runs/w6byo8u1
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_175601-w6byo8u1/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_180516-wva5bb9q
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wobbly-voice-307
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal1/runs/wva5bb9q
	 Logging train Loss: 3.2878e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.396e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.5143e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 7.26e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.9364e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 9.77e-08 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 41.02019739151001
Epoch 9/9
	 Logging train Loss: 2.9244e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.4785e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.7586e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 7.77e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 5.188e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.009e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 40.76989483833313
Saved model in  trained_models/gru/data_t(0,0)_r(5,20)_combi_pNone_gNone/'log_quat_1'_'False'.pth
It took  557.4566652774811  seconds.
----- ITERATION 9/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 59.9500949382782 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 15.104675769805908 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_semi_pNone_gNone took 15.097841024398804 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_full_pNone_gNone took 15.088262796401978 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_tennis_pNone_gNone took 15.100764751434326 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_none_pNone_gNone took 15.122600317001343 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: log_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0004591826 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.09955e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.7625e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 7.692e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.87995e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 8.419e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 40.27552652359009
Epoch 1/9
	 Logging train Loss: 4.9129e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.0087e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 9.8206e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.294e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.08534e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.688e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 40.85263514518738
Epoch 2/9
	 Logging train Loss: 4.2498e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.5562e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.0352e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.03e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 7.5535e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.404e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 40.384190797805786
Epoch 3/9
	 Logging train Loss: 4.5213e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.378e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.6569e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 9.12e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 7.1723e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.266e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 40.461458683013916
Epoch 4/9
	 Logging train Loss: 4.0532e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.9462e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.8899e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 7.2e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 6.3112e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.055e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 40.56442475318909
Epoch 5/9
	 Logging train Loss: 3.94e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.2733e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.6549e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.74e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.8448e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 6.91e-08 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 41.181941747665405
Epoch 6/9
	 Logging train Loss: 3.741e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.3128e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.7183e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.107e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 7.3448e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.376e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 40.551920652389526
Epoch 7/9
	 Logging train Loss: 3.26e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.5913e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.1828e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 8.87e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 5.5902e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.133e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 40.5733642578125
Epoch 8/9
	 Logging train Loss: 3.0995e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.186e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.4568e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.331e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 7.0697e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.524e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 41.06089234352112
Epoch 9/9
	 Logging train Loss: 2.7746e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.6679e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.3415e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.06e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.5761e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 5.97e-08 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 40.68851280212402
Saved model in  trained_models/gru/data_t(0,0)_r(5,20)_combi_pNone_gNone/'log_quat_1'_'False'.pth
It took  555.5992841720581  seconds.
----- ITERATION 10/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 59.96902871131897 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 15.077902793884277 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_semi_pNone_gNone took 15.076030015945435 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_full_pNone_gNone took 15.073492765426636 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_tennis_pNone_gNone took 15.083195209503174 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_none_pNone_gNone took 15.106796264648438 seconds.
-- Finished Test Dataloader(s) --
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone █▃▄▂▂▂▂▁▄▁
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone █▂▂▁▁▁▁▁▃▁
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone █▂▂▁▁▁▁▁▃▁
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone █▃▅▃▃▃▂▁▅▁
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone █▃▅▃▃▃▂▁▆▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone 0.0
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: 🚀 View run wobbly-voice-307 at: https://wandb.ai/nreints/ThesisFinal1/runs/wva5bb9q
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_180516-wva5bb9q/logs
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: log_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0003354264 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.7993e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.11417e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 5.705e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.19877e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 5.917e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 40.71209216117859
Epoch 1/9
	 Logging train Loss: 5.5049e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.6662e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.2698e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.23e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 6.5556e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.559e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 41.213334798812866
Epoch 2/9
	 Logging train Loss: 5.0882e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.509e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.7369e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.337e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 8.2968e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.65e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 40.87413215637207
Epoch 3/9
	 Logging train Loss: 4.7484e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.3632e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.8797e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 7.06e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 6.1642e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.007e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 40.62945818901062
Epoch 4/9
	 Logging train Loss: 4.3335e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.3722e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.9098e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 8.39e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 6.2519e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.114e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 40.4967086315155
Epoch 5/9
	 Logging train Loss: 3.8374e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.5081e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.1239e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 8.9e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 6.6207e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.14e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 40.58292841911316
Epoch 6/9
	 Logging train Loss: 3.5279e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.1973e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.6434e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 8.57e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 5.971e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.073e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 40.29925012588501
Epoch 7/9
	 Logging train Loss: 3.2544e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.5451e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.5479e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 6.41e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.7987e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 8.28e-08 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 40.733253479003906
Epoch 8/9
	 Logging train Loss: 2.8003e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.9368e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.5499e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.135e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 9.4987e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.281e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 40.45952224731445
Epoch 9/9
	 Logging train Loss: 2.4882e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.4368e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.2753e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 8.6e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.5731e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 9.88e-08 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 40.57476878166199
Saved model in  trained_models/gru/data_t(0,0)_r(5,20)_combi_pNone_gNone/'log_quat_1'_'False'.pth
It took  555.8478631973267  seconds.

JOB STATISTICS
==============
Job ID: 2971268
Array Job ID: 2971258_10
Cluster: snellius
User/Group: nreints/nreints
State: COMPLETED (exit code 0)
Nodes: 1
Cores per node: 18
CPU Utilized: 06:24:55
CPU Efficiency: 22.66% of 1-04:18:54 core-walltime
Job Wall-clock time: 01:34:23
Memory Utilized: 8.17 GB
Memory Efficiency: 0.00% of 0.00 MB
