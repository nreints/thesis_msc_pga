wandb: Currently logged in as: nreints. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230329_135641-kb292lx0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lucky-sky-543
wandb: â­ï¸ View project at https://wandb.ai/nreints/test
wandb: ðŸš€ View run at https://wandb.ai/nreints/test/runs/kb292lx0
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                                  Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb: Test loss t(5, 20)_r(0, 0)_semi_pNone_gNone, MSELoss() â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–
wandb:                                             Train loss â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                                  Epoch 9
wandb: Test loss t(5, 20)_r(0, 0)_semi_pNone_gNone, MSELoss() 0.14524
wandb:                                             Train loss 0.0667
wandb: 
wandb: ðŸš€ View run lucky-sky-543 at: https://wandb.ai/nreints/test/runs/kb292lx0
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230329_135641-kb292lx0/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230329_140407-az9y9q9n
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sparkling-water-546
wandb: â­ï¸ View project at https://wandb.ai/nreints/test
wandb: ðŸš€ View run at https://wandb.ai/nreints/test/runs/az9y9q9n
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.031 MB of 0.031 MB uploaded (0.000 MB deduped)wandb: \ 0.031 MB of 0.031 MB uploaded (0.000 MB deduped)wandb: | 0.031 MB of 0.031 MB uploaded (0.000 MB deduped)wandb: / 0.031 MB of 0.031 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:                                                  Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb: Test loss t(5, 20)_r(0, 0)_semi_pNone_gNone, MSELoss() â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–
wandb:                                             Train loss â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                                  Epoch 9
wandb: Test loss t(5, 20)_r(0, 0)_semi_pNone_gNone, MSELoss() 0.13037
wandb:                                             Train loss 0.07049
wandb: 
wandb: ðŸš€ View run sparkling-water-546 at: https://wandb.ai/nreints/test/runs/az9y9q9n
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230329_140407-az9y9q9n/logs
Running for data type: pos
----- ITERATION 1/2 ------
Number of train simulations: 1600
Number of test simulations: 400
-- Finished Train Dataloader --
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(24, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=24, bias=True)
)
-- Started Training --
Epoch 0
	 Logging train Loss: 127.4590704272 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss: 32.1343879699707 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 39.352962493896484
Epoch 1
	 Logging train Loss: 15.7655689357 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss: 9.04563045501709 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 37.476210594177246
Epoch 2
	 Logging train Loss: 5.1600454252 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss: 3.8295207023620605 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 37.37747812271118
Epoch 3
	 Logging train Loss: 1.9401034061 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss: 1.6576813459396362 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 37.38122296333313
Epoch 4
	 Logging train Loss: 0.6951273573 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss: 0.7814317345619202 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 37.08306550979614
Epoch 5
	 Logging train Loss: 0.3150988835 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss: 0.48772406578063965 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 37.32464361190796
Epoch 6
	 Logging train Loss: 0.1823668945 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss: 0.33299434185028076 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 36.9568350315094
Epoch 7
	 Logging train Loss: 0.1201596025 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss: 0.24066346883773804 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 37.44124388694763
Epoch 8
	 Logging train Loss: 0.0871550556 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss: 0.18659400939941406 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 39.512192487716675
Epoch 9
	 Logging train Loss: 0.0666997831 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss: 0.14532431960105896 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 39.43247890472412
	 Logging test loss: 0.1452426165342331 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
It took  446.73467350006104  seconds.
----- ITERATION 2/2 ------
Number of train simulations: 1600
Number of test simulations: 400
-- Finished Train Dataloader --
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(24, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=24, bias=True)
)
-- Started Training --
Epoch 0
	 Logging train Loss: 128.330868241 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss: 28.28940200805664 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 41.61997365951538
Epoch 1
	 Logging train Loss: 15.7385993825 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss: 7.892437934875488 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 40.17026734352112
Epoch 2
	 Logging train Loss: 5.1855292734 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss: 3.333263635635376 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 40.71031141281128
Epoch 3
	 Logging train Loss: 2.0860638077 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss: 1.5117496252059937 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 39.34545421600342
Epoch 4
	 Logging train Loss: 0.8359859859 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss: 0.763414204120636 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 37.18106722831726
Epoch 5
	 Logging train Loss: 0.3742088247 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss: 0.44625037908554077 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 37.032392740249634
Epoch 6
	 Logging train Loss: 0.2052320575 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss: 0.30124178528785706 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 37.44842481613159
Epoch 7
	 Logging train Loss: 0.1316189225 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss: 0.21474146842956543 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 37.24189567565918
Epoch 8
	 Logging train Loss: 0.0931629848 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss: 0.16581867635250092 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 37.13421583175659
Epoch 9
	 Logging train Loss: 0.0704862852 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss: 0.13039997220039368 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 37.12594127655029
	 Logging test loss: 0.13036856055259705 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
It took  448.53330302238464  seconds.

JOB STATISTICS
==============
Job ID: 2514856
Array Job ID: 2514848_8
Cluster: snellius
User/Group: nreints/nreints
State: COMPLETED (exit code 0)
Nodes: 1
Cores per node: 18
CPU Utilized: 02:56:00
CPU Efficiency: 64.33% of 04:33:36 core-walltime
Job Wall-clock time: 00:15:12
Memory Utilized: 27.94 GB
Memory Efficiency: 89.41% of 31.25 GB
