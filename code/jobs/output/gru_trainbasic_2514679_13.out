wandb: Currently logged in as: nreints. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230329_124733-t42y27pn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fluent-spaceship-476
wandb: ⭐️ View project at https://wandb.ai/nreints/test
wandb: 🚀 View run at https://wandb.ai/nreints/test/runs/t42y27pn
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.031 MB of 0.079 MB uploaded (0.000 MB deduped)wandb: \ 0.036 MB of 0.079 MB uploaded (0.000 MB deduped)wandb: | 0.036 MB of 0.079 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:                                                  Epoch ▁▂▃▃▄▅▆▆▇█
wandb: Test loss t(5, 20)_r(0, 0)_full_pNone_gNone, MSELoss() █▃▂▁▁▁▃▁▁▁▁
wandb:                                             Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                                  Epoch 9
wandb: Test loss t(5, 20)_r(0, 0)_full_pNone_gNone, MSELoss() 0.00111
wandb:                                             Train loss 0.0019
wandb: 
wandb: 🚀 View run fluent-spaceship-476 at: https://wandb.ai/nreints/test/runs/t42y27pn
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230329_124733-t42y27pn/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230329_125700-rpv3gir5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run solar-meadow-500
wandb: ⭐️ View project at https://wandb.ai/nreints/test
wandb: 🚀 View run at https://wandb.ai/nreints/test/runs/rpv3gir5
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.031 MB of 0.031 MB uploaded (0.000 MB deduped)wandb: \ 0.031 MB of 0.079 MB uploaded (0.000 MB deduped)wandb: | 0.079 MB of 0.079 MB uploaded (0.000 MB deduped)wandb: / 0.079 MB of 0.079 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:                                                  Epoch ▁▂▃▃▄▅▆▆▇█
wandb: Test loss t(5, 20)_r(0, 0)_full_pNone_gNone, MSELoss() █▃▂▁▁▁▁▁▁▁▁
wandb:                                             Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                                  Epoch 9
wandb: Test loss t(5, 20)_r(0, 0)_full_pNone_gNone, MSELoss() 0.00052
wandb:                                             Train loss 0.00158
wandb: 
wandb: 🚀 View run solar-meadow-500 at: https://wandb.ai/nreints/test/runs/rpv3gir5
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230329_125700-rpv3gir5/logs
Running for data type: log_dualQ
----- ITERATION 1/2 ------
Number of train simulations: 1600
Number of test simulations: 400
-- Finished Train Dataloader --
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(6, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=6, bias=True)
)
-- Started Training --
Epoch 0
	 Logging train Loss: 2.1696793642 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss: 0.09561493247747421 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
     --> Epoch time; 51.69913864135742
Epoch 1
	 Logging train Loss: 0.0455437776 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss: 0.032996103167533875 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
     --> Epoch time; 49.912534952163696
Epoch 2
	 Logging train Loss: 0.020489065 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss: 0.016183512285351753 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
     --> Epoch time; 49.778170108795166
Epoch 3
	 Logging train Loss: 0.0107152974 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss: 0.007316915318369865 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
     --> Epoch time; 49.44293808937073
Epoch 4
	 Logging train Loss: 0.0065198906 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss: 0.0031846051570028067 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
     --> Epoch time; 49.53434133529663
Epoch 5
	 Logging train Loss: 0.0034630887 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss: 0.002172510139644146 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
     --> Epoch time; 49.47139286994934
Epoch 6
	 Logging train Loss: 0.0027933178 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss: 0.02300424501299858 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
     --> Epoch time; 50.01143407821655
Epoch 7
	 Logging train Loss: 0.0022360712 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss: 0.0009681604569777846 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
     --> Epoch time; 50.18221879005432
Epoch 8
	 Logging train Loss: 0.0021379408 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss: 0.0006666354602202773 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
     --> Epoch time; 49.67391538619995
Epoch 9
	 Logging train Loss: 0.0018998348 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss: 0.0011054221540689468 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
     --> Epoch time; 49.694254875183105
	 Logging test loss: 0.0011055412469431758 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
It took  568.6237416267395  seconds.
----- ITERATION 2/2 ------
Number of train simulations: 1600
Number of test simulations: 400
-- Finished Train Dataloader --
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(6, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=6, bias=True)
)
-- Started Training --
Epoch 0
	 Logging train Loss: 1.8590291613 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss: 0.06535206735134125 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
     --> Epoch time; 50.36471629142761
Epoch 1
	 Logging train Loss: 0.0407326549 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss: 0.021342620253562927 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
     --> Epoch time; 50.458088874816895
Epoch 2
	 Logging train Loss: 0.0180305333 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss: 0.010429677553474903 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
     --> Epoch time; 50.12254047393799
Epoch 3
	 Logging train Loss: 0.0099893635 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss: 0.005035598762333393 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
     --> Epoch time; 50.0650053024292
Epoch 4
	 Logging train Loss: 0.0054225941 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss: 0.002675427123904228 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
     --> Epoch time; 50.066571950912476
Epoch 5
	 Logging train Loss: 0.0041604857 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss: 0.001901136478409171 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
     --> Epoch time; 50.27530097961426
Epoch 6
	 Logging train Loss: 0.0030461395 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss: 0.0011136941611766815 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
     --> Epoch time; 53.95936417579651
Epoch 7
	 Logging train Loss: 0.0024958655 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss: 0.0009358178358525038 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
     --> Epoch time; 51.82057857513428
Epoch 8
	 Logging train Loss: 0.0024648076 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss: 0.001267371466383338 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
     --> Epoch time; 52.624847412109375
Epoch 9
	 Logging train Loss: 0.0015832614 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss: 0.0005230006645433605 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
     --> Epoch time; 49.521618366241455
	 Logging test loss: 0.0005236276192590594 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
It took  571.267272233963  seconds.

JOB STATISTICS
==============
Job ID: 2514692
Array Job ID: 2514679_13
Cluster: snellius
User/Group: nreints/nreints
State: COMPLETED (exit code 0)
Nodes: 1
Cores per node: 18
CPU Utilized: 04:03:54
CPU Efficiency: 70.09% of 05:48:00 core-walltime
Job Wall-clock time: 00:19:20
Memory Utilized: 24.77 GB
Memory Efficiency: 79.26% of 31.25 GB
