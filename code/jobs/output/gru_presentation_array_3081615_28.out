wandb: Currently logged in as: nreints. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_125108-varz1nkr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run unique-sun-5
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: ğŸš€ View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/varz1nkr
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue â–ˆâ–…â–„â–„â–ƒâ–ƒâ–‚â–‚â–â–
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue â–ˆâ–‚â–‚â–‚â–„â–â–â–â–â–
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue â–ˆâ–ƒâ–†â–ƒâ–‚â–‚â–â–â–â–
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue â–ˆâ–…â–…â–ƒâ–ƒâ–‚â–‚â–â–â–
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue 0.00615
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 2e-05
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.00124
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.01374
wandb:                                 Train loss 0.00071
wandb: 
wandb: ğŸš€ View run unique-sun-5 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/varz1nkr
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_125108-varz1nkr/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_125953-nfg1qy6g
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run spring-river-69
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: ğŸš€ View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/nfg1qy6g
Training on dataset: data_t(0,0)_r(0,0)_combi_pTrue_gTrue
Testing on 4 datasets: ['data_t(0,0)_r(0,0)_full_pTrue_gTrue', 'data_t(0,0)_r(0,0)_tennis_pTrue_gTrue', 'data_t(0,0)_r(0,0)_combi_pTrue_gTrue', 'data_t(0,0)_r(0,0)_semi_pTrue_gTrue']
Focussing on identity: False
Using extra input: False
Using start-fr as reference point.
----- ITERATION 1/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 76.48786807060242 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 19.04944658279419 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 19.525718450546265 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 19.651519060134888 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 19.523659706115723 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(6, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=6, bias=True)
)
Datatype: log_dualQ
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0988971964 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.000149687 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0749933273 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.024050273 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0160515532 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 36.69078230857849
Epoch 1/9
	 Logging train Loss: 0.0031760226 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 4.05137e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0444017276 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0172846708 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0059741628 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 35.649160623550415
Epoch 2/9
	 Logging train Loss: 0.0016060758 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 3.52812e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0519480333 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0142005514 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0123617835 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 35.43839955329895
Epoch 3/9
	 Logging train Loss: 0.0012908936 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.78473e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.032501366 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0131425392 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0053010029 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 35.28818988800049
Epoch 4/9
	 Logging train Loss: 0.0013684783 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 7.39826e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0295201708 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0121165365 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.004183732 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 35.53456234931946
Epoch 5/9
	 Logging train Loss: 0.0005518584 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.93918e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0224283487 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.01030582 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0026458548 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 35.55190896987915
Epoch 6/9
	 Logging train Loss: 0.0009811149 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.52157e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0204448868 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0087375175 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0020334693 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 35.46543002128601
Epoch 7/9
	 Logging train Loss: 0.0006424904 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.54369e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0169781465 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0075312722 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0016607459 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 35.466450214385986
Epoch 8/9
	 Logging train Loss: 0.0005641995 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.15885e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.014752198 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0063902177 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0014651226 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 35.35105347633362
Epoch 9/9
	 Logging train Loss: 0.0007054663 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.99683e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0137383584 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0061462033 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0012351673 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 35.6176872253418
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pTrue_gTrue/'log_dualQ'_'False'.pth
It took  526.0627634525299  seconds.
----- ITERATION 2/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 72.19707727432251 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 18.145952701568604 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 18.113664388656616 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 18.018964529037476 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 18.12437891960144 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(6, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=6, bias=True)
)
Datatype: log_dualQ
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0904735774 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0001082293 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0734921023 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0102763753 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0174216907 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 35.82653737068176
Epoch 1/9
	 Logging train Loss: 0.0026231974 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 6.81225e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0514374673 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0053997976 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0128840776 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 35.8571994304657
Epoch 2/9
	 Logging train Loss: 0.0022022859 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.47354e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0332204401 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0036855196 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.007548051 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 35.747361183166504
Epoch 3/9
	 Logging train Loss: 0.001479898 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.18381e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0269932598 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0036615226 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.006404941 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 35.57540941238403
Epoch 4/9
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue â–ˆâ–„â–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–â–
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue â–ˆâ–…â–‚â–‚â–ƒâ–‚â–‚â–„â–â–
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue â–ˆâ–†â–ƒâ–ƒâ–…â–‚â–‚â–‚â–â–
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue â–ˆâ–…â–ƒâ–ƒâ–„â–‚â–‚â–‚â–â–
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue 0.00114
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 1e-05
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.00289
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.01212
wandb:                                 Train loss 0.00068
wandb: 
wandb: ğŸš€ View run spring-river-69 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/nfg1qy6g
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_125953-nfg1qy6g/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_130828-zrjlvpqj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run brisk-moon-107
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: ğŸš€ View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/zrjlvpqj
wandb: Waiting for W&B process to finish... (success).
wandb: ERROR Error while calling W&B API: An internal error occurred. Please contact support. (<Response [500]>)
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue â–ˆâ–„â–…â–ƒâ–ƒâ–‚â–‚â–‚â–â–
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue â–ˆâ–ƒâ–„â–‚â–ƒâ–‚â–â–‚â–‚â–…
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue â–ˆâ–…â–…â–ƒâ–‚â–‚â–â–â–â–
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue â–ˆâ–…â–„â–ƒâ–‚â–‚â–â–â–‚â–
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue 0.00429
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 7e-05
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.00454
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.01924
wandb:                                 Train loss 0.0007
wandb: 
wandb: ğŸš€ View run brisk-moon-107 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/zrjlvpqj
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_130828-zrjlvpqj/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_131704-ve8uo4ce
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run copper-oath-146
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: ğŸš€ View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/ve8uo4ce
	 Logging train Loss: 0.0009454995 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 4.38435e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.038377095 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0031801923 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0105215851 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 35.80698895454407
Epoch 5/9
	 Logging train Loss: 0.0010755633 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.88685e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0201026257 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0023808775 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0055517233 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 35.496248722076416
Epoch 6/9
	 Logging train Loss: 0.0011427246 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.81673e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0188180264 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0020704835 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0052350154 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 35.40096879005432
Epoch 7/9
	 Logging train Loss: 0.0004579931 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 4.66956e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0166995358 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0019333973 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0041147633 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 35.70732831954956
Epoch 8/9
	 Logging train Loss: 0.0011309087 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.14155e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0137672387 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0013196659 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0034385398 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 35.63754916191101
Epoch 9/9
	 Logging train Loss: 0.0006759648 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 8.8266e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.012115404 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0011392892 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.00288832 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 35.85341954231262
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pTrue_gTrue/'log_dualQ'_'False'.pth
It took  515.1085150241852  seconds.
----- ITERATION 3/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 71.79180645942688 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 18.138606786727905 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 18.146342515945435 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 17.901206731796265 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 18.13151741027832 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(6, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=6, bias=True)
)
Datatype: log_dualQ
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0917503908 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0001240538 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0609398 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0284578297 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.029987406 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 35.626627922058105
Epoch 1/9
	 Logging train Loss: 0.0035286793 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 3.92397e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0446779877 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0163469929 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.017424887 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 35.85776710510254
Epoch 2/9
	 Logging train Loss: 0.0019356543 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 5.17477e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0350950249 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0193246286 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0194371417 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 35.61632990837097
Epoch 3/9
	 Logging train Loss: 0.0017481736 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.35704e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0324182659 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.011688251 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.011278729 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 35.888936042785645
Epoch 4/9
	 Logging train Loss: 0.0008540173 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 4.22443e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0256694816 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0109411655 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0095107742 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 35.39584708213806
Epoch 5/9
	 Logging train Loss: 0.0010560906 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.6898e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.023041565 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0079170363 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0078706527 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 35.60117483139038
Epoch 6/9
	 Logging train Loss: 0.0012006405 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.11792e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0201457776 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0063904719 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0055139745 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 35.746888160705566
Epoch 7/9
	 Logging train Loss: 0.0007147128 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.13117e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0175413359 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0060598352 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0054287827 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 35.6844425201416
Epoch 8/9
	 Logging train Loss: 0.0007853811 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.30648e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0220162906 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0060038171 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0059850249 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 35.811829566955566
Epoch 9/9
	 Logging train Loss: 0.0006977006 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 7.3862e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0192368478 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0042949948 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0045422283 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 35.5281777381897
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pTrue_gTrue/'log_dualQ'_'False'.pth
It took  516.0705089569092  seconds.
----- ITERATION 4/10 ------
Number of train simulations:  1920
Number of test simulations:  480
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue â–ˆâ–ˆâ–…â–ƒâ–‚â–‚â–‚â–â–â–
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue â–ˆâ–†â–‚â–‚â–â–â–â–â–â–
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue â–ˆâ–†â–…â–‚â–‚â–‚â–â–â–â–
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue â–ˆâ–‡â–…â–ƒâ–‚â–‚â–‚â–â–â–
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue 0.00339
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 1e-05
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.00113
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.00695
wandb:                                 Train loss 0.00054
wandb: 
wandb: ğŸš€ View run copper-oath-146 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/ve8uo4ce
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_131704-ve8uo4ce/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_132539-ovus0xld
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run denim-snowball-184
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: ğŸš€ View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/ovus0xld
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 71.7985429763794 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 18.07567024230957 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 18.016863107681274 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 18.02183747291565 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 18.070254802703857 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(6, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=6, bias=True)
)
Datatype: log_dualQ
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0792036876 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0001034765 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0344247185 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0172874834 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0114268418 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 35.59412384033203
Epoch 1/9
	 Logging train Loss: 0.0022820423 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 7.32361e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0297504645 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0166683737 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0087940078 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 35.409640073776245
Epoch 2/9
	 Logging train Loss: 0.0012740417 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.29622e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0214512907 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0113694295 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0065250462 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 35.89168691635132
Epoch 3/9
	 Logging train Loss: 0.0012147464 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.71868e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0139877731 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0064616236 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0029132145 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 35.90843200683594
Epoch 4/9
	 Logging train Loss: 0.0006231298 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 9.4602e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0121191926 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0060696835 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0025766364 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 35.78233194351196
Epoch 5/9
	 Logging train Loss: 0.0009919213 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.30711e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.010620743 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0044856258 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0023515187 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 35.40972638130188
Epoch 6/9
	 Logging train Loss: 0.0011508536 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.32805e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0100604836 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0053669862 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0018427464 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 35.399657249450684
Epoch 7/9
	 Logging train Loss: 0.0002692946 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 9.9135e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0082004964 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0037685384 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0015585285 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 35.97734999656677
Epoch 8/9
	 Logging train Loss: 0.0004198538 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.33118e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0078527806 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0041035106 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0016007401 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 35.8248188495636
Epoch 9/9
	 Logging train Loss: 0.0005375514 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 7.6081e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0069505977 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0033861035 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0011319297 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 35.97630167007446
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pTrue_gTrue/'log_dualQ'_'False'.pth
It took  515.0232014656067  seconds.
----- ITERATION 5/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 71.42358636856079 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 18.069538354873657 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 18.07256507873535 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 18.03722357749939 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 18.121620416641235 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(6, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=6, bias=True)
)
Datatype: log_dualQ
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0867371261 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0001263336 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0897056386 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0033504299 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0126425447 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 35.68925595283508
Epoch 1/9
	 Logging train Loss: 0.0032228669 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 5.59973e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0553650968 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0011855577 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0064441306 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 35.329535484313965
Epoch 2/9
	 Logging train Loss: 0.0018226072 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 3.01087e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0394772142 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0008980702 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0045927563 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 35.64004945755005
Epoch 3/9
	 Logging train Loss: 0.0018747218 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.97908e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.033701431 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0006682195 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0025084212 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 35.48731827735901
Epoch 4/9
	 Logging train Loss: 0.001252763 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.72832e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0250296909 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0005215404 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0022344403 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 35.71374559402466
Epoch 5/9
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue â–ˆâ–ƒâ–‚â–‚â–‚â–‚â–â–â–ƒâ–
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue â–ˆâ–„â–‚â–â–â–â–â–‚â–†â–
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue â–ˆâ–„â–ƒâ–‚â–‚â–‚â–â–â–‚â–
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue â–ˆâ–…â–ƒâ–ƒâ–‚â–‚â–â–â–‚â–
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue 0.00029
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 1e-05
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.00092
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.01202
wandb:                                 Train loss 0.00082
wandb: 
wandb: ğŸš€ View run denim-snowball-184 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/ovus0xld
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_132539-ovus0xld/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_133502-9yi2wasj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run revived-hill-228
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: ğŸš€ View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/9yi2wasj
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue â–ˆâ–ƒâ–„â–‚â–‚â–â–â–â–â–
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue â–ˆâ–„â–ƒâ–‚â–‚â–â–â–â–â–
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue â–ˆâ–ƒâ–„â–‚â–‚â–â–â–â–â–
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue â–ˆâ–‡â–‡â–ƒâ–‚â–‚â–â–â–â–
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue 0.00013
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 1e-05
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.00068
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.01367
wandb:                                 Train loss 0.0009
wandb: 
wandb: ğŸš€ View run revived-hill-228 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/9yi2wasj
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_133502-9yi2wasj/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_134344-rywumcmj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run whole-darkness-275
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: ğŸš€ View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/rywumcmj
	 Logging train Loss: 0.0015846505 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.8414e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0256306995 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0005889576 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0019180868 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 35.70018720626831
Epoch 6/9
	 Logging train Loss: 0.000541006 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.71783e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0167128146 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0004873794 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0016406171 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 45.04754447937012
Epoch 7/9
	 Logging train Loss: 0.0008650743 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.51136e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0175609663 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0003686046 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0013762424 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 48.798256158828735
Epoch 8/9
	 Logging train Loss: 0.0008864672 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 8.844e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0258037485 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0011931722 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0025690596 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 48.4507110118866
Epoch 9/9
	 Logging train Loss: 0.0008160507 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.16894e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0120153828 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.000289063 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0009218534 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 49.02164435386658
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pTrue_gTrue/'log_dualQ'_'False'.pth
It took  563.0802369117737  seconds.
----- ITERATION 6/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 72.92830157279968 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 18.02913737297058 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 18.03175449371338 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 17.803800106048584 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 18.02460813522339 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(6, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=6, bias=True)
)
Datatype: log_dualQ
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.1167328879 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0001579585 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0630234256 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0019003287 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0092589194 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 35.55424666404724
Epoch 1/9
	 Logging train Loss: 0.0051964489 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 7.80871e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.052552782 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0005749618 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0036151705 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 35.75888681411743
Epoch 2/9
	 Logging train Loss: 0.0025570141 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 6.04422e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0524393246 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0008399235 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0048383847 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 35.68273687362671
Epoch 3/9
	 Logging train Loss: 0.0017325394 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 3.60119e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.02779321 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.000344607 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0016128223 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 35.68998050689697
Epoch 4/9
	 Logging train Loss: 0.0010527846 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.37231e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0227548108 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0002606248 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0014690984 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 36.980700969696045
Epoch 5/9
	 Logging train Loss: 0.0020737841 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.02859e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0187539645 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0001211922 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0007831529 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 36.80996656417847
Epoch 6/9
	 Logging train Loss: 0.0006387112 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.16098e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0153538957 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0001017872 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0006078875 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 36.76318335533142
Epoch 7/9
	 Logging train Loss: 0.0013026492 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 8.065e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0151583413 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 9.15635e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0005494006 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 37.00164198875427
Epoch 8/9
	 Logging train Loss: 0.000651145 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.32186e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0129631236 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 8.32327e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0004966056 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 37.10212063789368
Epoch 9/9
	 Logging train Loss: 0.0008979387 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.07289e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0136740329 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0001276693 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0006790276 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 36.93509602546692
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pTrue_gTrue/'log_dualQ'_'False'.pth
It took  522.0547993183136  seconds.
----- ITERATION 7/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 71.74792861938477 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 18.162076234817505 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 18.16654658317566 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 18.18384027481079 seconds.
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue â–ˆâ–ƒâ–ƒâ–‚â–‚â–ƒâ–â–â–â–
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue â–ˆâ–ƒâ–‚â–‚â–‚â–„â–â–â–â–
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue â–ˆâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–â–â–
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue â–ˆâ–„â–ƒâ–‚â–‚â–ƒâ–‚â–â–â–
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue 0.00186
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 1e-05
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.00216
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.00847
wandb:                                 Train loss 0.0007
wandb: 
wandb: ğŸš€ View run whole-darkness-275 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/rywumcmj
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_134344-rywumcmj/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_135230-7lql2bar
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run devoted-energy-317
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: ğŸš€ View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/7lql2bar
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 18.19314169883728 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(6, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=6, bias=True)
)
Datatype: log_dualQ
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0823865831 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0001273918 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0534717329 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0172727983 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0166200195 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 36.803853034973145
Epoch 1/9
	 Logging train Loss: 0.0030759196 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 4.90029e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0289565641 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0070591294 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.007246485 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 36.876426219940186
Epoch 2/9
	 Logging train Loss: 0.0019459508 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 3.45852e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0212758761 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0060006627 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0056971819 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 36.81771659851074
Epoch 3/9
	 Logging train Loss: 0.0011044164 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.05919e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0156533942 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0037081935 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0045524668 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 36.64005398750305
Epoch 4/9
	 Logging train Loss: 0.0016061198 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.31038e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0151044196 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0030696141 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0041316943 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 36.76944661140442
Epoch 5/9
	 Logging train Loss: 0.0017610474 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 6.15403e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0237119161 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0060893586 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0045843725 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 36.90050172805786
Epoch 6/9
	 Logging train Loss: 0.000417405 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 9.8594e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.010772476 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0025518739 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0031941449 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 36.76803779602051
Epoch 7/9
	 Logging train Loss: 0.0004486987 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.15125e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0074702948 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0021229552 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0028887314 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 37.11290216445923
Epoch 8/9
	 Logging train Loss: 0.000922912 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.02595e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0088820811 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0020227658 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0025762082 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 36.84460210800171
Epoch 9/9
	 Logging train Loss: 0.0007027086 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.20051e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0084715905 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0018589487 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0021579242 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 37.07260179519653
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pTrue_gTrue/'log_dualQ'_'False'.pth
It took  525.980940580368  seconds.
----- ITERATION 8/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 71.87706160545349 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 18.103949308395386 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 18.100555419921875 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 18.05512547492981 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 18.122055053710938 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(6, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=6, bias=True)
)
Datatype: log_dualQ
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.1035747752 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0001705034 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0749357045 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0239827149 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0271134544 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 36.77609133720398
Epoch 1/9
	 Logging train Loss: 0.0046490273 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 4.08177e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0410040803 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0134035442 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0188357756 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 36.83517789840698
Epoch 2/9
	 Logging train Loss: 0.0018148085 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.42653e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0270640776 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0069397003 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.008315403 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 36.85072422027588
Epoch 3/9
	 Logging train Loss: 0.0019864568 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 3.07359e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0225308817 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.005633356 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0063280575 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 36.93748664855957
Epoch 4/9
	 Logging train Loss: 0.0017905307 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.47539e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0168605596 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0039510741 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0050309012 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 36.66601872444153
Epoch 5/9
	 Logging train Loss: 0.0007879813 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0001332039 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0190646276 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.005513113 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.00718142 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
wandb: Waiting for W&B process to finish... (success).
wandb: ERROR Error while calling W&B API: An internal error occurred. Please contact support. (<Response [500]>)
wandb: ERROR Error while calling W&B API: An internal error occurred. Please contact support. (<Response [500]>)
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue â–ˆâ–…â–‚â–‚â–‚â–‚â–‚â–â–â–
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue â–ˆâ–‚â–‚â–‚â–â–†â–ƒâ–â–â–‚
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue â–ˆâ–†â–ƒâ–‚â–‚â–‚â–‚â–â–â–
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue â–ˆâ–„â–ƒâ–‚â–‚â–‚â–‚â–â–â–
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue 0.00305
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 4e-05
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.00311
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.01005
wandb:                                 Train loss 0.00083
wandb: 
wandb: ğŸš€ View run devoted-energy-317 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/7lql2bar
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_135230-7lql2bar/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_140145-4j7csgrn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run neat-totem-352
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: ğŸš€ View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/4j7csgrn
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue â–ˆâ–„â–ƒâ–‚â–ƒâ–‚â–‚â–‚â–‚â–
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue â–…â–ƒâ–‚â–‚â–‚â–â–ˆâ–â–â–
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue â–ˆâ–„â–…â–ƒâ–ƒâ–‚â–ƒâ–â–‚â–
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue â–ˆâ–„â–ƒâ–‚â–‚â–‚â–‚â–‚â–â–
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue 0.00234
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 1e-05
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.00497
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.01639
wandb:                                 Train loss 0.00078
wandb: 
wandb: ğŸš€ View run neat-totem-352 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/4j7csgrn
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_140145-4j7csgrn/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_141032-ogjpdqoc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run still-snowflake-359
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: ğŸš€ View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/ogjpdqoc
		--> Epoch time; 37.083638429641724
Epoch 6/9
	 Logging train Loss: 0.0005807414 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 4.43131e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0147195514 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0044994592 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.005102383 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 36.917813539505005
Epoch 7/9
	 Logging train Loss: 0.0008276002 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 8.5944e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0106988112 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0027145655 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0031701389 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 36.95986270904541
Epoch 8/9
	 Logging train Loss: 0.0008761731 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.07732e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.009802077 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0023378185 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0033169596 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 36.916444063186646
Epoch 9/9
	 Logging train Loss: 0.0008280791 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 3.63275e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0100541478 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0030498991 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0031083433 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 36.873804807662964
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pTrue_gTrue/'log_dualQ'_'False'.pth
It took  554.4196887016296  seconds.
----- ITERATION 9/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 72.46843385696411 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 18.10560154914856 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 18.17348027229309 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 18.144574403762817 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 18.18563723564148 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(6, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=6, bias=True)
)
Datatype: log_dualQ
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0952131897 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0001285004 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0920609534 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0168101117 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.024352679 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 36.6344633102417
Epoch 1/9
	 Logging train Loss: 0.0037099803 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 6.05421e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0497594178 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0081466017 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0136145232 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 37.06972336769104
Epoch 2/9
	 Logging train Loss: 0.0017473252 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 3.73493e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0408117995 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0069070812 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0170583799 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 36.844043493270874
Epoch 3/9
	 Logging train Loss: 0.0018286436 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 3.62176e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0317289084 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0050484245 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0096707968 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 36.88159370422363
Epoch 4/9
	 Logging train Loss: 0.0014440831 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 3.51976e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0311918072 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0065892772 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0094285579 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 37.1262092590332
Epoch 5/9
	 Logging train Loss: 0.0006219895 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.98998e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0259735584 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0048125573 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0068355845 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 36.8422327041626
Epoch 6/9
	 Logging train Loss: 0.0015618451 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0002263957 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0280301925 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0053751161 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0091415392 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 36.733845233917236
Epoch 7/9
	 Logging train Loss: 0.0005116129 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.49718e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0252768807 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0049579949 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0057485602 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 36.962843894958496
Epoch 8/9
	 Logging train Loss: 0.0006024325 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.0726e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0212756842 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0037092713 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0068939421 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 36.953906297683716
Epoch 9/9
	 Logging train Loss: 0.000778414 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.02224e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0163949579 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0023358692 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0049702632 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 36.85797190666199
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pTrue_gTrue/'log_dualQ'_'False'.pth
It took  527.2360458374023  seconds.
----- ITERATION 10/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 72.6693389415741 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 18.17599129676819 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 18.208056211471558 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 18.129435062408447 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 18.16009831428528 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(6, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=6, bias=True)
)
Datatype: log_dualQ
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0848116651 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0001097732 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue â–ˆâ–†â–…â–†â–„â–…â–ƒâ–â–ƒâ–
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue â–‡â–ƒâ–ƒâ–‚â–‚â–ˆâ–‚â–‚â–‚â–
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue â–ˆâ–„â–„â–ƒâ–ƒâ–ˆâ–‚â–‚â–‚â–
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue â–ˆâ–…â–„â–ƒâ–ƒâ–…â–‚â–â–‚â–
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue 0.00766
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 1e-05
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.00262
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.01152
wandb:                                 Train loss 0.0007
wandb: 
wandb: ğŸš€ View run still-snowflake-359 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/ogjpdqoc
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_141032-ogjpdqoc/logs
	 Logging test loss: 0.0509979203 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0171262287 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0156734306 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 36.81479096412659
Epoch 1/9
	 Logging train Loss: 0.0027311202 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 4.64475e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0326015875 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.014471896 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0091045909 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 37.261422634124756
Epoch 2/9
	 Logging train Loss: 0.0015101746 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 3.98171e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0296632461 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0134086423 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0079662073 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 37.21018409729004
Epoch 3/9
	 Logging train Loss: 0.0011094835 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.8369e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0255164802 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0138498787 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0064068157 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 37.04429388046265
Epoch 4/9
	 Logging train Loss: 0.0011029772 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.95383e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0213677473 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0118448921 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0059228009 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 36.90071368217468
Epoch 5/9
	 Logging train Loss: 0.0010183564 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0001282037 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0318254419 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0130939046 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0148023758 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 36.97076892852783
Epoch 6/9
	 Logging train Loss: 0.0005833602 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.7321e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0158204976 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0098912055 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0040975176 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 36.76543664932251
Epoch 7/9
	 Logging train Loss: 0.0006908964 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.8739e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.013532728 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.007227804 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0049490076 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 37.133923292160034
Epoch 8/9
	 Logging train Loss: 0.0007061458 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.28471e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.015509746 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0105745448 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.003607092 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 36.868408203125
Epoch 9/9
	 Logging train Loss: 0.0006963409 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 8.1837e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0115246978 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0076557291 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0026217464 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 37.25851583480835
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pTrue_gTrue/'log_dualQ'_'False'.pth
It took  530.4458696842194  seconds.

JOB STATISTICS
==============
Job ID: 3081641
Array Job ID: 3081615_28
Cluster: snellius
User/Group: nreints/nreints
State: RUNNING
Nodes: 1
Cores per node: 18
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 1-02:33:18 core-walltime
Job Wall-clock time: 01:28:31
Memory Utilized: 0.00 MB (estimated maximum)
Memory Efficiency: 0.00% of 0.00 MB (0.00 MB/node)
WARNING: Efficiency statistics may be misleading for RUNNING jobs.
