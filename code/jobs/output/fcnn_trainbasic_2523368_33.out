wandb: Currently logged in as: nreints. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home/nreints/.netrc
/gpfs/home2/nreints/MScThesis/code/fcnn.py:566: DeprecationWarning: Sampling from a set deprecated
since Python 3.9 and will be removed in a subsequent version.
  train_sims = set(random.sample(sims_train, int(0.8 * n_sims_train)))
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230330_123650-pf4szrfy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run crimson-sunset-598
wandb: â­ï¸ View project at https://wandb.ai/nreints/test
wandb: ðŸš€ View run at https://wandb.ai/nreints/test/runs/pf4szrfy
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.029 MB of 0.078 MB uploaded (0.000 MB deduped)wandb: \ 0.029 MB of 0.078 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  Test loss t(0, 0)_r(5, 20)_full L1Loss() â–ˆâ–‡â–…â–„â–„â–ƒâ–„â–ƒâ–ƒâ–‚â–‚â–‚â–ƒâ–‚â–‚â–ƒâ–â–‚â–â–‚â–‚
wandb: Test loss t(0, 0)_r(5, 20)_full MSELoss() â–ˆâ–†â–…â–„â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–
wandb:     Train loss data_t(0, 0)_r(5, 20)_full â–ˆâ–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:  Test loss t(0, 0)_r(5, 20)_full L1Loss() 0.07864
wandb: Test loss t(0, 0)_r(5, 20)_full MSELoss() 0.03393
wandb:     Train loss data_t(0, 0)_r(5, 20)_full 0.03377
wandb: 
wandb: ðŸš€ View run crimson-sunset-598 at: https://wandb.ai/nreints/test/runs/pf4szrfy
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230330_123650-pf4szrfy/logs
/gpfs/home2/nreints/MScThesis/code/fcnn.py:566: DeprecationWarning: Sampling from a set deprecated
since Python 3.9 and will be removed in a subsequent version.
  train_sims = set(random.sample(sims_train, int(0.8 * n_sims_train)))
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230330_124835-909rd3un
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run smooth-wood-628
wandb: â­ï¸ View project at https://wandb.ai/nreints/test
wandb: ðŸš€ View run at https://wandb.ai/nreints/test/runs/909rd3un
Training on dataset: data/data_t(0, 0)_r(5, 20)_full_pNone_gNone
Testing on datasets: ['data_t(0, 0)_r(5, 20)_full_pNone_gNone']
----- ITERATION 1/2 ------
Number of train simulations: 1600
Number of test simulations: 400
The dataloader took 60.707908391952515 seconds.
-- Finished Train Dataloader --
The dataloader took 15.134521007537842 seconds.
-- Finished Test Dataloader(s) --
Datatype: dual_quat
--- Started Training ---
Epoch 0
	 Logging train Loss: 0.7755631989 (MSELoss(): data_t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 0.202372744679451 (MSELoss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 0.18765069544315338 (L1Loss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
     --> Epoch time; 31.458741188049316
Epoch 1
	 Logging train Loss: 0.1842516731 (MSELoss(): data_t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 0.1620589643716812 (MSELoss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 0.1610742062330246 (L1Loss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
     --> Epoch time; 31.666663646697998
Epoch 2
	 Logging train Loss: 0.1383162455 (MSELoss(): data_t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 0.12647095322608948 (MSELoss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 0.12475565820932388 (L1Loss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
     --> Epoch time; 31.383127212524414
Epoch 3
	 Logging train Loss: 0.1119178223 (MSELoss(): data_t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 0.10282900184392929 (MSELoss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 0.11474534869194031 (L1Loss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
     --> Epoch time; 31.34392738342285
Epoch 4
	 Logging train Loss: 0.0949088203 (MSELoss(): data_t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 0.08100578188896179 (MSELoss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 0.11077238619327545 (L1Loss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
     --> Epoch time; 31.31755828857422
Epoch 5
	 Logging train Loss: 0.0851322349 (MSELoss(): data_t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 0.07756080478429794 (MSELoss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 0.09633976221084595 (L1Loss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
     --> Epoch time; 31.363478660583496
Epoch 6
	 Logging train Loss: 0.075985633 (MSELoss(): data_t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 0.07337363064289093 (MSELoss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 0.11580689996480942 (L1Loss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
     --> Epoch time; 31.596889972686768
Epoch 7
	 Logging train Loss: 0.0717370426 (MSELoss(): data_t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 0.07216285914182663 (MSELoss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 0.09267750382423401 (L1Loss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
     --> Epoch time; 30.950888872146606
Epoch 8
	 Logging train Loss: 0.0671737771 (MSELoss(): data_t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 0.05619380623102188 (MSELoss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 0.08864687383174896 (L1Loss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
     --> Epoch time; 31.12277579307556
Epoch 9
	 Logging train Loss: 0.0594309539 (MSELoss(): data_t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 0.05928846821188927 (MSELoss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 0.08400524407625198 (L1Loss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
     --> Epoch time; 29.703371286392212
Epoch 10
	 Logging train Loss: 0.0606925316 (MSELoss(): data_t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 0.04688296467065811 (MSELoss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 0.08006786555051804 (L1Loss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
     --> Epoch time; 29.86117434501648
Epoch 11
	 Logging train Loss: 0.0556097941 (MSELoss(): data_t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 0.059396952390670776 (MSELoss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 0.08548721671104431 (L1Loss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
     --> Epoch time; 30.06176257133484
Epoch 12
	 Logging train Loss: 0.049047687 (MSELoss(): data_t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 0.04793184623122215 (MSELoss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 0.09237490594387054 (L1Loss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
     --> Epoch time; 29.89724063873291
Epoch 13
	 Logging train Loss: 0.0517055786 (MSELoss(): data_t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 0.04986550286412239 (MSELoss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 0.08712387084960938 (L1Loss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
     --> Epoch time; 31.32286524772644
Epoch 14
	 Logging train Loss: 0.0451061623 (MSELoss(): data_t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 0.04278898984193802 (MSELoss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 0.08312996476888657 (L1Loss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
     --> Epoch time; 29.67952871322632
Epoch 15
	 Logging train Loss: 0.0416871488 (MSELoss(): data_t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 0.05044630914926529 (MSELoss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 0.09138438105583191 (L1Loss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
     --> Epoch time; 29.70777440071106
Epoch 16
	 Logging train Loss: 0.0402981852 (MSELoss(): data_t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 0.03349079191684723 (MSELoss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 0.06534013897180557 (L1Loss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
     --> Epoch time; 29.79696822166443
Epoch 17
	 Logging train Loss: 0.0387769886 (MSELoss(): data_t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 0.0363396555185318 (MSELoss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 0.07178300619125366 (L1Loss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
     --> Epoch time; 29.77940058708191
Epoch 18
	 Logging train Loss: 0.0369896733 (MSELoss(): data_t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 0.027844127267599106 (MSELoss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 0.06107975170016289 (L1Loss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
     --> Epoch time; 29.788031578063965
Epoch 19
	 Logging train Loss: 0.033767391 (MSELoss(): data_t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 0.03393953666090965 (MSELoss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 0.07861776649951935 (L1Loss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
     --> Epoch time; 32.430362939834595
	 Logging test loss 0.03392817825078964 (MSELoss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 0.07863934338092804 (L1Loss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
It took 704.7357223033905 seconds to train & eval the model.
----- ITERATION 2/2 ------
Number of train simulations: 1600
Number of test simulations: 400
The dataloader took 54.448835134506226 seconds.
-- Finished Train Dataloader --
The dataloader took 13.943434238433838 seconds.
-- Finished Test Dataloader(s) --
Datatype: dual_quat
--- Started Training ---
Epoch 0
	 Logging train Loss: 0.3364054761 (MSELoss(): data_t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 0.008694491349160671 (MSELoss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 0.06259049475193024 (L1Loss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
     --> Epoch time; 31.78408145904541
Epoch 1
	 Logging train Loss: 0.0052952972 (MSELoss(): data_t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 0.0042088450863957405 (MSELoss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 0.04373859614133835 (L1Loss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
     --> Epoch time; 29.57750368118286
Epoch 2
	 Logging train Loss: 0.0028125517 (MSELoss(): data_t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 0.0025196904316544533 (MSELoss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 0.03367328271269798 (L1Loss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
     --> Epoch time; 29.704443216323853
Epoch 3
	 Logging train Loss: 0.0018037855 (MSELoss(): data_t(0, 0)_r(5, 20)_full_pNone_gNone)
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:  Test loss t(0, 0)_r(5, 20)_full L1Loss() â–ˆâ–†â–„â–„â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–
wandb: Test loss t(0, 0)_r(5, 20)_full MSELoss() â–ˆâ–„â–ƒâ–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:     Train loss data_t(0, 0)_r(5, 20)_full â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:  Test loss t(0, 0)_r(5, 20)_full L1Loss() 0.00859
wandb: Test loss t(0, 0)_r(5, 20)_full MSELoss() 0.00016
wandb:     Train loss data_t(0, 0)_r(5, 20)_full 0.00013
wandb: 
wandb: ðŸš€ View run smooth-wood-628 at: https://wandb.ai/nreints/test/runs/909rd3un
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230330_124835-909rd3un/logs
	 Logging test loss 0.0017327232053503394 (MSELoss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 0.028004806488752365 (L1Loss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
     --> Epoch time; 29.179009437561035
Epoch 4
	 Logging train Loss: 0.0012657867 (MSELoss(): data_t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 0.0012647114926949143 (MSELoss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 0.02383916638791561 (L1Loss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
     --> Epoch time; 31.120765209197998
Epoch 5
	 Logging train Loss: 0.0009630736 (MSELoss(): data_t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 0.001034570042975247 (MSELoss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 0.021527912467718124 (L1Loss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
     --> Epoch time; 30.6754789352417
Epoch 6
	 Logging train Loss: 0.0007669045 (MSELoss(): data_t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 0.0008035378414206207 (MSELoss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 0.01917736791074276 (L1Loss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
     --> Epoch time; 30.604095935821533
Epoch 7
	 Logging train Loss: 0.000583287 (MSELoss(): data_t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 0.0005948568577878177 (MSELoss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 0.01639942079782486 (L1Loss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
     --> Epoch time; 29.614898204803467
Epoch 8
	 Logging train Loss: 0.0004421377 (MSELoss(): data_t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 0.0004776627174578607 (MSELoss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 0.014728949405252934 (L1Loss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
     --> Epoch time; 29.67597460746765
Epoch 9
	 Logging train Loss: 0.0003522487 (MSELoss(): data_t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 0.0003806001041084528 (MSELoss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 0.013101368211209774 (L1Loss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
     --> Epoch time; 29.57181453704834
Epoch 10
	 Logging train Loss: 0.0002974588 (MSELoss(): data_t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 0.00036295331665314734 (MSELoss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 0.012954393401741982 (L1Loss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
     --> Epoch time; 29.071495294570923
Epoch 11
	 Logging train Loss: 0.0002570746 (MSELoss(): data_t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 0.00032221814035438 (MSELoss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 0.012042112648487091 (L1Loss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
     --> Epoch time; 30.852994680404663
Epoch 12
	 Logging train Loss: 0.0002276925 (MSELoss(): data_t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 0.000254689046414569 (MSELoss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 0.01071418821811676 (L1Loss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
     --> Epoch time; 29.486526012420654
Epoch 13
	 Logging train Loss: 0.0002053377 (MSELoss(): data_t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 0.0002525038435123861 (MSELoss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 0.010724799707531929 (L1Loss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
     --> Epoch time; 29.300455331802368
Epoch 14
	 Logging train Loss: 0.0001873031 (MSELoss(): data_t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 0.00023470638552680612 (MSELoss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 0.010352901183068752 (L1Loss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
     --> Epoch time; 29.544437408447266
Epoch 15
	 Logging train Loss: 0.0001735478 (MSELoss(): data_t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 0.0002137334959115833 (MSELoss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 0.009877325966954231 (L1Loss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
     --> Epoch time; 29.36539387702942
Epoch 16
	 Logging train Loss: 0.0001605298 (MSELoss(): data_t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 0.000186674646101892 (MSELoss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 0.009106313809752464 (L1Loss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
     --> Epoch time; 31.563666820526123
Epoch 17
	 Logging train Loss: 0.0001506883 (MSELoss(): data_t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 0.0001776654098648578 (MSELoss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 0.008979062549769878 (L1Loss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
     --> Epoch time; 30.779358386993408
Epoch 18
	 Logging train Loss: 0.000141109 (MSELoss(): data_t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 0.0001965679257409647 (MSELoss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 0.009505956433713436 (L1Loss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
     --> Epoch time; 30.86497950553894
Epoch 19
	 Logging train Loss: 0.000133441 (MSELoss(): data_t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 0.00016361860616598278 (MSELoss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 0.008585551753640175 (L1Loss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
     --> Epoch time; 29.354105949401855
	 Logging test loss 0.0001636369852349162 (MSELoss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 0.008586094714701176 (L1Loss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
It took 686.6084880828857 seconds to train & eval the model.

JOB STATISTICS
==============
Job ID: 2523401
Array Job ID: 2523368_33
Cluster: snellius
User/Group: nreints/nreints
State: COMPLETED (exit code 0)
Nodes: 1
Cores per node: 18
CPU Utilized: 03:44:26
CPU Efficiency: 53.13% of 07:02:24 core-walltime
Job Wall-clock time: 00:23:28
Memory Utilized: 3.63 GB
Memory Efficiency: 12.39% of 29.30 GB
