wandb: Currently logged in as: nreints. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_125115-8m8cxzs1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fine-river-16
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/8m8cxzs1
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue ▄▂▁▁█▂▁▇▁▁
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue ▄▂▁▁▄▁▁█▅▁
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue ▅▂▂▁█▂▁█▁▁
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue ▃▂▁▁█▂▁▆▁▁
wandb:                                 Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.0
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.0
wandb:                                 Train loss 0.0
wandb: 
wandb: 🚀 View run fine-river-16 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/8m8cxzs1
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_125115-8m8cxzs1/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_125934-as8emse8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rare-spaceship-68
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/as8emse8
Training on dataset: data_t(0,0)_r(0,0)_combi_pTrue_gTrue
Testing on 4 datasets: ['data_t(0,0)_r(0,0)_tennis_pTrue_gTrue', 'data_t(0,0)_r(0,0)_combi_pTrue_gTrue', 'data_t(0,0)_r(0,0)_semi_pTrue_gTrue', 'data_t(0,0)_r(0,0)_full_pTrue_gTrue']
Focussing on identity: False
Using extra input: True
Using fr-fr as reference point.
----- ITERATION 1/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 60.58390927314758 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 15.151719808578491 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 15.245103597640991 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 15.448503255844116 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 15.292998790740967 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(6, 96, batch_first=True)
  (pre_hidden_lin_layer): Sequential(
    (0): Linear(in_features=3, out_features=96, bias=True)
    (1): ReLU()
    (2): Linear(in_features=96, out_features=96, bias=True)
    (3): ReLU()
  )
  (fc): Linear(in_features=96, out_features=6, bias=True)
)
Datatype: log_dualQ_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0005483639 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 5.4234e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.1687e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 3.251e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 2.025e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 37.301531076431274
Epoch 1/9
	 Logging train Loss: 1.2721e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.5005e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 9.922e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.3177e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 5.19e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 36.22205471992493
Epoch 2/9
	 Logging train Loss: 2.8936e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.103e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 4.722e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 7.504e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 3.22e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 36.00560116767883
Epoch 3/9
	 Logging train Loss: 2.9944e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 8.727e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 3.838e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 6.356e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 2.55e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 35.695109605789185
Epoch 4/9
	 Logging train Loss: 3.3133e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.62593e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 5.6441e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 5.8336e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 1.707e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 35.94221472740173
Epoch 5/9
	 Logging train Loss: 1.2325e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.7144e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 6.979e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 9.699e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 3.38e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 36.05904531478882
Epoch 6/9
	 Logging train Loss: 2.3495e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 7.405e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.82e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 3.683e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 1.8e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 36.23386216163635
Epoch 7/9
	 Logging train Loss: 2.596e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.23922e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 4.6345e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 5.7576e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 4.461e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 35.925920724868774
Epoch 8/9
	 Logging train Loss: 7.829e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 7.853e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 4.932e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 6.628e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 2.682e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 35.77301788330078
Epoch 9/9
	 Logging train Loss: 1.3913e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 4.129e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.759e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.84e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 1.63e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 36.040640115737915
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pTrue_gTrue/'log_dualQ_1'_'True'.pth
It took  500.1889555454254  seconds.
----- ITERATION 2/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 55.82417631149292 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 14.159631967544556 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 14.000429630279541 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 14.168275833129883 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 14.226755619049072 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(6, 96, batch_first=True)
  (pre_hidden_lin_layer): Sequential(
    (0): Linear(in_features=3, out_features=96, bias=True)
    (1): ReLU()
    (2): Linear(in_features=96, out_features=96, bias=True)
    (3): ReLU()
  )
  (fc): Linear(in_features=96, out_features=6, bias=True)
)
Datatype: log_dualQ_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0004169861 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 5.3816e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.1737e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 3.9731e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 2.765e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 36.23101353645325
Epoch 1/9
	 Logging train Loss: 7.2321e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.9402e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 7.596e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.3785e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 5.69e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 36.30210733413696
Epoch 2/9
	 Logging train Loss: 7.543e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.2539e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 7.317e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.0751e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 4.29e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 36.07929587364197
Epoch 3/9
	 Logging train Loss: 3.3121e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 5.56484e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue ▂▁▁█▁▁▁▂▁▇
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue ▂▁▁▃▁▁▁▂▁█
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue ▂▁▁▆▁▁▁▁▁█
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue ▂▁▁█▁▁▁▂▁▅
wandb:                                 Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue 2e-05
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 3e-05
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 3e-05
wandb:                                 Train loss 0.0
wandb: 
wandb: 🚀 View run rare-spaceship-68 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/as8emse8
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_125934-as8emse8/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_130741-k1rxbmgy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run jumping-dew-106
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/k1rxbmgy
	 Logging test loss: 1.87359e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.20886e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 6.369e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 35.91570830345154
Epoch 4/9
	 Logging train Loss: 4.0144e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 7.697e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.916e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 5.925e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 2.8e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 36.407541036605835
Epoch 5/9
	 Logging train Loss: 3.256e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 6.247e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.406e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 5.038e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 2.18e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 36.70589351654053
Epoch 6/9
	 Logging train Loss: 2.055e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 5.723e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.144e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 4.329e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 1.87e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 36.213979959487915
Epoch 7/9
	 Logging train Loss: 1.5273e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 4.8656e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.609e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.6886e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 1.946e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 35.99471354484558
Epoch 8/9
	 Logging train Loss: 2.3379e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 3.443e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.359e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.724e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 1.7e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 36.02578115463257
Epoch 9/9
	 Logging train Loss: 9.862e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 3.44807e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.67935e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 3.19165e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 1.817e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 36.269859790802
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pTrue_gTrue/'log_dualQ_1'_'True'.pth
It took  486.5030882358551  seconds.
----- ITERATION 3/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 55.842151403427124 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 14.109986543655396 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 13.961358547210693 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 14.093066930770874 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 14.110964059829712 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(6, 96, batch_first=True)
  (pre_hidden_lin_layer): Sequential(
    (0): Linear(in_features=3, out_features=96, bias=True)
    (1): ReLU()
    (2): Linear(in_features=96, out_features=96, bias=True)
    (3): ReLU()
  )
  (fc): Linear(in_features=96, out_features=6, bias=True)
)
Datatype: log_dualQ_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0008726235 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 7.4738e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 3.1007e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 4.2044e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 2.24e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 36.27067708969116
Epoch 1/9
	 Logging train Loss: 1.3478e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.0667e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 9.626e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.4043e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 6.67e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 36.11755299568176
Epoch 2/9
	 Logging train Loss: 3.2303e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.36994e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 7.2071e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 5.311e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 9.55e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 36.226556062698364
Epoch 3/9
	 Logging train Loss: 3.3552e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 5.2402e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.1399e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.2565e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 4.854e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 36.00451946258545
Epoch 4/9
	 Logging train Loss: 2.2637e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 9.948e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 4.445e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 6.277e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 3.96e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 35.77235388755798
Epoch 5/9
	 Logging train Loss: 2.7185e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 8.057e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 3.644e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 5.063e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 2.16e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 35.92916488647461
Epoch 6/9
	 Logging train Loss: 1.8044e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 5.8057e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.6716e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 4.3645e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 2.696e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 36.26152324676514
Epoch 7/9
	 Logging train Loss: 2.45e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.1841e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 5.007e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 7.181e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 4.41e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 36.04230213165283
Epoch 8/9
	 Logging train Loss: 1.9663e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 3.868e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.76e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.452e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 1.5e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 36.27806043624878
Epoch 9/9
	 Logging train Loss: 1.7364e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 4.5131e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.5433e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.3755e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 2.201e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue ▄▂█▃▁▁▃▁▁▂
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue ▄▂▂█▁▁▅▁▁▄
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue ▆▃█▄▂▁▇▂▁▃
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue ▃▂█▂▁▁▃▁▁▂
wandb:                                 Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.0
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.0
wandb:                                 Train loss 0.0
wandb: 
wandb: 🚀 View run jumping-dew-106 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/k1rxbmgy
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_130741-k1rxbmgy/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_131546-nbetdnhj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eternal-blaze-144
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/nbetdnhj
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue ▄▂▁▁▁▁▂█▁▁
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue ▂▁▁▁▁▁▁█▁▁
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue ▄▂▁▁▁▁▂█▁▁
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue ▆▂▂▁▁▁▂█▁▁
wandb:                                 Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.0
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.0
wandb:                                 Train loss 0.0
wandb: 
wandb: 🚀 View run eternal-blaze-144 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/nbetdnhj
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_131546-nbetdnhj/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_132353-9xgm0wh8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run bumbling-dragon-177
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/9xgm0wh8
		--> Epoch time; 35.830299377441406
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pTrue_gTrue/'log_dualQ_1'_'True'.pth
It took  485.50822615623474  seconds.
----- ITERATION 4/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 55.867326498031616 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 14.125121593475342 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 14.007247924804688 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 14.123372316360474 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 14.124855041503906 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(6, 96, batch_first=True)
  (pre_hidden_lin_layer): Sequential(
    (0): Linear(in_features=3, out_features=96, bias=True)
    (1): ReLU()
    (2): Linear(in_features=96, out_features=96, bias=True)
    (3): ReLU()
  )
  (fc): Linear(in_features=96, out_features=6, bias=True)
)
Datatype: log_dualQ_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0005783525 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 7.5834e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 3.2167e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 4.6484e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 2.393e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 36.04690074920654
Epoch 1/9
	 Logging train Loss: 3.7294e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.1381e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 9.272e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.5531e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 5.68e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 35.7185480594635
Epoch 2/9
	 Logging train Loss: 4.7438e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.6587e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 7.217e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.1798e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 3.74e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 36.02882480621338
Epoch 3/9
	 Logging train Loss: 5.5506e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.0363e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 4.969e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 9.229e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 3.13e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 36.077598094940186
Epoch 4/9
	 Logging train Loss: 3.3902e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.0345e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 4.633e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 8.056e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 2.74e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 36.77903699874878
Epoch 5/9
	 Logging train Loss: 5.5701e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 7.097e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 3.455e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 6.701e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 2.68e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 36.59131121635437
Epoch 6/9
	 Logging train Loss: 1.9439e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.4615e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.0486e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.4966e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 6.02e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 36.03699564933777
Epoch 7/9
	 Logging train Loss: 2.9514e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.04151e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 6.3433e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.13991e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 2.0051e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 36.03502631187439
Epoch 8/9
	 Logging train Loss: 1.4979e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.1035e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 5.924e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.1281e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 8.37e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 35.83094024658203
Epoch 9/9
	 Logging train Loss: 1.7898e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 6.115e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 3.189e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 4.06e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 1.276e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 36.02569556236267
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pTrue_gTrue/'log_dualQ_1'_'True'.pth
It took  486.61104249954224  seconds.
----- ITERATION 5/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 55.92460823059082 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 14.103782176971436 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 14.015727519989014 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 14.13645052909851 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 14.086475849151611 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(6, 96, batch_first=True)
  (pre_hidden_lin_layer): Sequential(
    (0): Linear(in_features=3, out_features=96, bias=True)
    (1): ReLU()
    (2): Linear(in_features=96, out_features=96, bias=True)
    (3): ReLU()
  )
  (fc): Linear(in_features=96, out_features=6, bias=True)
)
Datatype: log_dualQ_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0009494103 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 8.9285e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 3.321e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 5.398e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 2.364e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 36.11975693702698
Epoch 1/9
	 Logging train Loss: 1.6189e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.6118e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.0397e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.6749e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 6.87e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 36.15075874328613
Epoch 2/9
	 Logging train Loss: 3.2874e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 6.97865e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.09132e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.3305e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 5.842e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 36.07889437675476
Epoch 3/9
	 Logging train Loss: 3.7274e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.5452e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 5.867e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 9.458e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue ▂▁█▁▁▁▁▁▄▁
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue ▂▁▅▁▁▂▂▁█▁
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue ▄▂█▁▁▁▂▁▇▁
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue ▂▁█▁▁▁▁▁▄▁
wandb:                                 Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.0
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.0
wandb:                                 Train loss 0.0
wandb: 
wandb: 🚀 View run bumbling-dragon-177 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/9xgm0wh8
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_132353-9xgm0wh8/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_133158-bwfk91s0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run deep-moon-218
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/bwfk91s0
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue ▂▁█▂▇▁▁▁▁▄
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue ▄▂▂▂█▁▁▁▁▆
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue ▃▂▄▂█▁▁▁▁▆
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue ▂▁█▂▅▁▁▁▁▃
wandb:                                 Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue 1e-05
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 1e-05
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 1e-05
wandb:                                 Train loss 0.0
wandb: 
wandb: 🚀 View run deep-moon-218 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/bwfk91s0
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_133158-bwfk91s0/logs
	 Logging test loss: 4e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 36.23122978210449
Epoch 4/9
	 Logging train Loss: 5.4165e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.0794e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 4.575e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 7.951e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 3.1e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 35.89905858039856
Epoch 5/9
	 Logging train Loss: 2.6726e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.623e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 6.548e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 8.08e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 1.201e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 36.05904722213745
Epoch 6/9
	 Logging train Loss: 7.2958e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.8148e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 9.254e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.5017e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 1.148e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 35.864055156707764
Epoch 7/9
	 Logging train Loss: 1.316e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.0978e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 5.27e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 7.859e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 9.93e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 36.027066707611084
Epoch 8/9
	 Logging train Loss: 2.6119e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.57654e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.05759e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.14618e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 1.0568e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 36.1059627532959
Epoch 9/9
	 Logging train Loss: 1.7144e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 6.22e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.941e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 4.374e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 2.82e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 36.10962724685669
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pTrue_gTrue/'log_dualQ_1'_'True'.pth
It took  485.44610571861267  seconds.
----- ITERATION 6/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 56.05904412269592 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 14.04787564277649 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 14.010189771652222 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 14.138744592666626 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 14.107576608657837 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(6, 96, batch_first=True)
  (pre_hidden_lin_layer): Sequential(
    (0): Linear(in_features=3, out_features=96, bias=True)
    (1): ReLU()
    (2): Linear(in_features=96, out_features=96, bias=True)
    (3): ReLU()
  )
  (fc): Linear(in_features=96, out_features=6, bias=True)
)
Datatype: log_dualQ_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0007320543 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 8.5206e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.6369e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 5.2408e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 2.792e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 35.99123930931091
Epoch 1/9
	 Logging train Loss: 5.3261e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 3.0572e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 9.217e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.5878e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 6.33e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 36.065043210983276
Epoch 2/9
	 Logging train Loss: 2.986e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 4.61693e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.28538e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 6.3535e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 7.71e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 36.20541214942932
Epoch 3/9
	 Logging train Loss: 9.7261e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 5.1139e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.5591e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.9453e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 7.48e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 36.578686475753784
Epoch 4/9
	 Logging train Loss: 9.303e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.90723e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.06654e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.47432e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 5.757e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 36.5353639125824
Epoch 5/9
	 Logging train Loss: 4.4091e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 8.304e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.574e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 5.595e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 2.19e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 36.044968128204346
Epoch 6/9
	 Logging train Loss: 1.8114e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 7.972e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.532e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 4.375e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 2.47e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 36.20058035850525
Epoch 7/9
	 Logging train Loss: 2.8565e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.8943e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 5.693e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 6.642e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 4.89e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 36.02315711975098
Epoch 8/9
	 Logging train Loss: 1.932e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 6.941e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.233e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 3.808e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 2.41e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 36.29088640213013
Epoch 9/9
	 Logging train Loss: 1.8032e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.42873e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 5.7645e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 9.739e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 4.291e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 35.95244884490967
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pTrue_gTrue/'log_dualQ_1'_'True'.pth
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_134005-l4y6hi80
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run bumbling-shape-259
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/l4y6hi80
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue ▅█▂▂▁▁▁▁▅▁
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue ▅▂▁▁▁▂▁▁█▁
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue █▆▃▂▂▂▁▁█▁
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue ▃█▁▁▁▁▁▁▃▁
wandb:                                 Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.0
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.0
wandb:                                 Train loss 0.0
wandb: 
wandb: 🚀 View run bumbling-shape-259 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/l4y6hi80
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_134005-l4y6hi80/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_134811-gwmefh4o
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run drawn-sunset-294
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/gwmefh4o
It took  486.5525622367859  seconds.
----- ITERATION 7/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 56.015533208847046 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 14.097997188568115 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 13.995781660079956 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 14.059794664382935 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 14.137299537658691 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(6, 96, batch_first=True)
  (pre_hidden_lin_layer): Sequential(
    (0): Linear(in_features=3, out_features=96, bias=True)
    (1): ReLU()
    (2): Linear(in_features=96, out_features=96, bias=True)
    (3): ReLU()
  )
  (fc): Linear(in_features=96, out_features=6, bias=True)
)
Datatype: log_dualQ_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.00036485 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 4.7279e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.3164e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 3.3395e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 2.227e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 36.06497240066528
Epoch 1/9
	 Logging train Loss: 3.9221e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.25007e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 3.6382e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.4518e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 6.81e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 36.33872890472412
Epoch 2/9
	 Logging train Loss: 9.7011e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.1329e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 5.778e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 9.533e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 4.16e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 36.206568241119385
Epoch 3/9
	 Logging train Loss: 5.014e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 9.347e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 4.615e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 7.338e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 4.08e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 35.957093715667725
Epoch 4/9
	 Logging train Loss: 6.6086e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 7.91e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 3.68e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 5.679e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 3.39e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 36.048948526382446
Epoch 5/9
	 Logging train Loss: 1.7867e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 8.826e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 4.334e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 7.192e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 5.11e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 36.06158113479614
Epoch 6/9
	 Logging train Loss: 3.0325e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 4.929e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.414e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 3.711e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 3.13e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 36.07856559753418
Epoch 7/9
	 Logging train Loss: 3.6563e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 6.329e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.762e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 4.291e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 1.95e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 35.95563817024231
Epoch 8/9
	 Logging train Loss: 8.843e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 4.6956e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.1235e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 3.2318e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 3.608e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 35.967960596084595
Epoch 9/9
	 Logging train Loss: 1.5959e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 4.318e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.987e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.942e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 1.9e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 36.0654456615448
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pTrue_gTrue/'log_dualQ_1'_'True'.pth
It took  486.49358320236206  seconds.
----- ITERATION 8/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 55.95119261741638 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 14.048105955123901 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 14.057541847229004 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 14.138650894165039 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 14.074049711227417 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(6, 96, batch_first=True)
  (pre_hidden_lin_layer): Sequential(
    (0): Linear(in_features=3, out_features=96, bias=True)
    (1): ReLU()
    (2): Linear(in_features=96, out_features=96, bias=True)
    (3): ReLU()
  )
  (fc): Linear(in_features=96, out_features=6, bias=True)
)
Datatype: log_dualQ_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0007827103 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 6.647e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.8827e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 4.6634e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 2.504e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 35.764599084854126
Epoch 1/9
	 Logging train Loss: 5.4071e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.4204e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.0911e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.7897e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 7.12e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 36.13558387756348
Epoch 2/9
	 Logging train Loss: 1.29032e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.0092e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 8.669e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.362e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 3.84e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 36.51029181480408
Epoch 3/9
	 Logging train Loss: 5.506e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.1985e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 5.307e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 8.993e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 3.3e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 36.16600823402405
Epoch 4/9
	 Logging train Loss: 1.4173e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue ▅▃▂▂▂▆▁▁▁█
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue ▆▂▂▁▂█▁▁▁█
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue ▅▂▂▂▁▄▁▁▁█
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue ▆▃▂▂▂▇▁▁▁█
wandb:                                 Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 1e-05
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 1e-05
wandb:                                 Train loss 0.0
wandb: 
wandb: 🚀 View run drawn-sunset-294 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/gwmefh4o
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_134811-gwmefh4o/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_135617-fswbnccp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run feasible-totem-334
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/fswbnccp
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue █▂▃▁▁▁▂▁▂█
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue ▄▂▁▁▁▁▆▁▃█
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue █▂▂▁▁▁▂▂▂█
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue ▇▂▄▂▁▁▂▁▂█
wandb:                                 Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.0
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 1e-05
wandb:                                 Train loss 0.0
wandb: 
wandb: 🚀 View run feasible-totem-334 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/fswbnccp
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_135617-fswbnccp/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_140423-blh2j6vr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run happy-pyramid-357
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/blh2j6vr
	 Logging test loss: 1.106e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 4.818e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 7.719e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 4.01e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 35.92850732803345
Epoch 5/9
	 Logging train Loss: 2.8313e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 7.6675e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 3.0564e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 3.4795e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 3.386e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 36.28388333320618
Epoch 6/9
	 Logging train Loss: 2.681e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 9.013e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 3.925e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 6.683e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 2.59e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 35.88042497634888
Epoch 7/9
	 Logging train Loss: 2.6658e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 5.223e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.207e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 3.472e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 1.65e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 36.314927101135254
Epoch 8/9
	 Logging train Loss: 1.5346e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 3.469e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.546e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.61e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 1.25e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 36.032243728637695
Epoch 9/9
	 Logging train Loss: 2.2383e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 9.2674e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 4.4806e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 8.866e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 3.344e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 36.2945556640625
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pTrue_gTrue/'log_dualQ_1'_'True'.pth
It took  486.10755729675293  seconds.
----- ITERATION 9/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 55.9308397769928 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 14.032715797424316 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 14.025994062423706 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 14.087371349334717 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 14.084651947021484 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(6, 96, batch_first=True)
  (pre_hidden_lin_layer): Sequential(
    (0): Linear(in_features=3, out_features=96, bias=True)
    (1): ReLU()
    (2): Linear(in_features=96, out_features=96, bias=True)
    (3): ReLU()
  )
  (fc): Linear(in_features=96, out_features=6, bias=True)
)
Datatype: log_dualQ_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0006344839 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 6.0498e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.8951e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 4.541e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 2.079e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 35.91513538360596
Epoch 1/9
	 Logging train Loss: 3.7436e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.6092e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 7.835e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.3057e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 5.25e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 35.96336507797241
Epoch 2/9
	 Logging train Loss: 1.7435e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 3.1535e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.0913e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.2354e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 4.67e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 36.13379096984863
Epoch 3/9
	 Logging train Loss: 2.7896e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.1418e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 5.151e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 8.08e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 3.81e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 35.8212833404541
Epoch 4/9
	 Logging train Loss: 2.6866e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 7.92e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 3.877e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 6.609e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 3.21e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 35.87082242965698
Epoch 5/9
	 Logging train Loss: 5.1261e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 6.596e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 3.223e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 5.417e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 2.28e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 36.37237095832825
Epoch 6/9
	 Logging train Loss: 1.0606e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.5985e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 8.241e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.1221e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 2.846e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 35.8326952457428
Epoch 7/9
	 Logging train Loss: 1.8935e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 9.319e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 4.898e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 9.13e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 4.05e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 36.09643316268921
Epoch 8/9
	 Logging train Loss: 1.9021e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.1619e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 5.593e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 8.346e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 1.242e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 36.03044056892395
Epoch 9/9
	 Logging train Loss: 2.0496e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 6.833e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 3.0746e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 4.4717e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 4.255e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 36.03165888786316
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pTrue_gTrue/'log_dualQ_1'_'True'.pth
It took  485.4521722793579  seconds.
----- ITERATION 10/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 54.53210711479187 seconds.
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue ▅▂▂▁█▄▁▁▃▁
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue █▃▁▁▇▂▁▁▇▁
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue ▅▂▂▂█▂▁▁▂▁
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue ▅▂▂▂█▅▁▁▃▁
wandb:                                 Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.0
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.0
wandb:                                 Train loss 0.0
wandb: 
wandb: 🚀 View run happy-pyramid-357 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/blh2j6vr
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_140423-blh2j6vr/logs
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 14.018050909042358 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 13.761862993240356 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 14.14395523071289 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 14.022460699081421 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(6, 96, batch_first=True)
  (pre_hidden_lin_layer): Sequential(
    (0): Linear(in_features=3, out_features=96, bias=True)
    (1): ReLU()
    (2): Linear(in_features=96, out_features=96, bias=True)
    (3): ReLU()
  )
  (fc): Linear(in_features=96, out_features=6, bias=True)
)
Datatype: log_dualQ_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0006146395 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 5.6426e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.3167e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 3.8402e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 2.988e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 36.272254943847656
Epoch 1/9
	 Logging train Loss: 1.7548e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.0391e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 8.226e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.4243e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 7.89e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 36.429352045059204
Epoch 2/9
	 Logging train Loss: 1.7119e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.3022e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 5.171e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 9.313e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 3.71e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 36.07931327819824
Epoch 3/9
	 Logging train Loss: 3.6696e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 9.842e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 3.888e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 7.567e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 3.05e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 36.13596844673157
Epoch 4/9
	 Logging train Loss: 1.6324e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 9.1608e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 4.0509e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 6.4757e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 2.693e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 36.04896688461304
Epoch 5/9
	 Logging train Loss: 2e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 5.0466e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.5298e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.462e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 5.79e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 36.116947174072266
Epoch 6/9
	 Logging train Loss: 2.5943e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 5.924e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.565e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 4.805e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 2.35e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 35.96786189079285
Epoch 7/9
	 Logging train Loss: 2.4469e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 3.786e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.682e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 3.061e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 1.71e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 35.94139337539673
Epoch 8/9
	 Logging train Loss: 1.7456e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.8051e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.1271e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.2472e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 2.568e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 36.05787658691406
Epoch 9/9
	 Logging train Loss: 1.2946e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.372e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.104e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.735e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 1.83e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 35.98218297958374
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pTrue_gTrue/'log_dualQ_1'_'True'.pth
It took  485.0707907676697  seconds.

JOB STATISTICS
==============
Job ID: 3081656
Array Job ID: 3081615_42
Cluster: snellius
User/Group: nreints/nreints
State: COMPLETED (exit code 0)
Nodes: 1
Cores per node: 18
CPU Utilized: 01:28:52
CPU Efficiency: 6.06% of 1-00:26:06 core-walltime
Job Wall-clock time: 01:21:27
Memory Utilized: 7.58 GB
Memory Efficiency: 0.00% of 0.00 MB
