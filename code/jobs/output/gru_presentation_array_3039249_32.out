wandb: Currently logged in as: nreints. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_231700-wgr4zhjt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run snowy-dream-1143
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/wgr4zhjt
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue â–ˆâ–‚â–â–â–â–â–â–â–â–‚
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue â–ˆâ–‚â–â–â–â–â–â–â–â–ƒ
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue â–ˆâ–‚â–â–â–â–â–â–â–â–‚
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue â–ˆâ–‚â–â–â–â–â–â–â–â–‚
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 1e-05
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue 1e-05
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue 1e-05
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue 1e-05
wandb:                                 Train loss 4e-05
wandb: 
wandb: ðŸš€ View run snowy-dream-1143 at: https://wandb.ai/nreints/ThesisFinal2/runs/wgr4zhjt
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_231700-wgr4zhjt/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_232535-j2ap460e
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run jolly-darkness-1160
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/j2ap460e
Training on dataset: data_t(0,0)_r(0,0)_combi_pNone_gTrue
Testing on 4 datasets: ['data_t(0,0)_r(0,0)_tennis_pNone_gTrue', 'data_t(0,0)_r(0,0)_combi_pNone_gTrue', 'data_t(0,0)_r(0,0)_full_pNone_gTrue', 'data_t(0,0)_r(0,0)_semi_pNone_gTrue']
Focussing on identity: False
Using extra input: False
Using start-fr as reference point.
----- ITERATION 1/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 78.57195234298706 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pNone_gTrue took 19.690593004226685 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 19.836599349975586 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pNone_gTrue took 19.764052867889404 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pNone_gTrue took 19.65322256088257 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0734634101 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.64452e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 5.52285e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.60772e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 7.51335e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 35.59723711013794
Epoch 1/9
	 Logging train Loss: 2.60018e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.55895e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.09094e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.7717e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.52937e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 33.69740557670593
Epoch 2/9
	 Logging train Loss: 6.1787e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.5856e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.1988e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.9888e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 4.4654e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 33.63996481895447
Epoch 3/9
	 Logging train Loss: 2.156e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.0521e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.4449e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 9.068e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.9914e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 33.60486698150635
Epoch 4/9
	 Logging train Loss: 1.92781e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.1741e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 8.522e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.639e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.1421e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 33.276589155197144
Epoch 5/9
	 Logging train Loss: 4.25613e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 9.552e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 7.004e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.679e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 9.415e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 33.420398235321045
Epoch 6/9
	 Logging train Loss: 4.41921e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.8118e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.067e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.3229e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.7278e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 33.90062069892883
Epoch 7/9
	 Logging train Loss: 4.93342e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.9986e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.6685e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.4359e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 4.0707e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 33.82263445854187
Epoch 8/9
	 Logging train Loss: 4.27493e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.5815e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.2078e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.8497e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.6108e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 33.413148164749146
Epoch 9/9
	 Logging train Loss: 3.67273e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.39111e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.1248e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.8595e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.37606e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 33.63947582244873
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'dual_quat'_'False'.pth
It took  516.0579392910004  seconds.
----- ITERATION 2/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 72.60446333885193 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pNone_gTrue took 18.360923051834106 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 18.206149339675903 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pNone_gTrue took 18.337211847305298 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pNone_gTrue took 18.374836206436157 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0606685393 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0001282888 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 0.0001127271 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 9.76327e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 0.0001242762 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 33.91203808784485
Epoch 1/9
	 Logging train Loss: 5.32691e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.84725e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.54161e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.25658e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.77848e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 33.62362217903137
Epoch 2/9
	 Logging train Loss: 1.5973e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.06908e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 9.9248e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 9.2273e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.05878e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 33.48039746284485
Epoch 3/9
	 Logging train Loss: 7.1607e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.7109e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 5.1799e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.6869e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 5.6759e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 33.809038400650024
Epoch 4/9
	 Logging train Loss: 2.82565e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
wandb: Waiting for W&B process to finish... (success).
wandb: ERROR Error while calling W&B API: An internal error occurred. Please contact support. (<Response [500]>)
wandb: ERROR Error while calling W&B API: An internal error occurred. Please contact support. (<Response [500]>)
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue â–‡â–‚â–â–â–â–„â–„â–â–â–ˆ
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue â–ˆâ–ƒâ–‚â–â–â–ƒâ–ƒâ–â–â–…
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue â–…â–‚â–â–â–â–„â–„â–â–â–ˆ
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue â–…â–‚â–â–â–â–„â–„â–â–â–ˆ
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 0.00014
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue 6e-05
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue 0.00022
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue 0.00023
wandb:                                 Train loss 4e-05
wandb: 
wandb: ðŸš€ View run jolly-darkness-1160 at: https://wandb.ai/nreints/ThesisFinal2/runs/j2ap460e
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_232535-j2ap460e/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_233500-0deio6i7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lilac-river-1173
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/0deio6i7
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue â–â–â–â–â–ˆâ–â–ƒâ–â–â–
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue â–â–â–â–â–ˆâ–â–ƒâ–â–â–
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue â–â–â–â–â–ˆâ–â–ƒâ–â–â–
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue â–â–â–â–â–ˆâ–â–ƒâ–â–â–
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue 0.0
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue 0.0
wandb:                                 Train loss 4e-05
wandb: 
wandb: ðŸš€ View run lilac-river-1173 at: https://wandb.ai/nreints/ThesisFinal2/runs/0deio6i7
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_233500-0deio6i7/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_234315-cg1kyor7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vivid-sun-1181
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/cg1kyor7
	 Logging test loss: 3.6553e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.1113e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.6294e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.5806e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 33.80788254737854
Epoch 5/9
	 Logging train Loss: 3.38904e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 9.19096e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 5.38449e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.19696e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 9.04286e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 33.837958335876465
Epoch 6/9
	 Logging train Loss: 6.15464e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 9.8927e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 6.52515e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.42976e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 9.66567e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 33.74693965911865
Epoch 7/9
	 Logging train Loss: 5.22858e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 9.059e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 7.373e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.807e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 8.826e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 33.40341567993164
Epoch 8/9
	 Logging train Loss: 4.91166e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.1934e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.0549e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.9433e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.8908e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 33.85514760017395
Epoch 9/9
	 Logging train Loss: 4.45189e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0002339165 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 0.0001419946 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.86441e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 0.000223777 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 34.068318605422974
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'dual_quat'_'False'.pth
It took  564.5618124008179  seconds.
----- ITERATION 3/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 71.90789151191711 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pNone_gTrue took 18.365484952926636 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 18.114845991134644 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pNone_gTrue took 18.24771475791931 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pNone_gTrue took 18.28284978866577 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0286177993 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.24999e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.75424e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.42414e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.18889e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 33.9493305683136
Epoch 1/9
	 Logging train Loss: 1.43933e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.4258e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 5.4043e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.0213e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 7.1556e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 33.79702043533325
Epoch 2/9
	 Logging train Loss: 6.0305e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.304e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.7029e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.2674e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.2317e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 33.13496398925781
Epoch 3/9
	 Logging train Loss: 3.8256e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.83361e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.66826e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 9.4909e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.65586e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 33.730262756347656
Epoch 4/9
	 Logging train Loss: 7.19537e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0010818563 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 0.0006640162 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0004032581 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 0.0010159269 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 33.41854286193848
Epoch 5/9
	 Logging train Loss: 3.26495e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.5129e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.1172e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.506e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.4712e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 33.76869082450867
Epoch 6/9
	 Logging train Loss: 5.73271e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.000232167 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 0.0001570425 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 9.55123e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 0.0002278912 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 34.116225242614746
Epoch 7/9
	 Logging train Loss: 6.82464e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.46098e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.44878e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.43843e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.45991e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 33.33137774467468
Epoch 8/9
	 Logging train Loss: 3.53505e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.6285e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 4.6886e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.0867e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 5.5303e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 33.754215717315674
Epoch 9/9
	 Logging train Loss: 4.3297e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.178e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.836e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.597e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 4.141e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 33.7069034576416
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'dual_quat'_'False'.pth
It took  494.94383907318115  seconds.
----- ITERATION 4/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 71.3795096874237 seconds.
-- Finished Train Dataloader --
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue â–„â–‚â–â–â–ˆâ–â–ƒâ–â–â–
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue â–…â–‚â–â–â–ˆâ–â–‚â–â–â–
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue â–„â–‚â–â–â–ˆâ–â–ƒâ–â–â–
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue â–„â–‚â–â–â–ˆâ–‚â–ƒâ–â–â–
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue 0.0
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue 0.0
wandb:                                 Train loss 5e-05
wandb: 
wandb: ðŸš€ View run vivid-sun-1181 at: https://wandb.ai/nreints/ThesisFinal2/runs/cg1kyor7
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_234315-cg1kyor7/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_235131-09r3u9o6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run splendid-plant-1189
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/09r3u9o6
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pNone_gTrue took 18.23271942138672 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 18.003708124160767 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pNone_gTrue took 18.233729124069214 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pNone_gTrue took 18.165019035339355 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0395390093 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.91951e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.56795e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.21926e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.88904e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 33.43493056297302
Epoch 1/9
	 Logging train Loss: 1.25196e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.8897e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 5.2426e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.6133e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 5.8187e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 33.180670976638794
Epoch 2/9
	 Logging train Loss: 9.4784e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.319e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.9794e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.6371e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.2836e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 33.861987590789795
Epoch 3/9
	 Logging train Loss: 4.84543e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.3664e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.1321e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.95e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.342e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 33.923303842544556
Epoch 4/9
	 Logging train Loss: 4.46801e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.13356e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 5.37495e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.69582e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 7.03184e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 33.81496214866638
Epoch 5/9
	 Logging train Loss: 5.69187e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.6141e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 4.1504e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.7736e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 5.3809e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 33.20262002944946
Epoch 6/9
	 Logging train Loss: 4.63046e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.9946e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.2598e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.6128e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.93592e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 34.004358768463135
Epoch 7/9
	 Logging train Loss: 4.2008e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.674e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 4.06e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.482e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 4.591e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 34.590357303619385
Epoch 8/9
	 Logging train Loss: 4.45246e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 9.636e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 8.459e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.247e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 9.515e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 34.9185745716095
Epoch 9/9
	 Logging train Loss: 4.60106e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.5732e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 9.743e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.104e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.5357e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 35.161866664886475
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'dual_quat'_'False'.pth
It took  496.09022402763367  seconds.
----- ITERATION 5/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 72.63776850700378 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pNone_gTrue took 18.21968698501587 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 18.15868830680847 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pNone_gTrue took 18.247090816497803 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pNone_gTrue took 18.236324787139893 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0290980525 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.53364e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.76867e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.06002e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.46744e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 34.027713775634766
Epoch 1/9
	 Logging train Loss: 1.79301e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.4295e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.11e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.9431e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 4.253e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 33.632402658462524
Epoch 2/9
	 Logging train Loss: 3.43721e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.7504e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.2821e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.634e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.69e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 33.58271837234497
Epoch 3/9
	 Logging train Loss: 4.57466e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.50031e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.6051e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.69985e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.41923e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 33.208977699279785
Epoch 4/9
	 Logging train Loss: 6.75996e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.33e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 6.877e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.53e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 8.188e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 33.76675748825073
Epoch 5/9
	 Logging train Loss: 4.23984e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 9.72e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 7.767e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue â–‚â–â–â–ƒâ–â–â–â–ˆâ–â–
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue â–‚â–â–â–ƒâ–â–â–â–ˆâ–â–
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue â–‚â–â–â–ƒâ–â–â–â–ˆâ–â–
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue â–‚â–â–â–ƒâ–â–â–â–ˆâ–â–
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue 0.0
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue 0.0
wandb:                                 Train loss 3e-05
wandb: 
wandb: ðŸš€ View run splendid-plant-1189 at: https://wandb.ai/nreints/ThesisFinal2/runs/09r3u9o6
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_235131-09r3u9o6/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_235944-xbjjs0yy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run tough-glade-1199
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/xbjjs0yy
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue â–ƒâ–â–â–â–â–â–ˆâ–â–â–
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue â–ƒâ–â–â–â–â–â–ˆâ–â–â–
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue â–ƒâ–â–â–â–â–â–ˆâ–â–â–
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue â–ƒâ–â–â–â–‚â–â–ˆâ–â–â–
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue 0.0
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue 0.0
wandb:                                 Train loss 5e-05
wandb: 
wandb: ðŸš€ View run tough-glade-1199 at: https://wandb.ai/nreints/ThesisFinal2/runs/xbjjs0yy
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_235944-xbjjs0yy/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230710_000754-yie1anzf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fragrant-capybara-1209
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/yie1anzf
	 Logging test loss: 5.862e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 9.585e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 33.72615051269531
Epoch 6/9
	 Logging train Loss: 5.56167e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 9.292e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 7.377e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.469e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 9.08e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 33.91495680809021
Epoch 7/9
	 Logging train Loss: 4.7785e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0001365523 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 9.59128e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.59335e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 0.000131151 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 33.59397602081299
Epoch 8/9
	 Logging train Loss: 5.26896e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.0966e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.0666e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.0393e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.0936e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 33.40174698829651
Epoch 9/9
	 Logging train Loss: 2.84405e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.655e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 6.306e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.99e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 6.614e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 33.29348683357239
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'dual_quat'_'False'.pth
It took  492.9898793697357  seconds.
----- ITERATION 6/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 71.16798663139343 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pNone_gTrue took 18.19739580154419 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 17.94696044921875 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pNone_gTrue took 18.195623874664307 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pNone_gTrue took 18.22593379020691 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0545926206 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.24187e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.5892e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.06425e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.03278e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 33.66365933418274
Epoch 1/9
	 Logging train Loss: 7.3845e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.2248e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.271e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.5211e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.9046e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 33.82215404510498
Epoch 2/9
	 Logging train Loss: 2.2454e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.0596e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.6725e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.3574e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.956e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 33.79143810272217
Epoch 3/9
	 Logging train Loss: 2.79363e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.9745e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.5756e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.2366e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.8756e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 33.48501372337341
Epoch 4/9
	 Logging train Loss: 5.40026e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.2078e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.9796e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.0477e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 4.7752e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 32.74988508224487
Epoch 5/9
	 Logging train Loss: 6.12378e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.343e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 5.453e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.748e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 6.082e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 33.21989107131958
Epoch 6/9
	 Logging train Loss: 4.20371e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.46488e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 5.12176e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.98836e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 6.19487e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 33.134947061538696
Epoch 7/9
	 Logging train Loss: 5.74001e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.185e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 6.052e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.129e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 6.765e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 33.287896394729614
Epoch 8/9
	 Logging train Loss: 3.5249e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.593e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 4.922e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.385e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 5.364e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 33.585455894470215
Epoch 9/9
	 Logging train Loss: 4.67646e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.9538e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.7345e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.5582e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.8966e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 33.36543297767639
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'dual_quat'_'False'.pth
It took  490.03302669525146  seconds.
----- ITERATION 7/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 71.39123511314392 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pNone_gTrue took 18.173115253448486 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 17.949303150177002 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pNone_gTrue took 18.16571807861328 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pNone_gTrue took 18.169531106948853 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0573716275 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue â–‚â–â–â–ƒâ–â–„â–â–â–ˆâ–‚
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue â–‚â–â–â–ƒâ–â–„â–â–â–ˆâ–ƒ
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue â–‚â–â–â–ƒâ–â–ƒâ–â–â–ˆâ–‚
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue â–‚â–â–â–ƒâ–â–ƒâ–â–â–ˆâ–‚
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 2e-05
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue 2e-05
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue 2e-05
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue 2e-05
wandb:                                 Train loss 3e-05
wandb: 
wandb: ðŸš€ View run fragrant-capybara-1209 at: https://wandb.ai/nreints/ThesisFinal2/runs/yie1anzf
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230710_000754-yie1anzf/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230710_001602-m86bvy1s
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run deep-plasma-1217
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/m86bvy1s
	 Logging test loss: 2.72431e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.74552e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.9338e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.49769e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 33.160948514938354
Epoch 1/9
	 Logging train Loss: 8.3492e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.4737e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.7325e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.1758e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 5.028e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 32.6253821849823
Epoch 2/9
	 Logging train Loss: 9.6881e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.366e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 4.2557e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.4119e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 5.6898e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 33.16606020927429
Epoch 3/9
	 Logging train Loss: 2.06522e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.25831e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.76907e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.49668e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.80738e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 33.09889888763428
Epoch 4/9
	 Logging train Loss: 5.1809e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.6064e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.7021e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 9.045e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.4009e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 33.018945932388306
Epoch 5/9
	 Logging train Loss: 4.68874e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.26712e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 4.07829e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.2874e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 5.87086e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 33.319968461990356
Epoch 6/9
	 Logging train Loss: 5.9793e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.604e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 6.147e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.918e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 7.915e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 33.2761766910553
Epoch 7/9
	 Logging train Loss: 4.52473e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.981e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 7.507e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.23e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 8.644e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 32.512213706970215
Epoch 8/9
	 Logging train Loss: 5.5644e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0001816648 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 0.0001071933 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.77846e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 0.0001637543 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 33.79531192779541
Epoch 9/9
	 Logging train Loss: 2.69151e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.88245e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.79197e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.71918e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.86771e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 33.6485333442688
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'dual_quat'_'False'.pth
It took  488.1058785915375  seconds.
----- ITERATION 8/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 71.15275835990906 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pNone_gTrue took 18.12859869003296 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 17.85970401763916 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pNone_gTrue took 18.054656267166138 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pNone_gTrue took 18.055086135864258 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0329955816 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.93688e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.32486e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.85939e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.83381e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 32.276461124420166
Epoch 1/9
	 Logging train Loss: 1.10087e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.369e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 4.354e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.5631e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 5.2026e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 33.07039499282837
Epoch 2/9
	 Logging train Loss: 2.6058e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.1279e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.6832e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.3349e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.0688e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 32.845402240753174
Epoch 3/9
	 Logging train Loss: 5.01919e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.5221e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.1749e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 9.08e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.4722e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 33.02172017097473
Epoch 4/9
	 Logging train Loss: 5.21343e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.1492e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 9.024e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.14e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.116e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 32.71867227554321
Epoch 5/9
	 Logging train Loss: 5.75999e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.1915e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 9.304e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.275e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.1632e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 32.659897804260254
Epoch 6/9
	 Logging train Loss: 4.80822e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.535e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 7.398e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.514e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 8.376e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 33.318779706954956
Epoch 7/9
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue â–‚â–â–â–â–â–â–â–â–â–ˆ
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue â–‚â–â–â–â–â–â–â–â–â–ˆ
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue â–‚â–â–â–â–â–â–â–â–â–ˆ
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue â–‚â–â–â–â–â–â–â–â–â–ˆ
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 0.00022
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue 0.00021
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue 0.00024
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue 0.00024
wandb:                                 Train loss 4e-05
wandb: 
wandb: ðŸš€ View run deep-plasma-1217 at: https://wandb.ai/nreints/ThesisFinal2/runs/m86bvy1s
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230710_001602-m86bvy1s/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230710_002409-4b6l9lb4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ruby-flower-1227
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/4b6l9lb4
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue â–…â–‚â–â–â–ˆâ–â–â–â–†â–
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue â–‡â–‚â–â–â–ˆâ–â–â–â–†â–
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue â–…â–‚â–â–â–ˆâ–â–â–â–…â–
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue â–…â–‚â–â–â–ˆâ–â–â–â–…â–
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue 0.0
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue 0.0
wandb:                                 Train loss 3e-05
wandb: 
wandb: ðŸš€ View run ruby-flower-1227 at: https://wandb.ai/nreints/ThesisFinal2/runs/4b6l9lb4
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230710_002409-4b6l9lb4/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230710_003214-u4odpejb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dutiful-river-1237
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/u4odpejb
	 Logging train Loss: 4.42248e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.3626e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.7263e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.5353e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 4.0435e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 33.193726778030396
Epoch 8/9
	 Logging train Loss: 4.79761e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.30396e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 9.3569e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.4227e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.22171e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 33.231987953186035
Epoch 9/9
	 Logging train Loss: 3.60832e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.000241617 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 0.0002236817 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0002089755 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 0.0002390228 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 32.9376962184906
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'dual_quat'_'False'.pth
It took  486.5266971588135  seconds.
----- ITERATION 9/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 71.19905686378479 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pNone_gTrue took 18.103200435638428 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 17.890281677246094 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pNone_gTrue took 18.11692714691162 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pNone_gTrue took 18.111773252487183 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0670271367 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.68855e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 4.40925e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.91955e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 5.71647e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 32.87578797340393
Epoch 1/9
	 Logging train Loss: 2.02949e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.06021e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 8.1751e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.3577e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.06173e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 33.19870638847351
Epoch 2/9
	 Logging train Loss: 4.3208e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.0951e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.4023e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.6117e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.0902e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 32.374781131744385
Epoch 3/9
	 Logging train Loss: 3.127e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.9254e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.4733e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 9.491e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.9252e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 33.05798268318176
Epoch 4/9
	 Logging train Loss: 4.65043e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0001043618 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 7.27382e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.70655e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 0.0001047883 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 33.06382942199707
Epoch 5/9
	 Logging train Loss: 6.70495e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.879e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 6.452e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.834e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 7.869e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 32.98585367202759
Epoch 6/9
	 Logging train Loss: 6.24649e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.121e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 5.22e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.184e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 6.127e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 32.74007272720337
Epoch 7/9
	 Logging train Loss: 5.36729e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.468e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.942e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.342e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 4.472e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 32.78705096244812
Epoch 8/9
	 Logging train Loss: 3.816e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.46113e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 4.7057e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.43349e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 6.51287e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 33.0485405921936
Epoch 9/9
	 Logging train Loss: 3.44293e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.122e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 5.738e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.087e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 8.186e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 33.2897686958313
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'dual_quat'_'False'.pth
It took  485.7702000141144  seconds.
----- ITERATION 10/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 71.22026014328003 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pNone_gTrue took 18.103211641311646 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 17.927579641342163 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pNone_gTrue took 18.150405406951904 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pNone_gTrue took 18.15896224975586 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0554684326 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.71129e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.71443e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.86276e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 4.51958e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 33.40205979347229
Epoch 1/9
	 Logging train Loss: 1.68067e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 9.1435e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 6.7878e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.7712e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue â–ˆâ–‚â–â–â–â–â–â–â–â–ƒ
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue â–ˆâ–‚â–â–â–â–â–â–â–â–„
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue â–ˆâ–‚â–â–â–â–â–â–â–â–ƒ
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue â–ˆâ–‚â–â–â–â–â–â–â–â–ƒ
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 1e-05
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue 1e-05
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue 2e-05
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue 2e-05
wandb:                                 Train loss 4e-05
wandb: 
wandb: ðŸš€ View run dutiful-river-1237 at: https://wandb.ai/nreints/ThesisFinal2/runs/u4odpejb
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230710_003214-u4odpejb/logs
	 Logging test loss: 8.7716e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 33.59797954559326
Epoch 2/9
	 Logging train Loss: 4.1021e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.1605e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.2462e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.4665e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.006e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 33.15627145767212
Epoch 3/9
	 Logging train Loss: 1.597e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.4655e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.0682e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.294e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.3967e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 33.06218218803406
Epoch 4/9
	 Logging train Loss: 3.77662e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.775e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 6.647e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.806e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 8.435e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 32.4569411277771
Epoch 5/9
	 Logging train Loss: 4.39058e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.778e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 5.171e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.758e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 6.572e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 33.0182147026062
Epoch 6/9
	 Logging train Loss: 5.14544e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.492e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 4.913e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.558e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 6.268e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 33.24277353286743
Epoch 7/9
	 Logging train Loss: 4.96115e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.0472e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.8909e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.7544e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.0138e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 33.10266447067261
Epoch 8/9
	 Logging train Loss: 5.71386e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.9544e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.2452e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.6573e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.8079e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 33.26074957847595
Epoch 9/9
	 Logging train Loss: 3.72989e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.65295e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.34749e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.09367e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.60082e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 32.87857747077942
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'dual_quat'_'False'.pth
It took  487.39803099632263  seconds.

JOB STATISTICS
==============
Job ID: 3039257
Array Job ID: 3039249_32
Cluster: snellius
User/Group: nreints/nreints
State: COMPLETED (exit code 0)
Nodes: 1
Cores per node: 18
CPU Utilized: 01:30:14
CPU Efficiency: 6.00% of 1-01:05:06 core-walltime
Job Wall-clock time: 01:23:37
Memory Utilized: 8.76 GB
Memory Efficiency: 0.00% of 0.00 MB
