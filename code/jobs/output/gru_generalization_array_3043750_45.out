wandb: Currently logged in as: nreints. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230710_170033-y1djpz60
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run breezy-planet-1248
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/y1djpz60
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                     Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb: Test loss tennis_pNone_gNone_tennisEffect â–ˆâ–„â–…â–‚â–ƒâ–â–‚â–â–â–
wandb:                                Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                     Epoch 9
wandb: Test loss tennis_pNone_gNone_tennisEffect 1e-05
wandb:                                Train loss 1e-05
wandb: 
wandb: ðŸš€ View run breezy-planet-1248 at: https://wandb.ai/nreints/ThesisFinal2/runs/y1djpz60
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230710_170033-y1djpz60/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230710_170510-v08pvi5w
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run light-rain-1259
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/v08pvi5w
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                     Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb: Test loss tennis_pNone_gNone_tennisEffect â–†â–…â–…â–ˆâ–„â–‚â–‚â–â–â–‚
wandb:                                Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                     Epoch 9
wandb: Test loss tennis_pNone_gNone_tennisEffect 1e-05
wandb:                                Train loss 1e-05
wandb: 
wandb: ðŸš€ View run light-rain-1259 at: https://wandb.ai/nreints/ThesisFinal2/runs/v08pvi5w
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230710_170510-v08pvi5w/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230710_170943-e628kuis
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run curious-feather-1270
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/e628kuis
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                     Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb: Test loss tennis_pNone_gNone_tennisEffect â–ˆâ–†â–„â–†â–‚â–â–„â–â–â–
wandb:                                Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                     Epoch 9
wandb: Test loss tennis_pNone_gNone_tennisEffect 1e-05
wandb:                                Train loss 1e-05
wandb: 
wandb: ðŸš€ View run curious-feather-1270 at: https://wandb.ai/nreints/ThesisFinal2/runs/e628kuis
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230710_170943-e628kuis/logs
Training on dataset: data_tennis_pNone_gNone_tennisEffect
Testing on 1 datasets: ['data_tennis_pNone_gNone_tennisEffect']
Focussing on identity: True
Using extra input: False
Using fr-fr as reference point.
----- ITERATION 1/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 52.61237549781799 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 13.147876739501953 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0022138834 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 7.55036e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 20.429954051971436
Epoch 1/9
	 Logging train Loss: 4.43226e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 3.63008e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.569952487945557
Epoch 2/9
	 Logging train Loss: 3.84382e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 4.55135e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.554527044296265
Epoch 3/9
	 Logging train Loss: 3.15336e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.17782e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.8048734664917
Epoch 4/9
	 Logging train Loss: 2.57566e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.90884e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.699939250946045
Epoch 5/9
	 Logging train Loss: 2.10087e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.29498e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.574155807495117
Epoch 6/9
	 Logging train Loss: 1.6458e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.83809e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.638976573944092
Epoch 7/9
	 Logging train Loss: 1.38018e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.24314e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.548490047454834
Epoch 8/9
	 Logging train Loss: 1.27501e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.03494e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.758782148361206
Epoch 9/9
	 Logging train Loss: 1.16562e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 9.4994e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.74164628982544
Saved model in  trained_models/gru/data_tennis_pNone_gNone_tennisEffect/'quat_1'_'False'.pth
It took  278.21578574180603  seconds.
----- ITERATION 2/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 49.26200318336487 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 12.610999584197998 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0018280408 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 4.39286e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.482785940170288
Epoch 1/9
	 Logging train Loss: 4.49471e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 3.68004e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.955810070037842
Epoch 2/9
	 Logging train Loss: 3.8238e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 3.98413e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 20.302658796310425
Epoch 3/9
	 Logging train Loss: 3.04207e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 6.14806e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 20.068763971328735
Epoch 4/9
	 Logging train Loss: 2.47405e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 3.27219e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.895878314971924
Epoch 5/9
	 Logging train Loss: 1.85729e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.63044e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.820958614349365
Epoch 6/9
	 Logging train Loss: 1.52782e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.66853e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.673287630081177
Epoch 7/9
	 Logging train Loss: 1.35593e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.17312e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.73172092437744
Epoch 8/9
	 Logging train Loss: 1.23547e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 9.6019e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.633946895599365
Epoch 9/9
	 Logging train Loss: 1.14738e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.3418e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.710418939590454
Saved model in  trained_models/gru/data_tennis_pNone_gNone_tennisEffect/'quat_1'_'False'.pth
It took  273.2067811489105  seconds.
----- ITERATION 3/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 48.39586329460144 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 12.138893127441406 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0018631225 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 6.66982e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.664498329162598
Epoch 1/9
	 Logging train Loss: 4.86434e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 5.20199e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.764846086502075
Epoch 2/9
	 Logging train Loss: 3.9916e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 3.07289e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.869543075561523
Epoch 3/9
	 Logging train Loss: 3.25146e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 4.96628e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.493274450302124
Epoch 4/9
	 Logging train Loss: 2.44218e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.89854e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.816141843795776
Epoch 5/9
	 Logging train Loss: 1.91395e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.17397e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.64018678665161
Epoch 6/9
	 Logging train Loss: 1.56032e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 3.39106e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.914382219314575
Epoch 7/9
	 Logging train Loss: 1.32051e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.32543e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.79233407974243
Epoch 8/9
	 Logging train Loss: 1.20558e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.02582e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.607270002365112
Epoch 9/9
	 Logging train Loss: 1.13079e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.29261e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.681025505065918
Saved model in  trained_models/gru/data_tennis_pNone_gNone_tennisEffect/'quat_1'_'False'.pth
It took  269.59880352020264  seconds.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230710_171413-xgyhadao
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run spring-snowflake-1284
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/xgyhadao
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                     Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb: Test loss tennis_pNone_gNone_tennisEffect â–‡â–…â–ˆâ–ƒâ–„â–‚â–â–â–â–
wandb:                                Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                     Epoch 9
wandb: Test loss tennis_pNone_gNone_tennisEffect 1e-05
wandb:                                Train loss 1e-05
wandb: 
wandb: ðŸš€ View run spring-snowflake-1284 at: https://wandb.ai/nreints/ThesisFinal2/runs/xgyhadao
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230710_171413-xgyhadao/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230710_171909-365j4xc4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run different-snowball-1294
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/365j4xc4
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                     Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb: Test loss tennis_pNone_gNone_tennisEffect â–ˆâ–…â–…â–„â–ƒâ–‚â–‚â–â–â–
wandb:                                Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                     Epoch 9
wandb: Test loss tennis_pNone_gNone_tennisEffect 1e-05
wandb:                                Train loss 1e-05
wandb: 
wandb: ðŸš€ View run different-snowball-1294 at: https://wandb.ai/nreints/ThesisFinal2/runs/365j4xc4
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230710_171909-365j4xc4/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230710_172341-4rrpps67
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run grateful-sound-1306
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/4rrpps67
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                     Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb: Test loss tennis_pNone_gNone_tennisEffect â–ˆâ–„â–ƒâ–ƒâ–ƒâ–‚â–‚â–â–â–
wandb:                                Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                     Epoch 9
wandb: Test loss tennis_pNone_gNone_tennisEffect 1e-05
wandb:                                Train loss 1e-05
wandb: 
wandb: ðŸš€ View run grateful-sound-1306 at: https://wandb.ai/nreints/ThesisFinal2/runs/4rrpps67
wandb: Synced 7 W&B file(s), 0 media file(s), 1 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230710_172341-4rrpps67/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230710_172808-ovmmoyph
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sleek-feather-1318
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/ovmmoyph
----- ITERATION 4/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 48.41222953796387 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 12.057633638381958 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0018111741 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 4.50126e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.76837706565857
Epoch 1/9
	 Logging train Loss: 5.15413e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 3.424e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.903067588806152
Epoch 2/9
	 Logging train Loss: 4.31327e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 5.19244e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.853870153427124
Epoch 3/9
	 Logging train Loss: 3.45648e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.4132e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.357547998428345
Epoch 4/9
	 Logging train Loss: 2.6421e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.91741e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.56234312057495
Epoch 5/9
	 Logging train Loss: 2.1126e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.2983e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.517693758010864
Epoch 6/9
	 Logging train Loss: 1.61469e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.06387e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.54482936859131
Epoch 7/9
	 Logging train Loss: 1.39995e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.02849e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.675076246261597
Epoch 8/9
	 Logging train Loss: 1.20718e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.09337e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.845112562179565
Epoch 9/9
	 Logging train Loss: 1.14475e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 9.796e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.876481533050537
Saved model in  trained_models/gru/data_tennis_pNone_gNone_tennisEffect/'quat_1'_'False'.pth
It took  296.41526055336  seconds.
----- ITERATION 5/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 48.28355026245117 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 12.04799199104309 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0022156623 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 5.04464e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.636364221572876
Epoch 1/9
	 Logging train Loss: 4.58107e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 3.35084e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 20.010690927505493
Epoch 2/9
	 Logging train Loss: 3.95292e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 3.17477e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.7123920917511
Epoch 3/9
	 Logging train Loss: 3.40259e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.58851e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.920401334762573
Epoch 4/9
	 Logging train Loss: 2.70799e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.19369e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.791304349899292
Epoch 5/9
	 Logging train Loss: 2.15955e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.40696e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.592966556549072
Epoch 6/9
	 Logging train Loss: 1.74402e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.65359e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 20.140998125076294
Epoch 7/9
	 Logging train Loss: 1.32756e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.14059e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 20.02272915840149
Epoch 8/9
	 Logging train Loss: 1.27211e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.00173e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 20.29830837249756
Epoch 9/9
	 Logging train Loss: 1.17792e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 9.2504e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.664222240447998
Saved model in  trained_models/gru/data_tennis_pNone_gNone_tennisEffect/'quat_1'_'False'.pth
It took  272.1576132774353  seconds.
----- ITERATION 6/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 48.2549045085907 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 12.11096739768982 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0041583427 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 6.9429e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.59665012359619
Epoch 1/9
	 Logging train Loss: 4.20604e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 3.44678e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.617494821548462
Epoch 2/9
	 Logging train Loss: 3.39676e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 3.06778e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.679906368255615
Epoch 3/9
	 Logging train Loss: 3.1419e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.50777e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.63746476173401
Epoch 4/9
	 Logging train Loss: 2.90332e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.65e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.67043161392212
Epoch 5/9
	 Logging train Loss: 2.46345e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.66342e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.86147689819336
Epoch 6/9
	 Logging train Loss: 2.078e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.52573e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.521960020065308
Epoch 7/9
	 Logging train Loss: 1.68738e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 9.8243e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.854780197143555
Epoch 8/9
	 Logging train Loss: 1.40842e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.19496e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.59174132347107
Epoch 9/9
	 Logging train Loss: 1.30962e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 9.4722e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.767292976379395
Saved model in  trained_models/gru/data_tennis_pNone_gNone_tennisEffect/'quat_1'_'False'.pth
It took  267.07706594467163  seconds.
----- ITERATION 7/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 48.28637909889221 seconds.
-- Finished Train Dataloader --
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                     Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb: Test loss tennis_pNone_gNone_tennisEffect â–ˆâ–‡â–„â–„â–ƒâ–‚â–â–‚â–‚â–
wandb:                                Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                     Epoch 9
wandb: Test loss tennis_pNone_gNone_tennisEffect 1e-05
wandb:                                Train loss 1e-05
wandb: 
wandb: ðŸš€ View run sleek-feather-1318 at: https://wandb.ai/nreints/ThesisFinal2/runs/ovmmoyph
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230710_172808-ovmmoyph/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230710_173239-9qhnaqy1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run crimson-moon-1329
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/9qhnaqy1
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                     Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb: Test loss tennis_pNone_gNone_tennisEffect â–„â–†â–…â–ˆâ–ƒâ–â–â–â–â–
wandb:                                Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                     Epoch 9
wandb: Test loss tennis_pNone_gNone_tennisEffect 1e-05
wandb:                                Train loss 1e-05
wandb: 
wandb: ðŸš€ View run crimson-moon-1329 at: https://wandb.ai/nreints/ThesisFinal2/runs/9qhnaqy1
wandb: Synced 7 W&B file(s), 0 media file(s), 1 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230710_173239-9qhnaqy1/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230710_173709-xj7vko6w
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wild-feather-1340
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/xj7vko6w
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                     Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb: Test loss tennis_pNone_gNone_tennisEffect â–†â–ˆâ–„â–ƒâ–‚â–‚â–ƒâ–â–‚â–
wandb:                                Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                     Epoch 9
wandb: Test loss tennis_pNone_gNone_tennisEffect 1e-05
wandb:                                Train loss 1e-05
wandb: 
wandb: ðŸš€ View run wild-feather-1340 at: https://wandb.ai/nreints/ThesisFinal2/runs/xj7vko6w
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230710_173709-xj7vko6w/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230710_174140-4h73e34v
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run absurd-dawn-1351
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/4h73e34v
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 12.096336841583252 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0022068024 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 4.79015e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.563020706176758
Epoch 1/9
	 Logging train Loss: 4.56679e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 4.38679e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.591228246688843
Epoch 2/9
	 Logging train Loss: 3.88698e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.75324e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.853543758392334
Epoch 3/9
	 Logging train Loss: 3.19201e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.43442e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.84665274620056
Epoch 4/9
	 Logging train Loss: 2.60543e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.23488e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.46745491027832
Epoch 5/9
	 Logging train Loss: 2.07469e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.37772e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.76371669769287
Epoch 6/9
	 Logging train Loss: 1.60413e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.05322e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.717406511306763
Epoch 7/9
	 Logging train Loss: 1.38205e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.25677e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.85813617706299
Epoch 8/9
	 Logging train Loss: 1.27301e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.38372e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 20.02477192878723
Epoch 9/9
	 Logging train Loss: 1.16338e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 8.7798e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.908680200576782
Saved model in  trained_models/gru/data_tennis_pNone_gNone_tennisEffect/'quat_1'_'False'.pth
It took  270.93687677383423  seconds.
----- ITERATION 8/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 48.48113536834717 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 12.124253273010254 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0024459495 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 4.05085e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.859397888183594
Epoch 1/9
	 Logging train Loss: 4.28005e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 5.36184e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.837931156158447
Epoch 2/9
	 Logging train Loss: 3.75171e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 4.3759e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.751662731170654
Epoch 3/9
	 Logging train Loss: 3.22751e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 7.81237e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.522777795791626
Epoch 4/9
	 Logging train Loss: 2.68476e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.80927e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.809799194335938
Epoch 5/9
	 Logging train Loss: 2.11311e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.09923e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.57540512084961
Epoch 6/9
	 Logging train Loss: 1.76559e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 9.8322e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.592533111572266
Epoch 7/9
	 Logging train Loss: 1.32542e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 8.664e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.78583574295044
Epoch 8/9
	 Logging train Loss: 1.28693e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.19008e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 20.010639190673828
Epoch 9/9
	 Logging train Loss: 1.17629e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.00086e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.816020965576172
Saved model in  trained_models/gru/data_tennis_pNone_gNone_tennisEffect/'quat_1'_'False'.pth
It took  269.57971835136414  seconds.
----- ITERATION 9/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 48.41796088218689 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 12.104985475540161 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0017139313 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 5.34012e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.815260887145996
Epoch 1/9
	 Logging train Loss: 5.39981e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 7.16219e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.80182147026062
Epoch 2/9
	 Logging train Loss: 4.36076e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 3.63609e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.657781839370728
Epoch 3/9
	 Logging train Loss: 3.40811e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.95057e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.922799825668335
Epoch 4/9
	 Logging train Loss: 2.70612e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.70865e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.74437141418457
Epoch 5/9
	 Logging train Loss: 2.14193e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.59909e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.66267228126526
Epoch 6/9
	 Logging train Loss: 1.57116e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 3.05433e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.733074188232422
Epoch 7/9
	 Logging train Loss: 1.40645e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 9.9765e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.91803789138794
Epoch 8/9
	 Logging train Loss: 1.18258e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.44901e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 20.073309898376465
Epoch 9/9
	 Logging train Loss: 1.13554e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 9.5273e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.823383569717407
Saved model in  trained_models/gru/data_tennis_pNone_gNone_tennisEffect/'quat_1'_'False'.pth
It took  271.40495562553406  seconds.
----- ITERATION 10/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 48.260284662246704 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 12.099705696105957 seconds.
-- Finished Test Dataloader(s) --
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                     Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb: Test loss tennis_pNone_gNone_tennisEffect â–ˆâ–†â–„â–ƒâ–‚â–‚â–ƒâ–â–â–
wandb:                                Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                     Epoch 9
wandb: Test loss tennis_pNone_gNone_tennisEffect 1e-05
wandb:                                Train loss 1e-05
wandb: 
wandb: ðŸš€ View run absurd-dawn-1351 at: https://wandb.ai/nreints/ThesisFinal2/runs/4h73e34v
wandb: Synced 7 W&B file(s), 0 media file(s), 1 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230710_174140-4h73e34v/logs
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0017649764 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 4.5957e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.79021406173706
Epoch 1/9
	 Logging train Loss: 5.34777e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 3.78637e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.955482244491577
Epoch 2/9
	 Logging train Loss: 4.17419e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.50139e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.50170588493347
Epoch 3/9
	 Logging train Loss: 3.38773e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.00471e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.73426580429077
Epoch 4/9
	 Logging train Loss: 2.51598e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.65141e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.889589071273804
Epoch 5/9
	 Logging train Loss: 1.84957e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.52455e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.541139841079712
Epoch 6/9
	 Logging train Loss: 1.53435e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.92097e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.870144844055176
Epoch 7/9
	 Logging train Loss: 1.33224e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.03609e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.56561017036438
Epoch 8/9
	 Logging train Loss: 1.24231e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.07732e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.85787320137024
Epoch 9/9
	 Logging train Loss: 1.12092e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 8.7134e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.636934757232666
Saved model in  trained_models/gru/data_tennis_pNone_gNone_tennisEffect/'quat_1'_'False'.pth
It took  269.1825602054596  seconds.

JOB STATISTICS
==============
Job ID: 3043756
Array Job ID: 3043750_45
Cluster: snellius
User/Group: nreints/nreints
State: RUNNING
Nodes: 1
Cores per node: 18
CPU Utilized: 00:46:46
CPU Efficiency: 5.66% of 13:46:12 core-walltime
Job Wall-clock time: 00:45:54
Memory Utilized: 6.36 GB
Memory Efficiency: 0.00% of 0.00 MB
WARNING: Efficiency statistics may be misleading for RUNNING jobs.
