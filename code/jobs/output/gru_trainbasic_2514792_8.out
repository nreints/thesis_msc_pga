wandb: Currently logged in as: nreints. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230329_133622-e5jj2c1l
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run misunderstood-shape-515
wandb: ⭐️ View project at https://wandb.ai/nreints/test
wandb: 🚀 View run at https://wandb.ai/nreints/test/runs/e5jj2c1l
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.031 MB of 0.031 MB uploaded (0.000 MB deduped)wandb: \ 0.031 MB of 0.031 MB uploaded (0.000 MB deduped)wandb: | 0.031 MB of 0.031 MB uploaded (0.000 MB deduped)wandb: / 0.031 MB of 0.031 MB uploaded (0.000 MB deduped)wandb: - 0.031 MB of 0.031 MB uploaded (0.000 MB deduped)wandb: \ 0.031 MB of 0.031 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:                                                    Epoch ▁▂▃▃▄▅▆▆▇█
wandb: Test loss t(5, 20)_r(0, 0)_tennis_pNone_gNone, MSELoss() █▃▂▁▁▁▁▁▁▁▁
wandb:                                               Train loss █▂▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                                    Epoch 9
wandb: Test loss t(5, 20)_r(0, 0)_tennis_pNone_gNone, MSELoss() 0.1927
wandb:                                               Train loss 0.08902
wandb: 
wandb: 🚀 View run misunderstood-shape-515 at: https://wandb.ai/nreints/test/runs/e5jj2c1l
wandb: Synced 6 W&B file(s), 0 media file(s), 2 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230329_133622-e5jj2c1l/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230329_134347-ddh81tg8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fine-surf-517
wandb: ⭐️ View project at https://wandb.ai/nreints/test
wandb: 🚀 View run at https://wandb.ai/nreints/test/runs/ddh81tg8
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                                    Epoch ▁▂▃▃▄▅▆▆▇█
wandb: Test loss t(5, 20)_r(0, 0)_tennis_pNone_gNone, MSELoss() █▃▂▁▁▁▁▁▁▁▁
wandb:                                               Train loss █▂▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                                    Epoch 9
wandb: Test loss t(5, 20)_r(0, 0)_tennis_pNone_gNone, MSELoss() 0.14243
wandb:                                               Train loss 0.09335
wandb: 
wandb: 🚀 View run fine-surf-517 at: https://wandb.ai/nreints/test/runs/ddh81tg8
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230329_134347-ddh81tg8/logs
Running for data type: pos
----- ITERATION 1/2 ------
Number of train simulations: 1600
Number of test simulations: 400
-- Finished Train Dataloader --
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(24, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=24, bias=True)
)
-- Started Training --
Epoch 0
	 Logging train Loss: 156.7713513852 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss: 51.88174057006836 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 39.81581139564514
Epoch 1
	 Logging train Loss: 29.1191510556 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss: 15.350826263427734 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 37.506195068359375
Epoch 2
	 Logging train Loss: 8.3914301099 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss: 5.148446083068848 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 37.50669765472412
Epoch 3
	 Logging train Loss: 2.6732757935 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss: 2.140113115310669 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 37.04177498817444
Epoch 4
	 Logging train Loss: 0.9908039006 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss: 1.070237636566162 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 37.29113292694092
Epoch 5
	 Logging train Loss: 0.4565178702 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss: 0.6511428356170654 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 37.612404346466064
Epoch 6
	 Logging train Loss: 0.2563397926 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss: 0.44037607312202454 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 37.57111096382141
Epoch 7
	 Logging train Loss: 0.1653866023 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss: 0.31821566820144653 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 37.64092230796814
Epoch 8
	 Logging train Loss: 0.1181261804 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss: 0.24563324451446533 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 37.33254909515381
Epoch 9
	 Logging train Loss: 0.0890207431 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss: 0.19315701723098755 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 37.670499324798584
	 Logging test loss: 0.19269561767578125 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
It took  445.7368788719177  seconds.
----- ITERATION 2/2 ------
Number of train simulations: 1600
Number of test simulations: 400
-- Finished Train Dataloader --
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(24, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=24, bias=True)
)
-- Started Training --
Epoch 0
	 Logging train Loss: 156.6497830441 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss: 51.42411804199219 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 38.26122713088989
Epoch 1
	 Logging train Loss: 29.1963320886 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss: 14.66329288482666 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 37.774099826812744
Epoch 2
	 Logging train Loss: 8.4446729754 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss: 5.01118803024292 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 37.40959405899048
Epoch 3
	 Logging train Loss: 2.8504027505 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss: 2.1157913208007812 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 37.70498299598694
Epoch 4
	 Logging train Loss: 1.1714796975 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss: 1.0584971904754639 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 37.79045581817627
Epoch 5
	 Logging train Loss: 0.5171733291 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss: 0.586200475692749 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 39.7124342918396
Epoch 6
	 Logging train Loss: 0.2813423065 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss: 0.379427045583725 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 39.36151361465454
Epoch 7
	 Logging train Loss: 0.1784037041 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss: 0.25559577345848083 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 39.650508880615234
Epoch 8
	 Logging train Loss: 0.1254430549 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss: 0.18547601997852325 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 40.479620695114136
Epoch 9
	 Logging train Loss: 0.0933536076 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss: 0.14250874519348145 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 40.73918151855469
	 Logging test loss: 0.14242935180664062 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
It took  452.68043279647827  seconds.

JOB STATISTICS
==============
Job ID: 2514800
Array Job ID: 2514792_8
Cluster: snellius
User/Group: nreints/nreints
State: COMPLETED (exit code 0)
Nodes: 1
Cores per node: 18
CPU Utilized: 02:56:03
CPU Efficiency: 64.06% of 04:34:48 core-walltime
Job Wall-clock time: 00:15:16
Memory Utilized: 27.84 GB
Memory Efficiency: 89.10% of 31.25 GB
