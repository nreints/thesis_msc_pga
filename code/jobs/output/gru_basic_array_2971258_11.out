wandb: Currently logged in as: nreints. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_164039-qzabaesh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run honest-durian-11
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal1/runs/qzabaesh
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone █▄▂▂▁▁▁▁▁▁
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone █▄▂▁▁▁▁▁▁▁
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone █▄▂▁▁▁▁▁▁▁
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone █▃▂▁▁▁▁▁▁▁
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone █▃▂▁▁▁▁▁▁▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone 1e-05
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone 2e-05
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone 1e-05
wandb:                                  Train loss 1e-05
wandb: 
wandb: 🚀 View run honest-durian-11 at: https://wandb.ai/nreints/ThesisFinal1/runs/qzabaesh
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_164039-qzabaesh/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_165041-fluscel1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run laced-flower-48
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal1/runs/fluscel1
Training on dataset: data_t(0,0)_r(5,20)_combi_pNone_gNone
Testing on 5 datasets: ['data_t(0,0)_r(5,20)_none_pNone_gNone', 'data_t(0,0)_r(5,20)_full_pNone_gNone', 'data_t(0,0)_r(5,20)_combi_pNone_gNone', 'data_t(0,0)_r(5,20)_semi_pNone_gNone', 'data_t(0,0)_r(5,20)_tennis_pNone_gNone']
Focussing on identity: False
Using extra input: False
Using fr-fr as reference point.
----- ITERATION 1/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 65.50782179832458 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(5,20)_none_pNone_gNone took 16.6998131275177 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_full_pNone_gNone took 16.615104913711548 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 16.574349880218506 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_semi_pNone_gNone took 16.692578554153442 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_tennis_pNone_gNone took 16.87217140197754 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0545749255 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.42363e-05 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 6.31375e-05 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0001830715 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0001598642 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0001629231 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 45.33034420013428
Epoch 1/9
	 Logging train Loss: 0.0001176186 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.43662e-05 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.41406e-05 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 7.81561e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.63937e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 5.58619e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 43.70661664009094
Epoch 2/9
	 Logging train Loss: 5.39526e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.5749e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 7.401e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.62744e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.10333e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.03053e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 43.45861029624939
Epoch 3/9
	 Logging train Loss: 2.641e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.3514e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.2056e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.24587e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.29906e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.22509e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 43.455708026885986
Epoch 4/9
	 Logging train Loss: 1.8267e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.2176e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.0884e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.75029e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.02412e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.94607e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 43.561891078948975
Epoch 5/9
	 Logging train Loss: 1.39529e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.154e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 6.984e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.35945e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.83319e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.74261e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 43.68308901786804
Epoch 6/9
	 Logging train Loss: 1.05052e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.686e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 4.626e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.06734e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.68448e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.59615e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 43.43682909011841
Epoch 7/9
	 Logging train Loss: 8.3576e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.413e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 4.437e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 9.3335e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.61066e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.53058e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 43.83731389045715
Epoch 8/9
	 Logging train Loss: 1.01319e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.686e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.704e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 7.987e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.41629e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.33971e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 43.41279888153076
Epoch 9/9
	 Logging train Loss: 1.36961e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.17e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.316e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 8.4654e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.51735e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.45962e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 44.11061930656433
Saved model in  trained_models/gru/data_t(0,0)_r(5,20)_combi_pNone_gNone/'dual_quat_1'_'False'.pth
It took  602.6863505840302  seconds.
----- ITERATION 2/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 60.80395698547363 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(5,20)_none_pNone_gNone took 15.414623975753784 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_full_pNone_gNone took 15.363709449768066 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 15.251114845275879 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_semi_pNone_gNone took 15.384031057357788 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_tennis_pNone_gNone took 15.393324136734009 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0243719704 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.3509e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.1989e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.64624e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.24171e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.36984e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 43.82695269584656
Epoch 1/9
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone █▄▃▂▂▁▁▁▂▂
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone █▂▁▁▁▁▁▁▂▂
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone █▂▂▁▁▁▁▁▂▂
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone █▃▂▂▂▂▁▁▂▄
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone █▃▃▂▂▂▁▁▂▄
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone 1e-05
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone 2e-05
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone 2e-05
wandb:                                  Train loss 2e-05
wandb: 
wandb: 🚀 View run laced-flower-48 at: https://wandb.ai/nreints/ThesisFinal1/runs/fluscel1
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_165041-fluscel1/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_170032-fp0np6jc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run mild-gorge-82
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal1/runs/fp0np6jc
	 Logging train Loss: 2.34655e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.282e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 6.942e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.87087e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.83198e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.92026e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 43.65681290626526
Epoch 2/9
	 Logging train Loss: 1.4959e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.808e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.533e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.27605e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.52736e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.61088e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 43.839519739151
Epoch 3/9
	 Logging train Loss: 1.07542e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.506e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.342e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 9.1576e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.38979e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.46387e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 44.20937728881836
Epoch 4/9
	 Logging train Loss: 8.9165e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.481e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.38e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 8.7207e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.51715e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.59745e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 43.81286311149597
Epoch 5/9
	 Logging train Loss: 1.13742e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.79e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.8e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 7.4512e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.34657e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.42413e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 43.7632794380188
Epoch 6/9
	 Logging train Loss: 1.31355e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.337e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.435e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 5.934e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.07758e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.14077e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 44.33561325073242
Epoch 7/9
	 Logging train Loss: 1.68129e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.448e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.591e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 5.9243e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.06199e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.11557e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 43.935176610946655
Epoch 8/9
	 Logging train Loss: 1.60571e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.561e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 5.807e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 8.4585e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.49654e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.5823e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 43.820868730545044
Epoch 9/9
	 Logging train Loss: 1.51518e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.224e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 7.5e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.12524e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.0257e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.17321e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 43.911590337753296
Saved model in  trained_models/gru/data_t(0,0)_r(5,20)_combi_pNone_gNone/'dual_quat_1'_'False'.pth
It took  590.6619348526001  seconds.
----- ITERATION 3/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 60.340805530548096 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(5,20)_none_pNone_gNone took 15.258803844451904 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_full_pNone_gNone took 15.246939420700073 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 15.113148927688599 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_semi_pNone_gNone took 15.211342573165894 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_tennis_pNone_gNone took 15.223582744598389 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0069889929 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.0704e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.8188e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.25126e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.31872e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.31292e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 43.852455615997314
Epoch 1/9
	 Logging train Loss: 1.62761e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.507e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 6.907e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.18262e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.7743e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.76183e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 44.02096223831177
Epoch 2/9
	 Logging train Loss: 1.01017e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.364e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 4.148e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 9.0925e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.69015e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.68285e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 44.010329723358154
Epoch 3/9
	 Logging train Loss: 9.3852e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.045e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.974e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 7.3031e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.4175e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.39626e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 44.90116500854492
Epoch 4/9
	 Logging train Loss: 1.5175e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.1029e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 5.9244e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.26831e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.31778e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone ▃▂▁▁▅▁█▁▂▃
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone ▃▁▁▁▅▁█▁▂▃
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone ▃▁▁▁▅▁█▁▂▃
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone ▂▁▁▁▅▁█▁▂▃
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone ▂▁▁▁▅▁█▁▂▃
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone 2e-05
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone 4e-05
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone 4e-05
wandb:                                  Train loss 1e-05
wandb: 
wandb: 🚀 View run mild-gorge-82 at: https://wandb.ai/nreints/ThesisFinal1/runs/fp0np6jc
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_170032-fp0np6jc/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_171022-yd12nzaz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run curious-butterfly-116
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal1/runs/yd12nzaz
	 Logging test loss: 7.12674e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 44.391162157058716
Epoch 5/9
	 Logging train Loss: 1.91618e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.719e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 4.722e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 8.8582e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.75228e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.82766e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 43.823792934417725
Epoch 6/9
	 Logging train Loss: 1.85131e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.09057e-05 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.06927e-05 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.99566e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 9.55144e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0001080669 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 43.90086913108826
Epoch 7/9
	 Logging train Loss: 1.58386e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 9.496e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 8.553e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 8.403e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.66327e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.73079e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 43.907180070877075
Epoch 8/9
	 Logging train Loss: 1.5143e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.5603e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.4591e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.1639e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.35047e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.52665e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 43.56898903846741
Epoch 9/9
	 Logging train Loss: 1.28075e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.1975e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.0647e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.00417e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.03551e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.38404e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 44.078102588653564
Saved model in  trained_models/gru/data_t(0,0)_r(5,20)_combi_pNone_gNone/'dual_quat_1'_'False'.pth
It took  589.7370617389679  seconds.
----- ITERATION 4/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 60.38014769554138 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(5,20)_none_pNone_gNone took 15.245153903961182 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_full_pNone_gNone took 15.237303495407104 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 15.108420610427856 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_semi_pNone_gNone took 15.19834566116333 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_tennis_pNone_gNone took 15.362938642501831 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0963709205 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.06129e-05 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.09404e-05 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 9.96465e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.73654e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 9.04434e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 43.908961057662964
Epoch 1/9
	 Logging train Loss: 6.26313e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.7969e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 6.6544e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.33911e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.3105e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.41526e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 44.05407428741455
Epoch 2/9
	 Logging train Loss: 2.84586e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.258e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.1244e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.04432e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.16756e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.21724e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 43.89945316314697
Epoch 3/9
	 Logging train Loss: 2.03669e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.0871e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 9.681e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.56587e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.82053e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.85461e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 43.66190695762634
Epoch 4/9
	 Logging train Loss: 1.58238e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.643e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 5.539e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.21733e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.6315e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.66729e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 43.68825578689575
Epoch 5/9
	 Logging train Loss: 1.20189e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.841e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.794e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 9.1517e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.46169e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.48091e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 44.018409967422485
Epoch 6/9
	 Logging train Loss: 9.0963e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.069e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.11e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 7.4986e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.37607e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.40927e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 43.874152183532715
Epoch 7/9
	 Logging train Loss: 7.6085e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.001e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 6.144e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 7.5319e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.45556e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.50834e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 43.935559034347534
Epoch 8/9
	 Logging train Loss: 8.5713e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 9.891e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 9.264e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone █▃▂▂▁▁▁▁▁▁
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone █▂▁▁▁▁▁▁▁▁
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone █▂▁▁▁▁▁▁▁▁
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone █▃▂▁▁▁▁▁▂▁
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone █▃▂▁▁▁▁▁▂▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone 1e-05
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone 2e-05
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone 2e-05
wandb:                                  Train loss 1e-05
wandb: 
wandb: 🚀 View run curious-butterfly-116 at: https://wandb.ai/nreints/ThesisFinal1/runs/yd12nzaz
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_171022-yd12nzaz/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_172013-ljpc3a21
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run celestial-bush-149
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal1/runs/ljpc3a21
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone █▃▂▁▁▁▁▂▂▁
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone █▂▁▁▁▁▁▂▁▁
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone █▂▁▁▁▁▁▂▁▁
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone █▂▁▁▁▁▁▂▂▁
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone █▂▁▁▁▁▁▂▂▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone 1e-05
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone 1e-05
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone 1e-05
wandb:                                  Train loss 2e-05
wandb: 
wandb: 🚀 View run celestial-bush-149 at: https://wandb.ai/nreints/ThesisFinal1/runs/ljpc3a21
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_172013-ljpc3a21/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_173000-bxec341x
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run likely-vortex-185
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal1/runs/bxec341x
	 Logging test loss: 1.0717e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.05685e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.20822e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 44.00396704673767
Epoch 9/9
	 Logging train Loss: 1.19848e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.303e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 5.743e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 8.5641e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.70312e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.77369e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 43.68187069892883
Saved model in  trained_models/gru/data_t(0,0)_r(5,20)_combi_pNone_gNone/'dual_quat_1'_'False'.pth
It took  590.9258444309235  seconds.
----- ITERATION 5/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 60.52586364746094 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(5,20)_none_pNone_gNone took 15.197497606277466 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_full_pNone_gNone took 15.19842791557312 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 15.08584475517273 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_semi_pNone_gNone took 15.259767055511475 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_tennis_pNone_gNone took 15.385294437408447 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0379295982 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.21171e-05 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.21085e-05 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 8.53063e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0001140341 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0001207513 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 43.966150999069214
Epoch 1/9
	 Logging train Loss: 4.54987e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.3655e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.228e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.5196e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.69448e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.76283e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 43.71535897254944
Epoch 2/9
	 Logging train Loss: 1.76313e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.582e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 6.425e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.44243e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.60747e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.59183e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 43.46311902999878
Epoch 3/9
	 Logging train Loss: 1.1643e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.818e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.752e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.06112e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.51453e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.49354e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 43.735979318618774
Epoch 4/9
	 Logging train Loss: 9.0574e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.55e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.533e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 8.4948e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.46295e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.45034e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 43.67384195327759
Epoch 5/9
	 Logging train Loss: 1.02026e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.796e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.845e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 8.3545e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.57452e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.56246e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 44.116387128829956
Epoch 6/9
	 Logging train Loss: 1.49899e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.219e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.299e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 8.954e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.69361e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.71447e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 44.52952718734741
Epoch 7/9
	 Logging train Loss: 1.9314e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.0674e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 9.83e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.64575e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.15441e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.29913e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 43.73848748207092
Epoch 8/9
	 Logging train Loss: 1.93504e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.992e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 7.127e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.37602e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.63648e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.73995e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 43.96946930885315
Epoch 9/9
	 Logging train Loss: 1.78111e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.744e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.037e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 5.903e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.13053e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.13143e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 43.67973589897156
Saved model in  trained_models/gru/data_t(0,0)_r(5,20)_combi_pNone_gNone/'dual_quat_1'_'False'.pth
It took  587.7957425117493  seconds.
----- ITERATION 6/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 60.376858711242676 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(5,20)_none_pNone_gNone took 15.257674932479858 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_full_pNone_gNone took 15.197662353515625 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 15.119871139526367 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_semi_pNone_gNone took 15.168094158172607 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_tennis_pNone_gNone took 15.29251503944397 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat_1
-- Started Training --
Epoch 0/9
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone █▃▂▁▁▁▂▂▄█
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone █▃▁▁▁▁▂▁▃▅
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone █▃▁▁▁▁▂▁▃▅
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone ▄▂▂▁▁▁▂▂▄█
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone ▄▂▂▁▁▁▂▂▄█
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone 3e-05
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone 1e-05
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone 1e-05
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone 5e-05
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone 6e-05
wandb:                                  Train loss 2e-05
wandb: 
wandb: 🚀 View run likely-vortex-185 at: https://wandb.ai/nreints/ThesisFinal1/runs/bxec341x
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_173000-bxec341x/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_173950-5iirtsz6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ancient-flower-219
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal1/runs/5iirtsz6
	 Logging train Loss: 0.013780239 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.9019e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 8.4563e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.76122e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.0826e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.11661e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 43.84112310409546
Epoch 1/9
	 Logging train Loss: 1.9579e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.3575e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.1424e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.26651e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.89779e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.90318e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 43.87541580200195
Epoch 2/9
	 Logging train Loss: 1.09959e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 9.003e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 7.749e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 8.1157e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.60901e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.6041e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 43.40150284767151
Epoch 3/9
	 Logging train Loss: 8.2678e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.946e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.922e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 6.4564e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.40185e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.38756e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 43.79327702522278
Epoch 4/9
	 Logging train Loss: 7.6873e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.018e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 5.103e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 6.9955e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.53157e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.53511e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 43.99899744987488
Epoch 5/9
	 Logging train Loss: 1.16491e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.18e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.329e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 5.5945e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.24368e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.22817e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 45.49055361747742
Epoch 6/9
	 Logging train Loss: 2.10493e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.2239e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.1528e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 8.4559e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.75323e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.78743e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 43.94034242630005
Epoch 7/9
	 Logging train Loss: 2.09457e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.831e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 4.245e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 8.6258e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.84656e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.95579e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 43.7659273147583
Epoch 8/9
	 Logging train Loss: 1.97877e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.5001e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.458e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.45956e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.88579e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.07313e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 43.60812997817993
Epoch 9/9
	 Logging train Loss: 1.60948e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.1174e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 5.1028e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.8243e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.42343e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 5.86397e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 43.66751790046692
Saved model in  trained_models/gru/data_t(0,0)_r(5,20)_combi_pNone_gNone/'dual_quat_1'_'False'.pth
It took  589.835086107254  seconds.
----- ITERATION 7/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 60.34266757965088 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(5,20)_none_pNone_gNone took 15.252530097961426 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_full_pNone_gNone took 15.161542415618896 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 15.06786298751831 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_semi_pNone_gNone took 15.245694398880005 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_tennis_pNone_gNone took 15.216613054275513 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0293798633 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.5326e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 5.2329e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 5.63232e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.54756e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 7.67518e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 43.5303521156311
Epoch 1/9
	 Logging train Loss: 2.93946e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.0395e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 8.817e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.71488e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.20209e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.17725e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 43.81831359863281
Epoch 2/9
	 Logging train Loss: 1.25597e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.242e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.832e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.03044e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.59596e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.55381e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 43.47148060798645
Epoch 3/9
	 Logging train Loss: 9.6088e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.0803e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 9.361e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.80391e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone █▃▂▃▁▁▃▁▁▂
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone █▂▁▂▁▁▄▁▁▂
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone █▂▁▂▁▁▃▁▁▂
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone █▂▂▃▂▂▃▁▁▂
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone █▂▁▃▂▂▃▁▁▂
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone 1e-05
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone 2e-05
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone 2e-05
wandb:                                  Train loss 2e-05
wandb: 
wandb: 🚀 View run ancient-flower-219 at: https://wandb.ai/nreints/ThesisFinal1/runs/5iirtsz6
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_173950-5iirtsz6/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_174938-0wvn0azb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run comic-wave-254
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal1/runs/0wvn0azb
	 Logging test loss: 3.13644e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.23999e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 44.731117486953735
Epoch 4/9
	 Logging train Loss: 1.17109e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.501e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.326e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 8.5918e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.57871e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.55658e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 43.7471125125885
Epoch 5/9
	 Logging train Loss: 1.36654e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.212e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 4.146e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 8.7866e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.60581e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.59119e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 43.8707013130188
Epoch 6/9
	 Logging train Loss: 1.75419e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.149e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.0437e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.70207e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.92908e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.03747e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 43.976162910461426
Epoch 7/9
	 Logging train Loss: 1.83505e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.109e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.093e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 7.9521e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.45599e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.4442e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 43.963716983795166
Epoch 8/9
	 Logging train Loss: 1.68651e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.107e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 4.273e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 6.0778e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.11444e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.08378e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 43.919206857681274
Epoch 9/9
	 Logging train Loss: 1.53269e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.3849e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.2887e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.08773e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.92195e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.95646e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 44.0326623916626
Saved model in  trained_models/gru/data_t(0,0)_r(5,20)_combi_pNone_gNone/'dual_quat_1'_'False'.pth
It took  587.9268033504486  seconds.
----- ITERATION 8/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 60.53322887420654 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(5,20)_none_pNone_gNone took 15.200203657150269 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_full_pNone_gNone took 15.168890476226807 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 15.09486174583435 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_semi_pNone_gNone took 15.190961122512817 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_tennis_pNone_gNone took 15.208192348480225 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.155028224 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.15054e-05 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 5.75232e-05 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0003186068 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0003888349 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0004483046 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 44.35588026046753
Epoch 1/9
	 Logging train Loss: 0.0001672823 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.10167e-05 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.00861e-05 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0001040502 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.55952e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 6.86221e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 43.866838455200195
Epoch 2/9
	 Logging train Loss: 8.25269e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.4609e-05 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.43951e-05 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 5.79692e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.84644e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.99157e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 44.2311053276062
Epoch 3/9
	 Logging train Loss: 4.39955e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.3567e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 4.2013e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.95837e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.36451e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.43188e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 43.5480215549469
Epoch 4/9
	 Logging train Loss: 2.46794e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.4535e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.3149e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.90896e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.85891e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.88484e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 43.588412046432495
Epoch 5/9
	 Logging train Loss: 1.80801e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.049e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 6.803e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.519e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.66163e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.67249e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 44.23331546783447
Epoch 6/9
	 Logging train Loss: 1.4469e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.005e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.879e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.21802e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.53992e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.54186e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 43.80236792564392
Epoch 7/9
	 Logging train Loss: 1.13932e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.566e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone █▃▂▂▁▁▁▁▁▁
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone █▅▃▁▁▁▁▁▁▁
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone █▅▃▁▁▁▁▁▁▁
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone █▂▁▁▁▁▁▁▁▁
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone █▂▁▁▁▁▁▁▁▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone 1e-05
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone 1e-05
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone 1e-05
wandb:                                  Train loss 1e-05
wandb: 
wandb: 🚀 View run comic-wave-254 at: https://wandb.ai/nreints/ThesisFinal1/runs/0wvn0azb
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_174938-0wvn0azb/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_175928-hqubm1t4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pious-darkness-287
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal1/runs/hqubm1t4
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone █▃▂▂▂▁▁▁▁▁
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone █▂▁▁▁▁▁▁▁▁
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone █▂▁▁▁▁▁▁▁▁
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone █▃▃▂▂▁▁▂▁▁
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone █▃▃▂▂▁▁▂▁▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone 1e-05
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone 1e-05
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone 1e-05
wandb:                                  Train loss 1e-05
wandb: 
wandb: 🚀 View run pious-darkness-287 at: https://wandb.ai/nreints/ThesisFinal1/runs/hqubm1t4
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_175928-hqubm1t4/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_180923-sss3y4qe
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run earthy-sky-317
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal1/runs/sss3y4qe
	 Logging test loss: 2.488e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 9.5723e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.41885e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.41655e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 43.564297914505005
Epoch 8/9
	 Logging train Loss: 9.0688e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.661e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.675e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 9.2826e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.60363e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.65433e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 43.81191349029541
Epoch 9/9
	 Logging train Loss: 8.9838e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.087e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 6.334e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 6.6562e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.22979e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.21471e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 44.436984062194824
Saved model in  trained_models/gru/data_t(0,0)_r(5,20)_combi_pNone_gNone/'dual_quat_1'_'False'.pth
It took  589.5206427574158  seconds.
----- ITERATION 9/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 60.30853486061096 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(5,20)_none_pNone_gNone took 15.253485679626465 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_full_pNone_gNone took 15.181132555007935 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 15.117256164550781 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_semi_pNone_gNone took 15.213837385177612 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_tennis_pNone_gNone took 15.160973310470581 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0874583796 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.211e-05 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.14905e-05 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 9.17839e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.01222e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 5.16319e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 43.58230686187744
Epoch 1/9
	 Logging train Loss: 4.76391e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.9076e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.7705e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.05207e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.48273e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.5513e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 43.88629508018494
Epoch 2/9
	 Logging train Loss: 2.4071e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.684e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 7.427e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.1452e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.05392e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.09176e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 43.57596302032471
Epoch 3/9
	 Logging train Loss: 1.85775e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.735e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 4.582e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.65978e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.84321e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.87361e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 43.97313904762268
Epoch 4/9
	 Logging train Loss: 1.44589e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.498e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.427e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.2505e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.6843e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.69661e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 43.379464864730835
Epoch 5/9
	 Logging train Loss: 1.09144e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.239e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.244e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 9.0115e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.47656e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.46606e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 44.34933423995972
Epoch 6/9
	 Logging train Loss: 8.4414e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.351e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.418e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 7.7689e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.46419e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.46983e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 43.89852476119995
Epoch 7/9
	 Logging train Loss: 7.6256e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 9.623e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 8.769e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 8.9001e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.68248e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.70981e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 45.08169937133789
Epoch 8/9
	 Logging train Loss: 1.29079e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.552e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.782e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 6.1992e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.25026e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.249e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 44.87549376487732
Epoch 9/9
	 Logging train Loss: 1.46068e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.38e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 4.684e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 6.1806e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.2097e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.22034e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 44.05491542816162
Saved model in  trained_models/gru/data_t(0,0)_r(5,20)_combi_pNone_gNone/'dual_quat_1'_'False'.pth
It took  595.5561029911041  seconds.
----- ITERATION 10/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 60.428611755371094 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(5,20)_none_pNone_gNone took 15.178630828857422 seconds.
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone █▃▂▁▁▁▁▁▁▄
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone █▂▁▁▁▁▁▁▁▂
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone █▂▁▁▁▁▁▁▁▂
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone █▃▂▁▁▂▂▁▂█
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone ▇▂▂▁▁▂▂▁▂█
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone 2e-05
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone 3e-05
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone 4e-05
wandb:                                  Train loss 2e-05
wandb: 
wandb: 🚀 View run earthy-sky-317 at: https://wandb.ai/nreints/ThesisFinal1/runs/sss3y4qe
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_180923-sss3y4qe/logs
The dataloader for data/data_t(0,0)_r(5,20)_full_pNone_gNone took 15.193601608276367 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 15.12035584449768 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_semi_pNone_gNone took 15.17057752609253 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_tennis_pNone_gNone took 15.222654819488525 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0212167762 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.4753e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 7.2768e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.41461e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.34644e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.52219e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 44.84277105331421
Epoch 1/9
	 Logging train Loss: 2.17674e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.7942e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.6469e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.74428e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.89116e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.91152e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 44.54327607154846
Epoch 2/9
	 Logging train Loss: 1.31409e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 9.112e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 7.839e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.23164e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.6941e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.71049e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 43.699045181274414
Epoch 3/9
	 Logging train Loss: 9.4978e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.288e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 5.123e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 9.7394e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.58078e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.57939e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 43.40337777137756
Epoch 4/9
	 Logging train Loss: 7.9143e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.395e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.314e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 8.4182e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.44411e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.433e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 43.13092303276062
Epoch 5/9
	 Logging train Loss: 8.4004e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.221e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.195e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 9.2561e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.60506e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.65027e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 43.640451431274414
Epoch 6/9
	 Logging train Loss: 1.47537e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.135e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 4.133e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.00102e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.76692e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.84086e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 43.73291611671448
Epoch 7/9
	 Logging train Loss: 1.71984e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.713e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.803e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 8.7009e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.52235e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.5719e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 43.54384136199951
Epoch 8/9
	 Logging train Loss: 1.65916e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.101e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 5.226e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 9.3927e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.64005e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.73315e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 43.648589849472046
Epoch 9/9
	 Logging train Loss: 1.6032e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.0963e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 9.96e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.02113e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.40933e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.84704e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 43.55231690406799
Saved model in  trained_models/gru/data_t(0,0)_r(5,20)_combi_pNone_gNone/'dual_quat_1'_'False'.pth
It took  588.5760877132416  seconds.

JOB STATISTICS
==============
Job ID: 2971269
Array Job ID: 2971258_11
Cluster: snellius
User/Group: nreints/nreints
State: COMPLETED (exit code 0)
Nodes: 1
Cores per node: 18
CPU Utilized: 06:55:10
CPU Efficiency: 23.36% of 1-05:37:30 core-walltime
Job Wall-clock time: 01:38:45
Memory Utilized: 8.86 GB
Memory Efficiency: 0.00% of 0.00 MB
