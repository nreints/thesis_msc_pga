wandb: Currently logged in as: nreints. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230616_155413-x5zu3t7p
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run upbeat-music-1
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal/runs/x5zu3t7p
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone █▃▂▂▂▂▂▁▁▁
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone █▂▂▁▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone █▃▃▃▂▂▂▂▁▁
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone █▃▂▂▂▂▂▁▁▁
wandb:                                   Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 0.0
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 0.0
wandb:                                   Train loss 0.0
wandb: 
wandb: 🚀 View run upbeat-music-1 at: https://wandb.ai/nreints/ThesisFinal/runs/x5zu3t7p
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230616_155413-x5zu3t7p/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230616_160023-sqgi13p7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run zany-firebrand-7
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal/runs/sqgi13p7
Training on dataset: data_t(5,20)_r(5,20)_combi_pNone_gNone
Testing on 4 datasets: ['data_t(5,20)_r(5,20)_full_pNone_gNone', 'data_t(5,20)_r(5,20)_semi_pNone_gNone', 'data_t(5,20)_r(5,20)_tennis_pNone_gNone', 'data_t(5,20)_r(5,20)_combi_pNone_gNone']
Focussing on identity: False
Using extra input: None
Using fr-fr as reference point.
----- ITERATION 1/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  800
Number of test simulations:  200
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 21.58333969116211 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 5.565692186355591 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 5.578559875488281 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 5.499018669128418 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 5.349659204483032 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(24, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=24, bias=True)
)
Datatype: pos_diff_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0004905901 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.49868e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.08545e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 5.87413e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.13934e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 31.76946759223938
Epoch 1/9
	 Logging train Loss: 2.06561e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.0179e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.61442e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.17209e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.36414e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 31.304736137390137
Epoch 2/9
	 Logging train Loss: 1.11184e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.3437e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.36176e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.58533e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.01481e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 30.99567747116089
Epoch 3/9
	 Logging train Loss: 8.7455e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.4664e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.16942e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.2745e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 8.2081e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 30.87790036201477
Epoch 4/9
	 Logging train Loss: 7.3264e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.8141e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.10319e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.17352e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 7.7907e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 31.29842185974121
Epoch 5/9
	 Logging train Loss: 6.3337e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.9022e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.00546e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.0407e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 7.183e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 30.892160415649414
Epoch 6/9
	 Logging train Loss: 5.5147e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.0154e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 8.9806e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 9.2055e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 6.3782e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 31.11235237121582
Epoch 7/9
	 Logging train Loss: 4.599e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.3405e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 6.6293e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 7.2148e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.8779e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 31.00687551498413
Epoch 8/9
	 Logging train Loss: 3.7083e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 9.073e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.924e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 5.5552e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.493e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 31.244280338287354
Epoch 9/9
	 Logging train Loss: 2.9631e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.32e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.6356e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.4196e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.6705e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 30.994266748428345
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gNone/'pos_diff_1'_'None'.pth
It took  370.77902460098267  seconds.
----- ITERATION 2/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  800
Number of test simulations:  200
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 18.76530623435974 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 5.062300682067871 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 5.060551166534424 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 5.085901975631714 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 4.724220275878906 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(24, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=24, bias=True)
)
Datatype: pos_diff_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0004543314 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.95855e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.71301e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.20286e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.01782e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 40.899993896484375
Epoch 1/9
	 Logging train Loss: 1.7808e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.3546e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.67737e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.67675e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.07891e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 33.98399996757507
Epoch 2/9
	 Logging train Loss: 1.05546e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.8747e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.41899e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.19756e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 8.2083e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 31.193430185317993
Epoch 3/9
	 Logging train Loss: 8.3892e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.7066e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone █▃▂▂▂▂▂▁▁▁
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone █▂▁▁▂▁▁▁▁▁
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone █▄▃▃▃▂▂▂▁▁
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone █▃▂▂▂▂▁▁▁▁
wandb:                                   Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 0.0
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 0.0
wandb:                                   Train loss 0.0
wandb: 
wandb: 🚀 View run zany-firebrand-7 at: https://wandb.ai/nreints/ThesisFinal/runs/sqgi13p7
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230616_160023-sqgi13p7/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230616_160639-9lwrmb5w
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run worldly-sponge-13
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal/runs/9lwrmb5w
	 Logging test loss: 1.2879e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.04411e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 7.2771e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 30.924915313720703
Epoch 4/9
	 Logging train Loss: 7.132e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.2438e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.20949e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 9.7609e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 7.0282e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 31.21364140510559
Epoch 5/9
	 Logging train Loss: 6.2243e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.565e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.0175e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 8.1887e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 5.9004e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 31.131773948669434
Epoch 6/9
	 Logging train Loss: 5.3481e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.4459e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 8.3361e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 6.7911e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.886e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 31.52144694328308
Epoch 7/9
	 Logging train Loss: 4.3768e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.0151e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 7.3652e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 6.4458e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.7545e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 31.033284187316895
Epoch 8/9
	 Logging train Loss: 3.4921e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.157e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.8904e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.2933e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.8722e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 31.241281032562256
Epoch 9/9
	 Logging train Loss: 2.8595e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.1163e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.427e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.1304e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.8862e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 31.184033155441284
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gNone/'pos_diff_1'_'None'.pth
It took  375.41486525535583  seconds.
----- ITERATION 3/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  800
Number of test simulations:  200
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 18.937280654907227 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 4.935680389404297 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 4.950852632522583 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 4.969735622406006 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 4.8169026374816895 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(24, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=24, bias=True)
)
Datatype: pos_diff_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0003420406 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.23007e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.72149e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.66128e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.57877e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 31.489133596420288
Epoch 1/9
	 Logging train Loss: 1.41201e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.8979e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.59818e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.76252e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.20385e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 31.054308652877808
Epoch 2/9
	 Logging train Loss: 9.0072e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.8295e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.59425e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.57626e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.15795e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 31.30966806411743
Epoch 3/9
	 Logging train Loss: 7.0924e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.3613e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.19254e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.17912e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 8.5475e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 30.95665955543518
Epoch 4/9
	 Logging train Loss: 5.8782e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.0718e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.18491e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.1558e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 9.0527e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 31.426751136779785
Epoch 5/9
	 Logging train Loss: 4.7867e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.5415e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 7.5178e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 7.4004e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 5.3625e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 30.98613452911377
Epoch 6/9
	 Logging train Loss: 3.6217e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.716e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.7681e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 5.1121e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.3885e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 31.4707510471344
Epoch 7/9
	 Logging train Loss: 2.8392e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.176e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.8973e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.3267e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.8515e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 30.958296060562134
Epoch 8/9
	 Logging train Loss: 2.4078e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.718e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.6018e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.0241e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.6863e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 31.3586745262146
Epoch 9/9
	 Logging train Loss: 2.2566e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.4457e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.335e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone █▄▄▃▃▂▁▁▁▁
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone █▂▃▂▃▂▁▁▁▂
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone █▅▅▃▃▂▁▁▁▁
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone █▄▄▃▃▂▁▁▁▁
wandb:                                   Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 0.0
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 0.0
wandb:                                   Train loss 0.0
wandb: 
wandb: 🚀 View run worldly-sponge-13 at: https://wandb.ai/nreints/ThesisFinal/runs/9lwrmb5w
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230616_160639-9lwrmb5w/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230616_161242-agq1igaq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run autumn-glitter-18
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal/runs/agq1igaq
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone █▄▃▃▂▂▁▁▁▁
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone █▂▂▂▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone █▄▄▃▃▂▂▁▁▁
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone █▄▃▂▂▂▁▁▁▁
wandb:                                   Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 0.0
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 0.0
wandb:                                   Train loss 0.0
wandb: 
wandb: 🚀 View run autumn-glitter-18 at: https://wandb.ai/nreints/ThesisFinal/runs/agq1igaq
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230616_161242-agq1igaq/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230616_161902-6liznmjy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dulcet-surf-22
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal/runs/6liznmjy
	 Logging test loss: 4.7649e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.4316e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 31.310367107391357
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gNone/'pos_diff_1'_'None'.pth
It took  363.54483461380005  seconds.
----- ITERATION 4/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  800
Number of test simulations:  200
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 18.82104253768921 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 4.88399076461792 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 4.874012231826782 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 4.879685878753662 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 4.681416034698486 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(24, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=24, bias=True)
)
Datatype: pos_diff_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0003825633 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.52402e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.48416e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.42963e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.83515e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 32.199676752090454
Epoch 1/9
	 Logging train Loss: 1.54847e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.1702e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.80845e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.01937e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.17841e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 31.080382585525513
Epoch 2/9
	 Logging train Loss: 9.4931e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.1821e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.5286e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.50253e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 9.1804e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 31.550604820251465
Epoch 3/9
	 Logging train Loss: 7.4517e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.9344e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.36662e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.27849e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 8.0959e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 31.304519653320312
Epoch 4/9
	 Logging train Loss: 6.3156e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.2907e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.10041e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.06445e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 6.3959e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 31.425928592681885
Epoch 5/9
	 Logging train Loss: 5.3785e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.291e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 9.3872e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 8.8492e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 5.457e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 35.01128697395325
Epoch 6/9
	 Logging train Loss: 4.2696e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 9.634e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 6.9702e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 6.8019e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.1486e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 41.22099161148071
Epoch 7/9
	 Logging train Loss: 3.2849e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.689e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 5.0856e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 5.317e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.0837e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 31.782390594482422
Epoch 8/9
	 Logging train Loss: 2.6919e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.131e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.3983e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.84e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.8317e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 31.421642780303955
Epoch 9/9
	 Logging train Loss: 2.4093e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.235e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.9173e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.347e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.4615e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 31.608657360076904
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gNone/'pos_diff_1'_'None'.pth
It took  379.73555731773376  seconds.
----- ITERATION 5/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  800
Number of test simulations:  200
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 18.84592914581299 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 4.897655725479126 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 4.877488851547241 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 4.859283685684204 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 4.735799074172974 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(24, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=24, bias=True)
)
Datatype: pos_diff_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0004199026 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.78534e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.64582e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.96932e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.03094e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 31.841371536254883
Epoch 1/9
	 Logging train Loss: 1.72263e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.8254e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.7925e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.10554e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.1501e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 31.52462387084961
Epoch 2/9
	 Logging train Loss: 1.03894e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.0892e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.50626e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.49456e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 8.4669e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 31.203522443771362
Epoch 3/9
	 Logging train Loss: 8.068e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.4934e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone █▃▃▂▂▂▂▁▁▁
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone █▂▂▁▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone █▄▃▃▃▂▂▁▁▁
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone █▄▃▂▂▂▁▁▁▁
wandb:                                   Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 0.0
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 0.0
wandb:                                   Train loss 0.0
wandb: 
wandb: 🚀 View run dulcet-surf-22 at: https://wandb.ai/nreints/ThesisFinal/runs/6liznmjy
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230616_161902-6liznmjy/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230616_162508-xhtv2rsf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run denim-wildflower-28
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal/runs/xhtv2rsf
	 Logging test loss: 1.30382e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.19978e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 6.9678e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 31.61533784866333
Epoch 4/9
	 Logging train Loss: 6.6909e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.6254e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.17801e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.06093e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 6.3031e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 31.053372621536255
Epoch 5/9
	 Logging train Loss: 5.5435e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.4602e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 9.4468e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 8.9807e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 5.345e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 31.824755668640137
Epoch 6/9
	 Logging train Loss: 4.3583e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.6839e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 7.3164e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 7.3217e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.4969e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 31.34589958190918
Epoch 7/9
	 Logging train Loss: 3.2848e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.873e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.9151e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 5.1934e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.9351e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 31.603588819503784
Epoch 8/9
	 Logging train Loss: 2.7092e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.432e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.9893e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.4222e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.3398e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 31.527563095092773
Epoch 9/9
	 Logging train Loss: 2.424e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.442e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.8998e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.3466e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.3551e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 31.64644980430603
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gNone/'pos_diff_1'_'None'.pth
It took  366.1888527870178  seconds.
----- ITERATION 6/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  800
Number of test simulations:  200
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 18.824801206588745 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 4.897728443145752 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 4.899939298629761 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 4.899489402770996 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 4.749927520751953 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(24, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=24, bias=True)
)
Datatype: pos_diff_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0003769054 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.49769e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.63165e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.04461e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.69169e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 31.581507205963135
Epoch 1/9
	 Logging train Loss: 1.65266e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.1381e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.85194e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.66865e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.02968e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 31.53907608985901
Epoch 2/9
	 Logging train Loss: 1.00216e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.183e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.59681e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.22576e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 8.1464e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 31.170066356658936
Epoch 3/9
	 Logging train Loss: 7.9603e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.4368e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.36179e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 9.9545e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 6.549e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 31.515280961990356
Epoch 4/9
	 Logging train Loss: 6.7378e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.3322e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.4088e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.11407e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 7.8151e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 31.172951459884644
Epoch 5/9
	 Logging train Loss: 5.7686e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 9.544e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 9.553e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 7.0985e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.5554e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 31.67534828186035
Epoch 6/9
	 Logging train Loss: 4.5763e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.4084e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 7.6455e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 6.155e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.0978e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 31.299813270568848
Epoch 7/9
	 Logging train Loss: 3.5369e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.0932e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 5.5542e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.803e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.1073e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 31.376625776290894
Epoch 8/9
	 Logging train Loss: 2.7735e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.245e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.2754e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.7431e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.293e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 31.19873809814453
Epoch 9/9
	 Logging train Loss: 2.4742e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.552e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.8466e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone █▃▃▂▃▂▂▁▁▁
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone █▂▂▁▂▁▁▁▁▁
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone █▄▄▃▃▂▂▁▁▁
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone █▄▃▂▂▂▂▁▁▁
wandb:                                   Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 0.0
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 0.0
wandb:                                   Train loss 0.0
wandb: 
wandb: 🚀 View run denim-wildflower-28 at: https://wandb.ai/nreints/ThesisFinal/runs/xhtv2rsf
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230616_162508-xhtv2rsf/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230616_163112-3hrcy3lu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wise-cloud-33
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal/runs/3hrcy3lu
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone █▃▃▃▂▂▂▁▁▁
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone █▂▁▂▁▁▂▁▁▁
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone █▄▄▃▃▂▂▁▁▁
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone █▄▃▃▂▂▂▁▁▁
wandb:                                   Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 0.0
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 0.0
wandb:                                   Train loss 0.0
wandb: 
wandb: 🚀 View run wise-cloud-33 at: https://wandb.ai/nreints/ThesisFinal/runs/3hrcy3lu
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230616_163112-3hrcy3lu/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230616_163721-unseakzj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fiery-planet-36
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal/runs/unseakzj
	 Logging test loss: 3.3932e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.025e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 31.10245108604431
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gNone/'pos_diff_1'_'None'.pth
It took  363.5858654975891  seconds.
----- ITERATION 7/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  800
Number of test simulations:  200
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 19.18032169342041 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 4.896845579147339 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 4.895650863647461 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 4.897928237915039 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 4.829982757568359 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(24, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=24, bias=True)
)
Datatype: pos_diff_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0003721553 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.46133e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.97573e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.95965e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.37766e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 37.54087686538696
Epoch 1/9
	 Logging train Loss: 1.54834e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.1735e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.59708e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.79791e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 9.9021e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 31.174448490142822
Epoch 2/9
	 Logging train Loss: 9.7474e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.6437e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.31932e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.30556e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 7.3343e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 31.515064477920532
Epoch 3/9
	 Logging train Loss: 7.6643e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.8031e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.27179e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.21174e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 7.5274e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 31.33488965034485
Epoch 4/9
	 Logging train Loss: 6.3883e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.4901e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 9.8452e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 9.5909e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 5.5796e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 31.137853622436523
Epoch 5/9
	 Logging train Loss: 5.2204e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.6125e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 7.8994e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 7.933e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.7024e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 31.3511061668396
Epoch 6/9
	 Logging train Loss: 4.0524e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.2509e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 7.1235e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 7.3366e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.6886e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 31.386767387390137
Epoch 7/9
	 Logging train Loss: 3.1388e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.367e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.0463e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.622e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.5006e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 31.648688793182373
Epoch 8/9
	 Logging train Loss: 2.6083e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.597e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.6094e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.1869e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.2651e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 31.615119695663452
Epoch 9/9
	 Logging train Loss: 2.4113e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.2578e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.1046e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.7275e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.8054e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 30.829169988632202
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gNone/'pos_diff_1'_'None'.pth
It took  369.47999906539917  seconds.
----- ITERATION 8/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  800
Number of test simulations:  200
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 18.79920220375061 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 4.887972354888916 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 4.913312196731567 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 4.900970935821533 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 4.8024821281433105 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(24, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=24, bias=True)
)
Datatype: pos_diff_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0003694581 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.50087e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.2515e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.91835e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.53477e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 31.402008295059204
Epoch 1/9
	 Logging train Loss: 1.55101e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.0043e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.70528e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.69568e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.02771e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 31.316519737243652
Epoch 2/9
	 Logging train Loss: 9.7052e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.6444e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.46488e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.21447e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 7.7679e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 31.135547399520874
Epoch 3/9
	 Logging train Loss: 7.7231e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.9173e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone █▃▃▂▂▂▁▁▁▁
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone █▂▂▂▂▁▁▁▁▁
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone █▄▄▃▃▂▂▁▁▁
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone █▄▃▂▂▂▁▁▁▁
wandb:                                   Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 0.0
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 0.0
wandb:                                   Train loss 0.0
wandb: 
wandb: 🚀 View run fiery-planet-36 at: https://wandb.ai/nreints/ThesisFinal/runs/unseakzj
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230616_163721-unseakzj/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230616_164325-chtnduks
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lilac-snowball-40
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal/runs/chtnduks
	 Logging test loss: 1.29411e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.12412e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 7.1031e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 31.04024052619934
Epoch 4/9
	 Logging train Loss: 6.5864e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.974e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.19663e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.01647e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 6.7212e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 31.18643808364868
Epoch 5/9
	 Logging train Loss: 5.6456e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.2544e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 9.4254e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 7.7441e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 5.0601e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 31.72653865814209
Epoch 6/9
	 Logging train Loss: 4.6002e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.806e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 6.6793e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 5.7966e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.557e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 31.391055822372437
Epoch 7/9
	 Logging train Loss: 3.6119e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.0318e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 5.5633e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.9943e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.2044e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 30.829148054122925
Epoch 8/9
	 Logging train Loss: 2.8756e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.628e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.0066e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.8717e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.2602e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 31.475915670394897
Epoch 9/9
	 Logging train Loss: 2.4848e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.587e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.8326e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.8183e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.2923e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 31.164390802383423
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gNone/'pos_diff_1'_'None'.pth
It took  363.58969616889954  seconds.
----- ITERATION 9/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  800
Number of test simulations:  200
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 18.786195278167725 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 5.013328313827515 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 4.948165416717529 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 4.870664834976196 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 4.690458536148071 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(24, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=24, bias=True)
)
Datatype: pos_diff_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0003956231 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.57914e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.05015e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.23469e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.49623e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 31.217334270477295
Epoch 1/9
	 Logging train Loss: 1.60928e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.2895e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.53817e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.857e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 9.4841e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 31.420872449874878
Epoch 2/9
	 Logging train Loss: 9.9513e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.7567e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.39018e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.43516e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 8.0353e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 31.395118713378906
Epoch 3/9
	 Logging train Loss: 7.8429e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.6916e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.14897e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.15407e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 6.2468e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 31.396775245666504
Epoch 4/9
	 Logging train Loss: 6.586e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.0081e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.04722e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.05628e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 5.9744e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 31.079716205596924
Epoch 5/9
	 Logging train Loss: 5.5781e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.1745e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 7.9692e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 8.1584e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.2993e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 31.383183479309082
Epoch 6/9
	 Logging train Loss: 4.6169e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.9253e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 7.1965e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 7.6164e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.3975e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 42.12338089942932
Epoch 7/9
	 Logging train Loss: 3.7049e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.0357e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 5.0814e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 5.5948e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.0459e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 36.83582377433777
Epoch 8/9
	 Logging train Loss: 2.9615e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.699e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.159e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.6574e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.5242e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 31.307616710662842
Epoch 9/9
	 Logging train Loss: 2.5661e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.876e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.6522e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone █▃▃▂▂▂▂▁▁▁
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone █▂▂▁▂▁▂▁▁▁
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone █▄▄▃▃▂▂▁▁▁
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone █▄▃▂▂▂▂▁▁▁
wandb:                                   Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 0.0
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 0.0
wandb:                                   Train loss 0.0
wandb: 
wandb: 🚀 View run lilac-snowball-40 at: https://wandb.ai/nreints/ThesisFinal/runs/chtnduks
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230616_164325-chtnduks/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230616_164944-2mcxzt2v
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run copper-microwave-46
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal/runs/2mcxzt2v
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone █▃▂▂▂▂▂▂▁▁
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone █▂▁▁▁▁▁▂▁▁
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone █▄▃▃▃▂▂▂▁▁
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone █▃▃▂▂▂▂▂▁▁
wandb:                                   Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 0.0
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 0.0
wandb:                                   Train loss 0.0
wandb: 
wandb: 🚀 View run copper-microwave-46 at: https://wandb.ai/nreints/ThesisFinal/runs/2mcxzt2v
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230616_164944-2mcxzt2v/logs
	 Logging test loss: 4.2431e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.2237e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 31.136738061904907
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gNone/'pos_diff_1'_'None'.pth
It took  379.54918098449707  seconds.
----- ITERATION 10/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  800
Number of test simulations:  200
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 18.84827423095703 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 4.8348047733306885 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 4.830830335617065 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 4.861189365386963 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 4.718975305557251 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(24, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=24, bias=True)
)
Datatype: pos_diff_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0004202344 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.03429e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.41036e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 5.14603e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.53073e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 31.204110622406006
Epoch 1/9
	 Logging train Loss: 1.76128e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.7763e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.56621e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.10563e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.27868e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 31.419910669326782
Epoch 2/9
	 Logging train Loss: 1.03017e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.9813e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.31344e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.51873e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 9.3666e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 30.950037002563477
Epoch 3/9
	 Logging train Loss: 8.3377e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.5624e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.1367e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.32062e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 8.2658e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 31.175765991210938
Epoch 4/9
	 Logging train Loss: 6.9144e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.1179e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.01169e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.06211e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 6.7625e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 31.24931526184082
Epoch 5/9
	 Logging train Loss: 5.9955e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.2231e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 9.2618e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 9.4175e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 6.0605e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 31.47050404548645
Epoch 6/9
	 Logging train Loss: 5.168e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.022e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 7.5423e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 8.0302e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 5.049e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 31.091607093811035
Epoch 7/9
	 Logging train Loss: 4.2328e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.2414e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 8.1785e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 8.7963e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 6.4336e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 31.65871000289917
Epoch 8/9
	 Logging train Loss: 3.3521e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 9.226e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.472e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 5.1424e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.275e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 31.516454458236694
Epoch 9/9
	 Logging train Loss: 2.6827e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.21e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.5406e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.3109e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.6259e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
		--> Epoch time; 31.76559090614319
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gNone/'pos_diff_1'_'None'.pth
It took  363.52420115470886  seconds.

JOB STATISTICS
==============
Job ID: 2928287
Array Job ID: 2928286_25
Cluster: snellius
User/Group: nreints/nreints
State: RUNNING
Nodes: 1
Cores per node: 18
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 18:32:42 core-walltime
Job Wall-clock time: 01:01:49
Memory Utilized: 0.00 MB (estimated maximum)
Memory Efficiency: 0.00% of 0.00 MB (0.00 MB/node)
WARNING: Efficiency statistics may be misleading for RUNNING jobs.
