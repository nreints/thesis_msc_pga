wandb: Currently logged in as: nreints. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230329_135637-wr3ex5q4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run giddy-jazz-534
wandb: ⭐️ View project at https://wandb.ai/nreints/test
wandb: 🚀 View run at https://wandb.ai/nreints/test/runs/wr3ex5q4
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.031 MB of 0.031 MB uploaded (0.000 MB deduped)wandb: \ 0.031 MB of 0.031 MB uploaded (0.000 MB deduped)wandb: | 0.031 MB of 0.031 MB uploaded (0.000 MB deduped)wandb: / 0.031 MB of 0.031 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:                                                  Epoch ▁▂▃▃▄▅▆▆▇█
wandb: Test loss t(5, 20)_r(0, 0)_semi_pNone_gNone, MSELoss() █▂▂▁▁▁▁▁▁▁▁
wandb:                                             Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                                  Epoch 9
wandb: Test loss t(5, 20)_r(0, 0)_semi_pNone_gNone, MSELoss() 0.00284
wandb:                                             Train loss 0.00471
wandb: 
wandb: 🚀 View run giddy-jazz-534 at: https://wandb.ai/nreints/test/runs/wr3ex5q4
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230329_135637-wr3ex5q4/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230329_140450-24hv0hnc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stoic-terrain-551
wandb: ⭐️ View project at https://wandb.ai/nreints/test
wandb: 🚀 View run at https://wandb.ai/nreints/test/runs/24hv0hnc
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.031 MB of 0.031 MB uploaded (0.000 MB deduped)wandb: \ 0.031 MB of 0.031 MB uploaded (0.000 MB deduped)wandb: | 0.031 MB of 0.031 MB uploaded (0.000 MB deduped)wandb: / 0.031 MB of 0.031 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:                                                  Epoch ▁▂▃▃▄▅▆▆▇█
wandb: Test loss t(5, 20)_r(0, 0)_semi_pNone_gNone, MSELoss() █▃▂▁▁▁▁▁▁▁▁
wandb:                                             Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                                  Epoch 9
wandb: Test loss t(5, 20)_r(0, 0)_semi_pNone_gNone, MSELoss() 0.00293
wandb:                                             Train loss 0.00463
wandb: 
wandb: 🚀 View run stoic-terrain-551 at: https://wandb.ai/nreints/test/runs/24hv0hnc
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230329_140450-24hv0hnc/logs
Running for data type: quat
----- ITERATION 1/2 ------
Number of train simulations: 1600
Number of test simulations: 400
-- Finished Train Dataloader --
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
-- Started Training --
Epoch 0
	 Logging train Loss: 12.7149337137 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss: 0.68840491771698 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 43.700929403305054
Epoch 1
	 Logging train Loss: 0.304415755 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss: 0.14441736042499542 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 41.860865116119385
Epoch 2
	 Logging train Loss: 0.0850887222 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss: 0.055960655212402344 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 41.77924180030823
Epoch 3
	 Logging train Loss: 0.0374199061 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss: 0.028208989650011063 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 41.97149395942688
Epoch 4
	 Logging train Loss: 0.0200459171 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss: 0.015598829835653305 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 41.58018922805786
Epoch 5
	 Logging train Loss: 0.0127575318 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss: 0.009497991763055325 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 41.639766216278076
Epoch 6
	 Logging train Loss: 0.0092572962 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss: 0.007675735745579004 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 41.19427800178528
Epoch 7
	 Logging train Loss: 0.0079436926 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss: 0.0048392764292657375 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 44.00919556617737
Epoch 8
	 Logging train Loss: 0.0058501528 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss: 0.003594147739931941 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 43.69489622116089
Epoch 9
	 Logging train Loss: 0.0047057713 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss: 0.0028383044991642237 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 43.15409207344055
	 Logging test loss: 0.0028384733013808727 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
It took  494.76068115234375  seconds.
----- ITERATION 2/2 ------
Number of train simulations: 1600
Number of test simulations: 400
-- Finished Train Dataloader --
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
-- Started Training --
Epoch 0
	 Logging train Loss: 10.5384829512 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss: 0.5586994290351868 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 42.45758557319641
Epoch 1
	 Logging train Loss: 0.2652296568 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss: 0.12835702300071716 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 41.3597252368927
Epoch 2
	 Logging train Loss: 0.0811287711 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss: 0.05163802579045296 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 41.29343056678772
Epoch 3
	 Logging train Loss: 0.0363188134 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss: 0.02497952990233898 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 41.330387353897095
Epoch 4
	 Logging train Loss: 0.0191713112 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss: 0.013393629342317581 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 41.6299614906311
Epoch 5
	 Logging train Loss: 0.0119261353 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss: 0.007848551496863365 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 41.12170672416687
Epoch 6
	 Logging train Loss: 0.0087237568 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss: 0.005667300894856453 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 41.30670642852783
Epoch 7
	 Logging train Loss: 0.0077181728 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss: 0.0047265393659472466 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 41.642293214797974
Epoch 8
	 Logging train Loss: 0.0054135615 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss: 0.0033323639072477818 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 41.41450309753418
Epoch 9
	 Logging train Loss: 0.0046342524 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss: 0.002932622330263257 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 41.522286891937256
	 Logging test loss: 0.0029285093769431114 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
It took  478.7277457714081  seconds.

JOB STATISTICS
==============
Job ID: 2514858
Array Job ID: 2514848_10
Cluster: snellius
User/Group: nreints/nreints
State: RUNNING
Nodes: 1
Cores per node: 18
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 04:56:06 core-walltime
Job Wall-clock time: 00:16:27
Memory Utilized: 0.00 MB (estimated maximum)
Memory Efficiency: 0.00% of 31.25 GB (31.25 GB/node)
WARNING: Efficiency statistics may be misleading for RUNNING jobs.
