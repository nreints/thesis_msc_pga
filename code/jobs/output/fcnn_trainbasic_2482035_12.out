wandb: Currently logged in as: nreints. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home/nreints/.netrc
/gpfs/home2/nreints/MScThesis/code/fcnn.py:521: DeprecationWarning: Sampling from a set deprecated
since Python 3.9 and will be removed in a subsequent version.
  train_sims = set(random.sample(sims_train, int(0.8 * n_sims_train)))
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230321_162902-6a3nmhgv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run quiet-pyramid-248
wandb: ⭐️ View project at https://wandb.ai/nreints/test
wandb: 🚀 View run at https://wandb.ai/nreints/test/runs/6a3nmhgv
['data_t(5,', '20)_r(0,', '0)_full_pNone_gNone']
data/data_t(5, 20)_r(0, 0)_full_pNone_gNone
Testing on datasets: ['data_t(5, 20)_r(0, 0)_full_pNone_gNone', 'data_tennis_pNone_gNone_tennisEffect']
----- ITERATION 1/2 ------
Number of train simulations: 3200
Number of test simulations: 800
The dataloader took 81.72724795341492 seconds.
-- Finished Train Dataloader --
The dataloader took 20.160808086395264 seconds.
The dataloader took 21.084012746810913 seconds.
-- Finished Test Dataloader(s) --
Datatype: dual_quat
--- Started Training ---
Epoch 0
	 Logging train Loss: 3.0895121655 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.08979547023773193 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.23461894690990448 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 746.272705078125 (MSELoss(): tennis_pNone_gNone_tennisEffect)
	 Logging test loss 20.12206268310547 (L1Loss(): tennis_pNone_gNone_tennisEffect)
     --> Epoch_time; 83.20422077178955
Epoch 1
	 Logging train Loss: 0.0390569375 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.00899956002831459 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.0738028958439827 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 751.77587890625 (MSELoss(): tennis_pNone_gNone_tennisEffect)
	 Logging test loss 20.25316619873047 (L1Loss(): tennis_pNone_gNone_tennisEffect)
     --> Epoch_time; 89.0808036327362
Epoch 2
	 Logging train Loss: 0.0217749527 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.00590097950771451 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.05964282155036926 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 754.0704345703125 (MSELoss(): tennis_pNone_gNone_tennisEffect)
	 Logging test loss 20.324647903442383 (L1Loss(): tennis_pNone_gNone_tennisEffect)
     --> Epoch_time; 88.95981812477112
Epoch 3
	 Logging train Loss: 0.0174198874 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.005313552916049957 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.056259218603372574 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 757.04833984375 (MSELoss(): tennis_pNone_gNone_tennisEffect)
	 Logging test loss 20.37465476989746 (L1Loss(): tennis_pNone_gNone_tennisEffect)
     --> Epoch_time; 85.99964022636414
Epoch 4
	 Logging train Loss: 0.0148099775 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.005556485615670681 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.055880218744277954 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 759.269287109375 (MSELoss(): tennis_pNone_gNone_tennisEffect)
	 Logging test loss 20.383787155151367 (L1Loss(): tennis_pNone_gNone_tennisEffect)
     --> Epoch_time; 89.96656727790833
Epoch 5
	 Logging train Loss: 0.0133020164 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.004574720282107592 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.0508681945502758 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 756.791259765625 (MSELoss(): tennis_pNone_gNone_tennisEffect)
	 Logging test loss 20.345937728881836 (L1Loss(): tennis_pNone_gNone_tennisEffect)
     --> Epoch_time; 90.79159569740295
Epoch 6
	 Logging train Loss: 0.0128760992 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.0036986658815294504 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.04590915888547897 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 753.8845825195312 (MSELoss(): tennis_pNone_gNone_tennisEffect)
	 Logging test loss 20.300809860229492 (L1Loss(): tennis_pNone_gNone_tennisEffect)
     --> Epoch_time; 90.40008354187012
Epoch 7
	 Logging train Loss: 0.0116856357 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.008142219856381416 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.06802816689014435 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 753.1035766601562 (MSELoss(): tennis_pNone_gNone_tennisEffect)
	 Logging test loss 20.282957077026367 (L1Loss(): tennis_pNone_gNone_tennisEffect)
     --> Epoch_time; 88.12358283996582
Epoch 8
	 Logging train Loss: 0.0109291401 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.009015661664307117 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.06890847533941269 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 752.9968872070312 (MSELoss(): tennis_pNone_gNone_tennisEffect)
	 Logging test loss 20.276639938354492 (L1Loss(): tennis_pNone_gNone_tennisEffect)
     --> Epoch_time; 88.88220119476318
Epoch 9
	 Logging train Loss: 0.010680913 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.006285460665822029 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.056813519448041916 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 752.9703369140625 (MSELoss(): tennis_pNone_gNone_tennisEffect)
	 Logging test loss 20.26943588256836 (L1Loss(): tennis_pNone_gNone_tennisEffect)
     --> Epoch_time; 84.67249965667725
Epoch 10
	 Logging train Loss: 0.0101796331 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.015926998108625412 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.08739148080348969 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 751.9893188476562 (MSELoss(): tennis_pNone_gNone_tennisEffect)
	 Logging test loss 20.245309829711914 (L1Loss(): tennis_pNone_gNone_tennisEffect)
     --> Epoch_time; 89.47191619873047
Epoch 11
	 Logging train Loss: 0.009583692 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.002038812730461359 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.03453587368130684 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 751.1163940429688 (MSELoss(): tennis_pNone_gNone_tennisEffect)
	 Logging test loss 20.226266860961914 (L1Loss(): tennis_pNone_gNone_tennisEffect)
     --> Epoch_time; 84.46528434753418
Epoch 12
	 Logging train Loss: 0.0095100833 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.001483571482822299 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.029397590085864067 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 750.1990966796875 (MSELoss(): tennis_pNone_gNone_tennisEffect)
	 Logging test loss 20.19920539855957 (L1Loss(): tennis_pNone_gNone_tennisEffect)
     --> Epoch_time; 90.52641201019287
Epoch 13
	 Logging train Loss: 0.0090739905 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.016142848879098892 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.08627825975418091 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 749.8327026367188 (MSELoss(): tennis_pNone_gNone_tennisEffect)
	 Logging test loss 20.183712005615234 (L1Loss(): tennis_pNone_gNone_tennisEffect)
     --> Epoch_time; 90.69204831123352
Epoch 14
	 Logging train Loss: 0.0087280348 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.002586260437965393 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.03812677785754204 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 750.1209716796875 (MSELoss(): tennis_pNone_gNone_tennisEffect)
	 Logging test loss 20.178136825561523 (L1Loss(): tennis_pNone_gNone_tennisEffect)
     --> Epoch_time; 89.47495937347412
Epoch 15
	 Logging train Loss: 0.0083610672 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.008087551221251488 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.0625428557395935 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 750.9437866210938 (MSELoss(): tennis_pNone_gNone_tennisEffect)
	 Logging test loss 20.183576583862305 (L1Loss(): tennis_pNone_gNone_tennisEffect)
     --> Epoch_time; 88.21136665344238
Epoch 16
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:  Test loss t(5, 20)_r(0, 0)_full L1Loss() █▃▂▂▂▂▂▂▂▂▃▁▁▃▁▂▁▁▂▂▂
wandb: Test loss t(5, 20)_r(0, 0)_full MSELoss() █▂▁▁▁▁▁▂▂▁▂▁▁▂▁▂▁▁▁▁▁
wandb:           Test loss tennisEffect L1Loss() ▁▅▆██▇▆▅▅▅▄▄▃▃▂▃▃▂▂▂▂
wandb:          Test loss tennisEffect MSELoss() ▁▄▅▇█▇▅▅▅▅▄▄▃▃▃▄▄▄▄▄▄
wandb:     Train loss data_t(5, 20)_r(0, 0)_full █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:  Test loss t(5, 20)_r(0, 0)_full L1Loss() 0.05348
wandb: Test loss t(5, 20)_r(0, 0)_full MSELoss() 0.00512
wandb:           Test loss tennisEffect L1Loss() 20.16745
wandb:          Test loss tennisEffect MSELoss() 751.43921
wandb:     Train loss data_t(5, 20)_r(0, 0)_full 0.00724
wandb: 
wandb: 🚀 View run quiet-pyramid-248 at: https://wandb.ai/nreints/test/runs/6a3nmhgv
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230321_162902-6a3nmhgv/logs
/gpfs/home2/nreints/MScThesis/code/fcnn.py:521: DeprecationWarning: Sampling from a set deprecated
since Python 3.9 and will be removed in a subsequent version.
  train_sims = set(random.sample(sims_train, int(0.8 * n_sims_train)))
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230321_170106-la4ksxev
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run upbeat-lake-306
wandb: ⭐️ View project at https://wandb.ai/nreints/test
wandb: 🚀 View run at https://wandb.ai/nreints/test/runs/la4ksxev
	 Logging train Loss: 0.0082990665 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.002352500567212701 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.035951972007751465 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 751.0927124023438 (MSELoss(): tennis_pNone_gNone_tennisEffect)
	 Logging test loss 20.178356170654297 (L1Loss(): tennis_pNone_gNone_tennisEffect)
     --> Epoch_time; 89.12687659263611
Epoch 17
	 Logging train Loss: 0.0081499792 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.0015116074355319142 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.02874239720404148 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 751.1184692382812 (MSELoss(): tennis_pNone_gNone_tennisEffect)
	 Logging test loss 20.172460556030273 (L1Loss(): tennis_pNone_gNone_tennisEffect)
     --> Epoch_time; 84.88752889633179
Epoch 18
	 Logging train Loss: 0.0073157915 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.006336298305541277 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.05874478071928024 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 751.2855224609375 (MSELoss(): tennis_pNone_gNone_tennisEffect)
	 Logging test loss 20.169681549072266 (L1Loss(): tennis_pNone_gNone_tennisEffect)
     --> Epoch_time; 88.65653443336487
Epoch 19
	 Logging train Loss: 0.0072411892 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.005119600798934698 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.053479596972465515 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 751.4423828125 (MSELoss(): tennis_pNone_gNone_tennisEffect)
	 Logging test loss 20.167741775512695 (L1Loss(): tennis_pNone_gNone_tennisEffect)
     --> Epoch_time; 84.57234406471252
	 Logging test loss 0.0051195514388382435 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.05347934365272522 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 751.439208984375 (MSELoss(): tennis_pNone_gNone_tennisEffect)
	 Logging test loss 20.167449951171875 (L1Loss(): tennis_pNone_gNone_tennisEffect)
It took 1923.8860294818878 seconds to train & eval the model.
----- ITERATION 2/2 ------
Number of train simulations: 3200
Number of test simulations: 800
The dataloader took 75.98687362670898 seconds.
-- Finished Train Dataloader --
The dataloader took 19.164970874786377 seconds.
The dataloader took 19.33565354347229 seconds.
-- Finished Test Dataloader(s) --
Datatype: dual_quat
--- Started Training ---
Epoch 0
	 Logging train Loss: 3.4110262204 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.012577972374856472 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.08749453723430634 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 731.4152221679688 (MSELoss(): tennis_pNone_gNone_tennisEffect)
	 Logging test loss 20.03921890258789 (L1Loss(): tennis_pNone_gNone_tennisEffect)
     --> Epoch_time; 88.6641902923584
Epoch 1
	 Logging train Loss: 0.0259692996 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.007566630840301514 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.06775934249162674 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 728.0023803710938 (MSELoss(): tennis_pNone_gNone_tennisEffect)
	 Logging test loss 20.060239791870117 (L1Loss(): tennis_pNone_gNone_tennisEffect)
     --> Epoch_time; 89.27384686470032
Epoch 2
	 Logging train Loss: 0.0201824213 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.012373048812150955 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.08263493329286575 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 730.7229614257812 (MSELoss(): tennis_pNone_gNone_tennisEffect)
	 Logging test loss 20.098777770996094 (L1Loss(): tennis_pNone_gNone_tennisEffect)
     --> Epoch_time; 88.31940269470215
Epoch 3
	 Logging train Loss: 0.0149180805 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.019193757325410843 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.0971919372677803 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 735.7982788085938 (MSELoss(): tennis_pNone_gNone_tennisEffect)
	 Logging test loss 20.154634475708008 (L1Loss(): tennis_pNone_gNone_tennisEffect)
     --> Epoch_time; 84.52341389656067
Epoch 4
	 Logging train Loss: 0.013389722 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.005769794341176748 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.05622458457946777 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 739.4934692382812 (MSELoss(): tennis_pNone_gNone_tennisEffect)
	 Logging test loss 20.218503952026367 (L1Loss(): tennis_pNone_gNone_tennisEffect)
     --> Epoch_time; 88.10050559043884
Epoch 5
	 Logging train Loss: 0.0122944065 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.0028175138868391514 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.03951804339885712 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 739.4215698242188 (MSELoss(): tennis_pNone_gNone_tennisEffect)
	 Logging test loss 20.235210418701172 (L1Loss(): tennis_pNone_gNone_tennisEffect)
     --> Epoch_time; 89.5343668460846
Epoch 6
	 Logging train Loss: 0.0124725766 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.006072974298149347 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.05770380422472954 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 731.99462890625 (MSELoss(): tennis_pNone_gNone_tennisEffect)
	 Logging test loss 20.134851455688477 (L1Loss(): tennis_pNone_gNone_tennisEffect)
     --> Epoch_time; 91.18540048599243
Epoch 7
	 Logging train Loss: 0.0102665733 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.0022259617689996958 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.035239897668361664 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 725.83203125 (MSELoss(): tennis_pNone_gNone_tennisEffect)
	 Logging test loss 20.0284481048584 (L1Loss(): tennis_pNone_gNone_tennisEffect)
     --> Epoch_time; 90.38325190544128
Epoch 8
	 Logging train Loss: 0.0103982832 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.0020149978809058666 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.033076174557209015 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 729.1093139648438 (MSELoss(): tennis_pNone_gNone_tennisEffect)
	 Logging test loss 20.050432205200195 (L1Loss(): tennis_pNone_gNone_tennisEffect)
     --> Epoch_time; 89.55046892166138
Epoch 9
	 Logging train Loss: 0.0097021346 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.038006994873285294 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.1365826427936554 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 731.3446655273438 (MSELoss(): tennis_pNone_gNone_tennisEffect)
	 Logging test loss 20.049936294555664 (L1Loss(): tennis_pNone_gNone_tennisEffect)
     --> Epoch_time; 89.02495884895325
Epoch 10
	 Logging train Loss: 0.0087002069 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.0016969249118119478 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.030765047296881676 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 732.8677978515625 (MSELoss(): tennis_pNone_gNone_tennisEffect)
	 Logging test loss 20.032024383544922 (L1Loss(): tennis_pNone_gNone_tennisEffect)
     --> Epoch_time; 90.1334137916565
Epoch 11
	 Logging train Loss: 0.0087801397 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.0015124029014259577 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.02900967374444008 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.028 MB of 0.097 MB uploaded (0.000 MB deduped)wandb: \ 0.028 MB of 0.097 MB uploaded (0.000 MB deduped)wandb: | 0.028 MB of 0.097 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  Test loss t(5, 20)_r(0, 0)_full L1Loss() ▅▄▅▆▃▂▃▂▁█▁▁▂▂▁▁▃▂▃▁▁
wandb: Test loss t(5, 20)_r(0, 0)_full MSELoss() ▃▂▃▄▂▁▂▁▁█▁▁▁▁▁▁▂▁▂▁▁
wandb:           Test loss tennisEffect L1Loss() ▁▂▃▅▇█▅▁▂▂▁▂▂▃▅▅▅▆▇▇▇
wandb:          Test loss tennisEffect MSELoss() ▃▂▃▄▆▆▃▁▂▃▃▄▅▅▆▆▆▇███
wandb:     Train loss data_t(5, 20)_r(0, 0)_full █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:  Test loss t(5, 20)_r(0, 0)_full L1Loss() 0.02778
wandb: Test loss t(5, 20)_r(0, 0)_full MSELoss() 0.0014
wandb:           Test loss tennisEffect L1Loss() 20.20151
wandb:          Test loss tennisEffect MSELoss() 746.22302
wandb:     Train loss data_t(5, 20)_r(0, 0)_full 0.006
wandb: 
wandb: 🚀 View run upbeat-lake-306 at: https://wandb.ai/nreints/test/runs/la4ksxev
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230321_170106-la4ksxev/logs
	 Logging test loss 734.6343994140625 (MSELoss(): tennis_pNone_gNone_tennisEffect)
	 Logging test loss 20.043243408203125 (L1Loss(): tennis_pNone_gNone_tennisEffect)
     --> Epoch_time; 89.10510087013245
Epoch 12
	 Logging train Loss: 0.008042108 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.0026069420855492353 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.03670806065201759 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 736.1874389648438 (MSELoss(): tennis_pNone_gNone_tennisEffect)
	 Logging test loss 20.066503524780273 (L1Loss(): tennis_pNone_gNone_tennisEffect)
     --> Epoch_time; 89.77413415908813
Epoch 13
	 Logging train Loss: 0.0079404444 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.0021310034207999706 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.0347336009144783 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 738.3129272460938 (MSELoss(): tennis_pNone_gNone_tennisEffect)
	 Logging test loss 20.096595764160156 (L1Loss(): tennis_pNone_gNone_tennisEffect)
     --> Epoch_time; 88.52448987960815
Epoch 14
	 Logging train Loss: 0.0072304395 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.0016541141085326672 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.030387386679649353 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 740.672119140625 (MSELoss(): tennis_pNone_gNone_tennisEffect)
	 Logging test loss 20.136972427368164 (L1Loss(): tennis_pNone_gNone_tennisEffect)
     --> Epoch_time; 88.45967268943787
Epoch 15
	 Logging train Loss: 0.0071893125 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.0011676946887746453 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.025257272645831108 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 741.22265625 (MSELoss(): tennis_pNone_gNone_tennisEffect)
	 Logging test loss 20.14820098876953 (L1Loss(): tennis_pNone_gNone_tennisEffect)
     --> Epoch_time; 87.8825192451477
Epoch 16
	 Logging train Loss: 0.0066346985 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.006642960011959076 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.05524936690926552 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 741.7174072265625 (MSELoss(): tennis_pNone_gNone_tennisEffect)
	 Logging test loss 20.15705680847168 (L1Loss(): tennis_pNone_gNone_tennisEffect)
     --> Epoch_time; 89.16019225120544
Epoch 17
	 Logging train Loss: 0.0065381119 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.0031443159095942974 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.04172486066818237 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 743.2828369140625 (MSELoss(): tennis_pNone_gNone_tennisEffect)
	 Logging test loss 20.175613403320312 (L1Loss(): tennis_pNone_gNone_tennisEffect)
     --> Epoch_time; 89.091224193573
Epoch 18
	 Logging train Loss: 0.0064273491 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.00437422888353467 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.04943625256419182 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 745.3062744140625 (MSELoss(): tennis_pNone_gNone_tennisEffect)
	 Logging test loss 20.19525718688965 (L1Loss(): tennis_pNone_gNone_tennisEffect)
     --> Epoch_time; 89.11844420433044
Epoch 19
	 Logging train Loss: 0.0060046501 (MSELoss(): data_t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.0014022529358044267 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.027776477858424187 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 746.2290649414062 (MSELoss(): tennis_pNone_gNone_tennisEffect)
	 Logging test loss 20.201440811157227 (L1Loss(): tennis_pNone_gNone_tennisEffect)
     --> Epoch_time; 88.71322679519653
	 Logging test loss 0.0014022510731592774 (MSELoss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 0.027776354923844337 (L1Loss(): t(5, 20)_r(0, 0)_full_pNone_gNone)
	 Logging test loss 746.2230224609375 (MSELoss(): tennis_pNone_gNone_tennisEffect)
	 Logging test loss 20.201509475708008 (L1Loss(): tennis_pNone_gNone_tennisEffect)
It took 1934.6608469486237 seconds to train & eval the model.

JOB STATISTICS
==============
Job ID: 2482048
Array Job ID: 2482035_12
Cluster: snellius
User/Group: nreints/nreints
State: RUNNING
Nodes: 1
Cores per node: 18
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 19:22:12 core-walltime
Job Wall-clock time: 01:04:34
Memory Utilized: 0.00 MB (estimated maximum)
Memory Efficiency: 0.00% of 29.30 GB (29.30 GB/node)
WARNING: Efficiency statistics may be misleading for RUNNING jobs.
