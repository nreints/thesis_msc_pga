wandb: Currently logged in as: nreints. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_164543-nup6c5fa
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ancient-fire-24
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal1/runs/nup6c5fa
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone â–ˆâ–‚â–‚â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–
wandb:                                   Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone 0.00161
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 0.00045
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone 0.00052
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 0.00256
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 0.00274
wandb:                                   Train loss 0.00162
wandb: 
wandb: ðŸš€ View run ancient-fire-24 at: https://wandb.ai/nreints/ThesisFinal1/runs/nup6c5fa
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_164543-nup6c5fa/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_170019-ezaqds62
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run woven-pond-81
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal1/runs/ezaqds62
Training on dataset: data_t(5,20)_r(5,20)_combi_pNone_gNone
Testing on 5 datasets: ['data_t(5,20)_r(5,20)_semi_pNone_gNone', 'data_t(5,20)_r(5,20)_full_pNone_gNone', 'data_t(5,20)_r(5,20)_combi_pNone_gNone', 'data_t(5,20)_r(5,20)_tennis_pNone_gNone', 'data_t(5,20)_r(5,20)_none_pNone_gNone']
Focussing on identity: False
Using extra input: False
Using start-fr as reference point.
----- ITERATION 1/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 77.58492088317871 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 19.704352378845215 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 19.77174687385559 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 19.554754734039307 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 19.900855541229248 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_none_pNone_gNone took 19.621893882751465 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 3.7635257244 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.1695898026 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.1118265539 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.140195027 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.1575416923 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.1327551156 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 69.33177781105042
Epoch 1/9
	 Logging train Loss: 0.0633271411 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0406641215 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0188446585 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0304034073 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0385928452 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0236167517 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 69.01112055778503
Epoch 2/9
	 Logging train Loss: 0.0198596288 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0202868562 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0071135201 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0144412778 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0202919953 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.009062008 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 68.43467235565186
Epoch 3/9
	 Logging train Loss: 0.0100798775 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0119180288 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.003458502 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0081696045 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0120285936 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0044475263 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 69.77618336677551
Epoch 4/9
	 Logging train Loss: 0.006163537 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0080214292 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0019781834 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0053588571 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0082158661 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0025144606 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 68.15236282348633
Epoch 5/9
	 Logging train Loss: 0.0042258399 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0056591248 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0012391503 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0037137833 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.005857449 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0015475875 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 68.04747581481934
Epoch 6/9
	 Logging train Loss: 0.0031448898 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0052377633 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0012205596 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0034637661 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0054624141 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0014315132 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 68.07353067398071
Epoch 7/9
	 Logging train Loss: 0.0024322758 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0036261573 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0006700567 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0022768585 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0037684953 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0008045824 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 68.0768370628357
Epoch 8/9
	 Logging train Loss: 0.0019352988 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0032632768 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0006996005 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0021109306 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0034702097 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0007986425 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 68.26020169258118
Epoch 9/9
	 Logging train Loss: 0.001624428 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0025589762 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0004486803 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0016096509 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0027394965 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0005159442 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 68.22393417358398
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gNone/'rot_mat'_'False'.pth
It took  876.8846914768219  seconds.
----- ITERATION 2/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 76.51392793655396 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 19.43687105178833 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 19.43894624710083 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 19.23963952064514 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 19.50792407989502 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_none_pNone_gNone took 19.62281060218811 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 3.7182381153 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.1466725022 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.1108681783 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.1387688518 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.1638730764 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone â–ˆâ–‚â–‚â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–
wandb:                                   Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone 0.00205
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 0.00083
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone 0.00082
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 0.00279
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 0.00311
wandb:                                   Train loss 0.00162
wandb: 
wandb: ðŸš€ View run woven-pond-81 at: https://wandb.ai/nreints/ThesisFinal1/runs/ezaqds62
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_170019-ezaqds62/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_171452-m54jn9lu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fine-plant-130
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal1/runs/m54jn9lu
	 Logging test loss: 0.1126248389 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 69.69536995887756
Epoch 1/9
	 Logging train Loss: 0.0592313334 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0353917181 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0179085769 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0304421317 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0411146171 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.018535886 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 69.33289980888367
Epoch 2/9
	 Logging train Loss: 0.0189295392 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0186363496 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0072772074 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0150602078 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0216676742 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0076267822 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 68.89210510253906
Epoch 3/9
	 Logging train Loss: 0.0100810556 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0123452842 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0038642234 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0094642192 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0142957913 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0040406785 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 70.50535941123962
Epoch 4/9
	 Logging train Loss: 0.0064315689 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0082589565 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.002247622 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0061094621 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.009375737 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0023289933 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 69.23604917526245
Epoch 5/9
	 Logging train Loss: 0.004529838 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0059014237 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0014594471 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0042422423 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0064971396 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0014930456 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 68.14032077789307
Epoch 6/9
	 Logging train Loss: 0.0033305436 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0058854618 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0018405938 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0043781851 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0064087217 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0018327811 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 68.01667356491089
Epoch 7/9
	 Logging train Loss: 0.0025704405 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0042613153 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0007993062 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0029112191 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0046124933 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.000797936 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 68.13789319992065
Epoch 8/9
	 Logging train Loss: 0.0019988315 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0030733144 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0005554024 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0021174576 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0033389393 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0005736838 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 68.23088669776917
Epoch 9/9
	 Logging train Loss: 0.0016243779 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0027938804 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0008257807 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.002050882 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0031092793 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0008241553 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 67.99258661270142
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gNone/'rot_mat'_'False'.pth
It took  873.5856266021729  seconds.
----- ITERATION 3/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 76.39502549171448 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 19.400054454803467 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 19.43436336517334 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 19.277323484420776 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 19.52673888206482 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_none_pNone_gNone took 19.540199756622314 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 4.0610232353 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.1957746744 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.1587226987 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.1861387342 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.2040771842 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.1480932832 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 69.41914105415344
Epoch 1/9
	 Logging train Loss: 0.0744358078 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0441736877 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0256549902 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0364168398 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0472964793 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.023300834 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 69.05960774421692
Epoch 2/9
	 Logging train Loss: 0.0223022494 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0216573514 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0098906457 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0166085605 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0235046595 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0092082303 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 68.34579920768738
Epoch 3/9
	 Logging train Loss: 0.0112350918 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0140236178 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.005047888 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0101660518 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0151979625 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0047623292 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 68.58413934707642
Epoch 4/9
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone â–ˆâ–‚â–‚â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone â–ˆâ–‚â–‚â–â–â–â–â–â–â–
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–
wandb:                                   Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone 0.00189
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 0.00064
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone 0.00063
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 0.00288
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 0.00309
wandb:                                   Train loss 0.00171
wandb: 
wandb: ðŸš€ View run fine-plant-130 at: https://wandb.ai/nreints/ThesisFinal1/runs/m54jn9lu
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_171452-m54jn9lu/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_172926-uwrkdllt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cerulean-bush-184
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal1/runs/uwrkdllt
	 Logging train Loss: 0.006825225 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0093311034 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0028070998 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0064738989 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0100176856 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0027065538 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 70.05096340179443
Epoch 5/9
	 Logging train Loss: 0.0045774495 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0062596551 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0017709492 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0043597571 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0068774968 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0017062017 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 68.14046263694763
Epoch 6/9
	 Logging train Loss: 0.0033245927 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0048214835 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.001189693 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.003216842 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0051747286 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0011564947 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 68.37975430488586
Epoch 7/9
	 Logging train Loss: 0.002538298 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0039457846 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0008587689 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0025575967 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0042264205 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0008450992 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 68.60101103782654
Epoch 8/9
	 Logging train Loss: 0.0020239111 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0030881616 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0006351743 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0020159658 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0033027532 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0006300369 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 68.61444544792175
Epoch 9/9
	 Logging train Loss: 0.0017098689 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0028846653 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0006353168 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0018933059 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0030872985 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0006262764 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 68.76767683029175
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gNone/'rot_mat'_'False'.pth
It took  873.779304265976  seconds.
----- ITERATION 4/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 76.08874821662903 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 19.349236726760864 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 19.419756412506104 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 19.163020849227905 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 19.341241359710693 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_none_pNone_gNone took 19.40857982635498 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 3.8521542549 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.1557830572 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.1167316884 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.1357782036 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.1414793581 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.1200148389 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 69.2893967628479
Epoch 1/9
	 Logging train Loss: 0.0643236488 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0393890552 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0219797231 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0302630924 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0353959985 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0221852884 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 68.98010063171387
Epoch 2/9
	 Logging train Loss: 0.0213104431 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.020280771 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0090287747 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.014423267 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0184301175 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0089593865 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 68.47821760177612
Epoch 3/9
	 Logging train Loss: 0.0111016799 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0133046275 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.004694364 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0088862646 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0123554636 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0046345904 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 68.15184473991394
Epoch 4/9
	 Logging train Loss: 0.0068776654 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0091353264 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0026868859 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0057816496 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0083000595 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0026497731 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 69.16571831703186
Epoch 5/9
	 Logging train Loss: 0.0047286404 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0066514364 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0019076824 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0042398158 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0061789788 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0018745066 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 69.10849165916443
Epoch 6/9
	 Logging train Loss: 0.0034863777 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0051753656 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0011310814 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0031094179 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0046858266 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0011254821 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 68.70926284790039
Epoch 7/9
	 Logging train Loss: 0.0026760816 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0043048672 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone â–ˆâ–‚â–‚â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone â–ˆâ–‚â–‚â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–
wandb:                                   Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone 0.0018
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 0.00065
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone 0.00066
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 0.00288
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 0.00276
wandb:                                   Train loss 0.00175
wandb: 
wandb: ðŸš€ View run cerulean-bush-184 at: https://wandb.ai/nreints/ThesisFinal1/runs/uwrkdllt
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_172926-uwrkdllt/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_174357-xa709szu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run atomic-oath-230
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal1/runs/xa709szu
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone â–ˆâ–‚â–‚â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–
wandb:                                   Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone 0.00157
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 0.00056
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone 0.00059
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 0.00243
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 0.00238
wandb:                                   Train loss 0.00163
wandb: 
wandb: ðŸš€ View run atomic-oath-230 at: https://wandb.ai/nreints/ThesisFinal1/runs/xa709szu
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_174357-xa709szu/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_175829-vue3uque
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run brisk-sunset-285
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal1/runs/vue3uque
	 Logging test loss: 0.0009446109 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0026182076 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0040246756 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0009517716 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 68.54636812210083
Epoch 8/9
	 Logging train Loss: 0.0021267752 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0029544455 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0006208541 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0017904914 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0027336099 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0006124683 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 68.49635696411133
Epoch 9/9
	 Logging train Loss: 0.001751626 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0028783886 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0006543715 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.00179639 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0027555691 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0006594479 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 68.41382312774658
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gNone/'rot_mat'_'False'.pth
It took  871.4576444625854  seconds.
----- ITERATION 5/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 76.4113552570343 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 19.35417151451111 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 19.333898544311523 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 19.18757700920105 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 19.424760341644287 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_none_pNone_gNone took 19.399019241333008 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 3.7954330444 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.1766942441 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.1289013624 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.1644085497 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.1704937816 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.1299893409 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 69.12299919128418
Epoch 1/9
	 Logging train Loss: 0.0634218156 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0409769006 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0205367152 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0334245004 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0396276675 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0216334835 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 68.92210721969604
Epoch 2/9
	 Logging train Loss: 0.0199299697 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0205736998 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0081630936 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0155650293 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0200556479 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0087990919 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 68.17021536827087
Epoch 3/9
	 Logging train Loss: 0.0104571385 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.013008032 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0043302276 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0092645269 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0128112556 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0045910189 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 67.97732877731323
Epoch 4/9
	 Logging train Loss: 0.0065609929 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0088322405 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0025447947 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0060278452 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0086381882 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0026390981 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 68.05995440483093
Epoch 5/9
	 Logging train Loss: 0.004522806 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0065235738 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0016602308 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0042702421 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0063368366 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0017208855 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 69.94579911231995
Epoch 6/9
	 Logging train Loss: 0.0032863058 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.004891397 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0012177192 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0031960912 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0047508385 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.001264377 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 68.93529891967773
Epoch 7/9
	 Logging train Loss: 0.0025344144 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0039258129 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0008437291 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0025130401 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0038674064 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0008787973 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 68.44448447227478
Epoch 8/9
	 Logging train Loss: 0.0020106304 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0028906409 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.000638728 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0018382213 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0027581477 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0006745271 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 68.33999514579773
Epoch 9/9
	 Logging train Loss: 0.0016287765 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0024258993 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0005636794 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0015677954 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0023844375 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0005914568 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 68.36111235618591
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gNone/'rot_mat'_'False'.pth
It took  871.5682511329651  seconds.
----- ITERATION 6/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone â–ˆâ–‚â–‚â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–
wandb:                                   Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone 0.0014
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 0.00042
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone 0.00043
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 0.00233
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 0.00246
wandb:                                   Train loss 0.00148
wandb: 
wandb: ðŸš€ View run brisk-sunset-285 at: https://wandb.ai/nreints/ThesisFinal1/runs/vue3uque
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_175829-vue3uque/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_181301-7wyr22yd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run breezy-tree-323
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal1/runs/7wyr22yd
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 76.33402991294861 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 19.343260049819946 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 19.292859077453613 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 19.223772764205933 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 19.43258047103882 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_none_pNone_gNone took 19.403189659118652 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 3.8345401287 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.1478448808 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.1122569963 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.1341018379 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.1560991853 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.1047377363 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 68.96404075622559
Epoch 1/9
	 Logging train Loss: 0.0620502084 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0365778171 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0187955629 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0295815784 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0395114273 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0183018558 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 69.17838144302368
Epoch 2/9
	 Logging train Loss: 0.0197015982 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0182136185 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0072491355 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0136796543 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0196330342 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0073406659 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 68.658438205719
Epoch 3/9
	 Logging train Loss: 0.0100864274 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0113638863 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.003681716 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.007915901 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0120374179 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0037761428 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 68.30027556419373
Epoch 4/9
	 Logging train Loss: 0.0062670028 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0081984755 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0022442935 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.00534068 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0085190022 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0022880954 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 68.11728000640869
Epoch 5/9
	 Logging train Loss: 0.004293934 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0056599155 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0014429183 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0035934462 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0058334568 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0014554035 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 68.15548896789551
Epoch 6/9
	 Logging train Loss: 0.0031350253 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.004629395 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0009903538 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0028939454 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0048863883 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0010070185 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 69.95263862609863
Epoch 7/9
	 Logging train Loss: 0.0023475566 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0029988491 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0006682027 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0018928432 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0031689107 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0006853164 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 69.11172938346863
Epoch 8/9
	 Logging train Loss: 0.0018296716 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0024859123 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0004956882 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0015039527 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0025817615 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0005111991 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 68.27785396575928
Epoch 9/9
	 Logging train Loss: 0.0014844828 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0023318788 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0004176852 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0013967779 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0024554415 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0004346781 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 68.23300409317017
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gNone/'rot_mat'_'False'.pth
It took  871.7816591262817  seconds.
----- ITERATION 7/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 76.75421714782715 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 19.338159799575806 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 19.28350329399109 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 19.214415550231934 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 19.399163246154785 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_none_pNone_gNone took 19.393858671188354 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 3.8379192352 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.1533080339 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.117617704 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.1298345327 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.1560789645 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.1139846146 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 69.10239577293396
Epoch 1/9
	 Logging train Loss: 0.0627256557 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0362515077 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0208781809 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0272868108 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0381404683 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone â–ˆâ–‚â–‚â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–
wandb:                                   Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone 0.00149
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 0.00052
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone 0.00052
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 0.00241
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 0.00253
wandb:                                   Train loss 0.00171
wandb: 
wandb: ðŸš€ View run breezy-tree-323 at: https://wandb.ai/nreints/ThesisFinal1/runs/7wyr22yd
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_181301-7wyr22yd/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_182732-1y4f78hk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run earnest-tree-345
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal1/runs/1y4f78hk
	 Logging test loss: 0.0196488257 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 68.8217523097992
Epoch 2/9
	 Logging train Loss: 0.0204460211 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0186315514 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0084875394 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0132384738 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0199388955 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0079670344 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 68.3158631324768
Epoch 3/9
	 Logging train Loss: 0.0105806105 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0113073913 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0042764586 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0077401721 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.012116828 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.003985431 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 68.16675019264221
Epoch 4/9
	 Logging train Loss: 0.0065501523 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.008377267 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0025207826 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0055144946 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.00902142 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0023266948 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 68.52059316635132
Epoch 5/9
	 Logging train Loss: 0.0044915308 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0062980466 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0017844053 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0041217594 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0067195133 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0017028578 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 68.53378486633301
Epoch 6/9
	 Logging train Loss: 0.0033307769 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0046678386 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0011671892 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0029698322 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0049976525 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0011147341 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 68.5081524848938
Epoch 7/9
	 Logging train Loss: 0.0025530492 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0038986802 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0008741341 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0024860455 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0042007915 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0008466151 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 69.79935550689697
Epoch 8/9
	 Logging train Loss: 0.0020698721 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0038621859 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0005856964 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0023402621 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0040735272 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0005805154 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 68.14774084091187
Epoch 9/9
	 Logging train Loss: 0.0017058954 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0024148088 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0005249946 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0014928309 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0025264577 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0005236321 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 67.89408445358276
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gNone/'rot_mat'_'False'.pth
It took  871.5716693401337  seconds.
----- ITERATION 8/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 76.00918221473694 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 19.30743718147278 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 19.294288158416748 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 19.117253303527832 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 19.201666831970215 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_none_pNone_gNone took 19.23261785507202 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 3.931794405 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.186591804 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.1392994225 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.1790966541 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.1862802804 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.1445736438 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 68.67261695861816
Epoch 1/9
	 Logging train Loss: 0.0715427622 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0435307808 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.022958478 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0373377316 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.043776121 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0237366036 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 68.54690361022949
Epoch 2/9
	 Logging train Loss: 0.0222989582 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.022333635 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0093128951 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0177689046 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0224807989 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0095301298 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 68.2794840335846
Epoch 3/9
	 Logging train Loss: 0.0115735522 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0135131394 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0048515019 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0102830632 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0137225166 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0048837387 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 67.87847828865051
Epoch 4/9
	 Logging train Loss: 0.0070769479 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0090747885 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0027911845 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0067000235 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0093074329 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0028023242 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 68.08007383346558
Epoch 5/9
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone â–ˆâ–‚â–‚â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–
wandb:                                   Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone 0.00177
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 0.00045
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone 0.00047
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 0.00265
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 0.00278
wandb:                                   Train loss 0.00162
wandb: 
wandb: ðŸš€ View run earnest-tree-345 at: https://wandb.ai/nreints/ThesisFinal1/runs/1y4f78hk
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_182732-1y4f78hk/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_184202-gwdhyv2s
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stellar-star-355
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal1/runs/gwdhyv2s
	 Logging train Loss: 0.0047899708 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0067100441 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0017866816 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0048537799 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0070467833 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0017752148 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 68.51138806343079
Epoch 6/9
	 Logging train Loss: 0.0034595113 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0049942811 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0012269509 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0035511737 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0052532558 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0012254455 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 68.30488872528076
Epoch 7/9
	 Logging train Loss: 0.0025776869 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0042684684 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.001076609 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0030524812 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0045707985 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0010650285 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 67.92868304252625
Epoch 8/9
	 Logging train Loss: 0.0020097122 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0033261897 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0006410496 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0022342952 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0035313086 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0006573192 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 70.06286215782166
Epoch 9/9
	 Logging train Loss: 0.0016215423 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0026501103 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0004494101 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0017696492 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0027750013 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0004656253 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 67.90993762016296
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gNone/'rot_mat'_'False'.pth
It took  869.511111497879  seconds.
----- ITERATION 9/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 75.98689770698547 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 19.248594760894775 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 19.24771285057068 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 19.13640022277832 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 19.230621814727783 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_none_pNone_gNone took 19.233960390090942 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 3.7884714603 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.1771094352 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.1345477998 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.161648944 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.2013589293 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.1379588693 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 68.7425765991211
Epoch 1/9
	 Logging train Loss: 0.0713201165 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0383337811 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.022427626 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0318661481 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0463232175 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0225978494 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 68.44967675209045
Epoch 2/9
	 Logging train Loss: 0.0213474818 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0185275935 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0089709675 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0143290889 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0225383509 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0090460768 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 68.1344883441925
Epoch 3/9
	 Logging train Loss: 0.0110117551 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0112552568 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0046244068 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0082637155 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.01365788 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0047341143 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 67.84081244468689
Epoch 4/9
	 Logging train Loss: 0.0068183742 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0079680625 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.002596817 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.005472437 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0095710773 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0026738006 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 68.08252334594727
Epoch 5/9
	 Logging train Loss: 0.0045765364 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0058212359 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0015574369 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0038596897 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.006922971 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0016205325 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 68.24010992050171
Epoch 6/9
	 Logging train Loss: 0.0032800876 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.004134391 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0010116402 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0027073293 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.00484232 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0010662221 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 68.02963709831238
Epoch 7/9
	 Logging train Loss: 0.0024324474 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0033358259 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0006929997 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0021623848 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0039838422 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0007305852 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 67.89988708496094
Epoch 8/9
	 Logging train Loss: 0.0019044689 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0025145165 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone â–ˆâ–‚â–‚â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone â–ˆâ–‚â–‚â–â–â–â–â–â–â–
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–
wandb:                                   Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone 0.00141
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 0.00047
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone 0.00049
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 0.00218
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 0.00256
wandb:                                   Train loss 0.00151
wandb: 
wandb: ðŸš€ View run stellar-star-355 at: https://wandb.ai/nreints/ThesisFinal1/runs/gwdhyv2s
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_184202-gwdhyv2s/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_185629-0dh48hxi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fanciful-star-361
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal1/runs/0dh48hxi
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone â–ˆâ–‚â–‚â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–
wandb:                                   Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone 0.00143
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 0.00047
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone 0.00054
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 0.00236
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 0.00239
wandb:                                   Train loss 0.00174
wandb: 
wandb: ðŸš€ View run fanciful-star-361 at: https://wandb.ai/nreints/ThesisFinal1/runs/0dh48hxi
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_185629-0dh48hxi/logs
	 Logging test loss: 0.0005105523 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0016285253 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0030064012 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0005388865 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 69.12707757949829
Epoch 9/9
	 Logging train Loss: 0.0015125773 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0021756317 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0004666515 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0014066504 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0025609466 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0004919238 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 68.26979446411133
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gNone/'rot_mat'_'False'.pth
It took  866.6931495666504  seconds.
----- ITERATION 10/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 76.50178456306458 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 19.390509128570557 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 19.374560117721558 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 19.273961544036865 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 19.329885959625244 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_none_pNone_gNone took 19.390461921691895 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 3.7917318344 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.1765787154 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.1218531057 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.1575425714 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.1634202152 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.1434772462 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 68.67648220062256
Epoch 1/9
	 Logging train Loss: 0.0668215156 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0421320908 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0202073976 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0334972627 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.039404247 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0260557588 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 68.54379868507385
Epoch 2/9
	 Logging train Loss: 0.0212355964 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0206734221 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0079625072 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0153133525 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.019566942 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0106615713 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 68.07760214805603
Epoch 3/9
	 Logging train Loss: 0.0109923379 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0126119917 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0040938091 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0088069616 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0120763741 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0054452852 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 67.68860578536987
Epoch 4/9
	 Logging train Loss: 0.0067376867 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0091526629 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0024242699 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0060196626 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0089285346 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0031666965 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 67.48208832740784
Epoch 5/9
	 Logging train Loss: 0.0045782034 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0064291544 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0016543255 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0042207763 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.006396661 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.00208597 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 67.6875352859497
Epoch 6/9
	 Logging train Loss: 0.0033553387 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0056917039 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0015389629 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0036911797 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0055984757 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0018346083 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 67.9509220123291
Epoch 7/9
	 Logging train Loss: 0.0025626998 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0035705429 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0007054834 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0021670531 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0035456917 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0008652074 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 67.86580991744995
Epoch 8/9
	 Logging train Loss: 0.0020734048 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0032417192 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0006215331 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0019796158 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0033558654 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0007442976 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 67.8667311668396
Epoch 9/9
	 Logging train Loss: 0.0017362322 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0023621931 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0004659807 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0014296413 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0023921765 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0005417961 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 69.4636013507843
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gNone/'rot_mat'_'False'.pth
It took  867.4302597045898  seconds.

JOB STATISTICS
==============
Job ID: 2971302
Array Job ID: 2971286_15
Cluster: snellius
User/Group: nreints/nreints
State: RUNNING
Nodes: 1
Cores per node: 18
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 1-19:38:42 core-walltime
Job Wall-clock time: 02:25:29
Memory Utilized: 0.00 MB (estimated maximum)
Memory Efficiency: 0.00% of 0.00 MB (0.00 MB/node)
WARNING: Efficiency statistics may be misleading for RUNNING jobs.
