wandb: Currently logged in as: nreints. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_164043-h09jpu9w
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lunar-snowball-14
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal1/runs/h09jpu9w
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone â–ˆâ–†â–„â–‚â–‚â–‚â–„â–â–‚â–‚
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone â–ˆâ–†â–„â–‚â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone â–ˆâ–†â–„â–‚â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone â–ˆâ–†â–„â–ƒâ–‚â–‚â–†â–â–‚â–‚
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone â–ˆâ–†â–„â–ƒâ–‚â–ƒâ–‡â–â–‚â–ƒ
wandb:                                   Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone 2e-05
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 3e-05
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 4e-05
wandb:                                   Train loss 2e-05
wandb: 
wandb: ðŸš€ View run lunar-snowball-14 at: https://wandb.ai/nreints/ThesisFinal1/runs/h09jpu9w
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_164043-h09jpu9w/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_165142-2wi9rc6r
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run celestial-lake-51
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal1/runs/2wi9rc6r
Training on dataset: data_t(5,20)_r(5,20)_combi_pNone_gNone
Testing on 5 datasets: ['data_t(5,20)_r(5,20)_combi_pNone_gNone', 'data_t(5,20)_r(5,20)_full_pNone_gNone', 'data_t(5,20)_r(5,20)_none_pNone_gNone', 'data_t(5,20)_r(5,20)_semi_pNone_gNone', 'data_t(5,20)_r(5,20)_tennis_pNone_gNone']
Focussing on identity: False
Using extra input: False
Using fr-fr as reference point.
----- ITERATION 1/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 65.97168922424316 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 16.027384519577026 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 16.354616165161133 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_none_pNone_gNone took 16.538963079452515 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 16.8433358669281 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 16.70955467224121 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0163284596 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 9.22077e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.88097e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 7.63972e-05 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0001095752 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0001097225 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 51.23720836639404
Epoch 1/9
	 Logging train Loss: 8.17798e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.73054e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.81466e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 5.61496e-05 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 8.01367e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 8.0223e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 49.33864402770996
Epoch 2/9
	 Logging train Loss: 5.79704e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.48709e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.69036e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.5523e-05 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 5.51516e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 5.59503e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 49.05091118812561
Epoch 3/9
	 Logging train Loss: 3.56374e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.37409e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.69142e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.62924e-05 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.19094e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.28574e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 49.73018026351929
Epoch 4/9
	 Logging train Loss: 1.74722e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.1795e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.1806e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.0971e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.98714e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.17905e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 49.10473895072937
Epoch 5/9
	 Logging train Loss: 1.24441e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.58553e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.9093e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.0017e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.96008e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.41816e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 47.758443117141724
Epoch 6/9
	 Logging train Loss: 2.3758e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.29386e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.0327e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.1308e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 8.22771e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 9.52497e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 48.885122537612915
Epoch 7/9
	 Logging train Loss: 3.17217e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.1527e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.562e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 5.166e-07 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.02839e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.13381e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 50.41662120819092
Epoch 8/9
	 Logging train Loss: 2.1896e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.29157e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.8744e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.9513e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.38331e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.76187e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 49.05646800994873
Epoch 9/9
	 Logging train Loss: 2.14798e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.64314e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.2976e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.3437e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.13481e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.56109e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 50.093573331832886
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gNone/'dual_quat_1'_'False'.pth
It took  659.7448811531067  seconds.
----- ITERATION 2/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 60.36493229866028 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 15.154831409454346 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 15.292738437652588 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_none_pNone_gNone took 15.204176902770996 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 15.287960290908813 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 15.265286207199097 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0643769354 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0001035376 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.52956e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 7.74521e-05 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0001225245 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone â–ˆâ–†â–…â–…â–ƒâ–‚â–â–â–‚â–
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone â–ˆâ–‡â–†â–…â–„â–‚â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone â–ˆâ–‡â–†â–…â–„â–‚â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone â–ˆâ–†â–…â–„â–ƒâ–‚â–â–â–‚â–
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone â–ˆâ–†â–…â–„â–ƒâ–‚â–â–â–‚â–
wandb:                                   Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone 1e-05
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 2e-05
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 2e-05
wandb:                                   Train loss 2e-05
wandb: 
wandb: ðŸš€ View run celestial-lake-51 at: https://wandb.ai/nreints/ThesisFinal1/runs/2wi9rc6r
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_165142-2wi9rc6r/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_170233-l2stviaz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lively-salad-88
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal1/runs/l2stviaz
	 Logging test loss: 0.0001253393 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 49.38574838638306
Epoch 1/9
	 Logging train Loss: 8.4875e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.10764e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.52747e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 6.65342e-05 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 9.09041e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 9.27077e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 53.28203225135803
Epoch 2/9
	 Logging train Loss: 7.11671e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.95828e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.76491e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 5.84648e-05 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 7.61144e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 7.75719e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 49.995285749435425
Epoch 3/9
	 Logging train Loss: 5.94377e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.61037e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.55577e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.62283e-05 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 6.25807e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 6.37315e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 49.80028033256531
Epoch 4/9
	 Logging train Loss: 4.56615e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.00057e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.0289e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.07612e-05 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 4.67533e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.76207e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 48.703315019607544
Epoch 5/9
	 Logging train Loss: 2.95934e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.26795e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.38873e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.42344e-05 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.97165e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.00359e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 50.291515588760376
Epoch 6/9
	 Logging train Loss: 1.54813e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.14506e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.6729e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.8349e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.83965e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.82223e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 50.18382167816162
Epoch 7/9
	 Logging train Loss: 9.457e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.5397e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.258e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 7.201e-07 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.57064e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.58412e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 48.542375564575195
Epoch 8/9
	 Logging train Loss: 1.16728e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.62737e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 9.166e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.0054e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.02905e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.13799e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 49.69494700431824
Epoch 9/9
	 Logging train Loss: 1.57113e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.28764e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.4642e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.5386e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.23241e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.29545e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 50.10039472579956
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gNone/'dual_quat_1'_'False'.pth
It took  651.7543988227844  seconds.
----- ITERATION 3/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 60.48676776885986 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 15.187907457351685 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 15.277767419815063 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_none_pNone_gNone took 15.238248109817505 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 15.218772411346436 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 15.219144344329834 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0108040655 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.59759e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.07293e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 6.9955e-05 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 9.77683e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 9.87885e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 49.65859889984131
Epoch 1/9
	 Logging train Loss: 6.97604e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.01614e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.02359e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.97981e-05 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 6.84261e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 6.85063e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 49.140872955322266
Epoch 2/9
	 Logging train Loss: 4.85949e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.95884e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.11332e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.09438e-05 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 4.77802e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.81495e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 48.638936281204224
Epoch 3/9
	 Logging train Loss: 2.96502e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.16726e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.35969e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.36491e-05 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.04364e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.10912e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 50.450082540512085
Epoch 4/9
	 Logging train Loss: 1.51692e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone â–ˆâ–†â–„â–‚â–â–â–‚â–ƒâ–â–
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone â–ˆâ–†â–„â–‚â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone â–ˆâ–†â–„â–‚â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone â–ˆâ–…â–„â–‚â–â–â–‚â–„â–â–
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone â–ˆâ–…â–„â–‚â–â–â–‚â–„â–‚â–
wandb:                                   Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone 1e-05
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 2e-05
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 2e-05
wandb:                                   Train loss 2e-05
wandb: 
wandb: ðŸš€ View run lively-salad-88 at: https://wandb.ai/nreints/ThesisFinal1/runs/l2stviaz
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_170233-l2stviaz/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_171325-thasheba
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run northern-thunder-126
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal1/runs/thasheba
	 Logging test loss: 9.7499e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.8958e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.0967e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.74972e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.81585e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 50.59070801734924
Epoch 5/9
	 Logging train Loss: 2.18047e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.5321e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.1803e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.276e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.68758e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.7662e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 50.166858434677124
Epoch 6/9
	 Logging train Loss: 2.42234e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.44103e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.6764e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.7471e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.75483e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.99518e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 50.32601475715637
Epoch 7/9
	 Logging train Loss: 2.44727e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.76494e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.4853e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.5475e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 5.16891e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 5.73039e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 53.44679141044617
Epoch 8/9
	 Logging train Loss: 2.10214e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.06881e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.968e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 8.655e-07 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.13491e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.30237e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 49.57870841026306
Epoch 9/9
	 Logging train Loss: 1.92155e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 9.6789e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.9556e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.0031e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.62413e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.69147e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 49.921045541763306
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gNone/'dual_quat_1'_'False'.pth
It took  651.8082573413849  seconds.
----- ITERATION 4/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 60.652366638183594 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 15.164942979812622 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 15.204237937927246 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_none_pNone_gNone took 15.227348804473877 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 15.219438791275024 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 15.191201448440552 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0056534624 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.19225e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.60776e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 5.50186e-05 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 8.33117e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 8.27311e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 50.37073087692261
Epoch 1/9
	 Logging train Loss: 5.30779e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.01655e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.72622e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.67574e-05 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 4.99193e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.92018e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 50.55353808403015
Epoch 2/9
	 Logging train Loss: 2.79104e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.98994e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.9617e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 8.9322e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.84736e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.77021e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 50.06727647781372
Epoch 3/9
	 Logging train Loss: 1.35572e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.06644e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.9659e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.0501e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.76798e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.67317e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 48.53610014915466
Epoch 4/9
	 Logging train Loss: 1.76781e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0001362462 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.1798e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.1745e-05 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0002154618 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0002265367 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 49.393216133117676
Epoch 5/9
	 Logging train Loss: 2.07655e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 9.6632e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.0941e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.1842e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.64936e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.59791e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 50.258973360061646
Epoch 6/9
	 Logging train Loss: 2.21641e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.96479e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.2238e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 6.2788e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 6.64379e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 6.97598e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 49.92226529121399
Epoch 7/9
	 Logging train Loss: 1.99937e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.32288e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 9.143e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 9.966e-07 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone â–…â–ƒâ–‚â–â–ˆâ–â–ƒâ–â–â–
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone â–ˆâ–„â–‚â–â–…â–â–‚â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone â–ˆâ–„â–‚â–â–…â–â–‚â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone â–ƒâ–‚â–‚â–â–ˆâ–â–ƒâ–â–â–
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone â–ƒâ–‚â–‚â–â–ˆâ–â–ƒâ–â–â–
wandb:                                   Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone 1e-05
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 1e-05
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 1e-05
wandb:                                   Train loss 1e-05
wandb: 
wandb: ðŸš€ View run northern-thunder-126 at: https://wandb.ai/nreints/ThesisFinal1/runs/thasheba
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_171325-thasheba/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_172414-18vh2bo6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run tough-snowflake-163
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal1/runs/18vh2bo6
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone â–ˆâ–†â–„â–ƒâ–â–‚â–â–‚â–â–
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone â–ˆâ–†â–„â–‚â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone â–ˆâ–†â–„â–‚â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone â–ˆâ–…â–„â–ƒâ–‚â–‚â–‚â–‚â–â–
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone â–ˆâ–…â–„â–ƒâ–‚â–‚â–‚â–‚â–â–
wandb:                                   Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone 1e-05
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 1e-05
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 1e-05
wandb:                                   Train loss 2e-05
wandb: 
wandb: ðŸš€ View run tough-snowflake-163 at: https://wandb.ai/nreints/ThesisFinal1/runs/18vh2bo6
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_172414-18vh2bo6/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_173500-wp996lbp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run silvery-shadow-201
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal1/runs/wp996lbp
	 Logging test loss: 2.28869e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.3229e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 49.61325430870056
Epoch 8/9
	 Logging train Loss: 1.76728e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.32304e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.8119e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.8528e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.98454e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.9598e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 49.463149309158325
Epoch 9/9
	 Logging train Loss: 1.47091e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.3368e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.4737e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.5269e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.19579e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.15944e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 50.28746771812439
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gNone/'dual_quat_1'_'False'.pth
It took  648.977548122406  seconds.
----- ITERATION 5/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 60.57021427154541 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 15.134313344955444 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 15.305400371551514 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_none_pNone_gNone took 15.226169109344482 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 15.191495180130005 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 15.334161758422852 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0246758014 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0001035974 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.81851e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 7.74454e-05 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0001239735 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.000123212 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 49.39292573928833
Epoch 1/9
	 Logging train Loss: 8.49179e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.16302e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.75806e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 5.6965e-05 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 8.31242e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 8.17693e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 49.28285360336304
Epoch 2/9
	 Logging train Loss: 5.84017e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.73109e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.55654e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.51428e-05 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 5.76734e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 5.52904e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 49.21074914932251
Epoch 3/9
	 Logging train Loss: 3.57134e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.69066e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.58037e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.57635e-05 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.77812e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.52877e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 49.65188479423523
Epoch 4/9
	 Logging train Loss: 1.79465e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.21218e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.8184e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.8529e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.11651e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.83665e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 49.89643311500549
Epoch 5/9
	 Logging train Loss: 1.21151e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.52592e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.8675e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.9535e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.94673e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.61987e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 49.478416442871094
Epoch 6/9
	 Logging train Loss: 2.13251e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.22711e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.9303e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.0618e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.26158e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.01655e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 49.46442651748657
Epoch 7/9
	 Logging train Loss: 2.05758e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.68118e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.1431e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.2124e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.18775e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.91312e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 51.00480532646179
Epoch 8/9
	 Logging train Loss: 1.93167e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.7613e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.1283e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.2074e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.51206e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.30026e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 49.6745343208313
Epoch 9/9
	 Logging train Loss: 1.88061e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.6655e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.254e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 5.951e-07 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.1489e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 9.5803e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 49.769102811813354
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gNone/'dual_quat_1'_'False'.pth
It took  645.7331454753876  seconds.
----- ITERATION 6/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 60.49077391624451 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 15.110324144363403 seconds.
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone â–ˆâ–…â–„â–„â–ƒâ–‚â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone â–ˆâ–†â–…â–„â–„â–‚â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone â–ˆâ–†â–…â–„â–ƒâ–‚â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone â–ˆâ–„â–„â–ƒâ–ƒâ–‚â–â–â–â–
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone â–ˆâ–„â–„â–ƒâ–ƒâ–‚â–â–â–â–
wandb:                                   Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone 1e-05
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 1e-05
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 1e-05
wandb:                                   Train loss 1e-05
wandb: 
wandb: ðŸš€ View run silvery-shadow-201 at: https://wandb.ai/nreints/ThesisFinal1/runs/wp996lbp
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_173500-wp996lbp/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_174554-ajil0ghu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run exalted-smoke-243
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal1/runs/ajil0ghu
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 15.881494522094727 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_none_pNone_gNone took 15.140356540679932 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 15.095550298690796 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 15.11152172088623 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.1044934615 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0001657662 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0001077814 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0001135262 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0002119585 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0002097572 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 49.765451431274414
Epoch 1/9
	 Logging train Loss: 0.0001084495 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 9.25269e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.19801e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 7.50242e-05 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0001104112 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0001076591 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 50.98720979690552
Epoch 2/9
	 Logging train Loss: 8.10772e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.78638e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.35641e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 6.63619e-05 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 9.02775e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 8.76775e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 49.97438621520996
Epoch 3/9
	 Logging train Loss: 6.84363e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.47133e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.29059e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 5.50293e-05 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 7.54352e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 7.31611e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 49.009023904800415
Epoch 4/9
	 Logging train Loss: 5.49229e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.94793e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.90827e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.06366e-05 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 5.93774e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 5.68829e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 51.342368364334106
Epoch 5/9
	 Logging train Loss: 3.86812e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.14538e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.25427e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.34772e-05 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 4.02534e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.80654e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 52.388784646987915
Epoch 6/9
	 Logging train Loss: 2.15533e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.51865e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.7596e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 7.9733e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.27428e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.06444e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 50.00616979598999
Epoch 7/9
	 Logging train Loss: 1.12345e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.12527e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.7229e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.7988e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.01597e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.85806e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 49.86855220794678
Epoch 8/9
	 Logging train Loss: 1.14903e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.5505e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.545e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 8.306e-07 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.5854e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.43996e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 50.72786283493042
Epoch 9/9
	 Logging train Loss: 1.41641e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.4711e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.075e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 7.673e-07 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.18479e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.05127e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 49.639686822891235
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gNone/'dual_quat_1'_'False'.pth
It took  653.9043157100677  seconds.
----- ITERATION 7/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 60.01133108139038 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 15.054006338119507 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 15.228943347930908 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_none_pNone_gNone took 15.09882664680481 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 15.162626266479492 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 15.071090936660767 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0088957064 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 9.7594e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.55541e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 7.46789e-05 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0001157998 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0001211053 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 49.36929440498352
Epoch 1/9
	 Logging train Loss: 7.75442e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.23262e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.26022e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 5.18632e-05 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 7.09642e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 7.24382e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 48.974453926086426
Epoch 2/9
	 Logging train Loss: 5.02038e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.80028e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone â–ˆâ–…â–ƒâ–‚â–â–â–â–‚â–â–
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone â–ˆâ–†â–„â–‚â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone â–ˆâ–†â–„â–‚â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone â–ˆâ–…â–ƒâ–‚â–â–â–â–‚â–‚â–
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone â–ˆâ–…â–ƒâ–‚â–â–â–â–‚â–‚â–
wandb:                                   Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone 1e-05
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 2e-05
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 2e-05
wandb:                                   Train loss 2e-05
wandb: 
wandb: ðŸš€ View run exalted-smoke-243 at: https://wandb.ai/nreints/ThesisFinal1/runs/ajil0ghu
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_174554-ajil0ghu/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_175642-9o4dnrp8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run iconic-sky-280
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal1/runs/9o4dnrp8
	 Logging test loss: 2.94109e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.90726e-05 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 4.56872e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.70776e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 49.42255687713623
Epoch 3/9
	 Logging train Loss: 2.76233e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.81334e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.00705e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.01342e-05 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.49657e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.66798e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 50.104875802993774
Epoch 4/9
	 Logging train Loss: 1.5474e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 9.681e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.8817e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.0153e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.66058e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.82481e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 48.99312973022461
Epoch 5/9
	 Logging train Loss: 1.65846e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.5666e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.164e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 5.916e-07 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.36226e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.53809e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 50.871615171432495
Epoch 6/9
	 Logging train Loss: 2.00785e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.1064e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.3797e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.4503e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.41611e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.55222e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 51.154606342315674
Epoch 7/9
	 Logging train Loss: 2.24639e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.58791e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.4541e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.5168e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.68347e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.01105e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 49.863290548324585
Epoch 8/9
	 Logging train Loss: 2.13631e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.22082e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.0175e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.0717e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.1379e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.40291e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 50.0149130821228
Epoch 9/9
	 Logging train Loss: 1.83734e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.0143e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.1547e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.2171e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.76497e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.0044e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 49.40743947029114
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gNone/'dual_quat_1'_'False'.pth
It took  647.8415577411652  seconds.
----- ITERATION 8/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 60.3064603805542 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 15.12006139755249 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 15.17246413230896 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_none_pNone_gNone took 15.134480476379395 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 15.146045207977295 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 15.210942029953003 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0160184782 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.85451e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.93774e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 7.0242e-05 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0001032715 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0001046467 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 49.84387683868408
Epoch 1/9
	 Logging train Loss: 7.40707e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.33116e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.87264e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.98048e-05 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 7.36846e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 7.47885e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 50.10623383522034
Epoch 2/9
	 Logging train Loss: 4.91076e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.77448e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.54088e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.60438e-05 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 4.65619e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.7587e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 49.37147307395935
Epoch 3/9
	 Logging train Loss: 2.56276e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.6758e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.9472e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 7.1562e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.44061e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.53486e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 48.90322518348694
Epoch 4/9
	 Logging train Loss: 1.49308e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.49867e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.6043e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.7663e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.57419e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.77831e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 49.667874813079834
Epoch 5/9
	 Logging train Loss: 1.69125e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 9.1786e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 9.28e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.027e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.59731e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone â–ˆâ–†â–„â–‚â–‚â–â–â–†â–‚â–‚
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone â–ˆâ–†â–„â–‚â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone â–ˆâ–†â–„â–‚â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone â–‡â–…â–ƒâ–‚â–‚â–â–â–ˆâ–‚â–‚
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone â–‡â–…â–ƒâ–‚â–‚â–â–â–ˆâ–‚â–‚
wandb:                                   Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone 2e-05
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 3e-05
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 3e-05
wandb:                                   Train loss 2e-05
wandb: 
wandb: ðŸš€ View run iconic-sky-280 at: https://wandb.ai/nreints/ThesisFinal1/runs/9o4dnrp8
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_175642-9o4dnrp8/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_180731-8zyog5od
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run robust-frost-313
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal1/runs/8zyog5od
	 Logging test loss: 1.67977e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 51.20303535461426
Epoch 6/9
	 Logging train Loss: 1.72188e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.28594e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.0944e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.1741e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.09892e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.24446e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 50.83740973472595
Epoch 7/9
	 Logging train Loss: 1.85762e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.39908e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.7803e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.8215e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0001112289 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0001259763 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 49.60013008117676
Epoch 8/9
	 Logging train Loss: 1.71941e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.88653e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.8585e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.9406e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.05237e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.26152e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 50.185654401779175
Epoch 9/9
	 Logging train Loss: 1.66012e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.74098e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.3708e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.4291e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.03661e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.32813e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 49.88538479804993
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gNone/'dual_quat_1'_'False'.pth
It took  649.5721695423126  seconds.
----- ITERATION 9/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 60.70425605773926 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 15.258917093276978 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 15.289109706878662 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_none_pNone_gNone took 15.257458925247192 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 15.186808586120605 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 15.15773630142212 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0406998992 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0001024501 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.453e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 7.24725e-05 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.000127961 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0001262939 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 49.800514936447144
Epoch 1/9
	 Logging train Loss: 7.75797e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.5347e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.50813e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 5.39636e-05 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 7.38574e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 7.44432e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 49.24156999588013
Epoch 2/9
	 Logging train Loss: 5.13127e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.30298e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.44669e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.38633e-05 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 4.99102e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.99707e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 49.8503520488739
Epoch 3/9
	 Logging train Loss: 3.20129e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.74023e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.67432e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.65396e-05 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.60432e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.62805e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 52.85231113433838
Epoch 4/9
	 Logging train Loss: 1.86705e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.60604e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.9878e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.9953e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.59187e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.548e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 50.615687131881714
Epoch 5/9
	 Logging train Loss: 1.37866e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.14191e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.5538e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.6185e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.78743e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.7956e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 50.42741274833679
Epoch 6/9
	 Logging train Loss: 1.6824e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.79986e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.5977e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.6578e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.27978e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.36439e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 50.0329749584198
Epoch 7/9
	 Logging train Loss: 1.705e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.26429e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.5144e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.5665e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.23769e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.21869e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 50.73271059989929
Epoch 8/9
	 Logging train Loss: 1.67376e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.70087e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.00472e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.00948e-05 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 4.2421e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.25028e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 50.04467844963074
Epoch 9/9
	 Logging train Loss: 1.43174e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone â–ˆâ–…â–ƒâ–‚â–â–‚â–â–â–‚â–‚
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone â–ˆâ–†â–„â–‚â–â–â–â–â–‚â–
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone â–ˆâ–†â–„â–‚â–â–â–â–â–‚â–
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone â–ˆâ–„â–ƒâ–‚â–â–‚â–‚â–â–‚â–‚
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone â–ˆâ–…â–ƒâ–‚â–â–‚â–‚â–â–‚â–‚
wandb:                                   Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone 2e-05
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 3e-05
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 3e-05
wandb:                                   Train loss 1e-05
wandb: 
wandb: ðŸš€ View run robust-frost-313 at: https://wandb.ai/nreints/ThesisFinal1/runs/8zyog5od
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_180731-8zyog5od/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_181827-mrr1092x
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run generous-paper-334
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal1/runs/mrr1092x
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone â–ˆâ–…â–ƒâ–‚â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone â–ˆâ–†â–ƒâ–‚â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone â–ˆâ–†â–ƒâ–‚â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone â–ˆâ–…â–ƒâ–‚â–â–â–‚â–â–‚â–
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone â–ˆâ–…â–ƒâ–‚â–â–â–‚â–â–‚â–
wandb:                                   Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone 1e-05
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 1e-05
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 1e-05
wandb:                                   Train loss 2e-05
wandb: 
wandb: ðŸš€ View run generous-paper-334 at: https://wandb.ai/nreints/ThesisFinal1/runs/mrr1092x
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_181827-mrr1092x/logs
	 Logging test loss: 1.92088e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.0335e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.0469e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.37432e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.49168e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 50.10939145088196
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gNone/'dual_quat_1'_'False'.pth
It took  655.2797291278839  seconds.
----- ITERATION 10/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 60.51128959655762 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 15.178161859512329 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 15.168833494186401 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_none_pNone_gNone took 15.194831848144531 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 15.166494369506836 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 15.138916969299316 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.019852994 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 9.36203e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.90577e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 7.84689e-05 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.000115295 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0001134478 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 49.653350830078125
Epoch 1/9
	 Logging train Loss: 7.97644e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.86831e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.28842e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 5.25272e-05 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 7.02431e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 6.8673e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 50.74542021751404
Epoch 2/9
	 Logging train Loss: 4.78642e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.17888e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.5028e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.53256e-05 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 4.12406e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.00583e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 50.36564493179321
Epoch 3/9
	 Logging train Loss: 2.20141e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.29319e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.244e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 6.4277e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.10628e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.99278e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 49.39565849304199
Epoch 4/9
	 Logging train Loss: 9.9621e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.2584e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.2186e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.3084e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.61676e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.50952e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 49.872026205062866
Epoch 5/9
	 Logging train Loss: 1.05147e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.8751e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.807e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 5.856e-07 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.41327e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.30911e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 50.69917130470276
Epoch 6/9
	 Logging train Loss: 1.86392e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.00444e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.9592e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.0647e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.85168e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.77838e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 50.83987379074097
Epoch 7/9
	 Logging train Loss: 1.84564e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.7928e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.83e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 5.568e-07 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.17829e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.10497e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 49.483038663864136
Epoch 8/9
	 Logging train Loss: 1.65488e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 9.4721e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 9.157e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 9.944e-07 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.82634e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.76197e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 52.47110652923584
Epoch 9/9
	 Logging train Loss: 1.66396e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.0461e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.509e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 8.118e-07 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 9.8875e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 9.2717e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 49.955156326293945
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gNone/'dual_quat_1'_'False'.pth
It took  654.6904418468475  seconds.

JOB STATISTICS
==============
Job ID: 2971275
Array Job ID: 2971258_17
Cluster: snellius
User/Group: nreints/nreints
State: RUNNING
Nodes: 1
Cores per node: 18
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 1-08:40:48 core-walltime
Job Wall-clock time: 01:48:56
Memory Utilized: 0.00 MB (estimated maximum)
Memory Efficiency: 0.00% of 0.00 MB (0.00 MB/node)
WARNING: Efficiency statistics may be misleading for RUNNING jobs.
