wandb: Currently logged in as: nreints. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_180136-shj9vlno
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run curious-aardvark-919
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/shj9vlno
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue █▄▃▂▂▂▁▁▁▁
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue █▂▂▂▁▁▁▁▁▁
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue █▃▂▂▁▁▁▁▁▁
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue █▅▃▄▂▂▂▁▁▁
wandb:                                 Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue 0.00129
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 5e-05
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.00079
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.00202
wandb:                                 Train loss 0.00098
wandb: 
wandb: 🚀 View run curious-aardvark-919 at: https://wandb.ai/nreints/ThesisFinal2/runs/shj9vlno
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_180136-shj9vlno/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_181038-cr19b6d4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pleasant-firefly-943
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/cr19b6d4
Training on dataset: data_t(0,0)_r(0,0)_combi_pTrue_gTrue
Testing on 4 datasets: ['data_t(0,0)_r(0,0)_full_pTrue_gTrue', 'data_t(0,0)_r(0,0)_tennis_pTrue_gTrue', 'data_t(0,0)_r(0,0)_semi_pTrue_gTrue', 'data_t(0,0)_r(0,0)_combi_pTrue_gTrue']
Focussing on identity: False
Using extra input: True
Using start-fr as reference point.
----- ITERATION 1/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 86.28199863433838 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 21.71979260444641 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 21.884910106658936 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 22.17055630683899 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 22.0086727142334 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (pre_hidden_lin_layer): Sequential(
    (0): Linear(in_features=3, out_features=96, bias=True)
    (1): ReLU()
    (2): Linear(in_features=96, out_features=96, bias=True)
    (3): ReLU()
  )
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.1032744199 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0024804256 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0211676285 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0112240193 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0157369468 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 35.61739134788513
Epoch 1/9
	 Logging train Loss: 0.006634939 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0004099159 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0135691063 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0031940963 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0073612109 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 33.94162917137146
Epoch 2/9
	 Logging train Loss: 0.0043707578 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0002410582 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0084795021 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0020008336 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0054927887 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 33.64232921600342
Epoch 3/9
	 Logging train Loss: 0.0024912194 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0002242361 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0096399225 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0016807558 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0041651861 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 34.00012540817261
Epoch 4/9
	 Logging train Loss: 0.0023907088 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0001380224 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0058354284 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0012332492 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0035569996 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 34.744110345840454
Epoch 5/9
	 Logging train Loss: 0.0009391914 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 8.04485e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.005736859 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0010012925 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0027851781 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 34.68713116645813
Epoch 6/9
	 Logging train Loss: 0.0016431591 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 6.42067e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0036782469 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0010017807 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0021016439 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 34.70658016204834
Epoch 7/9
	 Logging train Loss: 0.0027502761 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 6.10908e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0033193014 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0008625612 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0019073334 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 34.60653638839722
Epoch 8/9
	 Logging train Loss: 0.0005526866 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 3.81124e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0026345239 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0007919244 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.001536685 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 34.52916073799133
Epoch 9/9
	 Logging train Loss: 0.0009841759 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 5.28559e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0020204075 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0007867002 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0012899821 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 34.78950262069702
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pTrue_gTrue/'dual_quat'_'True'.pth
It took  543.8471477031708  seconds.
----- ITERATION 2/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 80.1154887676239 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 20.091811418533325 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 20.09664535522461 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 20.117744207382202 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 20.09197211265564 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (pre_hidden_lin_layer): Sequential(
    (0): Linear(in_features=3, out_features=96, bias=True)
    (1): ReLU()
    (2): Linear(in_features=96, out_features=96, bias=True)
    (3): ReLU()
  )
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.060252998 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0005583396 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0231328197 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0200878326 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.01667054 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 33.73330545425415
Epoch 1/9
	 Logging train Loss: 0.0048515671 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0004157624 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0096733775 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0125106005 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0108222235 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 34.17471265792847
Epoch 2/9
	 Logging train Loss: 0.0013450044 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0001099809 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0033046426 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0052799941 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0045233355 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 33.92508864402771
Epoch 3/9
wandb: Waiting for W&B process to finish... (success).
wandb: ERROR Error while calling W&B API: An internal error occurred. Please contact support. (<Response [500]>)
wandb: 
wandb: Run history:
wandb:                                      Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue █▅▃▃▂▂▁▂▁▁
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue █▆▂▂▃▁▁▂▁▁
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue █▅▃▃▂▂▁▂▁▁
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue █▄▁▂▂▁▁▂▁▁
wandb:                                 Train loss █▂▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue 0.00068
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 5e-05
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.00118
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.00214
wandb:                                 Train loss 0.00057
wandb: 
wandb: 🚀 View run pleasant-firefly-943 at: https://wandb.ai/nreints/ThesisFinal2/runs/cr19b6d4
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_181038-cr19b6d4/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_181914-0oge67rf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run upbeat-darkness-966
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/0oge67rf
	 Logging train Loss: 0.0039945631 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0001468512 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0042142081 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0061430889 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0054843179 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 33.722362995147705
Epoch 4/9
	 Logging train Loss: 0.000897481 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0002163477 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0053465599 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0043005235 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0035694879 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 33.66206216812134
Epoch 5/9
	 Logging train Loss: 0.0014229912 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 6.91145e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0035309433 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0028247701 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0020808587 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 33.685166120529175
Epoch 6/9
	 Logging train Loss: 0.0009303031 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 4.40448e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0024696745 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0016648805 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0011234664 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 34.26268768310547
Epoch 7/9
	 Logging train Loss: 0.0014777548 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0001212987 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0065492988 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0026517308 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0023926997 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 34.6394157409668
Epoch 8/9
	 Logging train Loss: 0.0004991093 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 3.60447e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0021477973 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0013280209 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0009027302 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 34.60549759864807
Epoch 9/9
	 Logging train Loss: 0.0005732084 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 4.78232e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0021366118 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0011784347 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0006836026 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 34.646992683410645
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pTrue_gTrue/'dual_quat'_'True'.pth
It took  515.8673207759857  seconds.
----- ITERATION 3/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 80.3352746963501 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 20.126325130462646 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 20.034014225006104 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 20.09033226966858 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 20.115095138549805 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (pre_hidden_lin_layer): Sequential(
    (0): Linear(in_features=3, out_features=96, bias=True)
    (1): ReLU()
    (2): Linear(in_features=96, out_features=96, bias=True)
    (3): ReLU()
  )
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0527108088 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0001510417 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.1479007006 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0552621 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0603083707 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 34.327566385269165
Epoch 1/9
	 Logging train Loss: 0.0003923565 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 7.55372e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.2720090747 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0708575696 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0752993301 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 34.94697165489197
Epoch 2/9
	 Logging train Loss: 0.0002340655 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 3.96836e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.1837583482 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0780066177 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.082447432 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 33.92983627319336
Epoch 3/9
	 Logging train Loss: 0.0002117994 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 7.40784e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.1348061711 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.093165338 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0964033827 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 33.79526901245117
Epoch 4/9
	 Logging train Loss: 0.0002436385 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 5.70253e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.1547936946 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0769271404 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0794005319 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 33.36590361595154
Epoch 5/9
	 Logging train Loss: 0.0002749416 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 5.9119e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.168166101 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0626085773 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0657353252 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 33.74865698814392
Epoch 6/9
	 Logging train Loss: 0.0001639257 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 8.59763e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.1996711046 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0807651877 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0842102244 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 33.74941682815552
Epoch 7/9
	 Logging train Loss: 0.0002568159 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0003030915 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0768710524 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0934286341 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0933476388 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 34.04874658584595
Epoch 8/9
	 Logging train Loss: 0.0001101473 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 3.38367e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.1361083686 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0735082477 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0768626258 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 34.825770139694214
Epoch 9/9
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue ▁▄▅█▅▂▆▇▄▃
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue ▄▂▂▂▂▂▃█▁▁
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue ▁▄▅█▅▂▆█▄▃
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue ▄█▅▃▄▄▅▁▃▂
wandb:                                 Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue 0.07077
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 2e-05
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.06751
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.09519
wandb:                                 Train loss 0.00017
wandb: 
wandb: 🚀 View run upbeat-darkness-966 at: https://wandb.ai/nreints/ThesisFinal2/runs/0oge67rf
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_181914-0oge67rf/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_182749-e1yzhf8o
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run desert-capybara-987
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/e1yzhf8o
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue █▃▂▃▁▂▁▁▂▁
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue █▃▂▄▁▁▁▁▁▁
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue █▄▃▇▂▂▁▁▂▁
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue █▅▃▅▂▂▁▁▂▁
wandb:                                 Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue 0.00026
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 6e-05
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.00114
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.00142
wandb:                                 Train loss 0.00069
wandb: 
wandb: 🚀 View run desert-capybara-987 at: https://wandb.ai/nreints/ThesisFinal2/runs/e1yzhf8o
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_182749-e1yzhf8o/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_183625-90tocd74
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run clear-cloud-1010
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/90tocd74
	 Logging train Loss: 0.0001727209 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.81243e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0951883793 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0675146803 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0707691163 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 34.74937868118286
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pTrue_gTrue/'dual_quat'_'True'.pth
It took  514.9417705535889  seconds.
----- ITERATION 4/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 80.54666829109192 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 20.02261710166931 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 20.174133777618408 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 20.05893111228943 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 20.128241777420044 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (pre_hidden_lin_layer): Sequential(
    (0): Linear(in_features=3, out_features=96, bias=True)
    (1): ReLU()
    (2): Linear(in_features=96, out_features=96, bias=True)
    (3): ReLU()
  )
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.1245736629 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0009035034 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0230045561 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0182211958 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0048770462 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 34.68782663345337
Epoch 1/9
	 Logging train Loss: 0.0048868833 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0003281585 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0133563215 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.009242964 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0015551575 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 34.53682470321655
Epoch 2/9
	 Logging train Loss: 0.002875569 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0001767292 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0073660281 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.005920697 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0012382681 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 34.39560604095459
Epoch 3/9
	 Logging train Loss: 0.0016990423 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.000468109 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0135263074 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0149045018 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0016827068 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 34.009233713150024
Epoch 4/9
	 Logging train Loss: 0.0021068698 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 7.01546e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0041629057 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0029466443 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0005840334 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 33.90215063095093
Epoch 5/9
	 Logging train Loss: 0.0008239352 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 6.1253e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0039001128 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0030085254 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0006672151 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 33.48863434791565
Epoch 6/9
	 Logging train Loss: 0.0008900941 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 9.53155e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0028598979 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0022929565 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0005853262 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 33.59662866592407
Epoch 7/9
	 Logging train Loss: 0.0008547364 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 4.16268e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0018517604 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0020502075 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0003777282 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 33.40727353096008
Epoch 8/9
	 Logging train Loss: 0.0010268429 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 9.21779e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0048912875 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0041897614 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0007799934 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 33.876988649368286
Epoch 9/9
	 Logging train Loss: 0.0006903101 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 5.62626e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0014230185 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.001141032 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0002565467 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 34.82521367073059
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pTrue_gTrue/'dual_quat'_'True'.pth
It took  515.790602684021  seconds.
----- ITERATION 5/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 80.06738257408142 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 20.026970624923706 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 19.983561754226685 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 19.99697208404541 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 20.06784749031067 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (pre_hidden_lin_layer): Sequential(
    (0): Linear(in_features=3, out_features=96, bias=True)
    (1): ReLU()
    (2): Linear(in_features=96, out_features=96, bias=True)
    (3): ReLU()
  )
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0622807555 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0002555897 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0041314233 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.072262831 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0619265884 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 34.12984323501587
Epoch 1/9
	 Logging train Loss: 0.0038034867 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0028704272 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0395905524 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.1216230616 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0681906939 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 34.22780203819275
Epoch 2/9
	 Logging train Loss: 0.0019769017 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0028150494 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0407060385 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue ▆▇█▆▄▄▃▂▂▁
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue ▂██▁▁▁▁▁▁▁
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue ▄██▄▃▃▂▂▁▁
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue ▂██▁▁▁▁▁▁▁
wandb:                                 Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue 0.02694
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 2e-05
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.02934
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.00107
wandb:                                 Train loss 0.00142
wandb: 
wandb: 🚀 View run clear-cloud-1010 at: https://wandb.ai/nreints/ThesisFinal2/runs/90tocd74
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_183625-90tocd74/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_184454-i7jm4dy1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glamorous-gorge-1032
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/i7jm4dy1
	 Logging test loss: 0.1181738079 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0757859498 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 34.374499797821045
Epoch 3/9
	 Logging train Loss: 0.0021996119 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 4.40693e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0018911369 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0668936893 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0621634126 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 33.81105637550354
Epoch 4/9
	 Logging train Loss: 0.0014706352 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 6.65939e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0020089415 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0546437427 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0504296422 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 33.60151147842407
Epoch 5/9
	 Logging train Loss: 0.00098672 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 3.74029e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0017964005 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0536836013 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0501864217 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 32.92422032356262
Epoch 6/9
	 Logging train Loss: 0.0008737606 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 4.06858e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.001405218 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0443172567 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0417957045 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 32.458797454833984
Epoch 7/9
	 Logging train Loss: 0.0012933 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.98509e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.001210382 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0374441147 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0351443775 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 33.44204640388489
Epoch 8/9
	 Logging train Loss: 0.0001833257 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 3.2573e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0013271699 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0358501114 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0330517776 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 33.4922935962677
Epoch 9/9
	 Logging train Loss: 0.0014172071 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.42285e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0010725694 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0293432251 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0269375071 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 33.28076720237732
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pTrue_gTrue/'dual_quat'_'True'.pth
It took  509.1511342525482  seconds.
----- ITERATION 6/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 80.8167576789856 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 20.21770477294922 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 20.278679370880127 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 20.190898418426514 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 20.113696575164795 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (pre_hidden_lin_layer): Sequential(
    (0): Linear(in_features=3, out_features=96, bias=True)
    (1): ReLU()
    (2): Linear(in_features=96, out_features=96, bias=True)
    (3): ReLU()
  )
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0909764841 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0006409736 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0558420718 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0388879441 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0445703268 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 34.220388412475586
Epoch 1/9
	 Logging train Loss: 0.0036173903 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0004898541 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0161232445 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0171782207 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0103887785 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 34.28694152832031
Epoch 2/9
	 Logging train Loss: 0.0115199266 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0006669546 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0255418085 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0205090437 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0157442968 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 34.026140213012695
Epoch 3/9
	 Logging train Loss: 0.0010681319 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 8.3936e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0068801208 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0092858346 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0037739917 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 34.13244867324829
Epoch 4/9
	 Logging train Loss: 0.0009595614 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 6.80964e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0062504592 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0072559621 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.00340017 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 34.10782504081726
Epoch 5/9
	 Logging train Loss: 0.0007361923 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 6.81786e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0065674679 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0070254542 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0036177642 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 34.07131481170654
Epoch 6/9
	 Logging train Loss: 0.0026198472 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 4.54616e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0054106759 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0060705682 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0029165533 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 33.46764826774597
Epoch 7/9
	 Logging train Loss: 0.0002096441 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 5.76293e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0060628238 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0057748412 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0028513926 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 33.530272245407104
Epoch 8/9
	 Logging train Loss: 0.0006274868 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 4.09886e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0038849015 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue █▂▃▁▁▁▁▁▁▁
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue █▆█▁▁▁▁▁▁▁
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue █▄▄▂▂▂▁▁▁▁
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue █▃▄▁▁▁▁▁▁▁
wandb:                                 Train loss █▁▂▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue 0.00221
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 6e-05
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.00412
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.00403
wandb:                                 Train loss 0.00125
wandb: 
wandb: 🚀 View run glamorous-gorge-1032 at: https://wandb.ai/nreints/ThesisFinal2/runs/i7jm4dy1
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_184454-i7jm4dy1/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_185327-u0nrlztg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fallen-elevator-1051
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/u0nrlztg
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue ▃█▁▁▁▁▁▁▁▁
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue ▃█▂▁▁▁▁▁▁▁
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue ▃█▂▁▁▁▁▁▁▁
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue ██▂▂▁▂▁▁▁▁
wandb:                                 Train loss █▁▁▁▁▂▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue 0.00024
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 8e-05
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.00381
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.00305
wandb:                                 Train loss 0.00085
wandb: 
wandb: 🚀 View run fallen-elevator-1051 at: https://wandb.ai/nreints/ThesisFinal2/runs/u0nrlztg
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_185327-u0nrlztg/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_190200-c3ypxjmo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vivid-morning-1071
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/c3ypxjmo
	 Logging test loss: 0.0039374833 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0020015435 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 33.553417682647705
Epoch 9/9
	 Logging train Loss: 0.0012506016 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 6.22145e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0040331334 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0041218409 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0022091432 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 33.13809013366699
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pTrue_gTrue/'dual_quat'_'True'.pth
It took  513.0731379985809  seconds.
----- ITERATION 7/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 80.50210642814636 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 20.113543272018433 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 20.089024543762207 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 20.231839179992676 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 20.24000120162964 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (pre_hidden_lin_layer): Sequential(
    (0): Linear(in_features=3, out_features=96, bias=True)
    (1): ReLU()
    (2): Linear(in_features=96, out_features=96, bias=True)
    (3): ReLU()
  )
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0970839188 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0011492722 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0401962213 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0263151899 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0041862992 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 33.93633055686951
Epoch 1/9
	 Logging train Loss: 0.0040589636 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0038100646 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0397661366 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0767546743 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0186539907 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 34.184393882751465
Epoch 2/9
	 Logging train Loss: 0.0036567911 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0003584932 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0099649914 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0142641952 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.001375556 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 34.2161283493042
Epoch 3/9
	 Logging train Loss: 0.0023534999 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 8.87996e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0057090032 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0056394157 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0003444675 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 34.086021900177
Epoch 4/9
	 Logging train Loss: 0.000829624 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 7.16736e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0039313473 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0054400982 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0003344257 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 34.032209396362305
Epoch 5/9
	 Logging train Loss: 0.0092468131 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 7.80012e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.005771298 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0064156302 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0003608492 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 33.96541929244995
Epoch 6/9
	 Logging train Loss: 0.0005656493 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 6.34275e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.004463091 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0052914103 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0002589927 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 34.4254891872406
Epoch 7/9
	 Logging train Loss: 0.0012242377 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 5.0562e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0038008303 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.004421982 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0002200099 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 33.38193130493164
Epoch 8/9
	 Logging train Loss: 0.0005880927 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 4.03132e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0030984692 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.003716429 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0001529084 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 33.33856797218323
Epoch 9/9
	 Logging train Loss: 0.0008486514 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 8.32466e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.00304807 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0038139164 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0002365939 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 32.91559648513794
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pTrue_gTrue/'dual_quat'_'True'.pth
It took  513.0081100463867  seconds.
----- ITERATION 8/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 80.65509247779846 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 20.18783950805664 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 20.228468894958496 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 20.199543476104736 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 20.085758924484253 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (pre_hidden_lin_layer): Sequential(
    (0): Linear(in_features=3, out_features=96, bias=True)
    (1): ReLU()
    (2): Linear(in_features=96, out_features=96, bias=True)
    (3): ReLU()
  )
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.1290785521 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0025359481 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0870568529 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0426486954 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0337731354 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 34.029030084609985
Epoch 1/9
	 Logging train Loss: 0.007660693 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0003797415 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0567431077 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0159624685 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0164826326 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 34.19928431510925
Epoch 2/9
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue █▄▂▂▁▁▁▁▁▁
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue █▂▂▁▁▁▁▁▁▁
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue █▃▃▂▁▁▁▁▁▁
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue █▅▃▂▁▁▁▁▁▁
wandb:                                 Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue 0.00502
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 4e-05
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.00162
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.01638
wandb:                                 Train loss 0.00449
wandb: 
wandb: 🚀 View run vivid-morning-1071 at: https://wandb.ai/nreints/ThesisFinal2/runs/c3ypxjmo
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_190200-c3ypxjmo/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_191034-2h2wulvl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sunny-morning-1088
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/2h2wulvl
	 Logging train Loss: 0.0019372865 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0002898341 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0363470241 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0139761241 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0100278296 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 34.14872431755066
Epoch 3/9
	 Logging train Loss: 0.0017144724 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 8.38814e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0270332545 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0063223164 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0074434816 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 34.37929821014404
Epoch 4/9
	 Logging train Loss: 0.0011977103 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 5.15485e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.020939298 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0041991896 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0056568426 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 33.93838810920715
Epoch 5/9
	 Logging train Loss: 0.0011918164 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0001603121 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.018607134 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0035277784 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0050545689 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 34.401225566864014
Epoch 6/9
	 Logging train Loss: 0.0014780721 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 3.36392e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0190719757 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.002691119 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0050547114 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 33.90409517288208
Epoch 7/9
	 Logging train Loss: 0.0008173276 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.56267e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0179439653 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0018575597 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0054329503 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 34.28832960128784
Epoch 8/9
	 Logging train Loss: 0.0008726335 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 3.73136e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0177804846 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0019011459 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0060491944 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 33.373634338378906
Epoch 9/9
	 Logging train Loss: 0.004490193 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 3.57734e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0163837802 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0016212829 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0050177118 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 33.470200538635254
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pTrue_gTrue/'dual_quat'_'True'.pth
It took  513.4359827041626  seconds.
----- ITERATION 9/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 80.879812002182 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 20.00450325012207 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 20.144277572631836 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 20.30682134628296 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 20.186842441558838 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (pre_hidden_lin_layer): Sequential(
    (0): Linear(in_features=3, out_features=96, bias=True)
    (1): ReLU()
    (2): Linear(in_features=96, out_features=96, bias=True)
    (3): ReLU()
  )
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0339232758 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0001559951 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0347805172 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0671889409 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0620417483 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 33.8123779296875
Epoch 1/9
	 Logging train Loss: 0.0009220588 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 5.62146e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0138659095 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0382559933 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0376358852 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 34.10547971725464
Epoch 2/9
	 Logging train Loss: 0.0004862973 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0001500228 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0260067564 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0412753299 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0395374037 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 33.909950733184814
Epoch 3/9
	 Logging train Loss: 0.0007105145 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 4.58479e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0076486487 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.017994564 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0176566616 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 34.328186988830566
Epoch 4/9
	 Logging train Loss: 0.0002686722 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 4.17473e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0079651056 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0161744747 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0160581283 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 33.91656494140625
Epoch 5/9
	 Logging train Loss: 0.0008631462 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.45934e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0071252049 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0145748677 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0143218664 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 34.17407822608948
Epoch 6/9
	 Logging train Loss: 7.80591e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.76743e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0064825062 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0125730056 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0124345478 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 34.01242446899414
Epoch 7/9
	 Logging train Loss: 0.0001927539 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 5.19764e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0084264101 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0149883917 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0142947324 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 34.06561255455017
Epoch 8/9
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue █▅▅▂▂▂▁▂▁▁
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue █▃█▂▂▁▁▂▁▁
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue █▅▅▂▂▂▁▂▁▁
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue █▃▆▂▂▂▁▂▁▁
wandb:                                 Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue 0.00886
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 3e-05
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.00905
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.0063
wandb:                                 Train loss 0.00029
wandb: 
wandb: 🚀 View run sunny-morning-1088 at: https://wandb.ai/nreints/ThesisFinal2/runs/2h2wulvl
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_191034-2h2wulvl/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_191912-eawyzhm4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run chocolate-sea-1103
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/eawyzhm4
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue █▂▂▁▁▁▁▁▁▁
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue █▂▁▁▁▁▁▁▁▁
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue █▃▂▂▂▁▂▁▁▁
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue █▄▃▂▂▂▂▁▁▁
wandb:                                 Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue 8e-05
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 4e-05
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.00103
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.00587
wandb:                                 Train loss 0.00014
wandb: 
wandb: 🚀 View run chocolate-sea-1103 at: https://wandb.ai/nreints/ThesisFinal2/runs/eawyzhm4
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_191912-eawyzhm4/logs
	 Logging train Loss: 0.0003178018 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 3.31238e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0043950463 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0101247206 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0100885173 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 34.151047468185425
Epoch 9/9
	 Logging train Loss: 0.0002912811 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.85447e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0062982277 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0090455376 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0088633178 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 34.116936683654785
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pTrue_gTrue/'dual_quat'_'True'.pth
It took  518.2617983818054  seconds.
----- ITERATION 10/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 80.68562698364258 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 20.262240648269653 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 20.11677122116089 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 20.099074363708496 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 20.104788064956665 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (pre_hidden_lin_layer): Sequential(
    (0): Linear(in_features=3, out_features=96, bias=True)
    (1): ReLU()
    (2): Linear(in_features=96, out_features=96, bias=True)
    (3): ReLU()
  )
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.1619234234 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0010086085 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0991560668 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0149497986 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0024552252 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 34.43388748168945
Epoch 1/9
	 Logging train Loss: 0.0038550145 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0001893623 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0437270589 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.004258377 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.000566028 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 33.905569314956665
Epoch 2/9
	 Logging train Loss: 0.002500863 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 8.66237e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0269390307 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.003798129 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0003135664 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 34.12488865852356
Epoch 3/9
	 Logging train Loss: 0.0015142408 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 6.86422e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0180904921 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0022995833 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0002182131 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 33.88154578208923
Epoch 4/9
	 Logging train Loss: 0.0016364082 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 4.98865e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0154574197 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0029049776 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0001679781 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 34.323683738708496
Epoch 5/9
	 Logging train Loss: 0.0013387095 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 4.16975e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.013217804 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0017867901 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0001321123 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 34.288490533828735
Epoch 6/9
	 Logging train Loss: 0.000467684 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 5.77148e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0142528089 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0020384577 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0001892682 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 34.23710918426514
Epoch 7/9
	 Logging train Loss: 0.0017926347 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 3.95122e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0064315386 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0019467054 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0001154913 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 34.24288582801819
Epoch 8/9
	 Logging train Loss: 0.0009321211 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 4.09196e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.009394289 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0017181495 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0001101975 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 33.90207529067993
Epoch 9/9
	 Logging train Loss: 0.0001434893 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 4.05884e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0058715604 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0010254782 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 8.12076e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
		--> Epoch time; 34.249070167541504
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pTrue_gTrue/'dual_quat'_'True'.pth
It took  515.5424489974976  seconds.

JOB STATISTICS
==============
Job ID: 3037967
Array Job ID: 3037875_29
Cluster: snellius
User/Group: nreints/nreints
State: COMPLETED (exit code 0)
Nodes: 1
Cores per node: 18
CPU Utilized: 01:34:02
CPU Efficiency: 6.04% of 1-01:55:48 core-walltime
Job Wall-clock time: 01:26:26
Memory Utilized: 7.71 GB
Memory Efficiency: 0.00% of 0.00 MB
