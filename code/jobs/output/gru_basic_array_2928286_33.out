wandb: Currently logged in as: nreints. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230616_170815-7vlt1xsj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run apricot-snowball-60
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal/runs/7vlt1xsj
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb: Test loss t(5,20)_r(5,20)_combiR_pNone_gNone â–ˆâ–…â–„â–ƒâ–ƒâ–‚â–‚â–‚â–â–
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone â–ˆâ–‡â–‡â–†â–…â–„â–ƒâ–ƒâ–‚â–
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone â–ˆâ–…â–„â–ƒâ–ƒâ–‚â–‚â–â–â–
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone â–ˆâ–…â–„â–ƒâ–ƒâ–‚â–‚â–â–â–
wandb:                                   Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb: Test loss t(5,20)_r(5,20)_combiR_pNone_gNone 3e-05
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 1e-05
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 3e-05
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 3e-05
wandb:                                   Train loss 2e-05
wandb: 
wandb: ðŸš€ View run apricot-snowball-60 at: https://wandb.ai/nreints/ThesisFinal/runs/7vlt1xsj
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230616_170815-7vlt1xsj/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230616_171503-81g8m2bx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run iconic-gorge-64
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal/runs/81g8m2bx
Training on dataset: data_t(5,20)_r(5,20)_combiR_pNone_gNone
Testing on 4 datasets: ['data_t(5,20)_r(5,20)_tennis_pNone_gNone', 'data_t(5,20)_r(5,20)_semi_pNone_gNone', 'data_t(5,20)_r(5,20)_combiR_pNone_gNone', 'data_t(5,20)_r(5,20)_full_pNone_gNone']
Focussing on identity: False
Using extra input: None
Using fr-fr as reference point.
----- ITERATION 1/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  800
Number of test simulations:  200
The dataloader for data/data_t(5,20)_r(5,20)_combiR_pNone_gNone took 21.87654423713684 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 5.472895383834839 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 5.474102020263672 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_combiR_pNone_gNone took 5.464972972869873 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 5.493208885192871 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0605672635 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 0.0002155407 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0002247383 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0001865653 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 7.7936e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 36.01922965049744
Epoch 1/9
	 Logging train Loss: 0.0001384677 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 0.0001420786 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0001453087 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0001262471 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 7.16306e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 35.13186264038086
Epoch 2/9
	 Logging train Loss: 0.0001050115 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 0.0001090661 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0001114883 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 9.9307e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 6.65823e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 35.29546046257019
Epoch 3/9
	 Logging train Loss: 8.46404e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 8.65983e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 8.90338e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 8.02953e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 5.7796e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 35.24224281311035
Epoch 4/9
	 Logging train Loss: 7.0725e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 7.50838e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 7.59649e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 6.97325e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 5.18139e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 35.10618448257446
Epoch 5/9
	 Logging train Loss: 5.98296e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 6.15709e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 6.28666e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 5.75627e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 4.27337e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 35.12994742393494
Epoch 6/9
	 Logging train Loss: 4.9885e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 5.18623e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 5.30806e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.83133e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 3.36251e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 35.04875373840332
Epoch 7/9
	 Logging train Loss: 4.02475e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 4.30164e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.42186e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.98613e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 2.51145e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 35.0100793838501
Epoch 8/9
	 Logging train Loss: 3.10918e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 3.33798e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.46749e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.04678e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 1.6964e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 35.210246324539185
Epoch 9/9
	 Logging train Loss: 2.39451e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 3.01602e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.11441e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.62176e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 9.9936e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 35.230486154556274
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combiR_pNone_gNone/'quat_1'_'None'.pth
It took  408.8428246974945  seconds.
----- ITERATION 2/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  800
Number of test simulations:  200
The dataloader for data/data_t(5,20)_r(5,20)_combiR_pNone_gNone took 20.01122283935547 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 5.0810770988464355 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 5.082235813140869 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_combiR_pNone_gNone took 4.998125314712524 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 5.130763053894043 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0560763292 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 0.0002265841 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0002472994 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0001809811 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 7.80401e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 35.36279320716858
Epoch 1/9
	 Logging train Loss: 0.0001379926 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 0.0001356331 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.000144794 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0001146303 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 6.80973e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 35.25406002998352
Epoch 2/9
	 Logging train Loss: 9.69895e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 9.47927e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0001021136 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 8.38985e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 5.79953e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 35.22230529785156
Epoch 3/9
	 Logging train Loss: 7.37706e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb: Test loss t(5,20)_r(5,20)_combiR_pNone_gNone â–ˆâ–…â–ƒâ–ƒâ–‚â–‚â–â–â–â–‚
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone â–ˆâ–‡â–†â–…â–„â–ƒâ–ƒâ–‚â–‚â–
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone â–ˆâ–„â–ƒâ–‚â–‚â–‚â–â–â–‚â–‚
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone â–ˆâ–…â–ƒâ–‚â–‚â–‚â–â–â–‚â–‚
wandb:                                   Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb: Test loss t(5,20)_r(5,20)_combiR_pNone_gNone 6e-05
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 1e-05
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 8e-05
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 8e-05
wandb:                                   Train loss 3e-05
wandb: 
wandb: ðŸš€ View run iconic-gorge-64 at: https://wandb.ai/nreints/ThesisFinal/runs/81g8m2bx
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230616_171503-81g8m2bx/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230616_172147-b14cdlb2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run blooming-disco-70
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal/runs/b14cdlb2
	 Logging test loss: 7.94672e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 8.46318e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 7.11619e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 5.17893e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 35.15121817588806
Epoch 4/9
	 Logging train Loss: 5.99536e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 5.93359e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 6.49408e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 5.43309e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 4.1782e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 35.11812734603882
Epoch 5/9
	 Logging train Loss: 5.06012e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 6.47892e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 6.95937e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 5.56432e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 3.57668e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 35.04825973510742
Epoch 6/9
	 Logging train Loss: 4.37486e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 4.67835e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 5.09968e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.1534e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 2.96113e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 35.414801359176636
Epoch 7/9
	 Logging train Loss: 3.78322e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 4.09802e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.48555e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.60202e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 2.50278e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 35.172773122787476
Epoch 8/9
	 Logging train Loss: 3.24398e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 5.65766e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 6.14835e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.50473e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 1.89935e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 35.36433935165405
Epoch 9/9
	 Logging train Loss: 2.82916e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 7.99851e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 8.25546e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 5.95829e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 1.43856e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 35.341795682907104
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combiR_pNone_gNone/'quat_1'_'None'.pth
It took  404.7285752296448  seconds.
----- ITERATION 3/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  800
Number of test simulations:  200
The dataloader for data/data_t(5,20)_r(5,20)_combiR_pNone_gNone took 19.890249490737915 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 5.059977054595947 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 5.0706353187561035 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_combiR_pNone_gNone took 4.978985071182251 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 5.057497978210449 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.079214178 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 0.0002342273 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0002307777 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.000178508 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 8.53678e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 35.71025800704956
Epoch 1/9
	 Logging train Loss: 0.0001271125 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 0.0001173039 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0001208845 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0001025367 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 7.19148e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 41.07680153846741
Epoch 2/9
	 Logging train Loss: 9.54116e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 9.49028e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 9.84088e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 8.51987e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 6.38787e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 39.08807826042175
Epoch 3/9
	 Logging train Loss: 7.97126e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 7.97727e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 8.30081e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 7.24761e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 5.60007e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 35.32949256896973
Epoch 4/9
	 Logging train Loss: 6.78327e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 7.00718e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 7.2673e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 6.34058e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 4.98125e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 35.27637028694153
Epoch 5/9
	 Logging train Loss: 5.783e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 5.97899e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 6.15854e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 5.31733e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 4.01731e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 35.44935703277588
Epoch 6/9
	 Logging train Loss: 4.86611e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 5.02457e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 5.13021e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.39632e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 3.18745e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 35.166008710861206
Epoch 7/9
	 Logging train Loss: 4.0102e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 4.24462e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.30299e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.58664e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 2.4058e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 35.39183831214905
Epoch 8/9
	 Logging train Loss: 3.23363e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 3.56454e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.55422e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.89397e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 1.74822e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 35.21092891693115
Epoch 9/9
	 Logging train Loss: 2.56814e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb: Test loss t(5,20)_r(5,20)_combiR_pNone_gNone â–ˆâ–…â–„â–ƒâ–ƒâ–‚â–‚â–‚â–â–
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone â–ˆâ–‡â–†â–…â–…â–„â–ƒâ–‚â–‚â–
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone â–ˆâ–„â–ƒâ–ƒâ–‚â–‚â–‚â–â–â–
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone â–ˆâ–„â–ƒâ–ƒâ–‚â–‚â–‚â–â–â–
wandb:                                   Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb: Test loss t(5,20)_r(5,20)_combiR_pNone_gNone 2e-05
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 1e-05
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 3e-05
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 3e-05
wandb:                                   Train loss 3e-05
wandb: 
wandb: ðŸš€ View run blooming-disco-70 at: https://wandb.ai/nreints/ThesisFinal/runs/b14cdlb2
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230616_172147-b14cdlb2/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230616_172842-3k5b6nfc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run bumbling-morning-76
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal/runs/3k5b6nfc
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb: Test loss t(5,20)_r(5,20)_combiR_pNone_gNone â–ˆâ–†â–…â–„â–ƒâ–ƒâ–‚â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone â–ˆâ–‡â–†â–…â–„â–ƒâ–ƒâ–‚â–â–
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone â–ˆâ–†â–„â–„â–ƒâ–ƒâ–‚â–â–â–
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone â–ˆâ–…â–„â–ƒâ–ƒâ–ƒâ–‚â–â–â–
wandb:                                   Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb: Test loss t(5,20)_r(5,20)_combiR_pNone_gNone 3e-05
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 1e-05
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 3e-05
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 4e-05
wandb:                                   Train loss 2e-05
wandb: 
wandb: ðŸš€ View run bumbling-morning-76 at: https://wandb.ai/nreints/ThesisFinal/runs/3k5b6nfc
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230616_172842-3k5b6nfc/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230616_173528-vs70qqdk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run trim-hill-81
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal/runs/vs70qqdk
	 Logging test loss: 3.10306e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.9706e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.33261e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 1.19233e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 35.340628147125244
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combiR_pNone_gNone/'quat_1'_'None'.pth
It took  414.76211190223694  seconds.
----- ITERATION 4/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  800
Number of test simulations:  200
The dataloader for data/data_t(5,20)_r(5,20)_combiR_pNone_gNone took 20.017780303955078 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 5.062454700469971 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 5.079027891159058 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_combiR_pNone_gNone took 4.981449604034424 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 5.08508563041687 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0204962101 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 0.0001458505 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0001351137 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0001255999 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 7.75902e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 35.09857130050659
Epoch 1/9
	 Logging train Loss: 9.89325e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 0.0001046078 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 9.85955e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 9.33804e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 6.34735e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 35.55929493904114
Epoch 2/9
	 Logging train Loss: 7.73039e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 8.57742e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 8.11234e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 7.79017e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 5.25043e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 35.15104913711548
Epoch 3/9
	 Logging train Loss: 6.37097e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 7.02362e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 6.65869e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 6.31914e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 4.33872e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 35.24319362640381
Epoch 4/9
	 Logging train Loss: 5.34317e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 6.0368e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 5.66101e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 5.45401e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 3.58532e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 35.397106647491455
Epoch 5/9
	 Logging train Loss: 4.48989e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 5.79795e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 5.48314e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 5.07124e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 2.83452e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 35.371357679367065
Epoch 6/9
	 Logging train Loss: 3.72095e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 5.01853e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.6816e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.28376e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 2.16029e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 35.3444139957428
Epoch 7/9
	 Logging train Loss: 2.99566e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 3.66904e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.40291e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.11476e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 1.49419e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 35.073970317840576
Epoch 8/9
	 Logging train Loss: 2.34544e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 3.1831e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.82778e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.6214e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 9.8345e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 35.454678773880005
Epoch 9/9
	 Logging train Loss: 1.8236e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 3.54869e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.20817e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.79232e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 6.2293e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 35.27729272842407
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combiR_pNone_gNone/'quat_1'_'None'.pth
It took  405.6531000137329  seconds.
----- ITERATION 5/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  800
Number of test simulations:  200
The dataloader for data/data_t(5,20)_r(5,20)_combiR_pNone_gNone took 19.998900413513184 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 5.0749831199646 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 5.069790601730347 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_combiR_pNone_gNone took 5.013894557952881 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 5.046403408050537 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.098996006 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 0.0004229234 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0004229879 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.000333561 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 8.34514e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 35.22293138504028
Epoch 1/9
	 Logging train Loss: 0.0001666997 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 0.0001457988 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0001407337 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0001225803 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 6.62296e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 35.424519300460815
Epoch 2/9
	 Logging train Loss: 0.0001014518 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 0.00010796 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0001036341 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 9.41082e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 5.82823e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb: Test loss t(5,20)_r(5,20)_combiR_pNone_gNone â–ˆâ–ƒâ–‚â–‚â–‚â–‚â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone â–ˆâ–†â–…â–…â–„â–ƒâ–ƒâ–‚â–‚â–
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone â–ˆâ–ƒâ–‚â–‚â–‚â–â–â–â–â–
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone â–ˆâ–ƒâ–‚â–‚â–‚â–â–â–â–â–
wandb:                                   Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb: Test loss t(5,20)_r(5,20)_combiR_pNone_gNone 3e-05
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 1e-05
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 3e-05
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 3e-05
wandb:                                   Train loss 3e-05
wandb: 
wandb: ðŸš€ View run trim-hill-81 at: https://wandb.ai/nreints/ThesisFinal/runs/vs70qqdk
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230616_173528-vs70qqdk/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230616_174223-6xkw2yxu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run breezy-thunder-85
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal/runs/6xkw2yxu
		--> Epoch time; 35.20775818824768
Epoch 3/9
	 Logging train Loss: 7.89159e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 8.28572e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 8.08578e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 7.46604e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 5.03846e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 35.44816613197327
Epoch 4/9
	 Logging train Loss: 6.44915e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 7.00525e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 6.77938e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 6.40377e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 4.44559e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 38.25271558761597
Epoch 5/9
	 Logging train Loss: 5.41334e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 5.97348e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 5.7964e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 5.49652e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 3.84163e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 41.56551718711853
Epoch 6/9
	 Logging train Loss: 4.58899e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 5.00002e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 5.07322e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.74436e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 3.19768e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 35.44619822502136
Epoch 7/9
	 Logging train Loss: 3.88387e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 4.15942e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.25222e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.89487e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 2.52999e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 35.284682512283325
Epoch 8/9
	 Logging train Loss: 3.25762e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 4.58927e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.71192e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.00794e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 1.99614e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 35.26660704612732
Epoch 9/9
	 Logging train Loss: 2.67585e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 3.35613e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.46154e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.9484e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 1.42433e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 35.37910866737366
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combiR_pNone_gNone/'quat_1'_'None'.pth
It took  414.88517665863037  seconds.
----- ITERATION 6/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  800
Number of test simulations:  200
The dataloader for data/data_t(5,20)_r(5,20)_combiR_pNone_gNone took 20.05392360687256 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 5.094143867492676 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 5.115198373794556 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_combiR_pNone_gNone took 5.02638578414917 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 5.146040439605713 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.033020854 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 0.0001884381 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0001935409 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.00015897 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 0.0001025266 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 35.44409728050232
Epoch 1/9
	 Logging train Loss: 0.0001439722 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 0.0001412585 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0001474369 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0001234704 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 8.66707e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 35.312981843948364
Epoch 2/9
	 Logging train Loss: 0.0001136287 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 0.0001110061 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0001179832 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 9.93872e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 7.52007e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 35.316847801208496
Epoch 3/9
	 Logging train Loss: 9.27981e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 9.00543e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 9.72022e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 8.2092e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 6.52164e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 35.41851472854614
Epoch 4/9
	 Logging train Loss: 7.77188e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 7.53293e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 8.32327e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 6.98609e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 5.64637e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 35.179962396621704
Epoch 5/9
	 Logging train Loss: 6.58155e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 6.40854e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 7.31742e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 5.98883e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 4.73529e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 35.38209557533264
Epoch 6/9
	 Logging train Loss: 5.56396e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 6.22519e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 6.96863e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 5.52984e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 3.97987e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 35.410850524902344
Epoch 7/9
	 Logging train Loss: 4.63334e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 5.00071e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 5.69736e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.41038e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 3.07588e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 35.38910150527954
Epoch 8/9
	 Logging train Loss: 3.80884e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 3.7096e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.32007e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.29012e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 2.24926e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb: Test loss t(5,20)_r(5,20)_combiR_pNone_gNone â–ˆâ–†â–…â–„â–ƒâ–ƒâ–‚â–‚â–â–
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone â–ˆâ–‡â–†â–…â–„â–„â–ƒâ–‚â–‚â–
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone â–ˆâ–†â–„â–„â–ƒâ–‚â–‚â–‚â–â–
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone â–ˆâ–†â–„â–ƒâ–ƒâ–‚â–‚â–‚â–â–
wandb:                                   Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb: Test loss t(5,20)_r(5,20)_combiR_pNone_gNone 3e-05
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 2e-05
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 4e-05
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 4e-05
wandb:                                   Train loss 3e-05
wandb: 
wandb: ðŸš€ View run breezy-thunder-85 at: https://wandb.ai/nreints/ThesisFinal/runs/6xkw2yxu
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230616_174223-6xkw2yxu/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230616_174909-zrqhfb3s
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ruby-terrain-91
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal/runs/zrqhfb3s
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb: Test loss t(5,20)_r(5,20)_combiR_pNone_gNone â–ˆâ–„â–„â–ƒâ–ƒâ–‚â–‚â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone â–ˆâ–‡â–†â–…â–…â–„â–ƒâ–‚â–‚â–
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone â–ˆâ–„â–ƒâ–ƒâ–‚â–‚â–‚â–â–â–
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone â–ˆâ–„â–ƒâ–ƒâ–‚â–‚â–‚â–â–â–
wandb:                                   Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb: Test loss t(5,20)_r(5,20)_combiR_pNone_gNone 2e-05
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 1e-05
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 3e-05
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 3e-05
wandb:                                   Train loss 2e-05
wandb: 
wandb: ðŸš€ View run ruby-terrain-91 at: https://wandb.ai/nreints/ThesisFinal/runs/zrqhfb3s
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230616_174909-zrqhfb3s/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230616_175605-3fp4m4fi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run super-fog-97
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal/runs/3fp4m4fi
		--> Epoch time; 35.415080547332764
Epoch 9/9
	 Logging train Loss: 3.06385e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 3.76499e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.27924e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.04797e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 1.62618e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 35.26695466041565
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combiR_pNone_gNone/'quat_1'_'None'.pth
It took  406.6997580528259  seconds.
----- ITERATION 7/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  800
Number of test simulations:  200
The dataloader for data/data_t(5,20)_r(5,20)_combiR_pNone_gNone took 19.110829830169678 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 5.003544569015503 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 5.026950359344482 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_combiR_pNone_gNone took 4.760407209396362 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 5.028510093688965 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0730739012 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 0.0002428796 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0002533593 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0002021851 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 8.60332e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 35.361422300338745
Epoch 1/9
	 Logging train Loss: 0.0001285653 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 0.0001196595 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0001222141 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0001094248 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 7.28439e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 35.40284252166748
Epoch 2/9
	 Logging train Loss: 9.38601e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 9.37044e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 9.71231e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 8.86806e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 6.5429e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 35.44475340843201
Epoch 3/9
	 Logging train Loss: 7.8117e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 7.76405e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 8.07362e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 7.4131e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 5.73297e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 35.256701707839966
Epoch 4/9
	 Logging train Loss: 6.64272e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 6.57098e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 6.93943e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 6.30594e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 4.86211e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 35.13798260688782
Epoch 5/9
	 Logging train Loss: 5.60351e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 5.70427e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 6.05423e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 5.39368e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 3.8941e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 35.715445041656494
Epoch 6/9
	 Logging train Loss: 4.61324e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 5.20588e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 5.42281e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.68276e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 3.03007e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 35.16817855834961
Epoch 7/9
	 Logging train Loss: 3.66979e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 3.79067e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.96038e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.41979e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 2.20497e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 36.44269943237305
Epoch 8/9
	 Logging train Loss: 2.79414e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 4.24644e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.20289e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.41709e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 1.42393e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 43.34158706665039
Epoch 9/9
	 Logging train Loss: 2.12947e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 2.72159e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.82802e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.18175e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 8.1866e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 35.35382056236267
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combiR_pNone_gNone/'quat_1'_'None'.pth
It took  416.0159146785736  seconds.
----- ITERATION 8/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  800
Number of test simulations:  200
The dataloader for data/data_t(5,20)_r(5,20)_combiR_pNone_gNone took 18.909919500350952 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 4.938261032104492 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 4.914795637130737 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_combiR_pNone_gNone took 4.71544337272644 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 4.950105667114258 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0276911985 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 0.0001372992 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0001473493 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0001204625 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 7.54346e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 35.571420669555664
Epoch 1/9
	 Logging train Loss: 0.0001047641 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 9.92475e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0001092066 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 9.17381e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 6.80581e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 35.42957043647766
Epoch 2/9
	 Logging train Loss: 8.54625e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 8.35008e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 9.35825e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb: Test loss t(5,20)_r(5,20)_combiR_pNone_gNone â–ˆâ–†â–…â–„â–ƒâ–ƒâ–‚â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone â–ˆâ–‡â–‡â–†â–…â–„â–ƒâ–‚â–â–
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone â–ˆâ–†â–…â–„â–ƒâ–ƒâ–‚â–â–â–
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone â–ˆâ–…â–„â–„â–ƒâ–‚â–‚â–â–â–
wandb:                                   Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb: Test loss t(5,20)_r(5,20)_combiR_pNone_gNone 2e-05
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 1e-05
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 3e-05
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 3e-05
wandb:                                   Train loss 2e-05
wandb: 
wandb: ðŸš€ View run super-fog-97 at: https://wandb.ai/nreints/ThesisFinal/runs/3fp4m4fi
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230616_175605-3fp4m4fi/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230616_180251-eo57orgj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run snowy-firefly-100
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal/runs/eo57orgj
	 Logging test loss: 7.91709e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 6.15841e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 35.533849477767944
Epoch 3/9
	 Logging train Loss: 7.41294e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 7.20466e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 8.04107e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 6.83954e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 5.45892e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 35.652520179748535
Epoch 4/9
	 Logging train Loss: 6.41315e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 6.23809e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 6.90782e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 5.84366e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 4.46232e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 35.394442081451416
Epoch 5/9
	 Logging train Loss: 5.39135e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 5.30282e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 5.90916e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 5.00532e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 3.72748e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 35.352431535720825
Epoch 6/9
	 Logging train Loss: 4.3593e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 4.48897e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.86994e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.02849e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 2.60604e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 35.73734998703003
Epoch 7/9
	 Logging train Loss: 3.36504e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 3.60089e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.88157e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.13824e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 1.78598e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 35.30375337600708
Epoch 8/9
	 Logging train Loss: 2.55703e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 3.21183e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.36202e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.59875e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 1.06443e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 35.42047882080078
Epoch 9/9
	 Logging train Loss: 1.97881e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 3.27487e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.43573e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.47247e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 6.516e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 35.072845220565796
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combiR_pNone_gNone/'quat_1'_'None'.pth
It took  405.6694121360779  seconds.
----- ITERATION 9/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  800
Number of test simulations:  200
The dataloader for data/data_t(5,20)_r(5,20)_combiR_pNone_gNone took 19.03206181526184 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 4.929266691207886 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 4.9077208042144775 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_combiR_pNone_gNone took 4.75172758102417 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 4.890375852584839 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0286915358 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 0.0001519222 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0001469361 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0001273517 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 8.67998e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 35.3686683177948
Epoch 1/9
	 Logging train Loss: 0.0001096281 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 0.0001188683 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.000113268 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0001020561 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 7.87902e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 35.39359378814697
Epoch 2/9
	 Logging train Loss: 9.32524e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 0.0001025619 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 9.84924e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 8.99815e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 7.16828e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 35.379841804504395
Epoch 3/9
	 Logging train Loss: 8.28397e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 9.1015e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 8.77812e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 7.99282e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 6.47523e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 35.190913915634155
Epoch 4/9
	 Logging train Loss: 7.42087e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 8.1989e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 7.92129e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 7.24927e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 5.82137e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 35.51659059524536
Epoch 5/9
	 Logging train Loss: 6.58893e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 7.23959e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 7.01166e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 6.38982e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 5.04068e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 35.29448699951172
Epoch 6/9
	 Logging train Loss: 5.74361e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 6.20328e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 6.009e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 5.46019e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 4.2139e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 35.54843330383301
Epoch 7/9
	 Logging train Loss: 4.85772e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 5.48059e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 5.31267e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.77708e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 3.33414e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 35.319636821746826
Epoch 8/9
	 Logging train Loss: 3.98912e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 4.2471e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.1469e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb: Test loss t(5,20)_r(5,20)_combiR_pNone_gNone â–ˆâ–†â–…â–„â–„â–ƒâ–ƒâ–‚â–â–
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone â–ˆâ–‡â–†â–†â–…â–„â–ƒâ–ƒâ–‚â–
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone â–ˆâ–†â–…â–„â–„â–ƒâ–‚â–‚â–â–
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone â–ˆâ–†â–…â–„â–„â–ƒâ–‚â–‚â–â–
wandb:                                   Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb: Test loss t(5,20)_r(5,20)_combiR_pNone_gNone 3e-05
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 2e-05
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 4e-05
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 4e-05
wandb:                                   Train loss 3e-05
wandb: 
wandb: ðŸš€ View run snowy-firefly-100 at: https://wandb.ai/nreints/ThesisFinal/runs/eo57orgj
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230616_180251-eo57orgj/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230616_180935-gs1edr2m
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dulcet-jazz-104
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal/runs/gs1edr2m
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb: Test loss t(5,20)_r(5,20)_combiR_pNone_gNone â–ˆâ–†â–…â–„â–ƒâ–‚â–‚â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone â–ˆâ–‡â–†â–…â–„â–ƒâ–‚â–‚â–â–
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone â–ˆâ–†â–„â–ƒâ–ƒâ–‚â–‚â–â–â–
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone â–ˆâ–†â–„â–ƒâ–ƒâ–‚â–‚â–â–‚â–
wandb:                                   Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb: Test loss t(5,20)_r(5,20)_combiR_pNone_gNone 2e-05
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 2e-05
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 2e-05
wandb:                                   Train loss 2e-05
wandb: 
wandb: ðŸš€ View run dulcet-jazz-104 at: https://wandb.ai/nreints/ThesisFinal/runs/gs1edr2m
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230616_180935-gs1edr2m/logs
	 Logging test loss: 3.67212e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 2.50485e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 35.278443574905396
Epoch 9/9
	 Logging train Loss: 3.17872e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 4.28441e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.10015e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.44117e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 1.79436e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 35.43846249580383
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combiR_pNone_gNone/'quat_1'_'None'.pth
It took  403.8717360496521  seconds.
----- ITERATION 10/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  800
Number of test simulations:  200
The dataloader for data/data_t(5,20)_r(5,20)_combiR_pNone_gNone took 18.977048635482788 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 4.872615575790405 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 4.878486394882202 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_combiR_pNone_gNone took 4.732882499694824 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 4.889040231704712 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0304848179 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 0.0001412087 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0001358578 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0001206537 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 7.39555e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 42.18160629272461
Epoch 1/9
	 Logging train Loss: 9.85279e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 0.0001016032 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 9.81809e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 9.06356e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 6.26511e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 37.015275955200195
Epoch 2/9
	 Logging train Loss: 7.52861e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 7.64613e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 7.44826e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 6.88202e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 5.01836e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 35.42596435546875
Epoch 3/9
	 Logging train Loss: 5.91259e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 6.05456e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 5.90244e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 5.44301e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 3.94966e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 35.38032293319702
Epoch 4/9
	 Logging train Loss: 4.70365e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 5.00545e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.92281e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.37554e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 3.07455e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 35.314119815826416
Epoch 5/9
	 Logging train Loss: 3.75035e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 3.95882e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.00646e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.60411e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 2.29516e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 35.32026433944702
Epoch 6/9
	 Logging train Loss: 2.9958e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 3.27974e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.35441e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.84173e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 1.57665e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 35.364737033843994
Epoch 7/9
	 Logging train Loss: 2.41406e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 2.909e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.95661e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.38739e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 1.12067e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 35.0253791809082
Epoch 8/9
	 Logging train Loss: 1.94751e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 2.96782e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.87721e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.30376e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 7.6638e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 35.31225299835205
Epoch 9/9
	 Logging train Loss: 1.59586e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 2.10147e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.15275e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.66802e-05 [MSELoss(): t(5,20)_r(5,20)_combiR_pNone_gNone]
	 Logging test loss: 4.7761e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 35.35572624206543
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combiR_pNone_gNone/'quat_1'_'None'.pth
It took  413.9591648578644  seconds.

JOB STATISTICS
==============
Job ID: 2929787
Array Job ID: 2928286_33
Cluster: snellius
User/Group: nreints/nreints
State: COMPLETED (exit code 0)
Nodes: 1
Cores per node: 18
CPU Utilized: 14:19:44
CPU Efficiency: 69.76% of 20:32:24 core-walltime
Job Wall-clock time: 01:08:28
Memory Utilized: 7.29 GB
Memory Efficiency: 0.00% of 0.00 MB
