wandb: Currently logged in as: nreints. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_211346-4q9pazdu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glorious-microwave-460
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/4q9pazdu
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gTrue â–ˆâ–…â–„â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gTrue â–ˆâ–ƒâ–ˆâ–â–‚â–â–â–‚â–â–
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gTrue â–ˆâ–†â–„â–â–â–â–â–â–â–
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gTrue â–ˆâ–…â–ƒâ–â–â–â–â–â–â–
wandb:                                   Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gTrue 0.0
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gTrue 0.0
wandb:                                   Train loss 0.0
wandb: 
wandb: ðŸš€ View run glorious-microwave-460 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/4q9pazdu
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_211346-4q9pazdu/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_212014-6besxh0k
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ethereal-spaceship-465
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/6besxh0k
Training on dataset: data_t(5,20)_r(5,20)_combi_pNone_gTrue
Testing on 4 datasets: ['data_t(5,20)_r(5,20)_full_pNone_gTrue', 'data_t(5,20)_r(5,20)_tennis_pNone_gTrue', 'data_t(5,20)_r(5,20)_semi_pNone_gTrue', 'data_t(5,20)_r(5,20)_combi_pNone_gTrue']
Focussing on identity: False
Using extra input: False
Using fr-fr as reference point.
----- ITERATION 1/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gTrue took 50.230144023895264 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gTrue took 13.18184781074524 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gTrue took 12.521322965621948 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gTrue took 13.287598609924316 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gTrue took 12.618378162384033 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(24, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=24, bias=True)
)
Datatype: pos_diff_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0001592773 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 2.3948e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 1.75941e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 1.43493e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 9.2919e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 27.501972198486328
Epoch 1/9
	 Logging train Loss: 6.7566e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 9.146e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 1.10152e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 1.04688e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 5.8793e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 27.25986957550049
Epoch 2/9
	 Logging train Loss: 4.4014e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 2.3968e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 8.2512e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 7.5022e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 5.1938e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 27.247734785079956
Epoch 3/9
	 Logging train Loss: 2.52e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 3.681e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 4.1602e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 3.2449e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 2.0866e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 27.04775333404541
Epoch 4/9
	 Logging train Loss: 1.9639e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 4.922e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 3.9753e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 3.1198e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 2.0737e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 27.259747743606567
Epoch 5/9
	 Logging train Loss: 1.8579e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 3.455e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 3.7678e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 2.8991e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 1.8797e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 27.342122793197632
Epoch 6/9
	 Logging train Loss: 1.8093e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 3.246e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 3.6024e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 2.8723e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 1.823e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 27.167585134506226
Epoch 7/9
	 Logging train Loss: 1.7568e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 4.791e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 3.6914e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 2.9769e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 1.9576e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 27.07494068145752
Epoch 8/9
	 Logging train Loss: 1.7173e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 3.653e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 3.5153e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 2.856e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 1.8189e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 26.928571701049805
Epoch 9/9
	 Logging train Loss: 1.6754e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 3.674e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 3.4033e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 2.8255e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 1.7829e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 27.216638326644897
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gTrue/'pos_diff_1'_'False'.pth
It took  388.9295196533203  seconds.
----- ITERATION 2/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gTrue took 52.06980895996094 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gTrue took 13.46095609664917 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gTrue took 12.569938659667969 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gTrue took 13.398967742919922 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gTrue took 12.540789365768433 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(24, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=24, bias=True)
)
Datatype: pos_diff_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.000164243 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 2.1067e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 1.6803e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 1.49992e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 8.7958e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 27.56939387321472
Epoch 1/9
	 Logging train Loss: 6.8968e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 1.0529e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 1.07794e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 1.0922e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 5.896e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 27.136932373046875
Epoch 2/9
	 Logging train Loss: 4.8304e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 5.918e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 7.0862e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 6.9339e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 3.7458e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 27.146111726760864
Epoch 3/9
	 Logging train Loss: 2.9435e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 6.965e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 4.485e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 3.8812e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 2.4136e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gTrue â–ˆâ–…â–ƒâ–‚â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gTrue â–ˆâ–„â–‚â–ƒâ–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gTrue â–ˆâ–†â–ƒâ–‚â–â–â–â–â–â–
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gTrue â–ˆâ–…â–ƒâ–‚â–â–â–â–â–â–
wandb:                                   Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gTrue 0.0
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gTrue 0.0
wandb:                                   Train loss 0.0
wandb: 
wandb: ðŸš€ View run ethereal-spaceship-465 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/6besxh0k
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_212014-6besxh0k/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_212643-c01kjt11
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run usual-dew-475
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/c01kjt11
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gTrue â–ˆâ–…â–ƒâ–‚â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gTrue â–ˆâ–ƒâ–‚â–‚â–â–‚â–â–‚â–â–‚
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gTrue â–ˆâ–…â–ƒâ–â–â–â–â–â–â–
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gTrue â–ˆâ–…â–ƒâ–‚â–â–â–â–â–â–
wandb:                                   Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gTrue 0.0
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gTrue 0.0
wandb:                                   Train loss 0.0
wandb: 
wandb: ðŸš€ View run usual-dew-475 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/c01kjt11
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_212643-c01kjt11/logs
		--> Epoch time; 27.063201189041138
Epoch 4/9
	 Logging train Loss: 2.0438e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 3.764e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 3.6412e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 3.084e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 1.8606e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 27.121537923812866
Epoch 5/9
	 Logging train Loss: 1.8756e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 4.122e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 3.5719e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 3.0481e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 1.851e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 27.180246591567993
Epoch 6/9
	 Logging train Loss: 1.8145e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 2.939e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 3.3742e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 2.8695e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 1.699e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 27.10611653327942
Epoch 7/9
	 Logging train Loss: 1.766e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 3.608e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 3.3423e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 2.9512e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 1.7502e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 27.172147750854492
Epoch 8/9
	 Logging train Loss: 1.7193e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 4.029e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 3.2931e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 2.963e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 1.7627e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 27.19857382774353
Epoch 9/9
	 Logging train Loss: 1.6747e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 3.102e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 3.1394e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 2.8104e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 1.6372e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 27.16895890235901
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gTrue/'pos_diff_1'_'False'.pth
It took  388.71940565109253  seconds.
----- ITERATION 3/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gTrue took 51.09385442733765 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gTrue took 13.386559247970581 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gTrue took 13.228243350982666 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gTrue took 13.291896343231201 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gTrue took 12.59512734413147 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(24, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=24, bias=True)
)
Datatype: pos_diff_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0001663776 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 2.2559e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 1.63016e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 1.42556e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 8.2978e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 27.101475954055786
Epoch 1/9
	 Logging train Loss: 6.9846e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 8.315e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 1.00422e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 1.00332e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 5.0895e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 27.380245685577393
Epoch 2/9
	 Logging train Loss: 4.7736e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 6.711e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 6.5784e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 6.5031e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 3.3874e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 27.213329553604126
Epoch 3/9
	 Logging train Loss: 2.8967e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 5.676e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 4.0942e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 3.5532e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 2.091e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 27.307478189468384
Epoch 4/9
	 Logging train Loss: 2.0746e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 3.122e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 3.4412e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 2.8791e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 1.6506e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 27.06082797050476
Epoch 5/9
	 Logging train Loss: 1.9156e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 6.314e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 3.626e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 3.1537e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 1.929e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 27.143569469451904
Epoch 6/9
	 Logging train Loss: 1.8489e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 4.09e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 3.3198e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 2.8971e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 1.6795e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 27.328376531600952
Epoch 7/9
	 Logging train Loss: 1.7987e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 4.514e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 3.2663e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 2.9334e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 1.6927e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 27.208569526672363
Epoch 8/9
	 Logging train Loss: 1.7545e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 3.526e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 3.1327e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 2.7871e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 1.5762e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 27.25655961036682
Epoch 9/9
	 Logging train Loss: 1.7146e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 4.554e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 3.1268e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 2.8585e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 1.6547e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 27.38561511039734
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gTrue/'pos_diff_1'_'False'.pth
It took  387.5340497493744  seconds.
----- ITERATION 4/10 ------
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_213310-0guo42d9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run comic-water-483
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/0guo42d9
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gTrue â–ˆâ–…â–„â–‚â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gTrue â–ˆâ–ƒâ–ƒâ–‚â–‚â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gTrue â–ˆâ–†â–„â–‚â–â–â–â–â–â–
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gTrue â–ˆâ–…â–ƒâ–‚â–â–â–â–â–â–
wandb:                                   Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gTrue 0.0
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gTrue 0.0
wandb:                                   Train loss 0.0
wandb: 
wandb: ðŸš€ View run comic-water-483 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/0guo42d9
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_213310-0guo42d9/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_213942-huapjmjo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run curious-dragon-493
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/huapjmjo
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gTrue took 50.641151905059814 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gTrue took 13.237792491912842 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gTrue took 13.08219289779663 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gTrue took 13.168830871582031 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gTrue took 12.759855270385742 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(24, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=24, bias=True)
)
Datatype: pos_diff_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0001696395 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 2.4583e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 1.6077e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 1.51249e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 9.5007e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 27.23984122276306
Epoch 1/9
	 Logging train Loss: 6.9626e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 9.295e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 1.03472e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 1.12085e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 6.1965e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 27.14751434326172
Epoch 2/9
	 Logging train Loss: 5.0053e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 8.377e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 7.5298e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 8.0352e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 4.5392e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 27.099220514297485
Epoch 3/9
	 Logging train Loss: 3.2924e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 5.787e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 4.4964e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 4.2203e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 2.6351e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 27.908456563949585
Epoch 4/9
	 Logging train Loss: 2.1269e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 4.682e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 3.6354e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 3.2043e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 2.0818e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 27.85722827911377
Epoch 5/9
	 Logging train Loss: 1.8721e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 3.687e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 3.3913e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 3.0059e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 1.9162e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 27.213701009750366
Epoch 6/9
	 Logging train Loss: 1.7915e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 4.308e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 3.3636e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 3.0129e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 1.9322e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 27.047033548355103
Epoch 7/9
	 Logging train Loss: 1.7446e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 3.105e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 3.1706e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 2.8461e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 1.786e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 27.398163318634033
Epoch 8/9
	 Logging train Loss: 1.7017e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 4.538e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 3.2638e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 2.9656e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 1.9022e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 27.37089467048645
Epoch 9/9
	 Logging train Loss: 1.6668e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 3.183e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 3.05e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 2.8303e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 1.7456e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 27.21256113052368
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gTrue/'pos_diff_1'_'False'.pth
It took  391.94234585762024  seconds.
----- ITERATION 5/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gTrue took 50.4350368976593 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gTrue took 13.163429737091064 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gTrue took 13.112066984176636 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gTrue took 13.139723777770996 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gTrue took 12.785351991653442 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(24, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=24, bias=True)
)
Datatype: pos_diff_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0001693287 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 2.4914e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 1.62659e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 1.45467e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 8.5631e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 27.41039514541626
Epoch 1/9
	 Logging train Loss: 7.0803e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 1.172e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 1.04176e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 1.07352e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 5.5893e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 27.220340490341187
Epoch 2/9
	 Logging train Loss: 4.9246e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 7.782e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 6.9528e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 7.0166e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 3.7138e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 27.287561893463135
Epoch 3/9
	 Logging train Loss: 3.0988e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 4.473e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 4.1931e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 3.7584e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 2.1266e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 27.186861038208008
Epoch 4/9
	 Logging train Loss: 2.1382e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 4.973e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 3.6643e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 3.1561e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gTrue â–ˆâ–…â–ƒâ–‚â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gTrue â–ˆâ–„â–‚â–â–‚â–‚â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gTrue â–ˆâ–†â–„â–‚â–â–â–â–â–â–
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gTrue â–ˆâ–…â–ƒâ–‚â–â–â–â–â–â–
wandb:                                   Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gTrue 0.0
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gTrue 0.0
wandb:                                   Train loss 0.0
wandb: 
wandb: ðŸš€ View run curious-dragon-493 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/huapjmjo
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_213942-huapjmjo/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_214611-3ywet80e
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fearless-snowflake-501
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/3ywet80e
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gTrue â–ˆâ–…â–„â–‚â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gTrue â–ˆâ–ƒâ–‚â–‚â–‚â–â–â–â–‚â–
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gTrue â–ˆâ–†â–„â–‚â–â–â–â–â–â–
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gTrue â–ˆâ–…â–„â–‚â–â–â–â–â–â–
wandb:                                   Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gTrue 0.0
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gTrue 0.0
wandb:                                   Train loss 0.0
wandb: 
wandb: ðŸš€ View run fearless-snowflake-501 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/3ywet80e
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_214611-3ywet80e/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_215241-6wklglav
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ethereal-meadow-511
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/6wklglav
	 Logging test loss: 1.8853e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 27.403155088424683
Epoch 5/9
	 Logging train Loss: 1.9263e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 4.956e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 3.5529e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 3.0814e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 1.8449e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 27.339412212371826
Epoch 6/9
	 Logging train Loss: 1.8628e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 4.273e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 3.4037e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 2.958e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 1.7373e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 27.428257942199707
Epoch 7/9
	 Logging train Loss: 1.8103e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 3.574e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 3.2719e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 2.8717e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 1.6488e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 27.4042546749115
Epoch 8/9
	 Logging train Loss: 1.7667e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 3.516e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 3.2203e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 2.8501e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 1.6221e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 27.07857584953308
Epoch 9/9
	 Logging train Loss: 1.7296e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 3.217e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 3.0944e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 2.7949e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 1.5641e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 27.304208755493164
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gTrue/'pos_diff_1'_'False'.pth
It took  389.0310502052307  seconds.
----- ITERATION 6/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gTrue took 50.21509337425232 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gTrue took 13.083124876022339 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gTrue took 13.062751770019531 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gTrue took 13.074856281280518 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gTrue took 12.811220645904541 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(24, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=24, bias=True)
)
Datatype: pos_diff_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0001847471 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 2.6812e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 1.90538e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 1.46314e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 9.735e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 27.216050148010254
Epoch 1/9
	 Logging train Loss: 7.3065e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 9.473e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 1.23958e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 1.11904e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 6.3513e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 27.43432378768921
Epoch 2/9
	 Logging train Loss: 5.3168e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 7.365e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 9.3065e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 8.5413e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 4.8423e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 27.385805368423462
Epoch 3/9
	 Logging train Loss: 3.7878e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 7.684e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 6.125e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 5.1786e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 3.1902e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 27.140557765960693
Epoch 4/9
	 Logging train Loss: 2.4395e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 5.345e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 4.2975e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 3.3792e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 2.1809e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 27.4125075340271
Epoch 5/9
	 Logging train Loss: 1.9863e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 3.674e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 3.8028e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 2.9311e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 1.8606e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 27.52508568763733
Epoch 6/9
	 Logging train Loss: 1.8596e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 3.561e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 3.6722e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 2.9283e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 1.8215e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 27.125864505767822
Epoch 7/9
	 Logging train Loss: 1.7977e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 3.04e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 3.5112e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 2.7714e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 1.7183e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 27.297252416610718
Epoch 8/9
	 Logging train Loss: 1.7334e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 4.773e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 3.6116e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 2.9046e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 1.8633e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 28.247379064559937
Epoch 9/9
	 Logging train Loss: 1.6966e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 2.979e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 3.3559e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 2.716e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 1.6655e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 27.797295808792114
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gTrue/'pos_diff_1'_'False'.pth
It took  389.1949200630188  seconds.
----- ITERATION 7/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gTrue took 50.41324973106384 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gTrue took 13.01120638847351 seconds.
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gTrue â–ˆâ–…â–ƒâ–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gTrue â–ˆâ–ƒâ–‚â–â–‚â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gTrue â–ˆâ–†â–ƒâ–â–â–â–â–â–â–
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gTrue â–ˆâ–…â–ƒâ–â–â–â–â–â–â–
wandb:                                   Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gTrue 0.0
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gTrue 0.0
wandb:                                   Train loss 0.0
wandb: 
wandb: ðŸš€ View run ethereal-meadow-511 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/6wklglav
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_215241-6wklglav/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_215908-l75o9jlq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run faithful-armadillo-518
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/l75o9jlq
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gTrue took 13.049924850463867 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gTrue took 13.084906816482544 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gTrue took 12.821358442306519 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(24, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=24, bias=True)
)
Datatype: pos_diff_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0001348648 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 1.7703e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 1.60186e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 1.40963e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 8.8232e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 27.162782907485962
Epoch 1/9
	 Logging train Loss: 6.3073e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 7.509e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 1.03644e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 1.01034e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 5.7963e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 27.4196834564209
Epoch 2/9
	 Logging train Loss: 4.3596e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 6.262e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 6.6179e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 6.1071e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 3.6921e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 27.11432671546936
Epoch 3/9
	 Logging train Loss: 2.6385e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 3.97e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 4.1678e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 3.4552e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 2.2494e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 27.36386728286743
Epoch 4/9
	 Logging train Loss: 1.9829e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 5.516e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 3.977e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 3.2636e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 2.2034e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 27.00088906288147
Epoch 5/9
	 Logging train Loss: 1.8384e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 3.495e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 3.6368e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 2.9741e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 1.9409e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 27.282910585403442
Epoch 6/9
	 Logging train Loss: 1.7789e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 3.8e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 3.5529e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 2.9845e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 1.9385e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 27.232016801834106
Epoch 7/9
	 Logging train Loss: 1.7356e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 3.325e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 3.4463e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 2.906e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 1.8637e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 27.4150447845459
Epoch 8/9
	 Logging train Loss: 1.6862e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 3.213e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 3.3405e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 2.8749e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 1.8208e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 27.46094512939453
Epoch 9/9
	 Logging train Loss: 1.6478e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 3.388e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 3.274e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 2.8784e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 1.8091e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 27.262458562850952
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gTrue/'pos_diff_1'_'False'.pth
It took  386.9963712692261  seconds.
----- ITERATION 8/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gTrue took 50.457927227020264 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gTrue took 13.044204473495483 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gTrue took 12.980742692947388 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gTrue took 13.012313604354858 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gTrue took 12.818874597549438 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(24, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=24, bias=True)
)
Datatype: pos_diff_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0001595093 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 2.5313e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 1.79636e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 1.4886e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 9.5059e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 27.31981110572815
Epoch 1/9
	 Logging train Loss: 6.8835e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 8.343e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 1.07166e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 1.03547e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 5.7096e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 27.476618766784668
Epoch 2/9
	 Logging train Loss: 4.5048e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 7.535e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 6.6944e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 6.1874e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 3.602e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 27.527228355407715
Epoch 3/9
	 Logging train Loss: 2.6138e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 5.897e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 4.2558e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 3.4958e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 2.2587e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 27.5116069316864
Epoch 4/9
	 Logging train Loss: 1.9707e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 3.014e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 3.6951e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 2.9824e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 1.8451e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 27.287301778793335
Epoch 5/9
	 Logging train Loss: 1.8658e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 3.092e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gTrue â–ˆâ–…â–ƒâ–‚â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gTrue â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gTrue â–ˆâ–…â–ƒâ–â–â–â–â–â–â–
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gTrue â–ˆâ–…â–ƒâ–â–â–â–â–â–â–
wandb:                                   Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gTrue 0.0
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gTrue 0.0
wandb:                                   Train loss 0.0
wandb: 
wandb: ðŸš€ View run faithful-armadillo-518 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/l75o9jlq
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_215908-l75o9jlq/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_220537-i6b6a8jg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run soft-bush-527
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/i6b6a8jg
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gTrue â–ˆâ–…â–ƒâ–‚â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gTrue â–ˆâ–ƒâ–„â–‚â–â–‚â–â–‚â–â–‚
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gTrue â–ˆâ–…â–ƒâ–â–â–â–â–â–â–
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gTrue â–ˆâ–…â–ƒâ–‚â–â–â–â–â–â–
wandb:                                   Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gTrue 0.0
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gTrue 0.0
wandb:                                   Train loss 0.0
wandb: 
wandb: ðŸš€ View run soft-bush-527 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/i6b6a8jg
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_220537-i6b6a8jg/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_221206-uyoztk1q
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wild-voice-537
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/uyoztk1q
	 Logging test loss: 3.5807e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 2.8993e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 1.8365e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 27.55841040611267
Epoch 6/9
	 Logging train Loss: 1.8138e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 2.935e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 3.4834e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 2.8485e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 1.7557e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 27.575164079666138
Epoch 7/9
	 Logging train Loss: 1.7557e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 4.049e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 3.5134e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 2.9398e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 1.839e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 27.24197483062744
Epoch 8/9
	 Logging train Loss: 1.7214e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 2.946e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 3.2924e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 2.8159e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 1.6963e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 27.172306299209595
Epoch 9/9
	 Logging train Loss: 1.6736e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 3.644e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 3.2809e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 2.8671e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 1.7407e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 27.09142518043518
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gTrue/'pos_diff_1'_'False'.pth
It took  389.42044138908386  seconds.
----- ITERATION 9/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gTrue took 50.34429049491882 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gTrue took 12.991825103759766 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gTrue took 12.969900846481323 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gTrue took 12.98969054222107 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gTrue took 12.812433242797852 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(24, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=24, bias=True)
)
Datatype: pos_diff_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0001436361 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 2.0031e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 1.51568e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 1.47664e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 8.6923e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 27.562475442886353
Epoch 1/9
	 Logging train Loss: 6.3751e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 8.085e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 9.1877e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 9.949e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 5.3305e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 27.655232906341553
Epoch 2/9
	 Logging train Loss: 3.9826e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 1.1331e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 5.7774e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 5.6644e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 3.5234e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 27.34246063232422
Epoch 3/9
	 Logging train Loss: 2.3185e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 6.223e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 3.9901e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 3.5062e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 2.2338e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 27.309900760650635
Epoch 4/9
	 Logging train Loss: 1.9342e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 2.819e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 3.4185e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 3.0258e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 1.7943e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 27.38951325416565
Epoch 5/9
	 Logging train Loss: 1.8514e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 5.529e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 3.5991e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 3.2173e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 2.0518e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 27.26447558403015
Epoch 6/9
	 Logging train Loss: 1.7986e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 2.963e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 3.2511e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 3.0388e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 1.7621e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 27.29076385498047
Epoch 7/9
	 Logging train Loss: 1.7548e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 4.291e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 3.3154e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 3.0211e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 1.8284e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 27.484130144119263
Epoch 8/9
	 Logging train Loss: 1.7109e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 2.897e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 3.1049e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 2.8804e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 1.6808e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 27.575324773788452
Epoch 9/9
	 Logging train Loss: 1.6721e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 4.189e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 3.1275e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 3.0056e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 1.7741e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 27.226201057434082
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gTrue/'pos_diff_1'_'False'.pth
It took  389.08148193359375  seconds.
----- ITERATION 10/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gTrue took 50.227442026138306 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gTrue took 12.988019227981567 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gTrue took 12.93284821510315 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gTrue took 12.923404216766357 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gTrue took 12.752862691879272 seconds.
-- Finished Test Dataloader(s) --
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gTrue â–ˆâ–…â–ƒâ–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gTrue â–ˆâ–ƒâ–ƒâ–â–‚â–â–â–‚â–â–
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gTrue â–ˆâ–…â–ƒâ–â–â–â–â–â–â–
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gTrue â–ˆâ–…â–ƒâ–â–â–â–â–â–â–
wandb:                                   Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gTrue 0.0
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gTrue 0.0
wandb:                                   Train loss 0.0
wandb: 
wandb: ðŸš€ View run wild-voice-537 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/uyoztk1q
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_221206-uyoztk1q/logs
GRU(
  (rnn): GRU(24, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=24, bias=True)
)
Datatype: pos_diff_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0001551598 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 2.1726e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 1.67306e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 1.59613e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 9.2006e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 27.322227239608765
Epoch 1/9
	 Logging train Loss: 6.6994e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 8.58e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 9.9873e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 1.10283e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 5.6254e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 27.151159286499023
Epoch 2/9
	 Logging train Loss: 4.4567e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 7.324e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 6.4697e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 6.7214e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 3.6151e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 27.250600814819336
Epoch 3/9
	 Logging train Loss: 2.6481e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 4.335e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 4.0395e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 3.6598e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 2.1335e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 27.235908031463623
Epoch 4/9
	 Logging train Loss: 1.9892e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 4.776e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 3.7221e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 3.3574e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 2.0062e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 27.178557872772217
Epoch 5/9
	 Logging train Loss: 1.8678e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 3.923e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 3.5429e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 3.188e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 1.8778e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 27.4823055267334
Epoch 6/9
	 Logging train Loss: 1.805e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 3.266e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 3.3885e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 3.1005e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 1.79e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 27.581247091293335
Epoch 7/9
	 Logging train Loss: 1.752e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 5.714e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 3.5776e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 3.2725e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 1.9948e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 27.31714630126953
Epoch 8/9
	 Logging train Loss: 1.7178e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 4.262e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 3.3717e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 3.1213e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 1.8478e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 27.215495109558105
Epoch 9/9
	 Logging train Loss: 1.6714e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 3.519e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 3.1531e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 3.0434e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 1.7147e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 27.382925271987915
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gTrue/'pos_diff_1'_'False'.pth
It took  387.0242991447449  seconds.

JOB STATISTICS
==============
Job ID: 3086316
Array Job ID: 3086289_68
Cluster: snellius
User/Group: nreints/nreints
State: RUNNING
Nodes: 1
Cores per node: 18
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 19:31:12 core-walltime
Job Wall-clock time: 01:05:04
Memory Utilized: 0.00 MB (estimated maximum)
Memory Efficiency: 0.00% of 0.00 MB (0.00 MB/node)
WARNING: Efficiency statistics may be misleading for RUNNING jobs.
