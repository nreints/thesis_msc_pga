wandb: Currently logged in as: nreints. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_222041-wkcdslbw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run devoted-armadillo-1127
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/wkcdslbw
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue █▅▄▃▂▂▂▁▁▁
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue █▅▄▃▂▂▂▁▁▁
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue █▅▄▃▂▂▂▁▁▁
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue █▅▄▃▂▂▂▁▁▁
wandb:                                 Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue 0.0
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue 0.0
wandb:                                 Train loss 1e-05
wandb: 
wandb: 🚀 View run devoted-armadillo-1127 at: https://wandb.ai/nreints/ThesisFinal2/runs/wkcdslbw
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_222041-wkcdslbw/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_222805-1jn6qnpz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run jolly-vortex-1129
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/1jn6qnpz
Training on dataset: data_t(0,0)_r(0,0)_combi_pNone_gTrue
Testing on 4 datasets: ['data_t(0,0)_r(0,0)_tennis_pNone_gTrue', 'data_t(0,0)_r(0,0)_semi_pNone_gTrue', 'data_t(0,0)_r(0,0)_combi_pNone_gTrue', 'data_t(0,0)_r(0,0)_full_pNone_gTrue']
Focussing on identity: False
Using extra input: False
Using start-fr as reference point.
----- ITERATION 1/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 78.57925295829773 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pNone_gTrue took 19.852713108062744 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pNone_gTrue took 20.073710680007935 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 19.81439781188965 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pNone_gTrue took 20.265539407730103 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(24, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=24, bias=True)
)
Datatype: pos_diff_start
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0272267722 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0001620493 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 0.0001619801 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 0.0001620582 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0001620417 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 28.118454456329346
Epoch 1/9
	 Logging train Loss: 0.0001216675 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 9.47924e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 9.47643e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 9.47685e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 9.47828e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 27.531267881393433
Epoch 2/9
	 Logging train Loss: 8.00135e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.56396e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 6.56242e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 6.56336e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.56254e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 27.173712015151978
Epoch 3/9
	 Logging train Loss: 5.83612e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.84663e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 4.84601e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 4.8454e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.84329e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 26.944290161132812
Epoch 4/9
	 Logging train Loss: 4.50918e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.31252e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.31442e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 3.31336e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.3154e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 26.99449872970581
Epoch 5/9
	 Logging train Loss: 3.32622e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.08977e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.08945e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.08993e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.09024e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 27.234589099884033
Epoch 6/9
	 Logging train Loss: 1.99779e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.17251e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.17348e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.17141e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.17149e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 27.26598596572876
Epoch 7/9
	 Logging train Loss: 1.18903e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.3043e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.3037e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.3061e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.3046e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 27.027288675308228
Epoch 8/9
	 Logging train Loss: 8.6191e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.6251e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.6238e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.6244e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.6228e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 26.991807222366333
Epoch 9/9
	 Logging train Loss: 9.2761e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.8737e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.8744e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.8728e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.8722e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 27.087551593780518
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'pos_diff_start'_'False'.pth
It took  444.943856716156  seconds.
----- ITERATION 2/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 77.67786049842834 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pNone_gTrue took 19.980725288391113 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pNone_gTrue took 19.925302982330322 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 19.60978603363037 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pNone_gTrue took 19.982694149017334 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(24, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=24, bias=True)
)
Datatype: pos_diff_start
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.031785164 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0001881471 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 0.0001880346 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 0.0001882396 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0001881355 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 27.184466123580933
Epoch 1/9
	 Logging train Loss: 0.0001343746 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0001033408 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 0.0001032435 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 0.0001033023 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0001032787 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 27.435112476348877
Epoch 2/9
	 Logging train Loss: 8.55291e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.93155e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 6.93195e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 6.93219e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.93184e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 27.09435534477234
Epoch 3/9
	 Logging train Loss: 5.85862e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.50009e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 4.50102e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 4.4969e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.50053e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 27.1474826335907
Epoch 4/9
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue █▅▄▃▂▁▁▁▁▁
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue █▅▄▃▂▁▁▁▁▁
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue █▅▄▃▂▁▁▁▁▁
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue █▅▄▃▂▁▁▁▁▁
wandb:                                 Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue 0.0
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue 0.0
wandb:                                 Train loss 1e-05
wandb: 
wandb: 🚀 View run jolly-vortex-1129 at: https://wandb.ai/nreints/ThesisFinal2/runs/1jn6qnpz
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_222805-1jn6qnpz/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_223527-84cqn9sd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run light-river-1131
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/84cqn9sd
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue █▅▄▃▂▁▁▁▁▁
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue █▅▄▃▂▁▁▁▁▁
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue █▅▄▃▂▁▁▁▁▁
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue █▅▄▃▂▁▁▁▁▁
wandb:                                 Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue 0.0
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue 0.0
wandb:                                 Train loss 1e-05
wandb: 
wandb: 🚀 View run light-river-1131 at: https://wandb.ai/nreints/ThesisFinal2/runs/84cqn9sd
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_223527-84cqn9sd/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_224248-e9mzew9l
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run earthy-eon-1133
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/e9mzew9l
	 Logging train Loss: 3.76389e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.73197e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.73085e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.7325e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.73192e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 27.441880226135254
Epoch 5/9
	 Logging train Loss: 1.66985e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 9.8456e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 9.8467e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 9.8428e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 9.8437e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 27.30768132209778
Epoch 6/9
	 Logging train Loss: 1.18313e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.26e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.2602e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.2588e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.2593e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 27.09817099571228
Epoch 7/9
	 Logging train Loss: 8.7959e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.387e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.3858e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.3865e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.3858e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 27.099148511886597
Epoch 8/9
	 Logging train Loss: 5.4583e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 9.247e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 9.255e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 9.247e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 9.243e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 26.967174768447876
Epoch 9/9
	 Logging train Loss: 7.6072e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.1573e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.1572e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.1564e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.1558e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 27.22219705581665
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'pos_diff_start'_'False'.pth
It took  441.9758710861206  seconds.
----- ITERATION 3/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 76.34397578239441 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pNone_gTrue took 19.696004390716553 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pNone_gTrue took 19.708433389663696 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 19.28461503982544 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pNone_gTrue took 19.78554677963257 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(24, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=24, bias=True)
)
Datatype: pos_diff_start
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0239622761 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0001582098 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 0.0001582732 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 0.0001583669 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0001583112 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 27.44986605644226
Epoch 1/9
	 Logging train Loss: 0.0001190641 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 9.27846e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 9.27703e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 9.2803e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 9.27377e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 28.06444239616394
Epoch 2/9
	 Logging train Loss: 7.78316e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.56323e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 6.56154e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 6.56173e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.56296e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 27.551902532577515
Epoch 3/9
	 Logging train Loss: 5.60443e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.72637e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 4.72475e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 4.72464e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.72321e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 27.23212504386902
Epoch 4/9
	 Logging train Loss: 3.7294e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.00446e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.00297e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.00219e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.00312e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 27.165457010269165
Epoch 5/9
	 Logging train Loss: 1.82968e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.7503e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 6.7482e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 6.7511e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.7544e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 27.19757103919983
Epoch 6/9
	 Logging train Loss: 1.3556e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.8362e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 7.8415e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 7.8424e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.8376e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 27.430880308151245
Epoch 7/9
	 Logging train Loss: 1.09601e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.0751e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 4.0729e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 4.0721e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.0736e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 27.21242666244507
Epoch 8/9
	 Logging train Loss: 1.18678e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.0969e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.0962e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.0963e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.0961e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 27.367838144302368
Epoch 9/9
	 Logging train Loss: 7.4614e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.292e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.2926e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 3.2913e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.2917e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 27.354974031448364
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'pos_diff_start'_'False'.pth
It took  440.9500114917755  seconds.
----- ITERATION 4/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 76.28884959220886 seconds.
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue █▅▄▃▁▁▁▁▂▁
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue █▅▄▃▁▁▁▁▂▁
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue █▅▄▃▁▁▁▁▂▁
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue █▅▄▃▁▁▁▁▂▁
wandb:                                 Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue 0.0
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue 0.0
wandb:                                 Train loss 1e-05
wandb: 
wandb: 🚀 View run earthy-eon-1133 at: https://wandb.ai/nreints/ThesisFinal2/runs/e9mzew9l
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_224248-e9mzew9l/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_225007-k3qu89ls
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vivid-brook-1135
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/k3qu89ls
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pNone_gTrue took 19.652215719223022 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pNone_gTrue took 19.69514489173889 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 19.298394441604614 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pNone_gTrue took 19.685776948928833 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(24, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=24, bias=True)
)
Datatype: pos_diff_start
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0271855816 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.000175205 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 0.0001754687 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 0.000175193 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0001752176 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 27.674479484558105
Epoch 1/9
	 Logging train Loss: 0.0001307626 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0001000875 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 0.0001000662 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 0.000100115 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0001000695 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 27.00779438018799
Epoch 2/9
	 Logging train Loss: 8.21913e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.45668e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 6.4526e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 6.45398e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.45421e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 27.363823652267456
Epoch 3/9
	 Logging train Loss: 5.28952e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.75939e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 5.757e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 5.76218e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.7604e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 27.453862190246582
Epoch 4/9
	 Logging train Loss: 2.48949e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.6425e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 7.6551e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 7.6425e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.642e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 27.37030816078186
Epoch 5/9
	 Logging train Loss: 9.9577e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.5089e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.5093e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.5091e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.51e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 27.224557876586914
Epoch 6/9
	 Logging train Loss: 9.9018e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.0417e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 8.0418e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 8.0455e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.0453e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 27.10915493965149
Epoch 7/9
	 Logging train Loss: 8.8219e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.1472e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.1464e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.1473e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.1474e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 27.229974031448364
Epoch 8/9
	 Logging train Loss: 7.669e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.65739e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.6575e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.65801e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.65733e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 27.165996551513672
Epoch 9/9
	 Logging train Loss: 7.9622e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.7505e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.7516e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 3.7506e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.7513e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 27.408028602600098
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'pos_diff_start'_'False'.pth
It took  439.3114016056061  seconds.
----- ITERATION 5/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 76.16281175613403 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pNone_gTrue took 19.668615579605103 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pNone_gTrue took 19.652529001235962 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 19.286245584487915 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pNone_gTrue took 19.636616230010986 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(24, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=24, bias=True)
)
Datatype: pos_diff_start
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0312653147 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0001720177 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 0.0001721723 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 0.0001722026 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0001720576 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 27.37904143333435
Epoch 1/9
	 Logging train Loss: 0.0001301497 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0001006938 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 0.000100738 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 0.0001007148 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0001007196 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 27.37276554107666
Epoch 2/9
	 Logging train Loss: 8.28612e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.5938e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 6.59281e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 6.59493e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.5949e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 27.477980613708496
Epoch 3/9
	 Logging train Loss: 5.43053e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.65681e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.65625e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 3.65563e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.65674e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 27.726516723632812
Epoch 4/9
	 Logging train Loss: 2.58643e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.4997e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 7.5005e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 7.5059e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.5012e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 27.38557004928589
Epoch 5/9
	 Logging train Loss: 1.22506e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue █▅▄▂▁▁▁▁▁▁
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue █▅▄▂▁▁▁▁▁▁
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue █▅▄▂▁▁▁▁▁▁
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue █▅▄▂▁▁▁▁▁▁
wandb:                                 Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue 0.0
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue 0.0
wandb:                                 Train loss 1e-05
wandb: 
wandb: 🚀 View run vivid-brook-1135 at: https://wandb.ai/nreints/ThesisFinal2/runs/k3qu89ls
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_225007-k3qu89ls/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_225920-8dnlnmkn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run logical-yogurt-1137
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/8dnlnmkn
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue █▅▃▂▁▂▁▁▁▂
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue █▅▃▂▁▂▁▁▁▂
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue █▅▃▂▁▂▁▁▁▂
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue █▅▃▂▁▂▁▁▁▂
wandb:                                 Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 3e-05
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue 3e-05
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue 3e-05
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue 3e-05
wandb:                                 Train loss 1e-05
wandb: 
wandb: 🚀 View run logical-yogurt-1137 at: https://wandb.ai/nreints/ThesisFinal2/runs/8dnlnmkn
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_225920-8dnlnmkn/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_230636-25qedlpw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run avid-resonance-1139
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/25qedlpw
	 Logging test loss: 2.6731e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.6708e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.6711e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.6723e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 27.355647563934326
Epoch 6/9
	 Logging train Loss: 1.04839e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.699e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.698e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.6974e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.6983e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 27.317052841186523
Epoch 7/9
	 Logging train Loss: 7.8158e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 9.1941e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 9.1846e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 9.1954e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 9.1939e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 27.29988741874695
Epoch 8/9
	 Logging train Loss: 8.5332e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.985e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 7.978e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 7.978e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.982e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 27.53857970237732
Epoch 9/9
	 Logging train Loss: 6.1804e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.765e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 7.764e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 7.763e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.76e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 27.200050354003906
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'pos_diff_start'_'False'.pth
It took  552.9634952545166  seconds.
----- ITERATION 6/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 76.114022731781 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pNone_gTrue took 19.57028079032898 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pNone_gTrue took 19.560930252075195 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 19.20609712600708 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pNone_gTrue took 19.573103189468384 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(24, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=24, bias=True)
)
Datatype: pos_diff_start
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0256795492 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0001724191 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 0.0001724709 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 0.0001724782 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0001725495 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 27.163530588150024
Epoch 1/9
	 Logging train Loss: 0.0001296193 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 9.88219e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 9.88661e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 9.88807e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 9.89017e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 27.369497776031494
Epoch 2/9
	 Logging train Loss: 8.05758e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.12421e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 6.12561e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 6.1236e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.12726e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 27.190076112747192
Epoch 3/9
	 Logging train Loss: 4.81068e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.78212e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.78353e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.78343e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.78392e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 27.293213844299316
Epoch 4/9
	 Logging train Loss: 2.05997e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.7372e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 5.7444e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 5.7352e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.7392e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 27.072473287582397
Epoch 5/9
	 Logging train Loss: 9.3189e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.70006e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.70059e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.70108e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.70255e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 27.233309507369995
Epoch 6/9
	 Logging train Loss: 9.7377e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.4952e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.4935e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.4939e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.4938e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 26.95120859146118
Epoch 7/9
	 Logging train Loss: 8.1963e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.8778e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 4.8757e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 4.8755e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.8774e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 27.094561338424683
Epoch 8/9
	 Logging train Loss: 8.3117e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.241e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 8.23e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 8.234e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.232e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 27.239403009414673
Epoch 9/9
	 Logging train Loss: 8.3244e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.16601e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.16496e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 3.16464e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.16552e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 27.0675950050354
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'pos_diff_start'_'False'.pth
It took  436.00679302215576  seconds.
----- ITERATION 7/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 76.06195092201233 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pNone_gTrue took 19.470762968063354 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pNone_gTrue took 19.41931462287903 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 19.174767017364502 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pNone_gTrue took 19.410863876342773 seconds.
-- Finished Test Dataloader(s) --
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue █▅▃▂▂▁▁▁▁▁
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue █▅▃▂▂▁▁▁▁▁
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue █▅▃▂▂▁▁▁▁▁
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue █▅▃▂▂▁▁▁▁▁
wandb:                                 Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue 0.0
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue 0.0
wandb:                                 Train loss 1e-05
wandb: 
wandb: 🚀 View run avid-resonance-1139 at: https://wandb.ai/nreints/ThesisFinal2/runs/25qedlpw
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_230636-25qedlpw/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_231359-gcl4bs4x
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sweet-butterfly-1141
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/gcl4bs4x
GRU(
  (rnn): GRU(24, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=24, bias=True)
)
Datatype: pos_diff_start
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.028870536 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0001939889 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 0.0001938574 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 0.000193839 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0001938479 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 27.71145224571228
Epoch 1/9
	 Logging train Loss: 0.0001439337 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0001101394 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 0.0001100724 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 0.0001100574 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0001100256 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 27.915417671203613
Epoch 2/9
	 Logging train Loss: 8.9409e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.95177e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 6.95268e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 6.95711e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.95655e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 27.10801672935486
Epoch 3/9
	 Logging train Loss: 5.51323e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.71657e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.7159e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 3.71354e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.7152e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 27.07082724571228
Epoch 4/9
	 Logging train Loss: 2.66416e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.51727e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.51781e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.51663e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.51784e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 27.10961890220642
Epoch 5/9
	 Logging train Loss: 1.28642e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.3876e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 4.3862e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 4.39e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.3855e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 27.322399854660034
Epoch 6/9
	 Logging train Loss: 1.07153e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.0705e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.0712e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.0726e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.0711e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 27.138252019882202
Epoch 7/9
	 Logging train Loss: 7.5123e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.5383e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 4.5375e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 4.5368e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.5349e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 27.240511178970337
Epoch 8/9
	 Logging train Loss: 8.5788e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.1627e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.1631e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.1622e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.1624e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 27.142783880233765
Epoch 9/9
	 Logging train Loss: 7.7181e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.5461e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.5458e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.5457e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.5457e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 27.101635217666626
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'pos_diff_start'_'False'.pth
It took  443.4442937374115  seconds.
----- ITERATION 8/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 75.86414194107056 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pNone_gTrue took 19.463895559310913 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pNone_gTrue took 19.472370386123657 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 19.24811291694641 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pNone_gTrue took 19.502466201782227 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(24, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=24, bias=True)
)
Datatype: pos_diff_start
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0319456197 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0001915702 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 0.000191616 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 0.0001916416 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0001916688 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 27.248611211776733
Epoch 1/9
	 Logging train Loss: 0.0001412721 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0001127086 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 0.0001127597 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 0.0001126968 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0001127516 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 27.42216730117798
Epoch 2/9
	 Logging train Loss: 8.9066e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.9438e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 6.94949e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 6.9462e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.95144e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 27.19056987762451
Epoch 3/9
	 Logging train Loss: 5.68163e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.85757e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.85958e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 3.85791e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.85653e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 27.288004398345947
Epoch 4/9
	 Logging train Loss: 2.71976e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 9.9255e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 9.9296e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 9.9268e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 9.9325e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 27.037455558776855
Epoch 5/9
	 Logging train Loss: 1.04661e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.2037e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.206e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.2032e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.2026e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 27.080499172210693
Epoch 6/9
	 Logging train Loss: 6.152e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue █▅▄▂▁▁▁▁▁▁
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue █▅▄▂▁▁▁▁▁▁
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue █▅▄▂▁▁▁▁▁▁
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue █▅▄▂▁▁▁▁▁▁
wandb:                                 Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue 0.0
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue 0.0
wandb:                                 Train loss 1e-05
wandb: 
wandb: 🚀 View run sweet-butterfly-1141 at: https://wandb.ai/nreints/ThesisFinal2/runs/gcl4bs4x
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_231359-gcl4bs4x/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_232117-o9q15hqg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run neat-wood-1153
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/o9q15hqg
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue █▅▄▃▁▁▁▁▁▁
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue █▅▄▃▁▁▁▁▁▁
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue █▅▄▃▁▁▁▁▁▁
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue █▅▄▃▁▁▁▁▁▁
wandb:                                 Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue 0.0
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue 0.0
wandb:                                 Train loss 1e-05
wandb: 
wandb: 🚀 View run neat-wood-1153 at: https://wandb.ai/nreints/ThesisFinal2/runs/o9q15hqg
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_232117-o9q15hqg/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_232833-l9u1ry8w
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run youthful-snow-1163
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/l9u1ry8w
	 Logging test loss: 2.3685e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.3683e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.3678e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.3698e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 27.095470666885376
Epoch 7/9
	 Logging train Loss: 8.6857e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.4333e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.4329e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.4336e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.4335e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 26.893933296203613
Epoch 8/9
	 Logging train Loss: 5.2441e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.6967e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.698e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 3.6966e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.6966e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 26.815553665161133
Epoch 9/9
	 Logging train Loss: 7.5651e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.946e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 5.946e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 5.944e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.947e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 26.94892692565918
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'pos_diff_start'_'False'.pth
It took  437.10730242729187  seconds.
----- ITERATION 9/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 76.20637440681458 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pNone_gTrue took 19.526812314987183 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pNone_gTrue took 19.479130029678345 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 19.31906032562256 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pNone_gTrue took 19.521612405776978 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(24, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=24, bias=True)
)
Datatype: pos_diff_start
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0308469534 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0001799096 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 0.000179904 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 0.0001799574 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0001799084 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 26.8494610786438
Epoch 1/9
	 Logging train Loss: 0.0001364327 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0001058757 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 0.0001059059 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 0.0001058742 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.000105847 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 27.222295999526978
Epoch 2/9
	 Logging train Loss: 8.65617e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.88099e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 6.88414e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 6.88483e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.88057e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 27.41139316558838
Epoch 3/9
	 Logging train Loss: 5.69864e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.98435e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.98468e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 3.98253e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.98322e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 27.370569705963135
Epoch 4/9
	 Logging train Loss: 2.80664e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.1465e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.14699e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.14606e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.14647e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 26.94739270210266
Epoch 5/9
	 Logging train Loss: 1.1457e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.0719e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.0737e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 3.0747e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.0743e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 26.885093450546265
Epoch 6/9
	 Logging train Loss: 1.10393e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.4116e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.4126e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.4121e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.412e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 26.817872524261475
Epoch 7/9
	 Logging train Loss: 7.6917e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.053e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.0534e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.0529e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.0521e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 27.037052154541016
Epoch 8/9
	 Logging train Loss: 8.9657e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 9.046e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 9.043e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 9.043e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 9.046e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 26.853896617889404
Epoch 9/9
	 Logging train Loss: 6.5171e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.0909e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.0924e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.0916e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.0918e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 26.99981689453125
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'pos_diff_start'_'False'.pth
It took  436.8874707221985  seconds.
----- ITERATION 10/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 75.98731088638306 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pNone_gTrue took 19.51536750793457 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pNone_gTrue took 19.46974754333496 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 19.254826068878174 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pNone_gTrue took 19.461629629135132 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(24, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=24, bias=True)
)
Datatype: pos_diff_start
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0267894901 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0001666805 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 0.0001666739 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 0.0001666277 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue █▅▄▃▂▁▁▁▁▁
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue █▅▄▃▂▁▁▁▁▁
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue █▅▄▃▂▁▁▁▁▁
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue █▅▄▃▂▁▁▁▁▁
wandb:                                 Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue 0.0
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue 0.0
wandb:                                 Train loss 1e-05
wandb: 
wandb: 🚀 View run youthful-snow-1163 at: https://wandb.ai/nreints/ThesisFinal2/runs/l9u1ry8w
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_232833-l9u1ry8w/logs
	 Logging test loss: 0.0001665765 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 26.854432821273804
Epoch 1/9
	 Logging train Loss: 0.0001259648 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 9.85909e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 9.863e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 9.86423e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 9.86669e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 27.037683963775635
Epoch 2/9
	 Logging train Loss: 8.21538e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.79746e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 6.79676e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 6.80506e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.79966e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 26.885453701019287
Epoch 3/9
	 Logging train Loss: 5.81095e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.56067e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 4.5593e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 4.56261e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.56033e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 26.83569622039795
Epoch 4/9
	 Logging train Loss: 3.99364e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.97952e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.98085e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.97926e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.97965e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 26.86421275138855
Epoch 5/9
	 Logging train Loss: 2.03947e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.3489e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 7.3524e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 7.351e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.3564e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 27.016101598739624
Epoch 6/9
	 Logging train Loss: 9.3145e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.6929e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.692e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.6926e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.693e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 27.16288733482361
Epoch 7/9
	 Logging train Loss: 1.0894e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.0264e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.0252e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.0257e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.0259e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 26.920682907104492
Epoch 8/9
	 Logging train Loss: 6.4512e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 9.111e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 9.106e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 9.106e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 9.107e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 26.96782159805298
Epoch 9/9
	 Logging train Loss: 6.3472e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.68e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 8.674e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 8.681e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.676e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 27.221730947494507
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'pos_diff_start'_'False'.pth
It took  434.8632836341858  seconds.

JOB STATISTICS
==============
Job ID: 3039024
Array Job ID: 3039024_24
Cluster: snellius
User/Group: nreints/nreints
State: COMPLETED (exit code 0)
Nodes: 1
Cores per node: 18
CPU Utilized: 01:14:06
CPU Efficiency: 5.46% of 22:36:18 core-walltime
Job Wall-clock time: 01:15:21
Memory Utilized: 10.49 GB
Memory Efficiency: 0.00% of 0.00 MB
