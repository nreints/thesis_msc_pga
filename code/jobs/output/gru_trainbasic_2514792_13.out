wandb: Currently logged in as: nreints. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230329_133617-x6ivid64
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run good-grass-505
wandb: â­ï¸ View project at https://wandb.ai/nreints/test
wandb: ðŸš€ View run at https://wandb.ai/nreints/test/runs/x6ivid64
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.031 MB of 0.078 MB uploaded (0.000 MB deduped)wandb: \ 0.078 MB of 0.078 MB uploaded (0.000 MB deduped)wandb: | 0.078 MB of 0.078 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:                                                    Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb: Test loss t(5, 20)_r(0, 0)_tennis_pNone_gNone, MSELoss() â–ˆâ–„â–‚â–â–â–â–â–â–â–â–
wandb:                                               Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                                    Epoch 9
wandb: Test loss t(5, 20)_r(0, 0)_tennis_pNone_gNone, MSELoss() 0.00291
wandb:                                               Train loss 0.00852
wandb: 
wandb: ðŸš€ View run good-grass-505 at: https://wandb.ai/nreints/test/runs/x6ivid64
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230329_133617-x6ivid64/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230329_134536-4ddx296e
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run clear-river-529
wandb: â­ï¸ View project at https://wandb.ai/nreints/test
wandb: ðŸš€ View run at https://wandb.ai/nreints/test/runs/4ddx296e
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                                    Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb: Test loss t(5, 20)_r(0, 0)_tennis_pNone_gNone, MSELoss() â–ˆâ–ƒâ–‡â–â–â–â–â–â–‡â–‚â–‚
wandb:                                               Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                                    Epoch 9
wandb: Test loss t(5, 20)_r(0, 0)_tennis_pNone_gNone, MSELoss() 0.01569
wandb:                                               Train loss 0.00738
wandb: 
wandb: ðŸš€ View run clear-river-529 at: https://wandb.ai/nreints/test/runs/4ddx296e
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230329_134536-4ddx296e/logs
Running for data type: log_dualQ
----- ITERATION 1/2 ------
Number of train simulations: 1600
Number of test simulations: 400
-- Finished Train Dataloader --
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(6, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=6, bias=True)
)
-- Started Training --
Epoch 0
	 Logging train Loss: 5.6466884231 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss: 0.1817064881324768 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 51.07320976257324
Epoch 1
	 Logging train Loss: 0.0968340478 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss: 0.08596711605787277 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 48.968499422073364
Epoch 2
	 Logging train Loss: 0.0406799164 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss: 0.02219945564866066 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 49.014554500579834
Epoch 3
	 Logging train Loss: 0.0231005334 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss: 0.010537486523389816 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 49.43336725234985
Epoch 4
	 Logging train Loss: 0.0177095627 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss: 0.007341292221099138 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 49.04149770736694
Epoch 5
	 Logging train Loss: 0.0156544786 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss: 0.00907069444656372 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 49.26279401779175
Epoch 6
	 Logging train Loss: 0.0113010992 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss: 0.0023416646290570498 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 49.23214936256409
Epoch 7
	 Logging train Loss: 0.0115521129 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss: 0.0020297772716730833 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 49.42146968841553
Epoch 8
	 Logging train Loss: 0.0106266229 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss: 0.003951206337660551 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 48.924150705337524
Epoch 9
	 Logging train Loss: 0.0085198239 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss: 0.0029056863859295845 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 48.8903284072876
	 Logging test loss: 0.0029101702384650707 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
It took  560.3617131710052  seconds.
----- ITERATION 2/2 ------
Number of train simulations: 1600
Number of test simulations: 400
-- Finished Train Dataloader --
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(6, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=6, bias=True)
)
-- Started Training --
Epoch 0
	 Logging train Loss: 5.8358136369 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss: 0.19250865280628204 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 49.767674684524536
Epoch 1
	 Logging train Loss: 0.1050093566 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss: 0.0542481392621994 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 51.852511405944824
Epoch 2
	 Logging train Loss: 0.0420222034 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss: 0.17633725702762604 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 51.2908296585083
Epoch 3
	 Logging train Loss: 0.025049887 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss: 0.008633904159069061 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 50.43222212791443
Epoch 4
	 Logging train Loss: 0.0158064872 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss: 0.00552429910749197 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 51.05315923690796
Epoch 5
	 Logging train Loss: 0.0157849474 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss: 0.0031500509940087795 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 49.44464325904846
Epoch 6
	 Logging train Loss: 0.0132971217 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss: 0.008146285079419613 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 49.48894929885864
Epoch 7
	 Logging train Loss: 0.0136762792 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss: 0.0019439677707850933 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 49.86716341972351
Epoch 8
	 Logging train Loss: 0.009468889 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss: 0.17315243184566498 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 49.79979372024536
Epoch 9
	 Logging train Loss: 0.0073798374 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss: 0.01571364514529705 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 48.75115704536438
	 Logging test loss: 0.015691380947828293 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
It took  564.3027439117432  seconds.

JOB STATISTICS
==============
Job ID: 2514805
Array Job ID: 2514792_13
Cluster: snellius
User/Group: nreints/nreints
State: COMPLETED (exit code 0)
Nodes: 1
Cores per node: 18
CPU Utilized: 04:00:27
CPU Efficiency: 70.49% of 05:41:06 core-walltime
Job Wall-clock time: 00:18:57
Memory Utilized: 24.73 GB
Memory Efficiency: 79.13% of 31.25 GB
