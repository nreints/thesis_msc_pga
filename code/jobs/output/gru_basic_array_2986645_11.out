wandb: Currently logged in as: nreints. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230629_112031-i3vza87j
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run clear-haze-31
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/i3vza87j
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone â–ˆâ–ƒâ–‚â–â–â–‚â–‚â–â–â–
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone â–ˆâ–ƒâ–â–â–â–â–â–â–â–
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone â–ˆâ–ƒâ–â–â–â–â–â–â–â–
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone â–ˆâ–‚â–‚â–â–â–ƒâ–ƒâ–â–‚â–
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone â–ˆâ–‚â–‚â–â–â–‚â–ƒâ–â–‚â–
wandb:                                  Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone 1e-05
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone 1e-05
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone 1e-05
wandb:                                  Train loss 2e-05
wandb: 
wandb: ðŸš€ View run clear-haze-31 at: https://wandb.ai/nreints/ThesisFinal2/runs/i3vza87j
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230629_112031-i3vza87j/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230629_112851-8wz5ty31
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run skilled-rain-43
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/8wz5ty31
Training on dataset: data_t(0,0)_r(5,20)_combi_pNone_gNone
Testing on 5 datasets: ['data_t(0,0)_r(5,20)_semi_pNone_gNone', 'data_t(0,0)_r(5,20)_tennis_pNone_gNone', 'data_t(0,0)_r(5,20)_full_pNone_gNone', 'data_t(0,0)_r(5,20)_combi_pNone_gNone', 'data_t(0,0)_r(5,20)_none_pNone_gNone']
Focussing on identity: False
Using extra input: False
Using fr-fr as reference point.
----- ITERATION 1/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 52.21923613548279 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(5,20)_semi_pNone_gNone took 13.142280578613281 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_tennis_pNone_gNone took 12.95041298866272 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_full_pNone_gNone took 12.518914699554443 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 13.496044158935547 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_none_pNone_gNone took 12.879793405532837 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0169289708 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.45214e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.70127e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.50601e-05 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.6709e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.53624e-05 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 37.36854863166809
Epoch 1/9
	 Logging train Loss: 2.90269e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.85138e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.89226e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.5188e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.91859e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.7278e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 35.7906014919281
Epoch 2/9
	 Logging train Loss: 1.5493e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.47233e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.49069e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.0058e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.26385e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.1507e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 35.340213775634766
Epoch 3/9
	 Logging train Loss: 1.05885e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.35512e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.37404e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 5.235e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 9.3895e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.467e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 35.39371037483215
Epoch 4/9
	 Logging train Loss: 8.3777e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.31901e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.33252e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.661e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 7.8829e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.779e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 35.46334624290466
Epoch 5/9
	 Logging train Loss: 1.26854e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.9038e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.9658e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 5.671e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.08166e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.728e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 35.5265531539917
Epoch 6/9
	 Logging train Loss: 1.67135e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.16344e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.27403e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 5.222e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.22678e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.188e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 35.59782552719116
Epoch 7/9
	 Logging train Loss: 1.83122e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.21776e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.25202e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.752e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 6.803e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.586e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 36.103883028030396
Epoch 8/9
	 Logging train Loss: 2.04232e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.43838e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.48056e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.895e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 8.1372e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.713e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 35.92999815940857
Epoch 9/9
	 Logging train Loss: 1.64171e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.18994e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.22078e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.569e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 6.6023e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.301e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 35.80279350280762
Saved model in  trained_models/gru/data_t(0,0)_r(5,20)_combi_pNone_gNone/'dual_quat_1'_'False'.pth
It took  501.32127356529236  seconds.
----- ITERATION 2/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 48.120033502578735 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(5,20)_semi_pNone_gNone took 12.479077816009521 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_tennis_pNone_gNone took 12.394533395767212 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_full_pNone_gNone took 11.48296594619751 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 12.069782495498657 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_none_pNone_gNone took 11.495927095413208 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0093926769 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.32242e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.49761e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 6.0306e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.39086e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.1227e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 35.8853178024292
Epoch 1/9
	 Logging train Loss: 2.11346e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.74167e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.76524e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone â–†â–ƒâ–‚â–â–„â–ƒâ–â–ˆâ–ƒâ–
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone â–ˆâ–‚â–â–â–‚â–ƒâ–â–†â–‚â–
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone â–ˆâ–‚â–â–â–‚â–ƒâ–â–…â–‚â–
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone â–ƒâ–‚â–â–â–„â–ƒâ–â–ˆâ–ƒâ–
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone â–ƒâ–‚â–â–â–„â–ƒâ–â–ˆâ–ƒâ–
wandb:                                  Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone 1e-05
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone 1e-05
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone 1e-05
wandb:                                  Train loss 2e-05
wandb: 
wandb: ðŸš€ View run skilled-rain-43 at: https://wandb.ai/nreints/ThesisFinal2/runs/8wz5ty31
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230629_112851-8wz5ty31/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230629_113648-b5wihbgo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dashing-star-60
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/b5wihbgo
	 Logging test loss: 7.214e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.60131e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.23e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 35.51892375946045
Epoch 2/9
	 Logging train Loss: 1.20975e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.55494e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.56564e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.916e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.00168e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.898e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 35.595925092697144
Epoch 3/9
	 Logging train Loss: 8.8908e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.45753e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.46715e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.487e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 7.8219e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.437e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 35.66073179244995
Epoch 4/9
	 Logging train Loss: 1.15322e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.36691e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.65242e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.2122e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.17852e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.2635e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 35.53078246116638
Epoch 5/9
	 Logging train Loss: 2.22098e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.8092e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.99502e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.6529e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.46706e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.7254e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 35.444103479385376
Epoch 6/9
	 Logging train Loss: 2.57572e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.18878e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.18947e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.185e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 5.9551e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.988e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 35.51871919631958
Epoch 7/9
	 Logging train Loss: 2.18238e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.40562e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 9.02003e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.0009e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.28745e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.0016e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 35.32991671562195
Epoch 8/9
	 Logging train Loss: 2.18774e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.99809e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.21529e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 9.754e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.51856e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.0208e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 35.66050386428833
Epoch 9/9
	 Logging train Loss: 1.84898e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.1609e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.19479e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.741e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 5.8169e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.384e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 35.51691436767578
Saved model in  trained_models/gru/data_t(0,0)_r(5,20)_combi_pNone_gNone/'dual_quat_1'_'False'.pth
It took  477.00214529037476  seconds.
----- ITERATION 3/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 46.78754210472107 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(5,20)_semi_pNone_gNone took 12.239065885543823 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_tennis_pNone_gNone took 12.20157241821289 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_full_pNone_gNone took 12.308153867721558 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 11.839500427246094 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_none_pNone_gNone took 12.354494333267212 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0237534642 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.12898e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.23344e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 8.3754e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.03446e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.5392e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 35.55056405067444
Epoch 1/9
	 Logging train Loss: 2.50022e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.12956e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.07555e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.3776e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.74724e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.4912e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 35.66677951812744
Epoch 2/9
	 Logging train Loss: 1.41012e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.87763e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.81481e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 6.194e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.25399e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.245e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 35.338401794433594
Epoch 3/9
	 Logging train Loss: 9.9407e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.65819e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.58657e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.322e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 9.5406e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.335e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 35.90340828895569
Epoch 4/9
	 Logging train Loss: 8.1164e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.47396e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.39096e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.984e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 7.9016e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.955e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 35.708357095718384
Epoch 5/9
	 Logging train Loss: 1.06826e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.97569e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone â–ˆâ–ƒâ–‚â–â–â–„â–â–‡â–‚â–ƒ
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone â–ˆâ–‚â–â–â–â–‚â–â–ƒâ–‚â–‚
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone â–ˆâ–‚â–â–â–â–‚â–â–ƒâ–‚â–‚
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone â–…â–‚â–‚â–â–â–…â–â–ˆâ–‚â–ƒ
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone â–…â–‚â–‚â–â–â–…â–â–ˆâ–‚â–„
wandb:                                  Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone 2e-05
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone 3e-05
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone 3e-05
wandb:                                  Train loss 2e-05
wandb: 
wandb: ðŸš€ View run dashing-star-60 at: https://wandb.ai/nreints/ThesisFinal2/runs/b5wihbgo
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230629_113648-b5wihbgo/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230629_114445-btuh7s7z
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wise-snow-75
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/btuh7s7z
	 Logging test loss: 4.20838e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.0183e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.1983e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.0587e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 35.62638235092163
Epoch 6/9
	 Logging train Loss: 1.72606e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.69516e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.66685e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 5.314e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 9.141e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.216e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 36.1908004283905
Epoch 7/9
	 Logging train Loss: 1.94887e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.1388e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 6.58693e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.3027e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.3715e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.3099e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 35.743210315704346
Epoch 8/9
	 Logging train Loss: 1.77702e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.28027e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.33661e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.1614e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.26775e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.2221e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 35.69235181808472
Epoch 9/9
	 Logging train Loss: 1.85283e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.1298e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.32288e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.6159e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.78052e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.6394e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 35.47901892662048
Saved model in  trained_models/gru/data_t(0,0)_r(5,20)_combi_pNone_gNone/'dual_quat_1'_'False'.pth
It took  476.9167618751526  seconds.
----- ITERATION 4/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 46.44470953941345 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(5,20)_semi_pNone_gNone took 12.267988443374634 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_tennis_pNone_gNone took 12.297987461090088 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_full_pNone_gNone took 12.33518123626709 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 11.864444494247437 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_none_pNone_gNone took 12.427864789962769 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0217149984 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.76642e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.70874e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 8.5635e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.13787e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.798e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 35.584582567214966
Epoch 1/9
	 Logging train Loss: 2.31592e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.19974e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.0963e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.4998e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.59353e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.6635e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 35.798407793045044
Epoch 2/9
	 Logging train Loss: 1.35298e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.8108e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.69788e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 7.79e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 9.8206e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 9.106e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 35.45125460624695
Epoch 3/9
	 Logging train Loss: 9.7978e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.67129e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.56585e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.081e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 7.7665e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.219e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 35.66136384010315
Epoch 4/9
	 Logging train Loss: 8.3983e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.5135e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.41279e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.233e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 6.8449e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.281e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 35.42626881599426
Epoch 5/9
	 Logging train Loss: 9.0106e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.43621e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.34529e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.264e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 6.4525e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.234e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 35.861802101135254
Epoch 6/9
	 Logging train Loss: 1.50042e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.455e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.60235e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 7.872e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.62755e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 9.049e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 35.87677049636841
Epoch 7/9
	 Logging train Loss: 1.95034e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.51872e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.45814e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 6.771e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 7.0329e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.575e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 35.50956058502197
Epoch 8/9
	 Logging train Loss: 1.53333e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.53972e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.50071e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.636e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 6.9685e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.496e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 35.70122218132019
Epoch 9/9
	 Logging train Loss: 1.53263e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone â–ˆâ–„â–‚â–â–â–â–„â–â–â–
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone â–ˆâ–ƒâ–â–â–â–â–â–â–â–
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone â–ˆâ–ƒâ–â–â–â–â–â–â–â–
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone â–ˆâ–ƒâ–‚â–‚â–â–â–‡â–â–â–
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone â–ˆâ–ƒâ–‚â–‚â–â–â–ˆâ–â–â–
wandb:                                  Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone 1e-05
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone 2e-05
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone 1e-05
wandb:                                  Train loss 2e-05
wandb: 
wandb: ðŸš€ View run wise-snow-75 at: https://wandb.ai/nreints/ThesisFinal2/runs/btuh7s7z
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230629_114445-btuh7s7z/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230629_115242-vlqmrdrw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run classic-breeze-92
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/vlqmrdrw
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone â–ˆâ–„â–‚â–‚â–‚â–‚â–ƒâ–â–‚â–
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone â–ˆâ–ƒâ–â–â–‚â–â–‚â–â–ƒâ–
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone â–ˆâ–ƒâ–‚â–â–‚â–â–‚â–â–ƒâ–
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone â–ˆâ–„â–ƒâ–‚â–„â–ƒâ–†â–‚â–„â–
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone â–ˆâ–„â–ƒâ–‚â–„â–ƒâ–†â–‚â–„â–
wandb:                                  Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone 1e-05
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone 1e-05
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone 1e-05
wandb:                                  Train loss 2e-05
wandb: 
wandb: ðŸš€ View run classic-breeze-92 at: https://wandb.ai/nreints/ThesisFinal2/runs/vlqmrdrw
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230629_115242-vlqmrdrw/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230629_120040-s3bsihsl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run golden-dawn-110
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/s3bsihsl
	 Logging test loss: 1.51678e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.49392e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.074e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 6.9302e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.857e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 35.57090401649475
Saved model in  trained_models/gru/data_t(0,0)_r(5,20)_combi_pNone_gNone/'dual_quat_1'_'False'.pth
It took  476.96095395088196  seconds.
----- ITERATION 5/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 46.52509808540344 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(5,20)_semi_pNone_gNone took 12.325981855392456 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_tennis_pNone_gNone took 12.283530712127686 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_full_pNone_gNone took 12.291259288787842 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 11.76132583618164 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_none_pNone_gNone took 12.351771593093872 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.016198542 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.32645e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.25348e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.7831e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.60096e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.1099e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 35.40618538856506
Epoch 1/9
	 Logging train Loss: 1.98725e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.08054e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.00658e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.4251e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.3137e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.5991e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 35.790531158447266
Epoch 2/9
	 Logging train Loss: 1.15496e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.71612e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.642e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 5.357e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 8.6335e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.703e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 35.626989126205444
Epoch 3/9
	 Logging train Loss: 8.9808e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.55836e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.49238e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.337e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 7.2111e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.558e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 35.534576416015625
Epoch 4/9
	 Logging train Loss: 9.1677e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.92644e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.89899e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 6.737e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 9.1412e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.82e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 35.35876131057739
Epoch 5/9
	 Logging train Loss: 1.42005e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.8683e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.84026e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 5.08e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 8.7853e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.133e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 36.11078238487244
Epoch 6/9
	 Logging train Loss: 1.84164e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.56322e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.6319e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 7.665e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.22886e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.642e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 35.857224225997925
Epoch 7/9
	 Logging train Loss: 2.00189e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.31944e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.27783e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.255e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 6.0417e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.085e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 35.71678423881531
Epoch 8/9
	 Logging train Loss: 1.82133e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.9332e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.95905e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.5746e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 9.6786e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.6476e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 35.82554745674133
Epoch 9/9
	 Logging train Loss: 1.59999e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.13809e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.11218e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.238e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 5.2265e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.997e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 35.62190222740173
Saved model in  trained_models/gru/data_t(0,0)_r(5,20)_combi_pNone_gNone/'dual_quat_1'_'False'.pth
It took  477.9376902580261  seconds.
----- ITERATION 6/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 46.451911211013794 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(5,20)_semi_pNone_gNone took 12.259626626968384 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_tennis_pNone_gNone took 12.198183536529541 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_full_pNone_gNone took 12.188916206359863 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 11.941251277923584 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_none_pNone_gNone took 12.371170282363892 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0403937772 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.85552e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 9.82553e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.9624e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 7.06143e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.4455e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 35.38391971588135
Epoch 1/9
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone â–ˆâ–‚â–‚â–â–â–ƒâ–‚â–‚â–„â–
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone â–ˆâ–ƒâ–â–â–â–†â–ƒâ–‚â–…â–
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone â–ˆâ–ƒâ–â–â–â–…â–ƒâ–‚â–…â–
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone â–ˆâ–‚â–â–â–â–ƒâ–‚â–‚â–„â–
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone â–ˆâ–‚â–â–â–â–ƒâ–‚â–‚â–…â–
wandb:                                  Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone 1e-05
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone 1e-05
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone 1e-05
wandb:                                  Train loss 1e-05
wandb: 
wandb: ðŸš€ View run golden-dawn-110 at: https://wandb.ai/nreints/ThesisFinal2/runs/s3bsihsl
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230629_120040-s3bsihsl/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230629_120836-3x0iyyaq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fine-dragon-124
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/3x0iyyaq
	 Logging train Loss: 3.54215e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.34224e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.54598e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.2643e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.08935e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.4645e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 35.775585412979126
Epoch 2/9
	 Logging train Loss: 1.41791e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.56273e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.66533e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.785e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.21964e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.299e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 35.64695119857788
Epoch 3/9
	 Logging train Loss: 9.0147e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.5111e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.61355e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.323e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.02787e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.647e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 35.45492696762085
Epoch 4/9
	 Logging train Loss: 7.5202e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.40484e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.48605e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.969e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 9.3335e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.214e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 35.46301484107971
Epoch 5/9
	 Logging train Loss: 7.7668e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.20252e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.60953e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.3747e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.14866e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.5186e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 35.78321075439453
Epoch 6/9
	 Logging train Loss: 1.4992e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.78091e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.06409e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.7538e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.83822e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.8934e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 35.74279546737671
Epoch 7/9
	 Logging train Loss: 1.64713e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.29664e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.55345e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 7.112e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.47996e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.366e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 35.51883912086487
Epoch 8/9
	 Logging train Loss: 1.85135e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.82276e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 5.52543e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.2263e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.14737e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.4039e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 35.85193872451782
Epoch 9/9
	 Logging train Loss: 1.44219e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.13874e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.2246e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.027e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 7.5556e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.888e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 35.53435134887695
Saved model in  trained_models/gru/data_t(0,0)_r(5,20)_combi_pNone_gNone/'dual_quat_1'_'False'.pth
It took  475.9270133972168  seconds.
----- ITERATION 7/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 46.542927503585815 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(5,20)_semi_pNone_gNone took 12.155893325805664 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_tennis_pNone_gNone took 12.258955717086792 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_full_pNone_gNone took 12.176241397857666 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 11.80370306968689 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_none_pNone_gNone took 12.295595407485962 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0237763766 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.12929e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.44527e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.6495e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.67192e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.7962e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 35.47865891456604
Epoch 1/9
	 Logging train Loss: 1.79849e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.9392e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.06417e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 6.96e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.38568e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.166e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 35.64838671684265
Epoch 2/9
	 Logging train Loss: 1.1058e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.69512e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.78778e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.111e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 9.9924e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.24e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 35.46746277809143
Epoch 3/9
	 Logging train Loss: 8.709e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.55859e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.63084e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.923e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 8.495e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.982e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 35.439926624298096
Epoch 4/9
	 Logging train Loss: 8.0289e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.51872e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.59167e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.574e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 8.0939e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.561e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone â–ˆâ–„â–‚â–‚â–‚â–â–‚â–â–„â–‚
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone â–ˆâ–ƒâ–‚â–â–â–â–‚â–â–‡â–‚
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone â–ˆâ–ƒâ–‚â–â–â–â–‚â–â–‡â–‚
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone â–ˆâ–„â–ƒâ–‚â–‚â–‚â–‚â–â–‡â–ƒ
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone â–ˆâ–„â–ƒâ–‚â–‚â–‚â–‚â–â–‡â–ƒ
wandb:                                  Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone 1e-05
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone 2e-05
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone 2e-05
wandb:                                  Train loss 2e-05
wandb: 
wandb: ðŸš€ View run fine-dragon-124 at: https://wandb.ai/nreints/ThesisFinal2/runs/3x0iyyaq
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230629_120836-3x0iyyaq/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230629_121631-6vgosyvx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lucky-universe-142
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/6vgosyvx
		--> Epoch time; 35.34779715538025
Epoch 5/9
	 Logging train Loss: 1.06522e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.34646e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.41698e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.432e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 7.2013e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.359e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 36.02116584777832
Epoch 6/9
	 Logging train Loss: 1.6735e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.49277e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.59292e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.365e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 8.0555e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.187e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 35.833853244781494
Epoch 7/9
	 Logging train Loss: 1.47294e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.16422e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.21817e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 9.6e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 6.1428e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.756e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 35.55640435218811
Epoch 8/9
	 Logging train Loss: 1.83226e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.82017e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.07155e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.3131e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.56057e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.3729e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 35.565054416656494
Epoch 9/9
	 Logging train Loss: 1.54392e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.7003e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.85181e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.926e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 9.1151e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.481e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 35.43393921852112
Saved model in  trained_models/gru/data_t(0,0)_r(5,20)_combi_pNone_gNone/'dual_quat_1'_'False'.pth
It took  474.9060914516449  seconds.
----- ITERATION 8/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 46.406007289886475 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(5,20)_semi_pNone_gNone took 12.079912424087524 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_tennis_pNone_gNone took 12.046020269393921 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_full_pNone_gNone took 12.08125901222229 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 11.749697923660278 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_none_pNone_gNone took 12.170248746871948 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0091252783 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.48709e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.52909e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 5.5008e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.16492e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.6367e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 35.56151604652405
Epoch 1/9
	 Logging train Loss: 1.70469e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.85921e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.86593e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.3575e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.15197e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.4799e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 35.7036247253418
Epoch 2/9
	 Logging train Loss: 1.04106e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.65455e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.6492e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.015e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 8.3368e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.151e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 35.7767539024353
Epoch 3/9
	 Logging train Loss: 8.4135e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.53067e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.52093e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.556e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 7.2785e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.618e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 35.58649921417236
Epoch 4/9
	 Logging train Loss: 8.227e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.5971e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.62467e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.04e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 7.6077e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.082e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 35.52518582344055
Epoch 5/9
	 Logging train Loss: 1.46321e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.5707e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.61237e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 5.277e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 7.684e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.275e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 35.82520318031311
Epoch 6/9
	 Logging train Loss: 1.89982e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.09671e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.44577e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 9.875e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.59151e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.1138e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 35.741063594818115
Epoch 7/9
	 Logging train Loss: 1.76593e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.75961e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.01354e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.1578e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.46484e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.2612e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 35.62862205505371
Epoch 8/9
	 Logging train Loss: 1.78873e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.43519e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.48175e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 7.191e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 7.0478e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone â–ˆâ–ƒâ–‚â–â–â–‚â–…â–…â–â–
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone â–ˆâ–‚â–â–â–â–â–‚â–„â–‚â–
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone â–ˆâ–‚â–â–â–â–â–‚â–„â–‚â–
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone â–†â–ƒâ–‚â–‚â–‚â–‚â–ˆâ–‡â–â–
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone â–…â–ƒâ–‚â–â–‚â–‚â–ˆâ–‡â–â–
wandb:                                  Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone 1e-05
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone 1e-05
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone 1e-05
wandb:                                  Train loss 1e-05
wandb: 
wandb: ðŸš€ View run lucky-universe-142 at: https://wandb.ai/nreints/ThesisFinal2/runs/6vgosyvx
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230629_121631-6vgosyvx/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230629_122426-4hju63dn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dazzling-vortex-159
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/4hju63dn
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone â–ˆâ–„â–‚â–‚â–‚â–‚â–ƒâ–†â–…â–
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone â–ˆâ–‚â–â–â–â–â–‚â–ƒâ–ƒâ–
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone â–ˆâ–‚â–â–â–â–â–‚â–ƒâ–ƒâ–
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone â–„â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ˆâ–…â–
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone â–„â–‚â–‚â–‚â–ƒâ–‚â–ƒâ–ˆâ–…â–
wandb:                                  Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone 1e-05
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone 1e-05
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone 1e-05
wandb:                                  Train loss 2e-05
wandb: 
wandb: ðŸš€ View run dazzling-vortex-159 at: https://wandb.ai/nreints/ThesisFinal2/runs/4hju63dn
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230629_122426-4hju63dn/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230629_123221-b0yzgbi9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vital-universe-171
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/b0yzgbi9
	 Logging test loss: 7.951e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 35.67972755432129
Epoch 9/9
	 Logging train Loss: 1.43299e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.32897e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.39736e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.02e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 6.5375e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.717e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 35.49348735809326
Saved model in  trained_models/gru/data_t(0,0)_r(5,20)_combi_pNone_gNone/'dual_quat_1'_'False'.pth
It took  475.1834008693695  seconds.
----- ITERATION 9/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 46.341495752334595 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(5,20)_semi_pNone_gNone took 12.013362169265747 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_tennis_pNone_gNone took 12.151365518569946 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_full_pNone_gNone took 12.166129112243652 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 11.832597017288208 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_none_pNone_gNone took 12.151955127716064 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0298585724 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.24464e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.44673e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 5.9912e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.39245e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.1544e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 35.6196231842041
Epoch 1/9
	 Logging train Loss: 2.39144e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.98771e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.07835e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.314e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.72946e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.4361e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 35.55532240867615
Epoch 2/9
	 Logging train Loss: 1.442e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.64086e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.69409e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.492e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.06778e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.59e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 35.40086030960083
Epoch 3/9
	 Logging train Loss: 1.08298e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.68753e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.76512e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.289e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 8.6592e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.333e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 35.5715868473053
Epoch 4/9
	 Logging train Loss: 1.0112e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.18914e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.36689e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 5.828e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.04749e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.883e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 35.31891441345215
Epoch 5/9
	 Logging train Loss: 1.09966e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.08676e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.25901e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.07e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 9.7838e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.094e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 36.04049849510193
Epoch 6/9
	 Logging train Loss: 1.56813e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.68559e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.99203e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 8.342e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.30977e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 9.383e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 35.53860640525818
Epoch 7/9
	 Logging train Loss: 1.59936e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.55984e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 6.40223e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.6617e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.67033e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.7992e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 35.65896677970886
Epoch 8/9
	 Logging train Loss: 1.86405e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.90037e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.38778e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.2137e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.97528e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.3163e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 35.67795538902283
Epoch 9/9
	 Logging train Loss: 1.85188e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.09055e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.15058e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 6.558e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 5.3491e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.215e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 35.39911127090454
Saved model in  trained_models/gru/data_t(0,0)_r(5,20)_combi_pNone_gNone/'dual_quat_1'_'False'.pth
It took  475.115168094635  seconds.
----- ITERATION 10/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 46.25569415092468 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(5,20)_semi_pNone_gNone took 11.942095756530762 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_tennis_pNone_gNone took 12.010992527008057 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_full_pNone_gNone took 12.01984453201294 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 11.811159610748291 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_none_pNone_gNone took 12.241931438446045 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0577496551 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.08294e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 6.69239e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.77589e-05 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone â–ˆâ–ƒâ–‚â–â–â–â–â–â–ƒâ–‚
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone â–ˆâ–‚â–â–â–â–â–‚â–â–†â–ƒ
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone â–ˆâ–‚â–â–â–â–â–‚â–â–†â–ƒ
wandb:                                  Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone 1e-05
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone 2e-05
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone 3e-05
wandb:                                  Train loss 2e-05
wandb: 
wandb: ðŸš€ View run vital-universe-171 at: https://wandb.ai/nreints/ThesisFinal2/runs/b0yzgbi9
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230629_123221-b0yzgbi9/logs
	 Logging test loss: 8.66318e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.84465e-05 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 35.27247428894043
Epoch 1/9
	 Logging train Loss: 4.73318e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.08273e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.2673e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.8169e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.46011e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.9401e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 35.665815353393555
Epoch 2/9
	 Logging train Loss: 1.95993e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.49107e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.59429e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.135e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.5097e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.386e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 35.747108459472656
Epoch 3/9
	 Logging train Loss: 1.42155e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.39056e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.47865e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.12e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.15294e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.332e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 35.39217519760132
Epoch 4/9
	 Logging train Loss: 1.08919e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.31231e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.39759e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.489e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 8.4723e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.614e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 35.04421019554138
Epoch 5/9
	 Logging train Loss: 8.4147e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.2333e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.31725e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.749e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 6.5164e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.835e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 34.98897194862366
Epoch 6/9
	 Logging train Loss: 7.4721e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.99879e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.26395e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 6.884e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.03488e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.722e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 35.0536572933197
Epoch 7/9
	 Logging train Loss: 9.8606e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.24532e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.34477e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.137e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 6.0957e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.027e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 34.91750621795654
Epoch 8/9
	 Logging train Loss: 1.49128e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.56546e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 5.50234e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.1839e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.47487e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.2545e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 35.11752653121948
Epoch 9/9
	 Logging train Loss: 1.72682e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.38834e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.76718e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.2348e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.2581e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.3072e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
		--> Epoch time; 34.92577528953552
Saved model in  trained_models/gru/data_t(0,0)_r(5,20)_combi_pNone_gNone/'dual_quat_1'_'False'.pth
It took  471.013920545578  seconds.

JOB STATISTICS
==============
Job ID: 2986705
Array Job ID: 2986645_11
Cluster: snellius
User/Group: nreints/nreints
State: RUNNING
Nodes: 1
Cores per node: 18
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 1-00:00:18 core-walltime
Job Wall-clock time: 01:20:01
Memory Utilized: 0.00 MB (estimated maximum)
Memory Efficiency: 0.00% of 0.00 MB (0.00 MB/node)
WARNING: Efficiency statistics may be misleading for RUNNING jobs.
