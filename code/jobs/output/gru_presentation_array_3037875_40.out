wandb: Currently logged in as: nreints. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_181403-j55la4br
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run winter-yogurt-949
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/j55la4br
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue █▃▂▂▂▁▁▁▁▁
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue █▅▄▃▃▂▂▁▁▁
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue █▃▂▂▂▁▁▁▁▁
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue █▃▂▂▂▁▁▁▁▁
wandb:                                 Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 1e-05
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 2e-05
wandb:                                 Train loss 1e-05
wandb: 
wandb: 🚀 View run winter-yogurt-949 at: https://wandb.ai/nreints/ThesisFinal2/runs/j55la4br
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_181403-j55la4br/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_182213-vw4z99sz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run noble-paper-972
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/vw4z99sz
Training on dataset: data_t(0,0)_r(0,0)_combi_pNone_gTrue
Testing on 4 datasets: ['data_t(0,0)_r(0,0)_semi_pTrue_gTrue', 'data_t(0,0)_r(0,0)_combi_pNone_gTrue', 'data_t(0,0)_r(0,0)_tennis_pTrue_gTrue', 'data_t(0,0)_r(0,0)_full_pTrue_gTrue']
Focussing on identity: False
Using extra input: True
Using fr-fr as reference point.
----- ITERATION 1/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 59.747145891189575 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 14.748992204666138 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 15.031304597854614 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 14.725183010101318 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 14.979259490966797 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (pre_hidden_lin_layer): Sequential(
    (0): Linear(in_features=3, out_features=96, bias=True)
    (1): ReLU()
    (2): Linear(in_features=96, out_features=96, bias=True)
    (3): ReLU()
  )
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0519417264 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0001414735 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 9.31556e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0001860304 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 3.76034e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 36.49739408493042
Epoch 1/9
	 Logging train Loss: 5.38032e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.26036e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 3.28801e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.36888e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.30395e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 35.430211305618286
Epoch 2/9
	 Logging train Loss: 2.4538e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.25538e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 1.88223e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.88009e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.65052e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 35.24559712409973
Epoch 3/9
	 Logging train Loss: 1.5687e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.37629e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 1.32667e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.8659e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.31736e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 35.583101987838745
Epoch 4/9
	 Logging train Loss: 1.16479e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.01242e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 1.01657e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.44614e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.18456e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 35.41630959510803
Epoch 5/9
	 Logging train Loss: 8.9772e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.58656e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 7.6582e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.00784e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 9.0037e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 35.59778070449829
Epoch 6/9
	 Logging train Loss: 7.1478e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.21284e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 5.4761e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.59902e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 5.8671e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 35.345245122909546
Epoch 7/9
	 Logging train Loss: 1.10381e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 9.0429e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 3.3687e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.25049e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 3.4995e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 35.57759070396423
Epoch 8/9
	 Logging train Loss: 1.08533e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.9215e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 2.022e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.02743e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.8524e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 35.21055579185486
Epoch 9/9
	 Logging train Loss: 1.30439e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.22959e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 4.4808e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.56203e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.239e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 35.63916611671448
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'dual_quat_1'_'True'.pth
It took  490.65316939353943  seconds.
----- ITERATION 2/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 54.778109073638916 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 13.75537657737732 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 13.799105882644653 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 13.76016116142273 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 13.82400631904602 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (pre_hidden_lin_layer): Sequential(
    (0): Linear(in_features=3, out_features=96, bias=True)
    (1): ReLU()
    (2): Linear(in_features=96, out_features=96, bias=True)
    (3): ReLU()
  )
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0095597785 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.99963e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 1.58227e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.80312e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.49423e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 35.841360092163086
Epoch 1/9
	 Logging train Loss: 1.21158e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.92132e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 9.28e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.55258e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.09817e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 36.056458473205566
Epoch 2/9
	 Logging train Loss: 7.4703e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.33723e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 5.7137e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.85749e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 6.7793e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 35.30156445503235
Epoch 3/9
	 Logging train Loss: 4.3414e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue █▅▃▂▁▁▂▁▁▁
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue █▆▄▂▁▁▁▁▁▁
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue █▅▃▂▂▁▂▁▁▁
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue █▅▄▂▂▁▂▁▁▁
wandb:                                 Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.0
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 1e-05
wandb:                                 Train loss 1e-05
wandb: 
wandb: 🚀 View run noble-paper-972 at: https://wandb.ai/nreints/ThesisFinal2/runs/vw4z99sz
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_182213-vw4z99sz/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_183013-9xp6ks27
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run devoted-durian-994
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/9xp6ks27
	 Logging test loss: 9.327e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 3.0078e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.38568e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 3.517e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 35.66819477081299
Epoch 4/9
	 Logging train Loss: 5.0255e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.7917e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 1.4462e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.05901e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.5501e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 35.351752519607544
Epoch 5/9
	 Logging train Loss: 8.155e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.6971e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 8.296e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.8048e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 8.414e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 35.67725110054016
Epoch 6/9
	 Logging train Loss: 1.07818e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.1187e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 2.2151e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.1403e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 9.089e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 35.423237323760986
Epoch 7/9
	 Logging train Loss: 1.07104e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.163e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 5.765e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.8926e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 7.631e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 35.33418846130371
Epoch 8/9
	 Logging train Loss: 9.4938e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.4139e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 1.4531e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.9549e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.141e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 34.93677473068237
Epoch 9/9
	 Logging train Loss: 7.2136e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.8082e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 4.31e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.464e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 6.991e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 35.234564781188965
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'dual_quat_1'_'True'.pth
It took  480.2762792110443  seconds.
----- ITERATION 3/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 54.987849950790405 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 13.758525609970093 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 13.775948286056519 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 13.748714208602905 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 13.733992576599121 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (pre_hidden_lin_layer): Sequential(
    (0): Linear(in_features=3, out_features=96, bias=True)
    (1): ReLU()
    (2): Linear(in_features=96, out_features=96, bias=True)
    (3): ReLU()
  )
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0199827664 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.64276e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 1.48218e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.15895e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.58078e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 35.18230676651001
Epoch 1/9
	 Logging train Loss: 1.20527e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.59686e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 9.7862e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.95051e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.2095e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 35.32154178619385
Epoch 2/9
	 Logging train Loss: 8.4977e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.13147e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 7.0716e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.52384e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.01408e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 35.179466247558594
Epoch 3/9
	 Logging train Loss: 8.1309e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.80036e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 5.8162e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.25567e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 5.8409e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 35.14542007446289
Epoch 4/9
	 Logging train Loss: 9.624e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.13066e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 2.4375e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.52363e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 3.5661e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 34.914573431015015
Epoch 5/9
	 Logging train Loss: 1.47091e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.7134e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 1.0536e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.07318e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.2325e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 35.020004749298096
Epoch 6/9
	 Logging train Loss: 1.31172e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.35584e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 3.7638e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.5415e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.3885e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 33.88327479362488
Epoch 7/9
	 Logging train Loss: 1.41246e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.4373e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 5.74e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 9.1401e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 8.564e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 33.50560665130615
Epoch 8/9
	 Logging train Loss: 8.3383e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.3461e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 4.779e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.9054e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 8.001e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 33.960832357406616
Epoch 9/9
	 Logging train Loss: 9.1953e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.2617e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 6.517e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue █▆▄▄▂▁▃▁▁▁
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue █▆▅▃▂▁▁▁▁▁
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue █▆▄▄▂▁▃▁▁▁
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue █▅▅▄▂▁▂▁▁▁
wandb:                                 Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 1e-05
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 1e-05
wandb:                                 Train loss 1e-05
wandb: 
wandb: 🚀 View run devoted-durian-994 at: https://wandb.ai/nreints/ThesisFinal2/runs/9xp6ks27
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_183013-9xp6ks27/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_183800-hkinjjbt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run serene-serenity-1014
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/hkinjjbt
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue ▂▁▁▁▁▁▁█▁▁
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue ▂▁▁▁▁▁▁█▁▁
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue ▃▁▁▁▁▁▁█▁▁
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue ▄▂▁▁▁▁▁█▁▁
wandb:                                 Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 1e-05
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 2e-05
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 2e-05
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 2e-05
wandb:                                 Train loss 1e-05
wandb: 
wandb: 🚀 View run serene-serenity-1014 at: https://wandb.ai/nreints/ThesisFinal2/runs/hkinjjbt
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_183800-hkinjjbt/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_184551-1abb2ed3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run celestial-haze-1037
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/1abb2ed3
	 Logging test loss: 8.8054e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 9.34e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 33.597825050354004
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'dual_quat_1'_'True'.pth
It took  467.07463026046753  seconds.
----- ITERATION 4/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 54.52814340591431 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 13.615334033966064 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 13.70617151260376 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 13.68806791305542 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 13.589272499084473 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (pre_hidden_lin_layer): Sequential(
    (0): Linear(in_features=3, out_features=96, bias=True)
    (1): ReLU()
    (2): Linear(in_features=96, out_features=96, bias=True)
    (3): ReLU()
  )
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0930850729 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0008065438 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0001648178 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0013520775 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 7.21147e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 34.482720136642456
Epoch 1/9
	 Logging train Loss: 8.78703e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0001395505 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 4.80977e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0003152658 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.26276e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 33.859349966049194
Epoch 2/9
	 Logging train Loss: 3.51792e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.27289e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 2.69307e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0001352022 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.83262e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 33.499398946762085
Epoch 3/9
	 Logging train Loss: 2.22234e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.14675e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 1.82831e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 9.06415e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.68768e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 33.5148491859436
Epoch 4/9
	 Logging train Loss: 1.67395e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.97225e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 1.49262e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.04507e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.55282e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 34.22604060173035
Epoch 5/9
	 Logging train Loss: 1.39838e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.25885e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 1.2846e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.71484e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.36206e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 37.01632857322693
Epoch 6/9
	 Logging train Loss: 1.2337e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.63367e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 1.21695e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.05692e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.31814e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 34.83496427536011
Epoch 7/9
	 Logging train Loss: 0.0005976225 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0025151512 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0013776125 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0028587452 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0004681426 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 36.660770654678345
Epoch 8/9
	 Logging train Loss: 2.96182e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.53124e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 1.18394e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.32222e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.40974e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 34.26592707633972
Epoch 9/9
	 Logging train Loss: 1.1138e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.4883e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 1.05914e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.33209e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.54254e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 36.750998735427856
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'dual_quat_1'_'True'.pth
It took  471.09136152267456  seconds.
----- ITERATION 5/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 55.42109560966492 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 13.920974969863892 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 13.77927303314209 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 13.895206212997437 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 13.897534847259521 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (pre_hidden_lin_layer): Sequential(
    (0): Linear(in_features=3, out_features=96, bias=True)
    (1): ReLU()
    (2): Linear(in_features=96, out_features=96, bias=True)
    (3): ReLU()
  )
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0180450454 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.35342e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 2.1587e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.88658e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.5842e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 35.78738498687744
Epoch 1/9
	 Logging train Loss: 1.55773e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.95828e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 1.18408e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.68519e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.20635e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 34.83435916900635
Epoch 2/9
	 Logging train Loss: 9.5475e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.14401e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 7.6751e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.89729e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 8.5624e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 36.6642050743103
Epoch 3/9
	 Logging train Loss: 5.9818e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue ▃▂▂▁▂▁▁█▁▂
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue █▆▅▃▂▁▁▄▁▂
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue ▃▂▂▂▂▁▁█▁▁
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue ▃▂▂▁▂▁▁█▁▂
wandb:                                 Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 1e-05
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 1e-05
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 2e-05
wandb:                                 Train loss 1e-05
wandb: 
wandb: 🚀 View run celestial-haze-1037 at: https://wandb.ai/nreints/ThesisFinal2/runs/1abb2ed3
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_184551-1abb2ed3/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_185347-i2ps69gg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run celestial-pine-1053
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/i2ps69gg
	 Logging test loss: 1.48884e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 4.5954e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.33971e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 5.019e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 33.977964878082275
Epoch 4/9
	 Logging train Loss: 7.1603e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.33981e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 1.01952e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.60092e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.541e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 35.92539310455322
Epoch 5/9
	 Logging train Loss: 9.9029e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 9.7158e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 2.4512e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.06064e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.4394e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 34.29159712791443
Epoch 6/9
	 Logging train Loss: 1.3626e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.3022e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 9.58e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.1851e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 9.639e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 35.15939235687256
Epoch 7/9
	 Logging train Loss: 1.05566e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0001244203 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 6.61315e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0001338713 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 6.2765e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 35.26648020744324
Epoch 8/9
	 Logging train Loss: 1.20627e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.4508e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 5.777e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.5912e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 7.514e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 35.1492223739624
Epoch 9/9
	 Logging train Loss: 8.493e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.4362e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 6.9372e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.05293e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.0357e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 35.37242603302002
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'dual_quat_1'_'True'.pth
It took  476.1121549606323  seconds.
----- ITERATION 6/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 55.598013162612915 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 13.757670164108276 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 13.703889846801758 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 13.862461566925049 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 14.016286849975586 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (pre_hidden_lin_layer): Sequential(
    (0): Linear(in_features=3, out_features=96, bias=True)
    (1): ReLU()
    (2): Linear(in_features=96, out_features=96, bias=True)
    (3): ReLU()
  )
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0193357598 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.42143e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 2.33203e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.27367e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.68536e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 35.81521463394165
Epoch 1/9
	 Logging train Loss: 1.57488e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.63289e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 1.2225e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.8945e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.3575e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 35.31303906440735
Epoch 2/9
	 Logging train Loss: 9.8199e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.00903e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 8.3013e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.21061e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.02624e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 36.00137972831726
Epoch 3/9
	 Logging train Loss: 6.5232e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.45117e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 5.2462e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.59877e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 6.2171e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 34.067264795303345
Epoch 4/9
	 Logging train Loss: 4.1651e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.38336e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 5.9566e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.01515e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.9029e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 36.43912148475647
Epoch 5/9
	 Logging train Loss: 9.9853e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.6393e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 1.6215e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 9.0586e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.2476e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 34.153178215026855
Epoch 6/9
	 Logging train Loss: 1.39923e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.03061e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 3.437e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.34603e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.1033e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 35.788116455078125
Epoch 7/9
	 Logging train Loss: 1.6121e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0001418099 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 6.56109e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0001105058 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.00902e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 34.866756200790405
Epoch 8/9
	 Logging train Loss: 1.24111e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.13995e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 2.26617e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.14986e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 3.9175e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 35.390239000320435
Epoch 9/9
	 Logging train Loss: 1.18521e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.9359e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue ▃▂▂▁▂▁▁█▃▁
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue █▇▅▃▂▁▁▅▂▁
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue ▃▂▂▁▁▁▁█▃▁
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue ▄▂▂▂▂▁▁█▄▁
wandb:                                 Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 1e-05
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 1e-05
wandb:                                 Train loss 1e-05
wandb: 
wandb: 🚀 View run celestial-pine-1053 at: https://wandb.ai/nreints/ThesisFinal2/runs/i2ps69gg
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_185347-i2ps69gg/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_190145-72o66vqi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run splendid-dragon-1070
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/72o66vqi
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue █▄▃▂▂▁▂▁▃▂
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue █▅▄▃▃▂▁▁▁▁
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue █▄▃▂▂▁▂▁▂▁
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue █▄▃▂▂▁▂▁▃▂
wandb:                                 Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 1e-05
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 1e-05
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 2e-05
wandb:                                 Train loss 2e-05
wandb: 
wandb: 🚀 View run splendid-dragon-1070 at: https://wandb.ai/nreints/ThesisFinal2/runs/72o66vqi
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_190145-72o66vqi/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_190941-9arkt560
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run crimson-smoke-1084
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/9arkt560
	 Logging test loss: 6.337e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.1371e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 6.44e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 35.44458770751953
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'dual_quat_1'_'True'.pth
It took  478.028249502182  seconds.
----- ITERATION 7/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 55.463056564331055 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 13.781639575958252 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 13.965172529220581 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 13.867335557937622 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 13.900442600250244 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (pre_hidden_lin_layer): Sequential(
    (0): Linear(in_features=3, out_features=96, bias=True)
    (1): ReLU()
    (2): Linear(in_features=96, out_features=96, bias=True)
    (3): ReLU()
  )
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0377654731 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 9.64163e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 5.42188e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 9.59318e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.99021e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 35.11799073219299
Epoch 1/9
	 Logging train Loss: 3.21982e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.5647e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 2.03588e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.00622e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.64021e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 34.53601336479187
Epoch 2/9
	 Logging train Loss: 1.64001e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.35805e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 1.37679e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.78755e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.36857e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 36.430601835250854
Epoch 3/9
	 Logging train Loss: 1.17059e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.58802e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 9.8574e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.15074e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.12958e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 33.96304130554199
Epoch 4/9
	 Logging train Loss: 8.3493e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.0445e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 7.341e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.84991e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 8.2149e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 35.45550060272217
Epoch 5/9
	 Logging train Loss: 8.2136e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.48139e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 4.2819e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.25855e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 4.8497e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 34.910106897354126
Epoch 6/9
	 Logging train Loss: 9.9379e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.6693e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 5.6265e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.6648e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.9521e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 35.51027798652649
Epoch 7/9
	 Logging train Loss: 2.08333e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.6992e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 1.4066e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.1876e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.5248e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 35.04374432563782
Epoch 8/9
	 Logging train Loss: 1.10814e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.42195e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 1.46231e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.74373e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.3401e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 35.13431906700134
Epoch 9/9
	 Logging train Loss: 1.74489e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.31268e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 7.5722e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.46443e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.4633e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 35.62718939781189
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'dual_quat_1'_'True'.pth
It took  476.09132957458496  seconds.
----- ITERATION 8/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 55.71956706047058 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 13.687230348587036 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 13.683103561401367 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 13.895931959152222 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 13.945747137069702 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (pre_hidden_lin_layer): Sequential(
    (0): Linear(in_features=3, out_features=96, bias=True)
    (1): ReLU()
    (2): Linear(in_features=96, out_features=96, bias=True)
    (3): ReLU()
  )
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0210843738 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.16273e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 2.14967e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.41037e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.50025e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 34.834956645965576
Epoch 1/9
	 Logging train Loss: 1.66394e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.61836e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 1.20226e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.2238e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.14398e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 34.55852484703064
Epoch 2/9
	 Logging train Loss: 1.02451e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.92192e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 7.9266e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.29893e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 8.1094e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 35.15086913108826
Epoch 3/9
	 Logging train Loss: 6.6613e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue ▃▂▂▁▁▁█▁▁▁
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue █▆▅▃▂▁▄▁▁▁
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue ▃▂▂▁▁▁█▁▁▁
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue ▂▂▁▁▁▁█▁▁▁
wandb:                                 Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 1e-05
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 1e-05
wandb:                                 Train loss 1e-05
wandb: 
wandb: 🚀 View run crimson-smoke-1084 at: https://wandb.ai/nreints/ThesisFinal2/runs/9arkt560
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_190941-9arkt560/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_191731-thuz9qz1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run charmed-serenity-1099
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/thuz9qz1
	 Logging test loss: 1.46497e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 4.9271e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.78082e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 5.4956e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 33.990875244140625
Epoch 4/9
	 Logging train Loss: 3.8571e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.0188e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 2.5966e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.27575e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.6563e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 35.29100751876831
Epoch 5/9
	 Logging train Loss: 1.13702e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.6111e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 1.2777e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.01828e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.3851e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 33.53299140930176
Epoch 6/9
	 Logging train Loss: 9.2949e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0001561053 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 9.73084e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0002328454 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 7.8757e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 34.35460543632507
Epoch 7/9
	 Logging train Loss: 1.47926e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.8598e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 2.4534e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.2324e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.2204e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 34.34585785865784
Epoch 8/9
	 Logging train Loss: 1.88274e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.9454e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 5.919e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.3126e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 8.317e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 33.769542932510376
Epoch 9/9
	 Logging train Loss: 5.2097e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.0534e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 1.3273e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 9.8415e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 8.466e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 36.11921977996826
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'dual_quat_1'_'True'.pth
It took  470.0136389732361  seconds.
----- ITERATION 9/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 55.406511068344116 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 13.86397671699524 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 13.660988330841064 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 13.8146812915802 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 13.950594902038574 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (pre_hidden_lin_layer): Sequential(
    (0): Linear(in_features=3, out_features=96, bias=True)
    (1): ReLU()
    (2): Linear(in_features=96, out_features=96, bias=True)
    (3): ReLU()
  )
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0093825627 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.87079e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 1.80112e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.26275e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.36797e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 35.50290250778198
Epoch 1/9
	 Logging train Loss: 1.20175e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.48792e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 9.244e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.7561e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.00821e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 33.5470609664917
Epoch 2/9
	 Logging train Loss: 6.9575e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.78052e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 5.5683e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.08311e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 6.7388e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 35.575618505477905
Epoch 3/9
	 Logging train Loss: 6.313e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.19497e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 3.0308e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.56439e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 3.3299e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 33.44174385070801
Epoch 4/9
	 Logging train Loss: 1.25808e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.4401e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 1.5123e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.19801e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.5603e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 34.68342089653015
Epoch 5/9
	 Logging train Loss: 1.40929e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.1419e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 1.0185e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.05464e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.053e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 34.49637317657471
Epoch 6/9
	 Logging train Loss: 1.6527e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.7552e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 7.994e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.01368e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 9.373e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 34.59111952781677
Epoch 7/9
	 Logging train Loss: 1.69095e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.19303e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 3.8386e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.60359e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.1822e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 34.91465759277344
Epoch 8/9
	 Logging train Loss: 1.0785e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.0328e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 1.7703e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.25731e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.4059e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 34.177356481552124
Epoch 9/9
	 Logging train Loss: 1.47151e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.4632e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 1.0307e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue █▄▃▂▁▁▁▂▁▁
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue █▆▄▂▁▁▁▁▁▁
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue █▅▃▂▁▁▁▂▁▁
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue █▅▃▂▁▁▁▂▂▁
wandb:                                 Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 1e-05
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 1e-05
wandb:                                 Train loss 1e-05
wandb: 
wandb: 🚀 View run charmed-serenity-1099 at: https://wandb.ai/nreints/ThesisFinal2/runs/thuz9qz1
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_191731-thuz9qz1/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_192522-ndxr6bdg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run feasible-water-1111
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/ndxr6bdg
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue █▃▂▁▁▁▁▁▁▁
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue █▅▄▄▃▃▃▂▂▁
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue █▂▂▂▂▂▁▁▁▁
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue █▁▁▁▁▁▁▁▁▁
wandb:                                 Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 1e-05
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 1e-05
wandb:                                 Train loss 0.0
wandb: 
wandb: 🚀 View run feasible-water-1111 at: https://wandb.ai/nreints/ThesisFinal2/runs/ndxr6bdg
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_192522-ndxr6bdg/logs
	 Logging test loss: 1.09561e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.0677e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 35.54093074798584
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'dual_quat_1'_'True'.pth
It took  470.499552488327  seconds.
----- ITERATION 10/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 55.28376817703247 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 13.725935697555542 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 13.697047233581543 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 13.813122510910034 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 13.870739936828613 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (pre_hidden_lin_layer): Sequential(
    (0): Linear(in_features=3, out_features=96, bias=True)
    (1): ReLU()
    (2): Linear(in_features=96, out_features=96, bias=True)
    (3): ReLU()
  )
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0760031492 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0002078539 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0001750378 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0029608919 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 3.06541e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 35.612239599227905
Epoch 1/9
	 Logging train Loss: 0.0017070858 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.07652e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 6.13579e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.45317e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.70536e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 33.971439361572266
Epoch 2/9
	 Logging train Loss: 7.69823e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.65781e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 1.70697e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.13678e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.45506e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 35.66272854804993
Epoch 3/9
	 Logging train Loss: 1.58058e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.93514e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 1.29236e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.32695e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.37131e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 33.52533411979675
Epoch 4/9
	 Logging train Loss: 1.20374e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.40552e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 1.01916e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.05599e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.20809e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 35.76913070678711
Epoch 5/9
	 Logging train Loss: 0.0012839353 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.33108e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 1.09229e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.6385e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.22896e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 33.7922797203064
Epoch 6/9
	 Logging train Loss: 9.317e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.99408e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 8.2289e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.86055e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.10217e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 35.00058650970459
Epoch 7/9
	 Logging train Loss: 7.2695e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.61991e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 6.3234e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.27262e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 8.3884e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 34.21689963340759
Epoch 8/9
	 Logging train Loss: 5.3152e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.21401e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 4.2572e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.71385e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 5.41e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 34.559463024139404
Epoch 9/9
	 Logging train Loss: 3.1589e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.5724e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 2.0851e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.24424e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.9604e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 35.02477407455444
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'dual_quat_1'_'True'.pth
It took  472.9156754016876  seconds.

JOB STATISTICS
==============
Job ID: 3038014
Array Job ID: 3037875_40
Cluster: snellius
User/Group: nreints/nreints
State: RUNNING
Nodes: 1
Cores per node: 18
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 23:49:48 core-walltime
Job Wall-clock time: 01:19:26
Memory Utilized: 0.00 MB (estimated maximum)
Memory Efficiency: 0.00% of 0.00 MB (0.00 MB/node)
WARNING: Efficiency statistics may be misleading for RUNNING jobs.
