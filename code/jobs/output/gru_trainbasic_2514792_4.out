wandb: Currently logged in as: nreints. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230329_133621-i1x9cygm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rural-fire-513
wandb: ⭐️ View project at https://wandb.ai/nreints/test
wandb: 🚀 View run at https://wandb.ai/nreints/test/runs/i1x9cygm
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.031 MB of 0.078 MB uploaded (0.000 MB deduped)wandb: \ 0.031 MB of 0.078 MB uploaded (0.000 MB deduped)wandb: | 0.031 MB of 0.078 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:                                                    Epoch ▁▂▃▃▄▅▆▆▇█
wandb: Test loss t(0, 0)_r(5, 20)_tennis_pNone_gNone, MSELoss() █▆▄▃▂▂▁▁▁▁▁
wandb:                                               Train loss █▂▂▂▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                                    Epoch 9
wandb: Test loss t(0, 0)_r(5, 20)_tennis_pNone_gNone, MSELoss() 3.74057
wandb:                                               Train loss 3.72286
wandb: 
wandb: 🚀 View run rural-fire-513 at: https://wandb.ai/nreints/test/runs/i1x9cygm
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230329_133621-i1x9cygm/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230329_134445-blulgoyn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run deep-cherry-524
wandb: ⭐️ View project at https://wandb.ai/nreints/test
wandb: 🚀 View run at https://wandb.ai/nreints/test/runs/blulgoyn
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                                    Epoch ▁▂▃▃▄▅▆▆▇█
wandb: Test loss t(0, 0)_r(5, 20)_tennis_pNone_gNone, MSELoss() █▆▅▃▂▂▁▁▁▁▁
wandb:                                               Train loss █▂▂▂▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                                    Epoch 9
wandb: Test loss t(0, 0)_r(5, 20)_tennis_pNone_gNone, MSELoss() 3.75358
wandb:                                               Train loss 3.65744
wandb: 
wandb: 🚀 View run deep-cherry-524 at: https://wandb.ai/nreints/test/runs/blulgoyn
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230329_134445-blulgoyn/logs
Running for data type: log_quat
----- ITERATION 1/2 ------
Number of train simulations: 1600
Number of test simulations: 400
-- Finished Train Dataloader --
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
-- Started Training --
Epoch 0
	 Logging train Loss: 142.3890186916 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss: 35.071495056152344 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 45.51300525665283
Epoch 1
	 Logging train Loss: 28.6954168057 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss: 25.251028060913086 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 43.26823043823242
Epoch 2
	 Logging train Loss: 22.3854149282 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss: 19.096128463745117 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 43.57863712310791
Epoch 3
	 Logging train Loss: 14.6755778538 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss: 10.826811790466309 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 43.88976287841797
Epoch 4
	 Logging train Loss: 8.4864650263 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss: 7.365481853485107 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 43.324541330337524
Epoch 5
	 Logging train Loss: 6.4072643733 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss: 6.084151744842529 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 43.58714294433594
Epoch 6
	 Logging train Loss: 5.3931107362 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss: 5.195530891418457 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 43.52913284301758
Epoch 7
	 Logging train Loss: 4.7261100738 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss: 4.574287414550781 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 43.457517862319946
Epoch 8
	 Logging train Loss: 4.1233056836 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss: 4.116929531097412 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 43.9836163520813
Epoch 9
	 Logging train Loss: 3.72286095 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss: 3.735574245452881 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 43.68273401260376
	 Logging test loss: 3.7405717372894287 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
It took  504.9586606025696  seconds.
----- ITERATION 2/2 ------
Number of train simulations: 1600
Number of test simulations: 400
-- Finished Train Dataloader --
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
-- Started Training --
Epoch 0
	 Logging train Loss: 149.6580962116 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss: 36.70191955566406 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 44.30673146247864
Epoch 1
	 Logging train Loss: 28.5005788969 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss: 26.741811752319336 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 43.8632435798645
Epoch 2
	 Logging train Loss: 22.4651697054 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss: 20.71705436706543 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 43.81599712371826
Epoch 3
	 Logging train Loss: 15.2174018483 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss: 11.546339988708496 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 44.141191482543945
Epoch 4
	 Logging train Loss: 8.5457250292 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss: 7.5435791015625 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 43.878923416137695
Epoch 5
	 Logging train Loss: 6.4318009951 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss: 6.214858531951904 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 44.45717906951904
Epoch 6
	 Logging train Loss: 5.382768822 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss: 5.297418594360352 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 44.06926369667053
Epoch 7
	 Logging train Loss: 4.6562917223 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss: 4.702105522155762 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 44.11551022529602
Epoch 8
	 Logging train Loss: 4.0856030697 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss: 4.1185150146484375 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 43.929399251937866
Epoch 9
	 Logging train Loss: 3.6574384335 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss: 3.7537877559661865 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 44.10633182525635
	 Logging test loss: 3.7535793781280518 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
It took  504.94574093818665  seconds.

JOB STATISTICS
==============
Job ID: 2514796
Array Job ID: 2514792_4
Cluster: snellius
User/Group: nreints/nreints
State: COMPLETED (exit code 0)
Nodes: 1
Cores per node: 18
CPU Utilized: 03:27:54
CPU Efficiency: 67.54% of 05:07:48 core-walltime
Job Wall-clock time: 00:17:06
Memory Utilized: 24.94 GB
Memory Efficiency: 79.81% of 31.25 GB
