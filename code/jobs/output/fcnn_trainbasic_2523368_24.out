wandb: Currently logged in as: nreints. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home/nreints/.netrc
/gpfs/home2/nreints/MScThesis/code/fcnn.py:566: DeprecationWarning: Sampling from a set deprecated
since Python 3.9 and will be removed in a subsequent version.
  train_sims = set(random.sample(sims_train, int(0.8 * n_sims_train)))
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230330_123650-uossgd3j
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run tough-wind-572
wandb: â­ï¸ View project at https://wandb.ai/nreints/test
wandb: ðŸš€ View run at https://wandb.ai/nreints/test/runs/uossgd3j
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.029 MB of 0.029 MB uploaded (0.000 MB deduped)wandb: \ 0.029 MB of 0.078 MB uploaded (0.000 MB deduped)wandb: | 0.029 MB of 0.078 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  Test loss t(5, 20)_r(0, 0)_tennis L1Loss() â–ƒâ–‚â–‚â–‚â–ˆâ–â–â–‚â–â–â–â–â–â–â–â–â–â–‚â–„â–â–
wandb: Test loss t(5, 20)_r(0, 0)_tennis MSELoss() â–‚â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–‚â–â–
wandb:     Train loss data_t(5, 20)_r(0, 0)_tennis â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:  Test loss t(5, 20)_r(0, 0)_tennis L1Loss() 0.0485
wandb: Test loss t(5, 20)_r(0, 0)_tennis MSELoss() 0.00418
wandb:     Train loss data_t(5, 20)_r(0, 0)_tennis 0.02107
wandb: 
wandb: ðŸš€ View run tough-wind-572 at: https://wandb.ai/nreints/test/runs/uossgd3j
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230330_123650-uossgd3j/logs
/gpfs/home2/nreints/MScThesis/code/fcnn.py:566: DeprecationWarning: Sampling from a set deprecated
since Python 3.9 and will be removed in a subsequent version.
  train_sims = set(random.sample(sims_train, int(0.8 * n_sims_train)))
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230330_124814-36pbz9ym
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run balmy-waterfall-624
wandb: â­ï¸ View project at https://wandb.ai/nreints/test
wandb: ðŸš€ View run at https://wandb.ai/nreints/test/runs/36pbz9ym
Training on dataset: data/data_t(5, 20)_r(0, 0)_tennis_pNone_gNone
Testing on datasets: ['data_t(5, 20)_r(0, 0)_tennis_pNone_gNone']
----- ITERATION 1/2 ------
Number of train simulations: 1600
Number of test simulations: 400
The dataloader took 60.537272214889526 seconds.
-- Finished Train Dataloader --
The dataloader took 15.309903144836426 seconds.
-- Finished Test Dataloader(s) --
Datatype: quat
--- Started Training ---
Epoch 0
	 Logging train Loss: 16.0138748468 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.0428788959980011 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.1490023285150528 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 30.2243595123291
Epoch 1
	 Logging train Loss: 0.0430112951 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.015042744576931 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.09194017201662064 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 30.47869324684143
Epoch 2
	 Logging train Loss: 0.0349449407 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.02141794189810753 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.11048542708158493 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 30.012844562530518
Epoch 3
	 Logging train Loss: 0.0396779677 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.011210568249225616 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.07881343364715576 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 30.227972745895386
Epoch 4
	 Logging train Loss: 0.037721609 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.3593617379665375 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.44783860445022583 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 30.11141014099121
Epoch 5
	 Logging train Loss: 0.0405173906 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.009498370811343193 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.07248874753713608 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 30.413960695266724
Epoch 6
	 Logging train Loss: 0.0354348077 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.010341755114495754 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.07486189901828766 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 30.68293070793152
Epoch 7
	 Logging train Loss: 0.0400107365 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.015071514993906021 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.09169125556945801 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 30.269402027130127
Epoch 8
	 Logging train Loss: 0.0333947624 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.006702459882944822 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.059558503329753876 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 30.63246488571167
Epoch 9
	 Logging train Loss: 0.0343987184 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.0060700965113937855 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.056908585131168365 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 28.695064306259155
Epoch 10
	 Logging train Loss: 0.031270749 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.00798838771879673 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.06732431799173355 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 28.46653151512146
Epoch 11
	 Logging train Loss: 0.0326875151 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.00586121017113328 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.055016037076711655 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 28.518000602722168
Epoch 12
	 Logging train Loss: 0.0304619484 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.005508160684257746 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.05332808196544647 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 28.427949905395508
Epoch 13
	 Logging train Loss: 0.0275687797 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.004612637683749199 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.04996659979224205 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 30.156152963638306
Epoch 14
	 Logging train Loss: 0.0280865065 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.006897269748151302 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.060573868453502655 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 29.02231216430664
Epoch 15
	 Logging train Loss: 0.0277357064 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.003947056829929352 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.0463617742061615 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 29.19316530227661
Epoch 16
	 Logging train Loss: 0.0265687905 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.005800439044833183 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.058014798909425735 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 29.043927907943726
Epoch 17
	 Logging train Loss: 0.0266235252 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.023655040189623833 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.11443299800157547 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 28.82028341293335
Epoch 18
	 Logging train Loss: 0.0184191274 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.07567030936479568 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.20584356784820557 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 28.89184594154358
Epoch 19
	 Logging train Loss: 0.0210682364 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.004175015725195408 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.048494499176740646 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 30.305701971054077
	 Logging test loss 0.004175220616161823 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.04849568009376526 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
It took 684.0511496067047 seconds to train & eval the model.
----- ITERATION 2/2 ------
Number of train simulations: 1600
Number of test simulations: 400
The dataloader took 56.021504163742065 seconds.
-- Finished Train Dataloader --
The dataloader took 13.95967411994934 seconds.
-- Finished Test Dataloader(s) --
Datatype: quat
--- Started Training ---
Epoch 0
	 Logging train Loss: 18.2678308824 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.038241203874349594 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.1352611929178238 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 30.25151491165161
Epoch 1
	 Logging train Loss: 0.0362153172 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.01522951852530241 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.0864013209939003 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 28.990290880203247
Epoch 2
	 Logging train Loss: 0.0346749125 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.013496915809810162 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.08149464428424835 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.029 MB of 0.029 MB uploaded (0.000 MB deduped)wandb: \ 0.029 MB of 0.029 MB uploaded (0.000 MB deduped)wandb: | 0.029 MB of 0.029 MB uploaded (0.000 MB deduped)wandb: / 0.029 MB of 0.029 MB uploaded (0.000 MB deduped)wandb: - 0.029 MB of 0.029 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  Test loss t(5, 20)_r(0, 0)_tennis L1Loss() â–…â–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–…â–ƒâ–â–‚â–ˆâ–â–‚â–â–ƒâ–â–ƒâ–â–â–
wandb: Test loss t(5, 20)_r(0, 0)_tennis MSELoss() â–„â–‚â–‚â–‚â–â–â–â–…â–‚â–â–â–ˆâ–â–â–â–‚â–â–‚â–â–â–
wandb:     Train loss data_t(5, 20)_r(0, 0)_tennis â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:  Test loss t(5, 20)_r(0, 0)_tennis L1Loss() 0.04179
wandb: Test loss t(5, 20)_r(0, 0)_tennis MSELoss() 0.00386
wandb:     Train loss data_t(5, 20)_r(0, 0)_tennis 0.01898
wandb: 
wandb: ðŸš€ View run balmy-waterfall-624 at: https://wandb.ai/nreints/test/runs/36pbz9ym
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230330_124814-36pbz9ym/logs
     --> Epoch time; 28.658179759979248
Epoch 3
	 Logging train Loss: 0.0361512228 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.01743149943649769 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.09751437604427338 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 28.190114736557007
Epoch 4
	 Logging train Loss: 0.0375900443 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.00859363004565239 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.06628169119358063 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 30.350746870040894
Epoch 5
	 Logging train Loss: 0.0396068174 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.007008511573076248 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.061419032514095306 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 29.96772313117981
Epoch 6
	 Logging train Loss: 0.0390606026 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.007146578747779131 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.061706673353910446 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 29.95343780517578
Epoch 7
	 Logging train Loss: 0.034783407 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.0433780774474144 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.1524801403284073 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 28.786803722381592
Epoch 8
	 Logging train Loss: 0.0359715007 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.014302951283752918 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.09041669964790344 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 28.886539220809937
Epoch 9
	 Logging train Loss: 0.032730297 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.005201405379921198 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.052514929324388504 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 28.71585440635681
Epoch 10
	 Logging train Loss: 0.0314837961 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.005337841343134642 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.05380075052380562 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 28.57896089553833
Epoch 11
	 Logging train Loss: 0.0320215786 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.08026131242513657 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.2170216590166092 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 30.200434684753418
Epoch 12
	 Logging train Loss: 0.0283330531 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.004732941742986441 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.050394974648952484 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 29.058057069778442
Epoch 13
	 Logging train Loss: 0.0282698388 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.005921097006648779 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.055348023772239685 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 28.777714729309082
Epoch 14
	 Logging train Loss: 0.0261130314 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.00408193888142705 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.04502939432859421 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 28.721601009368896
Epoch 15
	 Logging train Loss: 0.0247969559 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.012126662768423557 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.08182541280984879 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 28.86693811416626
Epoch 16
	 Logging train Loss: 0.0248033935 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.003676346270367503 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.04030940681695938 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 30.81343698501587
Epoch 17
	 Logging train Loss: 0.024538272 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.0168981421738863 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.09499906748533249 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 30.691954135894775
Epoch 18
	 Logging train Loss: 0.0236649332 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.0035961398389190435 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.041989073157310486 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 30.422103881835938
Epoch 19
	 Logging train Loss: 0.0189769583 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.0038643016014248133 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.04178827628493309 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 28.94525933265686
	 Logging test loss 0.0038644932210445404 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.041790448129177094 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
It took 674.3136105537415 seconds to train & eval the model.

JOB STATISTICS
==============
Job ID: 2523392
Array Job ID: 2523368_24
Cluster: snellius
User/Group: nreints/nreints
State: COMPLETED (exit code 0)
Nodes: 1
Cores per node: 18
CPU Utilized: 03:27:43
CPU Efficiency: 50.32% of 06:52:48 core-walltime
Job Wall-clock time: 00:22:56
Memory Utilized: 3.52 GB
Memory Efficiency: 12.01% of 29.30 GB
