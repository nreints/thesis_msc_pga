wandb: Currently logged in as: nreints. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230710_170033-67bniegz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fluent-night-1247
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/67bniegz
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                     Epoch ▁▂▃▃▄▅▆▆▇█
wandb: Test loss tennis_pNone_gNone_tennisEffect █▅▄▂▃▁▁▂▂▁
wandb:                                Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                     Epoch 9
wandb: Test loss tennis_pNone_gNone_tennisEffect 2e-05
wandb:                                Train loss 1e-05
wandb: 
wandb: 🚀 View run fluent-night-1247 at: https://wandb.ai/nreints/ThesisFinal2/runs/67bniegz
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230710_170033-67bniegz/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230710_170618-6yw6t0pp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run morning-morning-1265
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/6yw6t0pp
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                     Epoch ▁▂▃▃▄▅▆▆▇█
wandb: Test loss tennis_pNone_gNone_tennisEffect █▆▅▅▂▂▂▁▁▁
wandb:                                Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                     Epoch 9
wandb: Test loss tennis_pNone_gNone_tennisEffect 1e-05
wandb:                                Train loss 1e-05
wandb: 
wandb: 🚀 View run morning-morning-1265 at: https://wandb.ai/nreints/ThesisFinal2/runs/6yw6t0pp
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230710_170618-6yw6t0pp/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230710_171154-xf4oq0li
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vibrant-wood-1276
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/xf4oq0li
Training on dataset: data_tennis_pNone_gNone_tennisEffect
Testing on 1 datasets: ['data_tennis_pNone_gNone_tennisEffect']
Focussing on identity: True
Using extra input: True
Using fr-fr as reference point.
----- ITERATION 1/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 60.41884779930115 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 15.019092559814453 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (pre_hidden_lin_layer): Sequential(
    (0): Linear(in_features=3, out_features=96, bias=True)
    (1): ReLU()
    (2): Linear(in_features=96, out_features=96, bias=True)
    (3): ReLU()
  )
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0018892024 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 8.26798e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 26.564311265945435
Epoch 1/9
	 Logging train Loss: 6.2477e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 5.64856e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 25.603761911392212
Epoch 2/9
	 Logging train Loss: 4.9235e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 4.02668e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 25.324090242385864
Epoch 3/9
	 Logging train Loss: 3.75829e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.74178e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 25.453715324401855
Epoch 4/9
	 Logging train Loss: 2.7578e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 3.32263e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 25.64268159866333
Epoch 5/9
	 Logging train Loss: 2.03634e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.28439e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 25.0719952583313
Epoch 6/9
	 Logging train Loss: 1.59724e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.45748e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 25.40493655204773
Epoch 7/9
	 Logging train Loss: 1.45315e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.17101e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 25.090439796447754
Epoch 8/9
	 Logging train Loss: 1.25825e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.95969e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 25.34129548072815
Epoch 9/9
	 Logging train Loss: 1.16677e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.60356e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 25.574150800704956
Saved model in  trained_models/gru/data_tennis_pNone_gNone_tennisEffect/'dual_quat_1'_'True'.pth
It took  346.26638674736023  seconds.
----- ITERATION 2/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 55.474719524383545 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 13.909414529800415 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (pre_hidden_lin_layer): Sequential(
    (0): Linear(in_features=3, out_features=96, bias=True)
    (1): ReLU()
    (2): Linear(in_features=96, out_features=96, bias=True)
    (3): ReLU()
  )
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0028350167 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 7.74041e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 25.578128576278687
Epoch 1/9
	 Logging train Loss: 7.50373e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 6.05103e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 25.38427996635437
Epoch 2/9
	 Logging train Loss: 5.76999e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 4.61864e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 25.73558259010315
Epoch 3/9
	 Logging train Loss: 4.52037e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 5.13323e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 25.655720710754395
Epoch 4/9
	 Logging train Loss: 3.3614e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.33943e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 25.5074303150177
Epoch 5/9
	 Logging train Loss: 2.59924e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.06206e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 25.110976219177246
Epoch 6/9
	 Logging train Loss: 1.9298e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.5196e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 25.738030433654785
Epoch 7/9
	 Logging train Loss: 1.61313e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.1338e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 25.549302577972412
Epoch 8/9
	 Logging train Loss: 1.40562e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.03253e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 25.142197608947754
Epoch 9/9
	 Logging train Loss: 1.28591e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 9.5242e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 25.530837774276733
Saved model in  trained_models/gru/data_tennis_pNone_gNone_tennisEffect/'dual_quat_1'_'True'.pth
It took  336.0199444293976  seconds.
----- ITERATION 3/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 53.12019729614258 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 13.337279796600342 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (pre_hidden_lin_layer): Sequential(
    (0): Linear(in_features=3, out_features=96, bias=True)
    (1): ReLU()
    (2): Linear(in_features=96, out_features=96, bias=True)
    (3): ReLU()
  )
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0033235585 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 7.17926e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 25.409736156463623
Epoch 1/9
	 Logging train Loss: 6.1334e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 6.29344e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 25.370400190353394
Epoch 2/9
	 Logging train Loss: 5.14963e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 5.68112e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 25.197667121887207
Epoch 3/9
	 Logging train Loss: 4.21609e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 4.48502e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 25.296299695968628
Epoch 4/9
	 Logging train Loss: 3.3097e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 4.17211e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 25.55343198776245
Epoch 5/9
	 Logging train Loss: 2.56085e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.92269e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 25.54202389717102
Epoch 6/9
	 Logging train Loss: 1.96424e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 4.98275e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 25.76834225654602
Epoch 7/9
	 Logging train Loss: 1.65382e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                     Epoch ▁▂▃▃▄▅▆▆▇█
wandb: Test loss tennis_pNone_gNone_tennisEffect █▇▆▅▅▂▅▁▁▁
wandb:                                Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                     Epoch 9
wandb: Test loss tennis_pNone_gNone_tennisEffect 1e-05
wandb:                                Train loss 1e-05
wandb: 
wandb: 🚀 View run vibrant-wood-1276 at: https://wandb.ai/nreints/ThesisFinal2/runs/xf4oq0li
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230710_171154-xf4oq0li/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230710_171726-4sh5p8cj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run colorful-plant-1290
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/4sh5p8cj
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                     Epoch ▁▂▃▃▄▅▆▆▇█
wandb: Test loss tennis_pNone_gNone_tennisEffect █▇▅▃▂▁▁▁▁▁
wandb:                                Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                     Epoch 9
wandb: Test loss tennis_pNone_gNone_tennisEffect 1e-05
wandb:                                Train loss 1e-05
wandb: 
wandb: 🚀 View run colorful-plant-1290 at: https://wandb.ai/nreints/ThesisFinal2/runs/4sh5p8cj
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230710_171726-4sh5p8cj/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230710_172250-chfbv9pi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glorious-smoke-1305
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/chfbv9pi
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                     Epoch ▁▂▃▃▄▅▆▆▇█
wandb: Test loss tennis_pNone_gNone_tennisEffect █▇▅▃▂▁▂▁▂▁
wandb:                                Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                     Epoch 9
wandb: Test loss tennis_pNone_gNone_tennisEffect 1e-05
wandb:                                Train loss 1e-05
wandb: 
wandb: 🚀 View run glorious-smoke-1305 at: https://wandb.ai/nreints/ThesisFinal2/runs/chfbv9pi
wandb: Synced 7 W&B file(s), 0 media file(s), 1 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230710_172250-chfbv9pi/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230710_172812-ks3hhg6x
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run balmy-glade-1319
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/ks3hhg6x
	 Logging test loss: 1.38341e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 25.328913688659668
Epoch 8/9
	 Logging train Loss: 1.47296e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.12095e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 25.193456649780273
Epoch 9/9
	 Logging train Loss: 1.33179e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.09072e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 25.544379949569702
Saved model in  trained_models/gru/data_tennis_pNone_gNone_tennisEffect/'dual_quat_1'_'True'.pth
It took  332.18129873275757  seconds.
----- ITERATION 4/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 54.16448616981506 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 13.712559938430786 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (pre_hidden_lin_layer): Sequential(
    (0): Linear(in_features=3, out_features=96, bias=True)
    (1): ReLU()
    (2): Linear(in_features=96, out_features=96, bias=True)
    (3): ReLU()
  )
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0016147895 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 8.19288e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 24.4005286693573
Epoch 1/9
	 Logging train Loss: 7.00436e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 7.6097e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 24.261709690093994
Epoch 2/9
	 Logging train Loss: 5.26082e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 5.14946e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 24.06973385810852
Epoch 3/9
	 Logging train Loss: 3.84182e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.69516e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 24.284892082214355
Epoch 4/9
	 Logging train Loss: 2.77015e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.70398e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 24.371037006378174
Epoch 5/9
	 Logging train Loss: 1.89512e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.16151e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 24.437454223632812
Epoch 6/9
	 Logging train Loss: 1.59727e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.1135e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 24.114763975143433
Epoch 7/9
	 Logging train Loss: 1.31971e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.42652e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 23.93934941291809
Epoch 8/9
	 Logging train Loss: 1.22918e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.0866e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 24.366716861724854
Epoch 9/9
	 Logging train Loss: 1.1588e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.17586e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 24.089024305343628
Saved model in  trained_models/gru/data_tennis_pNone_gNone_tennisEffect/'dual_quat_1'_'True'.pth
It took  323.82670545578003  seconds.
----- ITERATION 5/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 53.02881979942322 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 13.398757934570312 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (pre_hidden_lin_layer): Sequential(
    (0): Linear(in_features=3, out_features=96, bias=True)
    (1): ReLU()
    (2): Linear(in_features=96, out_features=96, bias=True)
    (3): ReLU()
  )
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0021859978 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 6.91151e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 24.699997663497925
Epoch 1/9
	 Logging train Loss: 7.3598e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 5.65363e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 24.488718509674072
Epoch 2/9
	 Logging train Loss: 5.49783e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 4.35086e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 24.624883890151978
Epoch 3/9
	 Logging train Loss: 4.1069e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.67284e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 24.036943674087524
Epoch 4/9
	 Logging train Loss: 3.00652e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.00897e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 24.343916177749634
Epoch 5/9
	 Logging train Loss: 2.11448e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.20076e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 24.524203538894653
Epoch 6/9
	 Logging train Loss: 1.67146e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.63283e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 24.471774339675903
Epoch 7/9
	 Logging train Loss: 1.45114e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.3381e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 24.246569871902466
Epoch 8/9
	 Logging train Loss: 1.31058e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.48122e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 24.344402313232422
Epoch 9/9
	 Logging train Loss: 1.23164e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 9.458e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 24.100327491760254
Saved model in  trained_models/gru/data_tennis_pNone_gNone_tennisEffect/'dual_quat_1'_'True'.pth
It took  322.3725702762604  seconds.
----- ITERATION 6/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 53.20777225494385 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 13.383058309555054 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (pre_hidden_lin_layer): Sequential(
    (0): Linear(in_features=3, out_features=96, bias=True)
    (1): ReLU()
    (2): Linear(in_features=96, out_features=96, bias=True)
    (3): ReLU()
  )
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0024604078 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 6.36863e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 25.64048933982849
Epoch 1/9
	 Logging train Loss: 5.52711e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 4.47236e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 25.556995630264282
Epoch 2/9
	 Logging train Loss: 4.67813e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 4.13059e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 25.039625644683838
Epoch 3/9
	 Logging train Loss: 3.74374e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 3.54349e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 25.351768016815186
Epoch 4/9
	 Logging train Loss: 2.92554e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.06373e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 25.058501958847046
Epoch 5/9
	 Logging train Loss: 2.24233e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                     Epoch ▁▂▃▃▄▅▆▆▇█
wandb: Test loss tennis_pNone_gNone_tennisEffect █▅▅▄▂▂▁▂▂▁
wandb:                                Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                     Epoch 9
wandb: Test loss tennis_pNone_gNone_tennisEffect 1e-05
wandb:                                Train loss 1e-05
wandb: 
wandb: 🚀 View run balmy-glade-1319 at: https://wandb.ai/nreints/ThesisFinal2/runs/ks3hhg6x
wandb: Synced 7 W&B file(s), 0 media file(s), 1 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230710_172812-ks3hhg6x/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230710_173345-99mtj1ry
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run solar-donkey-1332
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/99mtj1ry
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                     Epoch ▁▂▃▃▄▅▆▆▇█
wandb: Test loss tennis_pNone_gNone_tennisEffect ██▄▃▂▂▁▁▁▁
wandb:                                Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                     Epoch 9
wandb: Test loss tennis_pNone_gNone_tennisEffect 1e-05
wandb:                                Train loss 1e-05
wandb: 
wandb: 🚀 View run solar-donkey-1332 at: https://wandb.ai/nreints/ThesisFinal2/runs/99mtj1ry
wandb: Synced 7 W&B file(s), 0 media file(s), 1 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230710_173345-99mtj1ry/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230710_173918-3ekygfkd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run upbeat-thunder-1348
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/3ekygfkd
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                     Epoch ▁▂▃▃▄▅▆▆▇█
wandb: Test loss tennis_pNone_gNone_tennisEffect █▅▆▃▂▄▁▁▁▁
wandb:                                Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                     Epoch 9
wandb: Test loss tennis_pNone_gNone_tennisEffect 1e-05
wandb:                                Train loss 1e-05
wandb: 
wandb: 🚀 View run upbeat-thunder-1348 at: https://wandb.ai/nreints/ThesisFinal2/runs/3ekygfkd
wandb: Synced 7 W&B file(s), 0 media file(s), 1 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230710_173918-3ekygfkd/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230710_174450-jd3j69nt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vibrant-music-1361
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/jd3j69nt
	 Logging test loss: 1.59881e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 25.52493143081665
Epoch 6/9
	 Logging train Loss: 1.723e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.06556e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 25.146153450012207
Epoch 7/9
	 Logging train Loss: 1.50705e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.96777e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 25.18381977081299
Epoch 8/9
	 Logging train Loss: 1.3171e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.56803e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 25.43562150001526
Epoch 9/9
	 Logging train Loss: 1.20416e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.11139e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 25.663206338882446
Saved model in  trained_models/gru/data_tennis_pNone_gNone_tennisEffect/'dual_quat_1'_'True'.pth
It took  332.337988615036  seconds.
----- ITERATION 7/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 53.25738000869751 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 13.323641777038574 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (pre_hidden_lin_layer): Sequential(
    (0): Linear(in_features=3, out_features=96, bias=True)
    (1): ReLU()
    (2): Linear(in_features=96, out_features=96, bias=True)
    (3): ReLU()
  )
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0016591782 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 6.68024e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 25.07737946510315
Epoch 1/9
	 Logging train Loss: 6.81375e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 7.04156e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 25.300846338272095
Epoch 2/9
	 Logging train Loss: 5.09346e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 3.84085e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 25.485580682754517
Epoch 3/9
	 Logging train Loss: 3.99104e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.83321e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 25.559237480163574
Epoch 4/9
	 Logging train Loss: 2.99887e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.09622e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 25.39896011352539
Epoch 5/9
	 Logging train Loss: 2.21816e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.94497e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 25.497626781463623
Epoch 6/9
	 Logging train Loss: 1.72634e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.03757e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 25.404675722122192
Epoch 7/9
	 Logging train Loss: 1.44823e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.00015e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 25.02709650993347
Epoch 8/9
	 Logging train Loss: 1.31166e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 9.5969e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 25.489928245544434
Epoch 9/9
	 Logging train Loss: 1.20489e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 9.1813e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 25.128931999206543
Saved model in  trained_models/gru/data_tennis_pNone_gNone_tennisEffect/'dual_quat_1'_'True'.pth
It took  333.33909797668457  seconds.
----- ITERATION 8/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 53.478882789611816 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 13.371445894241333 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (pre_hidden_lin_layer): Sequential(
    (0): Linear(in_features=3, out_features=96, bias=True)
    (1): ReLU()
    (2): Linear(in_features=96, out_features=96, bias=True)
    (3): ReLU()
  )
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0022349497 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 6.93154e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 25.703391551971436
Epoch 1/9
	 Logging train Loss: 7.27942e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 4.78178e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 25.453912496566772
Epoch 2/9
	 Logging train Loss: 5.64645e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 5.11768e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 25.393991708755493
Epoch 3/9
	 Logging train Loss: 4.48117e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.94574e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 25.069367170333862
Epoch 4/9
	 Logging train Loss: 3.4926e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.01262e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 25.210041999816895
Epoch 5/9
	 Logging train Loss: 2.56356e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 3.2434e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 25.442947149276733
Epoch 6/9
	 Logging train Loss: 1.96847e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.23691e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 25.534891843795776
Epoch 7/9
	 Logging train Loss: 1.60968e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.17541e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 25.150678157806396
Epoch 8/9
	 Logging train Loss: 1.42271e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.06148e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 25.562333345413208
Epoch 9/9
	 Logging train Loss: 1.30642e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.03215e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 25.13888907432556
Saved model in  trained_models/gru/data_tennis_pNone_gNone_tennisEffect/'dual_quat_1'_'True'.pth
It took  332.3072409629822  seconds.
----- ITERATION 9/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 53.631166219711304 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 13.483603715896606 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (pre_hidden_lin_layer): Sequential(
    (0): Linear(in_features=3, out_features=96, bias=True)
    (1): ReLU()
    (2): Linear(in_features=96, out_features=96, bias=True)
    (3): ReLU()
  )
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0022494809 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 9.21589e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 25.67926335334778
Epoch 1/9
	 Logging train Loss: 6.89552e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 6.30128e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 25.450965404510498
Epoch 2/9
	 Logging train Loss: 5.33855e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 5.50581e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 25.23701024055481
Epoch 3/9
	 Logging train Loss: 4.09346e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                     Epoch ▁▂▃▃▄▅▆▆▇█
wandb: Test loss tennis_pNone_gNone_tennisEffect █▅▅▄▂▂▂▁▁▁
wandb:                                Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                     Epoch 9
wandb: Test loss tennis_pNone_gNone_tennisEffect 1e-05
wandb:                                Train loss 1e-05
wandb: 
wandb: 🚀 View run vibrant-music-1361 at: https://wandb.ai/nreints/ThesisFinal2/runs/jd3j69nt
wandb: Synced 7 W&B file(s), 0 media file(s), 1 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230710_174450-jd3j69nt/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230710_175023-xov4qixh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run worthy-eon-1366
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/xov4qixh
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                     Epoch ▁▂▃▃▄▅▆▆▇█
wandb: Test loss tennis_pNone_gNone_tennisEffect ██▄▃▃▂▂▁▁▁
wandb:                                Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                     Epoch 9
wandb: Test loss tennis_pNone_gNone_tennisEffect 1e-05
wandb:                                Train loss 1e-05
wandb: 
wandb: 🚀 View run worthy-eon-1366 at: https://wandb.ai/nreints/ThesisFinal2/runs/xov4qixh
wandb: Synced 7 W&B file(s), 0 media file(s), 1 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230710_175023-xov4qixh/logs
	 Logging test loss: 4.24181e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 25.535043478012085
Epoch 4/9
	 Logging train Loss: 3.0197e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.29675e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 25.35005497932434
Epoch 5/9
	 Logging train Loss: 2.13313e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.48802e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 25.564109563827515
Epoch 6/9
	 Logging train Loss: 1.64336e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.31256e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 25.26072406768799
Epoch 7/9
	 Logging train Loss: 1.44713e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.26019e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 25.342154026031494
Epoch 8/9
	 Logging train Loss: 1.27106e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.08007e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 25.41101574897766
Epoch 9/9
	 Logging train Loss: 1.18721e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.22454e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 25.475006341934204
Saved model in  trained_models/gru/data_tennis_pNone_gNone_tennisEffect/'dual_quat_1'_'True'.pth
It took  332.20340490341187  seconds.
----- ITERATION 10/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 53.30885457992554 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 13.399060726165771 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (pre_hidden_lin_layer): Sequential(
    (0): Linear(in_features=3, out_features=96, bias=True)
    (1): ReLU()
    (2): Linear(in_features=96, out_features=96, bias=True)
    (3): ReLU()
  )
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0026996427 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 6.8631e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 23.886605262756348
Epoch 1/9
	 Logging train Loss: 6.23243e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 6.67524e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 24.299755334854126
Epoch 2/9
	 Logging train Loss: 5.08589e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 3.94979e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 24.20634412765503
Epoch 3/9
	 Logging train Loss: 3.90477e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.8343e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 24.18995189666748
Epoch 4/9
	 Logging train Loss: 2.90864e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.74427e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 24.28243899345398
Epoch 5/9
	 Logging train Loss: 2.19361e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.75973e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 24.615116357803345
Epoch 6/9
	 Logging train Loss: 1.777e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.0242e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 24.37965703010559
Epoch 7/9
	 Logging train Loss: 1.54796e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.29319e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 24.569456338882446
Epoch 8/9
	 Logging train Loss: 1.40779e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.05799e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 24.587016344070435
Epoch 9/9
	 Logging train Loss: 1.23954e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.0835e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 24.409905433654785
Saved model in  trained_models/gru/data_tennis_pNone_gNone_tennisEffect/'dual_quat_1'_'True'.pth
It took  323.23177886009216  seconds.
