wandb: Currently logged in as: nreints. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230710_170035-3g5jaxi5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run celestial-moon-1255
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/3g5jaxi5
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                     Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb: Test loss tennis_pNone_gNone_tennisEffect â–ˆâ–…â–„â–‚â–‚â–â–â–‚â–â–
wandb:                                Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                     Epoch 9
wandb: Test loss tennis_pNone_gNone_tennisEffect 1e-05
wandb:                                Train loss 1e-05
wandb: 
wandb: ðŸš€ View run celestial-moon-1255 at: https://wandb.ai/nreints/ThesisFinal2/runs/3g5jaxi5
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230710_170035-3g5jaxi5/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230710_170526-rrh6wg48
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fallen-lake-1261
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/rrh6wg48
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                     Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb: Test loss tennis_pNone_gNone_tennisEffect â–ˆâ–†â–…â–…â–„â–‚â–†â–â–â–‚
wandb:                                Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                     Epoch 9
wandb: Test loss tennis_pNone_gNone_tennisEffect 2e-05
wandb:                                Train loss 1e-05
wandb: 
wandb: ðŸš€ View run fallen-lake-1261 at: https://wandb.ai/nreints/ThesisFinal2/runs/rrh6wg48
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230710_170526-rrh6wg48/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230710_171014-aivtrg5q
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run young-silence-1272
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/aivtrg5q
Training on dataset: data_tennis_pNone_gNone_tennisEffect
Testing on 1 datasets: ['data_tennis_pNone_gNone_tennisEffect']
Focussing on identity: True
Using extra input: True
Using fr-fr as reference point.
----- ITERATION 1/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 59.90138554573059 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 15.006582736968994 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (pre_hidden_lin_layer): Sequential(
    (0): Linear(in_features=3, out_features=96, bias=True)
    (1): ReLU()
    (2): Linear(in_features=96, out_features=96, bias=True)
    (3): ReLU()
  )
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0024090132 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 0.000111786 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 20.97676730155945
Epoch 1/9
	 Logging train Loss: 7.92826e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 7.19844e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 20.33772897720337
Epoch 2/9
	 Logging train Loss: 5.6889e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 4.68881e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.826020002365112
Epoch 3/9
	 Logging train Loss: 4.57893e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.8838e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 20.192090272903442
Epoch 4/9
	 Logging train Loss: 3.3438e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.25617e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 20.476478099822998
Epoch 5/9
	 Logging train Loss: 2.4701e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.36707e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 20.043532609939575
Epoch 6/9
	 Logging train Loss: 1.82466e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.1814e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 20.332040786743164
Epoch 7/9
	 Logging train Loss: 1.55844e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 3.04841e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 20.256617307662964
Epoch 8/9
	 Logging train Loss: 1.40889e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.55526e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 20.303356885910034
Epoch 9/9
	 Logging train Loss: 1.24516e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.06216e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 20.316017627716064
Saved model in  trained_models/gru/data_tennis_pNone_gNone_tennisEffect/'quat_1'_'True'.pth
It took  292.8750193119049  seconds.
----- ITERATION 2/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 58.287076234817505 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 14.737943887710571 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (pre_hidden_lin_layer): Sequential(
    (0): Linear(in_features=3, out_features=96, bias=True)
    (1): ReLU()
    (2): Linear(in_features=96, out_features=96, bias=True)
    (3): ReLU()
  )
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0024906765 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 7.29047e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 20.24976420402527
Epoch 1/9
	 Logging train Loss: 6.57212e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 5.24894e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 20.213107109069824
Epoch 2/9
	 Logging train Loss: 5.2452e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 4.59586e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 20.265997648239136
Epoch 3/9
	 Logging train Loss: 4.11837e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 4.38241e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 20.430020093917847
Epoch 4/9
	 Logging train Loss: 3.16521e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 3.38491e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 20.37382173538208
Epoch 5/9
	 Logging train Loss: 2.28241e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.00602e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 20.145861625671387
Epoch 6/9
	 Logging train Loss: 1.8445e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 5.09918e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 20.22493314743042
Epoch 7/9
	 Logging train Loss: 1.49095e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.01411e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 20.305388689041138
Epoch 8/9
	 Logging train Loss: 1.33273e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.28074e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.959272623062134
Epoch 9/9
	 Logging train Loss: 1.24748e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.553e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 20.29624605178833
Saved model in  trained_models/gru/data_tennis_pNone_gNone_tennisEffect/'quat_1'_'True'.pth
It took  287.2937898635864  seconds.
----- ITERATION 3/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 56.620238304138184 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 14.152377843856812 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (pre_hidden_lin_layer): Sequential(
    (0): Linear(in_features=3, out_features=96, bias=True)
    (1): ReLU()
    (2): Linear(in_features=96, out_features=96, bias=True)
    (3): ReLU()
  )
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0048879571 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 7.45431e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.99727177619934
Epoch 1/9
	 Logging train Loss: 6.27229e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 7.28212e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.921921730041504
Epoch 2/9
	 Logging train Loss: 5.28338e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 5.25829e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 20.010611295700073
Epoch 3/9
	 Logging train Loss: 4.37763e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 4.9245e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 20.220290899276733
Epoch 4/9
	 Logging train Loss: 3.47025e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 3.22723e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 20.222697734832764
Epoch 5/9
	 Logging train Loss: 2.74563e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.85206e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 20.200211763381958
Epoch 6/9
	 Logging train Loss: 1.99634e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 6.94343e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 20.15654444694519
Epoch 7/9
	 Logging train Loss: 1.72981e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.86587e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                     Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb: Test loss tennis_pNone_gNone_tennisEffect â–ˆâ–ˆâ–†â–…â–ƒâ–‚â–‡â–‚â–â–
wandb:                                Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                     Epoch 9
wandb: Test loss tennis_pNone_gNone_tennisEffect 1e-05
wandb:                                Train loss 1e-05
wandb: 
wandb: ðŸš€ View run young-silence-1272 at: https://wandb.ai/nreints/ThesisFinal2/runs/aivtrg5q
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230710_171014-aivtrg5q/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230710_171457-72vxjrlb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run snowy-disco-1286
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/72vxjrlb
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                     Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb: Test loss tennis_pNone_gNone_tennisEffect â–ˆâ–„â–…â–ƒâ–‚â–â–ƒâ–â–â–
wandb:                                Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                     Epoch 9
wandb: Test loss tennis_pNone_gNone_tennisEffect 1e-05
wandb:                                Train loss 1e-05
wandb: 
wandb: ðŸš€ View run snowy-disco-1286 at: https://wandb.ai/nreints/ThesisFinal2/runs/72vxjrlb
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230710_171457-72vxjrlb/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230710_171940-5psxab08
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run decent-voice-1297
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/5psxab08
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                     Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb: Test loss tennis_pNone_gNone_tennisEffect â–ˆâ–‡â–†â–„â–ƒâ–ƒâ–â–â–â–
wandb:                                Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                     Epoch 9
wandb: Test loss tennis_pNone_gNone_tennisEffect 1e-05
wandb:                                Train loss 1e-05
wandb: 
wandb: ðŸš€ View run decent-voice-1297 at: https://wandb.ai/nreints/ThesisFinal2/runs/5psxab08
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230710_171940-5psxab08/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230710_172425-47afyxwb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run copper-hill-1308
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/47afyxwb
		--> Epoch time; 20.24221897125244
Epoch 8/9
	 Logging train Loss: 1.43773e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.12313e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 20.04643940925598
Epoch 9/9
	 Logging train Loss: 1.36597e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.34832e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 20.142128705978394
Saved model in  trained_models/gru/data_tennis_pNone_gNone_tennisEffect/'quat_1'_'True'.pth
It took  283.2661519050598  seconds.
----- ITERATION 4/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 56.39432764053345 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 14.121227502822876 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (pre_hidden_lin_layer): Sequential(
    (0): Linear(in_features=3, out_features=96, bias=True)
    (1): ReLU()
    (2): Linear(in_features=96, out_features=96, bias=True)
    (3): ReLU()
  )
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0019324542 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 9.79218e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.95521640777588
Epoch 1/9
	 Logging train Loss: 6.59189e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 4.95843e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 20.165719509124756
Epoch 2/9
	 Logging train Loss: 5.1367e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 6.34044e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 20.118019580841064
Epoch 3/9
	 Logging train Loss: 4.18712e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 3.34409e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 20.100654363632202
Epoch 4/9
	 Logging train Loss: 3.21487e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.77176e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 20.199102878570557
Epoch 5/9
	 Logging train Loss: 2.35909e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.44203e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 20.155729293823242
Epoch 6/9
	 Logging train Loss: 1.83025e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.96287e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 20.100064754486084
Epoch 7/9
	 Logging train Loss: 1.59296e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.16963e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 20.001916646957397
Epoch 8/9
	 Logging train Loss: 1.42421e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.01484e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 20.17367386817932
Epoch 9/9
	 Logging train Loss: 1.216e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.40881e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.796290397644043
Saved model in  trained_models/gru/data_tennis_pNone_gNone_tennisEffect/'quat_1'_'True'.pth
It took  283.20717906951904  seconds.
----- ITERATION 5/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 56.126896381378174 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 14.073163747787476 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (pre_hidden_lin_layer): Sequential(
    (0): Linear(in_features=3, out_features=96, bias=True)
    (1): ReLU()
    (2): Linear(in_features=96, out_features=96, bias=True)
    (3): ReLU()
  )
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0030214097 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 6.33897e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 20.132182836532593
Epoch 1/9
	 Logging train Loss: 6.08938e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 5.36998e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 20.07511019706726
Epoch 2/9
	 Logging train Loss: 5.36367e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 4.97674e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 20.365246295928955
Epoch 3/9
	 Logging train Loss: 4.38271e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 3.33706e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 20.16447162628174
Epoch 4/9
	 Logging train Loss: 3.68324e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.53421e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.999634504318237
Epoch 5/9
	 Logging train Loss: 2.69265e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.22513e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 20.265276432037354
Epoch 6/9
	 Logging train Loss: 2.07347e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.19053e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 20.1085467338562
Epoch 7/9
	 Logging train Loss: 1.70833e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.06311e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 20.051475524902344
Epoch 8/9
	 Logging train Loss: 1.4609e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.00489e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 20.29355549812317
Epoch 9/9
	 Logging train Loss: 1.35047e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 9.8466e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.97735857963562
Saved model in  trained_models/gru/data_tennis_pNone_gNone_tennisEffect/'quat_1'_'True'.pth
It took  284.5609178543091  seconds.
----- ITERATION 6/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 56.28588271141052 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 14.041701793670654 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (pre_hidden_lin_layer): Sequential(
    (0): Linear(in_features=3, out_features=96, bias=True)
    (1): ReLU()
    (2): Linear(in_features=96, out_features=96, bias=True)
    (3): ReLU()
  )
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0027226021 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 9.55944e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 20.19247341156006
Epoch 1/9
	 Logging train Loss: 6.11607e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 4.90324e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 20.124664306640625
Epoch 2/9
	 Logging train Loss: 5.08085e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 4.28074e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.981547594070435
Epoch 3/9
	 Logging train Loss: 3.93215e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 4.75574e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 20.09845757484436
Epoch 4/9
	 Logging train Loss: 3.16077e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.04642e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 20.18398404121399
Epoch 5/9
	 Logging train Loss: 2.30959e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.46056e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 20.32915496826172
Epoch 6/9
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                     Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb: Test loss tennis_pNone_gNone_tennisEffect â–ˆâ–„â–„â–„â–‚â–â–â–‚â–â–
wandb:                                Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                     Epoch 9
wandb: Test loss tennis_pNone_gNone_tennisEffect 1e-05
wandb:                                Train loss 1e-05
wandb: 
wandb: ðŸš€ View run copper-hill-1308 at: https://wandb.ai/nreints/ThesisFinal2/runs/47afyxwb
wandb: Synced 7 W&B file(s), 0 media file(s), 1 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230710_172425-47afyxwb/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230710_172908-dhu15imi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run grateful-elevator-1322
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/dhu15imi
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                     Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb: Test loss tennis_pNone_gNone_tennisEffect â–ˆâ–…â–„â–ƒâ–‚â–â–ƒâ–â–â–
wandb:                                Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                     Epoch 9
wandb: Test loss tennis_pNone_gNone_tennisEffect 1e-05
wandb:                                Train loss 1e-05
wandb: 
wandb: ðŸš€ View run grateful-elevator-1322 at: https://wandb.ai/nreints/ThesisFinal2/runs/dhu15imi
wandb: Synced 7 W&B file(s), 0 media file(s), 1 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230710_172908-dhu15imi/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230710_173351-xz0poyh8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run absurd-terrain-1333
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/xz0poyh8
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                     Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb: Test loss tennis_pNone_gNone_tennisEffect â–ˆâ–…â–…â–…â–‚â–‚â–â–‚â–â–
wandb:                                Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                     Epoch 9
wandb: Test loss tennis_pNone_gNone_tennisEffect 1e-05
wandb:                                Train loss 1e-05
wandb: 
wandb: ðŸš€ View run absurd-terrain-1333 at: https://wandb.ai/nreints/ThesisFinal2/runs/xz0poyh8
wandb: Synced 7 W&B file(s), 0 media file(s), 1 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230710_173351-xz0poyh8/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230710_173832-ziq3svyf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dazzling-river-1345
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/ziq3svyf
	 Logging train Loss: 1.72862e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.37036e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 20.066404819488525
Epoch 7/9
	 Logging train Loss: 1.51489e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.1716e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.923506498336792
Epoch 8/9
	 Logging train Loss: 1.34538e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.05312e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 20.191202402114868
Epoch 9/9
	 Logging train Loss: 1.26153e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 9.4345e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 20.228350400924683
Saved model in  trained_models/gru/data_tennis_pNone_gNone_tennisEffect/'quat_1'_'True'.pth
It took  283.2282700538635  seconds.
----- ITERATION 7/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 56.380532026290894 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 14.06336784362793 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (pre_hidden_lin_layer): Sequential(
    (0): Linear(in_features=3, out_features=96, bias=True)
    (1): ReLU()
    (2): Linear(in_features=96, out_features=96, bias=True)
    (3): ReLU()
  )
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0020728344 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 0.0001125417 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 20.017830848693848
Epoch 1/9
	 Logging train Loss: 7.18339e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 6.62297e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 20.11182403564453
Epoch 2/9
	 Logging train Loss: 5.68146e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 5.14289e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 20.15305781364441
Epoch 3/9
	 Logging train Loss: 4.28619e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 3.329e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 20.223028898239136
Epoch 4/9
	 Logging train Loss: 3.12399e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.50689e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 20.116326093673706
Epoch 5/9
	 Logging train Loss: 2.2909e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.45483e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 20.20674157142639
Epoch 6/9
	 Logging train Loss: 1.7391e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 4.07199e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 20.293028116226196
Epoch 7/9
	 Logging train Loss: 1.46862e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.27007e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.90687346458435
Epoch 8/9
	 Logging train Loss: 1.33002e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.22571e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 20.13425922393799
Epoch 9/9
	 Logging train Loss: 1.21838e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 8.8824e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.790263175964355
Saved model in  trained_models/gru/data_tennis_pNone_gNone_tennisEffect/'quat_1'_'True'.pth
It took  282.95838952064514  seconds.
----- ITERATION 8/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 56.16854476928711 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 14.042450189590454 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (pre_hidden_lin_layer): Sequential(
    (0): Linear(in_features=3, out_features=96, bias=True)
    (1): ReLU()
    (2): Linear(in_features=96, out_features=96, bias=True)
    (3): ReLU()
  )
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.001763206 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 7.62609e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 20.069456815719604
Epoch 1/9
	 Logging train Loss: 7.54102e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 5.18237e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.72140622138977
Epoch 2/9
	 Logging train Loss: 5.88644e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 4.31132e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.925431489944458
Epoch 3/9
	 Logging train Loss: 4.36679e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 4.69252e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.669652462005615
Epoch 4/9
	 Logging train Loss: 3.02012e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 2.09937e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.90141797065735
Epoch 5/9
	 Logging train Loss: 2.21041e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.99823e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.9033203125
Epoch 6/9
	 Logging train Loss: 1.71189e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.21782e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 20.067657947540283
Epoch 7/9
	 Logging train Loss: 1.45355e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.42887e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.89794921875
Epoch 8/9
	 Logging train Loss: 1.33878e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 9.101e-06 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 20.144612550735474
Epoch 9/9
	 Logging train Loss: 1.2163e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.07254e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.870863437652588
Saved model in  trained_models/gru/data_tennis_pNone_gNone_tennisEffect/'quat_1'_'True'.pth
It took  281.5247311592102  seconds.
----- ITERATION 9/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 56.16511583328247 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 14.049903631210327 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (pre_hidden_lin_layer): Sequential(
    (0): Linear(in_features=3, out_features=96, bias=True)
    (1): ReLU()
    (2): Linear(in_features=96, out_features=96, bias=True)
    (3): ReLU()
  )
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0014805315 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 0.000109773 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 20.021087646484375
Epoch 1/9
	 Logging train Loss: 7.46977e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 6.87493e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.97310519218445
Epoch 2/9
	 Logging train Loss: 5.655e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 4.05922e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.768080949783325
Epoch 3/9
	 Logging train Loss: 4.2096e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 4.92224e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 20.059004306793213
Epoch 4/9
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                     Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb: Test loss tennis_pNone_gNone_tennisEffect â–ˆâ–…â–ƒâ–„â–‚â–â–â–â–â–
wandb:                                Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                     Epoch 9
wandb: Test loss tennis_pNone_gNone_tennisEffect 1e-05
wandb:                                Train loss 1e-05
wandb: 
wandb: ðŸš€ View run dazzling-river-1345 at: https://wandb.ai/nreints/ThesisFinal2/runs/ziq3svyf
wandb: Synced 7 W&B file(s), 0 media file(s), 1 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230710_173832-ziq3svyf/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230710_174315-w9q8n0ie
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run balmy-snowball-1355
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/w9q8n0ie
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                     Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb: Test loss tennis_pNone_gNone_tennisEffect â–‡â–ˆâ–…â–†â–ƒâ–‚â–â–â–â–
wandb:                                Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                     Epoch 9
wandb: Test loss tennis_pNone_gNone_tennisEffect 1e-05
wandb:                                Train loss 1e-05
wandb: 
wandb: ðŸš€ View run balmy-snowball-1355 at: https://wandb.ai/nreints/ThesisFinal2/runs/w9q8n0ie
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230710_174315-w9q8n0ie/logs
	 Logging train Loss: 3.02484e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.81283e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.569400310516357
Epoch 5/9
	 Logging train Loss: 2.19409e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.4917e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.976584911346436
Epoch 6/9
	 Logging train Loss: 1.68167e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.59825e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.859243392944336
Epoch 7/9
	 Logging train Loss: 1.49578e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.30802e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.784151792526245
Epoch 8/9
	 Logging train Loss: 1.30874e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.0037e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.90356421470642
Epoch 9/9
	 Logging train Loss: 1.17952e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.22535e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.899351835250854
Saved model in  trained_models/gru/data_tennis_pNone_gNone_tennisEffect/'quat_1'_'True'.pth
It took  282.7451400756836  seconds.
----- ITERATION 10/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 56.12197995185852 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_tennis_pNone_gNone_tennisEffect took 14.051892042160034 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (pre_hidden_lin_layer): Sequential(
    (0): Linear(in_features=3, out_features=96, bias=True)
    (1): ReLU()
    (2): Linear(in_features=96, out_features=96, bias=True)
    (3): ReLU()
  )
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0021357876 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 6.86002e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.772404670715332
Epoch 1/9
	 Logging train Loss: 7.72903e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 7.52486e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 20.073500633239746
Epoch 2/9
	 Logging train Loss: 5.99327e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 4.50633e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 20.09645915031433
Epoch 3/9
	 Logging train Loss: 5.07722e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 5.94872e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.976535320281982
Epoch 4/9
	 Logging train Loss: 3.96485e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 3.30988e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.912321090698242
Epoch 5/9
	 Logging train Loss: 3.03606e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.97399e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 20.0973858833313
Epoch 6/9
	 Logging train Loss: 2.24372e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.27042e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 20.03146481513977
Epoch 7/9
	 Logging train Loss: 1.76977e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.3223e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.742270946502686
Epoch 8/9
	 Logging train Loss: 1.50266e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.11326e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.930020332336426
Epoch 9/9
	 Logging train Loss: 1.3215e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
	 Logging test loss: 1.00224e-05 [MSELoss(): tennis_pNone_gNone_tennisEffect]
		--> Epoch time; 19.633812427520752
Saved model in  trained_models/gru/data_tennis_pNone_gNone_tennisEffect/'quat_1'_'True'.pth
It took  282.8047959804535  seconds.

JOB STATISTICS
==============
Job ID: 3043761
Array Job ID: 3043750_50
Cluster: snellius
User/Group: nreints/nreints
State: COMPLETED (exit code 0)
Nodes: 1
Cores per node: 18
CPU Utilized: 00:49:15
CPU Efficiency: 5.74% of 14:18:18 core-walltime
Job Wall-clock time: 00:47:41
Memory Utilized: 5.67 GB
Memory Efficiency: 0.00% of 0.00 MB
