wandb: Currently logged in as: nreints. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230329_133618-e7ialvrh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run swept-pyramid-509
wandb: â­ï¸ View project at https://wandb.ai/nreints/test
wandb: ðŸš€ View run at https://wandb.ai/nreints/test/runs/e7ialvrh
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.031 MB of 0.031 MB uploaded (0.000 MB deduped)wandb: \ 0.031 MB of 0.031 MB uploaded (0.000 MB deduped)wandb: | 0.031 MB of 0.031 MB uploaded (0.000 MB deduped)wandb: / 0.031 MB of 0.031 MB uploaded (0.000 MB deduped)wandb: - 0.031 MB of 0.031 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:                                                    Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb: Test loss t(0, 0)_r(5, 20)_tennis_pNone_gNone, MSELoss() â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–
wandb:                                               Train loss â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                                    Epoch 9
wandb: Test loss t(0, 0)_r(5, 20)_tennis_pNone_gNone, MSELoss() 0.10881
wandb:                                               Train loss 0.12089
wandb: 
wandb: ðŸš€ View run swept-pyramid-509 at: https://wandb.ai/nreints/test/runs/e7ialvrh
wandb: Synced 6 W&B file(s), 0 media file(s), 2 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230329_133618-e7ialvrh/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230329_134344-3xzg0fse
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run silvery-puddle-516
wandb: â­ï¸ View project at https://wandb.ai/nreints/test
wandb: ðŸš€ View run at https://wandb.ai/nreints/test/runs/3xzg0fse
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.031 MB of 0.031 MB uploaded (0.000 MB deduped)wandb: \ 0.031 MB of 0.031 MB uploaded (0.000 MB deduped)wandb: | 0.031 MB of 0.031 MB uploaded (0.000 MB deduped)wandb: / 0.031 MB of 0.031 MB uploaded (0.000 MB deduped)wandb: - 0.031 MB of 0.031 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:                                                    Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb: Test loss t(0, 0)_r(5, 20)_tennis_pNone_gNone, MSELoss() â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–
wandb:                                               Train loss â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                                    Epoch 9
wandb: Test loss t(0, 0)_r(5, 20)_tennis_pNone_gNone, MSELoss() 0.11844
wandb:                                               Train loss 0.11932
wandb: 
wandb: ðŸš€ View run silvery-puddle-516 at: https://wandb.ai/nreints/test/runs/3xzg0fse
wandb: Synced 6 W&B file(s), 0 media file(s), 2 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230329_134344-3xzg0fse/logs
Running for data type: pos
----- ITERATION 1/2 ------
Number of train simulations: 1600
Number of test simulations: 400
-- Finished Train Dataloader --
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(24, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=24, bias=True)
)
-- Started Training --
Epoch 0
	 Logging train Loss: 127.9033398698 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss: 41.17820358276367 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 39.4010329246521
Epoch 1
	 Logging train Loss: 23.7522112817 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss: 10.468557357788086 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 37.57600283622742
Epoch 2
	 Logging train Loss: 6.6243370066 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss: 3.5062954425811768 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 37.32948637008667
Epoch 3
	 Logging train Loss: 2.4279323929 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss: 1.4804812669754028 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 37.558634519577026
Epoch 4
	 Logging train Loss: 1.0714406318 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss: 0.6958052515983582 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 37.730257987976074
Epoch 5
	 Logging train Loss: 0.5282560585 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss: 0.3934801518917084 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 37.40228509902954
Epoch 6
	 Logging train Loss: 0.3178310216 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss: 0.2527620494365692 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 37.535845041275024
Epoch 7
	 Logging train Loss: 0.2114747561 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss: 0.17696666717529297 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 37.50652742385864
Epoch 8
	 Logging train Loss: 0.1562310233 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss: 0.13743916153907776 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 37.47479248046875
Epoch 9
	 Logging train Loss: 0.1208857293 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss: 0.1088595911860466 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 37.28597283363342
	 Logging test loss: 0.1088121309876442 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
It took  446.8401176929474  seconds.
----- ITERATION 2/2 ------
Number of train simulations: 1600
Number of test simulations: 400
-- Finished Train Dataloader --
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(24, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=24, bias=True)
)
-- Started Training --
Epoch 0
	 Logging train Loss: 126.7481120661 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss: 45.41996383666992 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 38.668073892593384
Epoch 1
	 Logging train Loss: 24.073509471 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss: 11.958288192749023 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 37.917107343673706
Epoch 2
	 Logging train Loss: 6.8428888257 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss: 4.144405841827393 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 37.46686100959778
Epoch 3
	 Logging train Loss: 2.5419872982 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss: 1.7361172437667847 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 37.72555708885193
Epoch 4
	 Logging train Loss: 1.0904738219 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss: 0.8160104155540466 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 38.25394344329834
Epoch 5
	 Logging train Loss: 0.5498594888 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss: 0.4511371850967407 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 40.08204650878906
Epoch 6
	 Logging train Loss: 0.3260878396 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss: 0.29012352228164673 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 41.333683013916016
Epoch 7
	 Logging train Loss: 0.2170734278 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss: 0.19583353400230408 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 41.47041082382202
Epoch 8
	 Logging train Loss: 0.1549417167 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss: 0.1460139900445938 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 39.24690103530884
Epoch 9
	 Logging train Loss: 0.1193188106 (MSELoss(): data_t(0, 0)_r(5, 20)_tennis_pNone_gNone)
	 Logging test loss: 0.1185423955321312 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
     --> Epoch time; 37.7716588973999
	 Logging test loss: 0.11844269931316376 (MSELoss(): t(0, 0)_r(5, 20)_tennis_pNone_gNone)
It took  454.41546058654785  seconds.

JOB STATISTICS
==============
Job ID: 2514793
Array Job ID: 2514792_1
Cluster: snellius
User/Group: nreints/nreints
State: COMPLETED (exit code 0)
Nodes: 1
Cores per node: 18
CPU Utilized: 02:56:03
CPU Efficiency: 64.13% of 04:34:30 core-walltime
Job Wall-clock time: 00:15:15
Memory Utilized: 27.79 GB
Memory Efficiency: 88.94% of 31.25 GB
