wandb: Currently logged in as: nreints. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_211345-7vbmych7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lucky-pine-455
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/7vbmych7
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gTrue â–ˆâ–†â–…â–ƒâ–ƒâ–„â–ƒâ–‚â–‚â–
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gTrue â–ˆâ–ƒâ–‚â–â–â–‚â–â–â–ƒâ–
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gTrue â–ˆâ–‡â–†â–„â–„â–„â–ƒâ–‚â–‚â–
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gTrue â–ˆâ–‡â–†â–„â–„â–„â–ƒâ–‚â–‚â–
wandb:                                   Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gTrue 0.0
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gTrue 0.0
wandb:                                   Train loss 0.0
wandb: 
wandb: ðŸš€ View run lucky-pine-455 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/7vbmych7
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_211345-7vbmych7/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_212449-bcmjzoep
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rural-sunset-472
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/bcmjzoep
Training on dataset: data_t(5,20)_r(5,20)_combi_pNone_gTrue
Testing on 4 datasets: ['data_t(5,20)_r(5,20)_full_pNone_gTrue', 'data_t(5,20)_r(5,20)_tennis_pNone_gTrue', 'data_t(5,20)_r(5,20)_combi_pNone_gTrue', 'data_t(5,20)_r(5,20)_semi_pNone_gTrue']
Focussing on identity: True
Using extra input: False
Using fr-fr as reference point.
----- ITERATION 1/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gTrue took 51.908206939697266 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gTrue took 13.273743391036987 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gTrue took 12.90207839012146 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gTrue took 13.107158422470093 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gTrue took 13.163641214370728 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0003321974 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 4.8726e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 1.46197e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 9.6084e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 1.3551e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 54.793261766433716
Epoch 1/9
	 Logging train Loss: 6.1773e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 1.5644e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 1.26748e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 6.8571e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 1.14975e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 54.377124071121216
Epoch 2/9
	 Logging train Loss: 5.0269e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 9.264e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 1.14353e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 5.9939e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 1.04065e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 54.398982763290405
Epoch 3/9
	 Logging train Loss: 4.2883e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 5.379e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 7.1519e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 3.7227e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 6.4964e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 54.44467306137085
Epoch 4/9
	 Logging train Loss: 3.5732e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 5.664e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 7.8938e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 4.0735e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 7.1002e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 55.609391927719116
Epoch 5/9
	 Logging train Loss: 3.1298e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 6.773e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 8.1304e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 4.2923e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 7.1955e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 55.37011003494263
Epoch 6/9
	 Logging train Loss: 2.627e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 3.438e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 6.2676e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 3.177e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 5.5161e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 54.90255284309387
Epoch 7/9
	 Logging train Loss: 2.2257e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 3.937e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 3.8223e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 2.0303e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 3.3898e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 54.34677720069885
Epoch 8/9
	 Logging train Loss: 1.7433e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 1.382e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 3.4437e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 2.3902e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 3.1919e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 53.75516223907471
Epoch 9/9
	 Logging train Loss: 1.6659e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 4.038e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 2.3308e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 1.311e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 2.0967e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 53.81672716140747
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gTrue/'rot_mat_1'_'False'.pth
It took  664.8233082294464  seconds.
----- ITERATION 2/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gTrue took 50.67582607269287 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gTrue took 12.807918071746826 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gTrue took 12.758656740188599 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gTrue took 12.65104603767395 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gTrue took 12.754820585250854 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0002435574 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 3.0292e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 1.30797e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 7.7495e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 1.23757e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 55.283549070358276
Epoch 1/9
	 Logging train Loss: 5.9289e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 1.1828e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 7.8801e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 4.2991e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 7.7066e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 54.981045961380005
Epoch 2/9
	 Logging train Loss: 5.0344e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 5.946e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 6.2739e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 3.2711e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 6.1207e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 54.06661581993103
Epoch 3/9
	 Logging train Loss: 4.2044e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 6.963e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 1.13389e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 5.8323e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 1.09054e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gTrue â–ˆâ–„â–ƒâ–†â–‚â–â–ƒâ–â–â–
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gTrue â–ˆâ–ƒâ–‚â–‚â–â–â–ƒâ–â–â–
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gTrue â–ˆâ–…â–„â–‡â–‚â–â–ƒâ–â–â–
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gTrue â–ˆâ–…â–„â–‡â–‚â–â–ƒâ–â–â–
wandb:                                   Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gTrue 0.0
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gTrue 0.0
wandb:                                   Train loss 0.0
wandb: 
wandb: ðŸš€ View run rural-sunset-472 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/bcmjzoep
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_212449-bcmjzoep/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_213547-jf8hiczb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run scarlet-pond-488
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/jf8hiczb
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gTrue â–ˆâ–†â–ƒâ–„â–„â–…â–‚â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gTrue â–ˆâ–„â–‚â–‚â–â–‚â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gTrue â–ˆâ–‡â–„â–…â–…â–†â–‚â–â–â–
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gTrue â–ˆâ–‡â–„â–…â–†â–†â–‚â–â–â–
wandb:                                   Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gTrue 0.0
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gTrue 0.0
wandb:                                   Train loss 0.0
wandb: 
wandb: ðŸš€ View run scarlet-pond-488 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/jf8hiczb
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_213547-jf8hiczb/logs
		--> Epoch time; 54.02922749519348
Epoch 4/9
	 Logging train Loss: 3.3018e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 2.939e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 4.2911e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 2.1689e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 4.153e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 54.01365828514099
Epoch 5/9
	 Logging train Loss: 2.7855e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 2.22e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 2.7582e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 1.4263e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 2.6899e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 54.317950963974
Epoch 6/9
	 Logging train Loss: 2.0865e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 9.253e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 5.8688e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 3.2174e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 5.456e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 54.15497660636902
Epoch 7/9
	 Logging train Loss: 1.8752e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 1.935e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 2.4688e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 1.2717e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 2.3484e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 53.926225423812866
Epoch 8/9
	 Logging train Loss: 1.7277e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 3.839e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 3.0177e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 1.6535e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 2.8824e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 53.91109108924866
Epoch 9/9
	 Logging train Loss: 1.5852e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 2.186e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 2.9706e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 1.5603e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 2.7993e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 54.435222864151
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gTrue/'rot_mat_1'_'False'.pth
It took  658.1745247840881  seconds.
----- ITERATION 3/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gTrue took 50.61766481399536 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gTrue took 12.750086069107056 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gTrue took 12.757007837295532 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gTrue took 12.66393494606018 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gTrue took 12.767487525939941 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0003201582 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 3.7427e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 1.20388e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 7.8706e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 1.25693e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 55.06510853767395
Epoch 1/9
	 Logging train Loss: 6.4277e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 1.7242e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 1.09106e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 6.2388e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 1.12068e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 55.22305345535278
Epoch 2/9
	 Logging train Loss: 5.2543e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 8.155e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 6.4487e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 3.5398e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 6.6206e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 54.89234256744385
Epoch 3/9
	 Logging train Loss: 4.2225e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 5.469e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 8.006e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 4.1013e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 7.8604e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 55.219794034957886
Epoch 4/9
	 Logging train Loss: 3.4601e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 4.146e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 8.8238e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 4.4947e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 8.5151e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 54.91227412223816
Epoch 5/9
	 Logging train Loss: 2.8791e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 4.716e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 9.2148e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 4.8499e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 9.1779e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 55.21467566490173
Epoch 6/9
	 Logging train Loss: 2.3796e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 2.804e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 3.4868e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 1.7925e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 3.3962e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 55.0851526260376
Epoch 7/9
	 Logging train Loss: 1.9093e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 3.91e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 2.5047e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 1.3869e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 2.427e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 54.93095374107361
Epoch 8/9
	 Logging train Loss: 1.7446e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 1.96e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 2.5145e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 1.2852e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 2.4346e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 54.778188943862915
Epoch 9/9
	 Logging train Loss: 1.6092e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 3.928e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 2.1284e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 1.2016e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 2.0755e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 55.38741660118103
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gTrue/'rot_mat_1'_'False'.pth
It took  663.9347288608551  seconds.
----- ITERATION 4/10 ------
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_214651-0292885j
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run chocolate-salad-502
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/0292885j
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gTrue â–ˆâ–…â–ƒâ–‚â–‚â–â–â–â–â–‚
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gTrue â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gTrue â–ˆâ–†â–ƒâ–‚â–‚â–â–â–â–â–‚
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gTrue â–ˆâ–†â–ƒâ–‚â–‚â–â–â–â–â–‚
wandb:                                   Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gTrue 0.0
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gTrue 0.0
wandb:                                   Train loss 0.0
wandb: 
wandb: ðŸš€ View run chocolate-salad-502 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/0292885j
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_214651-0292885j/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_215805-bndov1du
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run icy-wildflower-516
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/bndov1du
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gTrue took 50.72159957885742 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gTrue took 12.708192586898804 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gTrue took 12.719552278518677 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gTrue took 12.671056747436523 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gTrue took 12.744508028030396 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0002816774 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 6.704e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 1.55928e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 1.15262e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 1.58252e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 56.0915162563324
Epoch 1/9
	 Logging train Loss: 7.5058e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 2.0092e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 1.18493e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 7.1618e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 1.18394e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 55.81409955024719
Epoch 2/9
	 Logging train Loss: 5.6673e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 1.0826e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 6.3123e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 3.8378e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 6.4234e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 55.048659563064575
Epoch 3/9
	 Logging train Loss: 4.513e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 6.01e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 4.6743e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 2.7564e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 4.8385e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 55.824317932128906
Epoch 4/9
	 Logging train Loss: 3.503e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 4.679e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 4.4364e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 2.5713e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 4.3981e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 56.815690994262695
Epoch 5/9
	 Logging train Loss: 2.6888e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 2.232e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 2.6621e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 1.5064e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 2.6494e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 56.30843734741211
Epoch 6/9
	 Logging train Loss: 2.1609e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 5.457e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 3.1219e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 1.8848e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 3.0089e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 55.81971025466919
Epoch 7/9
	 Logging train Loss: 1.9258e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 3.849e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 2.6571e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 1.5827e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 2.5822e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 56.184478998184204
Epoch 8/9
	 Logging train Loss: 1.5947e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 2.378e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 3.2585e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 1.8229e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 3.0688e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 56.186455488204956
Epoch 9/9
	 Logging train Loss: 1.5722e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 3.794e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 4.5547e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 2.5804e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 4.2754e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 56.34135723114014
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gTrue/'rot_mat_1'_'False'.pth
It took  674.1240830421448  seconds.
----- ITERATION 5/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gTrue took 50.708157777786255 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gTrue took 12.698520421981812 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gTrue took 12.67198896408081 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gTrue took 12.640532493591309 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gTrue took 12.708729028701782 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0003542165 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 2.569e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 1.14527e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 6.7596e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 1.15741e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 54.218069553375244
Epoch 1/9
	 Logging train Loss: 5.52e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 1.1504e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 8.9208e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 4.8935e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 9.0785e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 54.0654559135437
Epoch 2/9
	 Logging train Loss: 4.8328e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 5.478e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 6.8341e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 3.5673e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 6.9498e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 54.15550637245178
Epoch 3/9
	 Logging train Loss: 4.0293e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 3.098e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 5.4968e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 2.7781e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 5.5504e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 54.22520709037781
Epoch 4/9
	 Logging train Loss: 3.6307e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 3.299e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 4.6493e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 2.3686e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gTrue â–ˆâ–†â–„â–ƒâ–‚â–‚â–‚â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gTrue â–ˆâ–„â–‚â–â–â–â–‚â–â–‚â–
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gTrue â–ˆâ–†â–„â–ƒâ–ƒâ–‚â–‚â–â–â–
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gTrue â–ˆâ–†â–„â–ƒâ–ƒâ–‚â–‚â–â–â–
wandb:                                   Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gTrue 0.0
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gTrue 0.0
wandb:                                   Train loss 0.0
wandb: 
wandb: ðŸš€ View run icy-wildflower-516 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/bndov1du
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_215805-bndov1du/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_220909-8gffw5fa
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run devoted-durian-532
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/8gffw5fa
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gTrue â–ˆâ–‡â–†â–ƒâ–†â–â–â–‚â–â–
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gTrue â–ˆâ–„â–ƒâ–â–‚â–â–‚â–â–ƒâ–ƒ
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gTrue â–ˆâ–‡â–†â–„â–‡â–‚â–â–ƒâ–â–
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gTrue â–ˆâ–‡â–‡â–„â–‡â–‚â–â–ƒâ–â–
wandb:                                   Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gTrue 0.0
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gTrue 0.0
wandb:                                   Train loss 0.0
wandb: 
wandb: ðŸš€ View run devoted-durian-532 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/8gffw5fa
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_220909-8gffw5fa/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_222009-mepxebqu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run bumbling-sun-544
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/mepxebqu
	 Logging test loss: 4.6413e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 54.55124878883362
Epoch 5/9
	 Logging train Loss: 2.8796e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 4.183e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 3.7912e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 2.0057e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 3.7287e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 54.723926067352295
Epoch 6/9
	 Logging train Loss: 2.4492e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 4.702e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 3.8641e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 2.0453e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 3.7296e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 55.02173662185669
Epoch 7/9
	 Logging train Loss: 2.0188e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 2.885e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 2.8087e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 1.4509e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 2.7261e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 55.79570460319519
Epoch 8/9
	 Logging train Loss: 1.7392e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 5.428e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 2.7802e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 1.5625e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 2.6745e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 55.71468901634216
Epoch 9/9
	 Logging train Loss: 1.6427e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 2.889e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 2.5832e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 1.3466e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 2.471e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 56.6324987411499
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gTrue/'rot_mat_1'_'False'.pth
It took  663.8781168460846  seconds.
----- ITERATION 6/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gTrue took 50.6880578994751 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gTrue took 12.676231145858765 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gTrue took 12.700685024261475 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gTrue took 12.665616035461426 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gTrue took 12.701279163360596 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0002293711 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 1.7094e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 1.08837e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 5.8117e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 9.5997e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 54.46742558479309
Epoch 1/9
	 Logging train Loss: 5.3764e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 8.995e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 9.8617e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 4.9267e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 8.6768e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 54.60528254508972
Epoch 2/9
	 Logging train Loss: 4.2523e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 6.923e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 9.183e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 4.5134e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 7.9368e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 54.759262561798096
Epoch 3/9
	 Logging train Loss: 3.6043e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 2.954e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 6.0307e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 2.895e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 5.2324e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 55.58293700218201
Epoch 4/9
	 Logging train Loss: 3.2329e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 4.869e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 9.6222e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 4.6283e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 8.2031e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 54.80795860290527
Epoch 5/9
	 Logging train Loss: 2.6876e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 2.506e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 3.435e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 1.6819e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 2.9634e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 54.497658014297485
Epoch 6/9
	 Logging train Loss: 2.1337e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 5.271e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 3.0562e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 1.6694e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 2.6651e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 54.10131072998047
Epoch 7/9
	 Logging train Loss: 1.7742e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 3.172e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 4.951e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 2.4697e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 4.2843e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 54.328707218170166
Epoch 8/9
	 Logging train Loss: 1.6397e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 6.286e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 3.0565e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 1.7313e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 2.6842e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 54.35506844520569
Epoch 9/9
	 Logging train Loss: 1.5539e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 6.191e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 2.7915e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 1.5923e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 2.4417e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 54.55569100379944
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gTrue/'rot_mat_1'_'False'.pth
It took  660.2396092414856  seconds.
----- ITERATION 7/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gTrue took 50.69872784614563 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gTrue took 12.721797704696655 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gTrue took 12.682350158691406 seconds.
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gTrue â–ˆâ–…â–„â–„â–„â–‚â–‚â–„â–‚â–
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gTrue â–ˆâ–„â–‚â–‚â–‚â–â–â–‚â–â–
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gTrue â–ˆâ–…â–„â–…â–…â–‚â–‚â–„â–‚â–
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gTrue â–ˆâ–…â–„â–…â–…â–‚â–‚â–„â–‚â–
wandb:                                   Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gTrue 0.0
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gTrue 0.0
wandb:                                   Train loss 0.0
wandb: 
wandb: ðŸš€ View run bumbling-sun-544 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/mepxebqu
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_222009-mepxebqu/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_223122-mt91d034
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run royal-dawn-548
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/mt91d034
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gTrue took 12.64720344543457 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gTrue took 12.762491464614868 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0002483807 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 4.3417e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 1.2464e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 8.1516e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 1.19289e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 56.41435098648071
Epoch 1/9
	 Logging train Loss: 7.0232e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 1.9118e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 8.8429e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 5.3243e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 8.5058e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 55.71332025527954
Epoch 2/9
	 Logging train Loss: 5.4713e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 1.0175e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 7.2997e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 4.0811e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 6.9957e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 55.3804497718811
Epoch 3/9
	 Logging train Loss: 4.2733e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 6.971e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 8.0576e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 4.4211e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 7.6088e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 54.853846073150635
Epoch 4/9
	 Logging train Loss: 3.4033e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 6.722e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 8.616e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 4.7716e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 8.1117e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 54.880351543426514
Epoch 5/9
	 Logging train Loss: 2.771e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 4.046e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 4.1268e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 2.2836e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 3.8973e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 55.588523387908936
Epoch 6/9
	 Logging train Loss: 2.2141e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 3.68e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 3.7996e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 2.129e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 3.5611e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 54.97387886047363
Epoch 7/9
	 Logging train Loss: 1.8198e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 8.303e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 6.899e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 3.912e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 6.3886e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 55.76465916633606
Epoch 8/9
	 Logging train Loss: 1.6577e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 3.811e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 3.7007e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 2.0829e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 3.4234e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 55.91967296600342
Epoch 9/9
	 Logging train Loss: 1.5544e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 4.404e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 2.6e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 1.5394e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 2.4212e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 55.90299129486084
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gTrue/'rot_mat_1'_'False'.pth
It took  672.8578670024872  seconds.
----- ITERATION 8/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gTrue took 50.65091896057129 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gTrue took 12.680236339569092 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gTrue took 12.703490972518921 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gTrue took 12.651046991348267 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gTrue took 12.69059681892395 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0002073754 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 3.9693e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 1.53329e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 9.5789e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 1.49379e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 55.926254987716675
Epoch 1/9
	 Logging train Loss: 7.2564e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 1.7712e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 1.82515e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 9.7414e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 1.7122e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 56.01298999786377
Epoch 2/9
	 Logging train Loss: 5.1431e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 1.0535e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 1.11123e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 5.9195e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 1.0546e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 55.928476095199585
Epoch 3/9
	 Logging train Loss: 3.9142e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 4.942e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 8.5092e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 4.4077e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 7.9376e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 55.7934935092926
Epoch 4/9
	 Logging train Loss: 3.0846e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 2.652e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 4.2381e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 2.2309e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 4.0458e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 55.810487508773804
Epoch 5/9
	 Logging train Loss: 2.4362e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 3.342e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 5.7062e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gTrue â–ˆâ–ˆâ–…â–„â–‚â–‚â–‚â–â–‚â–
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gTrue â–ˆâ–„â–ƒâ–â–â–â–â–â–‚â–
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gTrue â–‡â–ˆâ–…â–„â–‚â–‚â–‚â–â–â–
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gTrue â–‡â–ˆâ–…â–„â–‚â–‚â–‚â–â–â–
wandb:                                   Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gTrue 0.0
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gTrue 0.0
wandb:                                   Train loss 0.0
wandb: 
wandb: ðŸš€ View run royal-dawn-548 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/mt91d034
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_223122-mt91d034/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_224236-rf555d0o
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run true-universe-550
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/rf555d0o
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gTrue â–‡â–…â–„â–„â–…â–ˆâ–„â–â–â–‚
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gTrue â–ˆâ–„â–ƒâ–‚â–ƒâ–…â–†â–â–â–ƒ
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gTrue â–‡â–…â–„â–„â–…â–ˆâ–ƒâ–â–â–‚
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gTrue â–†â–„â–„â–„â–…â–ˆâ–ƒâ–â–â–‚
wandb:                                   Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gTrue 0.0
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gTrue 0.0
wandb:                                   Train loss 0.0
wandb: 
wandb: ðŸš€ View run true-universe-550 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/rf555d0o
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_224236-rf555d0o/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_225336-1wp7p5ou
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run splendid-wave-552
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/1wp7p5ou
	 Logging test loss: 2.9465e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 5.2802e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 56.12288951873779
Epoch 6/9
	 Logging train Loss: 1.9735e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 2.783e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 4.2881e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 2.1938e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 3.9145e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 56.29303693771362
Epoch 7/9
	 Logging train Loss: 1.6583e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 2.36e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 2.3629e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 1.2701e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 2.1852e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 56.10639810562134
Epoch 8/9
	 Logging train Loss: 1.6076e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 1.0233e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 3.2606e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 2.1065e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 3.0728e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 55.99055480957031
Epoch 9/9
	 Logging train Loss: 1.4903e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 2.766e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 2.3815e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 1.2932e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 2.1956e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 55.70744442939758
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gTrue/'rot_mat_1'_'False'.pth
It took  674.2122821807861  seconds.
----- ITERATION 9/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gTrue took 49.36176300048828 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gTrue took 12.675224542617798 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gTrue took 12.628375053405762 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gTrue took 12.49858808517456 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gTrue took 12.654701471328735 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0002354577 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 2.7929e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 1.15587e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 7.2831e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 1.16171e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 54.489217042922974
Epoch 1/9
	 Logging train Loss: 6.6465e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 1.2398e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 8.4701e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 4.9263e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 8.4274e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 55.00115633010864
Epoch 2/9
	 Logging train Loss: 5.2077e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 1.058e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 7.2221e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 4.1889e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 7.1042e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 54.89013409614563
Epoch 3/9
	 Logging train Loss: 3.8812e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 5.571e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 7.3733e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 3.9846e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 7.1827e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 56.97864556312561
Epoch 4/9
	 Logging train Loss: 3.4459e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 1.1317e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 8.7277e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 4.8768e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 8.4239e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 54.22834372520447
Epoch 5/9
	 Logging train Loss: 2.7408e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 1.7275e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 1.49232e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 8.1228e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 1.36626e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 54.279834270477295
Epoch 6/9
	 Logging train Loss: 2.3501e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 2.0834e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 6.6436e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 4.3848e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 6.3541e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 54.61382436752319
Epoch 7/9
	 Logging train Loss: 1.9951e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 2.983e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 2.3776e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 1.3351e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 2.3073e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 54.31114459037781
Epoch 8/9
	 Logging train Loss: 1.7512e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 2.145e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 2.3898e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 1.3075e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 2.2966e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 54.58331084251404
Epoch 9/9
	 Logging train Loss: 1.6234e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 8.25e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 4.4586e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 2.6109e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 4.2469e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 55.56155228614807
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gTrue/'rot_mat_1'_'False'.pth
It took  660.1521692276001  seconds.
----- ITERATION 10/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gTrue took 50.615997314453125 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gTrue took 12.64867901802063 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gTrue took 12.67096209526062 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gTrue took 12.64821720123291 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gTrue took 12.654256105422974 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat_1
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gTrue â–ˆâ–†â–„â–†â–ƒâ–‚â–â–â–ƒâ–„
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gTrue â–ˆâ–„â–ƒâ–‚â–â–â–â–â–â–ˆ
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gTrue â–ˆâ–‡â–…â–‡â–ƒâ–‚â–â–â–ƒâ–ƒ
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gTrue â–ˆâ–‡â–…â–‡â–ƒâ–‚â–â–â–„â–ƒ
wandb:                                   Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gTrue 1e-05
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gTrue 1e-05
wandb:                                   Train loss 0.0
wandb: 
wandb: ðŸš€ View run splendid-wave-552 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/1wp7p5ou
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_225336-1wp7p5ou/logs
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0002392925 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 3.2056e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 1.23073e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 7.7001e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 1.29298e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 56.09378528594971
Epoch 1/9
	 Logging train Loss: 7.5158e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 1.709e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 1.04774e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 5.9062e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 1.07869e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 56.076229095458984
Epoch 2/9
	 Logging train Loss: 5.7235e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 9.718e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 7.6704e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 4.2145e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 7.8615e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 55.62550187110901
Epoch 3/9
	 Logging train Loss: 4.2347e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 6.45e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 1.11904e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 5.6927e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 1.09746e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 55.675148725509644
Epoch 4/9
	 Logging train Loss: 3.3787e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 3.966e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 5.2546e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 2.7432e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 5.2587e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 55.82875180244446
Epoch 5/9
	 Logging train Loss: 2.6756e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 3.824e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 3.2737e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 1.7645e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 3.2884e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 55.86409091949463
Epoch 6/9
	 Logging train Loss: 2.1383e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 2.474e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 2.373e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 1.2718e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 2.3624e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 55.848087310791016
Epoch 7/9
	 Logging train Loss: 1.8521e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 1.93e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 2.2039e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 1.1608e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 2.1875e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 55.9660005569458
Epoch 8/9
	 Logging train Loss: 1.6484e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 3.888e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 5.8638e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 3.0068e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 5.5916e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 55.90710639953613
Epoch 9/9
	 Logging train Loss: 1.5793e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 3.3812e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 5.4858e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 4.3854e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 5.4279e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 55.86698389053345
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gTrue/'rot_mat_1'_'False'.pth
It took  674.0808117389679  seconds.

JOB STATISTICS
==============
Job ID: 3086319
Array Job ID: 3086289_71
Cluster: snellius
User/Group: nreints/nreints
State: COMPLETED (exit code 0)
Nodes: 1
Cores per node: 18
CPU Utilized: 01:59:20
CPU Efficiency: 5.95% of 1-09:24:00 core-walltime
Job Wall-clock time: 01:51:20
Memory Utilized: 8.75 GB
Memory Efficiency: 0.00% of 0.00 MB
