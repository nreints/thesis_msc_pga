wandb: Currently logged in as: nreints. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_180604-ftrm8ldc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run serene-waterfall-933
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/ftrm8ldc
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue █▃▂▂▁▂▁▁▄▁
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue ▃▂▂▁▂▃▅▆██
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue ▄██▇▆▄▄▃▂▁
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue ██▇▇▅▄▄▃▂▁
wandb:                                 Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 0.00393
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.1172
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.23163
wandb:                                 Train loss 1e-05
wandb: 
wandb: 🚀 View run serene-waterfall-933 at: https://wandb.ai/nreints/ThesisFinal2/runs/ftrm8ldc
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_180604-ftrm8ldc/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_181911-fr7oslg5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hearty-lake-964
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/fr7oslg5
Training on dataset: data_t(0,0)_r(0,0)_combi_pNone_gTrue
Testing on 4 datasets: ['data_t(0,0)_r(0,0)_semi_pTrue_gTrue', 'data_t(0,0)_r(0,0)_full_pTrue_gTrue', 'data_t(0,0)_r(0,0)_tennis_pTrue_gTrue', 'data_t(0,0)_r(0,0)_combi_pNone_gTrue']
Focussing on identity: False
Using extra input: True
Using start-fr as reference point.
----- ITERATION 1/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 87.4099988937378 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 22.17094349861145 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 22.13028907775879 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 22.41624402999878 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 22.185928344726562 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (pre_hidden_lin_layer): Sequential(
    (0): Linear(in_features=3, out_features=96, bias=True)
    (1): ReLU()
    (2): Linear(in_features=96, out_features=96, bias=True)
    (3): ReLU()
  )
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0878692493 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1200952232 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0038742202 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.242946282 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 8.02324e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 59.67770338058472
Epoch 1/9
	 Logging train Loss: 4.78423e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1232080609 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0038592045 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.2427676171 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.69276e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 59.56179070472717
Epoch 2/9
	 Logging train Loss: 1.94155e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1234630495 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0038563977 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.2416172177 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.34007e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 59.69878792762756
Epoch 3/9
	 Logging train Loss: 1.05418e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1223836243 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0038480891 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.241539821 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 8.0984e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 59.51599907875061
Epoch 4/9
	 Logging train Loss: 7.9119e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1215331703 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0038636783 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.2388184071 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 5.5634e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 59.54129695892334
Epoch 5/9
	 Logging train Loss: 8.9551e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1199420244 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.003871409 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.2371058315 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 6.7737e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 59.82712769508362
Epoch 6/9
	 Logging train Loss: 1.03703e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1197055206 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0038916671 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.2358819991 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 4.1802e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 59.74946188926697
Epoch 7/9
	 Logging train Loss: 1.11347e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1190931723 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0039010821 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.2343252152 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.3447e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 59.581790924072266
Epoch 8/9
	 Logging train Loss: 1.05485e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1179825589 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.003929283 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.2333554626 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 3.47726e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 59.473772048950195
Epoch 9/9
	 Logging train Loss: 1.07082e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1172037795 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0039276974 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.2316261083 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 8.622e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 58.758078813552856
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'rot_mat'_'True'.pth
It took  787.5925071239471  seconds.
----- ITERATION 2/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 86.55500745773315 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 22.11872696876526 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 22.16527771949768 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 22.096089601516724 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 21.83154296875 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (pre_hidden_lin_layer): Sequential(
    (0): Linear(in_features=3, out_features=96, bias=True)
    (1): ReLU()
    (2): Linear(in_features=96, out_features=96, bias=True)
    (3): ReLU()
  )
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0642019063 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1279293299 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0040469007 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.4275295138 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 6.01107e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 58.525307416915894
Epoch 1/9
	 Logging train Loss: 2.73133e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1250753999 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.00404851 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.4188470244 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.00026e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 58.26738691329956
Epoch 2/9
	 Logging train Loss: 6.5717e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1244890615 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0040602274 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.4167931676 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 4.2581e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 58.55484747886658
Epoch 3/9
	 Logging train Loss: 3.3197e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue ▅▂▁▁█▃▁▁▁▁
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue ▁▁▂▃▃▇▄▆▆█
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue █▄▄▃▃▂▂▂▁▁
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue █▆▆▅▄▄▃▂▂▁
wandb:                                 Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 0.00411
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.1225
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.39694
wandb:                                 Train loss 1e-05
wandb: 
wandb: 🚀 View run hearty-lake-964 at: https://wandb.ai/nreints/ThesisFinal2/runs/fr7oslg5
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_181911-fr7oslg5/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_183208-g51xtjoq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vital-universe-999
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/g51xtjoq
	 Logging test loss: 0.1244197264 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0040626815 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.4152880013 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.9098e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 58.80666995048523
Epoch 4/9
	 Logging train Loss: 4.0053e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1236998215 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0040666088 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.4111434817 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0001003498 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 58.40861129760742
Epoch 5/9
	 Logging train Loss: 6.0344e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1232107058 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0041027018 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.4085478187 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.60573e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 58.71657419204712
Epoch 6/9
	 Logging train Loss: 8.2623e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1231462583 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0040770494 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.40442276 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.3668e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 59.22278380393982
Epoch 7/9
	 Logging train Loss: 9.7304e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1230062321 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.004091063 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.4026479423 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.3984e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 59.57067942619324
Epoch 8/9
	 Logging train Loss: 9.8128e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1226196438 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0040891985 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.4006189406 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.7853e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 60.71932363510132
Epoch 9/9
	 Logging train Loss: 9.646e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1225024313 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0041091195 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.3969377279 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 3.226e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 60.64837336540222
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'rot_mat'_'True'.pth
It took  777.2052803039551  seconds.
----- ITERATION 3/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 86.09451413154602 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 22.130320072174072 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 22.05894374847412 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 22.119619607925415 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 21.770325899124146 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (pre_hidden_lin_layer): Sequential(
    (0): Linear(in_features=3, out_features=96, bias=True)
    (1): ReLU()
    (2): Linear(in_features=96, out_features=96, bias=True)
    (3): ReLU()
  )
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0902137458 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.4944801033 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0032500015 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.5103257298 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 7.53495e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 60.047144174575806
Epoch 1/9
	 Logging train Loss: 4.51456e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.4909643233 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0032046493 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.5006774664 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.71778e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 60.1861252784729
Epoch 2/9
	 Logging train Loss: 2.1797e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.4834828377 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0032014716 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.493667841 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.66631e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 60.13714075088501
Epoch 3/9
	 Logging train Loss: 1.41455e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.4789784849 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0032013922 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.4882954657 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.07504e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 58.2467987537384
Epoch 4/9
	 Logging train Loss: 9.4163e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.4759009778 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0032132161 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.4837905765 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.41225e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 58.25864505767822
Epoch 5/9
	 Logging train Loss: 9.7778e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.4723484814 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0032090012 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.4786779881 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 5.2691e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 58.80067706108093
Epoch 6/9
	 Logging train Loss: 1.09556e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.4679419696 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0032169062 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.4731384814 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.27378e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 58.28279185295105
Epoch 7/9
	 Logging train Loss: 1.18077e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.4653128386 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0032291338 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.4680301845 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.23386e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 58.30832815170288
Epoch 8/9
	 Logging train Loss: 1.31368e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.4614545703 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0032262444 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.4639106989 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 9.336e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 58.33540058135986
Epoch 9/9
	 Logging train Loss: 1.22875e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.4586866498 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue █▃▂▂▂▁▂▃▂▁
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue █▁▁▁▃▂▃▅▅▅
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue █▇▆▅▄▄▃▂▂▁
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue █▇▆▅▄▄▃▂▂▁
wandb:                                 Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 0.00323
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.45869
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.45818
wandb:                                 Train loss 1e-05
wandb: 
wandb: 🚀 View run vital-universe-999 at: https://wandb.ai/nreints/ThesisFinal2/runs/g51xtjoq
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_183208-g51xtjoq/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_184503-wqrd6vs1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run jumping-bee-1033
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/wqrd6vs1
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue █▃▂▁▁▁▁▁▃▁
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue █▁▃▂▃▃▁▁▄▂
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue █▆▅▄▄▃▂▂▁▁
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue ██▇▆▅▃▃▃▂▁
wandb:                                 Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 0.00364
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.25296
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.25276
wandb:                                 Train loss 1e-05
wandb: 
wandb: 🚀 View run jumping-bee-1033 at: https://wandb.ai/nreints/ThesisFinal2/runs/wqrd6vs1
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_184503-wqrd6vs1/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_185806-lf49j6cb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run true-sun-1060
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/lf49j6cb
	 Logging test loss: 0.0032263277 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.4581831098 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.0205e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 58.331156492233276
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'rot_mat'_'True'.pth
It took  775.2149863243103  seconds.
----- ITERATION 4/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 86.1342396736145 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 22.075905561447144 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 21.99977421760559 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 21.975757598876953 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 21.73206353187561 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (pre_hidden_lin_layer): Sequential(
    (0): Linear(in_features=3, out_features=96, bias=True)
    (1): ReLU()
    (2): Linear(in_features=96, out_features=96, bias=True)
    (3): ReLU()
  )
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0751096085 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.2836153209 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0036722398 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.2850744426 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 8.81849e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 60.70990467071533
Epoch 1/9
	 Logging train Loss: 4.48136e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.2755859494 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0036303217 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.2842713594 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.13763e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 59.93333053588867
Epoch 2/9
	 Logging train Loss: 1.33463e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.2710283399 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0036410133 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.2801410556 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 9.4277e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 59.069260597229004
Epoch 3/9
	 Logging train Loss: 7.1915e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.2672480047 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0036370126 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.2744995356 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 6.6761e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 59.14474534988403
Epoch 4/9
	 Logging train Loss: 5.6541e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.2638073564 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0036398654 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.2698329985 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 5.7704e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 59.08905053138733
Epoch 5/9
	 Logging train Loss: 8.1905e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.2600921988 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0036398089 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.2640126348 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 3.7098e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 58.91682481765747
Epoch 6/9
	 Logging train Loss: 9.0271e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.2567131817 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.003630565 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.2604293227 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.5957e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 59.14330792427063
Epoch 7/9
	 Logging train Loss: 1.11945e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.2549682558 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0036294239 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.25996539 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 9.085e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 59.67023587226868
Epoch 8/9
	 Logging train Loss: 1.21543e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.2525443137 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.003649343 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.2558120489 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.42003e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 59.55706024169922
Epoch 9/9
	 Logging train Loss: 9.8647e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.252959162 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0036362088 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.2527604103 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 7.164e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 59.39538764953613
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'rot_mat'_'True'.pth
It took  783.1913342475891  seconds.
----- ITERATION 5/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 87.08944463729858 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 22.045255661010742 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 21.990427255630493 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 22.021606922149658 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 21.8597993850708 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (pre_hidden_lin_layer): Sequential(
    (0): Linear(in_features=3, out_features=96, bias=True)
    (1): ReLU()
    (2): Linear(in_features=96, out_features=96, bias=True)
    (3): ReLU()
  )
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.091067791 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.4736776054 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0042256722 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.2643454969 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 7.16739e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 59.3819215297699
Epoch 1/9
	 Logging train Loss: 3.78399e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.467241019 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0042286869 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.2632734179 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.38854e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 60.1672568321228
Epoch 2/9
	 Logging train Loss: 1.80395e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.459402293 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0042224242 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.261744976 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.68586e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 60.10326147079468
Epoch 3/9
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue █▃▂▂▁▂▁▁▁▁
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue ▁▂▁▃▄▅▆▆██
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue █▇▆▅▄▄▃▂▁▁
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue ██▇▇▅▅▃▂▂▁
wandb:                                 Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 0.00427
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.41913
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.24304
wandb:                                 Train loss 1e-05
wandb: 
wandb: 🚀 View run true-sun-1060 at: https://wandb.ai/nreints/ThesisFinal2/runs/lf49j6cb
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_185806-lf49j6cb/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_191107-pmnc07xz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fine-wind-1089
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/pmnc07xz
	 Logging train Loss: 1.17657e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.4529946446 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0042344444 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.2600062788 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 8.884e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 59.37963938713074
Epoch 4/9
	 Logging train Loss: 1.12405e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.4444904625 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0042399694 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.256090194 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 5.9302e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 58.74435639381409
Epoch 5/9
	 Logging train Loss: 1.05631e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.4387961626 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0042508212 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.2543951869 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 7.7928e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 58.58413529396057
Epoch 6/9
	 Logging train Loss: 1.19375e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.4326180518 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0042588641 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.2498033792 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 4.5115e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 58.45974373817444
Epoch 7/9
	 Logging train Loss: 1.3927e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.4278385043 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0042581954 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.2473119646 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 3.2726e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 58.75368332862854
Epoch 8/9
	 Logging train Loss: 1.18801e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.4212500751 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0042706067 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.2450010478 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.1428e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 58.80193781852722
Epoch 9/9
	 Logging train Loss: 1.10442e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.4191318452 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0042683692 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.243040055 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 4.5095e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 59.75384068489075
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'rot_mat'_'True'.pth
It took  780.0924170017242  seconds.
----- ITERATION 6/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 87.2321469783783 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 22.054185152053833 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 22.047016143798828 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 22.124874353408813 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 22.03592801094055 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (pre_hidden_lin_layer): Sequential(
    (0): Linear(in_features=3, out_features=96, bias=True)
    (1): ReLU()
    (2): Linear(in_features=96, out_features=96, bias=True)
    (3): ReLU()
  )
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0602288358 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.3176980317 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0042518089 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.2937889099 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 7.47591e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 58.86509728431702
Epoch 1/9
	 Logging train Loss: 3.24572e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.3116773069 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0041929502 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.2744559646 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.51117e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 58.904021978378296
Epoch 2/9
	 Logging train Loss: 1.14028e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.307510078 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0041608508 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.275323391 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 9.0669e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 58.54170751571655
Epoch 3/9
	 Logging train Loss: 8.4284e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.3036048412 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0041423412 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.2734651268 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 7.861e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 58.282026052474976
Epoch 4/9
	 Logging train Loss: 9.2748e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.295432955 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.004143775 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.2661446333 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 7.4566e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 58.80509805679321
Epoch 5/9
	 Logging train Loss: 9.2139e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.2891872227 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0041269925 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.2597740591 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.7795e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 59.85911297798157
Epoch 6/9
	 Logging train Loss: 1.10094e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.2790355086 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0041201818 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.2500132322 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 6.8075e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 59.515592098236084
Epoch 7/9
	 Logging train Loss: 1.3044e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.2659194469 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0041129929 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.2374342084 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.20212e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 59.559590101242065
Epoch 8/9
	 Logging train Loss: 1.21347e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.2598547637 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0040838034 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.2336307466 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 9.395e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 57.62408447265625
Epoch 9/9
	 Logging train Loss: 9.7128e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue █▂▂▂▂▁▂▂▁▆
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue █▆▅▄▄▃▃▃▂▁
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue █▇▇▆▆▅▄▂▂▁
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue █▆▆▆▅▄▃▂▁▁
wandb:                                 Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 6e-05
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 0.00407
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.25428
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.23122
wandb:                                 Train loss 1e-05
wandb: 
wandb: 🚀 View run fine-wind-1089 at: https://wandb.ai/nreints/ThesisFinal2/runs/pmnc07xz
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_191107-pmnc07xz/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_192403-nuuad5ah
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wobbly-firefly-1108
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/nuuad5ah
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue █▃▂▂▁▅▁▇▄▁
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue ▇████▇▆▅▃▁
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue █▇▇▇▅▄▃▂▂▁
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue ▇██▇▅▃▂▁▁▁
wandb:                                 Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 0.00543
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.34406
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.18086
wandb:                                 Train loss 1e-05
wandb: 
wandb: 🚀 View run wobbly-firefly-1108 at: https://wandb.ai/nreints/ThesisFinal2/runs/nuuad5ah
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_192403-nuuad5ah/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_193657-e1k8ros4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run smooth-moon-1118
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/e1k8ros4
	 Logging test loss: 0.2542754114 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0040684328 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.2312192321 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 5.63408e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 57.70415282249451
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'rot_mat'_'True'.pth
It took  776.4448580741882  seconds.
----- ITERATION 7/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 87.1921591758728 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 21.959493160247803 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 21.990466117858887 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 21.953999280929565 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 21.884464740753174 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (pre_hidden_lin_layer): Sequential(
    (0): Linear(in_features=3, out_features=96, bias=True)
    (1): ReLU()
    (2): Linear(in_features=96, out_features=96, bias=True)
    (3): ReLU()
  )
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.058402501 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.3832262158 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0056311376 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.1914716661 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 6.39247e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 58.589754819869995
Epoch 1/9
	 Logging train Loss: 3.66265e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.3785092235 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0056621516 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.1923266798 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.05271e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 57.957488775253296
Epoch 2/9
	 Logging train Loss: 1.4257e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.3780374825 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0056657083 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.1927390546 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 9.6525e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 58.199453592300415
Epoch 3/9
	 Logging train Loss: 7.7473e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.3748474419 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0056548659 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.1916221827 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 9.144e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 58.27451825141907
Epoch 4/9
	 Logging train Loss: 7.78e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.3677489161 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.005650477 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.1880195141 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 4.58e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 58.144078731536865
Epoch 5/9
	 Logging train Loss: 9.503e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.360232234 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0056323009 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.1846158355 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 3.5007e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 57.93380689620972
Epoch 6/9
	 Logging train Loss: 1.09995e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.3532496989 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0056085866 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.182904169 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.9604e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 58.06675982475281
Epoch 7/9
	 Logging train Loss: 1.01553e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.3497674763 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0055651404 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.1816892773 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 5.38913e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 59.824230670928955
Epoch 8/9
	 Logging train Loss: 1.11123e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.3484950066 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0054993113 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.1814135462 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.61848e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 59.85243773460388
Epoch 9/9
	 Logging train Loss: 1.13249e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.3440642059 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0054292581 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.1808554828 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 5.763e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 59.947367668151855
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'rot_mat'_'True'.pth
It took  774.2701640129089  seconds.
----- ITERATION 8/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 85.75229549407959 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 21.861522912979126 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 21.81848645210266 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 21.847163915634155 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 21.776816368103027 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (pre_hidden_lin_layer): Sequential(
    (0): Linear(in_features=3, out_features=96, bias=True)
    (1): ReLU()
    (2): Linear(in_features=96, out_features=96, bias=True)
    (3): ReLU()
  )
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0598125234 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.2759912312 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0044602784 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.3756029904 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 6.54139e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 60.05750370025635
Epoch 1/9
	 Logging train Loss: 3.39016e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.2747669816 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0044571548 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.3742629886 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.50807e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 60.34885835647583
Epoch 2/9
	 Logging train Loss: 8.7354e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.2759002149 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0044489647 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.3741886616 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue █▃▁▁▁▁▆▁▁▃
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue ██▇▇▆▆▅▃▁▂
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue ████▇▆▄▄▂▁
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue ███▇▆▅▄▃▂▁
wandb:                                 Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 2e-05
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 0.00438
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.25422
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.34517
wandb:                                 Train loss 1e-05
wandb: 
wandb: 🚀 View run smooth-moon-1118 at: https://wandb.ai/nreints/ThesisFinal2/runs/e1k8ros4
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_193657-e1k8ros4/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_194953-vfxseehr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run easy-sea-1122
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/vfxseehr
	 Logging test loss: 5.0872e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 59.54940152168274
Epoch 3/9
	 Logging train Loss: 3.8614e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.2754579484 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0044448613 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.3712307513 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.7947e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 59.48000931739807
Epoch 4/9
	 Logging train Loss: 4.8396e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.2738569379 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0044400753 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.3682387173 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.7546e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 58.35283303260803
Epoch 5/9
	 Logging train Loss: 7.1498e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.2689576447 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0044335239 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.3625817597 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 4.9654e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 58.3601758480072
Epoch 6/9
	 Logging train Loss: 9.7621e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.2648203969 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0044212267 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.3567583859 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 4.76341e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 58.26646280288696
Epoch 7/9
	 Logging train Loss: 1.06575e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.262472719 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0043917461 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.3539525568 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 5.0287e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 58.59436583518982
Epoch 8/9
	 Logging train Loss: 9.5103e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.2564456463 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0043704482 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.3495031595 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.1834e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 58.28232526779175
Epoch 9/9
	 Logging train Loss: 1.12446e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.2542156279 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0043773744 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.345168978 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.81251e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 58.6892786026001
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'rot_mat'_'True'.pth
It took  775.5197653770447  seconds.
----- ITERATION 9/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 85.39671277999878 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 21.7928626537323 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 21.763594388961792 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 21.754542589187622 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 21.73381018638611 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (pre_hidden_lin_layer): Sequential(
    (0): Linear(in_features=3, out_features=96, bias=True)
    (1): ReLU()
    (2): Linear(in_features=96, out_features=96, bias=True)
    (3): ReLU()
  )
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0548217818 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.5074925423 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0034128644 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.5155875087 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 6.33827e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 59.470717906951904
Epoch 1/9
	 Logging train Loss: 3.5373e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.4999389946 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0034206938 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.5057967305 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.08228e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 59.80395269393921
Epoch 2/9
	 Logging train Loss: 1.39959e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.4949807525 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.003426204 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.4982364178 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 9.4073e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 60.08454895019531
Epoch 3/9
	 Logging train Loss: 9.5588e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.4887066483 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0034238298 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.4845820367 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 6.1295e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 59.32374858856201
Epoch 4/9
	 Logging train Loss: 9.7357e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.4830736518 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0034286249 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.4698687792 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 3.7436e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 58.7740535736084
Epoch 5/9
	 Logging train Loss: 9.4519e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.4786970317 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0034316089 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.4642850161 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.21512e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 58.32610082626343
Epoch 6/9
	 Logging train Loss: 1.16816e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.471953243 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0034580121 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.4576896429 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.94245e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 58.22801756858826
Epoch 7/9
	 Logging train Loss: 1.05737e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.4685060382 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.003433394 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.4530752897 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.1352e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 58.72964000701904
Epoch 8/9
	 Logging train Loss: 1.10275e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.4655946195 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0034192733 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.4470808804 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 5.5979e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue █▃▂▁▁▃▃▁▁▂
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue ▁▂▃▃▃▄█▄▂▂
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue █▇▆▅▄▄▃▂▂▁
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue █▇▆▅▄▃▂▂▁▁
wandb:                                 Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 1e-05
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 0.00342
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.46127
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.44418
wandb:                                 Train loss 1e-05
wandb: 
wandb: 🚀 View run easy-sea-1122 at: https://wandb.ai/nreints/ThesisFinal2/runs/vfxseehr
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_194953-vfxseehr/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_200247-58uwupc0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eternal-water-1124
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/58uwupc0
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue ▃▂▁▁▁▁▁▂█▁
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue ▇▇███▇▆▅█▁
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue █▇▅▃▃▂▂▁▁▂
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue █▇▅▄▃▃▂▁▁▁
wandb:                                 Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 0.00377
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.31775
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.46962
wandb:                                 Train loss 1e-05
wandb: 
wandb: 🚀 View run eternal-water-1124 at: https://wandb.ai/nreints/ThesisFinal2/runs/58uwupc0
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_200247-58uwupc0/logs
		--> Epoch time; 58.531639099121094
Epoch 9/9
	 Logging train Loss: 9.6537e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.4612655938 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.003417088 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.4441834092 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 6.8689e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 58.445290327072144
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'rot_mat'_'True'.pth
It took  774.152423620224  seconds.
----- ITERATION 10/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 86.82767248153687 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 21.971937656402588 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 21.937735319137573 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 21.958682537078857 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 21.82290267944336 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (pre_hidden_lin_layer): Sequential(
    (0): Linear(in_features=3, out_features=96, bias=True)
    (1): ReLU()
    (2): Linear(in_features=96, out_features=96, bias=True)
    (3): ReLU()
  )
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0965572819 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.34921363 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0039236955 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.5160627365 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 7.02102e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 58.417378187179565
Epoch 1/9
	 Logging train Loss: 4.05249e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.3434095681 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0039124414 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.5103505254 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.26697e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 58.67458915710449
Epoch 2/9
	 Logging train Loss: 1.64217e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.3328562081 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0039299694 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.4976211786 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.0825e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 58.932132720947266
Epoch 3/9
	 Logging train Loss: 8.7815e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.3266739547 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.003931467 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.4867831469 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 6.3661e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 58.808884382247925
Epoch 4/9
	 Logging train Loss: 5.5655e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.3262401819 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.003935338 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.4799384773 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 3.6479e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 58.817983627319336
Epoch 5/9
	 Logging train Loss: 5.8219e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.3201540112 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0039191772 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.4808330834 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.9569e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 58.745713233947754
Epoch 6/9
	 Logging train Loss: 9.1154e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.3170415163 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0038930979 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.4760504663 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.9138e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 58.58598303794861
Epoch 7/9
	 Logging train Loss: 1.11913e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.3156245351 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0038553581 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.4721610248 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 4.52207e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 59.288196325302124
Epoch 8/9
	 Logging train Loss: 1.1978e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.3144184649 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0039304062 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.4692963362 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0002910183 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 58.87971639633179
Epoch 9/9
	 Logging train Loss: 1.18711e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.3177530766 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0037735722 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.4696157575 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.655e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 58.78068017959595
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'rot_mat'_'True'.pth
It took  773.1060693264008  seconds.

JOB STATISTICS
==============
Job ID: 3037987
Array Job ID: 3037875_33
Cluster: snellius
User/Group: nreints/nreints
State: COMPLETED (exit code 0)
Nodes: 1
Cores per node: 18
CPU Utilized: 02:18:09
CPU Efficiency: 5.91% of 1-14:57:00 core-walltime
Job Wall-clock time: 02:09:50
Memory Utilized: 8.62 GB
Memory Efficiency: 0.00% of 0.00 MB
