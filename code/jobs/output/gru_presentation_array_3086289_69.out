wandb: Currently logged in as: nreints. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_211346-tmo31pdn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run devoted-elevator-462
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/tmo31pdn
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gTrue â–ˆâ–‚â–â–â–â–â–‚â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gTrue â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gTrue â–ˆâ–‚â–â–‚â–â–â–‚â–‚â–â–
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gTrue â–ˆâ–‚â–â–‚â–â–â–‚â–‚â–â–
wandb:                                   Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gTrue 0.0
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gTrue 0.0
wandb:                                   Train loss 0.0
wandb: 
wandb: ðŸš€ View run devoted-elevator-462 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/tmo31pdn
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_211346-tmo31pdn/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_212032-zq6374eo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run decent-terrain-466
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/zq6374eo
Training on dataset: data_t(5,20)_r(5,20)_combi_pNone_gTrue
Testing on 4 datasets: ['data_t(5,20)_r(5,20)_tennis_pNone_gTrue', 'data_t(5,20)_r(5,20)_combi_pNone_gTrue', 'data_t(5,20)_r(5,20)_full_pNone_gTrue', 'data_t(5,20)_r(5,20)_semi_pNone_gTrue']
Focussing on identity: False
Using extra input: False
Using fr-fr as reference point.
----- ITERATION 1/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gTrue took 50.23013138771057 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gTrue took 12.830383777618408 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gTrue took 12.904489278793335 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gTrue took 12.071741104125977 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gTrue took 12.330933332443237 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: log_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0006327863 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 7.16615e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 4.70537e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 2.60734e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 6.50271e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 30.616890907287598
Epoch 1/9
	 Logging train Loss: 1.69077e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 1.0149e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 5.9894e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 2.372e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 9.4148e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 29.15084719657898
Epoch 2/9
	 Logging train Loss: 5.7945e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 7.9151e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 4.4731e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 1.3888e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 7.4165e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 29.131227731704712
Epoch 3/9
	 Logging train Loss: 5.1827e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 9.8977e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 5.2641e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 9.217e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 8.9212e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 29.07047390937805
Epoch 4/9
	 Logging train Loss: 4.8711e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 6.5696e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 3.4284e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 5.376e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 6.1068e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 28.915377140045166
Epoch 5/9
	 Logging train Loss: 4.5495e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 6.5743e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 3.3516e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 3.794e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 6.0594e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 29.095932483673096
Epoch 6/9
	 Logging train Loss: 4.0098e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 1.39814e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 7.0857e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 6.041e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 1.23509e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 28.929211616516113
Epoch 7/9
	 Logging train Loss: 3.9472e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 1.04866e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 5.248e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 4.003e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 9.2857e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 29.016594648361206
Epoch 8/9
	 Logging train Loss: 3.5817e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 7.5481e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 3.7914e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 3.114e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 6.7622e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 28.785272121429443
Epoch 9/9
	 Logging train Loss: 2.9993e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 4.4427e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 2.2413e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 2.019e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 4.0708e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 28.91606044769287
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gTrue/'log_quat_1'_'False'.pth
It took  406.9718668460846  seconds.
----- ITERATION 2/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gTrue took 44.748074531555176 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gTrue took 11.982057809829712 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gTrue took 11.630502223968506 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gTrue took 11.185407638549805 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gTrue took 11.15448546409607 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: log_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.000524631 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 5.09829e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 3.07343e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 1.44321e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 4.75053e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 29.525235176086426
Epoch 1/9
	 Logging train Loss: 1.02834e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 9.1547e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 5.3416e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 2.0525e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 8.9888e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 29.306194305419922
Epoch 2/9
	 Logging train Loss: 5.3986e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 1.01626e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 5.4902e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 1.2599e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 9.9374e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 29.354934692382812
Epoch 3/9
	 Logging train Loss: 5.3299e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 8.423e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 4.3781e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 7.67e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gTrue â–ˆâ–‚â–‚â–‚â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gTrue â–ˆâ–‚â–‚â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gTrue â–ˆâ–‚â–‚â–‚â–â–â–â–â–â–
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gTrue â–ˆâ–‚â–‚â–‚â–â–â–â–â–â–
wandb:                                   Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gTrue 0.0
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gTrue 0.0
wandb:                                   Train loss 0.0
wandb: 
wandb: ðŸš€ View run decent-terrain-466 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/zq6374eo
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_212032-zq6374eo/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_212712-n9muqne5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run classic-flower-476
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/n9muqne5
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gTrue â–ˆâ–‚â–‚â–‚â–ƒâ–‚â–â–â–â–‚
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gTrue â–ˆâ–‚â–‚â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gTrue â–ˆâ–‚â–‚â–‚â–ƒâ–‚â–â–â–â–‚
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gTrue â–ˆâ–‚â–‚â–‚â–ƒâ–‚â–â–â–â–‚
wandb:                                   Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gTrue 1e-05
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gTrue 1e-05
wandb:                                   Train loss 0.0
wandb: 
wandb: ðŸš€ View run classic-flower-476 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/n9muqne5
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_212712-n9muqne5/logs
	 Logging test loss: 8.2108e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 29.15398383140564
Epoch 4/9
	 Logging train Loss: 4.8604e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 6.1119e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 3.1363e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 4.55e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 6.033e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 29.327959060668945
Epoch 5/9
	 Logging train Loss: 4.546e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 5.8944e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 2.9653e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 3.183e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 5.8585e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 29.351457118988037
Epoch 6/9
	 Logging train Loss: 4.1823e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 5.9203e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 2.9014e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 2.732e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 5.7779e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 29.339398860931396
Epoch 7/9
	 Logging train Loss: 3.9567e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 5.1659e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 2.5742e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 2.354e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 5.0391e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 29.160631895065308
Epoch 8/9
	 Logging train Loss: 3.3127e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 4.2731e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 2.1157e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 1.976e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 4.1914e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 29.243278741836548
Epoch 9/9
	 Logging train Loss: 3.159e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 4.4693e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 2.2423e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 2.507e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 4.383e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 29.22254753112793
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gTrue/'log_quat_1'_'False'.pth
It took  399.0950355529785  seconds.
----- ITERATION 3/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gTrue took 44.55589985847473 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gTrue took 11.14246153831482 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gTrue took 11.516047716140747 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gTrue took 11.171030044555664 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gTrue took 11.098455667495728 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: log_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0004347555 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 4.16498e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 2.39636e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 9.6772e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 3.98361e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 29.54154086112976
Epoch 1/9
	 Logging train Loss: 9.1696e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 8.4861e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 4.8927e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 1.5324e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 8.698e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 29.62373685836792
Epoch 2/9
	 Logging train Loss: 5.992e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 7.3604e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 4.0306e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 9.012e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 7.5499e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 29.462597846984863
Epoch 3/9
	 Logging train Loss: 5.3539e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 1.01581e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 5.3352e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 6.638e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 1.02434e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 29.505359411239624
Epoch 4/9
	 Logging train Loss: 4.7339e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 1.38939e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 7.1715e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 6.066e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 1.34466e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 29.403250694274902
Epoch 5/9
	 Logging train Loss: 4.6018e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 1.06294e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 5.4549e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 4.232e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 1.06531e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 29.53149437904358
Epoch 6/9
	 Logging train Loss: 4.1149e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 5.6565e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 2.8605e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 2.528e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 5.6818e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 29.528326511383057
Epoch 7/9
	 Logging train Loss: 3.8383e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 4.8713e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 2.4468e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 2.183e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 4.9323e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 29.58394742012024
Epoch 8/9
	 Logging train Loss: 3.2684e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 3.853e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 1.9834e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 2.798e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 3.8753e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 29.674132108688354
Epoch 9/9
	 Logging train Loss: 2.9897e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 9.2816e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 4.6437e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 3.581e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 8.9667e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 29.41351556777954
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gTrue/'log_quat_1'_'False'.pth
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_213350-t7hmja3q
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lyric-music-484
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/t7hmja3q
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gTrue â–ˆâ–‚â–‚â–â–â–‚â–‚â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gTrue â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gTrue â–ˆâ–ƒâ–‚â–â–â–ƒâ–‚â–â–‚â–
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gTrue â–ˆâ–ƒâ–‚â–â–â–ƒâ–‚â–â–‚â–
wandb:                                   Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gTrue 0.0
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gTrue 0.0
wandb:                                   Train loss 0.0
wandb: 
wandb: ðŸš€ View run lyric-music-484 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/t7hmja3q
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_213350-t7hmja3q/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_214024-yq925pfg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run apricot-tree-494
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/yq925pfg
It took  398.0098466873169  seconds.
----- ITERATION 4/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gTrue took 44.904868841171265 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gTrue took 11.233483791351318 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gTrue took 11.211969375610352 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gTrue took 11.19797158241272 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gTrue took 11.184660196304321 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: log_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0004871903 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 4.92315e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 3.81522e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 2.45688e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 4.80373e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 29.513139009475708
Epoch 1/9
	 Logging train Loss: 1.45965e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 1.65028e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 1.00086e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 2.8821e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 1.59809e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 28.95820164680481
Epoch 2/9
	 Logging train Loss: 6.7731e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 1.10232e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 6.6607e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 1.7748e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 1.07096e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 29.703612327575684
Epoch 3/9
	 Logging train Loss: 5.9589e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 6.6092e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 4.0356e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 1.153e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 6.8093e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 29.649040460586548
Epoch 4/9
	 Logging train Loss: 5.4468e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 7.3867e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 4.2736e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 8.081e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 7.4087e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 29.430424451828003
Epoch 5/9
	 Logging train Loss: 4.7718e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 1.53358e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 8.2883e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 7.948e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 1.43491e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 29.16936755180359
Epoch 6/9
	 Logging train Loss: 4.4911e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 1.12226e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 6.2343e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 5.177e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 1.07665e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 29.428967237472534
Epoch 7/9
	 Logging train Loss: 3.7217e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 6.5212e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 3.5492e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 3.165e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 6.4607e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 29.29198455810547
Epoch 8/9
	 Logging train Loss: 3.6415e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 9.1618e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 5.0351e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 3.653e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 8.736e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 29.338837146759033
Epoch 9/9
	 Logging train Loss: 3.0577e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 4.7316e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 2.6163e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 2.234e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 4.7573e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 29.506797552108765
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gTrue/'log_quat_1'_'False'.pth
It took  394.94959926605225  seconds.
----- ITERATION 5/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gTrue took 44.694005489349365 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gTrue took 11.17548680305481 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gTrue took 11.157363176345825 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gTrue took 11.21691346168518 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gTrue took 11.16475534439087 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: log_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0008760008 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 9.11815e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 6.27233e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 3.78896e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 8.894e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 29.73944878578186
Epoch 1/9
	 Logging train Loss: 2.56447e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 1.51745e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 8.9165e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 3.2757e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 1.49773e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 29.05019783973694
Epoch 2/9
	 Logging train Loss: 6.7057e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 8.0368e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 4.706e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 1.6464e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 8.1486e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 29.440062284469604
Epoch 3/9
	 Logging train Loss: 5.3817e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 9.1603e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 4.8887e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 1.0416e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 9.1788e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 29.349501609802246
Epoch 4/9
	 Logging train Loss: 5.1519e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 7.0127e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 3.6356e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gTrue â–ˆâ–‚â–â–â–â–‚â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gTrue â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gTrue â–ˆâ–‚â–â–â–â–‚â–â–â–â–
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gTrue â–ˆâ–‚â–â–â–â–‚â–â–â–â–
wandb:                                   Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gTrue 0.0
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gTrue 0.0
wandb:                                   Train loss 0.0
wandb: 
wandb: ðŸš€ View run apricot-tree-494 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/yq925pfg
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_214024-yq925pfg/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_214700-vz68yjll
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run resilient-violet-503
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/vz68yjll
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gTrue â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gTrue â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gTrue â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gTrue â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb:                                   Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gTrue 1e-05
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gTrue 1e-05
wandb:                                   Train loss 0.0
wandb: 
wandb: ðŸš€ View run resilient-violet-503 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/vz68yjll
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_214700-vz68yjll/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_215339-b1r9rdzu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fancy-glitter-512
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/b1r9rdzu
	 Logging test loss: 5.929e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 7.0611e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 29.355578184127808
Epoch 5/9
	 Logging train Loss: 4.6644e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 1.65021e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 7.8289e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 6.755e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 1.56453e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 29.616778135299683
Epoch 6/9
	 Logging train Loss: 4.5448e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 5.3239e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 2.6727e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 2.461e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 5.4296e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 29.511120319366455
Epoch 7/9
	 Logging train Loss: 4.1466e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 8.07e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 3.8934e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 3.15e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 7.8827e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 29.15511679649353
Epoch 8/9
	 Logging train Loss: 3.8815e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 4.6471e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 2.3343e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 2.022e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 4.717e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 29.07105803489685
Epoch 9/9
	 Logging train Loss: 3.5415e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 3.9091e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 1.9739e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 2.052e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 3.983e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 29.28084707260132
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gTrue/'log_quat_1'_'False'.pth
It took  395.0655155181885  seconds.
----- ITERATION 6/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gTrue took 44.77372932434082 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gTrue took 11.1706063747406 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gTrue took 11.15979814529419 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gTrue took 11.177875518798828 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gTrue took 11.135851621627808 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: log_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0011891343 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 9.88934e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 6.45434e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 3.79112e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 8.93134e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 29.210418939590454
Epoch 1/9
	 Logging train Loss: 2.67785e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 1.38236e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 8.3164e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 3.7936e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 1.27394e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 29.580402612686157
Epoch 2/9
	 Logging train Loss: 6.239e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 9.9848e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 5.365e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 1.6682e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 8.9041e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 29.627515077590942
Epoch 3/9
	 Logging train Loss: 5.1076e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 9.2086e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 4.7477e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 1.0825e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 8.1546e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 29.477410078048706
Epoch 4/9
	 Logging train Loss: 4.7437e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 7.0028e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 3.5141e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 6.628e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 6.2566e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 29.35170817375183
Epoch 5/9
	 Logging train Loss: 4.6065e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 7.0335e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 3.4053e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 4.533e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 6.2345e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 29.51041054725647
Epoch 6/9
	 Logging train Loss: 4.351e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 6.5498e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 3.12e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 3.32e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 5.7849e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 29.509843587875366
Epoch 7/9
	 Logging train Loss: 3.8335e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 7.4942e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 3.5596e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 2.937e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 6.6047e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 29.697614431381226
Epoch 8/9
	 Logging train Loss: 3.7981e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 7.8279e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 3.6665e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 2.932e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 6.7812e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 29.486312866210938
Epoch 9/9
	 Logging train Loss: 3.5416e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 5.7946e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 2.7731e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 2.298e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 5.083e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 29.50637149810791
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gTrue/'log_quat_1'_'False'.pth
It took  399.19033455848694  seconds.
----- ITERATION 7/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gTrue took 44.90150189399719 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gTrue took 11.165924787521362 seconds.
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gTrue â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gTrue â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gTrue â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gTrue â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb:                                   Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gTrue 1e-05
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gTrue 1e-05
wandb:                                   Train loss 0.0
wandb: 
wandb: ðŸš€ View run fancy-glitter-512 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/b1r9rdzu
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_215339-b1r9rdzu/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_220015-j91v5aod
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sweet-vortex-522
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/j91v5aod
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gTrue took 11.137888431549072 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gTrue took 11.222611904144287 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gTrue took 11.24280858039856 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: log_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0006618472 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 7.93066e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 4.55735e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 1.10738e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 7.3838e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 29.09314203262329
Epoch 1/9
	 Logging train Loss: 1.56723e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 1.10581e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 6.2153e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 1.4459e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 1.0461e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 29.60342574119568
Epoch 2/9
	 Logging train Loss: 4.5897e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 7.4474e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 4.0619e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 7.655e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 7.1066e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 29.3419189453125
Epoch 3/9
	 Logging train Loss: 4.4722e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 8.05e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 4.3361e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 5.562e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 7.6778e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 29.209740161895752
Epoch 4/9
	 Logging train Loss: 4.5111e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 1.06531e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 5.6979e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 4.956e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 1.00094e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 29.178056955337524
Epoch 5/9
	 Logging train Loss: 4.7205e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 7.4599e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 3.9336e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 3.367e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 7.0712e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 29.586235761642456
Epoch 6/9
	 Logging train Loss: 4.1722e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 5.5466e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 2.9132e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 2.742e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 5.2475e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 29.507683277130127
Epoch 7/9
	 Logging train Loss: 4.1312e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 8.6634e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 4.5846e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 3.277e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 8.176e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 29.328916549682617
Epoch 8/9
	 Logging train Loss: 3.4325e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 9.7162e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 5.2567e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 4.315e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 9.12e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 29.41829514503479
Epoch 9/9
	 Logging train Loss: 3.2142e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 8.85e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 4.7654e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 3.445e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 8.2813e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 29.51755142211914
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gTrue/'log_quat_1'_'False'.pth
It took  396.02106642723083  seconds.
----- ITERATION 8/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gTrue took 45.3805513381958 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gTrue took 11.172155380249023 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gTrue took 11.167322874069214 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gTrue took 11.263922452926636 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gTrue took 11.173016786575317 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: log_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0005391166 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 6.06071e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 3.97497e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 1.92925e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 5.82253e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 29.221550464630127
Epoch 1/9
	 Logging train Loss: 1.24043e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 1.89987e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 1.01237e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 1.9953e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 1.73971e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 29.491597414016724
Epoch 2/9
	 Logging train Loss: 4.9368e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 7.3941e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 4.1677e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 9.794e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 7.2186e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 29.247933387756348
Epoch 3/9
	 Logging train Loss: 4.7261e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 1.32799e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 6.8428e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 8.006e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 1.24415e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 29.388802528381348
Epoch 4/9
	 Logging train Loss: 4.4215e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 6.7176e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 3.5311e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 3.807e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 6.5159e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 29.274142742156982
Epoch 5/9
	 Logging train Loss: 4.3265e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 1.69433e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gTrue â–ˆâ–‚â–â–‚â–â–‚â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gTrue â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gTrue â–ˆâ–ƒâ–â–‚â–â–‚â–â–â–â–
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gTrue â–ˆâ–ƒâ–â–‚â–â–‚â–â–â–â–
wandb:                                   Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gTrue 0.0
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gTrue 1e-05
wandb:                                   Train loss 0.0
wandb: 
wandb: ðŸš€ View run sweet-vortex-522 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/j91v5aod
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_220015-j91v5aod/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_220653-fc0b7k8m
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run radiant-water-528
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/fc0b7k8m
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gTrue â–ˆâ–‚â–â–â–‚â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gTrue â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gTrue â–ˆâ–‚â–â–â–ƒâ–â–â–â–â–
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gTrue â–ˆâ–‚â–â–â–ƒâ–‚â–â–â–â–
wandb:                                   Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gTrue 1e-05
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gTrue 1e-05
wandb:                                   Train loss 0.0
wandb: 
wandb: ðŸš€ View run radiant-water-528 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/fc0b7k8m
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_220653-fc0b7k8m/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_221329-i0l2f5uv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run prime-durian-538
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/i0l2f5uv
	 Logging test loss: 8.4587e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 6.039e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 1.58445e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 29.513227701187134
Epoch 6/9
	 Logging train Loss: 4.0102e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 6.6147e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 3.3547e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 2.529e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 6.3256e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 29.58735680580139
Epoch 7/9
	 Logging train Loss: 3.525e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 7.771e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 3.9117e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 2.921e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 7.2667e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 29.517380714416504
Epoch 8/9
	 Logging train Loss: 3.3501e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 6.4023e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 3.249e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 2.69e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 6.1117e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 29.41599726676941
Epoch 9/9
	 Logging train Loss: 2.9246e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 5.3533e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 2.7158e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 2.466e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 4.9998e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 29.444932222366333
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gTrue/'log_quat_1'_'False'.pth
It took  398.26157116889954  seconds.
----- ITERATION 9/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gTrue took 45.42959403991699 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gTrue took 11.289423704147339 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gTrue took 11.151903867721558 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gTrue took 11.286095142364502 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gTrue took 11.365151643753052 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: log_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0004914499 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 4.35503e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 3.19373e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 1.89159e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 4.16448e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 29.123189687728882
Epoch 1/9
	 Logging train Loss: 1.14654e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 8.7768e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 5.3189e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 1.7616e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 8.7174e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 29.61721181869507
Epoch 2/9
	 Logging train Loss: 5.6569e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 7.1082e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 4.1603e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 1.0624e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 7.1605e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 29.23356342315674
Epoch 3/9
	 Logging train Loss: 4.756e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 6.3089e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 3.5524e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 6.425e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 6.4355e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 29.434752702713013
Epoch 4/9
	 Logging train Loss: 5.0629e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 1.59532e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 8.1465e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 7.095e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 1.51806e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 29.260679006576538
Epoch 5/9
	 Logging train Loss: 4.2747e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 7.3233e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 3.8478e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 3.603e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 7.192e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 29.42872714996338
Epoch 6/9
	 Logging train Loss: 4.284e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 5.2702e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 2.8178e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 2.576e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 5.3884e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 29.21277093887329
Epoch 7/9
	 Logging train Loss: 3.7235e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 4.4604e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 2.379e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 2.143e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 4.5575e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 29.44823169708252
Epoch 8/9
	 Logging train Loss: 3.4131e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 5.5212e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 2.8865e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 2.474e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 5.519e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 29.396390199661255
Epoch 9/9
	 Logging train Loss: 2.9233e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 5.7823e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 3.0261e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 2.594e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 5.683e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 29.45731472969055
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gTrue/'log_quat_1'_'False'.pth
It took  396.38179087638855  seconds.
----- ITERATION 10/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gTrue took 45.516284227371216 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gTrue took 11.29361367225647 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gTrue took 11.153943538665771 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gTrue took 11.306458950042725 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gTrue took 11.266981363296509 seconds.
-- Finished Test Dataloader(s) --
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gTrue â–ˆâ–‚â–‚â–‚â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gTrue â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gTrue â–ˆâ–‚â–‚â–‚â–‚â–â–â–â–â–
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gTrue â–ˆâ–‚â–‚â–‚â–‚â–â–â–â–â–
wandb:                                   Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gTrue 0.0
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gTrue 0.0
wandb:                                   Train loss 0.0
wandb: 
wandb: ðŸš€ View run prime-durian-538 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/i0l2f5uv
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_221329-i0l2f5uv/logs
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: log_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0004926283 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 5.26963e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 3.33631e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 1.47909e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 5.16286e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 29.421401739120483
Epoch 1/9
	 Logging train Loss: 1.1909e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 8.8041e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 5.1129e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 1.5519e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 9.2518e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 29.463287353515625
Epoch 2/9
	 Logging train Loss: 5.1839e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 8.9086e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 4.7782e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 9.727e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 9.1288e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 29.458954334259033
Epoch 3/9
	 Logging train Loss: 5.3455e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 1.11156e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 5.6922e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 7.059e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 1.11895e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 29.440993070602417
Epoch 4/9
	 Logging train Loss: 4.7535e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 8.0412e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 4.0801e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 4.711e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 8.2729e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 29.36265516281128
Epoch 5/9
	 Logging train Loss: 4.4466e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 5.5581e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 2.8514e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 2.925e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 5.9226e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 29.671162605285645
Epoch 6/9
	 Logging train Loss: 4.0836e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 6.0416e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 3.0406e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 2.601e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 6.2201e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 29.421675443649292
Epoch 7/9
	 Logging train Loss: 3.9167e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 4.6702e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 2.3615e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 2.1e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 4.9314e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 29.73608660697937
Epoch 8/9
	 Logging train Loss: 3.2116e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 4.755e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 2.4071e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 2.06e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 4.9377e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 29.674651861190796
Epoch 9/9
	 Logging train Loss: 3.003e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 4.5897e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 2.4109e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 4.118e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 4.6982e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
		--> Epoch time; 29.851154804229736
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gTrue/'log_quat_1'_'False'.pth
It took  397.98840832710266  seconds.

JOB STATISTICS
==============
Job ID: 3086317
Array Job ID: 3086289_69
Cluster: snellius
User/Group: nreints/nreints
State: RUNNING
Nodes: 1
Cores per node: 18
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 19:59:24 core-walltime
Job Wall-clock time: 01:06:38
Memory Utilized: 0.00 MB (estimated maximum)
Memory Efficiency: 0.00% of 0.00 MB (0.00 MB/node)
WARNING: Efficiency statistics may be misleading for RUNNING jobs.
