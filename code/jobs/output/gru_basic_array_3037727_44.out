wandb: Currently logged in as: nreints. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_165448-yapifx72
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run giddy-microwave-755
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/yapifx72
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue â–ƒâ–‚â–â–â–â–â–â–ˆâ–â–
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue â–ˆâ–…â–ƒâ–‚â–â–â–â–„â–â–
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue â–‚â–â–â–â–â–â–â–ˆâ–â–
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue â–‚â–â–â–â–â–â–â–ˆâ–â–
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue 1e-05
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue 1e-05
wandb:                                 Train loss 1e-05
wandb: 
wandb: ðŸš€ View run giddy-microwave-755 at: https://wandb.ai/nreints/ThesisFinal2/runs/yapifx72
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_165448-yapifx72/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_170228-mo7vphmn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run true-paper-774
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/mo7vphmn
Training on dataset: data_t(0,0)_r(0,0)_combi_pNone_gTrue
Testing on 4 datasets: ['data_t(0,0)_r(0,0)_full_pNone_gTrue', 'data_t(0,0)_r(0,0)_combi_pNone_gTrue', 'data_t(0,0)_r(0,0)_semi_pNone_gTrue', 'data_t(0,0)_r(0,0)_tennis_pNone_gTrue']
Focussing on identity: False
Using extra input: False
Using fr-fr as reference point.
----- ITERATION 1/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 52.245972633361816 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_full_pNone_gTrue took 13.100312948226929 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 12.02922010421753 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pNone_gTrue took 12.268570184707642 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pNone_gTrue took 12.264179706573486 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0170672704 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.11251e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.53289e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.98754e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 3.06539e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 35.608142614364624
Epoch 1/9
	 Logging train Loss: 1.73637e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.06873e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.15005e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.22986e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.24015e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 34.171459436416626
Epoch 2/9
	 Logging train Loss: 8.5146e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.9128e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 6.2788e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.6486e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 6.6838e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 34.35880732536316
Epoch 3/9
	 Logging train Loss: 4.7022e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.1047e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.3043e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.516e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 3.5309e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 34.12291431427002
Epoch 4/9
	 Logging train Loss: 2.2462e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.2133e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.3325e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.459e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.4706e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 34.135770320892334
Epoch 5/9
	 Logging train Loss: 3.033e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.534e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 4.242e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.958e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 5.07e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 34.097816467285156
Epoch 6/9
	 Logging train Loss: 7.8562e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.254e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.188e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.175e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 3.259e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 34.21517062187195
Epoch 7/9
	 Logging train Loss: 1.50526e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.7968e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 0.0001112291 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0002221551 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 0.0002141424 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 34.35102462768555
Epoch 8/9
	 Logging train Loss: 1.69567e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.56e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.107e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.35e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.403e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 34.06806707382202
Epoch 9/9
	 Logging train Loss: 1.22553e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.4343e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.747e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.4707e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 6.1574e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 34.47079348564148
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'dual_quat_1'_'False'.pth
It took  461.6114218235016  seconds.
----- ITERATION 2/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 47.542492389678955 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_full_pNone_gTrue took 11.978011846542358 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 11.838953971862793 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pNone_gTrue took 12.078717470169067 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pNone_gTrue took 12.01774525642395 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0092406711 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.85447e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.42915e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.86e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 3.00432e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 34.71141219139099
Epoch 1/9
	 Logging train Loss: 1.47051e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 9.0066e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 9.633e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.01486e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.02832e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 34.45803117752075
Epoch 2/9
	 Logging train Loss: 7.109e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.499e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 4.8451e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.1297e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 5.2051e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 34.53833842277527
Epoch 3/9
	 Logging train Loss: 3.1217e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.4755e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.6366e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.7708e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.8047e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 34.65028762817383
Epoch 4/9
	 Logging train Loss: 2.697e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
wandb: Waiting for W&B process to finish... (success).
wandb: ERROR Error while calling W&B API: An internal error occurred. Please contact support. (<Response [500]>)
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue â–ƒâ–‚â–â–â–â–â–‚â–â–ˆâ–
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue â–ˆâ–„â–ƒâ–‚â–â–â–‚â–â–„â–
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue â–‚â–â–â–â–â–â–‚â–â–ˆâ–
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue â–‚â–â–â–â–â–â–‚â–â–ˆâ–
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue 1e-05
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue 1e-05
wandb:                                 Train loss 1e-05
wandb: 
wandb: ðŸš€ View run true-paper-774 at: https://wandb.ai/nreints/ThesisFinal2/runs/mo7vphmn
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_170228-mo7vphmn/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_171002-q7m0ch22
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run graceful-blaze-791
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/q7m0ch22
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue â–†â–„â–ƒâ–‚â–‚â–â–ˆâ–ƒâ–â–
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue â–ˆâ–…â–„â–ƒâ–‚â–â–‚â–â–â–
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue â–„â–ƒâ–‚â–‚â–â–â–ˆâ–ƒâ–â–
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue â–„â–ƒâ–‚â–‚â–â–â–ˆâ–ƒâ–â–
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue 0.0
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue 0.0
wandb:                                 Train loss 1e-05
wandb: 
wandb: ðŸš€ View run graceful-blaze-791 at: https://wandb.ai/nreints/ThesisFinal2/runs/q7m0ch22
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_171002-q7m0ch22/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_171735-kr95jd34
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stoic-butterfly-807
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/kr95jd34
	 Logging test loss: 2.725e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 4.905e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.236e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 7.301e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 34.474427461624146
Epoch 5/9
	 Logging train Loss: 2.19174e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.4e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.02e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.258e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.318e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 34.63731384277344
Epoch 6/9
	 Logging train Loss: 1.47047e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.0796e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.64939e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.0984e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 3.20616e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 34.301506996154785
Epoch 7/9
	 Logging train Loss: 2.70337e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.1e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 5.28e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.15e-08 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 7.61e-08 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 34.55652403831482
Epoch 8/9
	 Logging train Loss: 1.08591e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.2449e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 9.28179e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.00016849 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 0.0001813005 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 34.50717329978943
Epoch 9/9
	 Logging train Loss: 1.0053e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.0512e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 4.5024e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.7735e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 8.2615e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 34.7938928604126
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'dual_quat_1'_'False'.pth
It took  453.8251428604126  seconds.
----- ITERATION 3/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 47.03042697906494 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_full_pNone_gTrue took 11.958743810653687 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 11.78157663345337 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pNone_gTrue took 11.973623037338257 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pNone_gTrue took 11.989123821258545 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0244498011 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.46714e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.81757e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.27623e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.34841e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 34.64203476905823
Epoch 1/9
	 Logging train Loss: 1.34356e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 9.2777e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.00781e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.11481e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.13116e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 34.583558082580566
Epoch 2/9
	 Logging train Loss: 8.5844e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.5266e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 7.0167e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.6474e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 7.7293e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 34.505500078201294
Epoch 3/9
	 Logging train Loss: 5.8619e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.2209e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 4.553e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.9705e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 5.0138e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 34.46227049827576
Epoch 4/9
	 Logging train Loss: 5.6611e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.1267e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.5824e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.1924e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 3.278e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 34.516677141189575
Epoch 5/9
	 Logging train Loss: 6.7112e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.067e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 8.707e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.0896e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.1191e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 34.55528020858765
Epoch 6/9
	 Logging train Loss: 1.09995e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.838e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.39936e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.80321e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 4.90184e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 34.59311580657959
Epoch 7/9
	 Logging train Loss: 1.36492e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.94e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 6.188e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.2502e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.28466e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 34.54507541656494
Epoch 8/9
	 Logging train Loss: 1.02883e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.12e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 4.51e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.19e-08 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 6.4e-08 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 34.5325882434845
Epoch 9/9
	 Logging train Loss: 1.30543e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.55e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.2493e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.6411e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.7866e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 34.77335166931152
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'dual_quat_1'_'False'.pth
It took  453.03663420677185  seconds.
----- ITERATION 4/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 46.80507302284241 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_full_pNone_gTrue took 11.970606565475464 seconds.
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue â–ˆâ–…â–ƒâ–‚â–â–â–â–â–â–„
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue â–ˆâ–…â–ƒâ–‚â–â–â–â–â–â–
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue â–ˆâ–…â–ƒâ–‚â–â–â–â–â–â–†
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue â–ˆâ–…â–ƒâ–‚â–â–â–â–â–â–†
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 1e-05
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue 1e-05
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue 1e-05
wandb:                                 Train loss 1e-05
wandb: 
wandb: ðŸš€ View run stoic-butterfly-807 at: https://wandb.ai/nreints/ThesisFinal2/runs/kr95jd34
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_171735-kr95jd34/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_172508-uddois2u
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run elated-capybara-823
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/uddois2u
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 11.823806047439575 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pNone_gTrue took 11.946327924728394 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pNone_gTrue took 11.944490909576416 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0189892426 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.38419e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.52029e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.65343e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.66518e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 34.682117223739624
Epoch 1/9
	 Logging train Loss: 1.09785e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.8903e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 8.2419e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.5792e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 8.6155e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 34.28283977508545
Epoch 2/9
	 Logging train Loss: 6.5666e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.9331e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 5.1351e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.3279e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 5.3513e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 34.56972694396973
Epoch 3/9
	 Logging train Loss: 3.8253e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.5392e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.6185e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.6928e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.703e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 34.892537117004395
Epoch 4/9
	 Logging train Loss: 2.9405e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.685e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 9.067e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 9.424e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 9.457e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 34.53414559364319
Epoch 5/9
	 Logging train Loss: 5.044e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.528e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 4.246e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.973e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 6.118e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 34.55491638183594
Epoch 6/9
	 Logging train Loss: 6.8784e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 9.91e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.37e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.525e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 3.615e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 34.2470428943634
Epoch 7/9
	 Logging train Loss: 1.01015e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.09e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 5.09e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.05e-08 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 6.13e-08 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 34.99444937705994
Epoch 8/9
	 Logging train Loss: 1.07754e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.76e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 8.97e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.213e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.236e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 34.80827236175537
Epoch 9/9
	 Logging train Loss: 6.3762e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.523e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 6.7584e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.18494e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.23181e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 34.600579261779785
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'dual_quat_1'_'False'.pth
It took  453.03133487701416  seconds.
----- ITERATION 5/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 46.880539655685425 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_full_pNone_gTrue took 11.942286968231201 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 11.773320198059082 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pNone_gTrue took 11.92256498336792 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pNone_gTrue took 12.00972032546997 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.016090028 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.05129e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.12728e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.20213e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.20455e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 35.05816650390625
Epoch 1/9
	 Logging train Loss: 8.6668e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.2969e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 6.6588e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.0233e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 7.0632e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 34.38632774353027
Epoch 2/9
	 Logging train Loss: 5.2487e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.6596e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.9847e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.3136e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 4.3446e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 34.58663201332092
Epoch 3/9
	 Logging train Loss: 2.8627e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.6292e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.8709e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.1144e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.1399e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 35.13736820220947
Epoch 4/9
	 Logging train Loss: 3.7857e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.1363e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 4.3916e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.81277e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 8.32759e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 34.54594278335571
Epoch 5/9
	 Logging train Loss: 7.619e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 9.6e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.287e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.606e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue â–ƒâ–‚â–‚â–â–ˆâ–â–â–‚â–â–
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue â–ˆâ–…â–ƒâ–‚â–„â–â–â–ƒâ–‚â–
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue â–‚â–‚â–â–â–ˆâ–â–â–‚â–â–
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue â–‚â–‚â–â–â–ˆâ–â–â–‚â–â–
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue 0.0
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue 0.0
wandb:                                 Train loss 1e-05
wandb: 
wandb: ðŸš€ View run elated-capybara-823 at: https://wandb.ai/nreints/ThesisFinal2/runs/uddois2u
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_172508-uddois2u/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_173242-9sc7wnn2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sandy-flower-844
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/9sc7wnn2
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue â–ˆâ–†â–…â–ƒâ–‚â–â–â–…â–â–
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue â–ˆâ–‡â–…â–„â–‚â–â–â–‚â–â–
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue â–ˆâ–…â–„â–ƒâ–‚â–â–â–‡â–â–
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue â–ˆâ–…â–„â–ƒâ–‚â–â–â–ˆâ–â–
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue 0.0
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue 0.0
wandb:                                 Train loss 1e-05
wandb: 
wandb: ðŸš€ View run sandy-flower-844 at: https://wandb.ai/nreints/ThesisFinal2/runs/9sc7wnn2
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_173242-9sc7wnn2/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_174013-017f5oj0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run warm-dawn-861
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/017f5oj0
	 Logging test loss: 1.663e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 34.65038847923279
Epoch 6/9
	 Logging train Loss: 6.9599e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.5e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.183e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.673e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 3.814e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 34.4978768825531
Epoch 7/9
	 Logging train Loss: 1.32769e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.8242e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 6.1965e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 9.583e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 9.4132e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 34.44462060928345
Epoch 8/9
	 Logging train Loss: 1.4485e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.974e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.2763e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.6708e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 3.818e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 34.3138542175293
Epoch 9/9
	 Logging train Loss: 8.8464e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.3e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.97e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.58e-08 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 4.7e-08 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 34.682766914367676
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'dual_quat_1'_'False'.pth
It took  453.8032386302948  seconds.
----- ITERATION 6/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 46.86756181716919 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_full_pNone_gTrue took 11.915498733520508 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 11.853052139282227 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pNone_gTrue took 11.912141561508179 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pNone_gTrue took 11.886690616607666 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0437794067 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.17996e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.45674e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.65246e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.78053e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 34.3700852394104
Epoch 1/9
	 Logging train Loss: 1.15679e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 9.5343e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 9.8542e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.00936e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.02148e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 34.55186057090759
Epoch 2/9
	 Logging train Loss: 8.6861e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.3756e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 7.5337e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.6586e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 7.7104e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 34.50942015647888
Epoch 3/9
	 Logging train Loss: 6.3273e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.9883e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 5.0911e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.172e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 5.2038e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 34.45872759819031
Epoch 4/9
	 Logging train Loss: 3.8306e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.4746e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.5392e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.5938e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.6134e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 34.45642948150635
Epoch 5/9
	 Logging train Loss: 1.5549e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.829e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 7.233e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.59e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 7.693e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 34.857070446014404
Epoch 6/9
	 Logging train Loss: 7.3024e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.355e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.665e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.942e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 3.017e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 34.50630068778992
Epoch 7/9
	 Logging train Loss: 1.05806e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.4451e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 8.565e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.41972e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.66864e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 34.55070734024048
Epoch 8/9
	 Logging train Loss: 5.5982e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.527e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.707e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.37e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 6.165e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 34.52847337722778
Epoch 9/9
	 Logging train Loss: 1.1401e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.088e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.253e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.398e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.443e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 34.525444984436035
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'dual_quat_1'_'False'.pth
It took  451.138210773468  seconds.
----- ITERATION 7/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 46.68783259391785 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_full_pNone_gTrue took 11.778242349624634 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 11.816624879837036 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pNone_gTrue took 11.931048154830933 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pNone_gTrue took 11.983739614486694 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0222356617 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.12402e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.62822e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue â–ˆâ–…â–ƒâ–‚â–â–â–â–â–â–
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue â–ˆâ–†â–„â–ƒâ–‚â–â–â–â–â–
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue â–ˆâ–„â–ƒâ–‚â–â–â–â–â–â–
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue â–ˆâ–„â–ƒâ–‚â–â–â–â–â–â–
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue 0.0
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue 0.0
wandb:                                 Train loss 1e-05
wandb: 
wandb: ðŸš€ View run warm-dawn-861 at: https://wandb.ai/nreints/ThesisFinal2/runs/017f5oj0
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_174013-017f5oj0/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_174746-sbp44n37
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run likely-shadow-882
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/sbp44n37
	 Logging test loss: 2.08363e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.1845e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 34.58079743385315
Epoch 1/9
	 Logging train Loss: 1.1203e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.0686e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 8.7488e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 9.402e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 9.5284e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 34.63587737083435
Epoch 2/9
	 Logging train Loss: 7.1735e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.3407e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 5.7284e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.1017e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 6.1738e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 34.40618181228638
Epoch 3/9
	 Logging train Loss: 4.3199e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.793e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.0043e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.208e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 3.2485e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 34.56166386604309
Epoch 4/9
	 Logging train Loss: 1.9317e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 9.465e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.0424e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.1334e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.1536e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 34.355467557907104
Epoch 5/9
	 Logging train Loss: 4.6255e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.845e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.351e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.836e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.944e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 34.694724798202515
Epoch 6/9
	 Logging train Loss: 7.9561e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.14e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 8.82e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.237e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.316e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 34.579718351364136
Epoch 7/9
	 Logging train Loss: 1.04778e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.76e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 6.32e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.77e-08 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 9.33e-08 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 34.90089511871338
Epoch 8/9
	 Logging train Loss: 1.71224e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.45e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 7.12e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.69e-08 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 9.06e-08 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 34.887590408325195
Epoch 9/9
	 Logging train Loss: 6.0361e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.677e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 7.637e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.2518e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.3521e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 34.6355504989624
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'dual_quat_1'_'False'.pth
It took  453.15332674980164  seconds.
----- ITERATION 8/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 46.62353467941284 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_full_pNone_gTrue took 11.925055027008057 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 11.815657615661621 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pNone_gTrue took 11.876508474349976 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pNone_gTrue took 11.898736238479614 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0099502299 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.49977e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.57056e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.65197e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.66475e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 34.766597032547
Epoch 1/9
	 Logging train Loss: 1.19166e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.4446e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 8.6577e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.8842e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 8.9253e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 34.890350341796875
Epoch 2/9
	 Logging train Loss: 6.3214e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.1605e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 4.2707e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.3919e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 4.4132e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 34.68063163757324
Epoch 3/9
	 Logging train Loss: 2.7917e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.4607e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.5261e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.597e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.6091e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 34.51809287071228
Epoch 4/9
	 Logging train Loss: 8.086e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.777e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.098e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.451e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 3.523e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 34.654662132263184
Epoch 5/9
	 Logging train Loss: 3.2251e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.59e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 9.107e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.6604e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.846e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 34.805105209350586
Epoch 6/9
	 Logging train Loss: 1.19555e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.99e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 4.55e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.3e-08 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 6.66e-08 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 34.7104914188385
Epoch 7/9
	 Logging train Loss: 1.82193e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.53e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue â–ˆâ–…â–ƒâ–‚â–â–â–â–â–ƒâ–ƒ
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue â–ˆâ–…â–ƒâ–‚â–â–â–â–â–‚â–‚
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue â–ˆâ–…â–ƒâ–‚â–â–‚â–â–â–…â–„
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue â–ˆâ–…â–ƒâ–‚â–â–‚â–â–â–…â–„
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue 1e-05
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue 1e-05
wandb:                                 Train loss 1e-05
wandb: 
wandb: ðŸš€ View run likely-shadow-882 at: https://wandb.ai/nreints/ThesisFinal2/runs/sbp44n37
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_174746-sbp44n37/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_175520-ryasqzpv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run upbeat-haze-905
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/ryasqzpv
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue â–ˆâ–…â–„â–ƒâ–‚â–â–â–‚â–ƒâ–
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue â–ˆâ–†â–„â–ƒâ–‚â–â–â–â–â–
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue â–ˆâ–…â–„â–ƒâ–‚â–â–â–‚â–ƒâ–
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue â–ˆâ–…â–„â–ƒâ–‚â–â–â–‚â–ƒâ–
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue 0.0
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue 0.0
wandb:                                 Train loss 1e-05
wandb: 
wandb: ðŸš€ View run upbeat-haze-905 at: https://wandb.ai/nreints/ThesisFinal2/runs/ryasqzpv
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_175520-ryasqzpv/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_180253-611aypa6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run easy-salad-923
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/611aypa6
	 Logging test loss: 3.3e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.17e-08 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 4.34e-08 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 34.828967571258545
Epoch 8/9
	 Logging train Loss: 1.49915e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.3114e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 5.2759e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 9.8986e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.048e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 34.651864767074585
Epoch 9/9
	 Logging train Loss: 5.5139e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.4996e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 4.8639e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.5664e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 8.0274e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 34.4257435798645
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'dual_quat_1'_'False'.pth
It took  453.38356256484985  seconds.
----- ITERATION 9/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 46.56537985801697 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_full_pNone_gTrue took 11.84875774383545 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 11.732292175292969 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pNone_gTrue took 11.836426734924316 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pNone_gTrue took 11.844862222671509 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0303780828 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.44062e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.67006e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.87207e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.86805e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 34.497169494628906
Epoch 1/9
	 Logging train Loss: 1.29168e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 9.7248e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.03507e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.08738e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.08744e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 34.91323661804199
Epoch 2/9
	 Logging train Loss: 8.6939e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.9628e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 7.2902e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.5553e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 7.5607e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 34.69767880439758
Epoch 3/9
	 Logging train Loss: 5.9325e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.4524e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 4.6217e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.76e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 4.7674e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 34.81890106201172
Epoch 4/9
	 Logging train Loss: 3.3777e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.1486e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.2415e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.3197e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.3217e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 34.627310276031494
Epoch 5/9
	 Logging train Loss: 1.3751e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.379e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 6.903e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.343e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 7.352e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 34.66189122200012
Epoch 6/9
	 Logging train Loss: 4.9821e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.509e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 6.61e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.1216e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.0862e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 34.426294565200806
Epoch 7/9
	 Logging train Loss: 1.23119e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.573e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.8905e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.3275e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 3.2649e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 34.78167939186096
Epoch 8/9
	 Logging train Loss: 1.13889e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.321e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.9231e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.6954e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 6.6666e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 34.77439761161804
Epoch 9/9
	 Logging train Loss: 1.37763e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.51e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 4.38e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.94e-08 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 5.95e-08 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 34.52069115638733
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'dual_quat_1'_'False'.pth
It took  453.07799792289734  seconds.
----- ITERATION 10/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 46.24156308174133 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_full_pNone_gTrue took 11.879848957061768 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 11.677442789077759 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pNone_gTrue took 11.85912013053894 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pNone_gTrue took 11.884457111358643 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.056175679 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.34459e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.80549e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.22361e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.3485e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 34.72740125656128
Epoch 1/9
	 Logging train Loss: 1.40847e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.11092e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.1794e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.24795e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.25789e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 34.83893370628357
Epoch 2/9
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue â–ˆâ–†â–…â–„â–ƒâ–‚â–â–â–„â–
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue â–ˆâ–‡â–†â–…â–ƒâ–‚â–‚â–â–â–
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue â–ˆâ–…â–„â–ƒâ–ƒâ–‚â–â–â–…â–
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue â–ˆâ–…â–„â–ƒâ–‚â–‚â–â–â–†â–
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue 0.0
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue 0.0
wandb:                                 Train loss 1e-05
wandb: 
wandb: ðŸš€ View run easy-salad-923 at: https://wandb.ai/nreints/ThesisFinal2/runs/611aypa6
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_180253-611aypa6/logs
	 Logging train Loss: 1.07511e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 9.2946e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 9.6667e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.00432e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.01e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 34.525745153427124
Epoch 3/9
	 Logging train Loss: 8.5448e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.1303e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 7.3552e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.5759e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 7.6238e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 34.7087242603302
Epoch 4/9
	 Logging train Loss: 6.0517e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.5545e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 4.7207e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.8683e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 4.9154e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 34.407105684280396
Epoch 5/9
	 Logging train Loss: 3.4597e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.0792e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.2339e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.3689e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.4148e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 34.712178468704224
Epoch 6/9
	 Logging train Loss: 1.4332e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.2016e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.3129e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.4152e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.4407e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 34.430368423461914
Epoch 7/9
	 Logging train Loss: 3.1855e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 9.006e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.0492e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.19e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.2168e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 35.1812481880188
Epoch 8/9
	 Logging train Loss: 6.7478e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.894e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 7.3568e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.41112e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.53705e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 34.69292140007019
Epoch 9/9
	 Logging train Loss: 1.17148e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.93e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 6.64e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 9.24e-08 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 9.72e-08 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 34.45093894004822
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'dual_quat_1'_'False'.pth
It took  462.95021867752075  seconds.

JOB STATISTICS
==============
Job ID: 3037751
Array Job ID: 3037727_44
Cluster: snellius
User/Group: nreints/nreints
State: RUNNING
Nodes: 1
Cores per node: 18
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 22:48:54 core-walltime
Job Wall-clock time: 01:16:03
Memory Utilized: 0.00 MB (estimated maximum)
Memory Efficiency: 0.00% of 0.00 MB (0.00 MB/node)
WARNING: Efficiency statistics may be misleading for RUNNING jobs.
