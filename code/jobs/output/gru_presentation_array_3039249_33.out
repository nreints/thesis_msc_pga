wandb: Currently logged in as: nreints. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_231705-3u8fk7qh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dry-pine-1151
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/3u8fk7qh
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue █▂▂▄▂▁▃▁▁▁
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue ▅▂▁█▂▁▃▁▁▁
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue █▄▃▄▃▁▄▁▁▁
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue █▃▂▃▂▁▄▁▁▁
wandb:                                 Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue 0.00032
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 1e-05
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.00043
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.00074
wandb:                                 Train loss 0.00041
wandb: 
wandb: 🚀 View run dry-pine-1151 at: https://wandb.ai/nreints/ThesisFinal2/runs/3u8fk7qh
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_231705-3u8fk7qh/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_232551-udoxaq6b
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run gentle-violet-1162
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/udoxaq6b
Training on dataset: data_t(0,0)_r(0,0)_combi_pTrue_gTrue
Testing on 4 datasets: ['data_t(0,0)_r(0,0)_full_pTrue_gTrue', 'data_t(0,0)_r(0,0)_tennis_pTrue_gTrue', 'data_t(0,0)_r(0,0)_combi_pTrue_gTrue', 'data_t(0,0)_r(0,0)_semi_pTrue_gTrue']
Focussing on identity: False
Using extra input: False
Using start-fr as reference point.
----- ITERATION 1/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 78.81823253631592 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 19.696002960205078 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 19.742620944976807 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 19.996031999588013 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 19.840393781661987 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(6, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=6, bias=True)
)
Datatype: log_dualQ
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0500512645 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0003860576 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0089069232 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.002401727 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0028889845 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 36.19124364852905
Epoch 1/9
	 Logging train Loss: 0.0021120231 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 9.0017e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0028756587 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0006584656 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0016099947 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 34.757291316986084
Epoch 2/9
	 Logging train Loss: 0.0012804004 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 4.75228e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0016165437 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0004477766 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0009785931 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 34.87177324295044
Epoch 3/9
	 Logging train Loss: 0.0005557981 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.000606695 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0033321425 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0010757885 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0016179805 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 34.66972589492798
Epoch 4/9
	 Logging train Loss: 0.0010054928 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 7.55287e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0016698142 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0006871137 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0011251683 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 35.03146457672119
Epoch 5/9
	 Logging train Loss: 0.0002516912 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.17294e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0008916982 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0002665284 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0005475408 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 35.10466504096985
Epoch 6/9
	 Logging train Loss: 0.0004520518 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0002064691 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0037794807 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0010255729 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0014307327 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 35.03190541267395
Epoch 7/9
	 Logging train Loss: 0.0005968086 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.01523e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0007247516 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0003033589 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0004513541 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 35.076685667037964
Epoch 8/9
	 Logging train Loss: 0.0003347195 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.45006e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0007063582 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0002900558 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0004408331 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 34.8603937625885
Epoch 9/9
	 Logging train Loss: 0.0004125757 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.30062e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0007445906 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0003152961 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0004282262 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 35.28090167045593
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pTrue_gTrue/'log_dualQ'_'False'.pth
It took  526.2522189617157  seconds.
----- ITERATION 2/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 72.5304274559021 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 18.356428384780884 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 18.34403896331787 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 18.198107957839966 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 18.317318439483643 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(6, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=6, bias=True)
)
Datatype: log_dualQ
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0409923829 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0002072513 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0136245303 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0039689182 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0058992491 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 35.40873384475708
Epoch 1/9
	 Logging train Loss: 0.001988021 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0002202029 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0087239733 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0028948849 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0037409025 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 35.504528522491455
Epoch 2/9
	 Logging train Loss: 0.000753794 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 5.64838e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0038617009 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0014491596 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0022683807 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 35.04053616523743
Epoch 3/9
	 Logging train Loss: 0.0018862578 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 6.23175e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0051194904 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0015392139 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0025394047 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 35.05747413635254
Epoch 4/9
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue █▅▂▂▁▂▂▁▁▂
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue ██▂▃▂▂▁▁▁▁
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue █▄▁▂▁▁▁▁▁▁
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue █▅▂▃▂▂▂▁▁▁
wandb:                                 Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue 0.00143
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 1e-05
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.00213
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.00155
wandb:                                 Train loss 0.00035
wandb: 
wandb: 🚀 View run gentle-violet-1162 at: https://wandb.ai/nreints/ThesisFinal2/runs/udoxaq6b
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_232551-udoxaq6b/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_233456-ez452zos
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run logical-eon-1171
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/ez452zos
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue █▆▄▄▃▂▃▁▁▁
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue ▅▃▂▂▂▂█▂▂▁
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue █▆▄▄▃▂▂▂▁▁
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue █▅▄▃▃▃▂▂▁▁
wandb:                                 Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue 0.01767
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 1e-05
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.01561
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.01555
wandb:                                 Train loss 0.0002
wandb: 
wandb: 🚀 View run logical-eon-1171 at: https://wandb.ai/nreints/ThesisFinal2/runs/ez452zos
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_233456-ez452zos/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_234333-dftejqn9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run quiet-vortex-1182
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/dftejqn9
	 Logging train Loss: 0.0001897314 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 3.53582e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0036716065 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0012837111 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0021004886 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 35.28552722930908
Epoch 5/9
	 Logging train Loss: 0.0005682122 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 5.51845e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0030444169 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0014296795 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0021201908 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 35.177186727523804
Epoch 6/9
	 Logging train Loss: 0.0005146938 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.80489e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0026432911 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0014020731 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0021498373 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 34.88934397697449
Epoch 7/9
	 Logging train Loss: 0.0006274878 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.66806e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0019747652 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0011906156 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0020894241 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 35.14969515800476
Epoch 8/9
	 Logging train Loss: 0.0003352496 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.3066e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.001734479 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0012922141 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0021046912 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 34.84831929206848
Epoch 9/9
	 Logging train Loss: 0.0003470572 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.30437e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0015465118 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0014260205 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0021308069 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 35.00234031677246
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pTrue_gTrue/'log_dualQ'_'False'.pth
It took  545.4737966060638  seconds.
----- ITERATION 3/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 70.76447010040283 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 18.206406831741333 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 18.161831855773926 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 17.988514184951782 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 18.175687313079834 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(6, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=6, bias=True)
)
Datatype: log_dualQ
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0289279111 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 6.11444e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0477134548 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0539549254 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0509121604 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 35.18524098396301
Epoch 1/9
	 Logging train Loss: 0.0003262827 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 4.09791e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0358104445 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0415610038 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0389070623 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 35.46682333946228
Epoch 2/9
	 Logging train Loss: 0.000143887 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.38328e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0302562267 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0349570438 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0325713828 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 35.38406944274902
Epoch 3/9
	 Logging train Loss: 0.0001848819 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.2734e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0267426167 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0308490973 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0286262557 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 35.15432906150818
Epoch 4/9
	 Logging train Loss: 0.0001637851 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.10014e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0246570855 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0265506618 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0245309565 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 35.19315791130066
Epoch 5/9
	 Logging train Loss: 0.0002354936 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.61085e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0225515515 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0231054332 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0208645761 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 35.182621002197266
Epoch 6/9
	 Logging train Loss: 4.26685e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0001016261 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0210938752 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0255384576 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0229950529 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 35.67753982543945
Epoch 7/9
	 Logging train Loss: 6.49187e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.31947e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0184334684 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0200242344 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0182630699 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 35.30254793167114
Epoch 8/9
	 Logging train Loss: 8.97051e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.08377e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0166338887 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0179110281 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0160141308 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 35.02851915359497
Epoch 9/9
	 Logging train Loss: 0.0001954953 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.22419e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.015551026 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0176712256 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0156075926 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 35.28642225265503
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pTrue_gTrue/'log_dualQ'_'False'.pth
It took  516.6728372573853  seconds.
----- ITERATION 4/10 ------
Number of train simulations:  1920
Number of test simulations:  480
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue █▃▂▁▂▁▁▁▁▁
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue █▃▃▂▄▁▁▁▁▁
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue █▃▃▂▂▁▁▁▁▁
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue █▅▄▂▂▂▂▂▁▁
wandb:                                 Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue 4e-05
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 1e-05
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.00091
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.00523
wandb:                                 Train loss 0.00039
wandb: 
wandb: 🚀 View run quiet-vortex-1182 at: https://wandb.ai/nreints/ThesisFinal2/runs/dftejqn9
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_234333-dftejqn9/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_235202-woalp3hc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run smooth-wave-1190
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/woalp3hc
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 71.17034244537354 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 18.188969373703003 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 18.192744970321655 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 17.956737518310547 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 18.1667423248291 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(6, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=6, bias=True)
)
Datatype: log_dualQ
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.044249624 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0001727896 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0115340091 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0007968787 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0073949844 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 35.47807288169861
Epoch 1/9
	 Logging train Loss: 0.0022272698 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 5.77708e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.00880278 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0002308187 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0029830982 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 35.143009662628174
Epoch 2/9
	 Logging train Loss: 0.0006944932 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 6.51866e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0080576399 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0001700542 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0023228519 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 35.29704785346985
Epoch 3/9
	 Logging train Loss: 0.0007000249 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.81082e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0063570398 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 7.04894e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.001717086 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 35.60528373718262
Epoch 4/9
	 Logging train Loss: 0.0014581514 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 7.23594e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0065227621 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0001437106 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0016643608 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 35.28811264038086
Epoch 5/9
	 Logging train Loss: 0.000452586 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.88596e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0062382622 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 4.76949e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0011744114 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 35.1249885559082
Epoch 6/9
	 Logging train Loss: 0.0002110002 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.87996e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0059903841 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 4.63761e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0010112626 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 35.32056736946106
Epoch 7/9
	 Logging train Loss: 0.0007274812 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.53522e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0059072725 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 3.66182e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0009576469 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 35.466392993927
Epoch 8/9
	 Logging train Loss: 0.0002821911 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.50517e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0056176516 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 4.62526e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0009447483 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 35.261359214782715
Epoch 9/9
	 Logging train Loss: 0.0003851804 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.30039e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.005233346 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 3.96891e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0009056781 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 34.90566396713257
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pTrue_gTrue/'log_dualQ'_'False'.pth
It took  509.25782799720764  seconds.
----- ITERATION 5/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 70.9463529586792 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 18.12432360649109 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 18.1248459815979 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 17.84502673149109 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 18.12013030052185 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(6, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=6, bias=True)
)
Datatype: log_dualQ
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0387709178 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0001121405 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0034361714 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0166489296 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0255722944 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 35.328041553497314
Epoch 1/9
	 Logging train Loss: 0.0012737266 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0004349787 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0079135466 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0173957217 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0336625502 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 34.94444680213928
Epoch 2/9
	 Logging train Loss: 0.0007288688 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 7.43255e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.001199259 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0125915278 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0162288714 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 35.31127333641052
Epoch 3/9
	 Logging train Loss: 0.0006854882 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 4.69186e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0009442263 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0106802154 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0136627723 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 35.423137187957764
Epoch 4/9
	 Logging train Loss: 0.00087623 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 3.07149e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0008355795 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0106496606 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0141027076 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 35.49563956260681
Epoch 5/9
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue ▇█▄▃▃▂▂▁▂▁
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue ▃█▂▂▁▁▁▁█▁
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue ▆█▃▂▂▂▁▁▂▁
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue ▄█▂▁▁▁▁▁▃▁
wandb:                                 Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue 0.00875
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 1e-05
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.01042
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.00064
wandb:                                 Train loss 0.00035
wandb: 
wandb: 🚀 View run smooth-wave-1190 at: https://wandb.ai/nreints/ThesisFinal2/runs/woalp3hc
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_235202-woalp3hc/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230710_000031-kvd0fo8r
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sparkling-glade-1200
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/kvd0fo8r
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue ██▃▂▃▃▂▂▂▁
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue ▅█▂▁▂▆▃▁▁▁
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue ██▃▂▄▃▂▂▂▁
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue ██▃▂▃▃▂▂▂▁
wandb:                                 Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue 0.00714
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 1e-05
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.01142
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.00793
wandb:                                 Train loss 0.00034
wandb: 
wandb: 🚀 View run sparkling-glade-1200 at: https://wandb.ai/nreints/ThesisFinal2/runs/kvd0fo8r
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230710_000031-kvd0fo8r/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230710_000900-hndd240y
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run valiant-hill-1210
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/hndd240y
	 Logging train Loss: 0.0002373396 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.86386e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0007553559 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0104841823 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0129698645 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 35.14907622337341
Epoch 6/9
	 Logging train Loss: 0.0003511504 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 4.26204e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0009184541 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0096492786 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0119667361 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 35.266687631607056
Epoch 7/9
	 Logging train Loss: 0.0004621611 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.76299e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0007543465 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0093611274 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0115435477 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 35.36335301399231
Epoch 8/9
	 Logging train Loss: 0.0001752518 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0004364152 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0025094345 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0102948481 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0124471867 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 35.21403479576111
Epoch 9/9
	 Logging train Loss: 0.0003451494 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.28726e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0006364626 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0087465178 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0104156118 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 35.41327357292175
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pTrue_gTrue/'log_dualQ'_'False'.pth
It took  509.0376853942871  seconds.
----- ITERATION 6/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 70.68299317359924 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 18.139922618865967 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 18.134374380111694 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 17.90150547027588 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 18.125584363937378 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(6, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=6, bias=True)
)
Datatype: log_dualQ
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0390379541 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0002154503 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0182814803 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0146876378 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0216822233 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 35.24802374839783
Epoch 1/9
	 Logging train Loss: 0.0017208569 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0003287838 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0178343207 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0142680118 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0223356076 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 35.33099603652954
Epoch 2/9
	 Logging train Loss: 0.0011118096 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 4.81644e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0108421678 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.009615656 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0147771351 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 35.38981080055237
Epoch 3/9
	 Logging train Loss: 0.0004013375 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.9072e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0097594457 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0085217319 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0132357525 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 35.291465282440186
Epoch 4/9
	 Logging train Loss: 0.0005864196 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 6.01116e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.011245179 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0097486423 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0157910325 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 35.11481499671936
Epoch 5/9
	 Logging train Loss: 0.00061679 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0002362335 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0103639476 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0089791827 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0142400712 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 35.40077018737793
Epoch 6/9
	 Logging train Loss: 0.0005639723 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.000108947 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0095900409 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0085277427 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0125481915 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 35.1000657081604
Epoch 7/9
	 Logging train Loss: 0.0003202121 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.57144e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0092407959 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0083762622 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0129204746 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 35.382593393325806
Epoch 8/9
	 Logging train Loss: 0.0004222432 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.75369e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0089345928 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0080058631 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0129470397 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 35.13786768913269
Epoch 9/9
	 Logging train Loss: 0.0003360357 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.17923e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0079251975 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0071358392 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0114155402 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 35.39956212043762
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pTrue_gTrue/'log_dualQ'_'False'.pth
It took  509.03102231025696  seconds.
----- ITERATION 7/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 70.88328671455383 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 18.088181018829346 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 18.056349992752075 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 17.866419792175293 seconds.
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue ▁█▁▁▁▁▁▁▁▁
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue ▂█▁▁▁▁▂▁▁▁
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue ▂█▁▁▁▁▁▁▁▁
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue ▄█▂▂▂▂▂▁▁▁
wandb:                                 Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue 5e-05
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 2e-05
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.0017
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.0053
wandb:                                 Train loss 0.00022
wandb: 
wandb: 🚀 View run valiant-hill-1210 at: https://wandb.ai/nreints/ThesisFinal2/runs/hndd240y
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230710_000900-hndd240y/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230710_001733-sbtl1hcq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run treasured-universe-1221
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/sbtl1hcq
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 18.023829698562622 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(6, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=6, bias=True)
)
Datatype: log_dualQ
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0441721454 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0002096615 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0139892772 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0007315148 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0123891374 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 35.07474875450134
Epoch 1/9
	 Logging train Loss: 0.0018538623 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0011847691 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0231516343 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0149249136 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.058471892 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 35.44980573654175
Epoch 2/9
	 Logging train Loss: 0.0015701187 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 4.41373e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0080123013 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0001640285 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0042239241 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 35.19922208786011
Epoch 3/9
	 Logging train Loss: 0.0010938952 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 3.1851e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0074018706 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0001120978 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0035393992 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 35.130016803741455
Epoch 4/9
	 Logging train Loss: 0.0001803802 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.79909e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0069021122 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0001121089 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0028571482 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 35.18687176704407
Epoch 5/9
	 Logging train Loss: 0.0008680293 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.33203e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0069296714 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 8.19951e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0026963723 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 35.43081498146057
Epoch 6/9
	 Logging train Loss: 0.0002090533 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0001324525 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0078046918 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0002102619 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0031180116 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 35.30291152000427
Epoch 7/9
	 Logging train Loss: 0.0004869752 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.31859e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.005615118 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 6.24009e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0021987371 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 35.313493490219116
Epoch 8/9
	 Logging train Loss: 0.0007095747 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.63313e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0056334911 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 4.95754e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0018053567 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 35.03891897201538
Epoch 9/9
	 Logging train Loss: 0.0002227481 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.62567e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0053038406 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 4.79161e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.001698551 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 35.12058424949646
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pTrue_gTrue/'log_dualQ'_'False'.pth
It took  513.0745935440063  seconds.
----- ITERATION 8/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 70.82379293441772 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 18.149364471435547 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 18.088284015655518 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 17.92165732383728 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 18.11486315727234 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(6, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=6, bias=True)
)
Datatype: log_dualQ
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.045004826 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.000138484 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0421915203 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0089580333 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0141732786 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 34.940714836120605
Epoch 1/9
	 Logging train Loss: 0.0016783323 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 5.30071e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0336110182 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0068697701 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0084627504 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 35.10020685195923
Epoch 2/9
	 Logging train Loss: 0.0005644959 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0001112608 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0316929296 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.006346724 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0088588567 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 34.87680625915527
Epoch 3/9
	 Logging train Loss: 0.0009960001 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 5.77615e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.032855168 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0056943833 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0075168507 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 34.96629333496094
Epoch 4/9
	 Logging train Loss: 0.0006576335 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.27496e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0328797586 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.005908275 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0054684882 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 34.73914885520935
Epoch 5/9
	 Logging train Loss: 0.0008418598 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.0939e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0347565226 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0061223274 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.005261586 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue █▅▄▃▄▄▂▂▁▂
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue ▄▂▃▂▁▁▁▁▁█
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue █▄▄▃▂▂▁▁▁▂
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue █▃▂▃▃▄▁▂▁▂
wandb:                                 Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue 0.00447
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 0.00031
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.00519
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.03072
wandb:                                 Train loss 0.00077
wandb: 
wandb: 🚀 View run treasured-universe-1221 at: https://wandb.ai/nreints/ThesisFinal2/runs/sbtl1hcq
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230710_001733-sbtl1hcq/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230710_002558-xfp2dgt1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wobbly-darkness-1231
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/xfp2dgt1
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue █▆▅▄▃▃▂▃▃▁
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue ▃▁▁▂▂▁▁█▃▁
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue █▆▅▄▃▃▂▄▃▁
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue █▆▄▃▃▂▂▄▂▁
wandb:                                 Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue 0.01984
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 3e-05
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.02113
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.01149
wandb:                                 Train loss 9e-05
wandb: 
wandb: 🚀 View run wobbly-darkness-1231 at: https://wandb.ai/nreints/ThesisFinal2/runs/xfp2dgt1
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230710_002558-xfp2dgt1/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230710_003429-km1klwb4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run apricot-wave-1239
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/km1klwb4
		--> Epoch time; 35.18987154960632
Epoch 6/9
	 Logging train Loss: 0.0001517917 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 3.67897e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.030273702 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0046766922 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0047673248 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 34.81686305999756
Epoch 7/9
	 Logging train Loss: 0.0007371582 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.78638e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0312801041 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0045953668 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0044305907 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 35.0633909702301
Epoch 8/9
	 Logging train Loss: 0.0001172924 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.85276e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0294188131 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0038827066 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0042088712 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 34.936654806137085
Epoch 9/9
	 Logging train Loss: 0.0007694385 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0003103185 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.030722687 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0044701942 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0051909513 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 34.9045307636261
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pTrue_gTrue/'log_dualQ'_'False'.pth
It took  505.0628652572632  seconds.
----- ITERATION 9/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 70.8996069431305 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 18.103930950164795 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 18.09163546562195 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 17.924141883850098 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 18.171642303466797 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(6, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=6, bias=True)
)
Datatype: log_dualQ
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0284922756 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 7.83979e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0440852083 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0538767688 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0590205975 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 35.15771007537842
Epoch 1/9
	 Logging train Loss: 0.0004640808 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.93956e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0335123911 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0454393476 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0484260432 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 35.393561601638794
Epoch 2/9
	 Logging train Loss: 0.0004070987 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.76526e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0271077547 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0401422009 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0420254171 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 35.176745653152466
Epoch 3/9
	 Logging train Loss: 0.0001321865 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 4.35581e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0225318056 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0365360603 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0392551683 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 35.437580823898315
Epoch 4/9
	 Logging train Loss: 0.0001716588 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 4.85234e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0193134602 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0307891481 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0328680314 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 35.22025680541992
Epoch 5/9
	 Logging train Loss: 0.0003084368 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.00575e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0170646291 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0292395465 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0306667108 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 35.21886467933655
Epoch 6/9
	 Logging train Loss: 0.000239881 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.62998e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0149542885 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0270149093 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0283766109 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 34.60325264930725
Epoch 7/9
	 Logging train Loss: 0.0001469861 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.000281226 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.025001796 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0314740688 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0356215537 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 34.72406768798828
Epoch 8/9
	 Logging train Loss: 0.0001901548 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 9.32335e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0168466531 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0306092538 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.032418821 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 34.93672060966492
Epoch 9/9
	 Logging train Loss: 9.26398e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.50879e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0114924433 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.019835487 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0211287849 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 34.746344566345215
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pTrue_gTrue/'log_dualQ'_'False'.pth
It took  510.6494450569153  seconds.
----- ITERATION 10/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 70.906809091568 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 18.065301179885864 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 18.0260751247406 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 17.865397453308105 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 17.991926193237305 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(6, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=6, bias=True)
)
Datatype: log_dualQ
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0432972945 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0002019581 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue █▂▁▁▂▁▁▁▁▁
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue █▃▂▂▂▁▂▁▁▁
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue █▃▂▂▁▁▂▁▁▁
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue █▅▃▃▂▂▂▂▂▁
wandb:                                 Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue 3e-05
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 1e-05
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.0005
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.0174
wandb:                                 Train loss 0.00014
wandb: 
wandb: 🚀 View run apricot-wave-1239 at: https://wandb.ai/nreints/ThesisFinal2/runs/km1klwb4
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230710_003429-km1klwb4/logs
	 Logging test loss: 0.0375225581 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0004454475 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0074780611 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 34.654948711395264
Epoch 1/9
	 Logging train Loss: 0.0016706012 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 6.84321e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0275782142 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0001096972 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0023431897 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 34.8722357749939
Epoch 2/9
	 Logging train Loss: 0.0009150477 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 5.13534e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0231250618 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 5.72968e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0014960419 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 34.89626216888428
Epoch 3/9
	 Logging train Loss: 0.0013474957 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 3.6587e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0236099567 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 4.6949e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0010327011 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 34.82058382034302
Epoch 4/9
	 Logging train Loss: 0.0002007358 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 5.42351e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0209467802 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 8.05913e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.000778918 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 34.76513671875
Epoch 5/9
	 Logging train Loss: 0.0003296825 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.55498e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0201212652 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 3.78639e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0007517968 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 34.718199014663696
Epoch 6/9
	 Logging train Loss: 0.0006269536 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 3.48878e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0198620129 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 5.87499e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0009463825 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 34.69839000701904
Epoch 7/9
	 Logging train Loss: 0.0009289436 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.13669e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0206694547 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 3.53873e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0004264263 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 35.0102264881134
Epoch 8/9
	 Logging train Loss: 0.0002341594 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.54639e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0197018329 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 5.79982e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0004606186 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 34.95574116706848
Epoch 9/9
	 Logging train Loss: 0.0001351148 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.4282e-05 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 0.0173993725 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.97728e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 0.0005047855 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
		--> Epoch time; 34.546968936920166
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pTrue_gTrue/'log_dualQ'_'False'.pth
It took  502.9671335220337  seconds.

JOB STATISTICS
==============
Job ID: 3039258
Array Job ID: 3039249_33
Cluster: snellius
User/Group: nreints/nreints
State: COMPLETED (exit code 0)
Nodes: 1
Cores per node: 18
CPU Utilized: 01:32:21
CPU Efficiency: 5.96% of 1-01:50:06 core-walltime
Job Wall-clock time: 01:26:07
Memory Utilized: 7.67 GB
Memory Efficiency: 0.00% of 0.00 MB
