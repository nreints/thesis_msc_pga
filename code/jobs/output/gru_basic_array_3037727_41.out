wandb: Currently logged in as: nreints. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_165455-xstk6tqm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sage-snowflake-761
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/xstk6tqm
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue â–„â–ƒâ–ƒâ–‚â–‚â–ˆâ–â–â–â–
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue â–ˆâ–‡â–†â–„â–‚â–ƒâ–â–â–â–
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue â–ƒâ–‚â–‚â–‚â–â–ˆâ–â–â–â–
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue â–‚â–‚â–‚â–â–â–ˆâ–â–â–â–
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue 0.0
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue 0.0
wandb:                                 Train loss 0.0
wandb: 
wandb: ðŸš€ View run sage-snowflake-761 at: https://wandb.ai/nreints/ThesisFinal2/runs/xstk6tqm
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_165455-xstk6tqm/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_170621-ks37hjji
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run volcanic-butterfly-780
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/ks37hjji
Training on dataset: data_t(0,0)_r(0,0)_combi_pNone_gTrue
Testing on 4 datasets: ['data_t(0,0)_r(0,0)_tennis_pNone_gTrue', 'data_t(0,0)_r(0,0)_combi_pNone_gTrue', 'data_t(0,0)_r(0,0)_full_pNone_gTrue', 'data_t(0,0)_r(0,0)_semi_pNone_gTrue']
Focussing on identity: False
Using extra input: False
Using fr-fr as reference point.
----- ITERATION 1/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 51.50998020172119 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pNone_gTrue took 13.114161252975464 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 12.924448728561401 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pNone_gTrue took 12.11102843284607 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pNone_gTrue took 12.176660060882568 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0151547138 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.42157e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.26162e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.12869e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.41041e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 57.60720086097717
Epoch 1/9
	 Logging train Loss: 1.10544e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.02025e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 9.7094e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 9.3354e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.01116e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 57.04483151435852
Epoch 2/9
	 Logging train Loss: 8.6819e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.7211e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 7.5369e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.4016e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 7.6816e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 56.90419960021973
Epoch 3/9
	 Logging train Loss: 6.4404e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.1511e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 5.0768e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.021e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 5.135e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 56.924893856048584
Epoch 4/9
	 Logging train Loss: 3.8578e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.6818e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.9317e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.1494e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.6161e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 57.150495529174805
Epoch 5/9
	 Logging train Loss: 5.5681e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.1145e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.36239e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.3944e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 6.46863e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 56.73322796821594
Epoch 6/9
	 Logging train Loss: 6.3677e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.662e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.552e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.452e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.662e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 57.0133056640625
Epoch 7/9
	 Logging train Loss: 6.2442e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.376e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.232e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.113e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.363e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 56.87765955924988
Epoch 8/9
	 Logging train Loss: 7.1144e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.837e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.802e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.768e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.838e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 56.68212151527405
Epoch 9/9
	 Logging train Loss: 2.6768e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.921e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.634e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.47e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 4.758e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 56.82395601272583
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'rot_mat_1'_'False'.pth
It took  687.112140417099  seconds.
----- ITERATION 2/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 48.632304191589355 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pNone_gTrue took 12.053520917892456 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 12.140166997909546 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pNone_gTrue took 12.095476865768433 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pNone_gTrue took 12.059853315353394 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0088380203 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.07932e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.03617e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 9.9663e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.07569e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 58.31183648109436
Epoch 1/9
	 Logging train Loss: 8.8183e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.6269e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 7.5099e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.3997e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 7.6004e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 58.230329275131226
Epoch 2/9
	 Logging train Loss: 5.6026e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.6823e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.6237e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.5678e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.6718e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 58.0944709777832
Epoch 3/9
	 Logging train Loss: 2.0082e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.582e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 8.306e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.041e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 8.531e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 58.170167446136475
Epoch 4/9
	 Logging train Loss: 6.413e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue â–ˆâ–†â–ƒâ–â–â–â–â–â–â–
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue â–ˆâ–†â–ƒâ–â–â–â–â–â–â–
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue â–ˆâ–†â–ƒâ–â–â–â–â–â–â–
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue â–ˆâ–†â–ƒâ–â–â–â–â–â–â–
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue 0.0
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue 0.0
wandb:                                 Train loss 0.0
wandb: 
wandb: ðŸš€ View run volcanic-butterfly-780 at: https://wandb.ai/nreints/ThesisFinal2/runs/ks37hjji
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_170621-ks37hjji/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_171750-1mc6xbvs
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run denim-plant-809
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/1mc6xbvs
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue â–ƒâ–‚â–‚â–‚â–‚â–â–â–ˆâ–â–
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue â–‡â–‡â–†â–…â–„â–‚â–â–ˆâ–â–
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue â–‚â–‚â–‚â–‚â–â–â–â–ˆâ–â–
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue â–‚â–‚â–‚â–‚â–â–â–â–ˆâ–â–
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue 1e-05
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue 1e-05
wandb:                                 Train loss 0.0
wandb: 
wandb: ðŸš€ View run denim-plant-809 at: https://wandb.ai/nreints/ThesisFinal2/runs/1mc6xbvs
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_171750-1mc6xbvs/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_172916-4nm6xx1h
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run trim-lion-836
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/4nm6xx1h
	 Logging test loss: 8.191e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 7.965e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.752e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 8.148e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 58.10915660858154
Epoch 5/9
	 Logging train Loss: 3.3656e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.072e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 4e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.936e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 4.059e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 57.884886503219604
Epoch 6/9
	 Logging train Loss: 4.7811e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.072e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 4.269e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.488e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 4.899e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 57.95892357826233
Epoch 7/9
	 Logging train Loss: 9.6655e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.033e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.007e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.985e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.029e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 57.92964315414429
Epoch 8/9
	 Logging train Loss: 6.738e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.18e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.162e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.145e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.177e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 57.590296268463135
Epoch 9/9
	 Logging train Loss: 3.3892e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.259e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.961e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.688e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.232e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 57.95719122886658
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'rot_mat_1'_'False'.pth
It took  689.0935063362122  seconds.
----- ITERATION 3/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 48.486544370651245 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pNone_gTrue took 12.070894241333008 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 12.180660724639893 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pNone_gTrue took 12.552808046340942 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pNone_gTrue took 12.620875835418701 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0146539528 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.27305e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.57928e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.12986e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.19043e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 57.39553165435791
Epoch 1/9
	 Logging train Loss: 1.3425e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.26812e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.12542e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.03054e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.25026e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 57.571425437927246
Epoch 2/9
	 Logging train Loss: 1.06337e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.06111e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 9.9734e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 9.5423e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.05274e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 57.24751329421997
Epoch 3/9
	 Logging train Loss: 9.1682e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.6188e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 8.2822e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.061e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 8.5724e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 57.43760323524475
Epoch 4/9
	 Logging train Loss: 7.3197e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.2505e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 6.0628e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.9402e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 6.2236e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 57.20516300201416
Epoch 5/9
	 Logging train Loss: 4.6244e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.0564e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.9412e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.8644e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.0408e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 57.71285629272461
Epoch 6/9
	 Logging train Loss: 2.798e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.988e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 6.303e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.823e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 6.906e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 57.59559416770935
Epoch 7/9
	 Logging train Loss: 5.1797e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0001091857 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 5.51157e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.24445e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 0.0001064325 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 57.61217713356018
Epoch 8/9
	 Logging train Loss: 3.4146e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.036e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.761e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.562e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.007e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 57.84172439575195
Epoch 9/9
	 Logging train Loss: 3.2014e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.8398e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.254e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.67e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 6.5965e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 57.762065172195435
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'rot_mat_1'_'False'.pth
It took  685.9862670898438  seconds.
----- ITERATION 4/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 48.51206040382385 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pNone_gTrue took 12.375237226486206 seconds.
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue â–‚â–‚â–‚â–â–â–â–â–ˆâ–„â–
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue â–ˆâ–‡â–†â–ƒâ–‚â–â–â–…â–ƒâ–‚
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue â–‚â–â–â–â–â–â–â–ˆâ–„â–
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue â–‚â–â–â–â–â–â–â–ˆâ–„â–
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue 0.0
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue 0.0
wandb:                                 Train loss 0.0
wandb: 
wandb: ðŸš€ View run trim-lion-836 at: https://wandb.ai/nreints/ThesisFinal2/runs/4nm6xx1h
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_172916-4nm6xx1h/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_174029-emyik8th
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ethereal-cloud-863
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/emyik8th
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 12.172726154327393 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pNone_gTrue took 12.527207612991333 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pNone_gTrue took 12.821776866912842 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0287598092 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.746e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.42316e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.08711e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.70632e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 56.247453451156616
Epoch 1/9
	 Logging train Loss: 1.19361e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.13766e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.03137e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 9.2378e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.12587e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 55.911423683166504
Epoch 2/9
	 Logging train Loss: 8.8056e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.0964e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 7.6964e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.2901e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 8.054e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 56.16538643836975
Epoch 3/9
	 Logging train Loss: 5.9332e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.4655e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 4.2891e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.0992e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 4.4481e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 56.42114305496216
Epoch 4/9
	 Logging train Loss: 2.8443e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.5672e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.4632e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.3495e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.5571e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 56.17011046409607
Epoch 5/9
	 Logging train Loss: 1.0184e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.668e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 5.118e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.525e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 5.617e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 56.10810589790344
Epoch 6/9
	 Logging train Loss: 2.378e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.724e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 5.21e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.771e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 6.529e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 55.93674349784851
Epoch 7/9
	 Logging train Loss: 4.768e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.000188802 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 9.44738e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.3259e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 0.0001732918 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 56.54736638069153
Epoch 8/9
	 Logging train Loss: 5.5152e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 9.01128e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 4.62604e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.1102e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 8.42338e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 56.770519733428955
Epoch 9/9
	 Logging train Loss: 3.5565e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.4482e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.4084e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.3675e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.4445e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 56.85878896713257
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'rot_mat_1'_'False'.pth
It took  672.9630336761475  seconds.
----- ITERATION 5/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 48.3184700012207 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pNone_gTrue took 12.50687861442566 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 12.139784336090088 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pNone_gTrue took 12.473503828048706 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pNone_gTrue took 12.461296558380127 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.028889725 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.82267e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.46227e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.09621e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.79759e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 57.1213014125824
Epoch 1/9
	 Logging train Loss: 1.14329e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.01985e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 9.2652e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.3241e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.01382e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 56.7873432636261
Epoch 2/9
	 Logging train Loss: 7.5104e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.9772e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 5.5516e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.1159e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 5.952e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 56.90550637245178
Epoch 3/9
	 Logging train Loss: 3.9877e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.8983e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.493e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.1052e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.8593e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 56.88898229598999
Epoch 4/9
	 Logging train Loss: 5.9564e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.068e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 6.608e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.106e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 8.055e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 57.22846078872681
Epoch 5/9
	 Logging train Loss: 4.9317e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.168e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 4.421e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.668e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue â–…â–„â–ƒâ–‚â–â–â–â–â–ˆâ–
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue â–„â–ƒâ–‚â–‚â–â–â–â–â–ˆâ–
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue â–†â–„â–ƒâ–‚â–â–â–â–â–ˆâ–‚
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue â–†â–„â–ƒâ–‚â–â–â–â–â–ˆâ–‚
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue 0.0
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue 0.0
wandb:                                 Train loss 0.0
wandb: 
wandb: ðŸš€ View run ethereal-cloud-863 at: https://wandb.ai/nreints/ThesisFinal2/runs/emyik8th
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_174029-emyik8th/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_175152-n3cbakvo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run exalted-firefly-892
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/n3cbakvo
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue â–ˆâ–„â–‚â–â–â–‚â–â–â–â–„
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue â–ˆâ–…â–ƒâ–‚â–â–â–â–â–â–‚
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue â–ˆâ–„â–‚â–â–â–‚â–â–â–â–„
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue â–ˆâ–„â–‚â–â–â–‚â–â–â–â–…
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 1e-05
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue 1e-05
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue 1e-05
wandb:                                 Train loss 0.0
wandb: 
wandb: ðŸš€ View run exalted-firefly-892 at: https://wandb.ai/nreints/ThesisFinal2/runs/n3cbakvo
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_175152-n3cbakvo/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_180309-btphanjr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run peach-dawn-924
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/btphanjr
	 Logging test loss: 5.151e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 57.67610764503479
Epoch 6/9
	 Logging train Loss: 5.8011e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.474e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 4.017e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.593e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 4.424e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 57.76200771331787
Epoch 7/9
	 Logging train Loss: 6.4113e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.841e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.741e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.64e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.837e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 58.04760503768921
Epoch 8/9
	 Logging train Loss: 2.0359e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.47976e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.46535e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.45198e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.47734e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 57.56721782684326
Epoch 9/9
	 Logging train Loss: 4.0955e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.2948e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.2062e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.814e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.0728e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 57.676350116729736
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'rot_mat_1'_'False'.pth
It took  683.0324988365173  seconds.
----- ITERATION 6/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 48.366997957229614 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pNone_gTrue took 12.381772518157959 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 12.139892339706421 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pNone_gTrue took 12.459079027175903 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pNone_gTrue took 12.510732650756836 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0081075905 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.03555e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.40172e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 9.0405e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.85003e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 56.51936674118042
Epoch 1/9
	 Logging train Loss: 9.7413e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.8171e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 6.6844e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.7683e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 7.4751e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 56.74449181556702
Epoch 2/9
	 Logging train Loss: 4.7119e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.2663e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.8804e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.5674e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.1474e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 56.902769804000854
Epoch 3/9
	 Logging train Loss: 1.7044e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.1874e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 9.999e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.505e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.1329e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 56.76726055145264
Epoch 4/9
	 Logging train Loss: 6.555e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.151e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 4.214e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.475e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 4.893e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 56.8108184337616
Epoch 5/9
	 Logging train Loss: 6.778e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.5715e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.8661e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.887e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.1535e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 56.699000120162964
Epoch 6/9
	 Logging train Loss: 3.4616e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.584e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.274e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.026e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.496e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 56.57473587989807
Epoch 7/9
	 Logging train Loss: 5.4866e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.946e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 4.115e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.553e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 5.323e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 56.69121313095093
Epoch 8/9
	 Logging train Loss: 4.7983e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.401e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.261e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.147e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.36e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 56.878443002700806
Epoch 9/9
	 Logging train Loss: 4.407e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.04844e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 5.8273e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.7456e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 8.9527e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 56.463911294937134
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'rot_mat_1'_'False'.pth
It took  677.0244219303131  seconds.
----- ITERATION 7/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 50.37784194946289 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pNone_gTrue took 12.58852243423462 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 12.531999588012695 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pNone_gTrue took 12.605782508850098 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pNone_gTrue took 12.579609870910645 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0182389002 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.69664e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue â–ˆâ–†â–…â–ƒâ–‚â–â–â–â–â–
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue â–ˆâ–‡â–†â–„â–‚â–â–â–â–â–
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue â–ˆâ–…â–„â–ƒâ–‚â–â–â–â–â–
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue â–ˆâ–…â–„â–ƒâ–‚â–â–â–â–â–
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue 0.0
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue 0.0
wandb:                                 Train loss 0.0
wandb: 
wandb: ðŸš€ View run peach-dawn-924 at: https://wandb.ai/nreints/ThesisFinal2/runs/btphanjr
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_180309-btphanjr/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_181440-j9b6cgqb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run laced-donkey-953
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/j9b6cgqb
	 Logging test loss: 1.32388e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.00665e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.64142e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 56.969350814819336
Epoch 1/9
	 Logging train Loss: 1.08585e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 9.9778e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 9.312e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.7354e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 9.8474e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 57.345903396606445
Epoch 2/9
	 Logging train Loss: 8.2533e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.4905e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 7.2594e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.0565e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 7.4412e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 56.901017904281616
Epoch 3/9
	 Logging train Loss: 5.9933e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.8802e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 4.7223e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.5866e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 4.8439e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 56.98381066322327
Epoch 4/9
	 Logging train Loss: 3.1292e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.8466e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.7565e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.679e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.8283e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 56.93995904922485
Epoch 5/9
	 Logging train Loss: 2.825e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.973e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 5.502e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.109e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 5.883e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 57.79853892326355
Epoch 6/9
	 Logging train Loss: 2.9724e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.657e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 4.377e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.15e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 4.605e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 58.11117482185364
Epoch 7/9
	 Logging train Loss: 5.624e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.043e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.866e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.723e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 4.011e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 58.52721047401428
Epoch 8/9
	 Logging train Loss: 1.0455e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.823e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 5.748e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.861e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 6.569e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 58.71158838272095
Epoch 9/9
	 Logging train Loss: 4.1038e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.868e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.781e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.712e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.854e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 57.535664319992065
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'rot_mat_1'_'False'.pth
It took  691.1674075126648  seconds.
----- ITERATION 8/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 50.143585205078125 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pNone_gTrue took 12.618435859680176 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 12.59481406211853 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pNone_gTrue took 12.579518795013428 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pNone_gTrue took 12.580270290374756 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0109035242 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.87434e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.45636e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.14771e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.80054e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 57.390146255493164
Epoch 1/9
	 Logging train Loss: 1.20101e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.08817e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 9.8671e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 9.0995e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.07178e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 57.69968247413635
Epoch 2/9
	 Logging train Loss: 8.7055e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.9923e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 7.38e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.9173e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 7.8955e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 57.306209325790405
Epoch 3/9
	 Logging train Loss: 6.1997e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.1634e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 4.7766e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.4797e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 5.1016e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 57.497437953948975
Epoch 4/9
	 Logging train Loss: 3.5186e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.4592e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.2571e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.1032e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.4267e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 57.506853103637695
Epoch 5/9
	 Logging train Loss: 1.3391e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.002e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 6.251e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.674e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 6.873e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 57.442225217819214
Epoch 6/9
	 Logging train Loss: 5.353e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.23e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 4.029e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.873e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 4.192e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 57.48692607879639
Epoch 7/9
	 Logging train Loss: 4.618e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue â–ƒâ–‚â–‚â–‚â–â–â–â–â–ˆâ–
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue â–ˆâ–‡â–…â–„â–‚â–â–â–â–…â–
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue â–‚â–‚â–‚â–â–â–â–â–â–ˆâ–
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue â–‚â–‚â–â–â–â–â–â–â–ˆâ–
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue 0.0
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue 0.0
wandb:                                 Train loss 0.0
wandb: 
wandb: ðŸš€ View run laced-donkey-953 at: https://wandb.ai/nreints/ThesisFinal2/runs/j9b6cgqb
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_181440-j9b6cgqb/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_182607-fb2bjxuy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rich-meadow-981
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/fb2bjxuy
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue â–ˆâ–†â–…â–ƒâ–‚â–ƒâ–ƒâ–â–â–
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue â–ˆâ–‡â–†â–„â–‚â–‚â–â–â–â–
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue â–ˆâ–…â–„â–ƒâ–‚â–„â–„â–â–â–
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue â–ˆâ–…â–„â–ƒâ–‚â–„â–„â–â–â–
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue 0.0
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue 0.0
wandb:                                 Train loss 0.0
wandb: 
wandb: ðŸš€ View run rich-meadow-981 at: https://wandb.ai/nreints/ThesisFinal2/runs/fb2bjxuy
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_182607-fb2bjxuy/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_183725-ootqlxph
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run firm-lion-1013
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/ootqlxph
	 Logging test loss: 3.247e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.173e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.119e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.234e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 57.70372819900513
Epoch 8/9
	 Logging train Loss: 1.7056e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0001103761 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 5.05281e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.8072e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 9.67545e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 57.309375286102295
Epoch 9/9
	 Logging train Loss: 3.4708e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.521e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.488e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.463e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.516e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 57.36564517021179
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'rot_mat_1'_'False'.pth
It took  687.0954270362854  seconds.
----- ITERATION 9/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 50.36943173408508 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pNone_gTrue took 12.651881217956543 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 12.572715997695923 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pNone_gTrue took 12.641432046890259 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pNone_gTrue took 12.635984420776367 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0131637994 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.89668e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.54087e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.13114e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.92087e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 55.92091464996338
Epoch 1/9
	 Logging train Loss: 1.25017e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.20768e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.10119e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 9.7916e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.21261e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 56.3484206199646
Epoch 2/9
	 Logging train Loss: 9.6253e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 9.1371e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 8.7553e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.3067e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 9.1598e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 56.017165422439575
Epoch 3/9
	 Logging train Loss: 6.8379e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.3343e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 5.2249e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.0948e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 5.3432e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 55.962589740753174
Epoch 4/9
	 Logging train Loss: 3.6034e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.9903e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.9406e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.8835e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.9929e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 55.9364800453186
Epoch 5/9
	 Logging train Loss: 2.1871e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.6949e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 5.1441e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.1678e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 8.8201e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 55.95455837249756
Epoch 6/9
	 Logging train Loss: 3.1516e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.8217e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 5.0271e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.349e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 8.9835e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 55.907382011413574
Epoch 7/9
	 Logging train Loss: 4.0445e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.42e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.31e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.186e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.422e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 55.87082600593567
Epoch 8/9
	 Logging train Loss: 4.765e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.258e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 4.094e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.902e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 4.266e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 57.775869607925415
Epoch 9/9
	 Logging train Loss: 3.7088e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.475e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.426e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.371e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.478e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 57.67024493217468
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'rot_mat_1'_'False'.pth
It took  677.1996977329254  seconds.
----- ITERATION 10/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 50.11940550804138 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pNone_gTrue took 12.661213159561157 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 12.621941328048706 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pNone_gTrue took 12.61542296409607 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pNone_gTrue took 12.619646549224854 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0092983479 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.05173e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.86455e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.20894e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 6.27005e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 57.60140013694763
Epoch 1/9
	 Logging train Loss: 2.41852e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.05715e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.46688e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 9.6657e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.93179e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue â–ˆâ–ƒâ–ƒâ–‚â–â–â–ƒâ–ƒâ–ˆâ–ƒ
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue â–‡â–†â–…â–„â–‚â–â–â–â–ˆâ–
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue â–ˆâ–ƒâ–‚â–‚â–â–â–ƒâ–ƒâ–ˆâ–ƒ
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue â–ˆâ–ƒâ–‚â–‚â–â–â–„â–ƒâ–ˆâ–ƒ
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 1e-05
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue 2e-05
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue 2e-05
wandb:                                 Train loss 1e-05
wandb: 
wandb: ðŸš€ View run firm-lion-1013 at: https://wandb.ai/nreints/ThesisFinal2/runs/ootqlxph
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_183725-ootqlxph/logs
		--> Epoch time; 57.802391052246094
Epoch 2/9
	 Logging train Loss: 1.20649e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.18752e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 9.8582e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.1732e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.13583e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 57.86545658111572
Epoch 3/9
	 Logging train Loss: 8.6425e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.1546e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 7.2038e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.411e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 7.9192e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 57.81726360321045
Epoch 4/9
	 Logging train Loss: 5.8181e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.6255e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 4.208e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.8534e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 4.5343e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 57.66075372695923
Epoch 5/9
	 Logging train Loss: 2.802e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.6458e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.4795e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.3359e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.6155e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 57.958362340927124
Epoch 6/9
	 Logging train Loss: 6.3979e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.77727e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.34146e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.5941e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.45273e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 57.75788950920105
Epoch 7/9
	 Logging train Loss: 1.7353e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.05429e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.02607e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.8201e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.86116e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 57.871509075164795
Epoch 8/9
	 Logging train Loss: 5.2075e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.12443e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 4.02762e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.32235e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 6.70061e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 58.59044027328491
Epoch 9/9
	 Logging train Loss: 6.2902e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.33858e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.14606e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.4163e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.15859e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 58.615886211395264
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'rot_mat_1'_'False'.pth
It took  693.2257866859436  seconds.

JOB STATISTICS
==============
Job ID: 3037748
Array Job ID: 3037727_41
Cluster: snellius
User/Group: nreints/nreints
State: COMPLETED (exit code 0)
Nodes: 1
Cores per node: 18
CPU Utilized: 02:01:34
CPU Efficiency: 5.90% of 1-10:19:30 core-walltime
Job Wall-clock time: 01:54:25
Memory Utilized: 8.44 GB
Memory Efficiency: 0.00% of 0.00 MB
