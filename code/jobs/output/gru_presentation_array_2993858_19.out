wandb: Currently logged in as: nreints. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230629_204504-wq3wh5iq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run snowy-plant-412
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/wq3wh5iq
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone █▅▃▃▂▂▁▁▁▁
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone █▅▃▃▂▂▁▁▁▁
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone █▄▃▂▂▂▁▁▁▁
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone █▅▃▂▂▂▁▁▁▁
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone █▅▃▃▂▂▁▁▁▁
wandb:                                   Train loss █▃▂▂▂▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone 1.52092
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 1.69705
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone 0.81627
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 1.48611
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 1.84132
wandb:                                   Train loss 1.33669
wandb: 
wandb: 🚀 View run snowy-plant-412 at: https://wandb.ai/nreints/ThesisFinal2/runs/wq3wh5iq
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230629_204504-wq3wh5iq/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230629_205706-hhq6yik4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run mild-oath-415
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/hhq6yik4
Training on dataset: data_t(5,20)_r(5,20)_combi_pNone_gNone
Testing on 5 datasets: ['data_t(5,20)_r(5,20)_combi_pNone_gNone', 'data_t(5,20)_r(5,20)_none_pNone_gNone', 'data_t(5,20)_r(5,20)_full_pNone_gNone', 'data_t(5,20)_r(5,20)_tennis_pNone_gNone', 'data_t(5,20)_r(5,20)_semi_pNone_gNone']
Focussing on identity: False
Using extra input: False
Using start-fr as reference point.
----- ITERATION 1/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 103.52100157737732 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 26.051355600357056 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_none_pNone_gNone took 25.95801067352295 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 25.82584810256958 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 25.91880440711975 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 25.795297861099243 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(6, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=6, bias=True)
)
Datatype: log_dualQ
-- Started Training --
Epoch 0/9
	 Logging train Loss: 9.4381809235 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.0238413811 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.6887392998 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 4.2214813232 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 6.9180960655 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 5.929420948 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 48.79496455192566
Epoch 1/9
	 Logging train Loss: 3.8825821877 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.3537971973 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.6906553507 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.9777653217 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.5748305321 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.8170244694 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 47.036428689956665
Epoch 2/9
	 Logging train Loss: 2.7760961056 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.6539354324 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.3335869312 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.4727375507 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.5618071556 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.9384367466 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 46.68764781951904
Epoch 3/9
	 Logging train Loss: 2.2556829453 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.2805390358 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.1752345562 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.2388362885 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.9614937305 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.4321668148 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 46.82900857925415
Epoch 4/9
	 Logging train Loss: 1.9363070726 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.0260403156 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.0670104027 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.0784404278 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.5782198906 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.1154682636 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 46.8643741607666
Epoch 5/9
	 Logging train Loss: 1.7299180031 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.8865172863 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.007143259 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.9741820097 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.3429226875 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.9320366383 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 46.742971658706665
Epoch 6/9
	 Logging train Loss: 1.582991004 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.7081184387 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.8952941298 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.82619524 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.1312727928 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.7339366674 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 47.05924081802368
Epoch 7/9
	 Logging train Loss: 1.481166482 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.6244580746 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.8391532302 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.7922399044 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.9894474745 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.6110285521 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 46.8302743434906
Epoch 8/9
	 Logging train Loss: 1.399161458 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.5645747185 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.8040274978 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.7573741674 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.9039273262 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.5435353518 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 46.78604578971863
Epoch 9/9
	 Logging train Loss: 1.3366929293 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.5209228992 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.8162688613 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.6970512867 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.8413164616 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.4861075878 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 46.85078191757202
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gNone/'log_dualQ'_'False'.pth
It took  722.5344622135162  seconds.
----- ITERATION 2/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 93.45638012886047 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 23.420607089996338 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_none_pNone_gNone took 23.597467184066772 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 23.50652837753296 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 23.65108609199524 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 23.704716205596924 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(6, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=6, bias=True)
)
Datatype: log_dualQ
-- Started Training --
Epoch 0/9
	 Logging train Loss: 7.5600185394 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.8287433386 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.1325308084 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.72433424 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.1846768856 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.6386940479 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 47.32515907287598
Epoch 1/9
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone █▄▃▂▂▁▁▁▁▁
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone █▄▃▃▂▂▂▁▁▁
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone █▄▃▂▂▁▁▁▁▁
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone █▃▂▂▂▁▁▁▁▁
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone █▃▂▂▂▁▁▁▁▁
wandb:                                   Train loss █▂▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone 0.40948
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 0.93902
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone 0.16475
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 0.17097
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 0.31908
wandb:                                   Train loss 0.36782
wandb: 
wandb: 🚀 View run mild-oath-415 at: https://wandb.ai/nreints/ThesisFinal2/runs/hhq6yik4
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230629_205706-hhq6yik4/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230629_210841-9co9cune
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run young-water-417
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/9co9cune
	 Logging train Loss: 1.2930089235 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.9647666812 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.5406067967 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.7684650421 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.9545260668 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.6134608388 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 47.06057643890381
Epoch 2/9
	 Logging train Loss: 0.8107768297 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.7529255748 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.3920309842 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.5123487711 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.693264544 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.4200729132 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 47.07754445075989
Epoch 3/9
	 Logging train Loss: 0.6393806934 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.6451765895 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.3191821277 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.3436851501 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.5711352229 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.3409108222 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 47.24134135246277
Epoch 4/9
	 Logging train Loss: 0.5476381779 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.5934089422 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.2709278166 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.2749019861 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.4968422353 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.2810926437 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 46.85937571525574
Epoch 5/9
	 Logging train Loss: 0.4914749265 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.5019733906 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.2217830122 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.1145739555 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.422093302 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.2308729738 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 46.949440717697144
Epoch 6/9
	 Logging train Loss: 0.4451025128 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.4701545835 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.1917178482 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.086656332 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.3833295405 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.2045597583 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 47.15664076805115
Epoch 7/9
	 Logging train Loss: 0.409532547 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.4542981088 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.20375745 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.0206902027 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.372636646 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.206253916 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 46.96777391433716
Epoch 8/9
	 Logging train Loss: 0.3932362795 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.4274092019 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.17727305 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.9819088578 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.3440951407 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.1802334338 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 47.086928367614746
Epoch 9/9
	 Logging train Loss: 0.3678222597 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.4094751775 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.1647468954 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.9390153289 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.3190756142 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.1709701717 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 46.95147752761841
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gNone/'log_dualQ'_'False'.pth
It took  694.9915614128113  seconds.
----- ITERATION 3/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 93.09318161010742 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 23.308551788330078 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_none_pNone_gNone took 23.400386571884155 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 23.406914949417114 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 23.38391661643982 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 23.44446086883545 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(6, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=6, bias=True)
)
Datatype: log_dualQ
-- Started Training --
Epoch 0/9
	 Logging train Loss: 8.1872711182 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.0489251614 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.2769601345 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.9501268864 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.3890538216 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.5613688231 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 46.94636845588684
Epoch 1/9
	 Logging train Loss: 1.3872908354 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.0283020735 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.5917978287 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.9526458979 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.0386558771 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.5866459608 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 46.92085266113281
Epoch 2/9
	 Logging train Loss: 0.8578932881 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.783462882 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.4533897638 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.5924088955 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.7130427957 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.3980464339 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 46.81794047355652
Epoch 3/9
	 Logging train Loss: 0.6679222584 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.6357693076 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.34212026 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.3711872101 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.5554336309 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.3167667985 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 47.32093906402588
Epoch 4/9
	 Logging train Loss: 0.5600301027 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.5502121449 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.2912054658 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone █▄▃▂▂▁▁▁▁▁
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone █▅▃▃▂▂▁▁▁▁
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone █▄▃▂▂▁▁▁▁▁
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone █▃▂▂▁▁▁▁▁▁
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone █▃▂▂▂▁▁▁▁▁
wandb:                                   Train loss █▂▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone 0.38931
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 0.93755
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone 0.2067
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 0.17058
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 0.30773
wandb:                                   Train loss 0.35028
wandb: 
wandb: 🚀 View run young-water-417 at: https://wandb.ai/nreints/ThesisFinal2/runs/9co9cune
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230629_210841-9co9cune/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230629_212015-s7j9y320
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run breezy-puddle-420
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/s7j9y320
	 Logging test loss: 1.2262653112 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.4610635042 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.257892251 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 47.591065406799316
Epoch 5/9
	 Logging train Loss: 0.4899197221 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.4944258332 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.2542559505 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.1363503933 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.405880034 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.2290499806 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 47.665305852890015
Epoch 6/9
	 Logging train Loss: 0.4446509182 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.4586502612 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.2449489236 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.0513288975 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.3581493795 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.200333938 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 47.26373219490051
Epoch 7/9
	 Logging train Loss: 0.404609859 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.4079073071 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.2019724846 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.9765554667 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.3136219978 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.1775568277 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 46.974833488464355
Epoch 8/9
	 Logging train Loss: 0.3767814636 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.3990675807 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.2031829804 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.9449675679 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.3119030595 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.1746291816 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 47.09149932861328
Epoch 9/9
	 Logging train Loss: 0.3502845466 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.3893125355 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.2067006677 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.937549293 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.3077339232 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.1705774814 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 47.043968200683594
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gNone/'log_dualQ'_'False'.pth
It took  693.9347879886627  seconds.
----- ITERATION 4/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 92.88312530517578 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 23.313032627105713 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_none_pNone_gNone took 23.499004125595093 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 23.420963525772095 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 23.37626004219055 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 23.46345543861389 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(6, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=6, bias=True)
)
Datatype: log_dualQ
-- Started Training --
Epoch 0/9
	 Logging train Loss: 5.8118872643 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.4053823948 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.8811991811 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.5053749084 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.4568793774 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.9861209989 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 47.07546901702881
Epoch 1/9
	 Logging train Loss: 1.1525691748 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.9169766903 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.5225208998 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.8798767328 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.8743730187 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.5515798926 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 47.2410409450531
Epoch 2/9
	 Logging train Loss: 0.8352845907 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.7318382859 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.4069997966 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.5732195377 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.6802347302 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.4345201254 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 47.15233659744263
Epoch 3/9
	 Logging train Loss: 0.6766691208 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.5928744078 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.3021042943 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.3780310154 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.5256534219 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.3217430711 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 47.126795530319214
Epoch 4/9
	 Logging train Loss: 0.581808269 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.5138174891 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.2398304343 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.2340809107 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.4526583552 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.2669081688 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 46.93077540397644
Epoch 5/9
	 Logging train Loss: 0.5164551735 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.4794678688 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.2319047153 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.1286907196 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.4148007035 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.2517325282 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 47.24322271347046
Epoch 6/9
	 Logging train Loss: 0.4584959447 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.4515680671 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.2067136168 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.0757600069 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.3800513148 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.2289056033 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 47.00484323501587
Epoch 7/9
	 Logging train Loss: 0.4228929579 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.4227326512 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.19247742 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.0231045485 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.3414529264 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.2031706721 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 46.99048733711243
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone █▅▃▂▂▂▂▁▁▁
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone █▅▄▃▂▂▂▁▁▁
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone █▄▃▂▂▂▁▁▁▁
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone █▄▃▂▂▂▁▁▁▁
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone █▄▃▂▂▂▁▁▁▁
wandb:                                   Train loss █▂▂▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone 0.37381
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 0.92899
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone 0.1727
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 0.18382
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 0.30437
wandb:                                   Train loss 0.36926
wandb: 
wandb: 🚀 View run breezy-puddle-420 at: https://wandb.ai/nreints/ThesisFinal2/runs/s7j9y320
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230629_212015-s7j9y320/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230629_213150-j3xlohf4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cerulean-wave-422
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/j3xlohf4
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone █▃▂▂▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone █▄▃▂▂▂▁▁▁▁
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone █▃▂▂▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone █▃▂▁▁▁▁▁▁▁
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone █▃▂▁▁▁▁▁▁▁
wandb:                                   Train loss █▃▂▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone 0.44383
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 0.92269
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone 0.19725
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 0.20614
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 0.36245
wandb:                                   Train loss 0.34255
wandb: 
wandb: 🚀 View run cerulean-wave-422 at: https://wandb.ai/nreints/ThesisFinal2/runs/j3xlohf4
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230629_213150-j3xlohf4/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230629_214324-v9gzk4tu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run mild-bee-425
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/v9gzk4tu
Epoch 8/9
	 Logging train Loss: 0.3962208033 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.4068422616 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.1824785918 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.9911077023 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.332133621 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.201271683 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 47.129207134246826
Epoch 9/9
	 Logging train Loss: 0.3692573905 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.3738104701 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.1726980954 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.928988874 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.3043654859 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.183824867 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 47.50308036804199
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gNone/'log_dualQ'_'False'.pth
It took  695.7499115467072  seconds.
----- ITERATION 5/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 92.7524664402008 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 23.206834316253662 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_none_pNone_gNone took 23.370563507080078 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 23.35646939277649 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 23.36297082901001 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 23.40329098701477 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(6, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=6, bias=True)
)
Datatype: log_dualQ
-- Started Training --
Epoch 0/9
	 Logging train Loss: 9.6179361343 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.6100902557 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.384360075 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.8576657772 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 6.2371530533 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 5.5754208565 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 46.89765119552612
Epoch 1/9
	 Logging train Loss: 2.6911449432 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.7046999931 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.9163688421 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.2838816643 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.9918043613 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.4227520227 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 46.99405288696289
Epoch 2/9
	 Logging train Loss: 1.1754608154 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.0378789902 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.5085726976 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.7192685604 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.0555919409 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.6770524979 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 46.974366664886475
Epoch 3/9
	 Logging train Loss: 0.7691665292 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.7821643353 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.3644769192 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.4077371359 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.712695837 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.4365194142 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 46.851322174072266
Epoch 4/9
	 Logging train Loss: 0.5974730253 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.6502041221 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.2863593102 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.2312306166 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.5488344431 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.3243116438 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 47.1387403011322
Epoch 5/9
	 Logging train Loss: 0.5026345253 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.5649552345 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.2359500676 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.1228101254 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.4796952009 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.2709775567 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 47.353928565979004
Epoch 6/9
	 Logging train Loss: 0.440782845 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.520673573 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.2175236344 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.0359433889 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.4348107576 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.2562475204 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 47.243393421173096
Epoch 7/9
	 Logging train Loss: 0.3975501359 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.4773216546 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.1883285195 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.97812289 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.3879006207 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.212031275 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 47.019808292388916
Epoch 8/9
	 Logging train Loss: 0.3669547141 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.4380908608 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.1808954924 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.909266293 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.3457161486 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.1986855716 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 47.07437014579773
Epoch 9/9
	 Logging train Loss: 0.3425510228 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.4438338578 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.197249651 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.9226907492 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.3624462187 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.2061416507 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 47.1228461265564
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gNone/'log_dualQ'_'False'.pth
It took  693.9948809146881  seconds.
----- ITERATION 6/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 92.47860264778137 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 23.222247838974 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_none_pNone_gNone took 23.358823776245117 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 23.25930619239807 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 23.330820560455322 seconds.
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone █▄▃▂▂▂▁▁▁▁
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone █▅▄▃▂▂▂▁▂▁
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone █▄▃▂▂▂▁▁▁▁
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone █▄▃▂▂▂▁▁▁▁
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone █▄▃▂▂▂▁▁▁▁
wandb:                                   Train loss █▂▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone 0.40487
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 0.98803
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone 0.15372
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 0.19181
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 0.2883
wandb:                                   Train loss 0.36967
wandb: 
wandb: 🚀 View run mild-bee-425 at: https://wandb.ai/nreints/ThesisFinal2/runs/v9gzk4tu
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230629_214324-v9gzk4tu/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230629_215458-9tqu56wn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dashing-night-427
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/9tqu56wn
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 23.28733491897583 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(6, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=6, bias=True)
)
Datatype: log_dualQ
-- Started Training --
Epoch 0/9
	 Logging train Loss: 6.5238633156 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.687497735 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.0043315887 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.5319035053 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.626963973 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.248918891 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 47.16405749320984
Epoch 1/9
	 Logging train Loss: 1.1677091122 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.0323697329 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.5537388921 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.895275712 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.8902865648 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.6416450739 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 47.65527844429016
Epoch 2/9
	 Logging train Loss: 0.8070237637 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.782879591 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.3678945601 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.5741961002 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.6373844743 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.4485024512 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 46.894291162490845
Epoch 3/9
	 Logging train Loss: 0.6483627558 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.6751970649 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.3121033907 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.4143745899 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.5129538178 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.3604523838 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 46.81903553009033
Epoch 4/9
	 Logging train Loss: 0.5568583012 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.5655388236 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.241466105 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.2495985031 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.4263206124 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.2963004708 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 47.05902695655823
Epoch 5/9
	 Logging train Loss: 0.4959598184 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.5493734479 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.2455087453 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.2160927057 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.4234707654 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.2926205695 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 47.12710738182068
Epoch 6/9
	 Logging train Loss: 0.4494740665 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.4873100817 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.2003619969 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.1310486794 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.3584465981 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.240568161 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 47.068371534347534
Epoch 7/9
	 Logging train Loss: 0.416146636 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.4383206367 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.1720365137 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.0547795296 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.320119679 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.2194201201 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 46.79329562187195
Epoch 8/9
	 Logging train Loss: 0.3875859082 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.4723807275 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.1953630894 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.1101722717 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.3325384855 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.2267291695 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 46.95961356163025
Epoch 9/9
	 Logging train Loss: 0.3696717024 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.4048707187 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.1537157148 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.9880300164 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.2883023024 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.1918070018 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 46.871275424957275
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gNone/'log_dualQ'_'False'.pth
It took  693.803338766098  seconds.
----- ITERATION 7/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 92.912273645401 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 23.304752826690674 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_none_pNone_gNone took 23.325944185256958 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 23.306269884109497 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 23.3275785446167 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 23.50471043586731 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(6, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=6, bias=True)
)
Datatype: log_dualQ
-- Started Training --
Epoch 0/9
	 Logging train Loss: 8.8127508163 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.8880441189 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.6502846479 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.2361998558 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.7553939819 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.8883953094 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 46.75796437263489
Epoch 1/9
	 Logging train Loss: 1.7767256498 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.2174550295 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.7059419155 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.9309406281 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.337818861 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.8262121081 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 47.07434105873108
Epoch 2/9
	 Logging train Loss: 0.942168653 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.8280271888 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.4275087118 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.5551532507 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.8310334682 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.4659851491 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 46.77245855331421
Epoch 3/9
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone █▃▂▂▂▁▁▁▁▁
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone █▄▃▂▂▂▁▁▁▁
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone █▄▂▂▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone █▃▂▁▁▁▁▁▁▁
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone █▃▂▂▁▁▁▁▁▁
wandb:                                   Train loss █▂▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone 0.36802
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 0.86301
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone 0.15902
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 0.14665
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 0.30558
wandb:                                   Train loss 0.35503
wandb: 
wandb: 🚀 View run dashing-night-427 at: https://wandb.ai/nreints/ThesisFinal2/runs/9tqu56wn
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230629_215458-9tqu56wn/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230629_220632-gx3jsr9y
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run misty-wind-429
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/gx3jsr9y
	 Logging train Loss: 0.6856682897 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.6308677793 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.2977164984 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.3052985668 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.5964468718 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.3038964272 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 46.727001667022705
Epoch 4/9
	 Logging train Loss: 0.5652548075 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.5491485596 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.2614413798 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.1784210205 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.5009070039 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.2551179826 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 46.613102436065674
Epoch 5/9
	 Logging train Loss: 0.4886637032 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.5058495998 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.2390120924 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.1214859486 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.4474514723 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.2273841202 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 47.38425397872925
Epoch 6/9
	 Logging train Loss: 0.4387249649 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.4419585168 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.1901383996 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.0050755739 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.3771793544 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.1762875468 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 47.637038230895996
Epoch 7/9
	 Logging train Loss: 0.4039349258 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.4288109839 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.1917087734 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.9997419715 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.364223212 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.1760983467 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 46.91763472557068
Epoch 8/9
	 Logging train Loss: 0.377939254 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.3932476342 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.1691733599 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.9212912321 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.3299981058 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.1578457505 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 46.877586126327515
Epoch 9/9
	 Logging train Loss: 0.3550293148 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.3680166602 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.1590246707 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.8630065322 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.3055793047 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.14665474 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 47.00077843666077
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gNone/'log_dualQ'_'False'.pth
It took  693.9929127693176  seconds.
----- ITERATION 8/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 92.66997790336609 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 23.218223333358765 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_none_pNone_gNone took 23.372496843338013 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 23.301377296447754 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 23.253832817077637 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 23.263410329818726 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(6, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=6, bias=True)
)
Datatype: log_dualQ
-- Started Training --
Epoch 0/9
	 Logging train Loss: 9.2783117294 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.8098897934 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.3537592888 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.8586711884 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 6.7037210464 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 5.8113164902 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 46.119911432266235
Epoch 1/9
	 Logging train Loss: 3.7722759247 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.237102747 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.5426883698 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.9234676361 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.4443507195 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.6980969906 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 46.05394744873047
Epoch 2/9
	 Logging train Loss: 2.7325456142 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.5788607597 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.2512544394 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.4830925465 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.459592104 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.8144841194 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 45.96768403053284
Epoch 3/9
	 Logging train Loss: 2.2261705399 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.2218179703 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.1000857353 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.2101638317 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.9114115238 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.3683509827 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 45.734429597854614
Epoch 4/9
	 Logging train Loss: 1.9267103672 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.9468768835 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.9875987172 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.9860941172 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.5624992847 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.0446813107 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 45.90368390083313
Epoch 5/9
	 Logging train Loss: 1.7390540838 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.8131481409 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.9022105336 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.9310677052 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.3335096836 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.8696943521 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 46.16485357284546
Epoch 6/9
	 Logging train Loss: 1.6090239286 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.7082755566 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.8696600795 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone █▅▃▃▂▂▁▁▁▁
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone █▅▄▃▂▂▂▁▁▁
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone █▄▃▃▂▂▂▁▁▁
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone █▅▃▂▂▂▁▁▁▁
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone █▅▃▂▂▂▁▁▁▁
wandb:                                   Train loss █▃▂▂▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone 1.48871
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 1.68668
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone 0.7443
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 1.48502
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 1.87897
wandb:                                   Train loss 1.38053
wandb: 
wandb: 🚀 View run misty-wind-429 at: https://wandb.ai/nreints/ThesisFinal2/runs/gx3jsr9y
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230629_220632-gx3jsr9y/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230629_221755-22jtgapo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run prime-wave-430
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/22jtgapo
	 Logging test loss: 1.8449107409 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.188833952 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.7470362186 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 46.122848987579346
Epoch 7/9
	 Logging train Loss: 1.5151358843 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.6046575308 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.8064667583 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.7628586292 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.0502104759 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.6270791292 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 46.06571388244629
Epoch 8/9
	 Logging train Loss: 1.4413899183 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.5678566694 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.7899491191 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.749651432 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.9862139225 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.5695029497 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 46.01391386985779
Epoch 9/9
	 Logging train Loss: 1.3805320263 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.4887145758 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.7443044186 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.6866772175 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.8789676428 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.4850244522 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 46.04970669746399
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gNone/'log_dualQ'_'False'.pth
It took  682.2380385398865  seconds.
----- ITERATION 9/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 92.74606370925903 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 23.24317693710327 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_none_pNone_gNone took 23.296988487243652 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 23.414203882217407 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 23.30437159538269 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 23.229969024658203 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(6, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=6, bias=True)
)
Datatype: log_dualQ
-- Started Training --
Epoch 0/9
	 Logging train Loss: 7.5872364044 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.2869653702 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.2199522257 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.7720651627 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.6417732239 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.0313777924 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 45.67175912857056
Epoch 1/9
	 Logging train Loss: 1.4327756166 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.0936275721 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.5684441328 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.7875130177 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.1034867764 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.7095199823 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 46.18346691131592
Epoch 2/9
	 Logging train Loss: 0.8530110717 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.7767000794 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.3679181635 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.4505906105 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.7253266573 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.4280720651 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 45.93964171409607
Epoch 3/9
	 Logging train Loss: 0.6509974599 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.6535023451 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.2836745977 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.3234232664 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.5784714222 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.3200744987 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 45.74577879905701
Epoch 4/9
	 Logging train Loss: 0.5400669575 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.5662779212 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.2424811423 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.1874525547 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.480455935 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.2640605867 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 45.983702659606934
Epoch 5/9
	 Logging train Loss: 0.4714697599 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.5122517943 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.2194683105 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.112462163 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.4225637317 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.2336320728 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 46.21803689002991
Epoch 6/9
	 Logging train Loss: 0.4288738966 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.4647589624 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.1979646385 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.0203911066 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.3836230934 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.2099941969 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 46.18106937408447
Epoch 7/9
	 Logging train Loss: 0.3906899691 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.4274486303 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.1819246262 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.9469134808 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.3527854979 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.1897404939 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 46.081345319747925
Epoch 8/9
	 Logging train Loss: 0.3684950173 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.4171844721 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.1757068187 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.9373592734 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.3312221766 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.1792304367 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 46.18693685531616
Epoch 9/9
	 Logging train Loss: 0.3441349864 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.4024442732 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.1753089428 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.8882787824 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.3205443621 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.1839138418 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone █▄▂▂▂▁▁▁▁▁
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone █▄▃▃▂▂▁▁▁▁
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone █▄▂▂▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone █▃▂▂▁▁▁▁▁▁
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone █▃▂▂▁▁▁▁▁▁
wandb:                                   Train loss █▂▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone 0.40244
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 0.88828
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone 0.17531
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 0.18391
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 0.32054
wandb:                                   Train loss 0.34413
wandb: 
wandb: 🚀 View run prime-wave-430 at: https://wandb.ai/nreints/ThesisFinal2/runs/22jtgapo
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230629_221755-22jtgapo/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230629_222917-d1p5gsp6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ethereal-tree-431
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/d1p5gsp6
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone █▃▂▂▂▁▁▁▁▁
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone █▄▃▂▂▂▂▁▁▁
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone █▃▂▂▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone █▃▂▁▁▁▁▁▁▁
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone █▃▂▂▁▁▁▁▁▁
wandb:                                   Train loss █▂▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone 0.38102
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 0.84559
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone 0.14799
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 0.16727
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 0.31907
wandb:                                   Train loss 0.34112
wandb: 
wandb: 🚀 View run ethereal-tree-431 at: https://wandb.ai/nreints/ThesisFinal2/runs/d1p5gsp6
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230629_222917-d1p5gsp6/logs
		--> Epoch time; 45.8914430141449
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gNone/'log_dualQ'_'False'.pth
It took  682.3587453365326  seconds.
----- ITERATION 10/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 92.3731529712677 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 23.11902379989624 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_none_pNone_gNone took 23.214884281158447 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 23.297037839889526 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 23.250104188919067 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 23.1984281539917 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(6, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=6, bias=True)
)
Datatype: log_dualQ
-- Started Training --
Epoch 0/9
	 Logging train Loss: 8.9879217148 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.8478012085 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.6290198565 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.3170249462 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.539232254 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.8141634464 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 45.79755902290344
Epoch 1/9
	 Logging train Loss: 1.6949045658 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.1730722189 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.5986978412 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.923779726 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.2557612658 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.8010859489 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 46.74954891204834
Epoch 2/9
	 Logging train Loss: 0.9020077586 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.8035380244 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.358756423 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.521574378 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.7733020186 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.4515902102 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 46.36238098144531
Epoch 3/9
	 Logging train Loss: 0.67196244 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.65475595 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.2841073871 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.2849262953 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.6187013984 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.3436223269 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 45.850685119628906
Epoch 4/9
	 Logging train Loss: 0.5570939779 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.5675381422 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.230423525 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.195566535 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.5188481808 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.2834027708 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 45.7966411113739
Epoch 5/9
	 Logging train Loss: 0.4861160219 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.5078191161 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.2041442543 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.0911384821 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.450167805 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.237110287 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 46.11262011528015
Epoch 6/9
	 Logging train Loss: 0.4376518428 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.4758422375 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.1926775724 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.0483152866 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.4169228971 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.2187944651 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 46.2062304019928
Epoch 7/9
	 Logging train Loss: 0.3950669169 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.4259166121 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.1729980409 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.9418784976 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.3702389896 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.1926787049 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 46.08988118171692
Epoch 8/9
	 Logging train Loss: 0.3650596142 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.4394488335 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.1954930127 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.9189687967 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.3793032169 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.2195841968 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 46.03404116630554
Epoch 9/9
	 Logging train Loss: 0.3411169946 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.3810172379 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.1479902416 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.8455873132 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.3190719187 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.1672703922 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 46.01972055435181
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gNone/'log_dualQ'_'False'.pth
It took  684.0562636852264  seconds.

JOB STATISTICS
==============
Job ID: 2993858
Array Job ID: 2993858_19
Cluster: snellius
User/Group: nreints/nreints
State: RUNNING
Nodes: 1
Cores per node: 18
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 1-10:47:42 core-walltime
Job Wall-clock time: 01:55:59
Memory Utilized: 0.00 MB (estimated maximum)
Memory Efficiency: 0.00% of 0.00 MB (0.00 MB/node)
WARNING: Efficiency statistics may be misleading for RUNNING jobs.
