wandb: Currently logged in as: nreints. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_164026-hj7xo9qk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run treasured-snowflake-7
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal1/runs/hj7xo9qk
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone █▂▁▁▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone █▁▁▂▂▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone █▁▁▂▂▁▁▂▁▁
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone █▁▁▂▂▁▁▂▁▁
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone █▁▁▂▂▁▁▁▁▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone 0.0
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: 🚀 View run treasured-snowflake-7 at: https://wandb.ai/nreints/ThesisFinal1/runs/hj7xo9qk
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_164026-hj7xo9qk/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_164946-l7apikbt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run soft-brook-42
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal1/runs/l7apikbt
Training on dataset: data_t(5,20)_r(0,0)_combi_pNone_gNone
Testing on 5 datasets: ['data_t(5,20)_r(0,0)_full_pNone_gNone', 'data_t(5,20)_r(0,0)_combi_pNone_gNone', 'data_t(5,20)_r(0,0)_semi_pNone_gNone', 'data_t(5,20)_r(0,0)_tennis_pNone_gNone', 'data_t(5,20)_r(0,0)_none_pNone_gNone']
Focussing on identity: False
Using extra input: False
Using fr-fr as reference point.
----- ITERATION 1/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 66.63103294372559 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(0,0)_full_pNone_gNone took 16.730587005615234 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 16.62054967880249 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_semi_pNone_gNone took 16.94148564338684 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_tennis_pNone_gNone took 17.106752634048462 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_none_pNone_gNone took 17.068166732788086 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(24, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=24, bias=True)
)
Datatype: pos_diff_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 5.93862e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 8.687e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 4.0619e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 8.678e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 8.923e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 8.558e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 39.32970952987671
Epoch 1/9
	 Logging train Loss: 1.6489e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.944e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 9.841e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.939e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.959e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.932e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 39.38263130187988
Epoch 2/9
	 Logging train Loss: 6.42e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.486e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 4.875e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.464e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.478e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.467e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 39.24909543991089
Epoch 3/9
	 Logging train Loss: 3.793e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.498e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 4.207e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.481e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.494e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 2.503e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 39.36597037315369
Epoch 4/9
	 Logging train Loss: 3.024e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.128e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 3.332e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.145e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.126e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 2.114e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 39.45714616775513
Epoch 5/9
	 Logging train Loss: 2.881e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.541e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.573e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.521e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.526e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.535e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 38.85593128204346
Epoch 6/9
	 Logging train Loss: 2.799e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.56e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.547e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.549e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.549e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.559e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 38.90378499031067
Epoch 7/9
	 Logging train Loss: 2.776e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.993e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.956e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.985e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.983e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.988e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 39.181596994400024
Epoch 8/9
	 Logging train Loss: 2.706e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.842e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.785e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.826e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.829e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.85e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 39.74414420127869
Epoch 9/9
	 Logging train Loss: 2.626e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.635e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.552e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.623e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.626e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.627e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 39.50020384788513
Saved model in  trained_models/gru/data_t(5,20)_r(0,0)_combi_pNone_gNone/'pos_diff_1'_'False'.pth
It took  560.4516768455505  seconds.
----- ITERATION 2/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 65.82293272018433 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(0,0)_full_pNone_gNone took 16.706045389175415 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 16.51627230644226 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_semi_pNone_gNone took 16.680010318756104 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_tennis_pNone_gNone took 16.75021719932556 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_none_pNone_gNone took 16.673041820526123 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(24, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=24, bias=True)
)
Datatype: pos_diff_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 4.46201e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 6.63e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.8621e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 6.898e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 6.854e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 6.678e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 38.8582923412323
Epoch 1/9
	 Logging train Loss: 1.3426e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone █▃▂▁▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone █▁▁▂▁▁▁▁▂▂
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone █▁▁▂▁▁▁▁▂▂
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone █▁▁▂▁▁▁▁▂▂
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone █▁▁▂▁▁▁▁▂▂
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone 0.0
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: 🚀 View run soft-brook-42 at: https://wandb.ai/nreints/ThesisFinal1/runs/l7apikbt
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_164946-l7apikbt/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_165903-6f5zr4kz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vibrant-brook-75
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal1/runs/6f5zr4kz
	 Logging test loss: 1.781e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 9.056e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.826e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.816e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.781e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 39.29339241981506
Epoch 2/9
	 Logging train Loss: 5.752e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.425e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 4.512e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.453e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.47e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.433e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 39.45104265213013
Epoch 3/9
	 Logging train Loss: 3.63e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.346e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 3.965e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.356e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.372e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 2.343e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 39.43251919746399
Epoch 4/9
	 Logging train Loss: 3.041e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.521e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.694e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.545e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.549e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.516e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 39.33125686645508
Epoch 5/9
	 Logging train Loss: 2.876e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.776e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.805e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.783e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.798e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.761e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 39.194348096847534
Epoch 6/9
	 Logging train Loss: 2.813e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.694e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.68e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.703e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.714e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.682e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 39.81408381462097
Epoch 7/9
	 Logging train Loss: 2.745e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.507e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.459e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.529e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.535e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.508e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 39.389639139175415
Epoch 8/9
	 Logging train Loss: 2.701e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.928e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.891e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.941e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.959e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.924e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 39.98228454589844
Epoch 9/9
	 Logging train Loss: 2.624e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.206e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 3.119e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.236e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.254e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 2.201e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 39.418776750564575
Saved model in  trained_models/gru/data_t(5,20)_r(0,0)_combi_pNone_gNone/'pos_diff_1'_'False'.pth
It took  557.4266631603241  seconds.
----- ITERATION 3/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 65.50912046432495 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(0,0)_full_pNone_gNone took 16.517484664916992 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 16.383657932281494 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_semi_pNone_gNone took 16.56043577194214 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_tennis_pNone_gNone took 16.553577423095703 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_none_pNone_gNone took 16.54473042488098 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(24, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=24, bias=True)
)
Datatype: pos_diff_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 5.72916e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.0554e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 3.815e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.0633e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.0783e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.0364e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 39.005741596221924
Epoch 1/9
	 Logging train Loss: 1.6982e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.956e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 9.365e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.018e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.999e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.943e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 39.184099197387695
Epoch 2/9
	 Logging train Loss: 6.401e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.463e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 4.685e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.512e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.512e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.474e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 39.196004152297974
Epoch 3/9
	 Logging train Loss: 3.682e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.667e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 3.274e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.718e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.706e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.698e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 39.73122191429138
Epoch 4/9
	 Logging train Loss: 3.036e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.797e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.944e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.861e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.836e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.81e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 39.528512716293335
Epoch 5/9
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone █▂▁▁▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone █▁▁▁▁▂▁▂▁▁
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone █▁▁▁▁▂▁▂▁▁
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone █▁▁▁▁▂▁▂▁▁
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone █▁▁▁▁▂▁▂▁▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone 0.0
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: 🚀 View run vibrant-brook-75 at: https://wandb.ai/nreints/ThesisFinal1/runs/6f5zr4kz
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_165903-6f5zr4kz/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_170820-mgzduwf4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run snowy-sunset-106
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal1/runs/mgzduwf4
	 Logging train Loss: 2.878e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.342e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 3.348e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.39e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.378e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 2.35e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 40.803778886795044
Epoch 6/9
	 Logging train Loss: 2.833e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.882e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.83e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.935e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.923e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.909e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 40.925960063934326
Epoch 7/9
	 Logging train Loss: 2.795e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.298e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 3.229e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.345e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.335e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 2.308e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 39.2510621547699
Epoch 8/9
	 Logging train Loss: 2.723e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.6e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.5e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.646e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.637e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.61e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 39.599679946899414
Epoch 9/9
	 Logging train Loss: 2.681e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.057e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.932e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.107e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.094e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 2.067e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 39.612029790878296
Saved model in  trained_models/gru/data_t(5,20)_r(0,0)_combi_pNone_gNone/'pos_diff_1'_'False'.pth
It took  556.8667833805084  seconds.
----- ITERATION 4/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 65.60781478881836 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(0,0)_full_pNone_gNone took 16.577842235565186 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 16.453978776931763 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_semi_pNone_gNone took 16.492886066436768 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_tennis_pNone_gNone took 16.445186376571655 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_none_pNone_gNone took 16.452052354812622 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(24, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=24, bias=True)
)
Datatype: pos_diff_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 5.92697e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 8.887e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 3.8405e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 8.875e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 9.341e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 8.847e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 39.247411489486694
Epoch 1/9
	 Logging train Loss: 1.6931e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.094e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 9.645e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.1e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.173e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 2.091e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 39.88465762138367
Epoch 2/9
	 Logging train Loss: 6.684e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.546e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 4.929e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.531e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.618e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.547e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 39.18522882461548
Epoch 3/9
	 Logging train Loss: 4.065e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.102e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 3.887e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.09e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.156e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 2.108e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 39.194052934646606
Epoch 4/9
	 Logging train Loss: 3.258e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.745e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.977e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.73e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.772e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.731e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 39.1518919467926
Epoch 5/9
	 Logging train Loss: 3.087e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.715e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.781e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.702e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.774e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.719e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 39.77222394943237
Epoch 6/9
	 Logging train Loss: 2.95e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.103e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 3.095e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.08e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.146e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 2.102e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 39.82650661468506
Epoch 7/9
	 Logging train Loss: 2.881e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.713e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 3.67e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.715e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.768e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 2.718e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 39.74119305610657
Epoch 8/9
	 Logging train Loss: 2.816e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.954e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.873e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.923e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.982e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.94e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone █▂▁▁▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone █▂▁▂▁▁▂▂▁▁
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone █▂▁▂▁▁▂▂▁▁
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone █▂▁▂▁▁▂▂▁▁
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone █▂▁▁▁▁▁▂▁▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone 0.0
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: 🚀 View run snowy-sunset-106 at: https://wandb.ai/nreints/ThesisFinal1/runs/mgzduwf4
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_170820-mgzduwf4/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_171735-yfb17w0e
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run frosty-gorge-136
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal1/runs/yfb17w0e
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone █▂▁▁▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone █▂▁▁▂▂▁▂▁▂
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone █▂▁▁▂▂▁▂▁▂
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone █▂▁▁▂▂▁▂▁▂
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone █▂▁▁▂▂▁▂▁▂
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone 0.0
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: 🚀 View run frosty-gorge-136 at: https://wandb.ai/nreints/ThesisFinal1/runs/yfb17w0e
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_171735-yfb17w0e/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_172655-fx7dxnoj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fallen-leaf-172
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal1/runs/fx7dxnoj
		--> Epoch time; 39.80863046646118
Epoch 9/9
	 Logging train Loss: 2.765e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.049e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.948e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.041e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.096e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 2.054e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 39.493733644485474
Saved model in  trained_models/gru/data_t(5,20)_r(0,0)_combi_pNone_gNone/'pos_diff_1'_'False'.pth
It took  555.3029012680054  seconds.
----- ITERATION 5/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 65.63983845710754 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(0,0)_full_pNone_gNone took 16.50084090232849 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 16.40285062789917 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_semi_pNone_gNone took 16.485103845596313 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_tennis_pNone_gNone took 16.5143404006958 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_none_pNone_gNone took 16.504255056381226 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(24, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=24, bias=True)
)
Datatype: pos_diff_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 7.05103e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 9.161e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 4.8835e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 9.468e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 9.917e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 9.502e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 41.206650495529175
Epoch 1/9
	 Logging train Loss: 2.0014e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.179e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 9.607e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.208e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.283e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 2.212e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 41.29683303833008
Epoch 2/9
	 Logging train Loss: 7.194e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.555e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 5.044e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.565e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.586e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.537e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 39.518495082855225
Epoch 3/9
	 Logging train Loss: 4.323e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.914e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 3.65e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.92e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.932e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.889e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 39.25238490104675
Epoch 4/9
	 Logging train Loss: 3.328e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.712e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 3.812e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.7e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.711e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 2.669e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 39.01498031616211
Epoch 5/9
	 Logging train Loss: 3.086e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.672e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 3.578e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.675e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.7e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 2.643e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 39.44195628166199
Epoch 6/9
	 Logging train Loss: 2.997e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.963e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.781e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.941e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.967e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.924e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 39.490297079086304
Epoch 7/9
	 Logging train Loss: 2.915e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.843e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 3.678e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.851e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.861e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 2.81e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 39.53074312210083
Epoch 8/9
	 Logging train Loss: 2.851e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.864e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.649e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.877e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.91e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.839e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 39.78939986228943
Epoch 9/9
	 Logging train Loss: 2.758e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.958e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 3.718e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.957e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.967e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 2.936e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 39.639230728149414
Saved model in  trained_models/gru/data_t(5,20)_r(0,0)_combi_pNone_gNone/'pos_diff_1'_'False'.pth
It took  559.4719183444977  seconds.
----- ITERATION 6/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 65.56990242004395 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(0,0)_full_pNone_gNone took 16.453331470489502 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 16.41640853881836 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_semi_pNone_gNone took 16.453157424926758 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_tennis_pNone_gNone took 16.455774307250977 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_none_pNone_gNone took 16.48261594772339 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(24, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=24, bias=True)
)
Datatype: pos_diff_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 5.61454e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 6.729e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.9454e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 6.316e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone █▃▂▁▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone █▂▁▂▂▁▁▂▁▁
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone █▂▁▂▂▁▁▂▁▁
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone █▂▁▂▂▁▁▂▁▁
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone █▂▁▂▂▁▁▂▁▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone 0.0
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: 🚀 View run fallen-leaf-172 at: https://wandb.ai/nreints/ThesisFinal1/runs/fx7dxnoj
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_172655-fx7dxnoj/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_173547-phhtyux2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run good-durian-205
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal1/runs/phhtyux2
	 Logging test loss: 6.558e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 6.385e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 37.118058919906616
Epoch 1/9
	 Logging train Loss: 1.4433e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.886e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 8.717e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.812e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.872e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.79e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 37.534711599349976
Epoch 2/9
	 Logging train Loss: 6.136e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.552e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 4.392e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.509e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.525e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.464e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 37.24546551704407
Epoch 3/9
	 Logging train Loss: 3.775e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.988e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 3.446e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.953e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.974e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.897e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 36.915266036987305
Epoch 4/9
	 Logging train Loss: 3.098e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.322e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 3.368e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.255e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.301e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 2.231e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 37.29578161239624
Epoch 5/9
	 Logging train Loss: 2.935e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.474e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.4e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.419e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.466e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.394e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 37.433781147003174
Epoch 6/9
	 Logging train Loss: 2.865e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.777e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.672e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.726e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.76e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.703e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 37.25639724731445
Epoch 7/9
	 Logging train Loss: 2.792e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.02e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.872e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.969e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.013e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.94e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 37.222352743148804
Epoch 8/9
	 Logging train Loss: 2.741e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.775e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.616e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.735e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.768e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.734e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 37.237213134765625
Epoch 9/9
	 Logging train Loss: 2.683e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.804e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.611e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.762e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.792e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.723e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 37.27175498008728
Saved model in  trained_models/gru/data_t(5,20)_r(0,0)_combi_pNone_gNone/'pos_diff_1'_'False'.pth
It took  532.5211508274078  seconds.
----- ITERATION 7/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 66.4812638759613 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(0,0)_full_pNone_gNone took 16.45768642425537 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 16.36526584625244 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_semi_pNone_gNone took 16.41956400871277 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_tennis_pNone_gNone took 16.48632049560547 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_none_pNone_gNone took 16.531808376312256 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(24, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=24, bias=True)
)
Datatype: pos_diff_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 4.94529e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 7.989e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 3.1287e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 8.408e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 8.75e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 8.576e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 37.38414764404297
Epoch 1/9
	 Logging train Loss: 1.5226e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.973e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 8.089e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.044e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.12e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 2.077e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 37.25822472572327
Epoch 2/9
	 Logging train Loss: 6.019e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.436e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 4.045e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.499e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.505e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.508e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 37.2309672832489
Epoch 3/9
	 Logging train Loss: 3.717e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.567e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.965e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.633e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.628e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.629e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 37.00245690345764
Epoch 4/9
	 Logging train Loss: 3.104e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.479e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.506e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone █▂▁▁▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone █▂▁▁▁▁▂▂▁▂
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone █▂▁▁▁▁▂▂▁▂
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone █▂▁▁▁▁▂▂▁▂
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone █▂▁▁▁▁▂▂▁▂
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone 0.0
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: 🚀 View run good-durian-205 at: https://wandb.ai/nreints/ThesisFinal1/runs/phhtyux2
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_173547-phhtyux2/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_174441-wrng2dqi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dutiful-smoke-236
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal1/runs/wrng2dqi
	 Logging test loss: 1.533e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.557e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.542e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 37.18809747695923
Epoch 5/9
	 Logging train Loss: 2.947e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.753e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.659e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.813e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.819e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.84e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 37.55569314956665
Epoch 6/9
	 Logging train Loss: 2.914e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.305e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 3.155e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.373e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.372e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 2.383e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 37.501031160354614
Epoch 7/9
	 Logging train Loss: 2.854e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.123e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.943e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.197e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.186e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 2.189e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 37.05563426017761
Epoch 8/9
	 Logging train Loss: 2.795e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.627e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.434e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.687e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.693e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.696e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 37.43613004684448
Epoch 9/9
	 Logging train Loss: 2.714e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.227e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 3.017e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.281e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.301e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 2.294e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 37.39494013786316
Saved model in  trained_models/gru/data_t(5,20)_r(0,0)_combi_pNone_gNone/'pos_diff_1'_'False'.pth
It took  533.4626533985138  seconds.
----- ITERATION 8/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 65.53996539115906 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(0,0)_full_pNone_gNone took 16.434439420700073 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 16.419252634048462 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_semi_pNone_gNone took 16.438600063323975 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_tennis_pNone_gNone took 16.418028354644775 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_none_pNone_gNone took 16.44086456298828 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(24, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=24, bias=True)
)
Datatype: pos_diff_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 5.9112e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 9.291e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 3.2682e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 9.346e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.0116e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 9.744e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 38.12530446052551
Epoch 1/9
	 Logging train Loss: 1.6217e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.941e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 7.768e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.949e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.045e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.971e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 39.9857075214386
Epoch 2/9
	 Logging train Loss: 6.096e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.517e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 4.044e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.556e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.555e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.514e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 39.2426061630249
Epoch 3/9
	 Logging train Loss: 3.735e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.804e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 3.151e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.809e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.835e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.793e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 38.15020203590393
Epoch 4/9
	 Logging train Loss: 3.121e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.63e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.597e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.645e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.643e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.623e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 37.74404191970825
Epoch 5/9
	 Logging train Loss: 2.992e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.208e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 3.067e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.219e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.231e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 2.185e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 38.18319129943848
Epoch 6/9
	 Logging train Loss: 2.922e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.302e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 3.125e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.32e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.319e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 2.281e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 40.86933636665344
Epoch 7/9
	 Logging train Loss: 2.837e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.684e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.465e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.684e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.717e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.661e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 40.45499348640442
Epoch 8/9
	 Logging train Loss: 2.787e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.106e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone █▂▁▁▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone █▁▁▁▁▂▂▁▂▁
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone █▁▁▁▁▂▂▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone █▁▁▁▁▂▂▁▂▁
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone █▁▁▁▁▂▂▁▁▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone 0.0
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: 🚀 View run dutiful-smoke-236 at: https://wandb.ai/nreints/ThesisFinal1/runs/wrng2dqi
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_174441-wrng2dqi/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_175349-5j5aoser
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run light-cherry-267
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal1/runs/5j5aoser
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone █▂▁▁▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone █▁▁▁▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone █▁▁▁▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone █▁▁▁▁▁▁▁▁▁
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone █▁▁▁▁▁▁▁▁▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone 0.0
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: 🚀 View run light-cherry-267 at: https://wandb.ai/nreints/ThesisFinal1/runs/5j5aoser
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_175349-5j5aoser/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_180250-tnmseevi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ruby-capybara-297
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal1/runs/tnmseevi
	 Logging test loss: 2.88e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.119e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.142e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 2.099e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 38.76509428024292
Epoch 9/9
	 Logging train Loss: 2.719e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.774e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.534e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.79e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.81e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.771e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 37.87006235122681
Saved model in  trained_models/gru/data_t(5,20)_r(0,0)_combi_pNone_gNone/'pos_diff_1'_'False'.pth
It took  548.2780504226685  seconds.
----- ITERATION 9/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 65.18135070800781 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(0,0)_full_pNone_gNone took 16.405375242233276 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 16.348403215408325 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_semi_pNone_gNone took 16.3907253742218 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_tennis_pNone_gNone took 16.38612461090088 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_none_pNone_gNone took 16.460448265075684 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(24, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=24, bias=True)
)
Datatype: pos_diff_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 7.34938e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.0786e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 4.8239e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.1209e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.1349e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.0962e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 37.53425049781799
Epoch 1/9
	 Logging train Loss: 1.864e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.106e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 9.738e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.118e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.135e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 2.097e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 37.50046682357788
Epoch 2/9
	 Logging train Loss: 6.805e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.496e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 5.014e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.475e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.488e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.482e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 37.466835737228394
Epoch 3/9
	 Logging train Loss: 3.909e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.555e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 3.267e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.529e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.543e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.539e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 37.311274766922
Epoch 4/9
	 Logging train Loss: 3.107e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.769e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.884e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.755e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.767e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.754e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 37.45150446891785
Epoch 5/9
	 Logging train Loss: 2.931e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.849e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.792e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.821e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.848e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.845e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 37.568300008773804
Epoch 6/9
	 Logging train Loss: 2.901e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.859e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.736e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.832e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.843e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.84e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 38.68977499008179
Epoch 7/9
	 Logging train Loss: 2.87e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.53e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.381e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.506e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.519e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.515e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 39.148141622543335
Epoch 8/9
	 Logging train Loss: 2.803e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.779e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.622e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.75e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.764e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.761e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 39.471192598342896
Epoch 9/9
	 Logging train Loss: 2.737e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.83e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.643e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.805e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.817e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.813e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 39.04067039489746
Saved model in  trained_models/gru/data_t(5,20)_r(0,0)_combi_pNone_gNone/'pos_diff_1'_'False'.pth
It took  540.5389537811279  seconds.
----- ITERATION 10/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 65.50714325904846 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(0,0)_full_pNone_gNone took 16.433905601501465 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 16.30431818962097 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_semi_pNone_gNone took 16.40886092185974 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_tennis_pNone_gNone took 16.45462703704834 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_none_pNone_gNone took 16.390530109405518 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(24, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=24, bias=True)
)
Datatype: pos_diff_1
-- Started Training --
Epoch 0/9
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone █▂▁▁▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone █▂▁▁▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone █▂▁▁▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone █▂▁▁▁▁▁▁▁▁
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone █▂▁▁▁▁▁▁▁▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone 0.0
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: 🚀 View run ruby-capybara-297 at: https://wandb.ai/nreints/ThesisFinal1/runs/tnmseevi
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_180250-tnmseevi/logs
	 Logging train Loss: 7.05332e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.2412e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 4.8169e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.2529e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.2583e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.1705e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 37.21559166908264
Epoch 1/9
	 Logging train Loss: 2.0721e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.759e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.0129e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.803e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.772e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 2.63e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 37.35164475440979
Epoch 2/9
	 Logging train Loss: 7.422e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.016e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 5.566e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.034e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.989e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.984e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 37.63611316680908
Epoch 3/9
	 Logging train Loss: 4.386e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.499e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 3.338e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.521e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.472e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.462e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 39.31297183036804
Epoch 4/9
	 Logging train Loss: 3.449e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.18e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 3.389e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.207e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.155e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 2.154e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 38.41762661933899
Epoch 5/9
	 Logging train Loss: 3.123e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.577e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.546e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.601e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.553e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.553e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 37.926581621170044
Epoch 6/9
	 Logging train Loss: 3.041e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.195e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 3.079e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.219e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.171e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 2.169e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 37.35540056228638
Epoch 7/9
	 Logging train Loss: 2.96e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.081e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.925e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.111e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.068e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 2.057e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 37.71581530570984
Epoch 8/9
	 Logging train Loss: 2.885e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.965e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.793e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.995e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.941e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.941e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 37.503453493118286
Epoch 9/9
	 Logging train Loss: 2.822e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.974e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.756e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.995e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.937e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
	 Logging test loss: 1.948e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
		--> Epoch time; 37.21412777900696
Saved model in  trained_models/gru/data_t(5,20)_r(0,0)_combi_pNone_gNone/'pos_diff_1'_'False'.pth
It took  538.769828081131  seconds.

JOB STATISTICS
==============
Job ID: 2971259
Array Job ID: 2971258_1
Cluster: snellius
User/Group: nreints/nreints
State: RUNNING
Nodes: 1
Cores per node: 18
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 1-03:30:00 core-walltime
Job Wall-clock time: 01:31:40
Memory Utilized: 0.00 MB (estimated maximum)
Memory Efficiency: 0.00% of 0.00 MB (0.00 MB/node)
WARNING: Efficiency statistics may be misleading for RUNNING jobs.
