wandb: Currently logged in as: nreints. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_125115-qx8xaxmf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run brisk-water-17
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/qx8xaxmf
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(5,20)_combi_pTrue_gTrue █▃▃▆▂▂▂▁▁▁
wandb:   Test loss t(0,0)_r(5,20)_full_pTrue_gTrue ▆▂▃█▂▁▃▁▃▂
wandb:   Test loss t(0,0)_r(5,20)_semi_pTrue_gTrue █▅▅▆▄▃▃▂▁▁
wandb: Test loss t(0,0)_r(5,20)_tennis_pTrue_gTrue █▃▃█▂▁▂▁▁▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(0,0)_r(5,20)_combi_pTrue_gTrue 0.0
wandb:   Test loss t(0,0)_r(5,20)_full_pTrue_gTrue 0.0
wandb:   Test loss t(0,0)_r(5,20)_semi_pTrue_gTrue 0.00107
wandb: Test loss t(0,0)_r(5,20)_tennis_pTrue_gTrue 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: 🚀 View run brisk-water-17 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/qx8xaxmf
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_125115-qx8xaxmf/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_125904-g0lrmwr2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run comic-waterfall-61
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/g0lrmwr2
Training on dataset: data_t(0,0)_r(5,20)_combi_pTrue_gTrue
Testing on 4 datasets: ['data_t(0,0)_r(5,20)_tennis_pTrue_gTrue', 'data_t(0,0)_r(5,20)_full_pTrue_gTrue', 'data_t(0,0)_r(5,20)_semi_pTrue_gTrue', 'data_t(0,0)_r(5,20)_combi_pTrue_gTrue']
Focussing on identity: True
Using extra input: False
Using fr-fr as reference point.
----- ITERATION 1/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(5,20)_combi_pTrue_gTrue took 52.92968201637268 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(5,20)_tennis_pTrue_gTrue took 13.032358407974243 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_full_pTrue_gTrue took 12.858893394470215 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_semi_pTrue_gTrue took 12.948733806610107 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_combi_pTrue_gTrue took 12.8876633644104 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0005099713 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
	 Logging test loss: 3.23723e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pTrue_gTrue]
	 Logging test loss: 6.74e-07 [MSELoss(): t(0,0)_r(5,20)_full_pTrue_gTrue]
	 Logging test loss: 0.001182601 [MSELoss(): t(0,0)_r(5,20)_semi_pTrue_gTrue]
	 Logging test loss: 2.97395e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
		--> Epoch time; 35.301283836364746
Epoch 1/9
	 Logging train Loss: 2.17198e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
	 Logging test loss: 9.0686e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pTrue_gTrue]
	 Logging test loss: 1.826e-07 [MSELoss(): t(0,0)_r(5,20)_full_pTrue_gTrue]
	 Logging test loss: 0.0011342879 [MSELoss(): t(0,0)_r(5,20)_semi_pTrue_gTrue]
	 Logging test loss: 1.19388e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
		--> Epoch time; 33.53751540184021
Epoch 2/9
	 Logging train Loss: 1.53546e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
	 Logging test loss: 1.30749e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pTrue_gTrue]
	 Logging test loss: 3.136e-07 [MSELoss(): t(0,0)_r(5,20)_full_pTrue_gTrue]
	 Logging test loss: 0.0011369853 [MSELoss(): t(0,0)_r(5,20)_semi_pTrue_gTrue]
	 Logging test loss: 1.30328e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
		--> Epoch time; 33.35662364959717
Epoch 3/9
	 Logging train Loss: 1.31039e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
	 Logging test loss: 3.06265e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pTrue_gTrue]
	 Logging test loss: 8.745e-07 [MSELoss(): t(0,0)_r(5,20)_full_pTrue_gTrue]
	 Logging test loss: 0.0011570783 [MSELoss(): t(0,0)_r(5,20)_semi_pTrue_gTrue]
	 Logging test loss: 2.10445e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
		--> Epoch time; 32.69481182098389
Epoch 4/9
	 Logging train Loss: 1.09625e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
	 Logging test loss: 7.2997e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pTrue_gTrue]
	 Logging test loss: 1.696e-07 [MSELoss(): t(0,0)_r(5,20)_full_pTrue_gTrue]
	 Logging test loss: 0.0011204365 [MSELoss(): t(0,0)_r(5,20)_semi_pTrue_gTrue]
	 Logging test loss: 9.4575e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
		--> Epoch time; 33.0255606174469
Epoch 5/9
	 Logging train Loss: 8.738e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
	 Logging test loss: 4.2611e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pTrue_gTrue]
	 Logging test loss: 1.145e-07 [MSELoss(): t(0,0)_r(5,20)_full_pTrue_gTrue]
	 Logging test loss: 0.0011079739 [MSELoss(): t(0,0)_r(5,20)_semi_pTrue_gTrue]
	 Logging test loss: 7.4076e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
		--> Epoch time; 35.7027952671051
Epoch 6/9
	 Logging train Loss: 6.7475e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
	 Logging test loss: 7.3417e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pTrue_gTrue]
	 Logging test loss: 3.058e-07 [MSELoss(): t(0,0)_r(5,20)_full_pTrue_gTrue]
	 Logging test loss: 0.001103516 [MSELoss(): t(0,0)_r(5,20)_semi_pTrue_gTrue]
	 Logging test loss: 8.5059e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
		--> Epoch time; 36.2721631526947
Epoch 7/9
	 Logging train Loss: 5.3978e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
	 Logging test loss: 3.3568e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pTrue_gTrue]
	 Logging test loss: 9.26e-08 [MSELoss(): t(0,0)_r(5,20)_full_pTrue_gTrue]
	 Logging test loss: 0.0010857134 [MSELoss(): t(0,0)_r(5,20)_semi_pTrue_gTrue]
	 Logging test loss: 6.1641e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
		--> Epoch time; 36.14053297042847
Epoch 8/9
	 Logging train Loss: 4.722e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
	 Logging test loss: 3.0208e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pTrue_gTrue]
	 Logging test loss: 2.69e-07 [MSELoss(): t(0,0)_r(5,20)_full_pTrue_gTrue]
	 Logging test loss: 0.0010692795 [MSELoss(): t(0,0)_r(5,20)_semi_pTrue_gTrue]
	 Logging test loss: 5.4779e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
		--> Epoch time; 35.8012969493866
Epoch 9/9
	 Logging train Loss: 3.9173e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
	 Logging test loss: 2.5214e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pTrue_gTrue]
	 Logging test loss: 2.025e-07 [MSELoss(): t(0,0)_r(5,20)_full_pTrue_gTrue]
	 Logging test loss: 0.0010682273 [MSELoss(): t(0,0)_r(5,20)_semi_pTrue_gTrue]
	 Logging test loss: 4.9833e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
		--> Epoch time; 36.010295391082764
Saved model in  trained_models/gru/data_t(0,0)_r(5,20)_combi_pTrue_gTrue/'dual_quat_1'_'False'.pth
It took  470.39611077308655  seconds.
----- ITERATION 2/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(5,20)_combi_pTrue_gTrue took 48.50807595252991 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(5,20)_tennis_pTrue_gTrue took 12.144723176956177 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_full_pTrue_gTrue took 12.124785900115967 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_semi_pTrue_gTrue took 12.156207084655762 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_combi_pTrue_gTrue took 12.091667413711548 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0003222334 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
	 Logging test loss: 1.96534e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pTrue_gTrue]
	 Logging test loss: 4.431e-07 [MSELoss(): t(0,0)_r(5,20)_full_pTrue_gTrue]
	 Logging test loss: 0.0011933731 [MSELoss(): t(0,0)_r(5,20)_semi_pTrue_gTrue]
	 Logging test loss: 3.61898e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
		--> Epoch time; 36.368918895721436
Epoch 1/9
	 Logging train Loss: 1.92667e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
	 Logging test loss: 1.00997e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pTrue_gTrue]
	 Logging test loss: 5.219e-07 [MSELoss(): t(0,0)_r(5,20)_full_pTrue_gTrue]
	 Logging test loss: 0.0011690076 [MSELoss(): t(0,0)_r(5,20)_semi_pTrue_gTrue]
	 Logging test loss: 2.2616e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
		--> Epoch time; 36.305264711380005
Epoch 2/9
	 Logging train Loss: 1.38014e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
	 Logging test loss: 6.792e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pTrue_gTrue]
	 Logging test loss: 1.444e-07 [MSELoss(): t(0,0)_r(5,20)_full_pTrue_gTrue]
	 Logging test loss: 0.0011075307 [MSELoss(): t(0,0)_r(5,20)_semi_pTrue_gTrue]
	 Logging test loss: 1.63527e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
		--> Epoch time; 36.45590162277222
Epoch 3/9
	 Logging train Loss: 1.16912e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
	 Logging test loss: 1.28255e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pTrue_gTrue]
	 Logging test loss: 4.289e-07 [MSELoss(): t(0,0)_r(5,20)_full_pTrue_gTrue]
	 Logging test loss: 0.0011036525 [MSELoss(): t(0,0)_r(5,20)_semi_pTrue_gTrue]
	 Logging test loss: 1.62726e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
		--> Epoch time; 36.34337878227234
Epoch 4/9
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(5,20)_combi_pTrue_gTrue █▅▄▄▃▂▁▁▁▁
wandb:   Test loss t(0,0)_r(5,20)_full_pTrue_gTrue ▅▆▂▅█▃▂▁▃▁
wandb:   Test loss t(0,0)_r(5,20)_semi_pTrue_gTrue █▇▆▆▆▄▂▂▁▁
wandb: Test loss t(0,0)_r(5,20)_tennis_pTrue_gTrue █▄▃▅▆▃▁▁▁▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(0,0)_r(5,20)_combi_pTrue_gTrue 0.0
wandb:   Test loss t(0,0)_r(5,20)_full_pTrue_gTrue 0.0
wandb:   Test loss t(0,0)_r(5,20)_semi_pTrue_gTrue 0.00087
wandb: Test loss t(0,0)_r(5,20)_tennis_pTrue_gTrue 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: 🚀 View run comic-waterfall-61 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/g0lrmwr2
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_125904-g0lrmwr2/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_130644-cx93qkuy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run frosty-cosmos-98
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/cx93qkuy
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(5,20)_combi_pTrue_gTrue █▃▃▂▃▂▂▁▁▁
wandb:   Test loss t(0,0)_r(5,20)_full_pTrue_gTrue ▄▂▁▂█▁▂▁▁▅
wandb:   Test loss t(0,0)_r(5,20)_semi_pTrue_gTrue █▃▃▂▃▂▂▁▁▁
wandb: Test loss t(0,0)_r(5,20)_tennis_pTrue_gTrue █▂▂▂▄▂▂▁▁▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(0,0)_r(5,20)_combi_pTrue_gTrue 1e-05
wandb:   Test loss t(0,0)_r(5,20)_full_pTrue_gTrue 0.0
wandb:   Test loss t(0,0)_r(5,20)_semi_pTrue_gTrue 0.00047
wandb: Test loss t(0,0)_r(5,20)_tennis_pTrue_gTrue 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: 🚀 View run frosty-cosmos-98 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/cx93qkuy
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_130644-cx93qkuy/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_131429-30nabpid
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run whole-dew-135
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/30nabpid
	 Logging train Loss: 9.7879e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
	 Logging test loss: 1.57314e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pTrue_gTrue]
	 Logging test loss: 6.722e-07 [MSELoss(): t(0,0)_r(5,20)_full_pTrue_gTrue]
	 Logging test loss: 0.0011153404 [MSELoss(): t(0,0)_r(5,20)_semi_pTrue_gTrue]
	 Logging test loss: 1.53702e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
		--> Epoch time; 34.91369390487671
Epoch 5/9
	 Logging train Loss: 7.498e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
	 Logging test loss: 8.5248e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pTrue_gTrue]
	 Logging test loss: 2.299e-07 [MSELoss(): t(0,0)_r(5,20)_full_pTrue_gTrue]
	 Logging test loss: 0.0009863456 [MSELoss(): t(0,0)_r(5,20)_semi_pTrue_gTrue]
	 Logging test loss: 9.2465e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
		--> Epoch time; 34.421244859695435
Epoch 6/9
	 Logging train Loss: 5.9753e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
	 Logging test loss: 3.1249e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pTrue_gTrue]
	 Logging test loss: 1.734e-07 [MSELoss(): t(0,0)_r(5,20)_full_pTrue_gTrue]
	 Logging test loss: 0.0009344392 [MSELoss(): t(0,0)_r(5,20)_semi_pTrue_gTrue]
	 Logging test loss: 5.48e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
		--> Epoch time; 34.11135005950928
Epoch 7/9
	 Logging train Loss: 4.9827e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
	 Logging test loss: 3.0534e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pTrue_gTrue]
	 Logging test loss: 8.79e-08 [MSELoss(): t(0,0)_r(5,20)_full_pTrue_gTrue]
	 Logging test loss: 0.0009102803 [MSELoss(): t(0,0)_r(5,20)_semi_pTrue_gTrue]
	 Logging test loss: 4.8771e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
		--> Epoch time; 33.8523645401001
Epoch 8/9
	 Logging train Loss: 4.2739e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
	 Logging test loss: 3.7743e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pTrue_gTrue]
	 Logging test loss: 2.265e-07 [MSELoss(): t(0,0)_r(5,20)_full_pTrue_gTrue]
	 Logging test loss: 0.0008791283 [MSELoss(): t(0,0)_r(5,20)_semi_pTrue_gTrue]
	 Logging test loss: 4.7828e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
		--> Epoch time; 33.215513467788696
Epoch 9/9
	 Logging train Loss: 3.8333e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
	 Logging test loss: 2.7079e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pTrue_gTrue]
	 Logging test loss: 6.55e-08 [MSELoss(): t(0,0)_r(5,20)_full_pTrue_gTrue]
	 Logging test loss: 0.0008691101 [MSELoss(): t(0,0)_r(5,20)_semi_pTrue_gTrue]
	 Logging test loss: 3.9413e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
		--> Epoch time; 33.56518483161926
Saved model in  trained_models/gru/data_t(0,0)_r(5,20)_combi_pTrue_gTrue/'dual_quat_1'_'False'.pth
It took  459.9833209514618  seconds.
----- ITERATION 3/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(5,20)_combi_pTrue_gTrue took 47.885040044784546 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(5,20)_tennis_pTrue_gTrue took 12.036751985549927 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_full_pTrue_gTrue took 12.021179676055908 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_semi_pTrue_gTrue took 12.021852493286133 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_combi_pTrue_gTrue took 12.029130458831787 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0006920626 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
	 Logging test loss: 4.03649e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pTrue_gTrue]
	 Logging test loss: 9.29e-07 [MSELoss(): t(0,0)_r(5,20)_full_pTrue_gTrue]
	 Logging test loss: 0.0006383872 [MSELoss(): t(0,0)_r(5,20)_semi_pTrue_gTrue]
	 Logging test loss: 4.99784e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
		--> Epoch time; 33.567800760269165
Epoch 1/9
	 Logging train Loss: 2.38217e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
	 Logging test loss: 1.01644e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pTrue_gTrue]
	 Logging test loss: 2.695e-07 [MSELoss(): t(0,0)_r(5,20)_full_pTrue_gTrue]
	 Logging test loss: 0.0005286059 [MSELoss(): t(0,0)_r(5,20)_semi_pTrue_gTrue]
	 Logging test loss: 1.91048e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
		--> Epoch time; 33.12488412857056
Epoch 2/9
	 Logging train Loss: 1.47778e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
	 Logging test loss: 8.2443e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pTrue_gTrue]
	 Logging test loss: 1.938e-07 [MSELoss(): t(0,0)_r(5,20)_full_pTrue_gTrue]
	 Logging test loss: 0.0005114047 [MSELoss(): t(0,0)_r(5,20)_semi_pTrue_gTrue]
	 Logging test loss: 1.53731e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
		--> Epoch time; 33.219650745391846
Epoch 3/9
	 Logging train Loss: 1.28813e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
	 Logging test loss: 7.5624e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pTrue_gTrue]
	 Logging test loss: 3.069e-07 [MSELoss(): t(0,0)_r(5,20)_full_pTrue_gTrue]
	 Logging test loss: 0.0005029629 [MSELoss(): t(0,0)_r(5,20)_semi_pTrue_gTrue]
	 Logging test loss: 1.34399e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
		--> Epoch time; 36.154152631759644
Epoch 4/9
	 Logging train Loss: 1.14817e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
	 Logging test loss: 1.86663e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pTrue_gTrue]
	 Logging test loss: 1.7875e-06 [MSELoss(): t(0,0)_r(5,20)_full_pTrue_gTrue]
	 Logging test loss: 0.000511469 [MSELoss(): t(0,0)_r(5,20)_semi_pTrue_gTrue]
	 Logging test loss: 1.80645e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
		--> Epoch time; 36.403226375579834
Epoch 5/9
	 Logging train Loss: 9.9063e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
	 Logging test loss: 5.9593e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pTrue_gTrue]
	 Logging test loss: 2.123e-07 [MSELoss(): t(0,0)_r(5,20)_full_pTrue_gTrue]
	 Logging test loss: 0.0004875901 [MSELoss(): t(0,0)_r(5,20)_semi_pTrue_gTrue]
	 Logging test loss: 9.4556e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
		--> Epoch time; 36.29233407974243
Epoch 6/9
	 Logging train Loss: 7.7414e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
	 Logging test loss: 7.8616e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pTrue_gTrue]
	 Logging test loss: 4.011e-07 [MSELoss(): t(0,0)_r(5,20)_full_pTrue_gTrue]
	 Logging test loss: 0.0004924382 [MSELoss(): t(0,0)_r(5,20)_semi_pTrue_gTrue]
	 Logging test loss: 9.4626e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
		--> Epoch time; 36.29191851615906
Epoch 7/9
	 Logging train Loss: 6.2249e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
	 Logging test loss: 3.165e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pTrue_gTrue]
	 Logging test loss: 2.318e-07 [MSELoss(): t(0,0)_r(5,20)_full_pTrue_gTrue]
	 Logging test loss: 0.0004739055 [MSELoss(): t(0,0)_r(5,20)_semi_pTrue_gTrue]
	 Logging test loss: 5.9492e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
		--> Epoch time; 36.12670016288757
Epoch 8/9
	 Logging train Loss: 5.0286e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
	 Logging test loss: 3.6762e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pTrue_gTrue]
	 Logging test loss: 1.168e-07 [MSELoss(): t(0,0)_r(5,20)_full_pTrue_gTrue]
	 Logging test loss: 0.0004744278 [MSELoss(): t(0,0)_r(5,20)_semi_pTrue_gTrue]
	 Logging test loss: 5.675e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
		--> Epoch time; 36.4372923374176
Epoch 9/9
	 Logging train Loss: 4.4817e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
	 Logging test loss: 3.7664e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pTrue_gTrue]
	 Logging test loss: 1.108e-06 [MSELoss(): t(0,0)_r(5,20)_full_pTrue_gTrue]
	 Logging test loss: 0.0004746638 [MSELoss(): t(0,0)_r(5,20)_semi_pTrue_gTrue]
	 Logging test loss: 6.0462e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
		--> Epoch time; 36.04683828353882
Saved model in  trained_models/gru/data_t(0,0)_r(5,20)_combi_pTrue_gTrue/'dual_quat_1'_'False'.pth
It took  464.36639404296875  seconds.
----- ITERATION 4/10 ------
Number of train simulations:  1920
Number of test simulations:  480
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(5,20)_combi_pTrue_gTrue █▃▂▂▂▁▁▁▁▁
wandb:   Test loss t(0,0)_r(5,20)_full_pTrue_gTrue █▃▂▂▃▁▁▃▂▁
wandb:   Test loss t(0,0)_r(5,20)_semi_pTrue_gTrue ▆█▃▃▃▃▂▁▁▁
wandb: Test loss t(0,0)_r(5,20)_tennis_pTrue_gTrue █▃▂▂▁▁▁▂▁▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(0,0)_r(5,20)_combi_pTrue_gTrue 0.0
wandb:   Test loss t(0,0)_r(5,20)_full_pTrue_gTrue 0.0
wandb:   Test loss t(0,0)_r(5,20)_semi_pTrue_gTrue 0.00113
wandb: Test loss t(0,0)_r(5,20)_tennis_pTrue_gTrue 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: 🚀 View run whole-dew-135 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/30nabpid
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_131429-30nabpid/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_132202-16uh9j6y
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run polished-shadow-167
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/16uh9j6y
The dataloader for data/data_t(0,0)_r(5,20)_combi_pTrue_gTrue took 48.24669361114502 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(5,20)_tennis_pTrue_gTrue took 12.127209901809692 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_full_pTrue_gTrue took 12.072275638580322 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_semi_pTrue_gTrue took 12.04286003112793 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_combi_pTrue_gTrue took 12.092975378036499 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0007184297 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
	 Logging test loss: 4.59304e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pTrue_gTrue]
	 Logging test loss: 1.4818e-06 [MSELoss(): t(0,0)_r(5,20)_full_pTrue_gTrue]
	 Logging test loss: 0.0013120162 [MSELoss(): t(0,0)_r(5,20)_semi_pTrue_gTrue]
	 Logging test loss: 4.70164e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
		--> Epoch time; 36.358696937561035
Epoch 1/9
	 Logging train Loss: 2.60378e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
	 Logging test loss: 1.29371e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pTrue_gTrue]
	 Logging test loss: 4.165e-07 [MSELoss(): t(0,0)_r(5,20)_full_pTrue_gTrue]
	 Logging test loss: 0.0013809374 [MSELoss(): t(0,0)_r(5,20)_semi_pTrue_gTrue]
	 Logging test loss: 1.84197e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
		--> Epoch time; 35.961382150650024
Epoch 2/9
	 Logging train Loss: 1.50103e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
	 Logging test loss: 7.4574e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pTrue_gTrue]
	 Logging test loss: 2.303e-07 [MSELoss(): t(0,0)_r(5,20)_full_pTrue_gTrue]
	 Logging test loss: 0.0012103675 [MSELoss(): t(0,0)_r(5,20)_semi_pTrue_gTrue]
	 Logging test loss: 1.25708e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
		--> Epoch time; 34.78073787689209
Epoch 3/9
	 Logging train Loss: 1.27803e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
	 Logging test loss: 6.0986e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pTrue_gTrue]
	 Logging test loss: 2.735e-07 [MSELoss(): t(0,0)_r(5,20)_full_pTrue_gTrue]
	 Logging test loss: 0.0011982485 [MSELoss(): t(0,0)_r(5,20)_semi_pTrue_gTrue]
	 Logging test loss: 1.01387e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
		--> Epoch time; 34.262279748916626
Epoch 4/9
	 Logging train Loss: 1.11196e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
	 Logging test loss: 5.1916e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pTrue_gTrue]
	 Logging test loss: 4.595e-07 [MSELoss(): t(0,0)_r(5,20)_full_pTrue_gTrue]
	 Logging test loss: 0.001187623 [MSELoss(): t(0,0)_r(5,20)_semi_pTrue_gTrue]
	 Logging test loss: 8.4023e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
		--> Epoch time; 34.148703813552856
Epoch 5/9
	 Logging train Loss: 9.1973e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
	 Logging test loss: 3.9615e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pTrue_gTrue]
	 Logging test loss: 1.296e-07 [MSELoss(): t(0,0)_r(5,20)_full_pTrue_gTrue]
	 Logging test loss: 0.0011871069 [MSELoss(): t(0,0)_r(5,20)_semi_pTrue_gTrue]
	 Logging test loss: 6.3533e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
		--> Epoch time; 34.151079416275024
Epoch 6/9
	 Logging train Loss: 7.6279e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
	 Logging test loss: 4.3819e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pTrue_gTrue]
	 Logging test loss: 1.357e-07 [MSELoss(): t(0,0)_r(5,20)_full_pTrue_gTrue]
	 Logging test loss: 0.0011535626 [MSELoss(): t(0,0)_r(5,20)_semi_pTrue_gTrue]
	 Logging test loss: 5.4558e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
		--> Epoch time; 33.26305532455444
Epoch 7/9
	 Logging train Loss: 5.7596e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
	 Logging test loss: 6.7914e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pTrue_gTrue]
	 Logging test loss: 5.71e-07 [MSELoss(): t(0,0)_r(5,20)_full_pTrue_gTrue]
	 Logging test loss: 0.0011405521 [MSELoss(): t(0,0)_r(5,20)_semi_pTrue_gTrue]
	 Logging test loss: 6.3476e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
		--> Epoch time; 33.50509834289551
Epoch 8/9
	 Logging train Loss: 4.9604e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
	 Logging test loss: 3.7042e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pTrue_gTrue]
	 Logging test loss: 1.994e-07 [MSELoss(): t(0,0)_r(5,20)_full_pTrue_gTrue]
	 Logging test loss: 0.0011318966 [MSELoss(): t(0,0)_r(5,20)_semi_pTrue_gTrue]
	 Logging test loss: 4.1017e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
		--> Epoch time; 33.88713812828064
Epoch 9/9
	 Logging train Loss: 4.1183e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
	 Logging test loss: 2.9784e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pTrue_gTrue]
	 Logging test loss: 7.89e-08 [MSELoss(): t(0,0)_r(5,20)_full_pTrue_gTrue]
	 Logging test loss: 0.0011259104 [MSELoss(): t(0,0)_r(5,20)_semi_pTrue_gTrue]
	 Logging test loss: 3.4268e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
		--> Epoch time; 33.66157341003418
Saved model in  trained_models/gru/data_t(0,0)_r(5,20)_combi_pTrue_gTrue/'dual_quat_1'_'False'.pth
It took  453.23679542541504  seconds.
----- ITERATION 5/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(5,20)_combi_pTrue_gTrue took 48.538196325302124 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(5,20)_tennis_pTrue_gTrue took 12.125010967254639 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_full_pTrue_gTrue took 12.154186487197876 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_semi_pTrue_gTrue took 12.067655324935913 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_combi_pTrue_gTrue took 12.100786685943604 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0006578746 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
	 Logging test loss: 3.58473e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pTrue_gTrue]
	 Logging test loss: 7.994e-07 [MSELoss(): t(0,0)_r(5,20)_full_pTrue_gTrue]
	 Logging test loss: 0.0011840787 [MSELoss(): t(0,0)_r(5,20)_semi_pTrue_gTrue]
	 Logging test loss: 3.53194e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
		--> Epoch time; 33.53743886947632
Epoch 1/9
	 Logging train Loss: 2.38241e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
	 Logging test loss: 9.6188e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pTrue_gTrue]
	 Logging test loss: 2.321e-07 [MSELoss(): t(0,0)_r(5,20)_full_pTrue_gTrue]
	 Logging test loss: 0.0010378148 [MSELoss(): t(0,0)_r(5,20)_semi_pTrue_gTrue]
	 Logging test loss: 1.31534e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
		--> Epoch time; 36.39174294471741
Epoch 2/9
	 Logging train Loss: 1.49555e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
	 Logging test loss: 1.526e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pTrue_gTrue]
	 Logging test loss: 5.671e-07 [MSELoss(): t(0,0)_r(5,20)_full_pTrue_gTrue]
	 Logging test loss: 0.0010261391 [MSELoss(): t(0,0)_r(5,20)_semi_pTrue_gTrue]
	 Logging test loss: 1.41127e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
		--> Epoch time; 36.63385534286499
Epoch 3/9
	 Logging train Loss: 1.25769e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
	 Logging test loss: 7.7154e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pTrue_gTrue]
	 Logging test loss: 6.77e-07 [MSELoss(): t(0,0)_r(5,20)_full_pTrue_gTrue]
	 Logging test loss: 0.0010187384 [MSELoss(): t(0,0)_r(5,20)_semi_pTrue_gTrue]
	 Logging test loss: 8.8394e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
		--> Epoch time; 36.006582260131836
Epoch 4/9
	 Logging train Loss: 1.12883e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
	 Logging test loss: 1.12938e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pTrue_gTrue]
	 Logging test loss: 3.165e-07 [MSELoss(): t(0,0)_r(5,20)_full_pTrue_gTrue]
	 Logging test loss: 0.0010042435 [MSELoss(): t(0,0)_r(5,20)_semi_pTrue_gTrue]
	 Logging test loss: 9.1995e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
		--> Epoch time; 36.25401949882507
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(5,20)_combi_pTrue_gTrue █▃▃▂▂▂▂▁▁▁
wandb:   Test loss t(0,0)_r(5,20)_full_pTrue_gTrue █▂▆▇▃▃▃▅▁▂
wandb:   Test loss t(0,0)_r(5,20)_semi_pTrue_gTrue █▄▃▃▃▂▂▁▁▁
wandb: Test loss t(0,0)_r(5,20)_tennis_pTrue_gTrue █▂▄▂▃▁▃▁▁▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(0,0)_r(5,20)_combi_pTrue_gTrue 0.0
wandb:   Test loss t(0,0)_r(5,20)_full_pTrue_gTrue 0.0
wandb:   Test loss t(0,0)_r(5,20)_semi_pTrue_gTrue 0.00094
wandb: Test loss t(0,0)_r(5,20)_tennis_pTrue_gTrue 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: 🚀 View run polished-shadow-167 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/16uh9j6y
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_132202-16uh9j6y/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_132952-r34jylm0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run laced-galaxy-206
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/r34jylm0
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(5,20)_combi_pTrue_gTrue █▄▃▂▂▂▁▁▁▁
wandb:   Test loss t(0,0)_r(5,20)_full_pTrue_gTrue █▄▃▄▂▁▂▆▃▁
wandb:   Test loss t(0,0)_r(5,20)_semi_pTrue_gTrue █▄▃▃▂▂▁▁▁▃
wandb: Test loss t(0,0)_r(5,20)_tennis_pTrue_gTrue █▃▂▂▂▁▂▁▁▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(0,0)_r(5,20)_combi_pTrue_gTrue 0.0
wandb:   Test loss t(0,0)_r(5,20)_full_pTrue_gTrue 0.0
wandb:   Test loss t(0,0)_r(5,20)_semi_pTrue_gTrue 0.00071
wandb: Test loss t(0,0)_r(5,20)_tennis_pTrue_gTrue 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: 🚀 View run laced-galaxy-206 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/r34jylm0
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_132952-r34jylm0/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_133716-di136mcg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run clear-leaf-241
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/di136mcg
Epoch 5/9
	 Logging train Loss: 9.1717e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
	 Logging test loss: 4.5076e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pTrue_gTrue]
	 Logging test loss: 3.256e-07 [MSELoss(): t(0,0)_r(5,20)_full_pTrue_gTrue]
	 Logging test loss: 0.0009859779 [MSELoss(): t(0,0)_r(5,20)_semi_pTrue_gTrue]
	 Logging test loss: 4.79e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
		--> Epoch time; 36.30042600631714
Epoch 6/9
	 Logging train Loss: 7.1698e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
	 Logging test loss: 9.8225e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pTrue_gTrue]
	 Logging test loss: 3.137e-07 [MSELoss(): t(0,0)_r(5,20)_full_pTrue_gTrue]
	 Logging test loss: 0.0009619551 [MSELoss(): t(0,0)_r(5,20)_semi_pTrue_gTrue]
	 Logging test loss: 6.7962e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
		--> Epoch time; 36.15281653404236
Epoch 7/9
	 Logging train Loss: 5.8676e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
	 Logging test loss: 4.177e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pTrue_gTrue]
	 Logging test loss: 4.477e-07 [MSELoss(): t(0,0)_r(5,20)_full_pTrue_gTrue]
	 Logging test loss: 0.0009495484 [MSELoss(): t(0,0)_r(5,20)_semi_pTrue_gTrue]
	 Logging test loss: 3.5951e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
		--> Epoch time; 35.89927816390991
Epoch 8/9
	 Logging train Loss: 4.8614e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
	 Logging test loss: 2.7681e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pTrue_gTrue]
	 Logging test loss: 8.62e-08 [MSELoss(): t(0,0)_r(5,20)_full_pTrue_gTrue]
	 Logging test loss: 0.0009483667 [MSELoss(): t(0,0)_r(5,20)_semi_pTrue_gTrue]
	 Logging test loss: 2.5406e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
		--> Epoch time; 35.67994475364685
Epoch 9/9
	 Logging train Loss: 4.2702e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
	 Logging test loss: 2.691e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pTrue_gTrue]
	 Logging test loss: 1.821e-07 [MSELoss(): t(0,0)_r(5,20)_full_pTrue_gTrue]
	 Logging test loss: 0.0009415736 [MSELoss(): t(0,0)_r(5,20)_semi_pTrue_gTrue]
	 Logging test loss: 2.3952e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
		--> Epoch time; 35.93732476234436
Saved model in  trained_models/gru/data_t(0,0)_r(5,20)_combi_pTrue_gTrue/'dual_quat_1'_'False'.pth
It took  470.0192937850952  seconds.
----- ITERATION 6/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(5,20)_combi_pTrue_gTrue took 48.30197763442993 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(5,20)_tennis_pTrue_gTrue took 12.082742929458618 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_full_pTrue_gTrue took 12.083368301391602 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_semi_pTrue_gTrue took 12.099998950958252 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_combi_pTrue_gTrue took 12.091963529586792 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0006157486 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
	 Logging test loss: 3.65162e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pTrue_gTrue]
	 Logging test loss: 6.536e-07 [MSELoss(): t(0,0)_r(5,20)_full_pTrue_gTrue]
	 Logging test loss: 0.0007937311 [MSELoss(): t(0,0)_r(5,20)_semi_pTrue_gTrue]
	 Logging test loss: 5.14884e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
		--> Epoch time; 33.700364112854004
Epoch 1/9
	 Logging train Loss: 2.28526e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
	 Logging test loss: 1.06722e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pTrue_gTrue]
	 Logging test loss: 3.17e-07 [MSELoss(): t(0,0)_r(5,20)_full_pTrue_gTrue]
	 Logging test loss: 0.000725532 [MSELoss(): t(0,0)_r(5,20)_semi_pTrue_gTrue]
	 Logging test loss: 2.09452e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
		--> Epoch time; 33.960389375686646
Epoch 2/9
	 Logging train Loss: 1.41082e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
	 Logging test loss: 7.356e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pTrue_gTrue]
	 Logging test loss: 2.236e-07 [MSELoss(): t(0,0)_r(5,20)_full_pTrue_gTrue]
	 Logging test loss: 0.0007096132 [MSELoss(): t(0,0)_r(5,20)_semi_pTrue_gTrue]
	 Logging test loss: 1.54789e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
		--> Epoch time; 33.54372954368591
Epoch 3/9
	 Logging train Loss: 1.19093e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
	 Logging test loss: 6.0278e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pTrue_gTrue]
	 Logging test loss: 3.437e-07 [MSELoss(): t(0,0)_r(5,20)_full_pTrue_gTrue]
	 Logging test loss: 0.0007025147 [MSELoss(): t(0,0)_r(5,20)_semi_pTrue_gTrue]
	 Logging test loss: 1.25508e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
		--> Epoch time; 33.470378398895264
Epoch 4/9
	 Logging train Loss: 1.06474e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
	 Logging test loss: 5.5678e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pTrue_gTrue]
	 Logging test loss: 2.191e-07 [MSELoss(): t(0,0)_r(5,20)_full_pTrue_gTrue]
	 Logging test loss: 0.000694167 [MSELoss(): t(0,0)_r(5,20)_semi_pTrue_gTrue]
	 Logging test loss: 1.01984e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
		--> Epoch time; 33.128663301467896
Epoch 5/9
	 Logging train Loss: 9.0716e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
	 Logging test loss: 4.1005e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pTrue_gTrue]
	 Logging test loss: 1.369e-07 [MSELoss(): t(0,0)_r(5,20)_full_pTrue_gTrue]
	 Logging test loss: 0.0006848837 [MSELoss(): t(0,0)_r(5,20)_semi_pTrue_gTrue]
	 Logging test loss: 7.4466e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
		--> Epoch time; 33.246370792388916
Epoch 6/9
	 Logging train Loss: 6.7153e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
	 Logging test loss: 6.1049e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pTrue_gTrue]
	 Logging test loss: 1.895e-07 [MSELoss(): t(0,0)_r(5,20)_full_pTrue_gTrue]
	 Logging test loss: 0.0006814696 [MSELoss(): t(0,0)_r(5,20)_semi_pTrue_gTrue]
	 Logging test loss: 6.7104e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
		--> Epoch time; 32.871689319610596
Epoch 7/9
	 Logging train Loss: 5.5053e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
	 Logging test loss: 3.6766e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pTrue_gTrue]
	 Logging test loss: 5.224e-07 [MSELoss(): t(0,0)_r(5,20)_full_pTrue_gTrue]
	 Logging test loss: 0.000676116 [MSELoss(): t(0,0)_r(5,20)_semi_pTrue_gTrue]
	 Logging test loss: 5.152e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
		--> Epoch time; 33.51707887649536
Epoch 8/9
	 Logging train Loss: 4.6421e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
	 Logging test loss: 3.0121e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pTrue_gTrue]
	 Logging test loss: 2.863e-07 [MSELoss(): t(0,0)_r(5,20)_full_pTrue_gTrue]
	 Logging test loss: 0.0006731422 [MSELoss(): t(0,0)_r(5,20)_semi_pTrue_gTrue]
	 Logging test loss: 4.1867e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
		--> Epoch time; 33.14392590522766
Epoch 9/9
	 Logging train Loss: 4.2791e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
	 Logging test loss: 2.9907e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pTrue_gTrue]
	 Logging test loss: 1.025e-07 [MSELoss(): t(0,0)_r(5,20)_full_pTrue_gTrue]
	 Logging test loss: 0.0007134756 [MSELoss(): t(0,0)_r(5,20)_semi_pTrue_gTrue]
	 Logging test loss: 3.752e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
		--> Epoch time; 32.98574686050415
Saved model in  trained_models/gru/data_t(0,0)_r(5,20)_combi_pTrue_gTrue/'dual_quat_1'_'False'.pth
It took  443.9741163253784  seconds.
----- ITERATION 7/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(5,20)_combi_pTrue_gTrue took 47.81089973449707 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(5,20)_tennis_pTrue_gTrue took 12.085031032562256 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_full_pTrue_gTrue took 12.080503225326538 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_semi_pTrue_gTrue took 12.150190353393555 seconds.
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(5,20)_combi_pTrue_gTrue █▃▂▂▂▂▁▁▁▁
wandb:   Test loss t(0,0)_r(5,20)_full_pTrue_gTrue █▂▄▇▂▅▁▅▆█
wandb:   Test loss t(0,0)_r(5,20)_semi_pTrue_gTrue █▄▃▃▂▂▁▁▁▁
wandb: Test loss t(0,0)_r(5,20)_tennis_pTrue_gTrue █▂▂▃▂▂▁▁▁▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(0,0)_r(5,20)_combi_pTrue_gTrue 0.0
wandb:   Test loss t(0,0)_r(5,20)_full_pTrue_gTrue 0.0
wandb:   Test loss t(0,0)_r(5,20)_semi_pTrue_gTrue 0.00024
wandb: Test loss t(0,0)_r(5,20)_tennis_pTrue_gTrue 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: 🚀 View run clear-leaf-241 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/di136mcg
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_133716-di136mcg/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_134505-u9hh96le
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rosy-darkness-280
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/u9hh96le
The dataloader for data/data_t(0,0)_r(5,20)_combi_pTrue_gTrue took 12.113971471786499 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0006334161 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
	 Logging test loss: 3.18306e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pTrue_gTrue]
	 Logging test loss: 8.107e-07 [MSELoss(): t(0,0)_r(5,20)_full_pTrue_gTrue]
	 Logging test loss: 0.0003591012 [MSELoss(): t(0,0)_r(5,20)_semi_pTrue_gTrue]
	 Logging test loss: 3.54499e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
		--> Epoch time; 36.052467346191406
Epoch 1/9
	 Logging train Loss: 2.32542e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
	 Logging test loss: 9.0961e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pTrue_gTrue]
	 Logging test loss: 2.112e-07 [MSELoss(): t(0,0)_r(5,20)_full_pTrue_gTrue]
	 Logging test loss: 0.0002877497 [MSELoss(): t(0,0)_r(5,20)_semi_pTrue_gTrue]
	 Logging test loss: 1.37235e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
		--> Epoch time; 35.95019197463989
Epoch 2/9
	 Logging train Loss: 1.43916e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
	 Logging test loss: 6.7333e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pTrue_gTrue]
	 Logging test loss: 4.56e-07 [MSELoss(): t(0,0)_r(5,20)_full_pTrue_gTrue]
	 Logging test loss: 0.0002706548 [MSELoss(): t(0,0)_r(5,20)_semi_pTrue_gTrue]
	 Logging test loss: 1.0432e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
		--> Epoch time; 35.63903498649597
Epoch 3/9
	 Logging train Loss: 1.25629e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
	 Logging test loss: 1.02183e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pTrue_gTrue]
	 Logging test loss: 7.945e-07 [MSELoss(): t(0,0)_r(5,20)_full_pTrue_gTrue]
	 Logging test loss: 0.0002667532 [MSELoss(): t(0,0)_r(5,20)_semi_pTrue_gTrue]
	 Logging test loss: 1.0628e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
		--> Epoch time; 35.695613861083984
Epoch 4/9
	 Logging train Loss: 1.10405e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
	 Logging test loss: 5.1446e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pTrue_gTrue]
	 Logging test loss: 2.496e-07 [MSELoss(): t(0,0)_r(5,20)_full_pTrue_gTrue]
	 Logging test loss: 0.0002553392 [MSELoss(): t(0,0)_r(5,20)_semi_pTrue_gTrue]
	 Logging test loss: 6.8822e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
		--> Epoch time; 35.67234921455383
Epoch 5/9
	 Logging train Loss: 9.1497e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
	 Logging test loss: 8.6436e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pTrue_gTrue]
	 Logging test loss: 5.754e-07 [MSELoss(): t(0,0)_r(5,20)_full_pTrue_gTrue]
	 Logging test loss: 0.0002530118 [MSELoss(): t(0,0)_r(5,20)_semi_pTrue_gTrue]
	 Logging test loss: 8.0783e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
		--> Epoch time; 35.67503213882446
Epoch 6/9
	 Logging train Loss: 7.3421e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
	 Logging test loss: 3.9689e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pTrue_gTrue]
	 Logging test loss: 1.38e-07 [MSELoss(): t(0,0)_r(5,20)_full_pTrue_gTrue]
	 Logging test loss: 0.0002429928 [MSELoss(): t(0,0)_r(5,20)_semi_pTrue_gTrue]
	 Logging test loss: 5.0465e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
		--> Epoch time; 35.76978611946106
Epoch 7/9
	 Logging train Loss: 5.8198e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
	 Logging test loss: 3.9898e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pTrue_gTrue]
	 Logging test loss: 5.366e-07 [MSELoss(): t(0,0)_r(5,20)_full_pTrue_gTrue]
	 Logging test loss: 0.0002384981 [MSELoss(): t(0,0)_r(5,20)_semi_pTrue_gTrue]
	 Logging test loss: 5.0442e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
		--> Epoch time; 35.629878520965576
Epoch 8/9
	 Logging train Loss: 4.9834e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
	 Logging test loss: 3.3609e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pTrue_gTrue]
	 Logging test loss: 6.945e-07 [MSELoss(): t(0,0)_r(5,20)_full_pTrue_gTrue]
	 Logging test loss: 0.0002371852 [MSELoss(): t(0,0)_r(5,20)_semi_pTrue_gTrue]
	 Logging test loss: 4.6053e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
		--> Epoch time; 35.48826718330383
Epoch 9/9
	 Logging train Loss: 4.3483e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
	 Logging test loss: 2.9315e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pTrue_gTrue]
	 Logging test loss: 8.519e-07 [MSELoss(): t(0,0)_r(5,20)_full_pTrue_gTrue]
	 Logging test loss: 0.0002355586 [MSELoss(): t(0,0)_r(5,20)_semi_pTrue_gTrue]
	 Logging test loss: 4.3126e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
		--> Epoch time; 35.63561201095581
Saved model in  trained_models/gru/data_t(0,0)_r(5,20)_combi_pTrue_gTrue/'dual_quat_1'_'False'.pth
It took  468.85982060432434  seconds.
----- ITERATION 8/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(5,20)_combi_pTrue_gTrue took 48.55280590057373 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(5,20)_tennis_pTrue_gTrue took 11.986446380615234 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_full_pTrue_gTrue took 12.023228406906128 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_semi_pTrue_gTrue took 12.049546241760254 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_combi_pTrue_gTrue took 12.002288579940796 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0006080624 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
	 Logging test loss: 3.3707e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pTrue_gTrue]
	 Logging test loss: 8.993e-07 [MSELoss(): t(0,0)_r(5,20)_full_pTrue_gTrue]
	 Logging test loss: 0.0018775795 [MSELoss(): t(0,0)_r(5,20)_semi_pTrue_gTrue]
	 Logging test loss: 4.4162e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
		--> Epoch time; 33.27638530731201
Epoch 1/9
	 Logging train Loss: 2.45792e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
	 Logging test loss: 1.03655e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pTrue_gTrue]
	 Logging test loss: 2.557e-07 [MSELoss(): t(0,0)_r(5,20)_full_pTrue_gTrue]
	 Logging test loss: 0.0018149725 [MSELoss(): t(0,0)_r(5,20)_semi_pTrue_gTrue]
	 Logging test loss: 1.62218e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
		--> Epoch time; 33.22837996482849
Epoch 2/9
	 Logging train Loss: 1.42269e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
	 Logging test loss: 1.02865e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pTrue_gTrue]
	 Logging test loss: 3.286e-07 [MSELoss(): t(0,0)_r(5,20)_full_pTrue_gTrue]
	 Logging test loss: 0.0018292621 [MSELoss(): t(0,0)_r(5,20)_semi_pTrue_gTrue]
	 Logging test loss: 1.38785e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
		--> Epoch time; 33.00934457778931
Epoch 3/9
	 Logging train Loss: 1.22639e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
	 Logging test loss: 9.5562e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pTrue_gTrue]
	 Logging test loss: 5.703e-07 [MSELoss(): t(0,0)_r(5,20)_full_pTrue_gTrue]
	 Logging test loss: 0.0018139554 [MSELoss(): t(0,0)_r(5,20)_semi_pTrue_gTrue]
	 Logging test loss: 1.18362e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
		--> Epoch time; 32.778571367263794
Epoch 4/9
	 Logging train Loss: 1.13222e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
	 Logging test loss: 1.15661e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pTrue_gTrue]
	 Logging test loss: 4.23e-07 [MSELoss(): t(0,0)_r(5,20)_full_pTrue_gTrue]
	 Logging test loss: 0.0017925559 [MSELoss(): t(0,0)_r(5,20)_semi_pTrue_gTrue]
	 Logging test loss: 1.16286e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
		--> Epoch time; 33.00227093696594
Epoch 5/9
	 Logging train Loss: 9.5782e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
	 Logging test loss: 5.3924e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pTrue_gTrue]
	 Logging test loss: 8.294e-07 [MSELoss(): t(0,0)_r(5,20)_full_pTrue_gTrue]
	 Logging test loss: 0.0017310095 [MSELoss(): t(0,0)_r(5,20)_semi_pTrue_gTrue]
	 Logging test loss: 8.2505e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(5,20)_combi_pTrue_gTrue █▃▃▂▂▂▁▁▁▁
wandb:   Test loss t(0,0)_r(5,20)_full_pTrue_gTrue █▂▃▅▄▇▁▂▁▄
wandb:   Test loss t(0,0)_r(5,20)_semi_pTrue_gTrue █▆▇▆▆▄▃▂▁▁
wandb: Test loss t(0,0)_r(5,20)_tennis_pTrue_gTrue █▃▃▃▃▂▁▂▁▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(0,0)_r(5,20)_combi_pTrue_gTrue 1e-05
wandb:   Test loss t(0,0)_r(5,20)_full_pTrue_gTrue 0.0
wandb:   Test loss t(0,0)_r(5,20)_semi_pTrue_gTrue 0.00163
wandb: Test loss t(0,0)_r(5,20)_tennis_pTrue_gTrue 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: 🚀 View run rosy-darkness-280 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/u9hh96le
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_134505-u9hh96le/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_135225-2j78zdcm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run gallant-feather-316
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/2j78zdcm
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(5,20)_combi_pTrue_gTrue █▃▂▂▃▁▁▁▁▁
wandb:   Test loss t(0,0)_r(5,20)_full_pTrue_gTrue █▂▁▂▂▁▃▁▁▁
wandb:   Test loss t(0,0)_r(5,20)_semi_pTrue_gTrue █▄▄▃▃▂▂▁▁▁
wandb: Test loss t(0,0)_r(5,20)_tennis_pTrue_gTrue █▂▂▂▃▁▁▁▁▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(0,0)_r(5,20)_combi_pTrue_gTrue 0.0
wandb:   Test loss t(0,0)_r(5,20)_full_pTrue_gTrue 0.0
wandb:   Test loss t(0,0)_r(5,20)_semi_pTrue_gTrue 0.00056
wandb: Test loss t(0,0)_r(5,20)_tennis_pTrue_gTrue 0.0
wandb:                                  Train loss 1e-05
wandb: 
wandb: 🚀 View run gallant-feather-316 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/2j78zdcm
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_135225-2j78zdcm/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_140010-ecv0e63w
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run elated-flower-344
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/ecv0e63w
		--> Epoch time; 32.92650628089905
Epoch 6/9
	 Logging train Loss: 7.7443e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
	 Logging test loss: 3.3762e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pTrue_gTrue]
	 Logging test loss: 1.048e-07 [MSELoss(): t(0,0)_r(5,20)_full_pTrue_gTrue]
	 Logging test loss: 0.0016938407 [MSELoss(): t(0,0)_r(5,20)_semi_pTrue_gTrue]
	 Logging test loss: 6.1746e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
		--> Epoch time; 33.107518434524536
Epoch 7/9
	 Logging train Loss: 6.2312e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
	 Logging test loss: 4.5611e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pTrue_gTrue]
	 Logging test loss: 2.112e-07 [MSELoss(): t(0,0)_r(5,20)_full_pTrue_gTrue]
	 Logging test loss: 0.0016604271 [MSELoss(): t(0,0)_r(5,20)_semi_pTrue_gTrue]
	 Logging test loss: 5.9999e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
		--> Epoch time; 33.25799012184143
Epoch 8/9
	 Logging train Loss: 5.3392e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
	 Logging test loss: 2.2018e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pTrue_gTrue]
	 Logging test loss: 1.26e-07 [MSELoss(): t(0,0)_r(5,20)_full_pTrue_gTrue]
	 Logging test loss: 0.0016464778 [MSELoss(): t(0,0)_r(5,20)_semi_pTrue_gTrue]
	 Logging test loss: 4.7218e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
		--> Epoch time; 33.273643016815186
Epoch 9/9
	 Logging train Loss: 4.5697e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
	 Logging test loss: 4.1809e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pTrue_gTrue]
	 Logging test loss: 4.371e-07 [MSELoss(): t(0,0)_r(5,20)_full_pTrue_gTrue]
	 Logging test loss: 0.0016313012 [MSELoss(): t(0,0)_r(5,20)_semi_pTrue_gTrue]
	 Logging test loss: 5.1609e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
		--> Epoch time; 32.53154134750366
Saved model in  trained_models/gru/data_t(0,0)_r(5,20)_combi_pTrue_gTrue/'dual_quat_1'_'False'.pth
It took  440.1379027366638  seconds.
----- ITERATION 9/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(5,20)_combi_pTrue_gTrue took 47.883073568344116 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(5,20)_tennis_pTrue_gTrue took 12.208970785140991 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_full_pTrue_gTrue took 12.30168342590332 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_semi_pTrue_gTrue took 12.29965353012085 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_combi_pTrue_gTrue took 12.107583999633789 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0010415136 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
	 Logging test loss: 6.51332e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pTrue_gTrue]
	 Logging test loss: 2.8039e-06 [MSELoss(): t(0,0)_r(5,20)_full_pTrue_gTrue]
	 Logging test loss: 0.0007353539 [MSELoss(): t(0,0)_r(5,20)_semi_pTrue_gTrue]
	 Logging test loss: 4.77284e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
		--> Epoch time; 35.52610969543457
Epoch 1/9
	 Logging train Loss: 3.67595e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
	 Logging test loss: 1.32312e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pTrue_gTrue]
	 Logging test loss: 3.313e-07 [MSELoss(): t(0,0)_r(5,20)_full_pTrue_gTrue]
	 Logging test loss: 0.0006345557 [MSELoss(): t(0,0)_r(5,20)_semi_pTrue_gTrue]
	 Logging test loss: 1.26894e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
		--> Epoch time; 35.68671369552612
Epoch 2/9
	 Logging train Loss: 1.77841e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
	 Logging test loss: 8.5397e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pTrue_gTrue]
	 Logging test loss: 2.016e-07 [MSELoss(): t(0,0)_r(5,20)_full_pTrue_gTrue]
	 Logging test loss: 0.0006313289 [MSELoss(): t(0,0)_r(5,20)_semi_pTrue_gTrue]
	 Logging test loss: 8.4054e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
		--> Epoch time; 35.336278438568115
Epoch 3/9
	 Logging train Loss: 1.42872e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
	 Logging test loss: 1.51028e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pTrue_gTrue]
	 Logging test loss: 4.701e-07 [MSELoss(): t(0,0)_r(5,20)_full_pTrue_gTrue]
	 Logging test loss: 0.0006236144 [MSELoss(): t(0,0)_r(5,20)_semi_pTrue_gTrue]
	 Logging test loss: 1.12626e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
		--> Epoch time; 35.76959729194641
Epoch 4/9
	 Logging train Loss: 1.28278e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
	 Logging test loss: 2.15185e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pTrue_gTrue]
	 Logging test loss: 6.586e-07 [MSELoss(): t(0,0)_r(5,20)_full_pTrue_gTrue]
	 Logging test loss: 0.0006240293 [MSELoss(): t(0,0)_r(5,20)_semi_pTrue_gTrue]
	 Logging test loss: 1.3877e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
		--> Epoch time; 35.713635206222534
Epoch 5/9
	 Logging train Loss: 1.08924e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
	 Logging test loss: 6.8221e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pTrue_gTrue]
	 Logging test loss: 2.022e-07 [MSELoss(): t(0,0)_r(5,20)_full_pTrue_gTrue]
	 Logging test loss: 0.0005982454 [MSELoss(): t(0,0)_r(5,20)_semi_pTrue_gTrue]
	 Logging test loss: 5.4011e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
		--> Epoch time; 35.547931432724
Epoch 6/9
	 Logging train Loss: 9.3429e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
	 Logging test loss: 6.786e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pTrue_gTrue]
	 Logging test loss: 8.288e-07 [MSELoss(): t(0,0)_r(5,20)_full_pTrue_gTrue]
	 Logging test loss: 0.0005950354 [MSELoss(): t(0,0)_r(5,20)_semi_pTrue_gTrue]
	 Logging test loss: 5.1426e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
		--> Epoch time; 35.4052951335907
Epoch 7/9
	 Logging train Loss: 7.6119e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
	 Logging test loss: 4.7215e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pTrue_gTrue]
	 Logging test loss: 1.606e-07 [MSELoss(): t(0,0)_r(5,20)_full_pTrue_gTrue]
	 Logging test loss: 0.0005712956 [MSELoss(): t(0,0)_r(5,20)_semi_pTrue_gTrue]
	 Logging test loss: 3.484e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
		--> Epoch time; 35.756784439086914
Epoch 8/9
	 Logging train Loss: 5.8319e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
	 Logging test loss: 3.5972e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pTrue_gTrue]
	 Logging test loss: 1.684e-07 [MSELoss(): t(0,0)_r(5,20)_full_pTrue_gTrue]
	 Logging test loss: 0.0005762631 [MSELoss(): t(0,0)_r(5,20)_semi_pTrue_gTrue]
	 Logging test loss: 2.6649e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
		--> Epoch time; 35.430081605911255
Epoch 9/9
	 Logging train Loss: 5.3064e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
	 Logging test loss: 3.5693e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pTrue_gTrue]
	 Logging test loss: 1.391e-07 [MSELoss(): t(0,0)_r(5,20)_full_pTrue_gTrue]
	 Logging test loss: 0.0005647019 [MSELoss(): t(0,0)_r(5,20)_semi_pTrue_gTrue]
	 Logging test loss: 2.5723e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
		--> Epoch time; 34.42729139328003
Saved model in  trained_models/gru/data_t(0,0)_r(5,20)_combi_pTrue_gTrue/'dual_quat_1'_'False'.pth
It took  465.394633769989  seconds.
----- ITERATION 10/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(5,20)_combi_pTrue_gTrue took 48.018697023391724 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(5,20)_tennis_pTrue_gTrue took 12.048419713973999 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_full_pTrue_gTrue took 12.017200469970703 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_semi_pTrue_gTrue took 12.02261996269226 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_combi_pTrue_gTrue took 12.037039756774902 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0005126217 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
	 Logging test loss: 3.57431e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pTrue_gTrue]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(5,20)_combi_pTrue_gTrue █▃▄▅▂▂▂▂▁▁
wandb:   Test loss t(0,0)_r(5,20)_full_pTrue_gTrue ▄▁▄█▁▁▄▆▁▁
wandb:   Test loss t(0,0)_r(5,20)_semi_pTrue_gTrue █▄▄▄▃▂▂▂▁▁
wandb: Test loss t(0,0)_r(5,20)_tennis_pTrue_gTrue █▂▅▇▂▁▁▂▁▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(0,0)_r(5,20)_combi_pTrue_gTrue 1e-05
wandb:   Test loss t(0,0)_r(5,20)_full_pTrue_gTrue 0.0
wandb:   Test loss t(0,0)_r(5,20)_semi_pTrue_gTrue 5e-05
wandb: Test loss t(0,0)_r(5,20)_tennis_pTrue_gTrue 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: 🚀 View run elated-flower-344 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/ecv0e63w
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_140010-ecv0e63w/logs
	 Logging test loss: 7.99e-07 [MSELoss(): t(0,0)_r(5,20)_full_pTrue_gTrue]
	 Logging test loss: 0.0002161865 [MSELoss(): t(0,0)_r(5,20)_semi_pTrue_gTrue]
	 Logging test loss: 3.53413e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
		--> Epoch time; 33.31988739967346
Epoch 1/9
	 Logging train Loss: 2.05021e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
	 Logging test loss: 9.3605e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pTrue_gTrue]
	 Logging test loss: 2.155e-07 [MSELoss(): t(0,0)_r(5,20)_full_pTrue_gTrue]
	 Logging test loss: 0.0001202315 [MSELoss(): t(0,0)_r(5,20)_semi_pTrue_gTrue]
	 Logging test loss: 1.50059e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
		--> Epoch time; 32.82422590255737
Epoch 2/9
	 Logging train Loss: 1.43856e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
	 Logging test loss: 2.37199e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pTrue_gTrue]
	 Logging test loss: 7.961e-07 [MSELoss(): t(0,0)_r(5,20)_full_pTrue_gTrue]
	 Logging test loss: 0.0001295049 [MSELoss(): t(0,0)_r(5,20)_semi_pTrue_gTrue]
	 Logging test loss: 2.01509e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
		--> Epoch time; 32.84173393249512
Epoch 3/9
	 Logging train Loss: 1.28498e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
	 Logging test loss: 3.32448e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pTrue_gTrue]
	 Logging test loss: 1.564e-06 [MSELoss(): t(0,0)_r(5,20)_full_pTrue_gTrue]
	 Logging test loss: 0.0001265954 [MSELoss(): t(0,0)_r(5,20)_semi_pTrue_gTrue]
	 Logging test loss: 2.43814e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
		--> Epoch time; 32.84721255302429
Epoch 4/9
	 Logging train Loss: 1.02472e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
	 Logging test loss: 6.4483e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pTrue_gTrue]
	 Logging test loss: 2.232e-07 [MSELoss(): t(0,0)_r(5,20)_full_pTrue_gTrue]
	 Logging test loss: 9.19998e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pTrue_gTrue]
	 Logging test loss: 9.4849e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
		--> Epoch time; 32.82961368560791
Epoch 5/9
	 Logging train Loss: 8.3301e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
	 Logging test loss: 4.7097e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pTrue_gTrue]
	 Logging test loss: 1.434e-07 [MSELoss(): t(0,0)_r(5,20)_full_pTrue_gTrue]
	 Logging test loss: 8.47642e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pTrue_gTrue]
	 Logging test loss: 8.4868e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
		--> Epoch time; 32.99335074424744
Epoch 6/9
	 Logging train Loss: 6.2904e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
	 Logging test loss: 5.489e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pTrue_gTrue]
	 Logging test loss: 8.001e-07 [MSELoss(): t(0,0)_r(5,20)_full_pTrue_gTrue]
	 Logging test loss: 7.89896e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pTrue_gTrue]
	 Logging test loss: 8.7762e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
		--> Epoch time; 32.92082357406616
Epoch 7/9
	 Logging train Loss: 5.194e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
	 Logging test loss: 9.798e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pTrue_gTrue]
	 Logging test loss: 1.125e-06 [MSELoss(): t(0,0)_r(5,20)_full_pTrue_gTrue]
	 Logging test loss: 7.52232e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pTrue_gTrue]
	 Logging test loss: 1.06899e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
		--> Epoch time; 32.71058511734009
Epoch 8/9
	 Logging train Loss: 4.5624e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
	 Logging test loss: 4.2592e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pTrue_gTrue]
	 Logging test loss: 1.254e-07 [MSELoss(): t(0,0)_r(5,20)_full_pTrue_gTrue]
	 Logging test loss: 6.53325e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pTrue_gTrue]
	 Logging test loss: 6.5389e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
		--> Epoch time; 32.50073790550232
Epoch 9/9
	 Logging train Loss: 3.7288e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
	 Logging test loss: 4.1811e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pTrue_gTrue]
	 Logging test loss: 1.707e-07 [MSELoss(): t(0,0)_r(5,20)_full_pTrue_gTrue]
	 Logging test loss: 5.4068e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pTrue_gTrue]
	 Logging test loss: 6.147e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pTrue_gTrue]
		--> Epoch time; 32.571003913879395
Saved model in  trained_models/gru/data_t(0,0)_r(5,20)_combi_pTrue_gTrue/'dual_quat_1'_'False'.pth
It took  457.045565366745  seconds.
