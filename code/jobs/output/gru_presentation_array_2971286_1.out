wandb: Currently logged in as: nreints. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_164550-jcn8zy4q
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wise-glade-37
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal1/runs/jcn8zy4q
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone â–ˆâ–„â–‚â–‚â–‚â–â–â–â–â–
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone â–ˆâ–ƒâ–‚â–‚â–‚â–â–â–â–â–
wandb:                                   Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone 0.00117
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 0.00028
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone 0.00032
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 0.00192
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 0.00196
wandb:                                   Train loss 0.0014
wandb: 
wandb: ðŸš€ View run wise-glade-37 at: https://wandb.ai/nreints/ThesisFinal1/runs/jcn8zy4q
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_164550-jcn8zy4q/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_170439-m2bq8b5m
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pretty-water-94
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal1/runs/m2bq8b5m
Training on dataset: data_t(5,20)_r(5,20)_combi_pNone_gNone
Testing on 5 datasets: ['data_t(5,20)_r(5,20)_none_pNone_gNone', 'data_t(5,20)_r(5,20)_combi_pNone_gNone', 'data_t(5,20)_r(5,20)_full_pNone_gNone', 'data_t(5,20)_r(5,20)_tennis_pNone_gNone', 'data_t(5,20)_r(5,20)_semi_pNone_gNone']
Focussing on identity: False
Using extra input: True
Using start-fr as reference point.
----- ITERATION 1/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 109.79937839508057 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_none_pNone_gNone took 27.72805380821228 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 27.272887229919434 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 27.84069848060608 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 28.25099468231201 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 27.95077872276306 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (pre_hidden_lin_layer): Sequential(
    (0): Linear(in_features=3, out_features=96, bias=True)
    (1): ReLU()
    (2): Linear(in_features=96, out_features=96, bias=True)
    (3): ReLU()
  )
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 3.0009756088 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0149712469 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0312569737 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0133068012 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0503823347 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.044486545 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 87.3710515499115
Epoch 1/9
	 Logging train Loss: 0.0168507732 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0045559257 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0117059872 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.003926212 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0187890232 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.017904982 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 86.88411688804626
Epoch 2/9
	 Logging train Loss: 0.0078102024 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0024650153 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0067308657 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0021377106 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0108687393 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.010657195 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 86.13871598243713
Epoch 3/9
	 Logging train Loss: 0.0047400487 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0015955265 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0044522542 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0014028616 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.007100638 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0069839917 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 85.69832611083984
Epoch 4/9
	 Logging train Loss: 0.0032738706 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.000976647 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0032779574 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.000844428 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0055435169 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0053662607 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 86.92524790763855
Epoch 5/9
	 Logging train Loss: 0.0025337555 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0010130947 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0024445693 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0009133745 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0037272468 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0037412057 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 86.83352041244507
Epoch 6/9
	 Logging train Loss: 0.0020944497 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0007098808 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0020428784 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0006424141 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0032257917 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0033183119 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 87.24589419364929
Epoch 7/9
	 Logging train Loss: 0.0017615238 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0007742329 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0018574364 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0007135081 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0028879526 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0028354474 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 86.49619460105896
Epoch 8/9
	 Logging train Loss: 0.0015599753 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0004979604 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0013794862 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0004494163 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0021849873 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0021970074 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 86.0746214389801
Epoch 9/9
	 Logging train Loss: 0.0013962002 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0003156086 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0011704086 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0002805268 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0019572594 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0019170584 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 86.3270959854126
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gNone/'rot_mat'_'True'.pth
It took  1130.2091808319092  seconds.
----- ITERATION 2/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 109.19519138336182 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_none_pNone_gNone took 27.671239614486694 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 27.576865911483765 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 27.737427711486816 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 27.762691974639893 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 27.83295774459839 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (pre_hidden_lin_layer): Sequential(
    (0): Linear(in_features=3, out_features=96, bias=True)
    (1): ReLU()
    (2): Linear(in_features=96, out_features=96, bias=True)
    (3): ReLU()
  )
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat
-- Started Training --
Epoch 0/9
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone â–ˆâ–ƒâ–‚â–‚â–â–‚â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone â–ˆâ–ƒâ–‚â–‚â–â–‚â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone â–ˆâ–ƒâ–‚â–‚â–â–‚â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone â–ˆâ–ƒâ–‚â–‚â–‚â–‚â–â–â–â–
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone â–ˆâ–ƒâ–‚â–‚â–â–‚â–â–â–â–
wandb:                                   Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone 0.00152
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 0.00061
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone 0.00062
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 0.0023
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 0.0023
wandb:                                   Train loss 0.00141
wandb: 
wandb: ðŸš€ View run pretty-water-94 at: https://wandb.ai/nreints/ThesisFinal1/runs/m2bq8b5m
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_170439-m2bq8b5m/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_172328-jzxisb0s
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rural-donkey-161
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal1/runs/jzxisb0s
	 Logging train Loss: 3.1624908447 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0148818484 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0293095354 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0142905135 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0431363806 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0420749635 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 87.58624458312988
Epoch 1/9
	 Logging train Loss: 0.0154829565 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0037908354 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0102283191 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0035795493 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0158174187 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0163429845 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 86.8437979221344
Epoch 2/9
	 Logging train Loss: 0.0070603015 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0018857329 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0060993559 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0017827902 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0095839538 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0098517481 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 87.17570972442627
Epoch 3/9
	 Logging train Loss: 0.0045770383 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0014622884 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0040966626 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.001392009 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0062987125 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0065474701 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 87.14591598510742
Epoch 4/9
	 Logging train Loss: 0.0034242694 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0009490962 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0030440784 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0008955142 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0048218518 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0050949352 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 87.35921549797058
Epoch 5/9
	 Logging train Loss: 0.002713911 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0017151502 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0035453448 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0016913483 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0050898478 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0051711467 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 86.96956586837769
Epoch 6/9
	 Logging train Loss: 0.0021915555 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0007010252 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0020408982 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0006510306 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0031739664 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0032658197 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 86.27563524246216
Epoch 7/9
	 Logging train Loss: 0.0019125328 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.000494273 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0017036914 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0004654852 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0027525891 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0028031231 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 86.56193447113037
Epoch 8/9
	 Logging train Loss: 0.0016029872 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.000358057 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0012985995 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0003249952 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0020949733 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0021289561 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 86.03970289230347
Epoch 9/9
	 Logging train Loss: 0.001411248 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.000622612 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0015226749 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0006093131 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.002300299 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0022994524 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 86.31632256507874
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gNone/'rot_mat'_'True'.pth
It took  1129.3662729263306  seconds.
----- ITERATION 3/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 109.43123078346252 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_none_pNone_gNone took 27.558205604553223 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 27.408159732818604 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 27.522154808044434 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 27.601850271224976 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 27.629478693008423 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (pre_hidden_lin_layer): Sequential(
    (0): Linear(in_features=3, out_features=96, bias=True)
    (1): ReLU()
    (2): Linear(in_features=96, out_features=96, bias=True)
    (3): ReLU()
  )
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 3.1166305542 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0196256991 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.035429053 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0182041898 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0489475951 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0474438742 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 88.9115240573883
Epoch 1/9
	 Logging train Loss: 0.0180737339 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0047573419 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0118516153 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0042432011 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0178897511 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0175337493 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 87.83772420883179
Epoch 2/9
	 Logging train Loss: 0.0079124812 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0022758909 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0067369523 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0020206424 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0105664907 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0103646163 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone â–ˆâ–ƒâ–‚â–‚â–‚â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone â–ˆâ–ƒâ–‚â–‚â–‚â–â–â–â–â–
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone â–ˆâ–ƒâ–‚â–‚â–‚â–â–â–â–â–
wandb:                                   Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone 0.00112
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 0.0003
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone 0.00033
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 0.00179
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 0.00184
wandb:                                   Train loss 0.00136
wandb: 
wandb: ðŸš€ View run rural-donkey-161 at: https://wandb.ai/nreints/ThesisFinal1/runs/jzxisb0s
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_172328-jzxisb0s/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_174217-qr3q1rlg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run devoted-disco-223
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal1/runs/qr3q1rlg
		--> Epoch time; 87.04142546653748
Epoch 3/9
	 Logging train Loss: 0.0048581227 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0014033925 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.004281898 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0012332835 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.006840697 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0067958036 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 86.17406415939331
Epoch 4/9
	 Logging train Loss: 0.0034485045 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.001622354 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0036650787 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.00147064 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0055324123 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0053642662 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 85.8168716430664
Epoch 5/9
	 Logging train Loss: 0.0026471841 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0007539903 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0023501832 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0006711219 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0037537692 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0036378663 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 86.44351434707642
Epoch 6/9
	 Logging train Loss: 0.0020807281 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0005926439 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0018563138 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0005256405 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0030428106 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0029540292 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 86.23469924926758
Epoch 7/9
	 Logging train Loss: 0.001742046 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0014187867 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0024009808 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0013859194 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0032841335 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.003298125 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 86.22522377967834
Epoch 8/9
	 Logging train Loss: 0.0015586346 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0003344816 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0011735457 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0003037134 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0019026051 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0018767255 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 85.95290923118591
Epoch 9/9
	 Logging train Loss: 0.0013619942 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0003281142 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0011238246 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0003045989 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0018356442 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0017915562 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 85.98402237892151
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gNone/'rot_mat'_'True'.pth
It took  1128.2193615436554  seconds.
----- ITERATION 4/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 109.66454434394836 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_none_pNone_gNone took 27.665032625198364 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 27.54533624649048 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 27.850507259368896 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 27.70310401916504 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 27.76425862312317 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (pre_hidden_lin_layer): Sequential(
    (0): Linear(in_features=3, out_features=96, bias=True)
    (1): ReLU()
    (2): Linear(in_features=96, out_features=96, bias=True)
    (3): ReLU()
  )
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 3.1011476517 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0162948444 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0306136347 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0142195942 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0451384261 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0437330455 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 88.66336035728455
Epoch 1/9
	 Logging train Loss: 0.0164529625 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0041741412 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.010893303 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0037658839 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.017600609 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.016810853 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 87.46611332893372
Epoch 2/9
	 Logging train Loss: 0.0075598522 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0020902916 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0064617642 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0019138396 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0106336046 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0102204941 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 86.83022379875183
Epoch 3/9
	 Logging train Loss: 0.0047539542 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.001264087 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0042230887 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0011681096 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0069226329 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0068675629 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 86.91981315612793
Epoch 4/9
	 Logging train Loss: 0.003419443 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0008607035 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0033359812 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0008068611 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0055511957 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0055822274 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 86.94236588478088
Epoch 5/9
	 Logging train Loss: 0.0026487566 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0008312708 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0025994654 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0007780755 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0042069089 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0040983357 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone â–ˆâ–ƒâ–‚â–‚â–‚â–â–â–â–â–
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone â–ˆâ–„â–‚â–‚â–‚â–â–â–â–â–
wandb:                                   Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone 0.00149
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 0.0006
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone 0.00061
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 0.00222
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 0.00225
wandb:                                   Train loss 0.00137
wandb: 
wandb: ðŸš€ View run devoted-disco-223 at: https://wandb.ai/nreints/ThesisFinal1/runs/qr3q1rlg
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_174217-qr3q1rlg/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_180109-6b356hxw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run flowing-cherry-290
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal1/runs/6b356hxw
		--> Epoch time; 86.61903262138367
Epoch 6/9
	 Logging train Loss: 0.0021436966 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0009036924 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0022013774 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0008599359 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0033992191 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0033152585 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 86.9179174900055
Epoch 7/9
	 Logging train Loss: 0.0018221659 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0004606761 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0017809194 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0004284817 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0029388019 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0028164142 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 86.91690278053284
Epoch 8/9
	 Logging train Loss: 0.0015808111 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0003808459 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0013847725 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0003480011 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0022546244 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0022514171 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 86.64210295677185
Epoch 9/9
	 Logging train Loss: 0.0013652145 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0006147468 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0014870726 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0005957466 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0022474828 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0022194504 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 87.48041605949402
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gNone/'rot_mat'_'True'.pth
It took  1132.081823348999  seconds.
----- ITERATION 5/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 109.5428569316864 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_none_pNone_gNone took 27.561518907546997 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 27.40304470062256 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 27.582298517227173 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 27.64747166633606 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 27.601083278656006 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (pre_hidden_lin_layer): Sequential(
    (0): Linear(in_features=3, out_features=96, bias=True)
    (1): ReLU()
    (2): Linear(in_features=96, out_features=96, bias=True)
    (3): ReLU()
  )
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 2.9502279758 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.014201113 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0301824324 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0136742285 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0482240953 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0429414362 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 87.59173226356506
Epoch 1/9
	 Logging train Loss: 0.0171825718 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0040050698 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0116254576 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0038856212 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0199637003 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0182549115 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 87.07003498077393
Epoch 2/9
	 Logging train Loss: 0.0076756696 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0022135263 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0065917298 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0021370417 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0110200122 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0104360413 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 86.96152234077454
Epoch 3/9
	 Logging train Loss: 0.0045041936 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0011560057 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0036370384 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0011169608 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0062374533 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0057820878 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 87.1072039604187
Epoch 4/9
	 Logging train Loss: 0.0031126339 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0009677827 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0028759476 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0009442067 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0048283082 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0044525526 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 86.88999533653259
Epoch 5/9
	 Logging train Loss: 0.00234782 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0010167953 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0025220632 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0009899097 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0041115498 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0037753531 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 86.84413290023804
Epoch 6/9
	 Logging train Loss: 0.0019697896 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0004983087 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0020200186 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0004865303 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0036604353 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0032175891 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 87.25592112541199
Epoch 7/9
	 Logging train Loss: 0.0017366498 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0003483685 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0014014229 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0003342479 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.002429957 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0023207597 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 87.4695041179657
Epoch 8/9
	 Logging train Loss: 0.0014622605 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0003187486 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0013240366 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0003015475 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0024229409 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone â–ˆâ–„â–‚â–‚â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone â–ˆâ–„â–‚â–‚â–â–â–â–â–â–
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone â–ˆâ–„â–‚â–‚â–â–â–â–â–â–
wandb:                                   Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone 0.00119
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 0.00036
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone 0.00037
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 0.00187
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 0.00206
wandb:                                   Train loss 0.00132
wandb: 
wandb: ðŸš€ View run flowing-cherry-290 at: https://wandb.ai/nreints/ThesisFinal1/runs/6b356hxw
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_180109-6b356hxw/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_182000-n1rx4ym8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run faithful-thunder-338
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal1/runs/n1rx4ym8
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone â–ˆâ–ƒâ–‚â–‚â–‚â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone â–ˆâ–ƒâ–‚â–â–‚â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone â–ˆâ–ƒâ–‚â–â–‚â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone â–ˆâ–„â–‚â–‚â–‚â–â–â–â–â–
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone â–ˆâ–ƒâ–‚â–‚â–‚â–â–â–â–â–
wandb:                                   Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone 0.00111
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 0.00033
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone 0.00035
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 0.00169
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 0.00187
wandb:                                   Train loss 0.00133
wandb: 
wandb: ðŸš€ View run faithful-thunder-338 at: https://wandb.ai/nreints/ThesisFinal1/runs/n1rx4ym8
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_182000-n1rx4ym8/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_183847-wdmk5peg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run iconic-sunset-354
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal1/runs/wdmk5peg
	 Logging test loss: 0.0021713728 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 87.41297268867493
Epoch 9/9
	 Logging train Loss: 0.0013153504 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.000368457 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0011894529 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0003593208 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0020573935 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0018667717 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 86.38148999214172
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gNone/'rot_mat'_'True'.pth
It took  1131.4632396697998  seconds.
----- ITERATION 6/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 109.38081932067871 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_none_pNone_gNone took 27.558724403381348 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 27.410226345062256 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 27.503488779067993 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 27.601609706878662 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 27.624001264572144 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (pre_hidden_lin_layer): Sequential(
    (0): Linear(in_features=3, out_features=96, bias=True)
    (1): ReLU()
    (2): Linear(in_features=96, out_features=96, bias=True)
    (3): ReLU()
  )
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 3.4778709412 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0161505137 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0315533727 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0135822333 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0485624783 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0415433943 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 87.5206847190857
Epoch 1/9
	 Logging train Loss: 0.0172708072 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0041060923 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0113731977 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0036459756 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0183185507 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0165750924 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 86.35607290267944
Epoch 2/9
	 Logging train Loss: 0.0079396944 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0020978074 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0064413417 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0019021679 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0105124796 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0096249757 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 86.17988133430481
Epoch 3/9
	 Logging train Loss: 0.0048617981 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0012278388 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0040274994 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0011042099 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0067160507 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0061662714 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 85.95664715766907
Epoch 4/9
	 Logging train Loss: 0.0033860221 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0016389317 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0036754673 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0015361832 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0057064076 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0053573032 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 87.23387336730957
Epoch 5/9
	 Logging train Loss: 0.0025459232 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0007430525 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0022080119 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0006683273 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0036776292 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.003371675 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 86.9459617137909
Epoch 6/9
	 Logging train Loss: 0.0020857237 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0006211889 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0017902271 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0005604413 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0029246747 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0027026939 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 86.67310285568237
Epoch 7/9
	 Logging train Loss: 0.0017464856 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0004116225 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0015824494 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0003692426 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0028425781 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0024625806 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 86.68099236488342
Epoch 8/9
	 Logging train Loss: 0.0014880435 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.000373878 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0014666189 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0003415523 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.002581951 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0022728371 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 86.1685311794281
Epoch 9/9
	 Logging train Loss: 0.0013348735 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0003503982 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0011141392 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0003252621 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0018655176 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0016933455 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 85.94792056083679
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gNone/'rot_mat'_'True'.pth
It took  1126.414512872696  seconds.
----- ITERATION 7/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 109.44178533554077 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_none_pNone_gNone took 27.500317096710205 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 27.418169260025024 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 27.50606369972229 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 27.636590242385864 seconds.
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone â–ˆâ–ƒâ–‚â–‚â–‚â–â–â–â–â–
wandb:                                   Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone 0.00161
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 0.00044
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone 0.00046
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 0.0027
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 0.00284
wandb:                                   Train loss 0.00148
wandb: 
wandb: ðŸš€ View run iconic-sunset-354 at: https://wandb.ai/nreints/ThesisFinal1/runs/wdmk5peg
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_183847-wdmk5peg/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_185736-rcuz89zk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run flowing-dust-362
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal1/runs/rcuz89zk
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 27.614572763442993 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (pre_hidden_lin_layer): Sequential(
    (0): Linear(in_features=3, out_features=96, bias=True)
    (1): ReLU()
    (2): Linear(in_features=96, out_features=96, bias=True)
    (3): ReLU()
  )
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 3.0069000721 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0167982131 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0350370742 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0177906621 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.047607448 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.050816346 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 87.58440589904785
Epoch 1/9
	 Logging train Loss: 0.0181162413 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0044471957 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0119461166 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0046034735 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0182433855 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.018646853 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 86.95305061340332
Epoch 2/9
	 Logging train Loss: 0.0082071498 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0022568528 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0065135295 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0022782926 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0103770187 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0103832735 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 87.63737201690674
Epoch 3/9
	 Logging train Loss: 0.0051321518 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0013085996 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0041990983 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0012780873 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0070674745 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0067752642 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 87.22436594963074
Epoch 4/9
	 Logging train Loss: 0.0036376757 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0011028629 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0034382187 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0010697173 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0058488259 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0054987716 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 87.24605965614319
Epoch 5/9
	 Logging train Loss: 0.0028339562 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.000751402 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0024324539 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0007314002 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0040499792 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0040206132 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 86.98272323608398
Epoch 6/9
	 Logging train Loss: 0.0023125377 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0007514403 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0022621378 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0007452113 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0036718459 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.00364517 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 86.68083262443542
Epoch 7/9
	 Logging train Loss: 0.0019214625 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0012170159 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0023632124 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0011886377 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0034818165 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0034050865 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 86.67512106895447
Epoch 8/9
	 Logging train Loss: 0.00166204 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0003907898 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.001458519 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0003766012 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0025330067 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0024390325 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 86.40091061592102
Epoch 9/9
	 Logging train Loss: 0.0014843728 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0004589498 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0016071296 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0004394506 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0028443686 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0027016506 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 86.50683188438416
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gNone/'rot_mat'_'True'.pth
It took  1129.436196565628  seconds.
----- ITERATION 8/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 109.76805400848389 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_none_pNone_gNone took 27.537749528884888 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 27.506471157073975 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 27.6165554523468 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 27.67587113380432 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 27.599727869033813 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (pre_hidden_lin_layer): Sequential(
    (0): Linear(in_features=3, out_features=96, bias=True)
    (1): ReLU()
    (2): Linear(in_features=96, out_features=96, bias=True)
    (3): ReLU()
  )
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 3.2339632511 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0187218618 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0364805274 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0204109885 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0536706336 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0482944697 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 88.47018146514893
Epoch 1/9
	 Logging train Loss: 0.0188588426 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.004418483 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0118934847 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0044641253 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0192365497 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0178720448 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 87.52754807472229
Epoch 2/9
slurmstepd: error: *** JOB 2971288 ON gcn35 CANCELLED AT 2023-06-26T19:15:51 DUE TO TIME LIMIT ***
slurmstepd: error: *** STEP 2971288.0 ON gcn35 CANCELLED AT 2023-06-26T19:15:51 DUE TO TIME LIMIT ***

JOB STATISTICS
==============
Job ID: 2971288
Array Job ID: 2971286_1
Cluster: snellius
User/Group: nreints/nreints
State: TIMEOUT (exit code 0)
Nodes: 1
Cores per node: 18
CPU Utilized: 09:23:27
CPU Efficiency: 20.82% of 1-21:06:18 core-walltime
Job Wall-clock time: 02:30:21
Memory Utilized: 8.96 GB
Memory Efficiency: 0.00% of 0.00 MB
