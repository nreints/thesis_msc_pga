wandb: Currently logged in as: nreints. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_165450-glyu1a0w
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run magic-violet-757
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ğŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/glyu1a0w
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue â–†â–â–â–â–â–ˆâ–â–â–â–
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue â–ˆâ–‚â–â–â–â–‚â–â–â–â–
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue â–„â–â–â–â–â–ˆâ–â–â–â–
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue â–ƒâ–â–â–â–â–ˆâ–â–â–â–
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue 0.0
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue 0.0
wandb:                                 Train loss 0.0
wandb: 
wandb: ğŸš€ View run magic-violet-757 at: https://wandb.ai/nreints/ThesisFinal2/runs/glyu1a0w
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_165450-glyu1a0w/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_170156-nfdhiviz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fresh-deluge-770
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ğŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/nfdhiviz
Training on dataset: data_t(0,0)_r(0,0)_combi_pNone_gTrue
Testing on 4 datasets: ['data_t(0,0)_r(0,0)_semi_pNone_gTrue', 'data_t(0,0)_r(0,0)_full_pNone_gTrue', 'data_t(0,0)_r(0,0)_tennis_pNone_gTrue', 'data_t(0,0)_r(0,0)_combi_pNone_gTrue']
Focussing on identity: True
Using extra input: False
Using fr-fr as reference point.
----- ITERATION 1/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 51.986289978027344 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_semi_pNone_gTrue took 13.297470092773438 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pNone_gTrue took 13.009701251983643 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pNone_gTrue took 12.279074430465698 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 12.484381675720215 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0002670316 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.9882e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 5.6606e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 5.9774e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 5.8165e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 30.77988839149475
Epoch 1/9
	 Logging train Loss: 2.2742e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.779e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 4.296e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 4.794e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 4.524e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 30.26780652999878
Epoch 2/9
	 Logging train Loss: 1.2194e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.16e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.931e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.17e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.039e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 30.029219388961792
Epoch 3/9
	 Logging train Loss: 7.953e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.321e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.884e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.359e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.115e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 29.931079387664795
Epoch 4/9
	 Logging train Loss: 1.3813e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.067e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.143e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.899e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.501e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 30.117482662200928
Epoch 5/9
	 Logging train Loss: 1.6791e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.56473e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 5.861e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.73213e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 8.7816e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 31.084038019180298
Epoch 6/9
	 Logging train Loss: 1.4073e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.84e-08 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.23e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.85e-08 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.52e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 31.653179168701172
Epoch 7/9
	 Logging train Loss: 1.0528e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.6e-09 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 3e-09 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 7.7e-09 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 5.2e-09 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 31.70974111557007
Epoch 8/9
	 Logging train Loss: 8.193e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.24e-08 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.9e-09 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.31e-08 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 7e-09 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 31.440173149108887
Epoch 9/9
	 Logging train Loss: 9.103e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.9e-09 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.8e-09 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 7.1e-09 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 4.4e-09 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 31.56185221672058
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'quat_1'_'False'.pth
It took  427.0183525085449  seconds.
----- ITERATION 2/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 50.876441955566406 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_semi_pNone_gTrue took 12.979532480239868 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pNone_gTrue took 12.97916555404663 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pNone_gTrue took 12.978679656982422 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 12.786513328552246 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0001917019 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.5001e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 5.3736e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 5.5108e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 5.4363e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 30.92371916770935
Epoch 1/9
	 Logging train Loss: 2.5052e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.86775e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.1704e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.95021e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 9.4244e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 30.98875069618225
Epoch 2/9
	 Logging train Loss: 1.1947e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.958e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 3.727e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.972e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.844e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 31.134105443954468
Epoch 3/9
	 Logging train Loss: 1.4511e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.7608e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 3.808e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.9664e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.0081e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 30.761786699295044
Epoch 4/9
	 Logging train Loss: 2.0113e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.076e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue â–…â–ˆâ–â–‚â–â–â–â–â–â–
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue â–ˆâ–ƒâ–â–â–â–â–â–â–â–
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue â–ƒâ–ˆâ–â–‚â–â–â–â–â–â–
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue â–ƒâ–ˆâ–â–‚â–â–â–â–â–â–
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue 0.0
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue 0.0
wandb:                                 Train loss 0.0
wandb: 
wandb: ğŸš€ View run fresh-deluge-770 at: https://wandb.ai/nreints/ThesisFinal2/runs/nfdhiviz
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_170156-nfdhiviz/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_170900-h7t93y8r
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run earthy-night-789
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ğŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/h7t93y8r
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue â–‡â–‚â–â–â–ˆâ–‚â–â–â–â–
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue â–ˆâ–ƒâ–â–â–‚â–â–â–â–â–
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue â–„â–‚â–â–â–ˆâ–‚â–â–â–â–
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue â–„â–‚â–â–â–ˆâ–‚â–â–â–â–
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue 0.0
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue 0.0
wandb:                                 Train loss 0.0
wandb: 
wandb: ğŸš€ View run earthy-night-789 at: https://wandb.ai/nreints/ThesisFinal2/runs/h7t93y8r
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_170900-h7t93y8r/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_171601-wxi4b8ql
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run absurd-dragon-802
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ğŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/wxi4b8ql
	 Logging test loss: 2.163e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 8.012e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 4.958e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 30.834796667099
Epoch 5/9
	 Logging train Loss: 1.527e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.024e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.223e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.09e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.614e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 30.848793029785156
Epoch 6/9
	 Logging train Loss: 1.0223e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.281e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 7.04e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.532e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.561e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 30.82986879348755
Epoch 7/9
	 Logging train Loss: 1.1977e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.1e-08 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.02e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.1e-08 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.06e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 30.843141794204712
Epoch 8/9
	 Logging train Loss: 8.542e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.4e-09 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 5.5e-09 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 8.4e-09 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 6.9e-09 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 30.89344596862793
Epoch 9/9
	 Logging train Loss: 6.43e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.7e-09 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.3e-09 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.7e-09 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.5e-09 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 30.934157848358154
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'quat_1'_'False'.pth
It took  424.1511914730072  seconds.
----- ITERATION 3/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 50.74308109283447 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_semi_pNone_gTrue took 12.926260232925415 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pNone_gTrue took 12.921179294586182 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pNone_gTrue took 12.904192686080933 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 12.730633020401001 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0002113375 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.4825e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 6.2533e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 6.5012e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 6.3505e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 30.79131555557251
Epoch 1/9
	 Logging train Loss: 3.7479e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.4211e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.3644e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.4259e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.3883e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 31.013450384140015
Epoch 2/9
	 Logging train Loss: 1.1175e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.204e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 4.039e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 4.217e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 4.109e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 30.739403009414673
Epoch 3/9
	 Logging train Loss: 1.2906e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.243e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 3.188e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.248e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.212e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 30.657520294189453
Epoch 4/9
	 Logging train Loss: 1.8677e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.57336e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 8.186e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.72092e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 7.1361e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 30.77894687652588
Epoch 5/9
	 Logging train Loss: 1.6859e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.3823e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.412e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.5484e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.1307e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 30.600566387176514
Epoch 6/9
	 Logging train Loss: 9.665e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 9.34e-08 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 9.09e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 9.37e-08 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 9.21e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 30.846450328826904
Epoch 7/9
	 Logging train Loss: 1.2926e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 9.901e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 7.27e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.0491e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 4.642e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 30.667035579681396
Epoch 8/9
	 Logging train Loss: 9.722e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.27e-08 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.11e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.28e-08 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.18e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 30.874653816223145
Epoch 9/9
	 Logging train Loss: 4.86e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.7e-09 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.5e-09 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.7e-09 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3e-09 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 30.751171350479126
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'quat_1'_'False'.pth
It took  421.01691603660583  seconds.
----- ITERATION 4/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 50.31021785736084 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_semi_pNone_gTrue took 12.92521858215332 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pNone_gTrue took 12.926298141479492 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pNone_gTrue took 12.934187650680542 seconds.
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue â–ˆâ–‚â–â–â–â–â–â–â–‚â–
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue â–ˆâ–‚â–â–â–â–â–â–â–ƒâ–
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue â–ˆâ–‚â–â–â–â–â–â–â–ƒâ–
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue 0.0
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue 0.0
wandb:                                 Train loss 0.0
wandb: 
wandb: ğŸš€ View run absurd-dragon-802 at: https://wandb.ai/nreints/ThesisFinal2/runs/wxi4b8ql
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_171601-wxi4b8ql/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_172304-hua66zaz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dulcet-pond-819
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ğŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/hua66zaz
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 12.543381929397583 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0001665752 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.8562e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 5.7518e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 5.8603e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 5.8076e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 31.18531084060669
Epoch 1/9
	 Logging train Loss: 3.195e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.0593e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.0102e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.0626e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.0364e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 30.671386003494263
Epoch 2/9
	 Logging train Loss: 1.1234e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.757e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 3.531e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.772e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.653e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 31.003122806549072
Epoch 3/9
	 Logging train Loss: 1.1834e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.873e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 4.049e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.496e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 30.957958698272705
Epoch 4/9
	 Logging train Loss: 2.6227e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.252e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.175e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.258e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.216e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 31.046724796295166
Epoch 5/9
	 Logging train Loss: 1.1631e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.643e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.595e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.704e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.156e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 31.1433687210083
Epoch 6/9
	 Logging train Loss: 1.2228e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.194e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 9.74e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.295e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.147e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 30.901843070983887
Epoch 7/9
	 Logging train Loss: 1.2833e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.64e-08 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 4.77e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 5.69e-08 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 5.24e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 30.87558341026306
Epoch 8/9
	 Logging train Loss: 5.231e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.5895e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.454e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.654e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 8.682e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 30.84813952445984
Epoch 9/9
	 Logging train Loss: 6.795e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 9.6e-09 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 4.7e-09 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 9.9e-09 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 7.3e-09 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 30.9320330619812
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'quat_1'_'False'.pth
It took  422.9915773868561  seconds.
----- ITERATION 5/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 50.687594413757324 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_semi_pNone_gTrue took 12.883040428161621 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pNone_gTrue took 12.867112398147583 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pNone_gTrue took 12.872554063796997 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 12.674307584762573 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0002605619 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.561e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 5.4204e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 5.5769e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 5.4893e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 30.985730409622192
Epoch 1/9
	 Logging train Loss: 3.0381e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.1651e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.1225e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.1674e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.1438e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 31.058279991149902
Epoch 2/9
	 Logging train Loss: 6.206e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.4e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 4.196e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 4.41e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 4.3e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 30.928527355194092
Epoch 3/9
	 Logging train Loss: 2.8362e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.69e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 3.61e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.698e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.653e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 31.010414123535156
Epoch 4/9
	 Logging train Loss: 5.284e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.91e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 3.024e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 5.062e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.947e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 31.134114503860474
Epoch 5/9
	 Logging train Loss: 1.7689e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.332e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.311e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.333e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.321e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 31.320295810699463
Epoch 6/9
	 Logging train Loss: 1.4113e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.662e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue â–ˆâ–‚â–‚â–â–â–â–â–‚â–â–
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue â–ˆâ–‚â–‚â–â–â–â–â–â–â–
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue â–ˆâ–‚â–‚â–â–‚â–â–â–‚â–â–
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue â–ˆâ–‚â–‚â–â–‚â–â–â–‚â–â–
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue 0.0
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue 0.0
wandb:                                 Train loss 0.0
wandb: 
wandb: ğŸš€ View run dulcet-pond-819 at: https://wandb.ai/nreints/ThesisFinal2/runs/hua66zaz
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_172304-hua66zaz/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_173009-gyv26v1k
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run woven-thunder-840
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ğŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/gyv26v1k
wandb: Waiting for W&B process to finish... (success).
wandb: ERROR Error while calling W&B API: An internal error occurred. Please contact support. (<Response [500]>)
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue â–ˆâ–ƒâ–â–„â–â–â–â–â–â–‚
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue â–ˆâ–ƒâ–â–â–â–â–â–â–â–
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue â–ˆâ–ƒâ–â–†â–â–â–â–â–‚â–ƒ
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue â–ˆâ–ƒâ–â–‡â–â–â–â–â–‚â–ƒ
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue 0.0
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue 0.0
wandb:                                 Train loss 0.0
wandb: 
wandb: ğŸš€ View run woven-thunder-840 at: https://wandb.ai/nreints/ThesisFinal2/runs/gyv26v1k
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_173009-gyv26v1k/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_173707-1narwyml
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run daily-pyramid-855
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ğŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/1narwyml
	 Logging test loss: 1.648e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.663e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.655e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 31.152218103408813
Epoch 7/9
	 Logging train Loss: 1.3698e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.557e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.4e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 7.87e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 4.645e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 31.158849239349365
Epoch 8/9
	 Logging train Loss: 9.442e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.3e-08 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 5.21e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 5.3e-08 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 5.26e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 30.664263486862183
Epoch 9/9
	 Logging train Loss: 6.683e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.81e-08 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.17e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.82e-08 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.49e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 31.075191497802734
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'quat_1'_'False'.pth
It took  425.0094668865204  seconds.
----- ITERATION 6/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 49.879154682159424 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_semi_pNone_gTrue took 12.730721235275269 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pNone_gTrue took 12.765581846237183 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pNone_gTrue took 12.721879243850708 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 12.711666822433472 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0010407001 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.7738e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 7.5415e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 7.7989e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 7.6597e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 30.49092674255371
Epoch 1/9
	 Logging train Loss: 5.0319e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.4565e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.3736e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.4651e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.4161e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 30.77347207069397
Epoch 2/9
	 Logging train Loss: 1.0124e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.499e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 4.033e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 4.564e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 4.274e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 30.663828134536743
Epoch 3/9
	 Logging train Loss: 7.216e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.2501e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 4.518e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 6.3118e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.0274e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 30.527747869491577
Epoch 4/9
	 Logging train Loss: 1.2201e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.429e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.311e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.444e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.372e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 30.468760013580322
Epoch 5/9
	 Logging train Loss: 1.6381e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.664e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.61e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.669e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.637e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 30.57579016685486
Epoch 6/9
	 Logging train Loss: 2.3441e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.029e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 9.86e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.034e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.007e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 30.154335498809814
Epoch 7/9
	 Logging train Loss: 1.6957e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.8e-08 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 4.85e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 7.16e-08 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 5.92e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 30.54465103149414
Epoch 8/9
	 Logging train Loss: 6.357e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.428e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 4.33e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 9e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 4.499e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 30.58548378944397
Epoch 9/9
	 Logging train Loss: 1.1331e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.9955e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.108e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.2372e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.0732e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 30.530916213989258
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'quat_1'_'False'.pth
It took  417.92829608917236  seconds.
----- ITERATION 7/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 49.58867430686951 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_semi_pNone_gTrue took 12.680083990097046 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pNone_gTrue took 12.723101377487183 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pNone_gTrue took 12.7124662399292 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 12.614469766616821 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0002343013 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.6267e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 3.5524e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.6408e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.5933e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 31.80215620994568
Epoch 1/9
	 Logging train Loss: 1.5809e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue â–ˆâ–ƒâ–‚â–ƒâ–‚â–â–â–‚â–â–
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue â–ˆâ–‚â–‚â–â–â–â–â–‚â–â–
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue â–ˆâ–…â–‚â–„â–‚â–â–â–‚â–â–
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue â–ˆâ–…â–‚â–„â–‚â–â–â–ƒâ–â–
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue 0.0
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue 0.0
wandb:                                 Train loss 0.0
wandb: 
wandb: ğŸš€ View run daily-pyramid-855 at: https://wandb.ai/nreints/ThesisFinal2/runs/1narwyml
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_173707-1narwyml/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_174419-hqbochqi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fragrant-plasma-875
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ğŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/hqbochqi
	 Logging test loss: 1.9491e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 3.906e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.1303e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.192e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 32.22176384925842
Epoch 2/9
	 Logging train Loss: 7.173e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.85e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.643e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.872e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.747e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 31.82654333114624
Epoch 3/9
	 Logging train Loss: 1.141e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.5144e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.421e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.6454e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 8.981e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 32.10507559776306
Epoch 4/9
	 Logging train Loss: 1.303e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.098e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.289e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 4.34e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.719e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 31.71615719795227
Epoch 5/9
	 Logging train Loss: 1.4218e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.12e-08 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 6.65e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 7.18e-08 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 6.89e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 32.21060872077942
Epoch 6/9
	 Logging train Loss: 7.733e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.39e-08 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.98e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.44e-08 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.19e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 31.927510023117065
Epoch 7/9
	 Logging train Loss: 9.379e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.724e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 6.793e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 7.849e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 7.258e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 31.9933819770813
Epoch 8/9
	 Logging train Loss: 1.3023e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6e-09 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 3.4e-09 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 6.3e-09 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 4.7e-09 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 32.122775077819824
Epoch 9/9
	 Logging train Loss: 4.388e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3e-09 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.1e-09 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.2e-09 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.1e-09 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 31.902994871139526
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'quat_1'_'False'.pth
It took  432.00779604911804  seconds.
----- ITERATION 8/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 49.31642508506775 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_semi_pNone_gTrue took 12.703224420547485 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pNone_gTrue took 12.689096212387085 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pNone_gTrue took 12.792560815811157 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 12.700916528701782 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0003642202 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.0694e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 4.9232e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 5.0763e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 4.9898e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 30.399245262145996
Epoch 1/9
	 Logging train Loss: 1.8763e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.188e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 3.754e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 4.225e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.957e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 30.64103889465332
Epoch 2/9
	 Logging train Loss: 3.327e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.934e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.66e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.955e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.788e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 30.419592142105103
Epoch 3/9
	 Logging train Loss: 6.274e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.239e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.833e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.268e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.022e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 30.43254518508911
Epoch 4/9
	 Logging train Loss: 1.3368e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.253e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.17e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.258e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.208e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 30.49919104576111
Epoch 5/9
	 Logging train Loss: 1.45e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.13e-08 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 6.7e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 7.16e-08 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 6.89e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 30.54921841621399
Epoch 6/9
	 Logging train Loss: 9.889e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.495e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 5.93e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.569e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.028e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 30.580259799957275
Epoch 7/9
	 Logging train Loss: 1.9019e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.46e-08 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.27e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.48e-08 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.36e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 30.640140056610107
Epoch 8/9
	 Logging train Loss: 6.346e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue â–ˆâ–‚â–â–â–â–â–â–â–â–‚
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue â–ˆâ–‚â–â–â–â–â–â–â–â–‚
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue 0.0
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue 0.0
wandb:                                 Train loss 0.0
wandb: 
wandb: ğŸš€ View run fragrant-plasma-875 at: https://wandb.ai/nreints/ThesisFinal2/runs/hqbochqi
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_174419-hqbochqi/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_175117-0ueetmf9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run genial-universe-891
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ğŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/0ueetmf9
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue â–ƒâ–â–ˆâ–â–â–â–â–â–‚â–
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue â–ˆâ–‚â–ƒâ–â–â–‚â–â–â–â–
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue â–‚â–â–ˆâ–â–â–â–â–â–‚â–
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue â–‚â–â–ˆâ–â–â–â–â–â–‚â–
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue 0.0
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue 0.0
wandb:                                 Train loss 0.0
wandb: 
wandb: ğŸš€ View run genial-universe-891 at: https://wandb.ai/nreints/ThesisFinal2/runs/0ueetmf9
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_175117-0ueetmf9/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_175827-tlq5r1w3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cool-deluge-912
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ğŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/tlq5r1w3
	 Logging test loss: 1.573e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 4.17e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.781e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.005e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 30.573651552200317
Epoch 9/9
	 Logging train Loss: 1.0739e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.85e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 3.17e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 6.406e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.999e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 30.23788547515869
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'quat_1'_'False'.pth
It took  418.36481952667236  seconds.
----- ITERATION 9/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 49.42717242240906 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_semi_pNone_gTrue took 12.734452247619629 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pNone_gTrue took 12.745924472808838 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pNone_gTrue took 12.765261888504028 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 12.286324977874756 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0001918654 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.265e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 4.1967e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 4.2641e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 4.2329e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 31.65239405632019
Epoch 1/9
	 Logging train Loss: 1.3686e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.962e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 3.749e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.965e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.863e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 32.21908473968506
Epoch 2/9
	 Logging train Loss: 2.3831e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.62831e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.0309e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.6398e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.42511e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 31.727877378463745
Epoch 3/9
	 Logging train Loss: 1.8454e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.928e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.846e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.927e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.89e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 32.15340447425842
Epoch 4/9
	 Logging train Loss: 1.8074e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.053e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.022e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.052e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.038e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 31.9395854473114
Epoch 5/9
	 Logging train Loss: 1.301e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.1509e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 6.455e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.1411e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 9.086e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 31.915627479553223
Epoch 6/9
	 Logging train Loss: 9.241e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.44e-08 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.31e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.39e-08 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.9e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 31.800232887268066
Epoch 7/9
	 Logging train Loss: 7.245e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.3e-09 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.3e-09 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.3e-09 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.8e-09 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 31.83298110961914
Epoch 8/9
	 Logging train Loss: 6.288e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.2789e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.944e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 4.2311e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.3239e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 31.049031496047974
Epoch 9/9
	 Logging train Loss: 5.875e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.3e-08 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.9e-09 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.27e-08 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 7.9e-09 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 31.07206630706787
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'quat_1'_'False'.pth
It took  429.88528084754944  seconds.
----- ITERATION 10/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 50.5156991481781 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_semi_pNone_gTrue took 12.819427251815796 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pNone_gTrue took 12.829439640045166 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pNone_gTrue took 12.782521486282349 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 12.75720739364624 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.000148603 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.1165e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 3.9347e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 4.142e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 4.03e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 31.056163549423218
Epoch 1/9
	 Logging train Loss: 1.8051e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.146e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 4.667e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 6.338e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 5.447e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 31.276673793792725
Epoch 2/9
	 Logging train Loss: 1.7386e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.455e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 3.246e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.474e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.352e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 30.937812328338623
Epoch 3/9
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue â–ˆâ–‚â–‚â–â–â–â–â–‚â–ƒâ–
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue â–ˆâ–‚â–‚â–â–â–â–â–â–‚â–
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue â–ˆâ–‚â–‚â–â–â–â–â–‚â–…â–
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue â–ˆâ–‚â–‚â–â–â–â–â–‚â–…â–
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue 0.0
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue 0.0
wandb:                                 Train loss 0.0
wandb: 
wandb: ğŸš€ View run cool-deluge-912 at: https://wandb.ai/nreints/ThesisFinal2/runs/tlq5r1w3
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_175827-tlq5r1w3/logs
	 Logging train Loss: 1.1722e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.273e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.214e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.28e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.244e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 30.894754648208618
Epoch 4/9
	 Logging train Loss: 1.5021e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.353e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.317e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.357e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.334e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 30.905771017074585
Epoch 5/9
	 Logging train Loss: 1.6575e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.7e-08 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 6.26e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 6.77e-08 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 6.49e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 31.094930410385132
Epoch 6/9
	 Logging train Loss: 8.686e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.79e-08 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.14e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.89e-08 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.49e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 31.082365036010742
Epoch 7/9
	 Logging train Loss: 9.318e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.493e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 4.26e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 7.365e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.558e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 31.175662517547607
Epoch 8/9
	 Logging train Loss: 5.535e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.3435e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 3.72e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.4851e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.3585e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 31.193318605422974
Epoch 9/9
	 Logging train Loss: 6.781e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.6e-09 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 9e-10 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.7e-09 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.2e-09 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 30.992313146591187
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'quat_1'_'False'.pth
It took  424.94206380844116  seconds.

JOB STATISTICS
==============
Job ID: 3037754
Array Job ID: 3037727_47
Cluster: snellius
User/Group: nreints/nreints
State: RUNNING
Nodes: 1
Cores per node: 18
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 21:17:42 core-walltime
Job Wall-clock time: 01:10:59
Memory Utilized: 0.00 MB (estimated maximum)
Memory Efficiency: 0.00% of 0.00 MB (0.00 MB/node)
WARNING: Efficiency statistics may be misleading for RUNNING jobs.
