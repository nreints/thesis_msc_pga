wandb: Currently logged in as: nreints. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_165343-p1u4hmym
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run warm-deluge-747
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/p1u4hmym
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue â–ˆâ–‚â–ƒâ–…â–„â–â–â–â–„â–
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue â–ˆâ–‚â–‚â–‚â–‚â–â–â–â–‚â–
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue â–ˆâ–‚â–ƒâ–‡â–…â–â–â–â–†â–
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue â–ˆâ–‚â–ƒâ–‡â–…â–â–â–â–…â–
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.0
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.0
wandb:                                 Train loss 0.0
wandb: 
wandb: ðŸš€ View run warm-deluge-747 at: https://wandb.ai/nreints/ThesisFinal2/runs/p1u4hmym
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_165343-p1u4hmym/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_170115-4jv5ntei
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glamorous-pond-766
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/4jv5ntei
Training on dataset: data_t(0,0)_r(0,0)_combi_pTrue_gTrue
Testing on 4 datasets: ['data_t(0,0)_r(0,0)_semi_pTrue_gTrue', 'data_t(0,0)_r(0,0)_combi_pTrue_gTrue', 'data_t(0,0)_r(0,0)_full_pTrue_gTrue', 'data_t(0,0)_r(0,0)_tennis_pTrue_gTrue']
Focussing on identity: True
Using extra input: False
Using fr-fr as reference point.
----- ITERATION 1/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 52.4756715297699 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 13.09937334060669 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 12.05187177658081 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 12.109179973602295 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 12.28071904182434 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0002389945 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.8547e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 2.5513e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.4305e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 3.2753e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 34.99961829185486
Epoch 1/9
	 Logging train Loss: 1.0663e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 5.117e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 4.404e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 3.532e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 5.924e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 33.61948847770691
Epoch 2/9
	 Logging train Loss: 8.823e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 9.158e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 6.316e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 3.025e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 1.0534e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 33.36200189590454
Epoch 3/9
	 Logging train Loss: 1.6384e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.5741e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 1.4811e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.852e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 2.8172e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 33.68290376663208
Epoch 4/9
	 Logging train Loss: 1.5344e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.5517e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 1.0044e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 3.42e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 1.7629e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 33.196752309799194
Epoch 5/9
	 Logging train Loss: 1.9719e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.395e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 1.763e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.162e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 2.614e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 33.48184943199158
Epoch 6/9
	 Logging train Loss: 1.4677e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.56e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 1.155e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 7.01e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 1.689e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 33.42378497123718
Epoch 7/9
	 Logging train Loss: 1.3315e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 8.69e-08 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 6.82e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 4.49e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 9.39e-08 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 33.27014398574829
Epoch 8/9
	 Logging train Loss: 1.1691e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.8707e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 1.1836e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 3.576e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 1.9855e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 33.23254728317261
Epoch 9/9
	 Logging train Loss: 6.966e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 8.37e-08 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 7.03e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 5.38e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 8.8e-08 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 33.38429141044617
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pTrue_gTrue/'dual_quat_1'_'False'.pth
It took  453.1164128780365  seconds.
----- ITERATION 2/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 44.778802156448364 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 11.958990573883057 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 11.2006094455719 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 11.216176748275757 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 11.235982656478882 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 9.43239e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.0088e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 8.784e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 6.867e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 1.1991e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 33.5906879901886
Epoch 1/9
	 Logging train Loss: 1.0422e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.5716e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 1.0694e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 3.705e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 1.7186e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 33.597559213638306
Epoch 2/9
	 Logging train Loss: 2.1056e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.653e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 1.31e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 9.03e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 1.975e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 33.44736075401306
Epoch 3/9
	 Logging train Loss: 1.0965e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.654e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 1.168e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 4.8e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 1.838e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 33.2971396446228
Epoch 4/9
	 Logging train Loss: 2.0745e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 7.73e-08 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue â–‡â–ˆâ–‚â–â–â–…â–ƒâ–â–„â–ƒ
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue â–ˆâ–…â–‚â–â–â–„â–ƒâ–â–‚â–ƒ
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue â–…â–ˆâ–â–â–â–…â–ƒâ–â–„â–ƒ
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue â–†â–ˆâ–â–â–â–…â–ƒâ–â–„â–ƒ
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.0
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.0
wandb:                                 Train loss 0.0
wandb: 
wandb: ðŸš€ View run glamorous-pond-766 at: https://wandb.ai/nreints/ThesisFinal2/runs/4jv5ntei
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_170115-4jv5ntei/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_170832-uva2wkqi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lyric-surf-785
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/uva2wkqi
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue â–ˆâ–‚â–â–â–â–â–‚â–â–â–
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue â–ˆâ–‚â–‚â–â–â–â–‚â–â–â–
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue â–ˆâ–‚â–‚â–â–â–â–‚â–â–â–
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.0
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.0
wandb:                                 Train loss 0.0
wandb: 
wandb: ðŸš€ View run lyric-surf-785 at: https://wandb.ai/nreints/ThesisFinal2/runs/uva2wkqi
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_170832-uva2wkqi/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_171549-s7yo4cx7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run polished-night-800
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/s7yo4cx7
	 Logging test loss: 5.66e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 3.02e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 8.47e-08 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 33.369741678237915
Epoch 5/9
	 Logging train Loss: 7.488e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 9.144e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 6.596e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 3.429e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 9.592e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 33.513781785964966
Epoch 6/9
	 Logging train Loss: 8.563e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 4.391e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 3.415e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.177e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 4.781e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 33.41439199447632
Epoch 7/9
	 Logging train Loss: 8.896e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 7.61e-08 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 5.62e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 3.22e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 8.19e-08 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 33.488682985305786
Epoch 8/9
	 Logging train Loss: 5.313e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 7.448e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 4.983e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.556e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 7.972e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 33.174763679504395
Epoch 9/9
	 Logging train Loss: 5.626e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 4.596e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 3.505e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.055e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 4.779e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 33.767858028411865
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pTrue_gTrue/'dual_quat_1'_'False'.pth
It took  436.9989535808563  seconds.
----- ITERATION 3/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 44.70287775993347 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 11.792881965637207 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 11.241103887557983 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 11.206582069396973 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 11.193760633468628 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0004341164 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.03163e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 9.1786e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 5.4702e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 1.04038e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 33.32159447669983
Epoch 1/9
	 Logging train Loss: 3.1319e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.1289e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 1.8274e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.0314e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 2.1639e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 33.722251892089844
Epoch 2/9
	 Logging train Loss: 8.086e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 8.825e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 7.268e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 4.192e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 9.022e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 33.26123237609863
Epoch 3/9
	 Logging train Loss: 1.4966e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 6.808e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 5.8e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 3.537e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 6.949e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 33.497318744659424
Epoch 4/9
	 Logging train Loss: 1.7632e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 5.883e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 4.924e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.847e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 6.066e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 33.37834048271179
Epoch 5/9
	 Logging train Loss: 1.7292e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 4.454e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 3.759e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.263e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 4.556e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 33.564491510391235
Epoch 6/9
	 Logging train Loss: 1.9933e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.8038e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 1.0464e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.697e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 1.8333e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 33.81727910041809
Epoch 7/9
	 Logging train Loss: 1.7798e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.41e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 1.997e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.167e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 2.519e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 33.586636781692505
Epoch 8/9
	 Logging train Loss: 1.0745e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 4.01e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 2.527e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 8.45e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 4.069e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 33.56407690048218
Epoch 9/9
	 Logging train Loss: 1.2504e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.042e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 8.52e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 5.25e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 1.135e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 33.5234317779541
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pTrue_gTrue/'dual_quat_1'_'False'.pth
It took  436.9325592517853  seconds.
----- ITERATION 4/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 44.905131101608276 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 11.196643114089966 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 11.249521970748901 seconds.
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue â–ˆâ–‚â–â–â–‚â–â–â–â–‚â–‚
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue â–ˆâ–‚â–â–â–‚â–â–â–â–‚â–‚
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue â–ˆâ–‚â–â–â–‚â–â–â–â–‚â–‚
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.0
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.0
wandb:                                 Train loss 0.0
wandb: 
wandb: ðŸš€ View run polished-night-800 at: https://wandb.ai/nreints/ThesisFinal2/runs/s7yo4cx7
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_171549-s7yo4cx7/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_172305-1sv111f1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run divine-pond-820
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/1sv111f1
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 11.178328037261963 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 11.183666706085205 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0003966032 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 7.6454e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 5.1518e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 5.6249e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 6.5388e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 33.825162410736084
Epoch 1/9
	 Logging train Loss: 3.0351e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.3316e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 9.104e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 8.633e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 1.1999e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 33.26893925666809
Epoch 2/9
	 Logging train Loss: 6.271e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 6.181e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 4.082e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 3.939e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 5.55e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 33.60023331642151
Epoch 3/9
	 Logging train Loss: 1.0347e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 5.009e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 3.327e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 3.241e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 4.413e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 33.47724437713623
Epoch 4/9
	 Logging train Loss: 1.2436e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.1787e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 6.904e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 3.11e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 1.1265e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 33.54873609542847
Epoch 5/9
	 Logging train Loss: 1.2488e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 3.59e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 2.326e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.98e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 3.266e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 33.691200971603394
Epoch 6/9
	 Logging train Loss: 1.2061e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 3.461e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 2.26e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.572e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 3.281e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 33.439719438552856
Epoch 7/9
	 Logging train Loss: 1.3257e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.45e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 1.007e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 8.69e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 1.42e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 33.27825927734375
Epoch 8/9
	 Logging train Loss: 1.0826e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 8.418e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 5.149e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.159e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 9.331e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 33.19054651260376
Epoch 9/9
	 Logging train Loss: 9.35e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.2946e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 7.075e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 7.66e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 1.3142e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 33.13873839378357
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pTrue_gTrue/'dual_quat_1'_'False'.pth
It took  435.98550629615784  seconds.
----- ITERATION 5/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 45.08200550079346 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 11.212906837463379 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 11.408825874328613 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 11.189135789871216 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 11.176836967468262 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0003752979 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 7.9959e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 5.535e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 4.8257e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 6.2695e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 32.954113245010376
Epoch 1/9
	 Logging train Loss: 2.3736e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.214e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 8.223e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 6.01e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 9.478e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 33.122958183288574
Epoch 2/9
	 Logging train Loss: 5.742e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 6.997e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 4.766e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 4.023e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 5.588e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 33.0096116065979
Epoch 3/9
	 Logging train Loss: 1.0479e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 5.577e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 3.806e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 3.07e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 4.593e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 32.955819845199585
Epoch 4/9
	 Logging train Loss: 1.3163e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 3.961e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 2.715e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.184e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 3.291e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 33.12350249290466
Epoch 5/9
	 Logging train Loss: 1.4512e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 6.159e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 3.683e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.595e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 6.019e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 33.09690546989441
Epoch 6/9
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue â–†â–‚â–â–â–â–â–â–â–â–ˆ
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue â–ˆâ–‚â–â–â–â–â–â–â–â–ƒ
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue â–…â–â–â–â–â–â–â–â–â–ˆ
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue â–„â–â–â–â–â–â–â–â–â–ˆ
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue 1e-05
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 1e-05
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 1e-05
wandb:                                 Train loss 0.0
wandb: 
wandb: ðŸš€ View run divine-pond-820 at: https://wandb.ai/nreints/ThesisFinal2/runs/1sv111f1
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_172305-1sv111f1/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_173019-yu9o8dos
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pretty-waterfall-841
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/yu9o8dos
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue â–ˆâ–‚â–‚â–‚â–â–â–‚â–â–‚â–‚
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue â–ˆâ–‚â–‚â–â–â–â–â–â–‚â–
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue â–ˆâ–‚â–‚â–‚â–â–â–‚â–â–â–‚
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue â–ˆâ–‚â–‚â–‚â–â–â–‚â–â–â–‚
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.0
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.0
wandb:                                 Train loss 0.0
wandb: 
wandb: ðŸš€ View run pretty-waterfall-841 at: https://wandb.ai/nreints/ThesisFinal2/runs/yu9o8dos
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_173019-yu9o8dos/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_173731-zva7mmuq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run astral-wildflower-856
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/zva7mmuq
	 Logging train Loss: 1.2018e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 9.325e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 5.246e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.123e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 9.241e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 32.99539375305176
Epoch 7/9
	 Logging train Loss: 1.4862e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 3.548e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 2.102e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 6.39e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 3.54e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 32.847073793411255
Epoch 8/9
	 Logging train Loss: 9.464e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 4.068e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 2.518e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.023e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 4.3e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 32.75749135017395
Epoch 9/9
	 Logging train Loss: 9.836e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.30457e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 7.5785e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.1243e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 1.48681e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 32.90850114822388
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pTrue_gTrue/'dual_quat_1'_'False'.pth
It took  434.06087827682495  seconds.
----- ITERATION 6/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 45.255552530288696 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 11.175172805786133 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 11.304453134536743 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 11.262560367584229 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 11.209988355636597 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0003435118 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 5.0555e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 3.8586e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 3.3766e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 4.6316e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 33.084155321121216
Epoch 1/9
	 Logging train Loss: 1.3502e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 7.975e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 5.759e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 4.196e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 7.713e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 33.196102142333984
Epoch 2/9
	 Logging train Loss: 4.661e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 4.746e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 3.552e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.746e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 4.454e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 32.96712279319763
Epoch 3/9
	 Logging train Loss: 5.876e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 5.17e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 3.53e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.004e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 5.266e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 32.77486801147461
Epoch 4/9
	 Logging train Loss: 1.1785e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.231e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 1.589e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.027e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 2.201e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 32.72043013572693
Epoch 5/9
	 Logging train Loss: 1.039e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.623e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 1.098e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 5.83e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 1.649e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 32.983256578445435
Epoch 6/9
	 Logging train Loss: 1.3871e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 8.86e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 5.288e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.075e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 9.845e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 32.8328115940094
Epoch 7/9
	 Logging train Loss: 1.0129e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 9.35e-08 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 6.2e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.9e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 9.55e-08 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 33.06000542640686
Epoch 8/9
	 Logging train Loss: 1.3425e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 3.903e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 3.688e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 3.418e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 3.936e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 33.29082703590393
Epoch 9/9
	 Logging train Loss: 6.052e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 4.846e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 3.894e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.571e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 5.149e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 33.077768087387085
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pTrue_gTrue/'dual_quat_1'_'False'.pth
It took  431.9490122795105  seconds.
----- ITERATION 7/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 45.31268382072449 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 11.191712856292725 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 11.39126992225647 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 11.261731147766113 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 11.242488622665405 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0003498887 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 6.8797e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 4.453e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 4.4932e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 4.998e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue â–„â–â–â–â–â–ƒâ–ˆâ–‚â–â–
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue â–ˆâ–‚â–â–â–â–„â–ƒâ–ƒâ–â–
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue â–ƒâ–â–â–â–â–ƒâ–ˆâ–‚â–â–
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue â–ƒâ–â–â–â–â–ƒâ–ˆâ–‚â–â–
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.0
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.0
wandb:                                 Train loss 0.0
wandb: 
wandb: ðŸš€ View run astral-wildflower-856 at: https://wandb.ai/nreints/ThesisFinal2/runs/zva7mmuq
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_173731-zva7mmuq/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_174445-f08802y7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run leafy-river-876
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/f08802y7
		--> Epoch time; 32.756858110427856
Epoch 1/9
	 Logging train Loss: 2.2596e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 9.45e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 5.784e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 5.042e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 7.065e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 32.94503569602966
Epoch 2/9
	 Logging train Loss: 5.611e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 5.869e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 3.618e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 3.138e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 4.438e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 33.017953395843506
Epoch 3/9
	 Logging train Loss: 1.0319e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.0181e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 5.957e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.929e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 1.04e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 33.078209400177
Epoch 4/9
	 Logging train Loss: 1.6657e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 3.662e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 2.336e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.935e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 2.936e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 32.84769034385681
Epoch 5/9
	 Logging train Loss: 2.2289e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 6.1351e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 3.8952e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.6438e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 7.1468e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 32.85913324356079
Epoch 6/9
	 Logging train Loss: 1.4679e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.11806e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 1.18289e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.4346e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 2.22408e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 33.023921489715576
Epoch 7/9
	 Logging train Loss: 1.4476e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.1784e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 1.6727e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.1499e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 2.2727e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 32.960824728012085
Epoch 8/9
	 Logging train Loss: 1.4257e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 8.49e-08 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 5.52e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 4.25e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 7.43e-08 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 32.97952747344971
Epoch 9/9
	 Logging train Loss: 1.1677e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.3859e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 7.335e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 8.73e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 1.5815e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 32.82891273498535
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pTrue_gTrue/'dual_quat_1'_'False'.pth
It took  433.9537274837494  seconds.
----- ITERATION 8/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 45.203019857406616 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 11.17948603630066 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 11.310022830963135 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 11.267361640930176 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 11.163991928100586 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.00035535 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 5.206e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 4.1862e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 3.8764e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 5.6746e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 32.62442135810852
Epoch 1/9
	 Logging train Loss: 1.7565e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 7.466e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 5.804e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 4.696e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 8.587e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 32.717767000198364
Epoch 2/9
	 Logging train Loss: 4.398e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 4.712e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 3.651e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 3.153e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 5.188e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 32.64318585395813
Epoch 3/9
	 Logging train Loss: 1.356e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 5.3317e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 2.9818e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 4.491e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 5.6024e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 32.768271684646606
Epoch 4/9
	 Logging train Loss: 1.263e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.939e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 2.279e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.982e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 3.176e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 32.558382987976074
Epoch 5/9
	 Logging train Loss: 2.0672e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.137e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 1.662e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.39e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 2.332e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 32.67468786239624
Epoch 6/9
	 Logging train Loss: 1.8273e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 6.2976e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 3.6991e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 8.759e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 6.8254e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 32.99582815170288
Epoch 7/9
	 Logging train Loss: 1.8252e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 6.165e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 3.662e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 9.82e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 6.632e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue â–…â–â–â–„â–â–â–„â–â–ˆâ–†
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue â–ˆâ–‚â–â–‚â–â–â–‚â–â–‚â–‚
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue â–„â–â–â–„â–â–â–„â–â–ˆâ–†
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue â–„â–â–â–„â–â–â–„â–â–ˆâ–‡
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue 1e-05
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 1e-05
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 1e-05
wandb:                                 Train loss 0.0
wandb: 
wandb: ðŸš€ View run leafy-river-876 at: https://wandb.ai/nreints/ThesisFinal2/runs/f08802y7
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_174445-f08802y7/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_175154-7z01g1jy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vital-waterfall-893
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/7z01g1jy
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue â–ƒâ–‚â–â–â–â–â–â–â–ƒâ–ˆ
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue â–ˆâ–„â–â–â–â–â–â–â–‚â–ƒ
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue â–‚â–‚â–â–â–â–â–â–â–ƒâ–ˆ
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue â–‚â–‚â–â–â–â–â–â–â–ƒâ–ˆ
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue 4e-05
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 6e-05
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 7e-05
wandb:                                 Train loss 0.0
wandb: 
wandb: ðŸš€ View run vital-waterfall-893 at: https://wandb.ai/nreints/ThesisFinal2/runs/7z01g1jy
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_175154-7z01g1jy/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_175906-4kbv2r3e
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ethereal-disco-914
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/4kbv2r3e
		--> Epoch time; 32.84718060493469
Epoch 8/9
	 Logging train Loss: 1.6319e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.35175e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 7.3171e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 6.095e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 1.39518e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 32.77057504653931
Epoch 9/9
	 Logging train Loss: 5.872e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.05373e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 5.7829e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 5.17e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 1.15318e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 32.732415199279785
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pTrue_gTrue/'dual_quat_1'_'False'.pth
It took  428.94311356544495  seconds.
----- ITERATION 9/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 45.16104507446289 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 11.134503841400146 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 11.41899037361145 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 11.218472957611084 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 11.201374530792236 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0007228635 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.33317e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 1.15481e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 7.4824e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 1.3546e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 32.955517053604126
Epoch 1/9
	 Logging train Loss: 5.049e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 4.9391e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 4.282e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.8063e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 4.9989e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 33.001224756240845
Epoch 2/9
	 Logging train Loss: 1.4951e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.1676e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 9.89e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 5.895e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 1.1818e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 32.83676075935364
Epoch 3/9
	 Logging train Loss: 4.406e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 6.286e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 5.206e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 3.022e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 6.371e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 32.90253925323486
Epoch 4/9
	 Logging train Loss: 1.0164e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.3591e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 9.679e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.934e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 1.4609e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 33.07877588272095
Epoch 5/9
	 Logging train Loss: 2.8454e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 6.896e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 5.27e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.333e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 7.465e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 32.92711400985718
Epoch 6/9
	 Logging train Loss: 1.4306e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 3.457e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 2.915e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.816e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 3.558e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 32.78466296195984
Epoch 7/9
	 Logging train Loss: 1.8978e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.737e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 2.311e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.381e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 2.844e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 32.907204151153564
Epoch 8/9
	 Logging train Loss: 1.2996e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.43925e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 8.4664e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 8.578e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 1.55087e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 33.02973961830139
Epoch 9/9
	 Logging train Loss: 1.4096e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 6.36515e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 3.69428e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.4041e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 6.60224e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 32.74461388587952
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pTrue_gTrue/'dual_quat_1'_'False'.pth
It took  432.0141656398773  seconds.
----- ITERATION 10/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 45.18878722190857 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 11.224786281585693 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pTrue_gTrue took 11.355966329574585 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 11.247385740280151 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 11.176311254501343 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0002524359 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 6.0676e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 3.2122e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 3.7077e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 6.852e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 32.89616513252258
Epoch 1/9
	 Logging train Loss: 2.0039e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 9.443e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 5.156e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 5.18e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 1.0977e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 33.061522006988525
Epoch 2/9
	 Logging train Loss: 4.828e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 5.515e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 3.078e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue â–ƒâ–â–â–â–‚â–‚â–ˆâ–â–â–
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue â–ˆâ–‚â–‚â–â–â–â–ƒâ–â–â–
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue â–ƒâ–â–â–â–‚â–‚â–ˆâ–â–â–
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue â–ƒâ–â–â–â–‚â–‚â–ˆâ–â–â–
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pTrue_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.0
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.0
wandb:                                 Train loss 0.0
wandb: 
wandb: ðŸš€ View run ethereal-disco-914 at: https://wandb.ai/nreints/ThesisFinal2/runs/4kbv2r3e
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_175906-4kbv2r3e/logs
	 Logging test loss: 3.098e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 6.427e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 32.92325782775879
Epoch 3/9
	 Logging train Loss: 1.7166e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 4.431e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 2.488e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.597e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 5.119e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 32.89883613586426
Epoch 4/9
	 Logging train Loss: 1.8423e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.6214e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 1.3991e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.739e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 2.8822e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 32.900755167007446
Epoch 5/9
	 Logging train Loss: 2.3353e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.3432e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 1.2195e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.675e-07 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 2.528e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 33.10033416748047
Epoch 6/9
	 Logging train Loss: 1.181e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 2.38758e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 1.21176e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.0437e-06 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 2.53668e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 32.964537382125854
Epoch 7/9
	 Logging train Loss: 1.2138e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.846e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 1.104e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 7.67e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 2.168e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 32.90599250793457
Epoch 8/9
	 Logging train Loss: 1.0414e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 9.6e-08 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 6.14e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 4.87e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 1.137e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 33.09642171859741
Epoch 9/9
	 Logging train Loss: 9.561e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 1.556e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 9.47e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pTrue_gTrue]
	 Logging test loss: 4.63e-08 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
	 Logging test loss: 1.723e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
		--> Epoch time; 33.05347681045532
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pTrue_gTrue/'dual_quat_1'_'False'.pth
It took  431.1961736679077  seconds.

JOB STATISTICS
==============
Job ID: 3037738
Array Job ID: 3037727_39
Cluster: snellius
User/Group: nreints/nreints
State: RUNNING
Nodes: 1
Cores per node: 18
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 21:51:18 core-walltime
Job Wall-clock time: 01:12:51
Memory Utilized: 0.00 MB (estimated maximum)
Memory Efficiency: 0.00% of 0.00 MB (0.00 MB/node)
WARNING: Efficiency statistics may be misleading for RUNNING jobs.
