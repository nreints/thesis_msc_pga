wandb: Currently logged in as: nreints. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230628_170553-e562tqpc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run devoted-river-16
wandb: ‚≠êÔ∏è View project at https://wandb.ai/nreints/ThesisFinal2
wandb: üöÄ View run at https://wandb.ai/nreints/ThesisFinal2/runs/e562tqpc
wandb: Waiting for W&B process to finish... (failed 1). Press Control-C to abort syncing.
wandb: - 0.018 MB of 0.018 MB uploaded (0.000 MB deduped)wandb: \ 0.018 MB of 0.044 MB uploaded (0.000 MB deduped)wandb: | 0.018 MB of 0.044 MB uploaded (0.000 MB deduped)wandb: üöÄ View run devoted-river-16 at: https://wandb.ai/nreints/ThesisFinal2/runs/e562tqpc
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230628_170553-e562tqpc/logs
Training on dataset: data_t(5,20)_r(0,0)_combi_pNone_gNone
Testing on 5 datasets: ['data_t(5,20)_r(0,0)_combi_pNone_gNone', 'data_t(5,20)_r(0,0)_full_pNone_gNone', 'data_t(5,20)_r(0,0)_none_pNone_gNone', 'data_t(5,20)_r(0,0)_semi_pNone_gNone', 'data_t(5,20)_r(0,0)_tennis_pNone_gNone']
Focussing on identity: False
Using extra input: False
Using fr-fr as reference point.
----- ITERATION 1/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 65.75761198997498 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 16.38649582862854 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_full_pNone_gNone took 15.764350652694702 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_none_pNone_gNone took 16.724112272262573 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_semi_pNone_gNone took 16.105874061584473 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_tennis_pNone_gNone took 15.79336142539978 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: log_quat_1
-- Started Training --
Traceback (most recent call last):
  File "/gpfs/home2/nreints/MScThesis/code/gru.py", line 293, in <module>
    model = model_pipeline(
  File "/gpfs/home2/nreints/MScThesis/code/utils.py", line 338, in model_pipeline
    train_fn(
  File "/gpfs/home2/nreints/MScThesis/code/gru.py", line 144, in train_model
    _, _, preds = model(data_inputs)  # Shape: [batch, frames, n_data]
  File "/home/nreints/.conda/envs/thesis/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1212, in _call_impl
    result = forward_call(*input, **kwargs)
  File "/gpfs/home2/nreints/MScThesis/code/gru.py", line 93, in forward
    x = self.fc(x)
  File "/home/nreints/.conda/envs/thesis/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/nreints/.conda/envs/thesis/lib/python3.10/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: Deterministic behavior was enabled with either `torch.use_deterministic_algorithms(True)` or `at::Context::setDeterministicAlgorithms(true)`, but this operation is not deterministic because it uses CuBLAS and you have CUDA >= 10.2. To enable deterministic behavior in this case, you must set an environment variable before running your PyTorch application: CUBLAS_WORKSPACE_CONFIG=:4096:8 or CUBLAS_WORKSPACE_CONFIG=:16:8. For more information, go to https://docs.nvidia.com/cuda/cublas/index.html#cublasApi_reproducibility
srun: error: gcn43: task 0: Exited with exit code 1
srun: launch/slurm: _step_signal: Terminating StepId=2982935.0

JOB STATISTICS
==============
Job ID: 2982935
Array Job ID: 2982931_4
Cluster: snellius
User/Group: nreints/nreints
State: RUNNING
Nodes: 1
Cores per node: 18
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 00:52:30 core-walltime
Job Wall-clock time: 00:02:55
Memory Utilized: 0.00 MB (estimated maximum)
Memory Efficiency: 0.00% of 0.00 MB (0.00 MB/node)
WARNING: Efficiency statistics may be misleading for RUNNING jobs.
