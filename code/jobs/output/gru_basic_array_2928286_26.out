wandb: Currently logged in as: nreints. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230616_155419-hgi3jyfw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vibrant-frost-4
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal/runs/hgi3jyfw
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone █▆▅▅▄▃▃▂▁▁
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone █▇▆▅▅▄▃▂▁▁
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone █▆▅▄▄▃▂▂▁▁
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone █▆▅▄▄▃▂▂▁▁
wandb:                                   Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone 1e-05
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 1e-05
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 2e-05
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 2e-05
wandb:                                   Train loss 2e-05
wandb: 
wandb: 🚀 View run vibrant-frost-4 at: https://wandb.ai/nreints/ThesisFinal/runs/hgi3jyfw
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230616_155419-hgi3jyfw/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230616_160421-er6n4st2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run balmy-blaze-12
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal/runs/er6n4st2
Training on dataset: data_t(5,20)_r(5,20)_combi_pNone_gNone
Testing on 4 datasets: ['data_t(5,20)_r(5,20)_combi_pNone_gNone', 'data_t(5,20)_r(5,20)_full_pNone_gNone', 'data_t(5,20)_r(5,20)_tennis_pNone_gNone', 'data_t(5,20)_r(5,20)_semi_pNone_gNone']
Focussing on identity: False
Using extra input: None
Using fr-fr as reference point.
----- ITERATION 1/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  800
Number of test simulations:  200
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 20.91939425468445 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 5.092980623245239 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 5.497591018676758 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 5.43848729133606 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 5.461340665817261 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0123022497 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0001110434 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.34323e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.000132542 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.000130359 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 55.845239877700806
Epoch 1/9
	 Logging train Loss: 9.34511e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.65715e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.99386e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 9.83425e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 9.84369e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 53.954572677612305
Epoch 2/9
	 Logging train Loss: 7.769e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.53513e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.23237e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 8.43367e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 8.55203e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 54.00621509552002
Epoch 3/9
	 Logging train Loss: 6.77631e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.49371e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.46055e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 7.23496e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 7.33251e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 53.82896971702576
Epoch 4/9
	 Logging train Loss: 5.84561e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.48689e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.64751e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 6.20499e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 6.25931e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 53.67139387130737
Epoch 5/9
	 Logging train Loss: 4.84275e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.38824e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.67523e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 5.01281e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 5.11965e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 55.26409697532654
Epoch 6/9
	 Logging train Loss: 3.80576e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.42129e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.71186e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.08017e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.15145e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 55.10372877120972
Epoch 7/9
	 Logging train Loss: 2.83673e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.42561e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.82657e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.01525e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.1025e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 54.95212697982788
Epoch 8/9
	 Logging train Loss: 2.04822e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.75656e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.16949e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.30761e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.40943e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 54.914544105529785
Epoch 9/9
	 Logging train Loss: 1.50751e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.26572e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.7204e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.75758e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.87126e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 54.87889742851257
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gNone/'rot_mat_1'_'None'.pth
It took  602.9879121780396  seconds.
----- ITERATION 2/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  800
Number of test simulations:  200
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 18.6835675239563 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 4.6747190952301025 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 4.8754425048828125 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 4.879728317260742 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 4.936750411987305 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0648108646 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0002323749 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0001054599 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0003646404 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0003125664 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 54.759998083114624
Epoch 1/9
	 Logging train Loss: 0.000153825 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0001111373 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.15663e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0001435189 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0001324129 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 58.2320761680603
Epoch 2/9
	 Logging train Loss: 9.86262e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.86688e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.42634e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0001030132 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 9.78239e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 54.28667712211609
Epoch 3/9
	 Logging train Loss: 8.22289e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone █▄▃▃▃▂▂▂▁▁
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone █▆▆▅▅▄▃▃▂▁
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone █▄▃▂▂▂▂▁▁▁
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone █▃▃▂▂▂▂▁▁▁
wandb:                                   Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone 2e-05
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 2e-05
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 3e-05
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 3e-05
wandb:                                   Train loss 3e-05
wandb: 
wandb: 🚀 View run balmy-blaze-12 at: https://wandb.ai/nreints/ThesisFinal/runs/er6n4st2
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230616_160421-er6n4st2/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230616_161421-i9201q8o
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run splendid-silence-19
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal/runs/i9201q8o
	 Logging test loss: 7.77788e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.82934e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 8.72258e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 8.50274e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 54.108779191970825
Epoch 4/9
	 Logging train Loss: 7.28533e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.88994e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.22865e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 7.66852e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 7.63159e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 53.71016597747803
Epoch 5/9
	 Logging train Loss: 6.45965e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.18109e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.48152e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 6.81872e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 6.73155e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 53.82170391082764
Epoch 6/9
	 Logging train Loss: 5.59876e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.17116e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.73894e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 5.95085e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 5.90618e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 54.02721285820007
Epoch 7/9
	 Logging train Loss: 4.61905e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.1739e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.60601e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.86337e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.70526e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 55.53999876976013
Epoch 8/9
	 Logging train Loss: 3.55895e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.06031e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.49222e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.75845e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.65695e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 55.219183921813965
Epoch 9/9
	 Logging train Loss: 2.51769e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.20055e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.55216e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.8333e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.66466e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 54.20132827758789
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gNone/'rot_mat_1'_'None'.pth
It took  599.905791759491  seconds.
----- ITERATION 3/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  800
Number of test simulations:  200
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 18.70030975341797 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 4.654646396636963 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 4.840407609939575 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 4.867491960525513 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 4.858954906463623 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0302793682 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0001571053 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 9.46733e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0002047269 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.000192759 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 55.54671311378479
Epoch 1/9
	 Logging train Loss: 0.0001122317 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 9.80441e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.76447e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0001106068 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0001088129 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 54.697861194610596
Epoch 2/9
	 Logging train Loss: 8.96227e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.74813e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.08356e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 9.67507e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 9.55494e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 57.74902963638306
Epoch 3/9
	 Logging train Loss: 8.21107e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.14506e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.67622e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 8.90311e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 8.75143e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 57.99200487136841
Epoch 4/9
	 Logging train Loss: 7.59722e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.52755e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.16645e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 8.3042e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 8.24345e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 56.336896657943726
Epoch 5/9
	 Logging train Loss: 6.95404e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.09141e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.60552e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 8.00472e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 7.84317e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 56.519912242889404
Epoch 6/9
	 Logging train Loss: 6.22622e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.07652e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.88001e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 6.79305e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 6.68363e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 56.24399948120117
Epoch 7/9
	 Logging train Loss: 5.34569e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.03339e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.00634e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 5.65811e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 5.60926e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 55.43644595146179
Epoch 8/9
	 Logging train Loss: 4.32328e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.26472e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.13535e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 5.0748e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.89807e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 55.260472536087036
Epoch 9/9
	 Logging train Loss: 3.23274e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone █▅▄▄▃▃▃▂▂▁
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone █▆▆▅▅▄▄▃▂▁
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone █▄▄▃▃▃▂▂▂▁
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone █▄▃▃▃▃▂▂▂▁
wandb:                                   Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone 3e-05
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 2e-05
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 4e-05
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 4e-05
wandb:                                   Train loss 3e-05
wandb: 
wandb: 🚀 View run splendid-silence-19 at: https://wandb.ai/nreints/ThesisFinal/runs/i9201q8o
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230616_161421-i9201q8o/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230616_162433-yqhn3dte
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run usual-paper-27
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal/runs/yqhn3dte
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone █▄▃▃▂▂▂▁▁▁
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone █▆▆▅▅▄▄▂▂▁
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone █▃▃▂▂▂▂▁▁▁
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone █▃▂▂▂▂▂▁▁▁
wandb:                                   Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone 2e-05
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 1e-05
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 3e-05
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 3e-05
wandb:                                   Train loss 3e-05
wandb: 
wandb: 🚀 View run usual-paper-27 at: https://wandb.ai/nreints/ThesisFinal/runs/yqhn3dte
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230616_162433-yqhn3dte/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230616_163427-vsf6ok78
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stellar-star-34
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal/runs/vsf6ok78
	 Logging test loss: 3.08718e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.14081e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.84033e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.77026e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 55.88190007209778
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gNone/'rot_mat_1'_'None'.pth
It took  612.0524637699127  seconds.
----- ITERATION 4/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  800
Number of test simulations:  200
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 18.70709800720215 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 4.682668685913086 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 4.810575008392334 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 4.815141677856445 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 4.822742700576782 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0880263373 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0002837362 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 9.81076e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0004574335 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0004099799 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 53.84268617630005
Epoch 1/9
	 Logging train Loss: 0.0001585465 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.000118435 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.6535e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0001543196 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0001522941 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 53.95035767555237
Epoch 2/9
	 Logging train Loss: 0.0001019526 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 9.37896e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.9701e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.000113868 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0001159187 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 53.80295276641846
Epoch 3/9
	 Logging train Loss: 8.39521e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.91177e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.54613e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 8.92508e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 9.61245e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 53.67992925643921
Epoch 4/9
	 Logging train Loss: 7.21582e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.45072e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.49561e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 8.06821e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 9.0048e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 56.55621314048767
Epoch 5/9
	 Logging train Loss: 6.27072e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.80079e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.86687e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 6.45819e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 6.89391e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 54.188843965530396
Epoch 6/9
	 Logging train Loss: 5.36886e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.54063e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.46074e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 6.34642e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 6.79409e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 53.90674161911011
Epoch 7/9
	 Logging train Loss: 4.44165e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.95426e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.07928e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.67007e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.96944e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 53.83598971366882
Epoch 8/9
	 Logging train Loss: 3.4646e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.15543e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.18023e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.01972e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.10296e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 55.46347093582153
Epoch 9/9
	 Logging train Loss: 2.55708e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.2845e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.45249e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.03032e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.20108e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 54.80557417869568
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gNone/'rot_mat_1'_'None'.pth
It took  594.0902593135834  seconds.
----- ITERATION 5/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  800
Number of test simulations:  200
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 18.63762354850769 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 4.677956581115723 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 4.8445048332214355 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 4.871319055557251 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 4.886634588241577 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0295410398 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0001455096 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.74493e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.000199878 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0001991482 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 57.22152090072632
Epoch 1/9
	 Logging train Loss: 0.0001050585 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.74836e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.52728e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0001021941 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0001029392 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 56.61966919898987
Epoch 2/9
	 Logging train Loss: 7.77879e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.23372e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.69046e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 8.01307e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 8.15289e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone █▅▄▃▃▂▂▂▁▁
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone █▇▆▅▄▃▃▂▁▁
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone █▄▃▃▂▂▂▂▁▁
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone █▄▃▃▂▂▂▂▁▁
wandb:                                   Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone 2e-05
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 1e-05
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 3e-05
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 3e-05
wandb:                                   Train loss 2e-05
wandb: 
wandb: 🚀 View run stellar-star-34 at: https://wandb.ai/nreints/ThesisFinal/runs/vsf6ok78
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230616_163427-vsf6ok78/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230616_164439-f9jiqjl5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fragrant-pond-42
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal/runs/f9jiqjl5
		--> Epoch time; 55.97350025177002
Epoch 3/9
	 Logging train Loss: 6.46722e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.26109e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.8557e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 6.835e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 6.99657e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 55.2369225025177
Epoch 4/9
	 Logging train Loss: 5.40049e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.18135e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.02607e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 6.00732e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 6.04055e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 55.6121621131897
Epoch 5/9
	 Logging train Loss: 4.44355e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.35144e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.18744e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.79782e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.94035e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 57.053672552108765
Epoch 6/9
	 Logging train Loss: 3.57023e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.64006e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.54414e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.08323e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.22362e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 56.40889024734497
Epoch 7/9
	 Logging train Loss: 2.77795e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.06279e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.72138e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.95466e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.99398e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 55.659626722335815
Epoch 8/9
	 Logging train Loss: 2.0918e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.11122e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.09754e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.85725e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.91582e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 55.450231313705444
Epoch 9/9
	 Logging train Loss: 1.55376e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.79738e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.7893e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.62664e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.63655e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 55.48792743682861
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gNone/'rot_mat_1'_'None'.pth
It took  611.9264421463013  seconds.
----- ITERATION 6/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  800
Number of test simulations:  200
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 18.750929594039917 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 4.667910575866699 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 4.82032322883606 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 4.830852031707764 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 4.879316329956055 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0268808715 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0001018738 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.57651e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0001249206 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0001201704 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 54.792184591293335
Epoch 1/9
	 Logging train Loss: 8.51262e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.76011e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.40351e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 9.02871e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 8.75059e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 57.74406456947327
Epoch 2/9
	 Logging train Loss: 6.96966e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.3163e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.13044e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 7.34839e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 7.18862e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 54.64853763580322
Epoch 3/9
	 Logging train Loss: 5.62157e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.07369e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.90112e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 5.97918e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 5.8964e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 55.95852065086365
Epoch 4/9
	 Logging train Loss: 4.26912e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.79352e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.67496e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.63749e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.45055e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 55.622034549713135
Epoch 5/9
	 Logging train Loss: 3.11207e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.08208e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.76785e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.15799e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.837e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 55.71536207199097
Epoch 6/9
	 Logging train Loss: 2.3516e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.20797e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.22051e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.96464e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.79026e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 55.728705644607544
Epoch 7/9
	 Logging train Loss: 1.81651e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.86335e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.4995e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.65525e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.5394e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 56.43174147605896
Epoch 8/9
	 Logging train Loss: 1.39633e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.27279e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.3626e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.89388e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.48067e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 55.49493598937988
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone █▆▅▄▃▂▂▁▂▁
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone █▇▆▄▃▂▂▁▁▁
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone █▆▄▄▂▂▁▁▂▁
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone █▆▄▃▂▂▁▁▂▁
wandb:                                   Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone 2e-05
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 2e-05
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 3e-05
wandb:                                   Train loss 1e-05
wandb: 
wandb: 🚀 View run fragrant-pond-42 at: https://wandb.ai/nreints/ThesisFinal/runs/f9jiqjl5
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230616_164439-f9jiqjl5/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230616_165447-odd84iz7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run azure-leaf-50
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal/runs/odd84iz7
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone █▃▂▂▂▁▁▁▁▁
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone █▆▅▄▃▂▂▁▁▁
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone █▃▂▂▁▁▁▁▁▁
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone █▃▂▂▁▁▁▁▁▁
wandb:                                   Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone 1e-05
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 2e-05
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 2e-05
wandb:                                   Train loss 1e-05
wandb: 
wandb: 🚀 View run azure-leaf-50 at: https://wandb.ai/nreints/ThesisFinal/runs/odd84iz7
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230616_165447-odd84iz7/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230616_170453-muajp3bq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run firm-breeze-57
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal/runs/muajp3bq
Epoch 9/9
	 Logging train Loss: 1.15509e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.57636e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.4215e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.54467e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.42164e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 54.43248271942139
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gNone/'rot_mat_1'_'None'.pth
It took  607.7681267261505  seconds.
----- ITERATION 7/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  800
Number of test simulations:  200
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 18.628816843032837 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 4.650147914886475 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 4.786357164382935 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 4.789369583129883 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 4.791104555130005 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0304572918 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0003229096 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.3748e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.00051689 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0004828389 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 55.54897332191467
Epoch 1/9
	 Logging train Loss: 0.0001568367 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0001025105 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.94308e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.000137853 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.000138472 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 55.343812704086304
Epoch 2/9
	 Logging train Loss: 8.39395e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.11058e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.48787e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 9.38309e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 9.40925e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 55.65356159210205
Epoch 3/9
	 Logging train Loss: 6.05304e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.43099e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.50008e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 6.99885e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 7.07149e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 56.27518677711487
Epoch 4/9
	 Logging train Loss: 4.49456e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.9554e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.35076e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 5.27641e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 5.39202e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 54.65232729911804
Epoch 5/9
	 Logging train Loss: 3.40607e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.30682e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.95697e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.41488e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.56387e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 55.02275061607361
Epoch 6/9
	 Logging train Loss: 2.62423e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.51298e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.28122e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.50374e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.61076e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 55.0115270614624
Epoch 7/9
	 Logging train Loss: 2.061e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.95091e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.7198e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.84495e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.98861e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 55.030553102493286
Epoch 8/9
	 Logging train Loss: 1.67211e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.62514e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.4134e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.42721e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.55401e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 55.22370767593384
Epoch 9/9
	 Logging train Loss: 1.41702e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.38582e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.0172e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.11356e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.24469e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 57.81434440612793
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gNone/'rot_mat_1'_'None'.pth
It took  606.8262996673584  seconds.
----- ITERATION 8/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  800
Number of test simulations:  200
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 18.635311126708984 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 4.648038864135742 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 4.764639377593994 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 4.794464826583862 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 4.780205726623535 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0282799676 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0001068899 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.25671e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0001264364 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0001361965 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 56.51742386817932
Epoch 1/9
	 Logging train Loss: 9.38181e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.46011e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.14018e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 9.31616e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0001043915 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 55.894256830215454
Epoch 2/9
	 Logging train Loss: 7.35634e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.41979e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.45512e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 7.05239e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone █▆▅▄▃▂▂▁▁▁
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone █▇▅▅▃▃▂▂▁▁
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone █▆▄▄▃▂▂▁▁▁
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone █▆▄▄▃▂▂▁▁▁
wandb:                                   Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone 1e-05
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 2e-05
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 2e-05
wandb:                                   Train loss 1e-05
wandb: 
wandb: 🚀 View run firm-breeze-57 at: https://wandb.ai/nreints/ThesisFinal/runs/muajp3bq
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230616_170453-muajp3bq/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230616_171455-srlmk40l
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fiery-wave-63
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal/runs/srlmk40l
	 Logging test loss: 7.70993e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 55.74304437637329
Epoch 3/9
	 Logging train Loss: 5.86631e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.30233e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.4818e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 5.77439e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 6.5295e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 54.47714591026306
Epoch 4/9
	 Logging train Loss: 4.61763e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.95882e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.20279e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.39986e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.92809e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 54.64641094207764
Epoch 5/9
	 Logging train Loss: 3.5379e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.18303e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.42399e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.54128e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.97786e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 55.335256814956665
Epoch 6/9
	 Logging train Loss: 2.65884e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.29622e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.52671e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.71614e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.11084e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 54.635372161865234
Epoch 7/9
	 Logging train Loss: 2.00067e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.79776e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.02112e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.21106e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.51375e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 54.713560819625854
Epoch 8/9
	 Logging train Loss: 1.53983e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.37146e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.1453e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.80842e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.11391e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 54.75429701805115
Epoch 9/9
	 Logging train Loss: 1.24298e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.22044e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.2498e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.72594e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.03332e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 54.612433195114136
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gNone/'rot_mat_1'_'None'.pth
It took  602.0360448360443  seconds.
----- ITERATION 9/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  800
Number of test simulations:  200
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 18.635725259780884 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 4.64033579826355 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 4.7797276973724365 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 4.772687196731567 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 4.779880523681641 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0512300357 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0001800426 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 9.75715e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0002835698 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0003107828 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 54.50819182395935
Epoch 1/9
	 Logging train Loss: 0.0001236952 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.84297e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.31387e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0001015759 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0001106659 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 53.98584532737732
Epoch 2/9
	 Logging train Loss: 8.31207e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.56821e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.6307e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 8.10432e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 8.8408e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 53.990991830825806
Epoch 3/9
	 Logging train Loss: 7.09173e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.77849e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.95414e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 7.04856e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 7.5634e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 53.80482625961304
Epoch 4/9
	 Logging train Loss: 6.14026e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.64582e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.0624e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 5.92012e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 6.46876e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 55.157482862472534
Epoch 5/9
	 Logging train Loss: 5.16835e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.97515e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.43415e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 5.28334e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 5.65974e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 55.566447257995605
Epoch 6/9
	 Logging train Loss: 4.17289e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.68922e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.25016e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.10603e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.58572e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 54.90798091888428
Epoch 7/9
	 Logging train Loss: 3.20907e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.64448e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.17831e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.96642e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.33414e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 56.15303325653076
Epoch 8/9
	 Logging train Loss: 2.4309e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.96426e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.49225e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.34026e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone █▄▄▃▃▂▂▁▁▁
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone █▆▆▅▄▄▃▂▁▁
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone █▃▃▂▂▂▁▁▁▁
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone █▃▃▂▂▂▁▁▁▁
wandb:                                   Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone 2e-05
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 1e-05
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 3e-05
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 2e-05
wandb:                                   Train loss 2e-05
wandb: 
wandb: 🚀 View run fiery-wave-63 at: https://wandb.ai/nreints/ThesisFinal/runs/srlmk40l
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230616_171455-srlmk40l/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230616_172452-cmtfuiy3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dainty-sunset-71
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal/runs/cmtfuiy3
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone █▄▃▂▂▂▁▁▁▁
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone █▇▆▅▄▃▃▂▁▁
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone █▃▂▂▂▁▁▁▁▁
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone █▃▂▂▂▁▁▁▁▁
wandb:                                   Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone 3e-05
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 1e-05
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 4e-05
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 4e-05
wandb:                                   Train loss 2e-05
wandb: 
wandb: 🚀 View run dainty-sunset-71 at: https://wandb.ai/nreints/ThesisFinal/runs/cmtfuiy3
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230616_172452-cmtfuiy3/logs
	 Logging test loss: 2.65703e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 54.69086837768555
Epoch 9/9
	 Logging train Loss: 1.85691e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.62592e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 9.5951e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.32403e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.56111e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 54.03062987327576
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gNone/'rot_mat_1'_'None'.pth
It took  596.2016162872314  seconds.
----- ITERATION 10/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  800
Number of test simulations:  200
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 18.60812211036682 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 4.650626182556152 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 4.853094100952148 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 4.843560695648193 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 4.809926748275757 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0722709373 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0002632418 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.8591e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0005137835 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.000476112 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 54.696091651916504
Epoch 1/9
	 Logging train Loss: 0.0001674142 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0001103387 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.23382e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.000148213 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0001499037 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 55.129889249801636
Epoch 2/9
	 Logging train Loss: 9.36514e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.38384e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.08823e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0001037019 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0001069684 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 55.15738320350647
Epoch 3/9
	 Logging train Loss: 7.42956e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.12298e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.4012e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 8.38012e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 8.72484e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 55.1756477355957
Epoch 4/9
	 Logging train Loss: 6.06438e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.60641e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.24956e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 6.45087e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 6.82331e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 55.05849027633667
Epoch 5/9
	 Logging train Loss: 4.91972e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.61371e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.40578e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 5.45598e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 5.65742e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 54.725746393203735
Epoch 6/9
	 Logging train Loss: 3.91624e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.73623e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.82115e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.38846e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.53969e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 54.903627157211304
Epoch 7/9
	 Logging train Loss: 3.0291e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.67203e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.71303e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.3373e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.49729e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 54.8653621673584
Epoch 8/9
	 Logging train Loss: 2.22807e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.11872e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.11802e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.89842e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.02628e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 55.076690912246704
Epoch 9/9
	 Logging train Loss: 1.63973e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.55122e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.0139e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.26577e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.23704e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 55.45915603637695
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gNone/'rot_mat_1'_'None'.pth
It took  599.8703525066376  seconds.

JOB STATISTICS
==============
Job ID: 2928288
Array Job ID: 2928286_26
Cluster: snellius
User/Group: nreints/nreints
State: COMPLETED (exit code 0)
Nodes: 1
Cores per node: 18
CPU Utilized: 16:11:24
CPU Efficiency: 53.49% of 1-06:15:54 core-walltime
Job Wall-clock time: 01:40:53
Memory Utilized: 7.49 GB
Memory Efficiency: 0.00% of 0.00 MB
