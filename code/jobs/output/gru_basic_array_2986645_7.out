wandb: Currently logged in as: nreints. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230629_111855-s0xz5xpf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run different-aardvark-20
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/s0xz5xpf
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone █▅▂▁▂▁▁▁▁▁
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone █▃▂▁▄▁▁▁▂▁
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone █▃▂▁▃▁▁▁▂▁
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone █▅▂▁▁▁▁▁▁▁
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone █▅▂▁▁▁▁▁▁▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone 0.0
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: 🚀 View run different-aardvark-20 at: https://wandb.ai/nreints/ThesisFinal2/runs/s0xz5xpf
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230629_111855-s0xz5xpf/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230629_112551-6dbx365m
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run splendid-music-36
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/6dbx365m
Training on dataset: data_t(0,0)_r(5,20)_combi_pNone_gNone
Testing on 5 datasets: ['data_t(0,0)_r(5,20)_combi_pNone_gNone', 'data_t(0,0)_r(5,20)_none_pNone_gNone', 'data_t(0,0)_r(5,20)_tennis_pNone_gNone', 'data_t(0,0)_r(5,20)_full_pNone_gNone', 'data_t(0,0)_r(5,20)_semi_pNone_gNone']
Focussing on identity: False
Using extra input: False
Using fr-fr as reference point.
----- ITERATION 1/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 50.14372205734253 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 12.435037612915039 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_none_pNone_gNone took 12.421611785888672 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_tennis_pNone_gNone took 12.535185813903809 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_full_pNone_gNone took 11.880373477935791 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_semi_pNone_gNone took 12.144320249557495 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(24, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=24, bias=True)
)
Datatype: pos_diff_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0001479818 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.4338e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.6783e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.51977e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.1147e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.29539e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 29.179974794387817
Epoch 1/9
	 Logging train Loss: 6.355e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.2343e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.018e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 9.3494e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.835e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 9.0268e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 28.968695640563965
Epoch 2/9
	 Logging train Loss: 3.8256e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.589e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.354e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 4.8057e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.392e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.0337e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 29.58335590362549
Epoch 3/9
	 Logging train Loss: 2.1403e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.9062e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.56e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.7141e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.95e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.8851e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 29.051637887954712
Epoch 4/9
	 Logging train Loss: 1.8219e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.1388e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.77e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.8569e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 5.264e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.1225e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 28.82263708114624
Epoch 5/9
	 Logging train Loss: 1.7349e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.7266e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.98e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.3561e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.563e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.7413e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 28.79195737838745
Epoch 6/9
	 Logging train Loss: 1.6783e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.7228e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.38e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.3166e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.043e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.711e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 29.034282684326172
Epoch 7/9
	 Logging train Loss: 1.6306e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.6608e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.91e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.1916e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.679e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.6585e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 28.964174270629883
Epoch 8/9
	 Logging train Loss: 1.5913e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.7662e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.168e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.2437e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.048e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.7706e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 28.87679433822632
Epoch 9/9
	 Logging train Loss: 1.5496e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.6215e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.67e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.0751e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.675e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.61e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 29.236215114593506
Saved model in  trained_models/gru/data_t(0,0)_r(5,20)_combi_pNone_gNone/'pos_diff_1'_'False'.pth
It took  416.5785892009735  seconds.
----- ITERATION 2/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 46.32261061668396 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 11.562495946884155 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_none_pNone_gNone took 12.28882622718811 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_tennis_pNone_gNone took 12.111399173736572 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_full_pNone_gNone took 12.092225313186646 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_semi_pNone_gNone took 12.150848388671875 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(24, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=24, bias=True)
)
Datatype: pos_diff_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.000153311 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.1665e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.7844e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.50928e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.2241e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.33447e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 29.32239818572998
Epoch 1/9
	 Logging train Loss: 6.511e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.9833e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.69e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone █▅▃▁▁▁▁▁▁▁
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone █▄▆▂▁▁▁▁▁▂
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone █▄▅▂▁▁▁▁▁▁
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone █▅▃▁▁▁▁▁▁▁
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone █▅▃▁▁▁▁▁▁▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone 0.0
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: 🚀 View run splendid-music-36 at: https://wandb.ai/nreints/ThesisFinal2/runs/6dbx365m
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230629_112551-6dbx365m/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230629_113240-fa2syn8a
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glad-pyramid-53
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/fa2syn8a
	 Logging test loss: 9.266e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 5.696e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 9.0157e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 29.162902355194092
Epoch 2/9
	 Logging train Loss: 4.1251e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.3558e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.1476e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 5.8194e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 9.597e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 5.2702e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 29.229814529418945
Epoch 3/9
	 Logging train Loss: 2.3335e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.9128e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.604e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.6811e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.065e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.0976e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 29.133880376815796
Epoch 4/9
	 Logging train Loss: 1.8816e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.6872e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.718e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.4229e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.313e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.7958e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 29.312683582305908
Epoch 5/9
	 Logging train Loss: 1.7721e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.5705e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.04e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.2421e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.7e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.6802e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 28.982234954833984
Epoch 6/9
	 Logging train Loss: 1.7059e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.5847e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.439e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.174e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.189e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.7232e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 29.114022970199585
Epoch 7/9
	 Logging train Loss: 1.6588e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.5015e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.687e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.0669e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.576e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.6454e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 28.821271419525146
Epoch 8/9
	 Logging train Loss: 1.6076e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.4937e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.822e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.9806e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.83e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.6639e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 29.262566804885864
Epoch 9/9
	 Logging train Loss: 1.5674e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.5421e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.293e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.9708e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.402e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.7456e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 28.934777975082397
Saved model in  trained_models/gru/data_t(0,0)_r(5,20)_combi_pNone_gNone/'pos_diff_1'_'False'.pth
It took  409.0467345714569  seconds.
----- ITERATION 3/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 46.1039617061615 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 11.504398584365845 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_none_pNone_gNone took 12.039575576782227 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_tennis_pNone_gNone took 12.04450535774231 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_full_pNone_gNone took 12.035110235214233 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_semi_pNone_gNone took 12.008571147918701 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(24, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=24, bias=True)
)
Datatype: pos_diff_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0001522252 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.9102e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.6544e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.50855e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.1763e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.44826e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 29.149107456207275
Epoch 1/9
	 Logging train Loss: 6.2989e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.8837e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.179e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 9.626e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.38e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.05859e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 29.06888747215271
Epoch 2/9
	 Logging train Loss: 4.1876e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.4978e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.678e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 5.8356e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.918e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 5.9303e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 29.173582553863525
Epoch 3/9
	 Logging train Loss: 2.4575e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.4842e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.33e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 4.0988e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 6.044e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.7826e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 29.103947162628174
Epoch 4/9
	 Logging train Loss: 1.8547e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.985e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.264e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.4759e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.087e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.1623e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 29.30099058151245
Epoch 5/9
	 Logging train Loss: 1.7215e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.9906e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.938e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone █▅▃▂▁▁▁▁▁▁
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone █▃▃▄▂▃▂▂▁▁
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone █▃▃▃▂▂▂▂▁▁
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone █▆▃▂▁▁▁▁▁▁
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone █▅▃▂▁▁▁▁▁▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone 0.0
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: 🚀 View run glad-pyramid-53 at: https://wandb.ai/nreints/ThesisFinal2/runs/fa2syn8a
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230629_113240-fa2syn8a/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230629_113931-awtkfxb1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pretty-forest-67
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/awtkfxb1
	 Logging test loss: 3.4417e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.777e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.1233e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 29.14463210105896
Epoch 6/9
	 Logging train Loss: 1.6581e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.8064e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.406e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.2229e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.312e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.9645e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 29.942529678344727
Epoch 7/9
	 Logging train Loss: 1.6077e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.8427e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.816e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.2244e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.868e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.9856e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 29.824385166168213
Epoch 8/9
	 Logging train Loss: 1.5682e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.6819e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.362e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.0293e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.481e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.8391e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 29.444730281829834
Epoch 9/9
	 Logging train Loss: 1.5306e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.6671e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.482e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.9298e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.719e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.8263e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 29.03133797645569
Saved model in  trained_models/gru/data_t(0,0)_r(5,20)_combi_pNone_gNone/'pos_diff_1'_'False'.pth
It took  411.3080883026123  seconds.
----- ITERATION 4/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 45.792253732681274 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 11.466334104537964 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_none_pNone_gNone took 11.900554418563843 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_tennis_pNone_gNone took 11.8575918674469 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_full_pNone_gNone took 11.90881633758545 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_semi_pNone_gNone took 11.905203342437744 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(24, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=24, bias=True)
)
Datatype: pos_diff_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0001612132 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.4276e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.8293e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.3818e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.1612e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.40005e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 29.196455478668213
Epoch 1/9
	 Logging train Loss: 6.7095e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.8185e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 9.252e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 8.8444e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 5.925e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.00752e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 29.38778829574585
Epoch 2/9
	 Logging train Loss: 4.6207e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.1173e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.009e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 5.7737e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.823e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 6.2527e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 29.03710174560547
Epoch 3/9
	 Logging train Loss: 2.7833e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.0967e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.967e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.8115e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 5.345e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.6169e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 29.297483682632446
Epoch 4/9
	 Logging train Loss: 2.0011e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.8357e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.891e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.4215e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.424e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.2165e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 29.194716215133667
Epoch 5/9
	 Logging train Loss: 1.8321e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.5572e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.85e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.1187e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.414e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.9109e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 29.149926900863647
Epoch 6/9
	 Logging train Loss: 1.7484e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.4525e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.044e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.9931e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.731e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.7882e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 29.099587202072144
Epoch 7/9
	 Logging train Loss: 1.7035e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.6208e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.564e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.0947e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.311e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.9322e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 29.292043209075928
Epoch 8/9
	 Logging train Loss: 1.661e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.3777e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.661e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.8191e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.559e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.7233e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 29.288959980010986
Epoch 9/9
	 Logging train Loss: 1.6197e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.3942e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.819e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone █▅▃▂▂▁▁▁▁▁
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone █▄▃▄▃▂▁▂▁▁
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone █▄▃▃▂▂▁▂▁▁
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone █▆▃▂▁▁▁▁▁▁
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone █▅▃▂▁▁▁▁▁▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone 0.0
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: 🚀 View run pretty-forest-67 at: https://wandb.ai/nreints/ThesisFinal2/runs/awtkfxb1
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230629_113931-awtkfxb1/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230629_114619-pfttm1jy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run helpful-wildflower-80
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/pfttm1jy
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone █▅▂▁▁▁▁▁▁▁
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone █▄▂▁▁▂▁▂▁▁
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone █▄▂▂▁▂▁▁▁▁
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone █▅▂▁▁▁▁▁▁▁
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone █▅▂▁▁▁▁▁▁▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone 0.0
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: 🚀 View run helpful-wildflower-80 at: https://wandb.ai/nreints/ThesisFinal2/runs/pfttm1jy
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230629_114619-pfttm1jy/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230629_115310-6z6llje5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rare-blaze-93
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/6z6llje5
	 Logging test loss: 2.771e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.782e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.7595e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 29.308080911636353
Saved model in  trained_models/gru/data_t(0,0)_r(5,20)_combi_pNone_gNone/'pos_diff_1'_'False'.pth
It took  408.12809920310974  seconds.
----- ITERATION 5/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 45.82148861885071 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 11.513681411743164 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_none_pNone_gNone took 11.804593801498413 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_tennis_pNone_gNone took 11.784049272537231 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_full_pNone_gNone took 11.86131238937378 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_semi_pNone_gNone took 11.828756093978882 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(24, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=24, bias=True)
)
Datatype: pos_diff_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0001572729 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.6888e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.9341e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.46299e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.3623e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.36809e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 29.30502939224243
Epoch 1/9
	 Logging train Loss: 6.6558e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.8127e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.054e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 9.1345e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 7.314e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 9.7458e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 29.247454166412354
Epoch 2/9
	 Logging train Loss: 4.2254e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.5145e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.18e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 4.9892e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.088e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.842e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 29.007014751434326
Epoch 3/9
	 Logging train Loss: 2.3967e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.7246e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.178e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.5306e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.488e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.0484e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 29.0773708820343
Epoch 4/9
	 Logging train Loss: 1.9175e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.5443e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.338e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.2829e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.747e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.8017e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 28.788389444351196
Epoch 5/9
	 Logging train Loss: 1.8153e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.7e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.998e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.3428e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.479e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.9959e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 29.37409543991089
Epoch 6/9
	 Logging train Loss: 1.7527e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.4706e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.102e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.1069e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.693e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.7667e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 29.201356649398804
Epoch 7/9
	 Logging train Loss: 1.7119e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.5367e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.011e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.115e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.717e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.8479e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 29.202341556549072
Epoch 8/9
	 Logging train Loss: 1.6679e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.4489e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.139e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.9728e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.971e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.7721e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 29.380778789520264
Epoch 9/9
	 Logging train Loss: 1.6298e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.4109e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.892e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.8844e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.84e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.7492e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 29.730212926864624
Saved model in  trained_models/gru/data_t(0,0)_r(5,20)_combi_pNone_gNone/'pos_diff_1'_'False'.pth
It took  410.24282240867615  seconds.
----- ITERATION 6/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 46.479480028152466 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 11.621438264846802 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_none_pNone_gNone took 11.83336877822876 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_tennis_pNone_gNone took 11.86039400100708 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_full_pNone_gNone took 11.983363389968872 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_semi_pNone_gNone took 11.943649053573608 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(24, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=24, bias=True)
)
Datatype: pos_diff_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0001526242 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.02098e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.0354e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.60083e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.3178e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.32657e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 29.14073896408081
Epoch 1/9
	 Logging train Loss: 6.4087e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.8817e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.995e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone █▅▃▂▁▂▁▁▁▁
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone █▃▃▃▁▆▁▁▁▁
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone █▃▃▂▁▄▁▁▁▁
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone █▆▄▂▁▂▁▁▁▁
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone █▅▃▂▁▂▁▁▁▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone 0.0
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: 🚀 View run rare-blaze-93 at: https://wandb.ai/nreints/ThesisFinal2/runs/6z6llje5
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230629_115310-6z6llje5/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230629_120004-jmw1m20a
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run gallant-flower-109
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/jmw1m20a
	 Logging test loss: 1.0603e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.997e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.00682e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 29.215481758117676
Epoch 2/9
	 Logging train Loss: 4.4417e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.5683e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.978e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 6.983e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 5.273e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 6.4398e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 29.219817399978638
Epoch 3/9
	 Logging train Loss: 2.7012e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.7031e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.195e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 4.2915e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.313e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.4976e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 28.874261617660522
Epoch 4/9
	 Logging train Loss: 1.897e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.1208e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.54e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.5502e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.862e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.8125e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 29.124242782592773
Epoch 5/9
	 Logging train Loss: 1.7017e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.8592e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.136e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 4.2135e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 9.851e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.5162e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 29.2116916179657
Epoch 6/9
	 Logging train Loss: 1.6276e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.0092e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.488e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.3423e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.015e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.7218e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 29.440144062042236
Epoch 7/9
	 Logging train Loss: 1.5774e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.917e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.959e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.1981e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.643e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.6193e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 28.97929859161377
Epoch 8/9
	 Logging train Loss: 1.5308e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.8966e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.973e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.1241e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.732e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.6332e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 29.227824449539185
Epoch 9/9
	 Logging train Loss: 1.4948e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.8815e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.074e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.0573e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.967e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.6146e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 28.931427001953125
Saved model in  trained_models/gru/data_t(0,0)_r(5,20)_combi_pNone_gNone/'pos_diff_1'_'False'.pth
It took  414.16740131378174  seconds.
----- ITERATION 7/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 46.436583280563354 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 11.701013088226318 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_none_pNone_gNone took 11.867678165435791 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_tennis_pNone_gNone took 11.878815412521362 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_full_pNone_gNone took 11.907745599746704 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_semi_pNone_gNone took 11.90092134475708 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(24, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=24, bias=True)
)
Datatype: pos_diff_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0001287748 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.5461e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.3874e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.4595e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 9.075e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.2469e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 29.17898678779602
Epoch 1/9
	 Logging train Loss: 6.1619e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.9355e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.148e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 9.4556e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.487e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 8.9059e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 29.41380786895752
Epoch 2/9
	 Logging train Loss: 4.0088e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.6796e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.299e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 5.2826e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.501e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.5755e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 29.233680486679077
Epoch 3/9
	 Logging train Loss: 2.3147e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.8693e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.865e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.7602e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.445e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.9962e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 29.17664623260498
Epoch 4/9
	 Logging train Loss: 1.8675e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.7168e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.64e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.504e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.303e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.7935e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 29.290467262268066
Epoch 5/9
	 Logging train Loss: 1.7505e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.6231e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.13e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone █▅▂▁▁▁▁▁▁▁
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone █▄▂▂▂▂▁▁▃▂
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone █▄▂▂▂▂▁▁▂▁
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone █▅▂▁▁▁▁▁▁▁
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone █▅▂▁▁▁▁▁▁▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone 0.0
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: 🚀 View run gallant-flower-109 at: https://wandb.ai/nreints/ThesisFinal2/runs/jmw1m20a
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230629_120004-jmw1m20a/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230629_120653-zhughzi8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run smart-pyramid-122
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/zhughzi8
	 Logging test loss: 3.3799e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.873e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.6811e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 29.138326168060303
Epoch 6/9
	 Logging train Loss: 1.6896e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.5635e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.847e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.2898e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.659e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.6382e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 29.252603769302368
Epoch 7/9
	 Logging train Loss: 1.6453e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.5251e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.298e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.1787e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.24e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.6039e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 29.068256378173828
Epoch 8/9
	 Logging train Loss: 1.6018e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.6917e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.23e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.3116e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.264e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.7857e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 29.12485408782959
Epoch 9/9
	 Logging train Loss: 1.5632e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.5045e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.702e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.0465e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.817e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.62e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 29.11161208152771
Saved model in  trained_models/gru/data_t(0,0)_r(5,20)_combi_pNone_gNone/'pos_diff_1'_'False'.pth
It took  409.12534642219543  seconds.
----- ITERATION 8/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 45.346277952194214 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 11.472005844116211 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_none_pNone_gNone took 11.807196855545044 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_tennis_pNone_gNone took 11.843988180160522 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_full_pNone_gNone took 11.871975421905518 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_semi_pNone_gNone took 11.817757844924927 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(24, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=24, bias=True)
)
Datatype: pos_diff_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0001536242 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.8883e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.8546e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.6136e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.213e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.34065e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 29.32341194152832
Epoch 1/9
	 Logging train Loss: 6.5506e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.9172e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.917e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 9.8902e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 5.674e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 9.4261e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 29.2623553276062
Epoch 2/9
	 Logging train Loss: 4.2205e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.1752e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 9.668e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 6.1188e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 7.587e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 5.3599e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 29.14029359817505
Epoch 3/9
	 Logging train Loss: 2.3702e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.8656e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.519e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.9375e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.897e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.0338e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 29.035222053527832
Epoch 4/9
	 Logging train Loss: 1.8897e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.7099e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.96e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.6645e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.492e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.856e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 29.236589908599854
Epoch 5/9
	 Logging train Loss: 1.7878e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.569e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.861e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.4395e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.471e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.7179e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 29.40057373046875
Epoch 6/9
	 Logging train Loss: 1.7359e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.6873e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.234e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.5363e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.909e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.8249e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 29.328631162643433
Epoch 7/9
	 Logging train Loss: 1.6818e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.5958e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.604e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.3295e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.387e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.7654e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 29.194099187850952
Epoch 8/9
	 Logging train Loss: 1.6363e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.5189e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.809e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.2344e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.736e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.6786e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 29.37994956970215
Epoch 9/9
	 Logging train Loss: 1.5939e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.4178e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.233e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone █▅▃▁▁▁▁▁▁▁
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone █▄▅▂▂▁▂▂▁▁
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone █▄▄▂▂▁▂▂▁▁
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone █▅▃▁▁▁▁▁▁▁
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone █▅▃▁▁▁▁▁▁▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone 0.0
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: 🚀 View run smart-pyramid-122 at: https://wandb.ai/nreints/ThesisFinal2/runs/zhughzi8
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230629_120653-zhughzi8/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230629_121350-y0ufw40c
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hopeful-water-136
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/y0ufw40c
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone █▄▂▁▁▁▁▁▁▁
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone █▅▆▃▁▁▁▂▂▁
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone █▅▅▂▁▁▁▁▁▁
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone █▄▂▁▁▁▁▁▁▁
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone █▄▂▁▁▁▁▁▁▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone 0.0
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: 🚀 View run hopeful-water-136 at: https://wandb.ai/nreints/ThesisFinal2/runs/y0ufw40c
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230629_121350-y0ufw40c/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230629_122039-k4a56yde
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run distinctive-voice-149
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/k4a56yde
	 Logging test loss: 3.0432e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.245e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.6221e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 29.32890820503235
Saved model in  trained_models/gru/data_t(0,0)_r(5,20)_combi_pNone_gNone/'pos_diff_1'_'False'.pth
It took  416.94177889823914  seconds.
----- ITERATION 9/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 46.3723783493042 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 11.51548171043396 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_none_pNone_gNone took 11.759901762008667 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_tennis_pNone_gNone took 11.73501706123352 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_full_pNone_gNone took 11.784623146057129 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_semi_pNone_gNone took 11.764942407608032 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(24, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=24, bias=True)
)
Datatype: pos_diff_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.000135274 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.7044e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.4874e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.34041e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 9.47e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.23238e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 29.267194747924805
Epoch 1/9
	 Logging train Loss: 6.0503e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.7077e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 9.302e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 7.3523e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 6.645e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 7.0941e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 29.22601866722107
Epoch 2/9
	 Logging train Loss: 3.1278e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.3007e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 9.019e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 4.3849e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 7.239e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.6915e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 29.091370820999146
Epoch 3/9
	 Logging train Loss: 2.1094e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.6914e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.157e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.5927e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.597e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.912e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 28.844449281692505
Epoch 4/9
	 Logging train Loss: 1.9067e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.4824e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.6e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.3062e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.133e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.6817e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 28.977507829666138
Epoch 5/9
	 Logging train Loss: 1.822e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.3813e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.974e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.1603e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.651e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.5821e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 29.267677783966064
Epoch 6/9
	 Logging train Loss: 1.7679e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.3821e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.152e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.1264e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.942e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.6313e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 29.260464429855347
Epoch 7/9
	 Logging train Loss: 1.7129e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.4153e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.604e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.0715e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.417e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.6572e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 28.967708349227905
Epoch 8/9
	 Logging train Loss: 1.6706e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.386e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.563e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.9867e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.513e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.6004e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 29.3354012966156
Epoch 9/9
	 Logging train Loss: 1.6293e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.3109e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.867e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.8776e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.909e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.5565e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 29.038922548294067
Saved model in  trained_models/gru/data_t(0,0)_r(5,20)_combi_pNone_gNone/'pos_diff_1'_'False'.pth
It took  409.1600511074066  seconds.
----- ITERATION 10/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 46.75270414352417 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 11.64208197593689 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_none_pNone_gNone took 11.751688241958618 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_tennis_pNone_gNone took 11.641801118850708 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_full_pNone_gNone took 11.664559841156006 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_semi_pNone_gNone took 11.733808755874634 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(24, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=24, bias=True)
)
Datatype: pos_diff_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0001431609 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.5538e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.6725e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.5688e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.0844e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.26064e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 29.003883600234985
Epoch 1/9
	 Logging train Loss: 6.3677e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.5734e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 9.271e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone █▅▃▁▁▁▁▁▁▁
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone █▅▄▁▁▁▁▂▂▁
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone █▄▃▁▁▁▁▂▂▁
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone █▅▃▁▁▁▁▁▁▁
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone █▄▂▁▁▁▁▁▁▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone 0.0
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: 🚀 View run distinctive-voice-149 at: https://wandb.ai/nreints/ThesisFinal2/runs/k4a56yde
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230629_122039-k4a56yde/logs
	 Logging test loss: 9.2082e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 6.218e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 8.3757e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 29.142847299575806
Epoch 2/9
	 Logging train Loss: 4.1303e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.9477e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.735e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 5.7076e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 5.64e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.9151e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 29.236225128173828
Epoch 3/9
	 Logging train Loss: 2.4581e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.7411e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.243e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.7826e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.59e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.817e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 29.783477544784546
Epoch 4/9
	 Logging train Loss: 1.9256e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.6651e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.68e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.576e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.113e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.6943e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 29.224833726882935
Epoch 5/9
	 Logging train Loss: 1.7996e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.5511e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.069e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.4098e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.618e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.5684e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 28.994819402694702
Epoch 6/9
	 Logging train Loss: 1.7367e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.5384e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.217e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.3515e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.823e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.5716e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 29.17177128791809
Epoch 7/9
	 Logging train Loss: 1.6934e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.6047e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.049e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.3546e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.765e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.7031e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 29.0068678855896
Epoch 8/9
	 Logging train Loss: 1.6467e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.5881e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.937e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.3205e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.808e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.6567e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 29.147306442260742
Epoch 9/9
	 Logging train Loss: 1.6096e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.4972e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.787e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.1092e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.759e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.5376e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 29.1779887676239
Saved model in  trained_models/gru/data_t(0,0)_r(5,20)_combi_pNone_gNone/'pos_diff_1'_'False'.pth
It took  409.0496196746826  seconds.

JOB STATISTICS
==============
Job ID: 2986688
Array Job ID: 2986645_7
Cluster: snellius
User/Group: nreints/nreints
State: RUNNING
Nodes: 1
Cores per node: 18
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 20:39:18 core-walltime
Job Wall-clock time: 01:08:51
Memory Utilized: 0.00 MB (estimated maximum)
Memory Efficiency: 0.00% of 0.00 MB (0.00 MB/node)
WARNING: Efficiency statistics may be misleading for RUNNING jobs.
