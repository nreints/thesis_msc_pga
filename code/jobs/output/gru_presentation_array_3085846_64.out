wandb: Currently logged in as: nreints. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_203203-voj1ngqz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sleek-firebrand-391
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/voj1ngqz
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gTrue █▂▂▁▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gTrue █▂▂▁▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gTrue █▂▂▁▁▁▁▁▁▁
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gTrue █▂▂▁▁▁▁▁▁▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gTrue 0.0
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gTrue 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: 🚀 View run sleek-firebrand-391 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/voj1ngqz
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_203203-voj1ngqz/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_204006-9cd3z8x4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run deft-wind-409
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/9cd3z8x4
Training on dataset: data_t(5,20)_r(0,0)_combi_pNone_gTrue
Testing on 4 datasets: ['data_t(5,20)_r(0,0)_full_pNone_gTrue', 'data_t(5,20)_r(0,0)_combi_pNone_gTrue', 'data_t(5,20)_r(0,0)_tennis_pNone_gTrue', 'data_t(5,20)_r(0,0)_semi_pNone_gTrue']
Focussing on identity: False
Using extra input: False
Using fr-fr as reference point.
----- ITERATION 1/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gTrue took 51.69385075569153 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(0,0)_full_pNone_gTrue took 13.45278024673462 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gTrue took 12.624711275100708 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_tennis_pNone_gTrue took 12.447349548339844 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_semi_pNone_gTrue took 12.788395404815674 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(6, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=6, bias=True)
)
Datatype: log_dualQ_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0004975456 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.49273e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.53332e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.59145e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.64739e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 37.53856182098389
Epoch 1/9
	 Logging train Loss: 5.349e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.8186e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.8283e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.9606e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.9273e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 36.49603462219238
Epoch 2/9
	 Logging train Loss: 2.3896e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.8071e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.7988e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.8777e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.8524e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 36.28085017204285
Epoch 3/9
	 Logging train Loss: 1.8002e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 9.701e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 9.76e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.0316e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.0175e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 36.50734353065491
Epoch 4/9
	 Logging train Loss: 1.6488e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.368e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 5.71e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.289e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 6.428e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 36.32671666145325
Epoch 5/9
	 Logging train Loss: 1.8306e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.996e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.171e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.205e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 36.362021684646606
Epoch 6/9
	 Logging train Loss: 1.3515e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.38e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.488e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.668e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.696e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 36.24786949157715
Epoch 7/9
	 Logging train Loss: 1.42e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.88e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 7.129e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.0203e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.0593e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 36.067867040634155
Epoch 8/9
	 Logging train Loss: 1.4684e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.547e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.614e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.774e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.779e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 35.999247789382935
Epoch 9/9
	 Logging train Loss: 1.8126e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.352e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.36e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.404e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.454e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 36.27312779426575
Saved model in  trained_models/gru/data_t(5,20)_r(0,0)_combi_pNone_gTrue/'log_dualQ_1'_'False'.pth
It took  483.13277864456177  seconds.
----- ITERATION 2/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gTrue took 48.32650661468506 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(0,0)_full_pNone_gTrue took 12.215607166290283 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gTrue took 12.08636212348938 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_tennis_pNone_gTrue took 12.194619417190552 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_semi_pNone_gTrue took 12.194937944412231 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(6, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=6, bias=True)
)
Datatype: log_dualQ_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0003493094 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.62156e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.56945e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.69503e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.5108e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 36.47617769241333
Epoch 1/9
	 Logging train Loss: 1.28278e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.4998e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 4.4791e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.7329e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 4.4403e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 36.54723906517029
Epoch 2/9
	 Logging train Loss: 3.603e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.3091e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.2789e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.3548e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.2341e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 36.598944902420044
Epoch 3/9
	 Logging train Loss: 2.9246e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.494e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.4713e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.5336e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.4475e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 36.27541399002075
Epoch 4/9
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gTrue █▂▂▁▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gTrue █▂▂▁▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gTrue █▂▂▁▁▁▁▁▁▁
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gTrue █▂▂▁▁▁▁▁▁▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gTrue 0.0
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gTrue 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: 🚀 View run deft-wind-409 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/9cd3z8x4
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_204006-9cd3z8x4/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_204802-86ak44j6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run twilight-firefly-421
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/86ak44j6
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gTrue █▂▂▁▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gTrue █▂▁▁▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gTrue █▂▂▂▁▁▁▁▁▁
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gTrue █▂▂▂▁▁▁▁▁▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gTrue 0.0
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gTrue 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: 🚀 View run twilight-firefly-421 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/86ak44j6
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_204802-86ak44j6/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_205553-3rwp2gij
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run comfy-surf-433
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/3rwp2gij
	 Logging train Loss: 2.3303e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 9.101e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 8.987e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 9.495e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 8.934e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 36.25435018539429
Epoch 5/9
	 Logging train Loss: 2.0433e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.48e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 5.484e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.832e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 5.503e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 36.716065645217896
Epoch 6/9
	 Logging train Loss: 1.8036e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.29e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.421e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.715e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.526e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 36.62040638923645
Epoch 7/9
	 Logging train Loss: 1.4552e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.796e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 7.851e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.3078e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.2806e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 36.40467715263367
Epoch 8/9
	 Logging train Loss: 1.3145e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.684e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.83e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.009e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.934e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 36.25881791114807
Epoch 9/9
	 Logging train Loss: 1.3755e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.484e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.539e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.568e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.527e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 36.3734233379364
Saved model in  trained_models/gru/data_t(5,20)_r(0,0)_combi_pNone_gTrue/'log_dualQ_1'_'False'.pth
It took  476.0347864627838  seconds.
----- ITERATION 3/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gTrue took 46.83901929855347 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(0,0)_full_pNone_gTrue took 12.04634714126587 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gTrue took 11.88964033126831 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_tennis_pNone_gTrue took 12.108902931213379 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_semi_pNone_gTrue took 12.108804702758789 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(6, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=6, bias=True)
)
Datatype: log_dualQ_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0006072759 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.24949e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.36916e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.28118e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.30171e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 36.406378507614136
Epoch 1/9
	 Logging train Loss: 1.59878e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.8747e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 7.1096e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.8466e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 6.869e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 36.46298694610596
Epoch 2/9
	 Logging train Loss: 3.8497e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.4358e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.2088e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.8576e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.9833e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 36.30562114715576
Epoch 3/9
	 Logging train Loss: 2.4913e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.6823e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.5357e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.3738e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.4468e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 36.20973348617554
Epoch 4/9
	 Logging train Loss: 2.1242e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.737e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 9.14e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 9.007e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 9.042e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 36.159969329833984
Epoch 5/9
	 Logging train Loss: 1.5653e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.521e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 6.742e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.874e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 7.682e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 36.1972074508667
Epoch 6/9
	 Logging train Loss: 1.4488e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.65e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.243e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.778e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.687e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 36.529024839401245
Epoch 7/9
	 Logging train Loss: 1.4139e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.741e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 8.725e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.4496e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.4754e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 36.52413535118103
Epoch 8/9
	 Logging train Loss: 1.579e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.868e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.674e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.482e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 5.653e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 36.47452640533447
Epoch 9/9
	 Logging train Loss: 1.088e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.455e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.53e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.517e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.567e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 36.67704749107361
Saved model in  trained_models/gru/data_t(5,20)_r(0,0)_combi_pNone_gTrue/'log_dualQ_1'_'False'.pth
It took  471.2698655128479  seconds.
----- ITERATION 4/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gTrue took 46.88747835159302 seconds.
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gTrue █▂▂▂▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gTrue █▂▂▁▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gTrue █▂▂▂▁▂▁▁▁▁
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gTrue █▂▂▂▁▂▁▁▁▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gTrue 0.0
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gTrue 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: 🚀 View run comfy-surf-433 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/3rwp2gij
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_205553-3rwp2gij/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_210346-qg33ngii
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run gentle-disco-445
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/qg33ngii
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(0,0)_full_pNone_gTrue took 12.09971308708191 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gTrue took 11.918067455291748 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_tennis_pNone_gTrue took 12.132969856262207 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_semi_pNone_gTrue took 12.125486850738525 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(6, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=6, bias=True)
)
Datatype: log_dualQ_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0005105328 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.34662e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.40851e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.42332e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.39503e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 36.51079034805298
Epoch 1/9
	 Logging train Loss: 1.08468e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.8983e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.9881e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.0553e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.9917e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 36.2438428401947
Epoch 2/9
	 Logging train Loss: 3.0924e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.4304e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.4687e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.4839e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.4428e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 36.859227418899536
Epoch 3/9
	 Logging train Loss: 2.2643e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.5458e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.1825e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.7632e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.7208e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 37.786749601364136
Epoch 4/9
	 Logging train Loss: 2.27e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.336e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 8.918e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 9.293e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 9.1e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 36.420053482055664
Epoch 5/9
	 Logging train Loss: 1.1763e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.884e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.5189e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.5154e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.4172e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 36.47609829902649
Epoch 6/9
	 Logging train Loss: 1.4345e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.407e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.595e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.713e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.678e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 36.36645007133484
Epoch 7/9
	 Logging train Loss: 1.3244e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.201e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 7.404e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.0859e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.0281e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 36.2036566734314
Epoch 8/9
	 Logging train Loss: 1.3578e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.418e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 8.838e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.1347e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.0754e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 36.6060357093811
Epoch 9/9
	 Logging train Loss: 1.1942e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.626e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.751e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.844e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.849e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 36.13484001159668
Saved model in  trained_models/gru/data_t(5,20)_r(0,0)_combi_pNone_gTrue/'log_dualQ_1'_'False'.pth
It took  473.09286737442017  seconds.
----- ITERATION 5/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gTrue took 49.51797866821289 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(0,0)_full_pNone_gTrue took 12.06993556022644 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gTrue took 12.153772830963135 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_tennis_pNone_gTrue took 12.0408935546875 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_semi_pNone_gTrue took 12.058402299880981 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(6, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=6, bias=True)
)
Datatype: log_dualQ_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0002409604 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.32105e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.35189e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.37322e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.31804e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 36.2623074054718
Epoch 1/9
	 Logging train Loss: 9.5157e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.3339e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.3367e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.353e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.2621e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 36.16259574890137
Epoch 2/9
	 Logging train Loss: 2.943e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.9021e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.8968e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.9091e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.8658e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 36.09104585647583
Epoch 3/9
	 Logging train Loss: 2.0004e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.0321e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.0305e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.038e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.0183e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 36.3563506603241
Epoch 4/9
	 Logging train Loss: 1.7165e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.287e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 5.324e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.36e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 5.302e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
		--> Epoch time; 36.13036394119263
Epoch 5/9
	 Logging train Loss: 1.5361e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
slurmstepd: error: *** JOB 3085867 ON gcn28 CANCELLED AT 2023-07-16T21:09:10 ***
slurmstepd: error: *** STEP 3085867.0 ON gcn28 CANCELLED AT 2023-07-16T21:09:10 ***

JOB STATISTICS
==============
Job ID: 3085867
Array Job ID: 3085846_64
Cluster: snellius
User/Group: nreints/nreints
State: CANCELLED (exit code 0)
Nodes: 1
Cores per node: 18
CPU Utilized: 00:00:01
CPU Efficiency: 0.00% of 11:11:42 core-walltime
Job Wall-clock time: 00:37:19
Memory Utilized: 6.54 MB
Memory Efficiency: 0.00% of 0.00 MB
