wandb: Currently logged in as: nreints. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_164043-z2vba2ol
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fragrant-surf-16
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal1/runs/z2vba2ol
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone █▂▁▁▁▁▁▁▁▁
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone █▃▁▁▁▁▁▁▂▂
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone █▃▁▁▁▁▁▁▂▁
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone █▁▁▁▁▁▁▁▁▁
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone █▁▁▁▁▁▁▁▁▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone 1e-05
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone 1e-05
wandb:                                  Train loss 0.0
wandb: 
wandb: 🚀 View run fragrant-surf-16 at: https://wandb.ai/nreints/ThesisFinal1/runs/z2vba2ol
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_164043-z2vba2ol/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_165151-qlfhpdih
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fresh-shadow-52
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal1/runs/qlfhpdih
Training on dataset: data_t(0,0)_r(5,20)_combi_pNone_gNone
Testing on 5 datasets: ['data_t(0,0)_r(5,20)_tennis_pNone_gNone', 'data_t(0,0)_r(5,20)_none_pNone_gNone', 'data_t(0,0)_r(5,20)_combi_pNone_gNone', 'data_t(0,0)_r(5,20)_semi_pNone_gNone', 'data_t(0,0)_r(5,20)_full_pNone_gNone']
Focussing on identity: False
Using extra input: False
Using fr-fr as reference point.
----- ITERATION 1/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 64.90912532806396 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(5,20)_tennis_pNone_gNone took 16.442050218582153 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_none_pNone_gNone took 16.41697120666504 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 16.33208131790161 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_semi_pNone_gNone took 16.56267261505127 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_full_pNone_gNone took 16.480263471603394 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(6, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=6, bias=True)
)
Datatype: log_dualQ_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0009431845 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.687e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.7537e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 4.11286e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.22344e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.3918e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 51.88984227180481
Epoch 1/9
	 Logging train Loss: 1.69351e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.927e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 7.132e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 6.2789e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.86e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 6.213e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 50.510239601135254
Epoch 2/9
	 Logging train Loss: 4.4659e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.162e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.372e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.724e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.3363e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.861e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 50.37221431732178
Epoch 3/9
	 Logging train Loss: 3.4292e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.8808e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.688e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.9607e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.1467e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.251e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 49.85199975967407
Epoch 4/9
	 Logging train Loss: 3.8785e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.665e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.681e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 4.2042e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.7664e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.262e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 50.17882800102234
Epoch 5/9
	 Logging train Loss: 4.2622e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.2368e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.371e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.451e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.4708e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 9.95e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 49.917072057724
Epoch 6/9
	 Logging train Loss: 4.0608e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.4563e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.236e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.6215e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.6731e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.868e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 50.070724964141846
Epoch 7/9
	 Logging train Loss: 3.7603e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.8473e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.964e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 4.2492e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.895e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.615e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 50.13515114784241
Epoch 8/9
	 Logging train Loss: 3.5182e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.2273e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.915e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 4.4353e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.1666e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.57e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 50.10192060470581
Epoch 9/9
	 Logging train Loss: 3.3147e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 9.1407e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.081e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 4.8787e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 9.2837e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.739e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 50.25407791137695
Saved model in  trained_models/gru/data_t(0,0)_r(5,20)_combi_pNone_gNone/'log_dualQ_1'_'False'.pth
It took  668.8067457675934  seconds.
----- ITERATION 2/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 60.59263563156128 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(5,20)_tennis_pNone_gNone took 15.155310153961182 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_none_pNone_gNone took 15.175599575042725 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 15.199330568313599 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_semi_pNone_gNone took 15.198648452758789 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_full_pNone_gNone took 15.23060131072998 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(6, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=6, bias=True)
)
Datatype: log_dualQ_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0005537421 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.64214e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.232e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.94538e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.46846e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.1498e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 51.31000638008118
Epoch 1/9
	 Logging train Loss: 8.3745e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone █▂▂▂▄▂▁▁▁▁
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone █▂▁▁▃▁▂▂▂▁
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone █▂▁▁▃▁▂▂▂▁
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone █▂▂▂▅▂▂▁▂▁
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone █▂▂▂▅▂▂▁▂▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone 0.0
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: 🚀 View run fresh-shadow-52 at: https://wandb.ai/nreints/ThesisFinal1/runs/qlfhpdih
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_165151-qlfhpdih/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_170246-4bvxt3cm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lively-music-89
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal1/runs/4bvxt3cm
	 Logging test loss: 6.2376e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.345e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 4.1986e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.2117e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.891e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 50.25446653366089
Epoch 2/9
	 Logging train Loss: 5.1061e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.7058e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.482e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.4192e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.6147e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.089e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 50.52792477607727
Epoch 3/9
	 Logging train Loss: 4.8455e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.2424e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.401e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.5611e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.0627e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.043e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 50.53351593017578
Epoch 4/9
	 Logging train Loss: 4.6888e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.76815e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.443e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 8.1504e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.65486e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.149e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 50.64938926696777
Epoch 5/9
	 Logging train Loss: 4.4491e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.5579e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.21e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.218e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.4232e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 9.17e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 50.0873486995697
Epoch 6/9
	 Logging train Loss: 4.1279e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.659e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.82e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.7997e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.5489e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.527e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 50.388145446777344
Epoch 7/9
	 Logging train Loss: 3.7051e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.5705e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.043e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.2789e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.5623e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.778e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 50.18964219093323
Epoch 8/9
	 Logging train Loss: 3.2942e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.0121e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.647e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.8004e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.728e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.416e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 50.32260847091675
Epoch 9/9
	 Logging train Loss: 3.1239e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.7464e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 8.1e-08 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.8055e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.6544e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 6.13e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 50.49969530105591
Saved model in  trained_models/gru/data_t(0,0)_r(5,20)_combi_pNone_gNone/'log_dualQ_1'_'False'.pth
It took  654.997656583786  seconds.
----- ITERATION 3/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 60.871482610702515 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(5,20)_tennis_pNone_gNone took 15.144209146499634 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_none_pNone_gNone took 15.212866306304932 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 15.181499719619751 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_semi_pNone_gNone took 15.195815324783325 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_full_pNone_gNone took 15.239834785461426 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(6, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=6, bias=True)
)
Datatype: log_dualQ_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0006896462 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.5111e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.0113e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.30649e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.8928e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.8906e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 50.58212447166443
Epoch 1/9
	 Logging train Loss: 1.16372e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.8216e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.807e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 4.8298e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.3544e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.296e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 50.35291337966919
Epoch 2/9
	 Logging train Loss: 4.0568e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.771e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.294e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.6941e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.3698e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 8.66e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 49.627809047698975
Epoch 3/9
	 Logging train Loss: 4.418e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.1383e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.203e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.79e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.6057e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 8.27e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 50.597299098968506
Epoch 4/9
	 Logging train Loss: 4.6383e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.04255e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.058e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 5.3065e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 9.3632e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.722e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 51.007696866989136
Epoch 5/9
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone █▂▁▁▂▂▂▂▁▁
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone █▂▁▁▁▄▂▂▁▁
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone █▂▁▁▁▄▂▂▁▁
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone █▂▁▁▂▂▂▂▁▁
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone █▁▁▁▂▂▂▂▁▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone 0.0
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: 🚀 View run lively-music-89 at: https://wandb.ai/nreints/ThesisFinal1/runs/4bvxt3cm
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_170246-4bvxt3cm/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_171341-29o78dua
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run exalted-gorge-128
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal1/runs/29o78dua
	 Logging train Loss: 4.5525e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.7799e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 9.05e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 4.8693e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.997e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 8.767e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 50.737250328063965
Epoch 6/9
	 Logging train Loss: 4.3392e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.17848e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.545e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 5.8979e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.05483e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.331e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 50.11039209365845
Epoch 7/9
	 Logging train Loss: 4.0992e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.8298e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.81e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 4.512e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.8731e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.58e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 49.98199534416199
Epoch 8/9
	 Logging train Loss: 3.6001e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.088e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 9.04e-08 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.6108e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.6824e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 6.6e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 50.404027462005615
Epoch 9/9
	 Logging train Loss: 3.4077e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.4072e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.586e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.3095e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.0849e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.373e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 50.308197259902954
Saved model in  trained_models/gru/data_t(0,0)_r(5,20)_combi_pNone_gNone/'log_dualQ_1'_'False'.pth
It took  655.3825399875641  seconds.
----- ITERATION 4/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 60.86434197425842 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(5,20)_tennis_pNone_gNone took 15.243972539901733 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_none_pNone_gNone took 15.275612831115723 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 15.203121185302734 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_semi_pNone_gNone took 15.250497102737427 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_full_pNone_gNone took 15.2163724899292 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(6, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=6, bias=True)
)
Datatype: log_dualQ_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0009144004 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.20058e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.1481e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.07612e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.71801e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.9937e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 49.97920536994934
Epoch 1/9
	 Logging train Loss: 1.34118e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.4908e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 5.216e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 5.0275e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.7989e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.582e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 50.47625255584717
Epoch 2/9
	 Logging train Loss: 4.5069e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.2136e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.854e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.5483e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.6189e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.379e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 50.41581630706787
Epoch 3/9
	 Logging train Loss: 4.0962e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.8356e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.017e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.7942e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.3784e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 6.12e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 49.88472890853882
Epoch 4/9
	 Logging train Loss: 4.2408e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.09444e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.528e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 5.1811e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 9.8439e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.139e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 50.10851693153381
Epoch 5/9
	 Logging train Loss: 3.9553e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.9536e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 9.75e-08 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.7889e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.4606e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 6.46e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 50.37247085571289
Epoch 6/9
	 Logging train Loss: 4.1305e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.6061e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 9.78e-08 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.6163e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.1096e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 6.75e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 50.607197761535645
Epoch 7/9
	 Logging train Loss: 3.6816e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.5564e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.154e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 4.0097e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.7987e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.874e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 50.31384348869324
Epoch 8/9
	 Logging train Loss: 3.5251e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.1908e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.201e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.393e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.6576e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone █▂▁▁▂▁▁▁▁▁
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone █▂▁▁▂▁▁▁▁▂
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone █▂▁▁▂▁▁▁▁▂
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone █▂▁▁▂▁▁▂▁▁
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone █▁▁▁▂▁▁▂▁▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone 1e-05
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone 1e-05
wandb:                                  Train loss 0.0
wandb: 
wandb: 🚀 View run exalted-gorge-128 at: https://wandb.ai/nreints/ThesisFinal1/runs/29o78dua
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_171341-29o78dua/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_172436-7x4vjwtm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run deft-violet-164
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal1/runs/7x4vjwtm
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone █▂▁▁▂▂▂▁▁▁
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone █▂▁▁▂▂▂▁▂▂
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone █▂▁▁▂▂▂▁▂▂
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone █▂▁▁▂▂▂▁▁▁
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone █▁▁▁▂▂▂▁▂▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone 1e-05
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone 1e-05
wandb:                                  Train loss 0.0
wandb: 
wandb: 🚀 View run deft-violet-164 at: https://wandb.ai/nreints/ThesisFinal1/runs/7x4vjwtm
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_172436-7x4vjwtm/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_173521-ha8162xp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lilac-sea-203
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal1/runs/ha8162xp
	 Logging test loss: 9.67e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 50.15541696548462
Epoch 9/9
	 Logging train Loss: 3.0948e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.0093e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.944e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.3342e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.3431e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.733e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 50.728317975997925
Saved model in  trained_models/gru/data_t(0,0)_r(5,20)_combi_pNone_gNone/'log_dualQ_1'_'False'.pth
It took  654.9774932861328  seconds.
----- ITERATION 5/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 60.490275621414185 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(5,20)_tennis_pNone_gNone took 15.026967763900757 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_none_pNone_gNone took 15.031122207641602 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 15.006567478179932 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_semi_pNone_gNone took 14.955342054367065 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_full_pNone_gNone took 15.06036639213562 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(6, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=6, bias=True)
)
Datatype: log_dualQ_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0005639829 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.79169e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.5126e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.49603e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.7054e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.3867e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 49.797624588012695
Epoch 1/9
	 Logging train Loss: 9.1099e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.6438e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.13e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 4.212e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.7928e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.74e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 49.81478309631348
Epoch 2/9
	 Logging train Loss: 3.541e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.624e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.041e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.2171e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.8233e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 7.09e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 49.5006582736969
Epoch 3/9
	 Logging train Loss: 3.8374e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.948e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.04e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.299e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.0822e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 7.2e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 49.609681606292725
Epoch 4/9
	 Logging train Loss: 4.2331e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 9.782e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.218e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 5.0462e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 9.2862e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.913e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 49.533515214920044
Epoch 5/9
	 Logging train Loss: 4.2416e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.2449e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.381e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 4.4072e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.0533e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.081e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 49.73332667350769
Epoch 6/9
	 Logging train Loss: 3.9091e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.8183e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.076e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 4.5195e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.447e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.822e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 49.78357982635498
Epoch 7/9
	 Logging train Loss: 3.664e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.3065e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.139e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.385e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.4469e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 9e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 49.35737586021423
Epoch 8/9
	 Logging train Loss: 3.2506e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.9938e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.495e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.6534e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.6795e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.261e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 49.07303237915039
Epoch 9/9
	 Logging train Loss: 2.9548e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.8853e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.716e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.1445e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.7108e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.502e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 49.01936984062195
Saved model in  trained_models/gru/data_t(0,0)_r(5,20)_combi_pNone_gNone/'log_dualQ_1'_'False'.pth
It took  644.6259970664978  seconds.
----- ITERATION 6/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 60.96925640106201 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(5,20)_tennis_pNone_gNone took 15.452368259429932 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_none_pNone_gNone took 15.09703540802002 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 15.116804122924805 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_semi_pNone_gNone took 15.162314176559448 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_full_pNone_gNone took 15.174930095672607 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(6, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=6, bias=True)
)
Datatype: log_dualQ_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0006845552 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.34928e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone █▁▁▁▂▁▂▁▁▁
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone █▂▁▁▃▁▂▁▁▁
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone █▂▁▁▂▁▂▁▁▁
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone █▁▁▁▃▁▂▁▁▁
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone █▁▁▁▃▁▂▁▁▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone 1e-05
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone 1e-05
wandb:                                  Train loss 0.0
wandb: 
wandb: 🚀 View run lilac-sea-203 at: https://wandb.ai/nreints/ThesisFinal1/runs/ha8162xp
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_173521-ha8162xp/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_174607-8mxry6n1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sunny-sky-244
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal1/runs/8mxry6n1
	 Logging test loss: 2.201e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.88821e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.68821e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.0514e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 49.09676146507263
Epoch 1/9
	 Logging train Loss: 1.06597e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.61e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.117e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 4.1497e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.8819e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.532e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 49.36463904380798
Epoch 2/9
	 Logging train Loss: 3.7944e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.7431e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.457e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.3138e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.0912e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.081e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 50.11265778541565
Epoch 3/9
	 Logging train Loss: 4.0091e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.7408e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.467e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.2347e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.1169e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.134e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 49.79524564743042
Epoch 4/9
	 Logging train Loss: 4.1154e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.79048e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 5.742e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 8.3107e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.59783e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 5.519e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 48.95952105522156
Epoch 5/9
	 Logging train Loss: 4.279e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.406e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.815e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.9283e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.5248e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.543e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 49.51726293563843
Epoch 6/9
	 Logging train Loss: 3.9606e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.09432e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.049e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 5.086e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 9.6629e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.824e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 49.497063875198364
Epoch 7/9
	 Logging train Loss: 3.7316e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.0552e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.401e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.2397e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.2394e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.175e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 49.434107542037964
Epoch 8/9
	 Logging train Loss: 3.5116e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.585e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.943e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.4764e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.7208e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.758e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 49.39272618293762
Epoch 9/9
	 Logging train Loss: 3.1274e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.6857e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.606e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 4.0301e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.7714e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.454e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 49.180206060409546
Saved model in  trained_models/gru/data_t(0,0)_r(5,20)_combi_pNone_gNone/'log_dualQ_1'_'False'.pth
It took  646.1708567142487  seconds.
----- ITERATION 7/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 60.57031869888306 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(5,20)_tennis_pNone_gNone took 15.19072699546814 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_none_pNone_gNone took 15.11980152130127 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 15.18801498413086 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_semi_pNone_gNone took 15.165699005126953 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_full_pNone_gNone took 15.197660684585571 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(6, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=6, bias=True)
)
Datatype: log_dualQ_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0005922258 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.60601e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.7854e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.42162e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.92466e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.5669e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 48.92583870887756
Epoch 1/9
	 Logging train Loss: 9.7592e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.3813e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.225e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 4.2076e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.503e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.633e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 49.015117168426514
Epoch 2/9
	 Logging train Loss: 4.434e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.4421e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.197e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 4.0646e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.4804e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.704e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 49.475703954696655
Epoch 3/9
	 Logging train Loss: 4.62e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.03341e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.686e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 5.4412e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.13698e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.237e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 49.4701714515686
Epoch 4/9
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone █▂▁▂▁▁▁▁▁▁
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone █▂▂▂▁▁▁▂▁▂
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone █▂▂▂▁▁▁▂▁▂
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone █▁▂▂▁▁▁▁▁▁
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone █▁▂▂▁▁▁▁▁▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone 1e-05
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone 1e-05
wandb:                                  Train loss 0.0
wandb: 
wandb: 🚀 View run sunny-sky-244 at: https://wandb.ai/nreints/ThesisFinal1/runs/8mxry6n1
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_174607-8mxry6n1/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_175701-py7nlsz4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run winter-thunder-281
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal1/runs/py7nlsz4
	 Logging train Loss: 5.0909e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.6273e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 9.72e-08 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.5703e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.5569e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 5.82e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 49.44870138168335
Epoch 5/9
	 Logging train Loss: 4.5292e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.1668e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 9.97e-08 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.7906e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.9998e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 6.42e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 49.71175956726074
Epoch 6/9
	 Logging train Loss: 4.3178e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.3618e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.062e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.8482e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.1302e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 7.3e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 49.60912466049194
Epoch 7/9
	 Logging train Loss: 3.6612e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.2134e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.754e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.8293e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.9179e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.443e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 49.603750705718994
Epoch 8/9
	 Logging train Loss: 3.4697e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.6117e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.884e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.9336e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.193e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.6e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 50.82631516456604
Epoch 9/9
	 Logging train Loss: 3.1442e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.0956e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.225e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.6973e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.6045e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.987e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 49.73870897293091
Saved model in  trained_models/gru/data_t(0,0)_r(5,20)_combi_pNone_gNone/'log_dualQ_1'_'False'.pth
It took  653.4650053977966  seconds.
----- ITERATION 8/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 60.626686573028564 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(5,20)_tennis_pNone_gNone took 15.247105360031128 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_none_pNone_gNone took 15.203614950180054 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 15.208168506622314 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_semi_pNone_gNone took 15.29559588432312 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_full_pNone_gNone took 15.168214082717896 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(6, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=6, bias=True)
)
Datatype: log_dualQ_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0006186123 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.97766e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.7287e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.42158e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.37049e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.5673e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 48.77367663383484
Epoch 1/9
	 Logging train Loss: 9.3479e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.7404e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.6e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 4.0117e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.9752e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.062e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 49.12340974807739
Epoch 2/9
	 Logging train Loss: 3.7337e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.5885e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.445e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.6289e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.7995e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 9.71e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 49.29701542854309
Epoch 3/9
	 Logging train Loss: 3.9203e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 9.0959e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.047e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 4.8743e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.03688e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.585e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 48.85247850418091
Epoch 4/9
	 Logging train Loss: 4.2285e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.7095e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.052e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.0864e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.7232e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 6.48e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 48.95475959777832
Epoch 5/9
	 Logging train Loss: 4.0431e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.2169e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.522e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.8009e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.1775e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.133e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 49.22409224510193
Epoch 6/9
	 Logging train Loss: 4.0454e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.7982e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.27e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.2989e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.7431e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.928e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 49.22578954696655
Epoch 7/9
	 Logging train Loss: 3.6007e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.6152e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.662e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.4522e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.5253e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone █▂▁▂▁▁▁▁▁▁
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone █▂▁▁▁▁▃▁▁▁
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone █▂▁▁▁▁▂▁▁▁
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone █▂▂▂▁▂▁▁▁▁
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone █▁▁▂▁▂▁▁▁▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone 1e-05
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: 🚀 View run winter-thunder-281 at: https://wandb.ai/nreints/ThesisFinal1/runs/py7nlsz4
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_175701-py7nlsz4/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_180741-okw6kpd5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run clear-waterfall-314
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal1/runs/okw6kpd5
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone ▅▁▁█▁▁▁▁▁▁
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone ▅▂▂█▁▁▁▁▁▁
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone ▅▂▂█▁▁▁▁▁▁
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone ▅▁▁█▁▁▁▁▁▁
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone ▄▁▁█▁▁▁▁▁▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone 0.0
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone 1e-05
wandb:                                  Train loss 0.0
wandb: 
wandb: 🚀 View run clear-waterfall-314 at: https://wandb.ai/nreints/ThesisFinal1/runs/okw6kpd5
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_180741-okw6kpd5/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230626_181828-xa010k3v
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run comfy-meadow-335
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal1
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal1/runs/xa010k3v
	 Logging test loss: 1.341e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 49.13089561462402
Epoch 8/9
	 Logging train Loss: 3.3196e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.259e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 8.76e-08 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.2987e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.0225e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 5.98e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 49.30291175842285
Epoch 9/9
	 Logging train Loss: 2.987e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.4223e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.584e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.3811e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.1126e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.342e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 49.04725193977356
Saved model in  trained_models/gru/data_t(0,0)_r(5,20)_combi_pNone_gNone/'log_dualQ_1'_'False'.pth
It took  640.6335430145264  seconds.
----- ITERATION 9/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 60.57663059234619 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(5,20)_tennis_pNone_gNone took 15.12189769744873 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_none_pNone_gNone took 15.175577163696289 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 15.138177633285522 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_semi_pNone_gNone took 15.183756351470947 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_full_pNone_gNone took 15.272598505020142 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(6, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=6, bias=True)
)
Datatype: log_dualQ_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0005068735 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.93728e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.5015e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.48117e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.94777e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.3972e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 48.85573673248291
Epoch 1/9
	 Logging train Loss: 8.1494e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.7468e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.305e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 5.129e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.4635e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.844e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 50.526283979415894
Epoch 2/9
	 Logging train Loss: 4.5108e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.0422e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.934e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 4.0284e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.8525e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.53e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 49.78660559654236
Epoch 3/9
	 Logging train Loss: 4.9939e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.10592e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.3343e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 4.01385e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.09294e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.3991e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 49.051987648010254
Epoch 4/9
	 Logging train Loss: 5.0413e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.5763e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.434e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.5973e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.3319e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.098e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 49.441670179367065
Epoch 5/9
	 Logging train Loss: 4.091e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 9.278e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.572e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 4.9866e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.8086e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.309e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 49.775567054748535
Epoch 6/9
	 Logging train Loss: 4.3272e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.3596e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.03e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.8748e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.1972e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 7.5e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 49.5162079334259
Epoch 7/9
	 Logging train Loss: 3.6182e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.5011e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.817e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.963e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.2636e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.569e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 49.351205348968506
Epoch 8/9
	 Logging train Loss: 3.4216e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.831e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.885e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.6321e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.5484e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.694e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 49.688236236572266
Epoch 9/9
	 Logging train Loss: 2.9923e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.0346e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.431e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.6709e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.8007e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.275e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 49.418272972106934
Saved model in  trained_models/gru/data_t(0,0)_r(5,20)_combi_pNone_gNone/'log_dualQ_1'_'False'.pth
It took  647.1100471019745  seconds.
----- ITERATION 10/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 60.698612451553345 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(5,20)_tennis_pNone_gNone took 15.151483058929443 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_none_pNone_gNone took 15.22560715675354 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 15.164957523345947 seconds.
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone █▂▁▁▁▁▁▁▂▁
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone █▂▁▁▁▁▂▁▂▁
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone █▂▁▁▁▁▂▁▂▁
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone █▂▁▁▁▁▁▁▂▁
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone █▂▁▁▁▁▁▁▂▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone 1e-05
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone 1e-05
wandb:                                  Train loss 0.0
wandb: 
wandb: 🚀 View run comfy-meadow-335 at: https://wandb.ai/nreints/ThesisFinal1/runs/xa010k3v
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230626_181828-xa010k3v/logs
The dataloader for data/data_t(0,0)_r(5,20)_semi_pNone_gNone took 15.165361881256104 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_full_pNone_gNone took 15.189091444015503 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(6, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=6, bias=True)
)
Datatype: log_dualQ_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0009009543 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.91094e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.5308e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 4.37853e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.05033e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.418e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 49.28613781929016
Epoch 1/9
	 Logging train Loss: 1.71275e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.16924e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 5.646e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 6.8144e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.05459e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 5.008e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 49.200501441955566
Epoch 2/9
	 Logging train Loss: 4.7359e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.5297e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.009e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 4.0349e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.8511e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.584e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 49.033262729644775
Epoch 3/9
	 Logging train Loss: 4.0916e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.4857e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.516e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.4163e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.9381e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.131e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 48.77720046043396
Epoch 4/9
	 Logging train Loss: 4.314e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.6519e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.37e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.8394e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.993e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.033e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 49.04530453681946
Epoch 5/9
	 Logging train Loss: 4.5985e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 9.2285e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.278e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 4.5467e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.3764e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.988e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 49.24170517921448
Epoch 6/9
	 Logging train Loss: 4.4727e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.6217e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.777e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.0606e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.1918e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.458e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 49.290932178497314
Epoch 7/9
	 Logging train Loss: 3.9299e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.0537e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.594e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 4.9915e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 9.5193e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.393e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 49.49076271057129
Epoch 8/9
	 Logging train Loss: 4.0369e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.93327e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.687e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 8.8811e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.73555e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.621e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 49.85569095611572
Epoch 9/9
	 Logging train Loss: 3.4264e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.5401e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.673e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.2068e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.9205e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.48e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 49.20538783073425
Saved model in  trained_models/gru/data_t(0,0)_r(5,20)_combi_pNone_gNone/'log_dualQ_1'_'False'.pth
It took  655.2098772525787  seconds.

JOB STATISTICS
==============
Job ID: 2971270
Array Job ID: 2971258_12
Cluster: snellius
User/Group: nreints/nreints
State: COMPLETED (exit code 0)
Nodes: 1
Cores per node: 18
CPU Utilized: 07:26:14
CPU Efficiency: 22.75% of 1-08:41:06 core-walltime
Job Wall-clock time: 01:48:57
Memory Utilized: 8.26 GB
Memory Efficiency: 0.00% of 0.00 MB
