wandb: Currently logged in as: nreints. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home/nreints/.netrc
/gpfs/home2/nreints/MScThesis/code/fcnn.py:566: DeprecationWarning: Sampling from a set deprecated
since Python 3.9 and will be removed in a subsequent version.
  train_sims = set(random.sample(sims_train, int(0.8 * n_sims_train)))
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230330_123650-4zdz62qq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run northern-firefly-587
wandb: â­ï¸ View project at https://wandb.ai/nreints/test
wandb: ðŸš€ View run at https://wandb.ai/nreints/test/runs/4zdz62qq
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:  Test loss t(5, 20)_r(0, 0)_tennis L1Loss() â–ˆâ–…â–„â–ƒâ–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–â–â–â–â–â–â–â–â–
wandb: Test loss t(5, 20)_r(0, 0)_tennis MSELoss() â–ˆâ–„â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:     Train loss data_t(5, 20)_r(0, 0)_tennis â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:  Test loss t(5, 20)_r(0, 0)_tennis L1Loss() 0.08154
wandb: Test loss t(5, 20)_r(0, 0)_tennis MSELoss() 0.01093
wandb:     Train loss data_t(5, 20)_r(0, 0)_tennis 0.00566
wandb: 
wandb: ðŸš€ View run northern-firefly-587 at: https://wandb.ai/nreints/test/runs/4zdz62qq
wandb: Synced 6 W&B file(s), 0 media file(s), 2 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230330_123650-4zdz62qq/logs
/gpfs/home2/nreints/MScThesis/code/fcnn.py:566: DeprecationWarning: Sampling from a set deprecated
since Python 3.9 and will be removed in a subsequent version.
  train_sims = set(random.sample(sims_train, int(0.8 * n_sims_train)))
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230330_124719-otvbtw76
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run peachy-pine-607
wandb: â­ï¸ View project at https://wandb.ai/nreints/test
wandb: ðŸš€ View run at https://wandb.ai/nreints/test/runs/otvbtw76
Training on dataset: data/data_t(5, 20)_r(0, 0)_tennis_pNone_gNone
Testing on datasets: ['data_t(5, 20)_r(0, 0)_tennis_pNone_gNone']
----- ITERATION 1/2 ------
Number of train simulations: 1600
Number of test simulations: 400
The dataloader took 59.985421657562256 seconds.
-- Finished Train Dataloader --
The dataloader took 15.127118110656738 seconds.
-- Finished Test Dataloader(s) --
Datatype: pos
--- Started Training ---
Epoch 0
	 Logging train Loss: 19.461291105 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.5794188380241394 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.5557299256324768 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 25.976196765899658
Epoch 1
	 Logging train Loss: 0.3549773173 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.23572027683258057 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.35346853733062744 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 27.14758825302124
Epoch 2
	 Logging train Loss: 0.1480556712 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.11148067563772202 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.24282221496105194 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 27.34712314605713
Epoch 3
	 Logging train Loss: 0.0739609912 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.06203513965010643 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.18023812770843506 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 27.667890787124634
Epoch 4
	 Logging train Loss: 0.0446247026 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.04192716255784035 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.15060508251190186 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 27.42031192779541
Epoch 5
	 Logging train Loss: 0.0305734772 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.030297687277197838 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.1287161260843277 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 27.402881860733032
Epoch 6
	 Logging train Loss: 0.0228216358 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.0241863951086998 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.11664240807294846 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 27.30364489555359
Epoch 7
	 Logging train Loss: 0.0181804894 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.01763182133436203 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.0996108278632164 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 27.339471578598022
Epoch 8
	 Logging train Loss: 0.015057206 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.01507800817489624 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.09299337863922119 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 27.424736976623535
Epoch 9
	 Logging train Loss: 0.0130324432 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.012409089133143425 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.08417989313602448 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 27.509178161621094
Epoch 10
	 Logging train Loss: 0.0114255668 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.01461087353527546 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.0942877009510994 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 27.113528728485107
Epoch 11
	 Logging train Loss: 0.0101829429 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.02264309488236904 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.11643505096435547 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 27.207809448242188
Epoch 12
	 Logging train Loss: 0.0092774454 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.007870733737945557 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.0676039308309555 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 25.792015314102173
Epoch 13
	 Logging train Loss: 0.0086331935 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.00802681501954794 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.0691559910774231 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 26.002719402313232
Epoch 14
	 Logging train Loss: 0.007759798 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.006953718606382608 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.06410897523164749 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 26.06000781059265
Epoch 15
	 Logging train Loss: 0.007395164 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.010886435396969318 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.08171560615301132 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 25.49884605407715
Epoch 16
	 Logging train Loss: 0.0067091786 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.006160013843327761 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.06042042747139931 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 27.57014036178589
Epoch 17
	 Logging train Loss: 0.0064472336 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.005832098890095949 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.05882791429758072 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 25.693052768707275
Epoch 18
	 Logging train Loss: 0.0058943237 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.004491413943469524 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.05092417821288109 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 25.472270727157593
Epoch 19
	 Logging train Loss: 0.0056614913 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.010927747003734112 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.08154512196779251 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 25.56901454925537
	 Logging test loss 0.01092691533267498 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.08154496550559998 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
It took 628.0910332202911 seconds to train & eval the model.
----- ITERATION 2/2 ------
Number of train simulations: 1600
Number of test simulations: 400
The dataloader took 55.673219203948975 seconds.
-- Finished Train Dataloader --
The dataloader took 13.849844694137573 seconds.
-- Finished Test Dataloader(s) --
Datatype: pos
--- Started Training ---
Epoch 0
	 Logging train Loss: 20.7061300041 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.6716269254684448 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.6056618094444275 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 27.45546841621399
Epoch 1
	 Logging train Loss: 0.3478366428 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.26869481801986694 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.38132935762405396 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 26.038804531097412
Epoch 2
	 Logging train Loss: 0.145744603 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.13027851283550262 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.26373589038848877 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 25.944891452789307
Epoch 3
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.029 MB of 0.029 MB uploaded (0.000 MB deduped)wandb: \ 0.029 MB of 0.029 MB uploaded (0.000 MB deduped)wandb: | 0.029 MB of 0.029 MB uploaded (0.000 MB deduped)wandb: / 0.029 MB of 0.029 MB uploaded (0.000 MB deduped)wandb: - 0.029 MB of 0.029 MB uploaded (0.000 MB deduped)wandb: \ 0.029 MB of 0.029 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  Test loss t(5, 20)_r(0, 0)_tennis L1Loss() â–ˆâ–…â–„â–ƒâ–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–‚â–â–â–‚â–â–â–
wandb: Test loss t(5, 20)_r(0, 0)_tennis MSELoss() â–ˆâ–„â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:     Train loss data_t(5, 20)_r(0, 0)_tennis â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:  Test loss t(5, 20)_r(0, 0)_tennis L1Loss() 0.05817
wandb: Test loss t(5, 20)_r(0, 0)_tennis MSELoss() 0.00579
wandb:     Train loss data_t(5, 20)_r(0, 0)_tennis 0.00535
wandb: 
wandb: ðŸš€ View run peachy-pine-607 at: https://wandb.ai/nreints/test/runs/otvbtw76
wandb: Synced 6 W&B file(s), 0 media file(s), 2 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230330_124719-otvbtw76/logs
	 Logging train Loss: 0.0725600249 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.07433363050222397 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.19933070242404938 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 25.569842100143433
Epoch 4
	 Logging train Loss: 0.0423637689 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.04560772702097893 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.155931293964386 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 27.70343017578125
Epoch 5
	 Logging train Loss: 0.0282487882 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.03444116190075874 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.13666799664497375 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 27.529741764068604
Epoch 6
	 Logging train Loss: 0.0210581586 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.036184679716825485 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.1479189544916153 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 27.06653618812561
Epoch 7
	 Logging train Loss: 0.0168708352 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.01935996301472187 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.10342366248369217 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 25.668355464935303
Epoch 8
	 Logging train Loss: 0.0139500013 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.01791844330728054 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.10168495029211044 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 25.724251747131348
Epoch 9
	 Logging train Loss: 0.012010502 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.013685237616300583 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.08812279999256134 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 25.491256713867188
Epoch 10
	 Logging train Loss: 0.0107020771 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.015834378078579903 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.09671463072299957 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 25.303961753845215
Epoch 11
	 Logging train Loss: 0.009579072 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.011386990547180176 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.08114534616470337 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 27.03699827194214
Epoch 12
	 Logging train Loss: 0.0086654183 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.009720437228679657 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.07506780326366425 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 25.536869049072266
Epoch 13
	 Logging train Loss: 0.0080218041 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.008352796547114849 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.06940267235040665 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 25.58693289756775
Epoch 14
	 Logging train Loss: 0.0075234737 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.024068478494882584 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.12779873609542847 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 25.655970335006714
Epoch 15
	 Logging train Loss: 0.0068196982 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.00682620657607913 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.06274371594190598 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 25.366943359375
Epoch 16
	 Logging train Loss: 0.0063675849 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.0068635777570307255 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.06299778074026108 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 27.352277278900146
Epoch 17
	 Logging train Loss: 0.0060422193 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.018680915236473083 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.10788833349943161 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 27.18924069404602
Epoch 18
	 Logging train Loss: 0.00570363 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.014167805202305317 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.09553197026252747 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 27.267001390457153
Epoch 19
	 Logging train Loss: 0.0053456356 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.0057897791266441345 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.05816679447889328 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 25.621997117996216
	 Logging test loss 0.005790200550109148 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.058166828006505966 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
It took 613.2947871685028 seconds to train & eval the model.

JOB STATISTICS
==============
Job ID: 2523390
Array Job ID: 2523368_22
Cluster: snellius
User/Group: nreints/nreints
State: RUNNING
Nodes: 1
Cores per node: 18
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 06:17:42 core-walltime
Job Wall-clock time: 00:20:59
Memory Utilized: 0.00 MB (estimated maximum)
Memory Efficiency: 0.00% of 29.30 GB (29.30 GB/node)
WARNING: Efficiency statistics may be misleading for RUNNING jobs.
