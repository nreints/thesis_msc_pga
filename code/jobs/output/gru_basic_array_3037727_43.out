wandb: Currently logged in as: nreints. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_165451-qgi297i8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run kind-violet-759
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/qgi297i8
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue â–ˆâ–‚â–â–â–â–â–‚â–â–…â–
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue â–ˆâ–‚â–â–â–â–â–â–â–‚â–
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue â–‡â–â–â–â–â–â–‚â–â–ˆâ–
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue â–‡â–â–â–â–â–â–‚â–â–ˆâ–
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue 0.0
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue 0.0
wandb:                                 Train loss 0.0
wandb: 
wandb: ðŸš€ View run kind-violet-759 at: https://wandb.ai/nreints/ThesisFinal2/runs/qgi297i8
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_165451-qgi297i8/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_170150-3ktlkagd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run desert-durian-769
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/3ktlkagd
Training on dataset: data_t(0,0)_r(0,0)_combi_pNone_gTrue
Testing on 4 datasets: ['data_t(0,0)_r(0,0)_combi_pNone_gTrue', 'data_t(0,0)_r(0,0)_tennis_pNone_gTrue', 'data_t(0,0)_r(0,0)_semi_pNone_gTrue', 'data_t(0,0)_r(0,0)_full_pNone_gTrue']
Focussing on identity: False
Using extra input: False
Using fr-fr as reference point.
----- ITERATION 1/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 51.58163380622864 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 12.877427577972412 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pNone_gTrue took 12.901339530944824 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pNone_gTrue took 12.953885316848755 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pNone_gTrue took 12.787951707839966 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: log_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0002921244 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.2815e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.4107e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 5.4207e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 5.1603e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 31.64890432357788
Epoch 1/9
	 Logging train Loss: 1.8184e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.202e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.377e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 4.363e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 4.044e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 30.008361339569092
Epoch 2/9
	 Logging train Loss: 9.585e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.012e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.098e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.097e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.934e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 29.915804862976074
Epoch 3/9
	 Logging train Loss: 7.333e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.977e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.024e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.024e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.935e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 29.844792127609253
Epoch 4/9
	 Logging train Loss: 1.6283e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.199e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.315e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.302e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.086e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 30.081678867340088
Epoch 5/9
	 Logging train Loss: 9.125e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.97e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.08e-08 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 5.08e-08 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 4.88e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 30.04666519165039
Epoch 6/9
	 Logging train Loss: 1.2632e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.721e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 9.578e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 8.697e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 6.99e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 29.93195867538452
Epoch 7/9
	 Logging train Loss: 9.145e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.7e-09 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.4e-09 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 5.3e-09 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 4.1e-09 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 29.82468271255493
Epoch 8/9
	 Logging train Loss: 1.1092e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.3789e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.5664e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 6.2821e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 5.299e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 29.788899898529053
Epoch 9/9
	 Logging train Loss: 8.905e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.11e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.2e-08 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.97e-08 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.1e-09 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 29.933868646621704
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'log_quat_1'_'False'.pth
It took  420.08991050720215  seconds.
----- ITERATION 2/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 47.782570123672485 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 11.929885625839233 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pNone_gTrue took 12.258467674255371 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pNone_gTrue took 12.112708568572998 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pNone_gTrue took 11.886032342910767 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: log_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0001913006 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.2828e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.3457e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 5.3407e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 5.2243e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 30.174986362457275
Epoch 1/9
	 Logging train Loss: 2.2634e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.827e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.204e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 7.148e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 6.488e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 30.236459732055664
Epoch 2/9
	 Logging train Loss: 9.654e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.7519e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.1301e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 4.8005e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 6.262e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 30.18366575241089
Epoch 3/9
	 Logging train Loss: 7.621e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.2535e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.2638e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.1876e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 3.871e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 30.19148063659668
Epoch 4/9
	 Logging train Loss: 1.0758e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.83e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue â–ˆâ–‚â–…â–ƒâ–â–â–â–â–â–‚
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue â–ˆâ–‚â–‚â–â–â–â–â–â–â–
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue â–ˆâ–‚â–‡â–„â–â–â–â–â–‚â–‚
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue â–ˆâ–‚â–ˆâ–„â–â–â–â–â–‚â–‚
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue 0.0
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue 0.0
wandb:                                 Train loss 0.0
wandb: 
wandb: ðŸš€ View run desert-durian-769 at: https://wandb.ai/nreints/ThesisFinal2/runs/3ktlkagd
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_170150-3ktlkagd/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_170846-4zu0ksl6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run azure-butterfly-787
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/4zu0ksl6
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue â–â–â–â–â–ˆâ–â–â–â–â–‚
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue â–†â–‚â–â–â–ˆâ–â–â–â–â–‚
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue â–â–â–â–â–ˆâ–â–â–â–â–‚
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue â–â–â–â–â–ˆâ–â–â–â–â–‚
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 1e-05
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue 1e-05
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue 1e-05
wandb:                                 Train loss 0.0
wandb: 
wandb: ðŸš€ View run azure-butterfly-787 at: https://wandb.ai/nreints/ThesisFinal2/runs/4zu0ksl6
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_170846-4zu0ksl6/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_171536-8ulpxj07
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run easy-snowflake-799
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/8ulpxj07
	 Logging test loss: 3.502e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.36e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.184e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 30.832149744033813
Epoch 5/9
	 Logging train Loss: 1.2499e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.197e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.257e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.114e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.319e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 33.985735177993774
Epoch 6/9
	 Logging train Loss: 1.8586e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.37e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.52e-08 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 6.51e-08 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 6.23e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 30.55274271965027
Epoch 7/9
	 Logging train Loss: 6.297e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.61e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.86e-08 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.81e-08 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.38e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 30.499297380447388
Epoch 8/9
	 Logging train Loss: 9.078e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.345e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.41e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 5.821e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 3.59e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 30.297679901123047
Epoch 9/9
	 Logging train Loss: 5.337e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.032e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.996e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 7.79e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 3.96e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 30.441817045211792
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'log_quat_1'_'False'.pth
It took  416.0703887939453  seconds.
----- ITERATION 3/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 47.526606798172 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 11.938271760940552 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pNone_gTrue took 12.059742212295532 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pNone_gTrue took 12.057448148727417 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pNone_gTrue took 11.862599849700928 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: log_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.000116645 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.9768e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.0333e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 4.0259e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 3.9394e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 30.17170476913452
Epoch 1/9
	 Logging train Loss: 1.3307e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.884e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.985e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 4.971e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 4.815e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 30.469677209854126
Epoch 2/9
	 Logging train Loss: 8.476e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.417e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.786e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.732e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 3.179e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 30.145901441574097
Epoch 3/9
	 Logging train Loss: 1.7455e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.964e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.017e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.01e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.93e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 30.457489252090454
Epoch 4/9
	 Logging train Loss: 1.7945e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.65897e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0001368535 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 0.0001255257 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 5.3119e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 30.10132360458374
Epoch 5/9
	 Logging train Loss: 1.4002e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.96e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.33e-08 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 4.28e-08 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 3.72e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 30.582379579544067
Epoch 6/9
	 Logging train Loss: 1.034e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 9.8e-09 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.27e-08 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.23e-08 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 7.9e-09 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 30.271449327468872
Epoch 7/9
	 Logging train Loss: 1.271e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.5e-09 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.7e-09 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 4.4e-09 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.2e-09 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 30.25636315345764
Epoch 8/9
	 Logging train Loss: 1.1015e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.1e-09 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.3e-09 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 7.8e-09 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.2e-09 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 30.294516801834106
Epoch 9/9
	 Logging train Loss: 6.002e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.0454e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.47088e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.38525e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 5.589e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 30.199172496795654
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'log_quat_1'_'False'.pth
It took  410.2177104949951  seconds.
----- ITERATION 4/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 47.56310033798218 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 11.916813373565674 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pNone_gTrue took 12.015419244766235 seconds.
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue â–ˆâ–‚â–‚â–â–â–â–â–â–â–
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue â–ˆâ–‚â–‚â–â–â–â–â–â–â–
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue â–ˆâ–‚â–‚â–â–â–â–â–â–â–
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue â–ˆâ–‚â–‚â–â–â–â–â–â–â–
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue 0.0
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue 0.0
wandb:                                 Train loss 0.0
wandb: 
wandb: ðŸš€ View run easy-snowflake-799 at: https://wandb.ai/nreints/ThesisFinal2/runs/8ulpxj07
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_171536-8ulpxj07/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_172226-bftainf6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run peachy-dew-817
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/bftainf6
The dataloader for data/data_t(0,0)_r(0,0)_semi_pNone_gTrue took 12.02675175666809 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pNone_gTrue took 11.361854553222656 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: log_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0001540085 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.4621e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.4851e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 4.4811e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 4.4438e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 30.497254133224487
Epoch 1/9
	 Logging train Loss: 2.0813e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.381e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.526e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 5.514e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 5.23e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 30.125991821289062
Epoch 2/9
	 Logging train Loss: 1.6845e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.762e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.771e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.771e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 3.753e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 30.38492774963379
Epoch 3/9
	 Logging train Loss: 1.9876e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.959e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.976e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.973e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.943e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 30.59069037437439
Epoch 4/9
	 Logging train Loss: 1.8479e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.216e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.319e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.309e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.107e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 29.57343053817749
Epoch 5/9
	 Logging train Loss: 1.1119e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.001e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.729e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.609e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.321e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 30.486844778060913
Epoch 6/9
	 Logging train Loss: 1.2851e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.38e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.83e-08 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 6.79e-08 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 5.9e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 30.174471855163574
Epoch 7/9
	 Logging train Loss: 8.735e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.83e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.95e-08 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.93e-08 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.71e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 30.48041534423828
Epoch 8/9
	 Logging train Loss: 8.618e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.3e-09 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.6e-09 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 5.5e-09 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 3e-09 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 30.304290771484375
Epoch 9/9
	 Logging train Loss: 5.704e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1e-09 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.4e-09 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.4e-09 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 6e-10 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 30.319526433944702
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'log_quat_1'_'False'.pth
It took  409.9689931869507  seconds.
----- ITERATION 5/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 47.66524291038513 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 11.935455083847046 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pNone_gTrue took 12.072059631347656 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pNone_gTrue took 12.063849210739136 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pNone_gTrue took 11.584837913513184 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: log_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0004662548 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.8021e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.9126e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 5.903e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 5.6954e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 30.583913564682007
Epoch 1/9
	 Logging train Loss: 3.0691e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.08e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.911e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 8.861e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 7.293e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 30.527451992034912
Epoch 2/9
	 Logging train Loss: 8.34e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.4e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.83e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 4.802e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 3.993e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 32.53990387916565
Epoch 3/9
	 Logging train Loss: 8.293e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.7853e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.3378e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.2989e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 3.569e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 32.029480934143066
Epoch 4/9
	 Logging train Loss: 1.0755e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.802e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.855e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.85e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.752e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 30.26648998260498
Epoch 5/9
	 Logging train Loss: 8.041e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.027e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.211e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.183e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 8.77e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 30.367271900177002
Epoch 6/9
	 Logging train Loss: 1.6474e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue â–ˆâ–‚â–‚â–ƒâ–â–â–â–â–â–
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue â–ˆâ–‚â–‚â–…â–â–â–â–‚â–â–
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue â–ˆâ–‚â–‚â–…â–â–â–â–‚â–â–
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue 0.0
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue 0.0
wandb:                                 Train loss 0.0
wandb: 
wandb: ðŸš€ View run peachy-dew-817 at: https://wandb.ai/nreints/ThesisFinal2/runs/bftainf6
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_172226-bftainf6/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_172920-l2dthjuo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sage-morning-837
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/l2dthjuo
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue â–ˆâ–‚â–â–â–â–â–â–â–‚â–
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue â–ˆâ–‚â–â–â–â–â–â–â–‚â–
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue â–ˆâ–‚â–â–â–â–â–â–â–‚â–
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue 0.0
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue 0.0
wandb:                                 Train loss 0.0
wandb: 
wandb: ðŸš€ View run sage-morning-837 at: https://wandb.ai/nreints/ThesisFinal2/runs/l2dthjuo
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_172920-l2dthjuo/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_173611-ovdwmepo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run true-music-852
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/ovdwmepo
	 Logging test loss: 3.47e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.69e-08 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.66e-08 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 3.28e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 30.5848445892334
Epoch 7/9
	 Logging train Loss: 1.0031e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.64e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.048e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 6.733e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 3.21e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 30.044710874557495
Epoch 8/9
	 Logging train Loss: 1.1925e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.4e-09 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.1e-09 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3e-09 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.7e-09 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 30.180378198623657
Epoch 9/9
	 Logging train Loss: 1.0521e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.5e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.32e-08 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 6.49e-08 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 5.4e-09 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 30.46098566055298
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'log_quat_1'_'False'.pth
It took  413.9569113254547  seconds.
----- ITERATION 6/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 47.71902108192444 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 11.924267292022705 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pNone_gTrue took 12.031622648239136 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pNone_gTrue took 12.141802072525024 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pNone_gTrue took 12.348637580871582 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: log_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0007453694 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.1962e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.2681e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 6.2475e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 6.1351e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 30.051159381866455
Epoch 1/9
	 Logging train Loss: 3.0235e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.425e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.917e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 6.8e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 6.014e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 30.291374683380127
Epoch 2/9
	 Logging train Loss: 6.183e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.22e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.478e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.418e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 3.003e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 30.30760431289673
Epoch 3/9
	 Logging train Loss: 6.79e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.062e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.203e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.172e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.945e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 30.455500841140747
Epoch 4/9
	 Logging train Loss: 6.842e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.896e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.956e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.544e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.089e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 30.153257608413696
Epoch 5/9
	 Logging train Loss: 1.0335e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.62e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.94e-08 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 4.86e-08 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 4.34e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 30.224130630493164
Epoch 6/9
	 Logging train Loss: 1.0951e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.63e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.98e-08 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.86e-08 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.33e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 29.99744701385498
Epoch 7/9
	 Logging train Loss: 7.81e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.1e-09 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.1e-09 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 4.8e-09 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 3.2e-09 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 30.263497829437256
Epoch 8/9
	 Logging train Loss: 1.0952e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.067e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.3295e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.1334e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 4.5e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 30.258336782455444
Epoch 9/9
	 Logging train Loss: 9.8e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.5e-09 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3e-09 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.5e-09 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 4e-10 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 30.307467222213745
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'log_quat_1'_'False'.pth
It took  411.12668228149414  seconds.
----- ITERATION 7/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 48.50311541557312 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 11.945796251296997 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pNone_gTrue took 12.017894744873047 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pNone_gTrue took 12.05369758605957 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pNone_gTrue took 12.050145864486694 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: log_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0002990968 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.7009e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.7488e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 5.7345e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 5.6616e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 30.34268045425415
Epoch 1/9
	 Logging train Loss: 2.425e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue â–…â–â–â–â–â–ƒâ–â–â–ˆâ–„
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue â–ˆâ–‚â–â–â–â–â–â–â–‚â–
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue â–ƒâ–â–â–â–â–ƒâ–â–â–ˆâ–„
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue â–ƒâ–â–â–â–â–ƒâ–â–â–ˆâ–„
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue 1e-05
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue 1e-05
wandb:                                 Train loss 0.0
wandb: 
wandb: ðŸš€ View run true-music-852 at: https://wandb.ai/nreints/ThesisFinal2/runs/ovdwmepo
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_173611-ovdwmepo/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_174304-wznheg3y
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run comfy-sponge-872
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/wznheg3y
	 Logging test loss: 4.599e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.703e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 4.674e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 4.507e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 30.72820019721985
Epoch 2/9
	 Logging train Loss: 3.515e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.022e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.073e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.06e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.982e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 30.441606283187866
Epoch 3/9
	 Logging train Loss: 9.632e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.347e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.617e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 6.207e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.508e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 30.462308406829834
Epoch 4/9
	 Logging train Loss: 1.5692e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.636e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.76e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.739e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.53e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 30.2258620262146
Epoch 5/9
	 Logging train Loss: 1.0737e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.4717e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.1104e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 4.6714e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 3.312e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 30.5030734539032
Epoch 6/9
	 Logging train Loss: 1.4725e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.07e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.29e-08 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 4.23e-08 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 3.87e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 30.33338236808777
Epoch 7/9
	 Logging train Loss: 1.5742e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.01e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.296e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.082e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.07e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 30.29717493057251
Epoch 8/9
	 Logging train Loss: 1.1847e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 9.0707e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.87444e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.61135e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 6.534e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 30.224880933761597
Epoch 9/9
	 Logging train Loss: 1.0628e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.7436e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.5978e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 6.9205e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.585e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 30.271604537963867
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'log_quat_1'_'False'.pth
It took  412.9404628276825  seconds.
----- ITERATION 8/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 47.48872399330139 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 11.923218965530396 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pNone_gTrue took 12.07660698890686 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pNone_gTrue took 12.114489316940308 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pNone_gTrue took 12.145204305648804 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: log_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0002205669 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.5389e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.5838e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.5773e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.5046e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 33.56513476371765
Epoch 1/9
	 Logging train Loss: 5.148e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.103e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.319e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.29e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.942e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 30.14960289001465
Epoch 2/9
	 Logging train Loss: 3.708e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.117e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.285e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.266e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.989e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 30.06345295906067
Epoch 3/9
	 Logging train Loss: 8.703e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.35e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.445e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.435e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.279e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 30.18627166748047
Epoch 4/9
	 Logging train Loss: 9.717e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.17e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.75e-08 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 8.69e-08 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 7.73e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 29.987284898757935
Epoch 5/9
	 Logging train Loss: 1.4156e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.666e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.626e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 7.417e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 4.177e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 30.31672191619873
Epoch 6/9
	 Logging train Loss: 9.226e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 9.12e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.735e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.599e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.51e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 30.112006902694702
Epoch 7/9
	 Logging train Loss: 1.0976e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.03e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.21e-08 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.19e-08 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 9e-09 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 30.346354961395264
Epoch 8/9
	 Logging train Loss: 7.438e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue â–ˆâ–‚â–‚â–‚â–â–„â–â–â–†â–
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue â–ˆâ–‚â–‚â–‚â–â–ƒâ–â–â–â–
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue â–†â–‚â–‚â–â–â–ƒâ–â–â–ˆâ–
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue â–†â–‚â–‚â–â–â–ƒâ–â–â–ˆâ–
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue 0.0
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue 0.0
wandb:                                 Train loss 0.0
wandb: 
wandb: ðŸš€ View run comfy-sponge-872 at: https://wandb.ai/nreints/ThesisFinal2/runs/wznheg3y
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_174304-wznheg3y/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_174956-8ta8wthy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run grateful-waterfall-886
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/8ta8wthy
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue â–ˆâ–‚â–â–‚â–â–â–„â–â–â–
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue â–ˆâ–‚â–â–‚â–â–‚â–‡â–â–â–
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue â–ˆâ–‚â–â–‚â–â–‚â–‡â–â–â–
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue 0.0
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue 0.0
wandb:                                 Train loss 0.0
wandb: 
wandb: ðŸš€ View run grateful-waterfall-886 at: https://wandb.ai/nreints/ThesisFinal2/runs/8ta8wthy
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_174956-8ta8wthy/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_175647-pz6bibnt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eager-universe-907
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/pz6bibnt
	 Logging test loss: 1.1193e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.4211e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.2014e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 8.45e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 30.199748039245605
Epoch 9/9
	 Logging train Loss: 9.705e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.1e-09 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.1e-09 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 4e-09 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.4e-09 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 30.152250289916992
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'log_quat_1'_'False'.pth
It took  412.2137944698334  seconds.
----- ITERATION 9/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 47.512996435165405 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 11.894641399383545 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pNone_gTrue took 12.053891658782959 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pNone_gTrue took 12.045813798904419 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pNone_gTrue took 12.014825820922852 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: log_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0002031852 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.8703e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.8927e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 4.896e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 4.8396e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 30.06528878211975
Epoch 1/9
	 Logging train Loss: 1.8721e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.131e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.193e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 4.193e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 4.057e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 30.45796823501587
Epoch 2/9
	 Logging train Loss: 9.059e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.895e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.94e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.938e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.844e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 30.17304491996765
Epoch 3/9
	 Logging train Loss: 7.13e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.692e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.969e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 4.991e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.266e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 30.37920641899109
Epoch 4/9
	 Logging train Loss: 1.5193e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.684e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.765e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.768e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.583e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 30.196223974227905
Epoch 5/9
	 Logging train Loss: 1.2583e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.663e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.813e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.924e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.166e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 30.644196033477783
Epoch 6/9
	 Logging train Loss: 9.894e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.3027e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.8831e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.9931e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.096e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 30.48058843612671
Epoch 7/9
	 Logging train Loss: 8.92e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.078e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.613e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.658e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 3.68e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 30.37777090072632
Epoch 8/9
	 Logging train Loss: 1.1502e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.94e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.12e-08 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.12e-08 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.73e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 30.402090072631836
Epoch 9/9
	 Logging train Loss: 5.99e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.896e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.228e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.332e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.17e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 30.25111436843872
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'log_quat_1'_'False'.pth
It took  410.29245805740356  seconds.
----- ITERATION 10/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 47.6795334815979 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 11.934314250946045 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pNone_gTrue took 12.055403470993042 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pNone_gTrue took 12.088182926177979 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pNone_gTrue took 12.064050436019897 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: log_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0001747145 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.2384e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.3642e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 4.3359e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 4.1331e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 30.33282470703125
Epoch 1/9
	 Logging train Loss: 1.5072e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.114e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.18e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 4.173e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 4.056e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 30.533653736114502
Epoch 2/9
	 Logging train Loss: 5.721e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.85487e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.04621e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 5.26897e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.1286e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 30.221649408340454
Epoch 3/9
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue â–‚â–â–ˆâ–â–â–â–„â–â–‚â–
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue â–ˆâ–‚â–…â–â–â–â–‚â–â–â–
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue â–‚â–â–ˆâ–â–â–â–„â–â–‚â–
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue â–‚â–â–ˆâ–â–â–â–„â–â–‚â–
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue 0.0
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue 0.0
wandb:                                 Train loss 0.0
wandb: 
wandb: ðŸš€ View run eager-universe-907 at: https://wandb.ai/nreints/ThesisFinal2/runs/pz6bibnt
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_175647-pz6bibnt/logs
	 Logging train Loss: 1.2208e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.399e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.491e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.469e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.319e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 30.341214895248413
Epoch 4/9
	 Logging train Loss: 1.3384e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.681e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.771e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.758e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.605e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 30.32258915901184
Epoch 5/9
	 Logging train Loss: 1.2158e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.1568e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.2417e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.1015e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.047e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 30.3613224029541
Epoch 6/9
	 Logging train Loss: 1.2835e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.1988e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.51308e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.43394e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 7.165e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 30.013349533081055
Epoch 7/9
	 Logging train Loss: 1.2101e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.18e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.39e-08 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.35e-08 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 30.302224159240723
Epoch 8/9
	 Logging train Loss: 6.977e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.0027e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.9396e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 7.9755e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 3.036e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 30.410894870758057
Epoch 9/9
	 Logging train Loss: 9.057e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.605e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.1685e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.0656e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 5.11e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 30.451973915100098
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'log_quat_1'_'False'.pth
It took  412.120126247406  seconds.

JOB STATISTICS
==============
Job ID: 3037750
Array Job ID: 3037727_43
Cluster: snellius
User/Group: nreints/nreints
State: COMPLETED (exit code 0)
Nodes: 1
Cores per node: 18
CPU Utilized: 01:15:03
CPU Efficiency: 6.03% of 20:43:48 core-walltime
Job Wall-clock time: 01:09:06
Memory Utilized: 7.42 GB
Memory Efficiency: 0.00% of 0.00 MB
