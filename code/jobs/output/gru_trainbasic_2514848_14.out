wandb: Currently logged in as: nreints. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230329_135637-mk59fpov
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run jolly-disco-536
wandb: ‚≠êÔ∏è View project at https://wandb.ai/nreints/test
wandb: üöÄ View run at https://wandb.ai/nreints/test/runs/mk59fpov
wandb: Waiting for W&B process to finish... (success).
wandb: ERROR Error while calling W&B API: An internal error occurred. Please contact support. (<Response [500]>)
wandb: 
wandb: Run history:
wandb:                                                  Epoch ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà
wandb: Test loss t(5, 20)_r(0, 0)_semi_pNone_gNone, MSELoss() ‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                             Train loss ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:                                                  Epoch 9
wandb: Test loss t(5, 20)_r(0, 0)_semi_pNone_gNone, MSELoss() 0.0006
wandb:                                             Train loss 0.00073
wandb: 
wandb: üöÄ View run jolly-disco-536 at: https://wandb.ai/nreints/test/runs/mk59fpov
wandb: Synced 6 W&B file(s), 0 media file(s), 2 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230329_135637-mk59fpov/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230329_140406-d1dqg135
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lemon-grass-545
wandb: ‚≠êÔ∏è View project at https://wandb.ai/nreints/test
wandb: üöÄ View run at https://wandb.ai/nreints/test/runs/d1dqg135
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.031 MB of 0.031 MB uploaded (0.000 MB deduped)wandb: \ 0.031 MB of 0.031 MB uploaded (0.000 MB deduped)wandb: | 0.031 MB of 0.031 MB uploaded (0.000 MB deduped)wandb: / 0.031 MB of 0.031 MB uploaded (0.000 MB deduped)wandb: - 0.031 MB of 0.031 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:                                                  Epoch ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà
wandb: Test loss t(5, 20)_r(0, 0)_semi_pNone_gNone, MSELoss() ‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                             Train loss ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:                                                  Epoch 9
wandb: Test loss t(5, 20)_r(0, 0)_semi_pNone_gNone, MSELoss() 0.00062
wandb:                                             Train loss 0.00075
wandb: 
wandb: üöÄ View run lemon-grass-545 at: https://wandb.ai/nreints/test/runs/d1dqg135
wandb: Synced 6 W&B file(s), 0 media file(s), 2 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230329_140406-d1dqg135/logs
Running for data type: pos_diff_start
----- ITERATION 1/2 ------
Number of train simulations: 1600
Number of test simulations: 400
-- Finished Train Dataloader --
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(24, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=24, bias=True)
)
-- Started Training --
Epoch 0
	 Logging train Loss: 4.9054217472 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss: 0.25510549545288086 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 39.731189250946045
Epoch 1
	 Logging train Loss: 0.108961057 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss: 0.034367240965366364 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 37.38992118835449
Epoch 2
	 Logging train Loss: 0.0225046792 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss: 0.010331029072403908 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 37.50292730331421
Epoch 3
	 Logging train Loss: 0.0084717436 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss: 0.004288874566555023 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 38.14127540588379
Epoch 4
	 Logging train Loss: 0.0041906439 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss: 0.00237241736613214 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 38.166654109954834
Epoch 5
	 Logging train Loss: 0.0024276217 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss: 0.001477736746892333 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 37.80806922912598
Epoch 6
	 Logging train Loss: 0.0015422871 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss: 0.0009502781904302537 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 37.846426248550415
Epoch 7
	 Logging train Loss: 0.0011296521 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss: 0.0007208703318610787 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 37.79521727561951
Epoch 8
	 Logging train Loss: 0.000868755 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss: 0.0005016283830627799 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 37.91679096221924
Epoch 9
	 Logging train Loss: 0.0007283953 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss: 0.0006002357695251703 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 37.67688703536987
	 Logging test loss: 0.0006006024777889252 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
It took  449.7656364440918  seconds.
----- ITERATION 2/2 ------
Number of train simulations: 1600
Number of test simulations: 400
-- Finished Train Dataloader --
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(24, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=24, bias=True)
)
-- Started Training --
Epoch 0
	 Logging train Loss: 4.7239522488 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss: 0.26775822043418884 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 39.25453734397888
Epoch 1
	 Logging train Loss: 0.1055536716 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss: 0.040568020194768906 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 37.9991512298584
Epoch 2
	 Logging train Loss: 0.0219875127 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss: 0.013290850445628166 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 37.77580261230469
Epoch 3
	 Logging train Loss: 0.0084630275 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss: 0.006019433960318565 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 37.666802644729614
Epoch 4
	 Logging train Loss: 0.0042623808 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss: 0.003412883263081312 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 37.73168396949768
Epoch 5
	 Logging train Loss: 0.0025218932 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss: 0.0018465471221134067 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 37.47556519508362
Epoch 6
	 Logging train Loss: 0.0016945526 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss: 0.0011687828227877617 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 37.973095178604126
Epoch 7
	 Logging train Loss: 0.0012382103 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss: 0.0024871984496712685 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 37.92931628227234
Epoch 8
	 Logging train Loss: 0.0009553499 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss: 0.0005635994602926075 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 37.87638759613037
Epoch 9
	 Logging train Loss: 0.0007506182 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss: 0.0006194555899128318 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 37.86439108848572
	 Logging test loss: 0.0006214050808921456 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
It took  444.68526458740234  seconds.
