wandb: Currently logged in as: nreints. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230629_111856-f3bcocjm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vague-mountain-23
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/f3bcocjm
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone █▆▄▃▂▁▇▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone █▆▅▃▂▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone █▆▅▃▂▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone ▆▄▃▂▁▁█▁▁▁
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone ▆▄▃▂▁▁█▁▁▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone 0.0
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone 0.0
wandb:                                  Train loss 2e-05
wandb: 
wandb: 🚀 View run vague-mountain-23 at: https://wandb.ai/nreints/ThesisFinal2/runs/f3bcocjm
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230629_111856-f3bcocjm/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230629_112700-t9ptojun
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run winter-music-40
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/t9ptojun
Training on dataset: data_t(5,20)_r(0,0)_combi_pNone_gNone
Testing on 5 datasets: ['data_t(5,20)_r(0,0)_combi_pNone_gNone', 'data_t(5,20)_r(0,0)_full_pNone_gNone', 'data_t(5,20)_r(0,0)_semi_pNone_gNone', 'data_t(5,20)_r(0,0)_none_pNone_gNone', 'data_t(5,20)_r(0,0)_tennis_pNone_gNone']
Focussing on identity: False
Using extra input: False
Using fr-fr as reference point.
----- ITERATION 1/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 51.31351590156555 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 12.831600189208984 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_full_pNone_gNone took 12.783762693405151 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_semi_pNone_gNone took 12.900842666625977 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_none_pNone_gNone took 12.863966464996338 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_tennis_pNone_gNone took 12.139946222305298 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0171114169 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 9.46734e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 7.87271e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 9.75527e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 7.84519e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 0.0001024775 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 37.24959444999695
Epoch 1/9
	 Logging train Loss: 7.67275e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 6.6467e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 5.87823e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 6.63144e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 5.85545e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 6.9705e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 35.44227695465088
Epoch 2/9
	 Logging train Loss: 5.40692e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 4.6169e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 4.08482e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 4.53901e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 4.08736e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 4.79826e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 35.14278793334961
Epoch 3/9
	 Logging train Loss: 3.46114e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.67475e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.35633e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.57328e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.34078e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 2.75566e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 35.20996594429016
Epoch 4/9
	 Logging train Loss: 1.68426e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.0194e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 8.783e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 9.5873e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 8.7736e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.04787e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 35.40806698799133
Epoch 5/9
	 Logging train Loss: 7.3439e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.241e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.6726e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.1629e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.6785e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 2.4209e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 35.450228214263916
Epoch 6/9
	 Logging train Loss: 1.45239e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 7.69882e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 5.4504e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 0.0001385113 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 5.2566e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 0.0001479265 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 35.46409320831299
Epoch 7/9
	 Logging train Loss: 2.33182e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.2526e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 5.944e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.6391e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 5.774e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.7262e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 35.15472388267517
Epoch 8/9
	 Logging train Loss: 1.12791e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 5.627e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.217e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 6.406e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 3.239e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 6.739e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 35.411093950271606
Epoch 9/9
	 Logging train Loss: 1.6072e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.45e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.54e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 3.187e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.461e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 3.29e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 35.664294958114624
Saved model in  trained_models/gru/data_t(5,20)_r(0,0)_combi_pNone_gNone/'dual_quat_1'_'False'.pth
It took  485.4938311576843  seconds.
----- ITERATION 2/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 44.84173274040222 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 11.722581148147583 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_full_pNone_gNone took 11.222288131713867 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_semi_pNone_gNone took 11.283676624298096 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_none_pNone_gNone took 11.223884105682373 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_tennis_pNone_gNone took 11.202294111251831 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0093150605 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 9.32779e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 8.57636e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 9.78866e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 8.23967e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 0.0001003664 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 35.8383994102478
Epoch 1/9
	 Logging train Loss: 7.03547e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 5.46817e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 5.26052e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone █▅▃▁▁▁▁▁▂▁
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone █▅▃▁▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone █▅▃▁▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone █▅▃▁▁▁▁▁▃▁
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone █▅▃▁▁▁▁▁▃▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone 1e-05
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone 1e-05
wandb:                                  Train loss 2e-05
wandb: 
wandb: 🚀 View run winter-music-40 at: https://wandb.ai/nreints/ThesisFinal2/runs/t9ptojun
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230629_112700-t9ptojun/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230629_113452-fasulgds
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run skilled-gorge-57
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/fasulgds
	 Logging test loss: 5.50218e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 5.06649e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 5.61086e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 35.52249240875244
Epoch 2/9
	 Logging train Loss: 3.90571e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.59944e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.47938e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.63798e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.37828e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 2.71674e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 35.36859917640686
Epoch 3/9
	 Logging train Loss: 1.48252e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 6.5949e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 6.0569e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 6.7843e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 5.8392e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 7.2565e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 36.210822105407715
Epoch 4/9
	 Logging train Loss: 1.01729e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.4234e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 8.654e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.7583e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 8.521e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.8843e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 36.092589139938354
Epoch 5/9
	 Logging train Loss: 1.4531e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.9442e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 5.135e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 3.0961e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 5.09e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 3.2119e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 35.466304302215576
Epoch 6/9
	 Logging train Loss: 2.87749e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 4.885e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.187e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 5.301e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 3.206e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 5.446e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 35.69690752029419
Epoch 7/9
	 Logging train Loss: 1.51926e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.828e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.958e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 3.659e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.924e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 3.793e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 35.40772032737732
Epoch 8/9
	 Logging train Loss: 1.71808e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.57142e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.5833e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.85412e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.5434e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 2.98339e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 35.70771646499634
Epoch 9/9
	 Logging train Loss: 2.26077e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 4.4257e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.499e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 6.9819e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.4495e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 7.2267e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 35.666587352752686
Saved model in  trained_models/gru/data_t(5,20)_r(0,0)_combi_pNone_gNone/'dual_quat_1'_'False'.pth
It took  472.05009055137634  seconds.
----- ITERATION 3/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 45.066240072250366 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 11.23944354057312 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_full_pNone_gNone took 11.180482149124146 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_semi_pNone_gNone took 11.194056034088135 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_none_pNone_gNone took 11.19002652168274 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_tennis_pNone_gNone took 11.207130432128906 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0258148331 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 8.4804e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 7.57268e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 8.93731e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 7.79526e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 9.21872e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 35.369640588760376
Epoch 1/9
	 Logging train Loss: 7.26384e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 6.20501e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 5.96376e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 6.41335e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 6.12926e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 6.64182e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 35.50857329368591
Epoch 2/9
	 Logging train Loss: 5.37169e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 4.40986e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 4.26302e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 4.53427e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 4.35105e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 4.66891e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 35.57120490074158
Epoch 3/9
	 Logging train Loss: 3.50243e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.5193e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.43225e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.62679e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.46972e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 2.68997e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 35.8188202381134
Epoch 4/9
	 Logging train Loss: 1.67515e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 9.6511e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 8.1447e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.12273e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 8.0854e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.11638e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 35.87774586677551
Epoch 5/9
	 Logging train Loss: 1.27198e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.51527e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone █▆▅▃▂▄▁▁▃▁
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone █▇▅▃▂▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone █▆▅▃▂▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone █▆▅▃▂▆▁▁▄▁
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone █▆▅▃▂▆▁▁▄▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone 0.0
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone 0.0
wandb:                                  Train loss 1e-05
wandb: 
wandb: 🚀 View run skilled-gorge-57 at: https://wandb.ai/nreints/ThesisFinal2/runs/fasulgds
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230629_113452-fasulgds/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230629_114243-3cv11rrr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run unique-blaze-73
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/3cv11rrr
	 Logging test loss: 2.9927e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 6.39966e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.9905e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 6.49902e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 35.64577031135559
Epoch 6/9
	 Logging train Loss: 1.36701e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.1986e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 5.556e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.6938e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 5.571e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.7194e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 35.4976270198822
Epoch 7/9
	 Logging train Loss: 1.17294e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 4.019e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.769e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 4.094e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.788e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 4.259e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 35.83098530769348
Epoch 8/9
	 Logging train Loss: 1.45008e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.41366e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.8649e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 4.32681e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.8958e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 4.42861e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 35.742921113967896
Epoch 9/9
	 Logging train Loss: 1.35924e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.326e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.344e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 3.178e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.353e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 3.209e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 35.84555983543396
Saved model in  trained_models/gru/data_t(5,20)_r(0,0)_combi_pNone_gNone/'dual_quat_1'_'False'.pth
It took  470.95271396636963  seconds.
----- ITERATION 4/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 45.588563442230225 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 11.227404594421387 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_full_pNone_gNone took 11.222323417663574 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_semi_pNone_gNone took 11.219980001449585 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_none_pNone_gNone took 11.272347927093506 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_tennis_pNone_gNone took 11.351782083511353 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0198137555 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 6.88253e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 6.60389e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 7.23624e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 6.81114e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 7.31322e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 35.56083416938782
Epoch 1/9
	 Logging train Loss: 5.94976e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 5.08657e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 4.95419e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 5.38215e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 5.10995e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 5.43111e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 35.85324287414551
Epoch 2/9
	 Logging train Loss: 4.20727e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.28219e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.19825e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 3.48928e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 3.28664e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 3.50718e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 35.66363000869751
Epoch 3/9
	 Logging train Loss: 2.31474e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.42835e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.36558e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.54441e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.38751e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.55179e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 36.01807880401611
Epoch 4/9
	 Logging train Loss: 1.0228e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.65885e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 5.2434e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.75023e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 5.3646e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 2.63813e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 35.47376465797424
Epoch 5/9
	 Logging train Loss: 6.2343e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 8.786e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 4.747e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.0845e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 4.726e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.0846e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 35.79654860496521
Epoch 6/9
	 Logging train Loss: 1.04407e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 4.256e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.952e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 3.982e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.967e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 4.003e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 35.591057538986206
Epoch 7/9
	 Logging train Loss: 1.46174e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 0.0002718326 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.79459e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 0.0004860612 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.6884e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 0.0004767926 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 35.57226490974426
Epoch 8/9
	 Logging train Loss: 9.7612e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 4.307e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.156e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 4.094e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 3.131e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 4.134e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 35.65884613990784
Epoch 9/9
	 Logging train Loss: 1.03403e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone ▃▂▂▁▁▁▁█▁▁
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone █▆▄▂▂▁▁▄▁▁
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone █▆▄▂▂▁▁▄▁▁
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone ▂▂▁▁▁▁▁█▁▁
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone ▂▂▂▁▁▁▁█▁▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone 1e-05
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone 1e-05
wandb:                                  Train loss 1e-05
wandb: 
wandb: 🚀 View run unique-blaze-73 at: https://wandb.ai/nreints/ThesisFinal2/runs/3cv11rrr
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230629_114243-3cv11rrr/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230629_115035-6v96cxy9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run iconic-snowflake-89
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/6v96cxy9
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone ▅▄▃▂▇▁▁▁█▁
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone █▆▄▂▂▁▁▁▃▁
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone █▆▄▂▂▁▁▁▃▁
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone ▃▃▂▁▇▁▁▁█▁
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone ▄▃▂▁▇▁▁▁█▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone 0.0
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone 0.0
wandb:                                  Train loss 1e-05
wandb: 
wandb: 🚀 View run iconic-snowflake-89 at: https://wandb.ai/nreints/ThesisFinal2/runs/6v96cxy9
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230629_115035-6v96cxy9/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230629_115827-bpj2llf7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run toasty-lion-106
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/bpj2llf7
	 Logging test loss: 3.5707e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.3872e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 5.4279e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.3804e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 5.3547e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 35.965222120285034
Saved model in  trained_models/gru/data_t(5,20)_r(0,0)_combi_pNone_gNone/'dual_quat_1'_'False'.pth
It took  471.9516546726227  seconds.
----- ITERATION 5/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 45.39569616317749 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 11.207930564880371 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_full_pNone_gNone took 11.237181425094604 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_semi_pNone_gNone took 11.21267056465149 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_none_pNone_gNone took 11.21468710899353 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_tennis_pNone_gNone took 11.433542013168335 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0162446126 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 6.86612e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 6.36505e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 6.93219e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 6.24067e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 7.34191e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 35.630287885665894
Epoch 1/9
	 Logging train Loss: 5.84693e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 4.90952e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 4.60006e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 4.97479e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 4.47992e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 5.25523e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 35.615580558776855
Epoch 2/9
	 Logging train Loss: 3.84706e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.83431e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.61248e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.92975e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.52376e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 3.10075e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 35.6921763420105
Epoch 3/9
	 Logging train Loss: 1.84027e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 9.6878e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 8.3624e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.04458e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 8.1701e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.12779e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 35.48438858985901
Epoch 4/9
	 Logging train Loss: 8.3758e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 8.85606e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.00939e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 0.0001575459 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 9.4692e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 0.0001648585 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 35.42912220954895
Epoch 5/9
	 Logging train Loss: 1.22828e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 6.051e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.745e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 6.692e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 3.617e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 7.092e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 35.71430945396423
Epoch 6/9
	 Logging train Loss: 1.24313e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 4.415e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.985e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 4.304e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.936e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 4.577e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 35.93680500984192
Epoch 7/9
	 Logging train Loss: 1.26016e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.848e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.686e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 3.589e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.664e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 3.853e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 35.77863430976868
Epoch 8/9
	 Logging train Loss: 1.01824e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 0.0001124055 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.57487e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 0.0001987053 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.55023e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 0.0001964231 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 35.868239879608154
Epoch 9/9
	 Logging train Loss: 1.14525e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.4984e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 4.369e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.2967e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 4.208e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 2.2897e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 35.84477615356445
Saved model in  trained_models/gru/data_t(5,20)_r(0,0)_combi_pNone_gNone/'dual_quat_1'_'False'.pth
It took  472.17181038856506  seconds.
----- ITERATION 6/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 45.85248112678528 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 11.219435214996338 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_full_pNone_gNone took 11.302307367324829 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_semi_pNone_gNone took 11.276637554168701 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_none_pNone_gNone took 11.21455454826355 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_tennis_pNone_gNone took 11.756462574005127 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0467215478 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 8.33829e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 7.30403e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 8.42244e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 7.63024e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 8.73082e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 35.809802293777466
Epoch 1/9
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone █▇▆▄▂▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone █▇▆▄▂▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone █▇▆▄▂▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone █▇▅▄▂▁▁▁▁▁
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone █▇▆▄▂▁▁▁▁▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone 0.0
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone 0.0
wandb:                                  Train loss 1e-05
wandb: 
wandb: 🚀 View run toasty-lion-106 at: https://wandb.ai/nreints/ThesisFinal2/runs/bpj2llf7
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230629_115827-bpj2llf7/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230629_120628-def33nhc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fanciful-wildflower-120
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/def33nhc
	 Logging train Loss: 7.44875e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 6.93666e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 6.33263e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 6.89567e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 6.60245e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 7.16682e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 35.66394758224487
Epoch 2/9
	 Logging train Loss: 6.09873e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 5.41292e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 5.03871e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 5.40256e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 5.22051e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 5.65637e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 36.417900800704956
Epoch 3/9
	 Logging train Loss: 4.4181e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.47668e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.24429e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 3.48785e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 3.34813e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 3.64119e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 36.05055618286133
Epoch 4/9
	 Logging train Loss: 2.34925e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.30195e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.19325e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.34145e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.23946e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.37866e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 35.56776976585388
Epoch 5/9
	 Logging train Loss: 6.0807e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.9947e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.6362e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.1896e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.7145e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 2.2348e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 35.62875556945801
Epoch 6/9
	 Logging train Loss: 8.0384e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 8.188e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 6.585e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 8.916e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 6.837e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 9.165e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 35.788695096969604
Epoch 7/9
	 Logging train Loss: 1.63246e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 5.919e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 5.052e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 6.002e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 5.19e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 6.22e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 35.51901960372925
Epoch 8/9
	 Logging train Loss: 1.0992e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 4.971e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 4.161e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 5.002e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 4.219e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 5.225e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 35.697057485580444
Epoch 9/9
	 Logging train Loss: 1.31801e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 5.109e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 4.401e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 5e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 4.529e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 5.087e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 35.670042514801025
Saved model in  trained_models/gru/data_t(5,20)_r(0,0)_combi_pNone_gNone/'dual_quat_1'_'False'.pth
It took  480.1562342643738  seconds.
----- ITERATION 7/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 46.217711210250854 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 11.2165367603302 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_full_pNone_gNone took 11.24543571472168 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_semi_pNone_gNone took 11.2474844455719 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_none_pNone_gNone took 11.32112193107605 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_tennis_pNone_gNone took 11.7913978099823 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0233923402 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 7.68093e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 6.72118e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 8.27424e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 6.92336e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 8.30966e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 35.65695118904114
Epoch 1/9
	 Logging train Loss: 6.46694e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 5.64101e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 5.27962e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 5.80698e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 5.4348e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 5.85687e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 35.90216016769409
Epoch 2/9
	 Logging train Loss: 4.59836e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.67386e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.43386e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 3.76941e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 3.54234e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 3.83507e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 35.540748834609985
Epoch 3/9
	 Logging train Loss: 2.62891e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.69909e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.57452e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.75467e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.62098e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.79413e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 35.68942904472351
Epoch 4/9
	 Logging train Loss: 9.3044e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.7781e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.2942e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 3.9628e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 3.3904e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 4.0874e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone █▆▄▃▁▁▁▁▁▃
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone █▆▅▃▁▁▁▁▁▂
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone █▆▅▃▁▁▁▁▁▂
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone █▆▄▂▁▁▁▁▁▄
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone █▆▄▂▁▁▁▁▁▄
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone 2e-05
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone 1e-05
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone 1e-05
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone 3e-05
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone 3e-05
wandb:                                  Train loss 1e-05
wandb: 
wandb: 🚀 View run fanciful-wildflower-120 at: https://wandb.ai/nreints/ThesisFinal2/runs/def33nhc
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230629_120628-def33nhc/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230629_121421-pw2im8w2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run jumping-fire-138
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/pw2im8w2
		--> Epoch time; 35.48803901672363
Epoch 5/9
	 Logging train Loss: 1.10061e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 6.345e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 4.303e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 6.758e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 4.396e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 6.836e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 35.728841066360474
Epoch 6/9
	 Logging train Loss: 6.5361e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 4.011e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.471e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 4.146e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.487e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 4.099e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 35.696327924728394
Epoch 7/9
	 Logging train Loss: 1.4477e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.635e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.499e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 3.403e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.522e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 3.366e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 35.942495346069336
Epoch 8/9
	 Logging train Loss: 1.63939e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.292e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.327e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.922e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.336e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 2.931e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 35.61744141578674
Epoch 9/9
	 Logging train Loss: 1.13967e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.20253e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 8.2763e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 3.127e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 8.2011e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 3.21614e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 35.64299297332764
Saved model in  trained_models/gru/data_t(5,20)_r(0,0)_combi_pNone_gNone/'dual_quat_1'_'False'.pth
It took  472.96350622177124  seconds.
----- ITERATION 8/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 46.180504322052 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 11.231154680252075 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_full_pNone_gNone took 11.256415367126465 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_semi_pNone_gNone took 11.23570203781128 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_none_pNone_gNone took 11.231916904449463 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_tennis_pNone_gNone took 11.547401189804077 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0094096903 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 7.67559e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 7.07782e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 8.06732e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 7.15312e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 8.08406e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 35.47176504135132
Epoch 1/9
	 Logging train Loss: 6.21585e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 5.04805e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 4.66812e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 5.20395e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 4.74302e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 5.2564e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 35.95216417312622
Epoch 2/9
	 Logging train Loss: 3.67341e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.62176e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.36477e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.69742e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.41411e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 2.76508e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 35.845009565353394
Epoch 3/9
	 Logging train Loss: 1.54338e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 8.327e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 6.8359e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 8.5955e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 7.1459e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 8.9611e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 36.11594319343567
Epoch 4/9
	 Logging train Loss: 4.0641e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.6866e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.0571e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.8652e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.0708e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 2.041e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 35.55448889732361
Epoch 5/9
	 Logging train Loss: 1.37499e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.74866e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 5.0063e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 4.21746e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 4.9126e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 4.71604e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 35.95234799385071
Epoch 6/9
	 Logging train Loss: 1.43035e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.1464e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 8.498e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.9403e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 8.635e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 3.1069e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 35.79387879371643
Epoch 7/9
	 Logging train Loss: 1.28828e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 7.1956e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.0085e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.06502e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 1.9692e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.12793e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 35.824628829956055
Epoch 8/9
	 Logging train Loss: 1.20092e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 4.002e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.661e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 4.061e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.652e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone █▆▃▂▁▃▁▂▁▁
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone █▆▃▂▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone █▆▃▂▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone █▆▃▂▁▅▁▂▁▁
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone █▆▃▂▁▅▁▂▁▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone 0.0
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone 0.0
wandb:                                  Train loss 1e-05
wandb: 
wandb: 🚀 View run jumping-fire-138 at: https://wandb.ai/nreints/ThesisFinal2/runs/pw2im8w2
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230629_121421-pw2im8w2/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230629_122221-4qfbw5ej
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run expert-sea-152
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/4qfbw5ej
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone █▆▅▃▂▁▂▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone █▇▅▃▂▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone █▇▅▃▂▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone █▆▅▃▂▁▂▁▁▁
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone █▆▅▃▂▁▃▁▁▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone 0.0
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone 0.0
wandb:                                  Train loss 1e-05
wandb: 
wandb: 🚀 View run expert-sea-152 at: https://wandb.ai/nreints/ThesisFinal2/runs/4qfbw5ej
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230629_122221-4qfbw5ej/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230629_123024-864pdfgf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run colorful-serenity-167
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/864pdfgf
	 Logging test loss: 4.235e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 36.019562005996704
Epoch 9/9
	 Logging train Loss: 1.34414e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.638e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.783e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 3.301e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.789e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 3.377e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 35.54930400848389
Saved model in  trained_models/gru/data_t(5,20)_r(0,0)_combi_pNone_gNone/'dual_quat_1'_'False'.pth
It took  480.04559087753296  seconds.
----- ITERATION 9/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 46.074098110198975 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 11.260500431060791 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_full_pNone_gNone took 11.27141785621643 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_semi_pNone_gNone took 11.253621816635132 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_none_pNone_gNone took 11.237939596176147 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_tennis_pNone_gNone took 11.529343366622925 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0315615125 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 8.103e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 7.46486e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 8.29948e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 7.27494e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 8.2912e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 35.8191192150116
Epoch 1/9
	 Logging train Loss: 6.95757e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 6.10688e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 5.87797e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 6.25064e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 5.73543e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 6.20963e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 35.87126278877258
Epoch 2/9
	 Logging train Loss: 5.12151e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 4.2327e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 4.11118e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 4.28698e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 3.98936e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 4.24618e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 35.81576371192932
Epoch 3/9
	 Logging train Loss: 3.18076e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.17894e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.15949e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.25394e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.1104e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 2.22847e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 35.59117770195007
Epoch 4/9
	 Logging train Loss: 1.35161e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 6.4582e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 6.2973e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 6.7751e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 6.1331e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 6.6772e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 35.57616925239563
Epoch 5/9
	 Logging train Loss: 3.8807e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.1496e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 9.675e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.2362e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 9.337e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.2329e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 35.81200814247131
Epoch 6/9
	 Logging train Loss: 7.864e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 9.7703e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.0022e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.74453e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 9.598e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.96705e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 35.76247453689575
Epoch 7/9
	 Logging train Loss: 1.56132e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 4.577e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.952e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 4.785e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.869e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 5.07e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 35.89508819580078
Epoch 8/9
	 Logging train Loss: 1.53522e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 6.016e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.971e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 6.713e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 4.002e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 7.174e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 35.86779236793518
Epoch 9/9
	 Logging train Loss: 9.7028e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.101e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.192e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.721e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.174e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 2.819e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 36.00287580490112
Saved model in  trained_models/gru/data_t(5,20)_r(0,0)_combi_pNone_gNone/'dual_quat_1'_'False'.pth
It took  482.9564025402069  seconds.
----- ITERATION 10/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 46.011836528778076 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gNone took 11.230645418167114 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_full_pNone_gNone took 11.253462076187134 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_semi_pNone_gNone took 11.231991529464722 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_none_pNone_gNone took 11.341217994689941 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_tennis_pNone_gNone took 11.509273290634155 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0577303506 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 9.58901e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 7.81629e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 9.07053e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 7.51201e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone █▆▅▄▃▂▂▁▃▁
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone █▇▆▅▃▂▂▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone █▇▆▅▃▂▂▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone █▇▆▄▃▂▂▁▅▁
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone █▇▆▄▃▂▂▁▅▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_none_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gNone 0.0
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gNone 0.0
wandb:                                  Train loss 1e-05
wandb: 
wandb: 🚀 View run colorful-serenity-167 at: https://wandb.ai/nreints/ThesisFinal2/runs/864pdfgf
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230629_123024-864pdfgf/logs
	 Logging test loss: 9.18553e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 35.636409521102905
Epoch 1/9
	 Logging train Loss: 8.11343e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 7.47017e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 7.0078e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 7.41133e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 6.71721e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 7.52833e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 35.88447189331055
Epoch 2/9
	 Logging train Loss: 6.57992e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 6.01728e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 5.85012e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 6.13249e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 5.63932e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 6.1659e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 36.4875328540802
Epoch 3/9
	 Logging train Loss: 5.16772e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 4.42885e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 4.31854e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 4.53328e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 4.16719e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 4.56491e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 35.46941924095154
Epoch 4/9
	 Logging train Loss: 3.45628e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.59155e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.48718e-05 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 2.68227e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.41595e-05 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 2.68451e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 35.50976204872131
Epoch 5/9
	 Logging train Loss: 1.63858e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 8.7134e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 8.0726e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 9.2258e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 7.9171e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 9.1959e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 35.60812711715698
Epoch 6/9
	 Logging train Loss: 4.5705e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 1.30612e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 6.8397e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 1.82774e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 6.8028e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 1.88829e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 35.884082078933716
Epoch 7/9
	 Logging train Loss: 8.397e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 4.268e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.768e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 4.478e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.738e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 4.484e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 35.43724060058594
Epoch 8/9
	 Logging train Loss: 9.6247e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.95946e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 3.2363e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 5.32869e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 3.1814e-06 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 5.6173e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 35.64271593093872
Epoch 9/9
	 Logging train Loss: 1.25889e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 4.148e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gNone]
	 Logging test loss: 2.519e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gNone]
	 Logging test loss: 4.39e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gNone]
	 Logging test loss: 2.479e-07 [MSELoss(): t(5,20)_r(0,0)_none_pNone_gNone]
	 Logging test loss: 4.451e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gNone]
		--> Epoch time; 35.57509660720825
Saved model in  trained_models/gru/data_t(5,20)_r(0,0)_combi_pNone_gNone/'dual_quat_1'_'False'.pth
It took  473.09700655937195  seconds.

JOB STATISTICS
==============
Job ID: 2986686
Array Job ID: 2986645_5
Cluster: snellius
User/Group: nreints/nreints
State: RUNNING
Nodes: 1
Cores per node: 18
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 23:54:00 core-walltime
Job Wall-clock time: 01:19:40
Memory Utilized: 0.00 MB (estimated maximum)
Memory Efficiency: 0.00% of 0.00 MB (0.00 MB/node)
WARNING: Efficiency statistics may be misleading for RUNNING jobs.
