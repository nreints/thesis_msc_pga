wandb: Currently logged in as: nreints. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home/nreints/.netrc
/gpfs/home2/nreints/MScThesis/code/fcnn.py:566: DeprecationWarning: Sampling from a set deprecated
since Python 3.9 and will be removed in a subsequent version.
  train_sims = set(random.sample(sims_train, int(0.8 * n_sims_train)))
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230330_123650-na4tj2zj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run worthy-tree-565
wandb: â­ï¸ View project at https://wandb.ai/nreints/test
wandb: ðŸš€ View run at https://wandb.ai/nreints/test/runs/na4tj2zj
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.029 MB of 0.029 MB uploaded (0.000 MB deduped)wandb: \ 0.029 MB of 0.078 MB uploaded (0.000 MB deduped)wandb: | 0.078 MB of 0.078 MB uploaded (0.000 MB deduped)wandb: / 0.078 MB of 0.078 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  Test loss t(5, 20)_r(0, 0)_tennis L1Loss() â–‡â–…â–…â–ˆâ–†â–„â–†â–‚â–‚â–…â–…â–â–â–‚â–â–‚â–„â–ƒâ–‚â–â–
wandb: Test loss t(5, 20)_r(0, 0)_tennis MSELoss() â–†â–ƒâ–„â–ˆâ–†â–‚â–…â–â–â–…â–…â–â–â–‚â–â–â–ƒâ–‚â–â–â–
wandb:     Train loss data_t(5, 20)_r(0, 0)_tennis â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:  Test loss t(5, 20)_r(0, 0)_tennis L1Loss() 0.0424
wandb: Test loss t(5, 20)_r(0, 0)_tennis MSELoss() 0.00332
wandb:     Train loss data_t(5, 20)_r(0, 0)_tennis 0.01147
wandb: 
wandb: ðŸš€ View run worthy-tree-565 at: https://wandb.ai/nreints/test/runs/na4tj2zj
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230330_123650-na4tj2zj/logs
/gpfs/home2/nreints/MScThesis/code/fcnn.py:566: DeprecationWarning: Sampling from a set deprecated
since Python 3.9 and will be removed in a subsequent version.
  train_sims = set(random.sample(sims_train, int(0.8 * n_sims_train)))
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230330_124832-53k1x7q7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wobbly-wood-626
wandb: â­ï¸ View project at https://wandb.ai/nreints/test
wandb: ðŸš€ View run at https://wandb.ai/nreints/test/runs/53k1x7q7
Training on dataset: data/data_t(5, 20)_r(0, 0)_tennis_pNone_gNone
Testing on datasets: ['data_t(5, 20)_r(0, 0)_tennis_pNone_gNone']
----- ITERATION 1/2 ------
Number of train simulations: 1600
Number of test simulations: 400
The dataloader took 60.01465845108032 seconds.
-- Finished Train Dataloader --
The dataloader took 15.070131301879883 seconds.
-- Finished Test Dataloader(s) --
Datatype: dual_quat
--- Started Training ---
Epoch 0
	 Logging train Loss: 12.0049338746 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.05884111672639847 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.18341976404190063 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 29.358347177505493
Epoch 1
	 Logging train Loss: 0.0381367877 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.02813688851892948 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.12944214046001434 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 31.43930459022522
Epoch 2
	 Logging train Loss: 0.0246182086 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.03415816277265549 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.14049161970615387 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 31.128746032714844
Epoch 3
	 Logging train Loss: 0.0203792722 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.07453063130378723 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.2011529505252838 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 31.16450309753418
Epoch 4
	 Logging train Loss: 0.0183970221 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.050913821905851364 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.16662205755710602 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 31.37572693824768
Epoch 5
	 Logging train Loss: 0.0174734789 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.0171606857329607 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.09969201683998108 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 30.949405431747437
Epoch 6
	 Logging train Loss: 0.0174313177 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.04357323423027992 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.1494743674993515 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 31.363940238952637
Epoch 7
	 Logging train Loss: 0.0156064576 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.007813417352735996 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.06744173914194107 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 31.16790533065796
Epoch 8
	 Logging train Loss: 0.0150088528 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.0065085142850875854 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.06158267334103584 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 31.49956226348877
Epoch 9
	 Logging train Loss: 0.0150419472 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.04072063788771629 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.14387547969818115 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 31.82501792907715
Epoch 10
	 Logging train Loss: 0.0140440237 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.04165342450141907 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.14332245290279388 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 30.78124237060547
Epoch 11
	 Logging train Loss: 0.0138310501 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.0048566171899437904 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.053013455122709274 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 30.957516193389893
Epoch 12
	 Logging train Loss: 0.0134210387 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.0038722159806638956 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.04684334620833397 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 29.338818788528442
Epoch 13
	 Logging train Loss: 0.0129724079 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.009466063231229782 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.07016564905643463 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 29.91345500946045
Epoch 14
	 Logging train Loss: 0.013366506 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.004052550531923771 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.04761147499084473 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 29.7003071308136
Epoch 15
	 Logging train Loss: 0.0122866462 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.0064272526651620865 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.05961131677031517 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 29.051785230636597
Epoch 16
	 Logging train Loss: 0.011562871 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.020531749352812767 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.10287535190582275 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 31.179731607437134
Epoch 17
	 Logging train Loss: 0.0114332448 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.014746378175914288 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.08381271362304688 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 29.621087551116943
Epoch 18
	 Logging train Loss: 0.0110830157 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.007118469104170799 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.05935470387339592 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 29.779438972473145
Epoch 19
	 Logging train Loss: 0.011466419 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.0033197421580553055 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.04239882528781891 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 29.969780683517456
	 Logging test loss 0.003320099087432027 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.04239851236343384 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
It took 701.9120965003967 seconds to train & eval the model.
----- ITERATION 2/2 ------
Number of train simulations: 1600
Number of test simulations: 400
The dataloader took 55.30743479728699 seconds.
-- Finished Train Dataloader --
The dataloader took 13.8272545337677 seconds.
-- Finished Test Dataloader(s) --
Datatype: dual_quat
--- Started Training ---
Epoch 0
	 Logging train Loss: 16.1598166871 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.08659720420837402 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.22491495311260223 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 31.550739526748657
Epoch 1
	 Logging train Loss: 0.0469183928 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.029184792190790176 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.13165515661239624 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 29.588375329971313
Epoch 2
	 Logging train Loss: 0.0229174795 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.016410859301686287 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.09953773021697998 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:  Test loss t(5, 20)_r(0, 0)_tennis L1Loss() â–ˆâ–„â–ƒâ–ƒâ–ƒâ–‚â–ƒâ–‚â–‚â–‚â–‚â–ƒâ–â–‚â–â–‚â–â–â–‚â–‚â–‚
wandb: Test loss t(5, 20)_r(0, 0)_tennis MSELoss() â–ˆâ–ƒâ–‚â–‚â–‚â–â–‚â–‚â–â–â–â–‚â–â–â–â–‚â–â–â–â–â–
wandb:     Train loss data_t(5, 20)_r(0, 0)_tennis â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:  Test loss t(5, 20)_r(0, 0)_tennis L1Loss() 0.06078
wandb: Test loss t(5, 20)_r(0, 0)_tennis MSELoss() 0.0067
wandb:     Train loss data_t(5, 20)_r(0, 0)_tennis 0.00999
wandb: 
wandb: ðŸš€ View run wobbly-wood-626 at: https://wandb.ai/nreints/test/runs/53k1x7q7
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230330_124832-53k1x7q7/logs
     --> Epoch time; 29.492892026901245
Epoch 3
	 Logging train Loss: 0.0193323023 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.01482449471950531 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.09275217354297638 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 29.256756067276
Epoch 4
	 Logging train Loss: 0.018811939 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.01617676205933094 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.09669505804777145 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 31.106987953186035
Epoch 5
	 Logging train Loss: 0.0181762583 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.009124512784183025 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.07328477501869202 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 30.801694631576538
Epoch 6
	 Logging train Loss: 0.0165122363 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.01933411881327629 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.1014057919383049 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 31.589115381240845
Epoch 7
	 Logging train Loss: 0.0160311281 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.00979364849627018 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.07410143315792084 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 30.042879819869995
Epoch 8
	 Logging train Loss: 0.01506361 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.005622835364192724 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.05735303834080696 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 29.508066654205322
Epoch 9
	 Logging train Loss: 0.0137650795 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.0055426936596632 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.05622941628098488 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 29.850943088531494
Epoch 10
	 Logging train Loss: 0.0136641995 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.00917793158441782 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.06973907351493835 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 29.3562753200531
Epoch 11
	 Logging train Loss: 0.0129570394 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.013810490258038044 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.08741916716098785 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 31.226062297821045
Epoch 12
	 Logging train Loss: 0.0126893336 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.005016664508730173 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.052912142127752304 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 29.735568284988403
Epoch 13
	 Logging train Loss: 0.0121871861 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.006367121357470751 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.05923852697014809 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 29.834115266799927
Epoch 14
	 Logging train Loss: 0.0121021645 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.004112863447517157 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.048200588673353195 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 29.770705699920654
Epoch 15
	 Logging train Loss: 0.0109831567 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.011862041428685188 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.07617606967687607 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 29.57755208015442
Epoch 16
	 Logging train Loss: 0.0114695443 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.0038919062353670597 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.047083694487810135 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 31.52732539176941
Epoch 17
	 Logging train Loss: 0.0106477127 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.003274755785241723 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.043206002563238144 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 31.174612998962402
Epoch 18
	 Logging train Loss: 0.0104689168 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.006633711978793144 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.06057708337903023 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 31.078083992004395
Epoch 19
	 Logging train Loss: 0.0099930346 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.006698321551084518 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.06078382581472397 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 29.49023151397705
	 Logging test loss 0.0066986726596951485 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.06078323349356651 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
It took 689.753347158432 seconds to train & eval the model.

JOB STATISTICS
==============
Job ID: 2523394
Array Job ID: 2523368_26
Cluster: snellius
User/Group: nreints/nreints
State: COMPLETED (exit code 0)
Nodes: 1
Cores per node: 18
CPU Utilized: 03:44:38
CPU Efficiency: 53.18% of 07:02:24 core-walltime
Job Wall-clock time: 00:23:28
Memory Utilized: 3.63 GB
Memory Efficiency: 12.39% of 29.30 GB
