wandb: Currently logged in as: nreints. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230329_124733-96ilo7ne
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run expert-hill-479
wandb: â­ï¸ View project at https://wandb.ai/nreints/test
wandb: ðŸš€ View run at https://wandb.ai/nreints/test/runs/96ilo7ne
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                                  Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb: Test loss t(0, 0)_r(5, 20)_full_pNone_gNone, MSELoss() â–ˆâ–†â–„â–ƒâ–‚â–‚â–‚â–â–â–â–
wandb:                                             Train loss â–ˆâ–‚â–‚â–‚â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                                  Epoch 9
wandb: Test loss t(0, 0)_r(5, 20)_full_pNone_gNone, MSELoss() 0.16232
wandb:                                             Train loss 0.17594
wandb: 
wandb: ðŸš€ View run expert-hill-479 at: https://wandb.ai/nreints/test/runs/96ilo7ne
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230329_124733-96ilo7ne/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230329_125700-mdao9x74
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run devoted-star-501
wandb: â­ï¸ View project at https://wandb.ai/nreints/test
wandb: ðŸš€ View run at https://wandb.ai/nreints/test/runs/mdao9x74
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                                  Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb: Test loss t(0, 0)_r(5, 20)_full_pNone_gNone, MSELoss() â–ˆâ–†â–„â–ƒâ–‚â–‚â–â–â–â–â–
wandb:                                             Train loss â–ˆâ–‚â–‚â–‚â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                                  Epoch 9
wandb: Test loss t(0, 0)_r(5, 20)_full_pNone_gNone, MSELoss() 0.2
wandb:                                             Train loss 0.18482
wandb: 
wandb: ðŸš€ View run devoted-star-501 at: https://wandb.ai/nreints/test/runs/mdao9x74
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230329_125700-mdao9x74/logs
Running for data type: log_dualQ
----- ITERATION 1/2 ------
Number of train simulations: 1600
Number of test simulations: 400
-- Finished Train Dataloader --
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(6, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=6, bias=True)
)
-- Started Training --
Epoch 0
	 Logging train Loss: 4.0232487718 (MSELoss(): data_t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss: 0.9343869686126709 (MSELoss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
     --> Epoch time; 54.036381244659424
Epoch 1
	 Logging train Loss: 0.7977523091 (MSELoss(): data_t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss: 0.6892682313919067 (MSELoss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
     --> Epoch time; 52.76059126853943
Epoch 2
	 Logging train Loss: 0.6327009418 (MSELoss(): data_t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss: 0.5452304482460022 (MSELoss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
     --> Epoch time; 48.42893362045288
Epoch 3
	 Logging train Loss: 0.4639527915 (MSELoss(): data_t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss: 0.36848482489585876 (MSELoss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
     --> Epoch time; 48.904791831970215
Epoch 4
	 Logging train Loss: 0.3356932371 (MSELoss(): data_t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss: 0.2926112711429596 (MSELoss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
     --> Epoch time; 48.91216421127319
Epoch 5
	 Logging train Loss: 0.2861993685 (MSELoss(): data_t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss: 0.26205936074256897 (MSELoss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
     --> Epoch time; 49.15633773803711
Epoch 6
	 Logging train Loss: 0.2544509623 (MSELoss(): data_t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss: 0.2322312593460083 (MSELoss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
     --> Epoch time; 48.971293926239014
Epoch 7
	 Logging train Loss: 0.2255657486 (MSELoss(): data_t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss: 0.20648576319217682 (MSELoss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
     --> Epoch time; 49.126972675323486
Epoch 8
	 Logging train Loss: 0.2044498051 (MSELoss(): data_t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss: 0.18006733059883118 (MSELoss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
     --> Epoch time; 48.487679958343506
Epoch 9
	 Logging train Loss: 0.1759441055 (MSELoss(): data_t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss: 0.16236060857772827 (MSELoss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
     --> Epoch time; 48.96100044250488
	 Logging test loss: 0.1623193323612213 (MSELoss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
It took  568.6493451595306  seconds.
----- ITERATION 2/2 ------
Number of train simulations: 1600
Number of test simulations: 400
-- Finished Train Dataloader --
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(6, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=6, bias=True)
)
-- Started Training --
Epoch 0
	 Logging train Loss: 4.0079256065 (MSELoss(): data_t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss: 1.0477914810180664 (MSELoss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
     --> Epoch time; 49.22313380241394
Epoch 1
	 Logging train Loss: 0.7916525419 (MSELoss(): data_t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss: 0.768491804599762 (MSELoss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
     --> Epoch time; 49.471545696258545
Epoch 2
	 Logging train Loss: 0.6390181212 (MSELoss(): data_t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss: 0.6226176619529724 (MSELoss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
     --> Epoch time; 48.993396043777466
Epoch 3
	 Logging train Loss: 0.4859013271 (MSELoss(): data_t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss: 0.439550518989563 (MSELoss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
     --> Epoch time; 49.36720609664917
Epoch 4
	 Logging train Loss: 0.3429735741 (MSELoss(): data_t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss: 0.33468297123908997 (MSELoss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
     --> Epoch time; 49.09723162651062
Epoch 5
	 Logging train Loss: 0.2793481111 (MSELoss(): data_t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss: 0.28570398688316345 (MSELoss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
     --> Epoch time; 49.69028830528259
Epoch 6
	 Logging train Loss: 0.2466048481 (MSELoss(): data_t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss: 0.2586010694503784 (MSELoss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
     --> Epoch time; 51.680158615112305
Epoch 7
	 Logging train Loss: 0.2219357662 (MSELoss(): data_t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss: 0.2317676693201065 (MSELoss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
     --> Epoch time; 51.16457986831665
Epoch 8
	 Logging train Loss: 0.201790681 (MSELoss(): data_t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss: 0.21535207331180573 (MSELoss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
     --> Epoch time; 51.500789403915405
Epoch 9
	 Logging train Loss: 0.1848233965 (MSELoss(): data_t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss: 0.20026935636997223 (MSELoss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
     --> Epoch time; 48.49093675613403
	 Logging test loss: 0.19999901950359344 (MSELoss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
It took  562.1871840953827  seconds.

JOB STATISTICS
==============
Job ID: 2514685
Array Job ID: 2514679_6
Cluster: snellius
User/Group: nreints/nreints
State: COMPLETED (exit code 0)
Nodes: 1
Cores per node: 18
CPU Utilized: 04:01:02
CPU Efficiency: 69.80% of 05:45:18 core-walltime
Job Wall-clock time: 00:19:11
Memory Utilized: 24.67 GB
Memory Efficiency: 78.93% of 31.25 GB
