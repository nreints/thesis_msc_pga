wandb: Currently logged in as: nreints. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home/nreints/.netrc
/gpfs/home2/nreints/MScThesis/code/fcnn.py:566: DeprecationWarning: Sampling from a set deprecated
since Python 3.9 and will be removed in a subsequent version.
  train_sims = set(random.sample(sims_train, int(0.8 * n_sims_train)))
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230330_123650-qaoh0i0x
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lunar-leaf-590
wandb: ⭐️ View project at https://wandb.ai/nreints/test
wandb: 🚀 View run at https://wandb.ai/nreints/test/runs/qaoh0i0x
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.029 MB of 0.029 MB uploaded (0.000 MB deduped)wandb: \ 0.029 MB of 0.079 MB uploaded (0.000 MB deduped)wandb: | 0.029 MB of 0.079 MB uploaded (0.000 MB deduped)wandb: / 0.029 MB of 0.079 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  Test loss t(0, 0)_r(5, 20)_full L1Loss() █▆▄▃▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁
wandb: Test loss t(0, 0)_r(5, 20)_full MSELoss() █▄▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     Train loss data_t(0, 0)_r(5, 20)_full █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:  Test loss t(0, 0)_r(5, 20)_full L1Loss() 0.00563
wandb: Test loss t(0, 0)_r(5, 20)_full MSELoss() 7e-05
wandb:     Train loss data_t(0, 0)_r(5, 20)_full 6e-05
wandb: 
wandb: 🚀 View run lunar-leaf-590 at: https://wandb.ai/nreints/test/runs/qaoh0i0x
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230330_123650-qaoh0i0x/logs
/gpfs/home2/nreints/MScThesis/code/fcnn.py:566: DeprecationWarning: Sampling from a set deprecated
since Python 3.9 and will be removed in a subsequent version.
  train_sims = set(random.sample(sims_train, int(0.8 * n_sims_train)))
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230330_124717-3zj4z66x
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sage-resonance-606
wandb: ⭐️ View project at https://wandb.ai/nreints/test
wandb: 🚀 View run at https://wandb.ai/nreints/test/runs/3zj4z66x
Training on dataset: data/data_t(0, 0)_r(5, 20)_full_pNone_gNone
Testing on datasets: ['data_t(0, 0)_r(5, 20)_full_pNone_gNone']
----- ITERATION 1/2 ------
Number of train simulations: 1600
Number of test simulations: 400
The dataloader took 60.08583855628967 seconds.
-- Finished Train Dataloader --
The dataloader took 15.301710844039917 seconds.
-- Finished Test Dataloader(s) --
Datatype: pos_diff_start
--- Started Training ---
Epoch 0
	 Logging train Loss: 0.6515904645 (MSELoss(): data_t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 0.02015361189842224 (MSELoss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 0.10089141875505447 (L1Loss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
     --> Epoch time; 27.616055965423584
Epoch 1
	 Logging train Loss: 0.0120254118 (MSELoss(): data_t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 0.008953718468546867 (MSELoss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 0.06747259944677353 (L1Loss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
     --> Epoch time; 27.259099006652832
Epoch 2
	 Logging train Loss: 0.0055916612 (MSELoss(): data_t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 0.004514126572757959 (MSELoss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 0.04756760597229004 (L1Loss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
     --> Epoch time; 27.569697380065918
Epoch 3
	 Logging train Loss: 0.0029928067 (MSELoss(): data_t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 0.002831837860867381 (MSELoss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 0.03716907277703285 (L1Loss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
     --> Epoch time; 27.529662609100342
Epoch 4
	 Logging train Loss: 0.0019165514 (MSELoss(): data_t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 0.0019054287113249302 (MSELoss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 0.029740789905190468 (L1Loss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
     --> Epoch time; 27.17272138595581
Epoch 5
	 Logging train Loss: 0.001329987 (MSELoss(): data_t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 0.0014483757549896836 (MSELoss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 0.025461064651608467 (L1Loss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
     --> Epoch time; 27.96479082107544
Epoch 6
	 Logging train Loss: 0.0009692013 (MSELoss(): data_t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 0.0010435676667839289 (MSELoss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 0.02137812413275242 (L1Loss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
     --> Epoch time; 27.94414186477661
Epoch 7
	 Logging train Loss: 0.0007102169 (MSELoss(): data_t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 0.000788988487329334 (MSELoss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 0.018582860007882118 (L1Loss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
     --> Epoch time; 27.165969610214233
Epoch 8
	 Logging train Loss: 0.0005149841 (MSELoss(): data_t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 0.0005474319914355874 (MSELoss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 0.015445785596966743 (L1Loss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
     --> Epoch time; 27.75048017501831
Epoch 9
	 Logging train Loss: 0.0003618599 (MSELoss(): data_t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 0.0003943814954254776 (MSELoss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 0.013220597989857197 (L1Loss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
     --> Epoch time; 25.8222074508667
Epoch 10
	 Logging train Loss: 0.0002540786 (MSELoss(): data_t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 0.00026529174647293985 (MSELoss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 0.010918969288468361 (L1Loss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
     --> Epoch time; 25.761087894439697
Epoch 11
	 Logging train Loss: 0.0001750114 (MSELoss(): data_t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 0.0001950349542312324 (MSELoss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 0.009563258849084377 (L1Loss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
     --> Epoch time; 26.521931409835815
Epoch 12
	 Logging train Loss: 0.0001284312 (MSELoss(): data_t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 0.00015473170788027346 (MSELoss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 0.00870103482156992 (L1Loss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
     --> Epoch time; 25.712880849838257
Epoch 13
	 Logging train Loss: 0.000100679 (MSELoss(): data_t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 0.0001255668030353263 (MSELoss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 0.007692492101341486 (L1Loss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
     --> Epoch time; 27.3809232711792
Epoch 14
	 Logging train Loss: 8.47012e-05 (MSELoss(): data_t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 0.00011198216088814661 (MSELoss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 0.007295997813344002 (L1Loss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
     --> Epoch time; 25.8307843208313
Epoch 15
	 Logging train Loss: 7.49401e-05 (MSELoss(): data_t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 7.294797978829592e-05 (MSELoss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 0.005858753342181444 (L1Loss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
     --> Epoch time; 25.769301176071167
Epoch 16
	 Logging train Loss: 6.95245e-05 (MSELoss(): data_t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 7.131764141377062e-05 (MSELoss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 0.0058496384881436825 (L1Loss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
     --> Epoch time; 25.797269582748413
Epoch 17
	 Logging train Loss: 6.8107e-05 (MSELoss(): data_t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 8.361443906323984e-05 (MSELoss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 0.006272445432841778 (L1Loss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
     --> Epoch time; 25.66221785545349
Epoch 18
	 Logging train Loss: 6.35948e-05 (MSELoss(): data_t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 4.9229973228648305e-05 (MSELoss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 0.004800358321517706 (L1Loss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
     --> Epoch time; 25.616888761520386
Epoch 19
	 Logging train Loss: 6.21429e-05 (MSELoss(): data_t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 6.537947047036141e-05 (MSELoss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 0.005630331113934517 (L1Loss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
     --> Epoch time; 27.172667980194092
	 Logging test loss 6.537041917908937e-05 (MSELoss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 0.005630158819258213 (L1Loss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
It took 626.2785034179688 seconds to train & eval the model.
----- ITERATION 2/2 ------
Number of train simulations: 1600
Number of test simulations: 400
The dataloader took 56.45633411407471 seconds.
-- Finished Train Dataloader --
The dataloader took 14.159964561462402 seconds.
-- Finished Test Dataloader(s) --
Datatype: pos_diff_start
--- Started Training ---
Epoch 0
	 Logging train Loss: 0.6317464991 (MSELoss(): data_t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 0.019574996083974838 (MSELoss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 0.0989765003323555 (L1Loss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
     --> Epoch time; 28.035712957382202
Epoch 1
	 Logging train Loss: 0.0116006041 (MSELoss(): data_t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 0.00788761954754591 (MSELoss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 0.06304951757192612 (L1Loss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
     --> Epoch time; 26.38049292564392
Epoch 2
	 Logging train Loss: 0.005104112 (MSELoss(): data_t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 0.003858411218971014 (MSELoss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 0.04389205574989319 (L1Loss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
     --> Epoch time; 26.04872226715088
Epoch 3
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.029 MB of 0.029 MB uploaded (0.000 MB deduped)wandb: \ 0.029 MB of 0.079 MB uploaded (0.000 MB deduped)wandb: | 0.079 MB of 0.079 MB uploaded (0.000 MB deduped)wandb: / 0.079 MB of 0.079 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  Test loss t(0, 0)_r(5, 20)_full L1Loss() █▅▄▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁
wandb: Test loss t(0, 0)_r(5, 20)_full MSELoss() █▄▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     Train loss data_t(0, 0)_r(5, 20)_full █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:  Test loss t(0, 0)_r(5, 20)_full L1Loss() 0.00655
wandb: Test loss t(0, 0)_r(5, 20)_full MSELoss() 9e-05
wandb:     Train loss data_t(0, 0)_r(5, 20)_full 6e-05
wandb: 
wandb: 🚀 View run sage-resonance-606 at: https://wandb.ai/nreints/test/runs/3zj4z66x
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230330_124717-3zj4z66x/logs
	 Logging train Loss: 0.0027719314 (MSELoss(): data_t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 0.002385288942605257 (MSELoss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 0.03423186391592026 (L1Loss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
     --> Epoch time; 26.182409286499023
Epoch 4
	 Logging train Loss: 0.0018294983 (MSELoss(): data_t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 0.0015808871248736978 (MSELoss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 0.02742782235145569 (L1Loss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
     --> Epoch time; 27.530458688735962
Epoch 5
	 Logging train Loss: 0.0013170638 (MSELoss(): data_t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 0.0011397418566048145 (MSELoss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 0.02280942164361477 (L1Loss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
     --> Epoch time; 27.724738597869873
Epoch 6
	 Logging train Loss: 0.0009794529 (MSELoss(): data_t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 0.0008698664605617523 (MSELoss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 0.019941242411732674 (L1Loss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
     --> Epoch time; 27.419177293777466
Epoch 7
	 Logging train Loss: 0.0007251972 (MSELoss(): data_t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 0.0006653355085290968 (MSELoss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 0.017346028238534927 (L1Loss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
     --> Epoch time; 25.879210710525513
Epoch 8
	 Logging train Loss: 0.000520784 (MSELoss(): data_t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 0.00044872445869259536 (MSELoss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 0.014332919381558895 (L1Loss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
     --> Epoch time; 25.750710010528564
Epoch 9
	 Logging train Loss: 0.0003562018 (MSELoss(): data_t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 0.0003158837207593024 (MSELoss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 0.012221910059452057 (L1Loss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
     --> Epoch time; 25.85074758529663
Epoch 10
	 Logging train Loss: 0.000234221 (MSELoss(): data_t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 0.0002664328785613179 (MSELoss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 0.011145343072712421 (L1Loss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
     --> Epoch time; 25.679211139678955
Epoch 11
	 Logging train Loss: 0.0001578887 (MSELoss(): data_t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 0.0001452246360713616 (MSELoss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 0.008308312855660915 (L1Loss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
     --> Epoch time; 27.351263523101807
Epoch 12
	 Logging train Loss: 0.000116209 (MSELoss(): data_t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 9.873989620245993e-05 (MSELoss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 0.006920559331774712 (L1Loss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
     --> Epoch time; 26.097182750701904
Epoch 13
	 Logging train Loss: 9.15896e-05 (MSELoss(): data_t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 8.056460501393303e-05 (MSELoss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 0.006111581809818745 (L1Loss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
     --> Epoch time; 26.0907564163208
Epoch 14
	 Logging train Loss: 8.00902e-05 (MSELoss(): data_t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 9.535303979646415e-05 (MSELoss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 0.006628173869103193 (L1Loss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
     --> Epoch time; 25.9669771194458
Epoch 15
	 Logging train Loss: 7.14878e-05 (MSELoss(): data_t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 7.456458843080327e-05 (MSELoss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 0.005898481234908104 (L1Loss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
     --> Epoch time; 25.58746838569641
Epoch 16
	 Logging train Loss: 6.91413e-05 (MSELoss(): data_t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 5.5462787713622674e-05 (MSELoss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 0.005090109538286924 (L1Loss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
     --> Epoch time; 27.728381633758545
Epoch 17
	 Logging train Loss: 6.58827e-05 (MSELoss(): data_t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 6.935445708222687e-05 (MSELoss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 0.005777657963335514 (L1Loss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
     --> Epoch time; 27.472452402114868
Epoch 18
	 Logging train Loss: 6.52777e-05 (MSELoss(): data_t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 5.502692511072382e-05 (MSELoss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 0.004949379246681929 (L1Loss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
     --> Epoch time; 27.36007523536682
Epoch 19
	 Logging train Loss: 6.33674e-05 (MSELoss(): data_t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 9.403123840456828e-05 (MSELoss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 0.006551822647452354 (L1Loss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
     --> Epoch time; 25.994715452194214
	 Logging test loss 9.405281161889434e-05 (MSELoss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
	 Logging test loss 0.006551398430019617 (L1Loss(): t(0, 0)_r(5, 20)_full_pNone_gNone)
It took 618.0334486961365 seconds to train & eval the model.

JOB STATISTICS
==============
Job ID: 2523403
Array Job ID: 2523368_35
Cluster: snellius
User/Group: nreints/nreints
State: RUNNING
Nodes: 1
Cores per node: 18
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 06:18:36 core-walltime
Job Wall-clock time: 00:21:02
Memory Utilized: 0.00 MB (estimated maximum)
Memory Efficiency: 0.00% of 29.30 GB (29.30 GB/node)
WARNING: Efficiency statistics may be misleading for RUNNING jobs.
