wandb: Currently logged in as: nreints. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home/nreints/.netrc
/gpfs/home2/nreints/MScThesis/code/fcnn.py:566: DeprecationWarning: Sampling from a set deprecated
since Python 3.9 and will be removed in a subsequent version.
  train_sims = set(random.sample(sims_train, int(0.8 * n_sims_train)))
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230330_123649-jrn32e3z
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hearty-water-558
wandb: ⭐️ View project at https://wandb.ai/nreints/test
wandb: 🚀 View run at https://wandb.ai/nreints/test/runs/jrn32e3z
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.029 MB of 0.029 MB uploaded (0.000 MB deduped)wandb: \ 0.029 MB of 0.078 MB uploaded (0.000 MB deduped)wandb: | 0.029 MB of 0.078 MB uploaded (0.000 MB deduped)wandb: / 0.029 MB of 0.078 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  Test loss t(0, 0)_r(5, 20)_semi L1Loss() █▆▄▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁
wandb: Test loss t(0, 0)_r(5, 20)_semi MSELoss() █▄▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     Train loss data_t(0, 0)_r(5, 20)_semi █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:  Test loss t(0, 0)_r(5, 20)_semi L1Loss() 0.06765
wandb: Test loss t(0, 0)_r(5, 20)_semi MSELoss() 0.01027
wandb:     Train loss data_t(0, 0)_r(5, 20)_semi 0.00985
wandb: 
wandb: 🚀 View run hearty-water-558 at: https://wandb.ai/nreints/test/runs/jrn32e3z
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230330_123649-jrn32e3z/logs
/gpfs/home2/nreints/MScThesis/code/fcnn.py:566: DeprecationWarning: Sampling from a set deprecated
since Python 3.9 and will be removed in a subsequent version.
  train_sims = set(random.sample(sims_train, int(0.8 * n_sims_train)))
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230330_124828-4w0c0wkf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run firm-vortex-625
wandb: ⭐️ View project at https://wandb.ai/nreints/test
wandb: 🚀 View run at https://wandb.ai/nreints/test/runs/4w0c0wkf
Training on dataset: data/data_t(0, 0)_r(5, 20)_semi_pNone_gNone
Testing on datasets: ['data_t(0, 0)_r(5, 20)_semi_pNone_gNone']
----- ITERATION 1/2 ------
Number of train simulations: 1600
Number of test simulations: 400
The dataloader took 62.44118642807007 seconds.
-- Finished Train Dataloader --
The dataloader took 15.382303714752197 seconds.
-- Finished Test Dataloader(s) --
Datatype: dual_quat
--- Started Training ---
Epoch 0
	 Logging train Loss: 11.9768101511 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 1.4411718845367432 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 0.8035504817962646 (L1Loss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
     --> Epoch time; 29.03222155570984
Epoch 1
	 Logging train Loss: 0.894910785 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 0.6660380363464355 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 0.5439155697822571 (L1Loss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
     --> Epoch time; 30.358941793441772
Epoch 2
	 Logging train Loss: 0.3859007991 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 0.27712103724479675 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 0.35301896929740906 (L1Loss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
     --> Epoch time; 31.051823616027832
Epoch 3
	 Logging train Loss: 0.187913224 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 0.15829965472221375 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 0.26757872104644775 (L1Loss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
     --> Epoch time; 31.40226936340332
Epoch 4
	 Logging train Loss: 0.1119450388 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 0.09668465703725815 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 0.20966479182243347 (L1Loss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
     --> Epoch time; 31.16687035560608
Epoch 5
	 Logging train Loss: 0.0746906405 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 0.06522253900766373 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 0.17221538722515106 (L1Loss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
     --> Epoch time; 30.877660512924194
Epoch 6
	 Logging train Loss: 0.0536462821 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 0.05263286828994751 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 0.15543721616268158 (L1Loss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
     --> Epoch time; 30.368322134017944
Epoch 7
	 Logging train Loss: 0.0406827141 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 0.042843110859394073 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 0.13986560702323914 (L1Loss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
     --> Epoch time; 30.68389654159546
Epoch 8
	 Logging train Loss: 0.0325943716 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 0.03351718187332153 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 0.12433857470750809 (L1Loss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
     --> Epoch time; 31.066038846969604
Epoch 9
	 Logging train Loss: 0.0270181394 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 0.025451600551605225 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 0.10764608532190323 (L1Loss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
     --> Epoch time; 31.202796697616577
Epoch 10
	 Logging train Loss: 0.0229199578 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 0.02849460393190384 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 0.11437136679887772 (L1Loss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
     --> Epoch time; 30.83041763305664
Epoch 11
	 Logging train Loss: 0.0199713701 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 0.02139643020927906 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 0.09798315167427063 (L1Loss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
     --> Epoch time; 30.845606565475464
Epoch 12
	 Logging train Loss: 0.0176772922 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 0.018018679693341255 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 0.08972526341676712 (L1Loss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
     --> Epoch time; 29.329237461090088
Epoch 13
	 Logging train Loss: 0.0161392249 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 0.017708485946059227 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 0.08933787792921066 (L1Loss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
     --> Epoch time; 29.207964420318604
Epoch 14
	 Logging train Loss: 0.014458397 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 0.015135543420910835 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 0.08253175020217896 (L1Loss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
     --> Epoch time; 29.310972690582275
Epoch 15
	 Logging train Loss: 0.0132461261 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 0.014160593040287495 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 0.07968548685312271 (L1Loss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
     --> Epoch time; 29.034467935562134
Epoch 16
	 Logging train Loss: 0.0120883979 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 0.012667039409279823 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 0.0745934247970581 (L1Loss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
     --> Epoch time; 30.544777393341064
Epoch 17
	 Logging train Loss: 0.0113214032 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 0.011014401912689209 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 0.0697086900472641 (L1Loss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
     --> Epoch time; 29.396444082260132
Epoch 18
	 Logging train Loss: 0.0106532041 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 0.01232810690999031 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 0.07489322125911713 (L1Loss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
     --> Epoch time; 29.325003623962402
Epoch 19
	 Logging train Loss: 0.009850876 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 0.010270404629409313 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 0.0676618367433548 (L1Loss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
     --> Epoch time; 30.12767004966736
	 Logging test loss 0.010270851664245129 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 0.06765291094779968 (L1Loss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
It took 699.1616597175598 seconds to train & eval the model.
----- ITERATION 2/2 ------
Number of train simulations: 1600
Number of test simulations: 400
The dataloader took 56.124022483825684 seconds.
-- Finished Train Dataloader --
The dataloader took 13.996890544891357 seconds.
-- Finished Test Dataloader(s) --
Datatype: dual_quat
--- Started Training ---
Epoch 0
	 Logging train Loss: 39.6740655637 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 15.044720649719238 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 1.7805416584014893 (L1Loss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
     --> Epoch time; 31.330355167388916
Epoch 1
	 Logging train Loss: 12.1231426164 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 10.97734546661377 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 1.4864519834518433 (L1Loss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
     --> Epoch time; 29.227874517440796
Epoch 2
	 Logging train Loss: 8.9231158088 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 9.669474601745605 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 1.4092919826507568 (L1Loss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
     --> Epoch time; 29.24145245552063
Epoch 3
	 Logging train Loss: 7.4338496987 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:  Test loss t(0, 0)_r(5, 20)_semi L1Loss() █▆▆▄▅▄▄▃▃▃▃▂▃▃▂▁▃▁▁▁▁
wandb: Test loss t(0, 0)_r(5, 20)_semi MSELoss() █▆▅▃▄▃▃▂▃▂▂▂▂▂▁▁▂▁▁▁▁
wandb:     Train loss data_t(0, 0)_r(5, 20)_semi █▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:  Test loss t(0, 0)_r(5, 20)_semi L1Loss() 0.73237
wandb: Test loss t(0, 0)_r(5, 20)_semi MSELoss() 2.38283
wandb:     Train loss data_t(0, 0)_r(5, 20)_semi 2.42948
wandb: 
wandb: 🚀 View run firm-vortex-625 at: https://wandb.ai/nreints/test/runs/4w0c0wkf
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230330_124828-4w0c0wkf/logs
	 Logging test loss 6.64258337020874 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 1.15597665309906 (L1Loss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
     --> Epoch time; 29.34372878074646
Epoch 4
	 Logging train Loss: 6.6401699091 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 8.188447952270508 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 1.2683181762695312 (L1Loss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
     --> Epoch time; 31.239900588989258
Epoch 5
	 Logging train Loss: 5.8861187704 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 6.593533039093018 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 1.156328797340393 (L1Loss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
     --> Epoch time; 30.730266332626343
Epoch 6
	 Logging train Loss: 5.5748806424 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 6.464962959289551 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 1.1680727005004883 (L1Loss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
     --> Epoch time; 30.698092699050903
Epoch 7
	 Logging train Loss: 4.9354792177 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 4.759396076202393 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 0.9917943477630615 (L1Loss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
     --> Epoch time; 29.408674240112305
Epoch 8
	 Logging train Loss: 4.525469133 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 5.415074348449707 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 1.039054274559021 (L1Loss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
     --> Epoch time; 29.347753286361694
Epoch 9
	 Logging train Loss: 4.3175774867 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 3.783501148223877 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 1.033748984336853 (L1Loss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
     --> Epoch time; 29.37509799003601
Epoch 10
	 Logging train Loss: 4.0462182138 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 3.706021308898926 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 0.9021902084350586 (L1Loss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
     --> Epoch time; 29.21593713760376
Epoch 11
	 Logging train Loss: 3.8612445108 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 3.5793333053588867 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 0.8335500955581665 (L1Loss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
     --> Epoch time; 30.82750129699707
Epoch 12
	 Logging train Loss: 3.5507483788 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 4.737813472747803 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 1.0149292945861816 (L1Loss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
     --> Epoch time; 29.245037078857422
Epoch 13
	 Logging train Loss: 3.2576995251 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 3.8683536052703857 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 0.9249526262283325 (L1Loss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
     --> Epoch time; 29.60496425628662
Epoch 14
	 Logging train Loss: 2.9757659314 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 3.022932291030884 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 0.7868210673332214 (L1Loss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
     --> Epoch time; 29.578189849853516
Epoch 15
	 Logging train Loss: 2.9500319138 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 2.4404773712158203 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 0.6975299119949341 (L1Loss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
     --> Epoch time; 28.878554582595825
Epoch 16
	 Logging train Loss: 2.6874297896 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 3.631479501724243 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 0.9668650031089783 (L1Loss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
     --> Epoch time; 31.379948616027832
Epoch 17
	 Logging train Loss: 2.6768358418 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 2.5233752727508545 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 0.725285530090332 (L1Loss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
     --> Epoch time; 30.694079875946045
Epoch 18
	 Logging train Loss: 2.6787323198 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 2.1502246856689453 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 0.6556079387664795 (L1Loss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
     --> Epoch time; 30.670109272003174
Epoch 19
	 Logging train Loss: 2.4294763902 (MSELoss(): data_t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 2.3814449310302734 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 0.7323319911956787 (L1Loss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
     --> Epoch time; 29.302905082702637
	 Logging test loss 2.3828320503234863 (MSELoss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
	 Logging test loss 0.7323742508888245 (L1Loss(): t(0, 0)_r(5, 20)_semi_pNone_gNone)
It took 684.5874953269958 seconds to train & eval the model.

JOB STATISTICS
==============
Job ID: 2523373
Array Job ID: 2523368_5
Cluster: snellius
User/Group: nreints/nreints
State: COMPLETED (exit code 0)
Nodes: 1
Cores per node: 18
CPU Utilized: 03:44:36
CPU Efficiency: 53.51% of 06:59:42 core-walltime
Job Wall-clock time: 00:23:19
Memory Utilized: 3.68 GB
Memory Efficiency: 12.55% of 29.30 GB
