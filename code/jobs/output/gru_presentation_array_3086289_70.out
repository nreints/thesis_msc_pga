wandb: Currently logged in as: nreints. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_211345-lio3asq1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dashing-universe-457
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/lio3asq1
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gTrue â–ˆâ–‚â–â–â–‚â–‚â–â–‚â–â–
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gTrue â–ˆâ–‚â–â–â–‚â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gTrue â–ˆâ–‚â–â–â–‚â–‚â–â–‚â–â–
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gTrue â–ˆâ–‚â–â–â–â–‚â–â–‚â–â–
wandb:                                   Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gTrue 1e-05
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gTrue 1e-05
wandb:                                   Train loss 0.0
wandb: 
wandb: ðŸš€ View run dashing-universe-457 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/lio3asq1
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_211345-lio3asq1/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_212135-rtjj748k
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run magic-pine-471
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/rtjj748k
Training on dataset: data_t(5,20)_r(5,20)_combi_pNone_gTrue
Testing on 4 datasets: ['data_t(5,20)_r(5,20)_semi_pNone_gTrue', 'data_t(5,20)_r(5,20)_tennis_pNone_gTrue', 'data_t(5,20)_r(5,20)_full_pNone_gTrue', 'data_t(5,20)_r(5,20)_combi_pNone_gTrue']
Focussing on identity: False
Using extra input: False
Using fr-fr as reference point.
----- ITERATION 1/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gTrue took 50.86715269088745 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gTrue took 12.890924215316772 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gTrue took 12.605434894561768 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gTrue took 12.587956190109253 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gTrue took 12.597052812576294 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(6, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=6, bias=True)
)
Datatype: log_dualQ_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0008138464 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 7.25459e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 8.25863e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 1.51732e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 4.68279e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 36.24810600280762
Epoch 1/9
	 Logging train Loss: 1.65125e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 1.18773e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 1.30807e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 1.9743e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 7.1298e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 35.5007426738739
Epoch 2/9
	 Logging train Loss: 5.3454e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 7.5196e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 8.031e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 1.1704e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 4.4108e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 35.43171215057373
Epoch 3/9
	 Logging train Loss: 4.5628e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 8.2146e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 8.8732e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 9.279e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 4.7601e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 34.746371269226074
Epoch 4/9
	 Logging train Loss: 4.4814e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 1.01899e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 1.1152e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 1.4933e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 6.1453e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 34.96859097480774
Epoch 5/9
	 Logging train Loss: 4.4519e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 1.22731e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 1.38778e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 5.644e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 6.9446e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 34.7639000415802
Epoch 6/9
	 Logging train Loss: 4.3312e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 9.2432e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 1.01987e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 1.2878e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 5.6038e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 34.84672236442566
Epoch 7/9
	 Logging train Loss: 4.1103e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 1.1705e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 1.33354e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 6.648e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 6.7353e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 34.86373996734619
Epoch 8/9
	 Logging train Loss: 3.7701e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 6.5326e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 7.2083e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 2.88e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 3.6012e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 34.73085832595825
Epoch 9/9
	 Logging train Loss: 3.4595e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 5.2035e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 5.7454e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 2.715e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 2.9149e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 35.13185381889343
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gTrue/'log_dualQ_1'_'False'.pth
It took  470.2235486507416  seconds.
----- ITERATION 2/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gTrue took 46.32317137718201 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gTrue took 11.7591872215271 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gTrue took 11.76335883140564 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gTrue took 11.822182416915894 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gTrue took 11.638282299041748 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(6, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=6, bias=True)
)
Datatype: log_dualQ_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.00063282 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 6.78884e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 7.41814e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 2.47144e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 4.62621e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 35.277347564697266
Epoch 1/9
	 Logging train Loss: 1.98016e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 1.01763e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 1.07697e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 3.147e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 6.5365e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 35.28510618209839
Epoch 2/9
	 Logging train Loss: 6.4741e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 8.0274e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 8.2226e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 1.4316e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 4.5905e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 35.341071367263794
Epoch 3/9
	 Logging train Loss: 5.7542e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 7.8511e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 8.0903e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 1.0405e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gTrue â–ˆâ–‚â–â–â–‚â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gTrue â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gTrue â–ˆâ–‚â–â–â–‚â–â–â–‚â–â–
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gTrue â–ˆâ–‚â–â–â–‚â–â–â–â–â–
wandb:                                   Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gTrue 0.0
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gTrue 0.0
wandb:                                   Train loss 0.0
wandb: 
wandb: ðŸš€ View run magic-pine-471 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/rtjj748k
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_212135-rtjj748k/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_212914-lsao4jvk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run gentle-cloud-481
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/lsao4jvk
	 Logging test loss: 4.3393e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 35.08483600616455
Epoch 4/9
	 Logging train Loss: 5.6429e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 1.16198e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 1.20724e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 9.275e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 6.329e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 35.28823733329773
Epoch 5/9
	 Logging train Loss: 5.0211e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 7.4365e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 7.6417e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 5.879e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 3.8901e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 35.36305046081543
Epoch 6/9
	 Logging train Loss: 4.5618e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 6.385e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 6.5485e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 4.411e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 3.3305e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 34.931148290634155
Epoch 7/9
	 Logging train Loss: 4.2338e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 9.2463e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 9.5331e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 6.386e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 4.9318e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 35.30860185623169
Epoch 8/9
	 Logging train Loss: 3.8151e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 6.0724e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 6.2224e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 3.6e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 3.1732e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 35.113025426864624
Epoch 9/9
	 Logging train Loss: 3.4867e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 4.7311e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 4.84e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 3.339e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 2.44e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 35.253032207489014
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gTrue/'log_dualQ_1'_'False'.pth
It took  458.89867067337036  seconds.
----- ITERATION 3/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gTrue took 45.309653997421265 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gTrue took 11.725191354751587 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gTrue took 11.66543698310852 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gTrue took 11.613372087478638 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gTrue took 11.406676530838013 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(6, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=6, bias=True)
)
Datatype: log_dualQ_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0008549789 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 8.33122e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 8.53451e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 3.34471e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 5.79819e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 35.038018226623535
Epoch 1/9
	 Logging train Loss: 2.52506e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 1.46928e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 1.48464e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 5.5126e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 9.9849e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 35.45580792427063
Epoch 2/9
	 Logging train Loss: 6.7997e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 1.04789e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 1.03537e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 2.0631e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 6.1108e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 35.751285552978516
Epoch 3/9
	 Logging train Loss: 5.5988e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 8.5385e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 8.5496e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 1.0696e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 4.6718e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 35.07434582710266
Epoch 4/9
	 Logging train Loss: 5.0804e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 1.5874e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 1.64148e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 1.2557e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 8.715e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 35.03190326690674
Epoch 5/9
	 Logging train Loss: 4.8297e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 4.18768e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 4.29555e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 1.8424e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 2.22088e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 35.110928773880005
Epoch 6/9
	 Logging train Loss: 4.5207e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 8.0648e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 8.0294e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 4.499e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 4.104e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 35.09951424598694
Epoch 7/9
	 Logging train Loss: 4.3395e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 7.5351e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 7.6597e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 3.463e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 3.9111e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 34.95173239707947
Epoch 8/9
	 Logging train Loss: 3.8023e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 5.8381e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 5.8544e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 2.701e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 2.9318e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 35.178574562072754
Epoch 9/9
	 Logging train Loss: 3.6057e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 6.9089e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 6.8892e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 1.073e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 3.8868e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 35.09365367889404
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gTrue â–ˆâ–‚â–â–â–‚â–ƒâ–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gTrue â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gTrue â–ˆâ–‚â–â–â–‚â–„â–â–â–â–
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gTrue â–ˆâ–‚â–â–â–‚â–„â–â–â–â–
wandb:                                   Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gTrue 1e-05
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gTrue 1e-05
wandb:                                   Train loss 0.0
wandb: 
wandb: ðŸš€ View run gentle-cloud-481 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/lsao4jvk
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_212914-lsao4jvk/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_213649-2gfoyhno
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run royal-water-491
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/2gfoyhno
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gTrue â–ˆâ–‚â–â–â–â–‚â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gTrue â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gTrue â–ˆâ–‚â–â–â–â–‚â–â–â–â–
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gTrue â–ˆâ–‚â–â–â–â–‚â–â–â–â–
wandb:                                   Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gTrue 0.0
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gTrue 0.0
wandb:                                   Train loss 0.0
wandb: 
wandb: ðŸš€ View run royal-water-491 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/2gfoyhno
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_213649-2gfoyhno/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_214425-8y85uys0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run gallant-water-499
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/8y85uys0
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gTrue/'log_dualQ_1'_'False'.pth
It took  455.5155727863312  seconds.
----- ITERATION 4/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gTrue took 45.002203702926636 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gTrue took 11.57197380065918 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gTrue took 11.591631412506104 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gTrue took 11.61279582977295 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gTrue took 11.408581495285034 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(6, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=6, bias=True)
)
Datatype: log_dualQ_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0008059689 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 8.71789e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 8.9906e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 2.55368e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 5.9713e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 35.18564248085022
Epoch 1/9
	 Logging train Loss: 2.10938e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 1.10513e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 1.09857e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 3.118e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 7.2723e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 34.99242424964905
Epoch 2/9
	 Logging train Loss: 5.4209e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 7.9895e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 7.8105e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 1.5806e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 4.8588e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 35.39184761047363
Epoch 3/9
	 Logging train Loss: 4.9348e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 7.0478e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 6.859e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 1.0624e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 4.1168e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 35.40693783760071
Epoch 4/9
	 Logging train Loss: 4.7023e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 1.02475e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 1.05121e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 8.898e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 5.938e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 35.21127963066101
Epoch 5/9
	 Logging train Loss: 4.4891e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 1.29906e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 1.37049e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 6.947e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 7.4116e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 34.94053912162781
Epoch 6/9
	 Logging train Loss: 4.4487e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 6.1424e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 6.0507e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 3.993e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 3.3982e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 35.1043746471405
Epoch 7/9
	 Logging train Loss: 3.9288e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 8.6901e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 8.9115e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 6.724e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 4.9636e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 35.26329064369202
Epoch 8/9
	 Logging train Loss: 3.7566e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 6.7956e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 6.8808e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 3.171e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 3.7972e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 35.274277210235596
Epoch 9/9
	 Logging train Loss: 3.334e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 4.8087e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 4.7261e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 3.989e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 2.6688e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 35.222973585128784
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gTrue/'log_dualQ_1'_'False'.pth
It took  455.53024911880493  seconds.
----- ITERATION 5/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gTrue took 45.230249643325806 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gTrue took 11.637166738510132 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gTrue took 11.636242628097534 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gTrue took 11.623493194580078 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gTrue took 11.445553541183472 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(6, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=6, bias=True)
)
Datatype: log_dualQ_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0005244897 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 5.28941e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 5.37137e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 2.34059e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 3.75047e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 35.29909300804138
Epoch 1/9
	 Logging train Loss: 1.41582e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 1.00932e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 1.01303e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 2.0623e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 5.8853e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 35.51037359237671
Epoch 2/9
	 Logging train Loss: 5.6537e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 8.3566e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 8.3545e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 1.2569e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 4.6189e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 35.746577501297
Epoch 3/9
	 Logging train Loss: 5.2751e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 7.7823e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 7.7153e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 8.451e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 4.1377e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 34.98385167121887
Epoch 4/9
	 Logging train Loss: 5.1839e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 7.7127e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gTrue â–ˆâ–‚â–â–â–â–‚â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gTrue â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gTrue â–ˆâ–‚â–‚â–â–â–‚â–‚â–‚â–â–
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gTrue â–ˆâ–‚â–‚â–â–â–‚â–‚â–‚â–â–
wandb:                                   Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gTrue 0.0
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gTrue 1e-05
wandb:                                   Train loss 0.0
wandb: 
wandb: ðŸš€ View run gallant-water-499 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/8y85uys0
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_214425-8y85uys0/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_215202-p7kabhyh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run trim-meadow-510
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/p7kabhyh
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gTrue â–ˆâ–‚â–â–â–‚â–â–â–â–‚â–
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gTrue â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gTrue â–ˆâ–‚â–â–â–‚â–â–â–â–‚â–
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gTrue â–ˆâ–‚â–â–â–‚â–â–â–â–‚â–
wandb:                                   Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gTrue 1e-05
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gTrue 1e-05
wandb:                                   Train loss 0.0
wandb: 
wandb: ðŸš€ View run trim-meadow-510 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/p7kabhyh
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_215202-p7kabhyh/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_215944-o34s90sj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fearless-hill-521
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/o34s90sj
	 Logging test loss: 7.7581e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 6.774e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 4.0196e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 35.28436827659607
Epoch 5/9
	 Logging train Loss: 4.5093e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 9.7846e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 1.00747e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 5.042e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 4.9141e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 35.3498318195343
Epoch 6/9
	 Logging train Loss: 4.1159e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 8.5538e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 8.725e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 4.833e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 4.3028e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 35.1663773059845
Epoch 7/9
	 Logging train Loss: 3.8751e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 8.6185e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 8.9201e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 6.633e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 4.4536e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 35.38603091239929
Epoch 8/9
	 Logging train Loss: 3.4868e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 4.423e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 4.4316e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 2.306e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 2.2151e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 35.16153430938721
Epoch 9/9
	 Logging train Loss: 3.0255e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 4.92e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 5.0246e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 3.222e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 2.5221e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 35.095279693603516
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gTrue/'log_dualQ_1'_'False'.pth
It took  457.46998715400696  seconds.
----- ITERATION 6/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gTrue took 45.001179695129395 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gTrue took 11.621494054794312 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gTrue took 11.639783143997192 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gTrue took 11.60497760772705 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gTrue took 11.461946249008179 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(6, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=6, bias=True)
)
Datatype: log_dualQ_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0009105486 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 8.5395e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 9.50011e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 3.75482e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 6.18185e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 35.158056020736694
Epoch 1/9
	 Logging train Loss: 2.69317e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 1.40326e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 1.51468e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 5.7581e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 9.9842e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 35.13795590400696
Epoch 2/9
	 Logging train Loss: 6.6222e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 8.0535e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 8.9324e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 1.9043e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 5.0228e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 35.53554606437683
Epoch 3/9
	 Logging train Loss: 5.5362e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 8.994e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 1.02158e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 1.4159e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 5.3213e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 35.06262135505676
Epoch 4/9
	 Logging train Loss: 5.2656e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 1.55842e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 1.83578e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 1.2304e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 8.9366e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 34.96340012550354
Epoch 5/9
	 Logging train Loss: 5.0309e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 7.0891e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 8.0363e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 7.571e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 4.0065e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 35.21553015708923
Epoch 6/9
	 Logging train Loss: 4.705e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 6.4152e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 7.3031e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 4.899e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 3.548e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 35.14658188819885
Epoch 7/9
	 Logging train Loss: 4.172e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 5.6223e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 6.2943e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 3.992e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 3.0704e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 35.441158294677734
Epoch 8/9
	 Logging train Loss: 3.8486e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 1.48723e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 1.73199e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 6.629e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 8.1947e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 35.44097185134888
Epoch 9/9
	 Logging train Loss: 3.6521e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 5.4104e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 6.195e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 3.236e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 2.9455e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 35.42121958732605
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gTrue/'log_dualQ_1'_'False'.pth
It took  462.1011402606964  seconds.
----- ITERATION 7/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gTrue took 45.22407245635986 seconds.
-- Finished Train Dataloader --
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gTrue â–ˆâ–‚â–‚â–‚â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gTrue â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gTrue â–ˆâ–‚â–ƒâ–‚â–â–â–â–â–â–
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gTrue â–ˆâ–‚â–ƒâ–‚â–â–â–â–â–â–
wandb:                                   Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gTrue 1e-05
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gTrue 1e-05
wandb:                                   Train loss 0.0
wandb: 
wandb: ðŸš€ View run fearless-hill-521 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/o34s90sj
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_215944-o34s90sj/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_220722-l970oteb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run olive-snow-531
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/l970oteb
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gTrue took 11.561973810195923 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gTrue took 11.557806491851807 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gTrue took 11.572511911392212 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gTrue took 11.475162982940674 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(6, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=6, bias=True)
)
Datatype: log_dualQ_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0004019505 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 3.22059e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 3.36055e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 1.78924e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 2.53312e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 35.18592977523804
Epoch 1/9
	 Logging train Loss: 1.13725e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 9.3354e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 9.7728e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 1.9924e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 5.8799e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 35.24754095077515
Epoch 2/9
	 Logging train Loss: 6.5111e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 1.26917e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 1.34357e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 1.4487e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 7.4856e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 35.7139196395874
Epoch 3/9
	 Logging train Loss: 5.6453e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 8.6461e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 9.1432e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 9.066e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 5.0525e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 35.66207766532898
Epoch 4/9
	 Logging train Loss: 5.2375e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 5.9336e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 6.1845e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 7.462e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 3.4371e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 35.18177390098572
Epoch 5/9
	 Logging train Loss: 4.699e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 5.4432e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 5.7383e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 3.911e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 3.0318e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 35.3492636680603
Epoch 6/9
	 Logging train Loss: 4.1205e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 5.7906e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 6.1169e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 3.024e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 3.2398e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 35.196614265441895
Epoch 7/9
	 Logging train Loss: 3.9006e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 6.1784e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 6.5593e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 3.816e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 3.496e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 35.177250385284424
Epoch 8/9
	 Logging train Loss: 3.2918e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 6.4766e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 6.8867e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 3.819e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 3.6845e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 35.13452768325806
Epoch 9/9
	 Logging train Loss: 3.1691e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 5.7181e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 6.0542e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 2.867e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 3.2279e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 35.10403656959534
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gTrue/'log_dualQ_1'_'False'.pth
It took  458.0687355995178  seconds.
----- ITERATION 8/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gTrue took 45.10415816307068 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gTrue took 11.598603010177612 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gTrue took 11.663556337356567 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gTrue took 11.608901977539062 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gTrue took 11.438743591308594 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(6, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=6, bias=True)
)
Datatype: log_dualQ_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.000539087 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 5.09155e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 5.58539e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 1.74867e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 3.57088e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 35.29621601104736
Epoch 1/9
	 Logging train Loss: 1.27633e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 9.3653e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 9.7573e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 2.0158e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 5.8358e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 35.22989630699158
Epoch 2/9
	 Logging train Loss: 5.2578e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 8.0542e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 8.2988e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 1.2517e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 4.7138e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 35.4824800491333
Epoch 3/9
	 Logging train Loss: 5.0641e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 8.6095e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 8.9172e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 1.0022e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 4.8818e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 35.22629475593567
Epoch 4/9
	 Logging train Loss: 4.7278e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 6.4762e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 6.6714e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 4.983e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 3.5582e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 35.24501585960388
Epoch 5/9
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gTrue â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gTrue â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gTrue â–ˆâ–‚â–‚â–‚â–â–â–‚â–â–â–
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gTrue â–ˆâ–‚â–â–‚â–â–â–‚â–â–â–
wandb:                                   Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gTrue 0.0
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gTrue 0.0
wandb:                                   Train loss 0.0
wandb: 
wandb: ðŸš€ View run olive-snow-531 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/l970oteb
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_220722-l970oteb/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_221500-33i1e6p7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run silvery-sound-541
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/33i1e6p7
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gTrue â–ˆâ–‚â–â–â–â–â–â–‚â–â–
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gTrue â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gTrue â–ˆâ–‚â–â–â–â–â–â–‚â–â–
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gTrue â–ˆâ–‚â–â–â–â–â–â–‚â–â–
wandb:                                   Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gTrue 1e-05
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gTrue 1e-05
wandb:                                   Train loss 0.0
wandb: 
wandb: ðŸš€ View run silvery-sound-541 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/33i1e6p7
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_221500-33i1e6p7/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_222241-m3bnykym
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run electric-dust-547
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/m3bnykym
	 Logging train Loss: 4.4401e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 6.7104e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 6.9387e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 4.604e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 3.6928e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 35.32440161705017
Epoch 6/9
	 Logging train Loss: 4.0196e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 8.3485e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 8.8522e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 8.212e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 4.7226e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 35.17168116569519
Epoch 7/9
	 Logging train Loss: 3.7352e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 6.2247e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 6.519e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 2.678e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 3.3535e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 35.3583037853241
Epoch 8/9
	 Logging train Loss: 3.4952e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 5.6773e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 5.9504e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 2.588e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 3.0611e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 35.17515420913696
Epoch 9/9
	 Logging train Loss: 3.0657e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 4.6425e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 4.8343e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 4.704e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 2.6255e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 34.865713357925415
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gTrue/'log_dualQ_1'_'False'.pth
It took  458.0160391330719  seconds.
----- ITERATION 9/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gTrue took 46.556196451187134 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gTrue took 11.67122483253479 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gTrue took 11.67361330986023 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gTrue took 11.671069145202637 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gTrue took 11.628499269485474 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(6, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=6, bias=True)
)
Datatype: log_dualQ_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0009069386 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 9.67574e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 0.0001008033 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 3.2934e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 6.5715e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 34.8820378780365
Epoch 1/9
	 Logging train Loss: 2.82296e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 1.49492e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 1.49434e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 6.308e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 1.0551e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 35.277098178863525
Epoch 2/9
	 Logging train Loss: 6.6199e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 8.9171e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 8.8603e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 1.9183e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 5.4783e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 35.172800064086914
Epoch 3/9
	 Logging train Loss: 4.7598e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 9.7767e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 9.9112e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 1.4327e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 5.7126e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 35.68735313415527
Epoch 4/9
	 Logging train Loss: 4.9723e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 9.8216e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 1.00861e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 1.0376e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 5.5532e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 35.752593755722046
Epoch 5/9
	 Logging train Loss: 4.7787e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 9.4048e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 9.8054e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 7.558e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 5.2629e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 35.22884774208069
Epoch 6/9
	 Logging train Loss: 4.5707e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 6.0501e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 5.9157e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 4.503e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 3.2511e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 35.00106716156006
Epoch 7/9
	 Logging train Loss: 4.3855e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 1.5255e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 1.63953e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 1.1278e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 8.526e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 35.07142162322998
Epoch 8/9
	 Logging train Loss: 3.8236e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 8.4274e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 8.6343e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 4.359e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 4.508e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 35.04098677635193
Epoch 9/9
	 Logging train Loss: 3.3413e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 5.6217e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 5.6685e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 3.197e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 3.0165e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 35.126484394073486
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gTrue/'log_dualQ_1'_'False'.pth
It took  460.55370831489563  seconds.
----- ITERATION 10/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gTrue took 46.3825523853302 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gTrue took 11.68658185005188 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gTrue took 11.636271476745605 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gTrue took 11.699223279953003 seconds.
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gTrue â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gTrue â–ˆâ–‚â–â–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gTrue â–ˆâ–â–â–â–â–â–â–â–â–
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gTrue â–ˆâ–â–â–â–â–â–â–â–â–
wandb:                                   Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gTrue 1e-05
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gTrue 1e-05
wandb:                                   Train loss 0.0
wandb: 
wandb: ðŸš€ View run electric-dust-547 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/m3bnykym
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_222241-m3bnykym/logs
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gTrue took 11.721940279006958 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(6, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=6, bias=True)
)
Datatype: log_dualQ_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0010117301 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 9.47172e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 9.57084e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 3.54666e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 6.49765e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 35.19479489326477
Epoch 1/9
	 Logging train Loss: 2.63072e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 1.16405e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 1.12645e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 3.5738e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 7.3366e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 35.287445306777954
Epoch 2/9
	 Logging train Loss: 5.2449e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 8.0223e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 7.5615e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 1.5546e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 4.4983e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 35.169456481933594
Epoch 3/9
	 Logging train Loss: 4.2996e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 8.0101e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 7.6477e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 1.0444e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 4.2647e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 36.00943374633789
Epoch 4/9
	 Logging train Loss: 4.1022e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 7.9588e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 7.6335e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 7.449e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 4.1085e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 35.466224908828735
Epoch 5/9
	 Logging train Loss: 4.2953e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 7.8239e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 7.6205e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 5.109e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 3.9238e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 35.098835468292236
Epoch 6/9
	 Logging train Loss: 4.1588e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 8.6324e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 8.5378e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 3.957e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 4.3322e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 35.176629304885864
Epoch 7/9
	 Logging train Loss: 3.9295e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 5.6727e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 5.4217e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 2.663e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 2.7371e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 35.34072661399841
Epoch 8/9
	 Logging train Loss: 3.6671e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 6.0501e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 5.9281e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 5.226e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 3.1492e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 35.42308592796326
Epoch 9/9
	 Logging train Loss: 3.2716e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 6.9508e-06 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 6.8438e-06 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gTrue]
	 Logging test loss: 3.521e-07 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 3.4642e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gTrue]
		--> Epoch time; 35.17177867889404
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gTrue/'log_dualQ_1'_'False'.pth
It took  461.320876121521  seconds.

JOB STATISTICS
==============
Job ID: 3086318
Array Job ID: 3086289_70
Cluster: snellius
User/Group: nreints/nreints
State: COMPLETED (exit code 0)
Nodes: 1
Cores per node: 18
CPU Utilized: 01:23:51
CPU Efficiency: 6.06% of 23:03:36 core-walltime
Job Wall-clock time: 01:16:52
Memory Utilized: 7.59 GB
Memory Efficiency: 0.00% of 0.00 MB
