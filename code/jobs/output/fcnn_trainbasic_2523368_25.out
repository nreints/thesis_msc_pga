wandb: Currently logged in as: nreints. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home/nreints/.netrc
/gpfs/home2/nreints/MScThesis/code/fcnn.py:566: DeprecationWarning: Sampling from a set deprecated
since Python 3.9 and will be removed in a subsequent version.
  train_sims = set(random.sample(sims_train, int(0.8 * n_sims_train)))
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230330_123650-hz215sf7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hearty-pine-573
wandb: â­ï¸ View project at https://wandb.ai/nreints/test
wandb: ðŸš€ View run at https://wandb.ai/nreints/test/runs/hz215sf7
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.029 MB of 0.029 MB uploaded (0.000 MB deduped)wandb: \ 0.029 MB of 0.078 MB uploaded (0.000 MB deduped)wandb: | 0.029 MB of 0.078 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  Test loss t(5, 20)_r(0, 0)_tennis L1Loss() â–„â–…â–ƒâ–ƒâ–‚â–‚â–â–ƒâ–‚â–â–ƒâ–â–‚â–ˆâ–‚â–â–â–ƒâ–â–â–
wandb: Test loss t(5, 20)_r(0, 0)_tennis MSELoss() â–‚â–ƒâ–‚â–‚â–â–â–â–‚â–â–â–â–â–â–ˆâ–â–â–â–‚â–â–â–
wandb:     Train loss data_t(5, 20)_r(0, 0)_tennis â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:  Test loss t(5, 20)_r(0, 0)_tennis L1Loss() 0.0965
wandb: Test loss t(5, 20)_r(0, 0)_tennis MSELoss() 0.02203
wandb:     Train loss data_t(5, 20)_r(0, 0)_tennis 0.14319
wandb: 
wandb: ðŸš€ View run hearty-pine-573 at: https://wandb.ai/nreints/test/runs/hz215sf7
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230330_123650-hz215sf7/logs
/gpfs/home2/nreints/MScThesis/code/fcnn.py:566: DeprecationWarning: Sampling from a set deprecated
since Python 3.9 and will be removed in a subsequent version.
  train_sims = set(random.sample(sims_train, int(0.8 * n_sims_train)))
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230330_124842-3azwhdxq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eager-pyramid-630
wandb: â­ï¸ View project at https://wandb.ai/nreints/test
wandb: ðŸš€ View run at https://wandb.ai/nreints/test/runs/3azwhdxq
Training on dataset: data/data_t(5, 20)_r(0, 0)_tennis_pNone_gNone
Testing on datasets: ['data_t(5, 20)_r(0, 0)_tennis_pNone_gNone']
----- ITERATION 1/2 ------
Number of train simulations: 1600
Number of test simulations: 400
The dataloader took 60.530476570129395 seconds.
-- Finished Train Dataloader --
The dataloader took 15.21417498588562 seconds.
-- Finished Test Dataloader(s) --
Datatype: log_quat
--- Started Training ---
Epoch 0
	 Logging train Loss: 166.7333231209 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.5026746988296509 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.4723043143749237 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 32.16705894470215
Epoch 1
	 Logging train Loss: 0.5995352153 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.717801570892334 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.5336957573890686 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 32.29945492744446
Epoch 2
	 Logging train Loss: 0.4120727938 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.19377249479293823 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.2993309497833252 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 31.7647705078125
Epoch 3
	 Logging train Loss: 0.3576571197 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.2675715982913971 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.32895731925964355 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 31.608057498931885
Epoch 4
	 Logging train Loss: 0.2985053966 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.091411292552948 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.1981765776872635 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 31.49419355392456
Epoch 5
	 Logging train Loss: 0.3127606959 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.09086509048938751 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.20518216490745544 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 32.12286853790283
Epoch 6
	 Logging train Loss: 0.2721151514 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.038970936089754105 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.13130642473697662 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 31.963709354400635
Epoch 7
	 Logging train Loss: 0.2476721471 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.266080379486084 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.34075379371643066 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 31.683485984802246
Epoch 8
	 Logging train Loss: 0.2472138847 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.0657331719994545 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.1599854975938797 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 31.568050622940063
Epoch 9
	 Logging train Loss: 0.201927953 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.03387688100337982 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.12319067865610123 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 29.973164081573486
Epoch 10
	 Logging train Loss: 0.2440594642 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.17193664610385895 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.2755442261695862 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 30.139166593551636
Epoch 11
	 Logging train Loss: 0.1944220848 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.0409521609544754 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.127884179353714 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 30.47287082672119
Epoch 12
	 Logging train Loss: 0.2002270268 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.07652755826711655 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.1698468029499054 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 29.815869331359863
Epoch 13
	 Logging train Loss: 0.197197509 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 2.464294195175171 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.9259760975837708 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 31.53192687034607
Epoch 14
	 Logging train Loss: 0.2054485246 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.05571199581027031 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.15563742816448212 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 30.021002531051636
Epoch 15
	 Logging train Loss: 0.1938338735 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.01676865480840206 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.08332004398107529 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 29.945207357406616
Epoch 16
	 Logging train Loss: 0.1245991925 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.04454778507351875 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.13813051581382751 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 30.145693063735962
Epoch 17
	 Logging train Loss: 0.1608772727 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.23589377105236053 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.3243893086910248 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 30.07394242286682
Epoch 18
	 Logging train Loss: 0.1414781558 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.04017657786607742 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.12344092130661011 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 30.030841588974
Epoch 19
	 Logging train Loss: 0.143188696 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.02201778255403042 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.09651211649179459 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 32.3200147151947
	 Logging test loss 0.022025439888238907 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.09650267660617828 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
It took 712.2589135169983 seconds to train & eval the model.
----- ITERATION 2/2 ------
Number of train simulations: 1600
Number of test simulations: 400
The dataloader took 55.99864149093628 seconds.
-- Finished Train Dataloader --
The dataloader took 13.996334791183472 seconds.
-- Finished Test Dataloader(s) --
Datatype: log_quat
--- Started Training ---
Epoch 0
	 Logging train Loss: 158.4504799837 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.7972304821014404 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.5716200470924377 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 32.024704694747925
Epoch 1
	 Logging train Loss: 0.6301901425 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.42869511246681213 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.4335079491138458 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 30.247772216796875
Epoch 2
	 Logging train Loss: 0.5173160329 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.6059927940368652 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.5153953433036804 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 29.883984327316284
Epoch 3
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.029 MB of 0.077 MB uploaded (0.000 MB deduped)wandb: \ 0.077 MB of 0.077 MB uploaded (0.000 MB deduped)wandb: | 0.077 MB of 0.077 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  Test loss t(5, 20)_r(0, 0)_tennis L1Loss() â–‡â–…â–†â–ƒâ–„â–†â–‡â–‚â–‚â–ƒâ–†â–â–â–â–‚â–…â–â–â–„â–ˆâ–ˆ
wandb: Test loss t(5, 20)_r(0, 0)_tennis MSELoss() â–†â–„â–…â–‚â–ƒâ–…â–†â–â–‚â–‚â–…â–â–â–â–â–ƒâ–â–â–ƒâ–ˆâ–ˆ
wandb:     Train loss data_t(5, 20)_r(0, 0)_tennis â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:  Test loss t(5, 20)_r(0, 0)_tennis L1Loss() 0.67161
wandb: Test loss t(5, 20)_r(0, 0)_tennis MSELoss() 1.08236
wandb:     Train loss data_t(5, 20)_r(0, 0)_tennis 0.14318
wandb: 
wandb: ðŸš€ View run eager-pyramid-630 at: https://wandb.ai/nreints/test/runs/3azwhdxq
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230330_124842-3azwhdxq/logs
	 Logging train Loss: 0.4050789627 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.1645556092262268 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.2670787274837494 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 29.61654806137085
Epoch 4
	 Logging train Loss: 0.3632201351 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.3255192041397095 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.33167630434036255 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 31.72641634941101
Epoch 5
	 Logging train Loss: 0.3309092004 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.6263124346733093 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.4947468340396881 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 31.69428038597107
Epoch 6
	 Logging train Loss: 0.2732239767 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.7601658701896667 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.5552973747253418 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 31.8046293258667
Epoch 7
	 Logging train Loss: 0.2583192514 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.06784682720899582 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.17158064246177673 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 30.334975242614746
Epoch 8
	 Logging train Loss: 0.2542038263 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.1279967874288559 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.2163095325231552 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 30.394282817840576
Epoch 9
	 Logging train Loss: 0.2403694103 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.16485020518302917 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.24192598462104797 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 30.12286639213562
Epoch 10
	 Logging train Loss: 0.2016587401 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.6351215839385986 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.5028937458992004 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 29.685423851013184
Epoch 11
	 Logging train Loss: 0.2311642915 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.030281752347946167 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.11202820390462875 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 31.80900740623474
Epoch 12
	 Logging train Loss: 0.2189700656 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.03722136840224266 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.12403085082769394 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 30.279094696044922
Epoch 13
	 Logging train Loss: 0.1649655012 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.04109550639986992 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.13516336679458618 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 30.289498805999756
Epoch 14
	 Logging train Loss: 0.1844135758 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.09415242820978165 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.1978210210800171 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 30.32863998413086
Epoch 15
	 Logging train Loss: 0.1711951761 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.4020503759384155 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.39204949140548706 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 29.96489429473877
Epoch 16
	 Logging train Loss: 0.1620155783 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.028154609724879265 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.11141396313905716 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 32.24671244621277
Epoch 17
	 Logging train Loss: 0.1626982446 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.05061981827020645 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.1367390751838684 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 31.953559398651123
Epoch 18
	 Logging train Loss: 0.1452794493 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.2656029462814331 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.31808674335479736 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 32.398361921310425
Epoch 19
	 Logging train Loss: 0.1431806677 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 1.0823562145233154 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.6716120839118958 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 30.199138402938843
	 Logging test loss 1.0823628902435303 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.6716081500053406 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
It took 701.5806782245636 seconds to train & eval the model.

JOB STATISTICS
==============
Job ID: 2523393
Array Job ID: 2523368_25
Cluster: snellius
User/Group: nreints/nreints
State: COMPLETED (exit code 0)
Nodes: 1
Cores per node: 18
CPU Utilized: 03:34:13
CPU Efficiency: 49.93% of 07:09:00 core-walltime
Job Wall-clock time: 00:23:50
Memory Utilized: 3.56 GB
Memory Efficiency: 12.15% of 29.30 GB
