wandb: Currently logged in as: nreints. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_203638-yt3nsw8m
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run youthful-grass-403
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/yt3nsw8m
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gTrue █▃▂▃▂▂▁▁▁▁
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gTrue █▂▁▁▁▁▁▁▁▂
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gTrue █▃▃▃▂▂▁▁▁▁
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gTrue █▃▃▃▂▂▂▁▁▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gTrue 0.0
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gTrue 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: 🚀 View run youthful-grass-403 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/yt3nsw8m
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_203638-yt3nsw8m/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_204742-maoa993q
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run clean-durian-420
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/maoa993q
Training on dataset: data_t(0,0)_r(5,20)_combi_pNone_gTrue
Testing on 4 datasets: ['data_t(0,0)_r(5,20)_semi_pNone_gTrue', 'data_t(0,0)_r(5,20)_combi_pNone_gTrue', 'data_t(0,0)_r(5,20)_full_pNone_gTrue', 'data_t(0,0)_r(5,20)_tennis_pNone_gTrue']
Focussing on identity: True
Using extra input: False
Using fr-fr as reference point.
----- ITERATION 1/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gTrue took 51.224202394485474 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(5,20)_semi_pNone_gTrue took 12.787087202072144 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gTrue took 13.294585704803467 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_full_pNone_gTrue took 12.29435110092163 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_tennis_pNone_gTrue took 12.510015964508057 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0002991428 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 1.72747e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 1.03549e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 2.621e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 1.8691e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gTrue]
		--> Epoch time; 54.936400175094604
Epoch 1/9
	 Logging train Loss: 5.1538e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 7.9825e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 4.2765e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 3.252e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 8.2503e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gTrue]
		--> Epoch time; 54.47674489021301
Epoch 2/9
	 Logging train Loss: 4.4512e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 6.2892e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 3.3662e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 2.352e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 6.6094e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gTrue]
		--> Epoch time; 54.21069264411926
Epoch 3/9
	 Logging train Loss: 3.72e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 7.3016e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 3.9602e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 2.33e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 7.7684e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gTrue]
		--> Epoch time; 54.22094368934631
Epoch 4/9
	 Logging train Loss: 3.2759e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 4.2509e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 2.2444e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 1.253e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 4.5054e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gTrue]
		--> Epoch time; 54.530869245529175
Epoch 5/9
	 Logging train Loss: 2.9682e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 4.1517e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 2.2366e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 1.449e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 4.492e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gTrue]
		--> Epoch time; 55.91911005973816
Epoch 6/9
	 Logging train Loss: 2.3623e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 3.8512e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 2.1399e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 1.902e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 4.3148e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gTrue]
		--> Epoch time; 55.64844632148743
Epoch 7/9
	 Logging train Loss: 2.0501e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 2.8703e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 1.5605e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 1.104e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 3.2017e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gTrue]
		--> Epoch time; 55.031898736953735
Epoch 8/9
	 Logging train Loss: 1.5889e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 3.0304e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 1.6981e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 2.08e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 3.3622e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gTrue]
		--> Epoch time; 54.38757610321045
Epoch 9/9
	 Logging train Loss: 1.4603e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 3.0131e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 1.7707e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 3.274e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 3.3712e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gTrue]
		--> Epoch time; 54.12474989891052
Saved model in  trained_models/gru/data_t(0,0)_r(5,20)_combi_pNone_gTrue/'rot_mat_1'_'False'.pth
It took  664.867502450943  seconds.
----- ITERATION 2/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gTrue took 49.95203971862793 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(5,20)_semi_pNone_gTrue took 12.580647230148315 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gTrue took 12.443864345550537 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_full_pNone_gTrue took 12.577559471130371 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_tennis_pNone_gTrue took 12.570124864578247 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0002331873 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 8.7005e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 4.4601e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 5.799e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 7.9211e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gTrue]
		--> Epoch time; 55.717267751693726
Epoch 1/9
	 Logging train Loss: 4.647e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 7.0313e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 3.5326e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 2.874e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 6.4592e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gTrue]
		--> Epoch time; 55.519073486328125
Epoch 2/9
	 Logging train Loss: 4.3997e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 7.9861e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 4.2093e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 3.412e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 7.7139e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gTrue]
		--> Epoch time; 54.70179033279419
Epoch 3/9
	 Logging train Loss: 3.718e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 4.6777e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gTrue]
	 Logging test loss: 2.3629e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gTrue]
	 Logging test loss: 1.517e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gTrue]
	 Logging test loss: 4.4268e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gTrue]
		--> Epoch time; 54.335065603256226
Epoch 4/9
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gTrue █▆▇▄▂▄▁▁▃▁
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gTrue █▄▅▂▂▂▃▁▃▁
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gTrue █▆▇▄▂▄▁▁▃▁
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gTrue █▆█▄▃▅▁▁▃▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gTrue 0.0
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gTrue 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: 🚀 View run clean-durian-420 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/maoa993q
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_204742-maoa993q/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_205842-dxa4dzah
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run polished-cosmos-439
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/dxa4dzah
slurmstepd: error: *** JOB 3085907 ON gcn21 CANCELLED AT 2023-07-16T21:09:10 ***
slurmstepd: error: *** STEP 3085907.0 ON gcn21 CANCELLED AT 2023-07-16T21:09:10 ***

JOB STATISTICS
==============
Job ID: 3085907
Array Job ID: 3085846_77
Cluster: snellius
User/Group: nreints/nreints
State: CANCELLED (exit code 0)
Nodes: 1
Cores per node: 18
CPU Utilized: 00:34:44
CPU Efficiency: 5.89% of 09:49:30 core-walltime
Job Wall-clock time: 00:32:45
Memory Utilized: 8.36 GB
Memory Efficiency: 0.00% of 0.00 MB
