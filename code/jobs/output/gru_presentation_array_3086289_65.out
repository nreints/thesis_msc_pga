wandb: Currently logged in as: nreints. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_211346-lc8c1ypz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run helpful-wind-459
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/lc8c1ypz
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gTrue █▃▂▁▃▁▁▁▅▃
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gTrue █▃▂▁▃▁▁▁▃▄
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gTrue █▃▂▁▃▁▁▁▆▃
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gTrue █▃▂▁▃▁▁▁▆▃
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gTrue 0.0
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gTrue 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: 🚀 View run helpful-wind-459 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/lc8c1ypz
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_211346-lc8c1ypz/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_212502-vjjpfauk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run unique-durian-473
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/vjjpfauk
Training on dataset: data_t(5,20)_r(0,0)_combi_pNone_gTrue
Testing on 4 datasets: ['data_t(5,20)_r(0,0)_tennis_pNone_gTrue', 'data_t(5,20)_r(0,0)_semi_pNone_gTrue', 'data_t(5,20)_r(0,0)_full_pNone_gTrue', 'data_t(5,20)_r(0,0)_combi_pNone_gTrue']
Focussing on identity: True
Using extra input: False
Using fr-fr as reference point.
----- ITERATION 1/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gTrue took 51.10002589225769 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(0,0)_tennis_pNone_gTrue took 12.812229633331299 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_semi_pNone_gTrue took 12.905014753341675 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_full_pNone_gTrue took 12.490175485610962 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gTrue took 12.313809633255005 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0001459819 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.9293e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 6.2178e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 4.9819e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 5.6027e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 55.969664096832275
Epoch 1/9
	 Logging train Loss: 2.9322e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.8162e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.8446e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.8383e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.8509e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 55.81985592842102
Epoch 2/9
	 Logging train Loss: 1.5003e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.1782e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.2206e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 8.516e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.0571e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 57.27420449256897
Epoch 3/9
	 Logging train Loss: 9.528e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.523e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.622e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 3.352e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.53e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 56.784504652023315
Epoch 4/9
	 Logging train Loss: 8.431e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.8699e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.9441e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.2526e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.6199e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 55.9893856048584
Epoch 5/9
	 Logging train Loss: 7.248e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.076e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 7.609e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.683e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 5.277e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 55.7826988697052
Epoch 6/9
	 Logging train Loss: 7.062e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.606e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.764e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.035e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.951e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 55.7525110244751
Epoch 7/9
	 Logging train Loss: 6.44e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.394e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 4.694e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.196e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.525e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 55.99104595184326
Epoch 8/9
	 Logging train Loss: 6.332e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.455e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 4.7706e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.5032e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.2167e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 55.25844192504883
Epoch 9/9
	 Logging train Loss: 5.603e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.1647e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.1709e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.1771e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.1718e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 55.18487501144409
Saved model in  trained_models/gru/data_t(5,20)_r(0,0)_combi_pNone_gTrue/'rot_mat_1'_'False'.pth
It took  676.2902116775513  seconds.
----- ITERATION 2/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gTrue took 50.04189658164978 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(0,0)_tennis_pNone_gTrue took 12.211922407150269 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_semi_pNone_gTrue took 12.20919942855835 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_full_pNone_gTrue took 12.244396924972534 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gTrue took 12.217517614364624 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 7.94996e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.2546e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 4.0336e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 3.4912e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.6699e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 55.832406997680664
Epoch 1/9
	 Logging train Loss: 2.3696e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.2612e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.2019e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.2289e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.1925e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 56.338783740997314
Epoch 2/9
	 Logging train Loss: 1.2166e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.091e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 4.881e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 4.796e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 4.753e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 56.30898594856262
Epoch 3/9
	 Logging train Loss: 9.48e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.06e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.962e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.796e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.856e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 56.21129870414734
Epoch 4/9
	 Logging train Loss: 9.307e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gTrue █▃▂▁▁▁▁▄▁▂
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gTrue █▃▂▁▁▁▁▂▁▂
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gTrue █▃▂▁▁▁▂▇▁▂
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gTrue █▃▂▁▁▁▂▆▁▂
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gTrue 0.0
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gTrue 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: 🚀 View run unique-durian-473 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/vjjpfauk
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_212502-vjjpfauk/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_213614-v1cl5xii
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run leafy-durian-489
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/v1cl5xii
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gTrue █▃▂▄▁▁▁▂▃▂
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gTrue █▃▂▃▁▁▁▂▃▂
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gTrue █▃▂▄▁▁▁▂▂▂
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gTrue █▃▂▄▁▁▁▂▃▂
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gTrue 0.0
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gTrue 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: 🚀 View run leafy-durian-489 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/v1cl5xii
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_213614-v1cl5xii/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_214755-fnehk155
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run easy-plasma-505
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/fnehk155
	 Logging test loss: 2.096e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.057e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.962e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.016e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 56.384860038757324
Epoch 5/9
	 Logging train Loss: 8.309e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.47e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.403e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 3.224e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.326e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 55.88929319381714
Epoch 6/9
	 Logging train Loss: 7.536e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.025e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 4.829e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 3.086e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.965e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 55.57573652267456
Epoch 7/9
	 Logging train Loss: 6.934e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.3719e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.3419e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 4.471e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.8115e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 55.510775327682495
Epoch 8/9
	 Logging train Loss: 6.148e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.029e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.978e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.655e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.838e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 55.42657399177551
Epoch 9/9
	 Logging train Loss: 5.45e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.476e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 5.436e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 5.158e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 5.317e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 55.57064771652222
Saved model in  trained_models/gru/data_t(5,20)_r(0,0)_combi_pNone_gTrue/'rot_mat_1'_'False'.pth
It took  672.2730689048767  seconds.
----- ITERATION 3/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gTrue took 49.151132583618164 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(0,0)_tennis_pNone_gTrue took 12.205448865890503 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_semi_pNone_gTrue took 12.208743572235107 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_full_pNone_gTrue took 12.271505355834961 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gTrue took 12.303076267242432 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0001268408 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.0749e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 5.21e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 4.4911e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 4.9708e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 57.758068323135376
Epoch 1/9
	 Logging train Loss: 2.7524e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.6843e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.7351e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.6752e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.7359e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 57.112144947052
Epoch 2/9
	 Logging train Loss: 1.167e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 9.692e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 9.813e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 8.526e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 9.33e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 56.878047466278076
Epoch 3/9
	 Logging train Loss: 8.369e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.5005e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.5189e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.5889e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.0933e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 56.985032081604004
Epoch 4/9
	 Logging train Loss: 7.52e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.108e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.15e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.976e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.05e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 56.958332538604736
Epoch 5/9
	 Logging train Loss: 7.487e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.309e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.337e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.201e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.249e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 58.4364173412323
Epoch 6/9
	 Logging train Loss: 7.203e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.738e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.778e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.438e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.589e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 58.52411723136902
Epoch 7/9
	 Logging train Loss: 6.296e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.807e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 6.857e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 6.714e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 6.754e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 57.38510847091675
Epoch 8/9
	 Logging train Loss: 5.623e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.2263e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.2232e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.1806e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.2029e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 57.028703927993774
Epoch 9/9
	 Logging train Loss: 5.189e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.176e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 8.202e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 6.626e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 7.45e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 57.013996839523315
Saved model in  trained_models/gru/data_t(5,20)_r(0,0)_combi_pNone_gTrue/'rot_mat_1'_'False'.pth
It took  701.5274031162262  seconds.
----- ITERATION 4/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gTrue took 49.090004682540894 seconds.
-- Finished Train Dataloader --
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gTrue █▃▂▂▁▂▁▁▂▂
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gTrue █▃▂▂▁▂▁▁▂▁
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gTrue █▃▂▃▁▂▁▁▂▂
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gTrue █▃▂▃▁▂▁▁▂▂
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gTrue 0.0
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gTrue 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: 🚀 View run easy-plasma-505 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/fnehk155
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_214755-fnehk155/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_215922-ns0zr4hl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fragrant-waterfall-519
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/ns0zr4hl
The dataloader for data/data_t(5,20)_r(0,0)_tennis_pNone_gTrue took 12.21875524520874 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_semi_pNone_gTrue took 12.572911500930786 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_full_pNone_gTrue took 12.608082056045532 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gTrue took 12.575446128845215 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0001195315 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.5512e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 8.5526e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 8.1998e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 8.3896e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 57.38159513473511
Epoch 1/9
	 Logging train Loss: 3.7593e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.2121e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.1751e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.2328e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.2018e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 57.220062494277954
Epoch 2/9
	 Logging train Loss: 1.7772e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.0419e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.0293e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.0395e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.0363e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 57.721516132354736
Epoch 3/9
	 Logging train Loss: 1.2318e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.0607e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.9679e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 7.579e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.8624e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 57.90514588356018
Epoch 4/9
	 Logging train Loss: 9.77e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.342e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.281e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.591e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.986e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 57.9106171131134
Epoch 5/9
	 Logging train Loss: 7.706e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.9503e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.8743e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.0371e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.481e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 57.40583610534668
Epoch 6/9
	 Logging train Loss: 7.62e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.19e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.153e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.65e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.921e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 57.361223220825195
Epoch 7/9
	 Logging train Loss: 6.971e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.486e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 5.489e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 4.969e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 5.244e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 57.33228778839111
Epoch 8/9
	 Logging train Loss: 6.149e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.0593e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.0544e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 9.52e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.002e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 57.30131983757019
Epoch 9/9
	 Logging train Loss: 5.622e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.4599e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.4058e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 7.255e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.0772e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 57.379064083099365
Saved model in  trained_models/gru/data_t(5,20)_r(0,0)_combi_pNone_gTrue/'rot_mat_1'_'False'.pth
It took  686.8316779136658  seconds.
----- ITERATION 5/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gTrue took 49.08421802520752 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(0,0)_tennis_pNone_gTrue took 12.523040771484375 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_semi_pNone_gTrue took 12.538052082061768 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_full_pNone_gTrue took 12.50325059890747 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gTrue took 12.302979707717896 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.000142605 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.6195e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.514e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 3.5442e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.5508e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 56.43411183357239
Epoch 1/9
	 Logging train Loss: 2.3077e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.3446e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.3059e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.3324e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.3274e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 56.36515736579895
Epoch 2/9
	 Logging train Loss: 1.022e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.371e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 5.235e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 5.113e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 5.211e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 56.348499059677124
Epoch 3/9
	 Logging train Loss: 8.19e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.13e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.103e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.038e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.085e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 56.358593225479126
Epoch 4/9
	 Logging train Loss: 7.268e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.116e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.1e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.992e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.051e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 56.61776685714722
Epoch 5/9
	 Logging train Loss: 8.37e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.3985e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gTrue ▆▃▂▁▁█▁▃▁▁
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gTrue ▇▃▂▁▁█▁▂▁▁
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gTrue ▆▃▁▁▁█▁▄▁▁
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gTrue ▆▃▁▁▁█▁▄▁▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gTrue 0.0
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gTrue 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: 🚀 View run fragrant-waterfall-519 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/ns0zr4hl
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_215922-ns0zr4hl/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_221044-ej91hdzk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fine-spaceship-533
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/ej91hdzk
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gTrue ▅▂▁█▁▁▁▄▁▁
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gTrue █▃▂▂▁▁▁▅▁▂
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gTrue ▃▂▁█▁▁▁▂▁▁
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gTrue ▃▂▁█▁▁▁▂▁▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gTrue 0.0
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gTrue 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: 🚀 View run fine-spaceship-533 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/ej91hdzk
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_221044-ej91hdzk/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_222159-8h0p9scb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rose-eon-545
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/8h0p9scb
	 Logging test loss: 5.2479e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 3.8512e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 4.5468e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 57.79235482215881
Epoch 6/9
	 Logging train Loss: 7.483e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.265e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.277e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 3.242e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.255e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 57.81995701789856
Epoch 7/9
	 Logging train Loss: 6.408e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.7626e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.5871e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 6.1e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.5743e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 58.18462252616882
Epoch 8/9
	 Logging train Loss: 5.89e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.074e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.046e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.634e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.842e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 58.058879375457764
Epoch 9/9
	 Logging train Loss: 5.86e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.455e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.407e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.829e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.099e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 56.831703662872314
Saved model in  trained_models/gru/data_t(5,20)_r(0,0)_combi_pNone_gTrue/'rot_mat_1'_'False'.pth
It took  682.0073411464691  seconds.
----- ITERATION 6/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gTrue took 49.40279221534729 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(0,0)_tennis_pNone_gTrue took 12.567793607711792 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_semi_pNone_gTrue took 12.554820537567139 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_full_pNone_gTrue took 12.59430193901062 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gTrue took 12.47433066368103 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 5.34077e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.277e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.1611e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.2265e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.2301e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 56.15281701087952
Epoch 1/9
	 Logging train Loss: 1.6901e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.243e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 6.845e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 6.934e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 7.005e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 56.32735061645508
Epoch 2/9
	 Logging train Loss: 1.0522e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.703e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.549e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 3.387e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.531e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 56.246846199035645
Epoch 3/9
	 Logging train Loss: 9.35e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.0074e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 6.8139e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 3.582e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.5616e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 56.37816858291626
Epoch 4/9
	 Logging train Loss: 7.59e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.146e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.085e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.98e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.085e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 58.938990354537964
Epoch 5/9
	 Logging train Loss: 7.306e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.166e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.105e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.656e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.938e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 56.552836418151855
Epoch 6/9
	 Logging train Loss: 6.695e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.793e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.736e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.311e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.574e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 55.46157956123352
Epoch 7/9
	 Logging train Loss: 6.023e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.4521e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.4428e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.3534e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.4103e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 55.35825824737549
Epoch 8/9
	 Logging train Loss: 5.72e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.009e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.921e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.635e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.347e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 55.409149408340454
Epoch 9/9
	 Logging train Loss: 4.924e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.695e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.688e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 3.129e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.447e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 55.72201681137085
Saved model in  trained_models/gru/data_t(5,20)_r(0,0)_combi_pNone_gTrue/'rot_mat_1'_'False'.pth
It took  674.4238350391388  seconds.
----- ITERATION 7/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gTrue took 49.16350078582764 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(0,0)_tennis_pNone_gTrue took 12.543082237243652 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_semi_pNone_gTrue took 12.515838623046875 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_full_pNone_gTrue took 12.614430665969849 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gTrue took 12.293956279754639 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat_1
-- Started Training --
Epoch 0/9
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gTrue █▃▂▁▃▁▁▂▃▁
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gTrue █▄▂▁▃▁▁▂▃▁
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gTrue █▃▂▁▃▁▁▂▃▁
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gTrue █▃▂▁▃▁▁▂▃▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gTrue 0.0
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gTrue 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: 🚀 View run rose-eon-545 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/8h0p9scb
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_222159-8h0p9scb/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_223323-e1w0cks6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run valiant-star-549
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/e1w0cks6
	 Logging train Loss: 9.86895e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.7155e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 5.6022e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 5.5758e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 5.4586e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 57.256103515625
Epoch 1/9
	 Logging train Loss: 3.4256e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.0817e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.0121e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.137e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.0369e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 57.40939211845398
Epoch 2/9
	 Logging train Loss: 1.6406e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 9.094e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 8.909e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 9.073e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 8.83e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 57.36603927612305
Epoch 3/9
	 Logging train Loss: 9.547e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.987e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.963e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 3.76e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.838e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 57.27427816390991
Epoch 4/9
	 Logging train Loss: 7.82e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.7879e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.7902e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.663e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.7331e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 56.09407138824463
Epoch 5/9
	 Logging train Loss: 7.057e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.958e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.038e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.126e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.589e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 56.211543560028076
Epoch 6/9
	 Logging train Loss: 7.672e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.468e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.43e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.445e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.451e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 57.40636658668518
Epoch 7/9
	 Logging train Loss: 5.647e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.1566e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.1547e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.0988e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.1291e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 57.40197420120239
Epoch 8/9
	 Logging train Loss: 5.286e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.6293e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.636e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.4658e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.559e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 57.65652585029602
Epoch 9/9
	 Logging train Loss: 5.022e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.393e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.397e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.899e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.169e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 57.63468098640442
Saved model in  trained_models/gru/data_t(5,20)_r(0,0)_combi_pNone_gTrue/'rot_mat_1'_'False'.pth
It took  684.2478613853455  seconds.
----- ITERATION 8/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gTrue took 50.518176317214966 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(0,0)_tennis_pNone_gTrue took 12.656954050064087 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_semi_pNone_gTrue took 12.670847415924072 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_full_pNone_gTrue took 12.669874906539917 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gTrue took 12.686368942260742 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 5.7272e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.0733e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 4.0207e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 4.0661e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.9313e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 57.68924069404602
Epoch 1/9
	 Logging train Loss: 2.4332e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.516e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.5108e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.5094e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.4579e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 57.85746145248413
Epoch 2/9
	 Logging train Loss: 1.2115e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.7923e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.8012e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.6644e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.708e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 57.685388803482056
Epoch 3/9
	 Logging train Loss: 9.388e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.048e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 4.047e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.516e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.249e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 57.65959334373474
Epoch 4/9
	 Logging train Loss: 7.103e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.912e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.966e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.848e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.868e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 57.70307540893555
Epoch 5/9
	 Logging train Loss: 6.397e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.356e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.371e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.083e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.229e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 58.844566345214844
Epoch 6/9
	 Logging train Loss: 5.797e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.17e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.165e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.832e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gTrue █▃▄▁▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gTrue █▃▄▁▁▁▁▁▁▁
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gTrue █▃▄▁▁▁▁▁▁▁
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gTrue █▃▄▁▁▁▁▂▁▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gTrue 0.0
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gTrue 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: 🚀 View run valiant-star-549 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/e1w0cks6
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_223323-e1w0cks6/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_224456-mk5ot4l5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run misunderstood-frost-551
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/mk5ot4l5
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gTrue ▆▂▁▁▂▅█▂▁▂
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gTrue ▆▂▁▁▁▅█▂▁▁
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gTrue ▆▂▁▁▂▅█▂▁▃
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gTrue ▆▂▁▁▂▅█▂▁▃
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gTrue 0.0
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gTrue 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: 🚀 View run misunderstood-frost-551 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/mk5ot4l5
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_224456-mk5ot4l5/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230716_225608-gk6m556r
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run jolly-armadillo-553
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/gk6m556r
	 Logging test loss: 2e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 58.34365129470825
Epoch 7/9
	 Logging train Loss: 5.324e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.656e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 4.466e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.385e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.531e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 58.23088812828064
Epoch 8/9
	 Logging train Loss: 5.011e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.831e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.855e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 3.822e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.825e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 58.038715839385986
Epoch 9/9
	 Logging train Loss: 4.507e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.822e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.826e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.722e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.779e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 57.9294638633728
Saved model in  trained_models/gru/data_t(5,20)_r(0,0)_combi_pNone_gTrue/'rot_mat_1'_'False'.pth
It took  693.2627577781677  seconds.
----- ITERATION 9/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gTrue took 50.30858135223389 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(0,0)_tennis_pNone_gTrue took 12.653186559677124 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_semi_pNone_gTrue took 12.619325399398804 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_full_pNone_gTrue took 12.587178945541382 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gTrue took 12.614928722381592 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 6.97083e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.0023e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.9531e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.8408e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.8226e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 56.19975399971008
Epoch 1/9
	 Logging train Loss: 2.1968e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.0184e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.0119e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 9.864e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 9.716e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 56.26009440422058
Epoch 2/9
	 Logging train Loss: 1.255e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.265e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 4.309e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 3.442e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.85e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 56.0728874206543
Epoch 3/9
	 Logging train Loss: 8.228e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.204e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.217e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.002e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.108e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 55.48569440841675
Epoch 4/9
	 Logging train Loss: 8.151e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.983e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 8.436e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.749e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 5.005e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 55.04716181755066
Epoch 5/9
	 Logging train Loss: 7.776e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.5679e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.6048e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.1827e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.3793e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 55.089877128601074
Epoch 6/9
	 Logging train Loss: 7.237e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.4238e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 4.4481e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 4.0526e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 4.2293e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 55.94800877571106
Epoch 7/9
	 Logging train Loss: 6.648e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.57e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 5.62e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 4.729e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 5.153e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 55.31402087211609
Epoch 8/9
	 Logging train Loss: 6.416e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.379e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.389e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.279e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.371e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 55.449408531188965
Epoch 9/9
	 Logging train Loss: 5.628e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.1423e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.2464e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.445e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 7.21e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 55.87926745414734
Saved model in  trained_models/gru/data_t(5,20)_r(0,0)_combi_pNone_gTrue/'rot_mat_1'_'False'.pth
It took  672.2102782726288  seconds.
----- ITERATION 10/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gTrue took 50.10430407524109 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(0,0)_tennis_pNone_gTrue took 12.655987977981567 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_semi_pNone_gTrue took 12.631861686706543 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_full_pNone_gTrue took 12.643104791641235 seconds.
The dataloader for data/data_t(5,20)_r(0,0)_combi_pNone_gTrue took 12.605002164840698 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 8.10763e-05 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.7873e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.5676e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 3.7185e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.7461e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 57.41543793678284
Epoch 1/9
	 Logging train Loss: 2.6892e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.12674e-05 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gTrue ▅█▂▁▁▂▁▂▁▁
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gTrue █▄▂▁▁▃▁▃▁▁
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gTrue ▃█▁▁▁▁▁▂▁▁
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gTrue ▃█▁▁▁▁▁▂▁▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(5,20)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(5,20)_r(0,0)_semi_pNone_gTrue 0.0
wandb: Test loss t(5,20)_r(0,0)_tennis_pNone_gTrue 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: 🚀 View run jolly-armadillo-553 at: https://wandb.ai/nreints/ThesisFinal2Grav%2Bcoll/runs/gk6m556r
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230716_225608-gk6m556r/logs
	 Logging test loss: 1.16807e-05 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.9452e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 5.9447e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 57.688133001327515
Epoch 2/9
	 Logging train Loss: 1.5234e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.083e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 6.819e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 6.734e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 6.968e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 57.438777446746826
Epoch 3/9
	 Logging train Loss: 1.0929e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.713e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.634e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 3.291e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.494e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 57.258307695388794
Epoch 4/9
	 Logging train Loss: 8.45e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.34e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.359e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.162e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.287e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 57.34438991546631
Epoch 5/9
	 Logging train Loss: 7.227e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 9.92e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 9.883e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 9.803e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 9.845e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 57.40047574043274
Epoch 6/9
	 Logging train Loss: 6.89e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.035e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 5.128e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.229e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.41e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 56.97890853881836
Epoch 7/9
	 Logging train Loss: 5.438e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.1984e-06 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.1936e-06 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.1638e-06 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.1776e-06 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 56.93597674369812
Epoch 8/9
	 Logging train Loss: 5.684e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.904e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 8.696e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.049e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 4.89e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 56.96376919746399
Epoch 9/9
	 Logging train Loss: 4.986e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.302e-07 [MSELoss(): t(5,20)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.324e-07 [MSELoss(): t(5,20)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 3.237e-07 [MSELoss(): t(5,20)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.293e-07 [MSELoss(): t(5,20)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 56.94062900543213
Saved model in  trained_models/gru/data_t(5,20)_r(0,0)_combi_pNone_gTrue/'rot_mat_1'_'False'.pth
It took  685.0303249359131  seconds.

JOB STATISTICS
==============
Job ID: 3086313
Array Job ID: 3086289_65
Cluster: snellius
User/Group: nreints/nreints
State: RUNNING
Nodes: 1
Cores per node: 18
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 1-10:12:54 core-walltime
Job Wall-clock time: 01:54:03
Memory Utilized: 0.00 MB (estimated maximum)
Memory Efficiency: 0.00% of 0.00 MB (0.00 MB/node)
WARNING: Efficiency statistics may be misleading for RUNNING jobs.
