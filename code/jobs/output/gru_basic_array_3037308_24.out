wandb: Currently logged in as: nreints. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_134800-05lle55z
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run revived-durian-655
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/05lle55z
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone █▃▄▂▃▅▂▁▁▁
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone █▂▂▁▂▄▁▁▁▁
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone █▂▂▁▂▄▁▁▁▁
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone █▃▄▂▃▆▂▁▁▁
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone █▃▄▂▃▆▂▁▁▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone 0.0
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: 🚀 View run revived-durian-655 at: https://wandb.ai/nreints/ThesisFinal2/runs/05lle55z
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_134800-05lle55z/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_135606-g2w3av9q
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run logical-water-666
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/g2w3av9q
Training on dataset: data_t(0,0)_r(5,20)_combi_pNone_gNone
Testing on 5 datasets: ['data_t(0,0)_r(5,20)_none_pNone_gNone', 'data_t(0,0)_r(5,20)_semi_pNone_gNone', 'data_t(0,0)_r(5,20)_combi_pNone_gNone', 'data_t(0,0)_r(5,20)_full_pNone_gNone', 'data_t(0,0)_r(5,20)_tennis_pNone_gNone']
Focussing on identity: True
Using extra input: False
Using fr-fr as reference point.
----- ITERATION 1/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 53.61231064796448 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(5,20)_none_pNone_gNone took 13.054444074630737 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_semi_pNone_gNone took 13.534257650375366 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 13.457728862762451 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_full_pNone_gNone took 12.9085853099823 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_tennis_pNone_gNone took 13.10039210319519 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0005914031 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.2325e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.88517e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.80173e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.1054e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.1472e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 35.39750552177429
Epoch 1/9
	 Logging train Loss: 8.6781e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.556e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 9.8894e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 5.8039e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.973e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.02468e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 35.702675580978394
Epoch 2/9
	 Logging train Loss: 5.734e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.856e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.28387e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 7.4492e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.357e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.34375e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 34.263182401657104
Epoch 3/9
	 Logging train Loss: 5.7783e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.186e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 6.8709e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.9647e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.5e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 7.146e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 35.945735454559326
Epoch 4/9
	 Logging train Loss: 5.3768e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.681e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.14607e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 6.6229e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.251e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.23613e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 34.31904363632202
Epoch 5/9
	 Logging train Loss: 4.6376e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.558e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.03822e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.17837e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.143e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.18238e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 35.403464555740356
Epoch 6/9
	 Logging train Loss: 4.4548e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.12e-08 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 4.84e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.7403e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.23e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 5.0094e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 34.40096855163574
Epoch 7/9
	 Logging train Loss: 3.7055e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.92e-08 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.6069e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.0539e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.53e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.7201e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 35.2173638343811
Epoch 8/9
	 Logging train Loss: 3.1453e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.237e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.9087e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.2535e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.063e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.1401e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 35.217690229415894
Epoch 9/9
	 Logging train Loss: 2.6684e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.7e-08 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.683e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.559e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.3e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.8411e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 34.98868942260742
Saved model in  trained_models/gru/data_t(0,0)_r(5,20)_combi_pNone_gNone/'quat_1'_'False'.pth
It took  486.97741866111755  seconds.
----- ITERATION 2/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 51.45447754859924 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(5,20)_none_pNone_gNone took 13.450810432434082 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_semi_pNone_gNone took 13.905268669128418 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 12.93301010131836 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_full_pNone_gNone took 13.091712236404419 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_tennis_pNone_gNone took 12.937161684036255 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0004734688 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.592e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.28046e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.50764e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.012e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.34791e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 35.69381856918335
Epoch 1/9
	 Logging train Loss: 8.1015e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.165e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.24974e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 6.6559e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone █▄▄▂▂▂▂▄▁▁
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone █▃▃▁▁▁▁▄▁▁
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone █▃▃▂▁▂▁▄▁▁
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone █▅▅▃▂▂▂▅▂▁
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone █▅▅▃▂▂▂▅▂▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone 0.0
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: 🚀 View run logical-water-666 at: https://wandb.ai/nreints/ThesisFinal2/runs/g2w3av9q
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_135606-g2w3av9q/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_140411-gilferm9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run winter-deluge-675
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/gilferm9
	 Logging test loss: 2.741e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.32324e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 35.148866415023804
Epoch 2/9
	 Logging train Loss: 6.6671e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.074e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.3162e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 6.8331e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.716e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.40963e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 35.47044062614441
Epoch 3/9
	 Logging train Loss: 6.1648e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.132e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 6.8256e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.5792e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.69e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 6.9795e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 35.54675579071045
Epoch 4/9
	 Logging train Loss: 5.8883e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.77e-08 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 5.3795e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.7821e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.44e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 5.4225e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 35.16579008102417
Epoch 5/9
	 Logging train Loss: 5.0258e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.149e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 6.1619e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.1369e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.74e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 6.34e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 35.76532697677612
Epoch 6/9
	 Logging train Loss: 4.354e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.46e-08 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 4.2585e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.1782e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.06e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.3184e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 35.09258222579956
Epoch 7/9
	 Logging train Loss: 3.797e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.085e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.30419e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 6.5997e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.028e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.40336e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 36.0463125705719
Epoch 8/9
	 Logging train Loss: 3.0883e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 9.53e-08 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.6303e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.8713e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.35e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.7724e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 34.57671880722046
Epoch 9/9
	 Logging train Loss: 2.5494e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.51e-08 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.0902e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.0828e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.66e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.1764e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 36.661776065826416
Saved model in  trained_models/gru/data_t(0,0)_r(5,20)_combi_pNone_gNone/'quat_1'_'False'.pth
It took  484.7675335407257  seconds.
----- ITERATION 3/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 51.363067388534546 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(5,20)_none_pNone_gNone took 13.422530889511108 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_semi_pNone_gNone took 13.10099172592163 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 12.71655535697937 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_full_pNone_gNone took 13.108846426010132 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_tennis_pNone_gNone took 12.922055006027222 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0004854228 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.0501e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.40247e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.55909e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 9.544e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.43129e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 35.9492826461792
Epoch 1/9
	 Logging train Loss: 8.4183e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.443e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 9.4888e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 5.3102e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.765e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 9.0764e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 34.72173523902893
Epoch 2/9
	 Logging train Loss: 6.4717e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.838e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.27872e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 7.0573e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.345e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.29151e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 36.30821776390076
Epoch 3/9
	 Logging train Loss: 6.3028e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.191e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 7.7794e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.2229e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.47e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 7.4864e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 34.45077919960022
Epoch 4/9
	 Logging train Loss: 5.4925e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.301e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.11872e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 6.2107e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.01e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.15641e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 36.27578115463257
Epoch 5/9
	 Logging train Loss: 5.1161e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.04e-08 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 5.6205e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.0242e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone █▃▄▂▃▂▃▂▁▁
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone █▂▂▁▂▁▃▂▁▁
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone █▂▃▁▂▁▃▂▁▁
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone █▃▄▃▄▂▄▂▁▁
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone █▃▄▃▄▂▄▃▁▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone 0.0
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: 🚀 View run winter-deluge-675 at: https://wandb.ai/nreints/ThesisFinal2/runs/gilferm9
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_140411-gilferm9/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_141215-q8l0ks2w
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run zesty-universe-681
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/q8l0ks2w
	 Logging test loss: 4.8e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 5.3544e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 34.63815093040466
Epoch 6/9
	 Logging train Loss: 4.1881e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.787e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.04477e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 5.734e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.615e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.06911e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 35.72762894630432
Epoch 7/9
	 Logging train Loss: 3.782e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.827e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 7.3335e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.9857e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.652e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 7.5973e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 35.18992209434509
Epoch 8/9
	 Logging train Loss: 2.9082e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.73e-08 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.3736e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.8295e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.47e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.3304e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 35.52293348312378
Epoch 9/9
	 Logging train Loss: 2.5082e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.47e-08 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.8285e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.5621e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.66e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.8804e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 35.43077611923218
Saved model in  trained_models/gru/data_t(0,0)_r(5,20)_combi_pNone_gNone/'quat_1'_'False'.pth
It took  483.82395815849304  seconds.
----- ITERATION 4/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 51.82287096977234 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(5,20)_none_pNone_gNone took 13.032963514328003 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_semi_pNone_gNone took 12.980421543121338 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 12.76913046836853 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_full_pNone_gNone took 13.348170518875122 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_tennis_pNone_gNone took 13.724714517593384 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0004875467 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 9.717e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.8136e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.21027e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.727e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.74073e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 34.62624549865723
Epoch 1/9
	 Logging train Loss: 8.6925e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.335e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.05649e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 5.3221e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.664e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.00541e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 35.92987132072449
Epoch 2/9
	 Logging train Loss: 7.6166e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.524e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.04356e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.9724e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.91e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.01354e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 35.28643536567688
Epoch 3/9
	 Logging train Loss: 7.274e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.478e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 7.5384e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.5393e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 9.72e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 7.0548e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 35.24218249320984
Epoch 4/9
	 Logging train Loss: 6.5914e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.543e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.81527e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 8.5241e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.938e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.87833e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 35.56559896469116
Epoch 5/9
	 Logging train Loss: 5.273e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.766e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 8.4146e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.9364e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.343e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 8.2816e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 35.11021184921265
Epoch 6/9
	 Logging train Loss: 4.6881e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.229e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 6.3648e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.9376e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 9.03e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 6.1379e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 36.11091136932373
Epoch 7/9
	 Logging train Loss: 4.0931e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 9.21e-08 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 4.709e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.1579e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.66e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.4668e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 34.70884895324707
Epoch 8/9
	 Logging train Loss: 3.3615e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.252e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 4.1643e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.9758e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.045e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.0992e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 36.42891573905945
Epoch 9/9
	 Logging train Loss: 2.6516e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.085e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.2371e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.518e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone █▄▃▂▆▃▂▁▁▁
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone █▃▂▁▄▂▁▁▁▁
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone █▃▂▁▄▂▁▁▁▁
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone █▄▄▃█▃▂▂▁▁
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone ▇▄▄▃█▃▂▂▁▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone 0.0
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: 🚀 View run zesty-universe-681 at: https://wandb.ai/nreints/ThesisFinal2/runs/q8l0ks2w
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_141215-q8l0ks2w/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_142017-jkzwefzt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run daily-silence-690
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/jkzwefzt
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone █▄▂▃▃▃▇▂▁▁
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone █▃▁▂▂▂▆▂▁▁
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone █▃▁▂▂▂▅▂▁▁
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone █▄▃▃▃▄█▂▁▁
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone ▇▄▂▃▃▃█▂▁▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone 0.0
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: 🚀 View run daily-silence-690 at: https://wandb.ai/nreints/ThesisFinal2/runs/jkzwefzt
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_142017-jkzwefzt/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_142820-le226u6p
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run peachy-salad-699
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/le226u6p
	 Logging test loss: 9.32e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.1732e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 34.52288293838501
Saved model in  trained_models/gru/data_t(0,0)_r(5,20)_combi_pNone_gNone/'quat_1'_'False'.pth
It took  482.07839465141296  seconds.
----- ITERATION 5/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 51.8684184551239 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(5,20)_none_pNone_gNone took 13.07349944114685 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_semi_pNone_gNone took 13.026359796524048 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 12.928696632385254 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_full_pNone_gNone took 13.357557773590088 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_tennis_pNone_gNone took 13.070998668670654 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0006219529 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.2149e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.56925e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.51515e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.1149e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.63799e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 34.769718170166016
Epoch 1/9
	 Logging train Loss: 8.2874e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.81e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.32469e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 6.5908e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.181e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.32959e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 36.55833196640015
Epoch 2/9
	 Logging train Loss: 6.1627e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.454e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 8.2196e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.8644e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.92e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 7.8653e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 34.70753192901611
Epoch 3/9
	 Logging train Loss: 6.244e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.227e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.08858e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 5.1011e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.75e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.10002e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 36.7654664516449
Epoch 4/9
	 Logging train Loss: 6.0456e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.141e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 9.3872e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.4184e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.697e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 9.3658e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 34.3720383644104
Epoch 5/9
	 Logging train Loss: 5.2332e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.041e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.16568e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 5.4741e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.637e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.1839e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 36.300880908966064
Epoch 6/9
	 Logging train Loss: 4.7749e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.968e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.67738e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.3538e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.596e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.8549e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 34.876585960388184
Epoch 7/9
	 Logging train Loss: 4.0169e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.731e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 7.0732e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.2998e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.463e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 7.1264e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 35.790175914764404
Epoch 8/9
	 Logging train Loss: 3.43e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.6e-08 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 4.1529e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.9516e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.53e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.1493e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 35.722484827041626
Epoch 9/9
	 Logging train Loss: 2.8171e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.84e-08 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.1473e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.487e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.41e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.1815e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 35.565189838409424
Saved model in  trained_models/gru/data_t(0,0)_r(5,20)_combi_pNone_gNone/'quat_1'_'False'.pth
It took  483.87869906425476  seconds.
----- ITERATION 6/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 50.28718614578247 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(5,20)_none_pNone_gNone took 13.147271871566772 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_semi_pNone_gNone took 13.472905158996582 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 12.983077764511108 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_full_pNone_gNone took 12.847708225250244 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_tennis_pNone_gNone took 12.840061902999878 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0014172175 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.689e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 6.60386e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.72033e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.3962e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 7.37544e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 35.50273513793945
Epoch 1/9
	 Logging train Loss: 1.71095e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.793e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.12934e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 7.9554e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone █▂▁▂▂▁▁▁▂▁
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone █▂▁▂▂▁▁▁▂▁
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone █▂▁▂▂▁▁▁▂▁
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone █▂▁▂▂▁▁▁▂▁
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone █▂▁▂▂▁▁▁▂▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone 1e-05
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone 1e-05
wandb:                                  Train loss 0.0
wandb: 
wandb: 🚀 View run peachy-salad-699 at: https://wandb.ai/nreints/ThesisFinal2/runs/le226u6p
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_142820-le226u6p/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_143624-wlm4mobt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run honest-fire-705
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/wlm4mobt
	 Logging test loss: 4.027e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.23198e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 35.46986389160156
Epoch 2/9
	 Logging train Loss: 4.7703e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.175e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 7.7163e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 5.2309e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.606e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 8.4027e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 35.514060258865356
Epoch 3/9
	 Logging train Loss: 4.4104e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.231e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.21069e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 8.0559e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.616e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.34945e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 35.46283197402954
Epoch 4/9
	 Logging train Loss: 4.4872e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.475e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.33658e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 8.7167e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.888e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.51035e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 34.92952561378479
Epoch 5/9
	 Logging train Loss: 4.5389e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.616e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 7.2085e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.7732e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.161e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 7.9569e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 35.9273841381073
Epoch 6/9
	 Logging train Loss: 4.7994e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.246e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 6.1276e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.035e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.48e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 6.6593e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 34.68773937225342
Epoch 7/9
	 Logging train Loss: 4.1912e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.873e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 7.1175e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.6486e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.478e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 7.884e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 36.42045998573303
Epoch 8/9
	 Logging train Loss: 3.9923e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.334e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.44451e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 9.2768e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.787e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.67292e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 34.50448536872864
Epoch 9/9
	 Logging train Loss: 3.5387e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.052e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 6.3021e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.0646e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.748e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 7.0047e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 36.4310245513916
Saved model in  trained_models/gru/data_t(0,0)_r(5,20)_combi_pNone_gNone/'quat_1'_'False'.pth
It took  483.0439772605896  seconds.
----- ITERATION 7/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 51.036221981048584 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(5,20)_none_pNone_gNone took 13.053491115570068 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_semi_pNone_gNone took 12.91963815689087 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 12.694413900375366 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_full_pNone_gNone took 12.943507671356201 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_tennis_pNone_gNone took 12.871782541275024 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0005697721 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.0676e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.51307e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.97051e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 9.481e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.86001e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 36.09277677536011
Epoch 1/9
	 Logging train Loss: 9.405e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.311e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.0899e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 5.9868e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.78e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.15809e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 34.77770638465881
Epoch 2/9
	 Logging train Loss: 6.438e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.902e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.13801e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 6.2625e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.458e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.23995e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 36.52603101730347
Epoch 3/9
	 Logging train Loss: 5.2507e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.093e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 6.9666e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.8013e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.52e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 7.4178e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 34.07424235343933
Epoch 4/9
	 Logging train Loss: 5.1304e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.583e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 9.0979e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.9329e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.235e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 9.7215e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 35.914050579071045
Epoch 5/9
	 Logging train Loss: 5.0617e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.069e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 8.429e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.5405e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone █▃▃▂▂▂▃▂▁▁
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone █▂▂▁▃▂▂▁▁▁
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone █▂▂▁▃▂▂▁▁▁
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone █▃▃▂▂▂▃▂▁▁
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone █▃▃▂▂▂▃▂▁▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone 0.0
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: 🚀 View run honest-fire-705 at: https://wandb.ai/nreints/ThesisFinal2/runs/wlm4mobt
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_143624-wlm4mobt/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_144426-4hyawqqi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run still-gorge-714
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/4hyawqqi
	 Logging test loss: 1.775e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 9.1822e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 34.76384997367859
Epoch 6/9
	 Logging train Loss: 4.2498e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.688e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.03826e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 5.5956e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.442e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.14956e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 35.613693714141846
Epoch 7/9
	 Logging train Loss: 3.6438e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.299e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 5.8804e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.1729e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.106e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 6.4956e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 35.20833706855774
Epoch 8/9
	 Logging train Loss: 3.4744e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.222e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 4.597e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.4776e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.073e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 5.0462e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 35.17028570175171
Epoch 9/9
	 Logging train Loss: 2.3435e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 9.81e-08 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.1658e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.7283e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.87e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.4807e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 36.07958364486694
Saved model in  trained_models/gru/data_t(0,0)_r(5,20)_combi_pNone_gNone/'quat_1'_'False'.pth
It took  482.0873668193817  seconds.
----- ITERATION 8/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 51.61392402648926 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(5,20)_none_pNone_gNone took 12.957432985305786 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_semi_pNone_gNone took 12.894858121871948 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 12.928938388824463 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_full_pNone_gNone took 13.098418235778809 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_tennis_pNone_gNone took 13.151353359222412 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0006782552 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.289e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.87979e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.08635e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.1435e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.21079e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 35.19435691833496
Epoch 1/9
	 Logging train Loss: 8.4523e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.234e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 8.9572e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.4285e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.648e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 9.0368e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 35.63467717170715
Epoch 2/9
	 Logging train Loss: 4.8736e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.306e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.01479e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 5.0199e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.749e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.07865e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 35.532405614852905
Epoch 3/9
	 Logging train Loss: 5.0908e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.747e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.49227e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 7.5026e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.134e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.65617e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 35.0562481880188
Epoch 4/9
	 Logging train Loss: 5.2456e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.122e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 7.3829e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.5957e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.704e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 7.5839e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 35.67534565925598
Epoch 5/9
	 Logging train Loss: 4.9096e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.275e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 6.5899e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.2225e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.91e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 6.8677e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 34.81096911430359
Epoch 6/9
	 Logging train Loss: 4.3729e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.34e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 6.3687e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.1212e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.009e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 6.6891e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 36.51279282569885
Epoch 7/9
	 Logging train Loss: 3.9615e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 9.74e-08 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 4.8638e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.3977e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.99e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 5.0531e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 34.4147834777832
Epoch 8/9
	 Logging train Loss: 3.4483e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.859e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 6.0918e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.1384e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.578e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 6.7617e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 36.59138822555542
Epoch 9/9
	 Logging train Loss: 2.6582e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.18e-08 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.1457e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.5717e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone █▂▂▃▂▂▂▁▂▁
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone █▂▂▃▂▁▁▁▂▁
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone █▂▂▃▂▁▁▁▂▁
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone █▂▂▃▂▂▂▁▂▁
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone █▂▂▃▂▂▂▁▂▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone 0.0
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: 🚀 View run still-gorge-714 at: https://wandb.ai/nreints/ThesisFinal2/runs/4hyawqqi
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_144426-4hyawqqi/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_145234-9wcz8pol
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fluent-water-720
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/9wcz8pol
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone █▇▄▄▂█▂▂▁▂
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone █▆▃▃▁█▂▂▁▂
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone █▇▃▃▂▇▂▂▁▂
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone ▅▇▄▄▂█▂▂▁▂
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone ▄▇▄▄▂█▂▂▁▂
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone 0.0
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone 1e-05
wandb:                                  Train loss 0.0
wandb: 
wandb: 🚀 View run fluent-water-720 at: https://wandb.ai/nreints/ThesisFinal2/runs/9wcz8pol
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_145234-9wcz8pol/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_150036-kxc1ckdm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run worthy-spaceship-729
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/kxc1ckdm
	 Logging test loss: 5.6e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.3643e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 34.135355949401855
Saved model in  trained_models/gru/data_t(0,0)_r(5,20)_combi_pNone_gNone/'quat_1'_'False'.pth
It took  487.9767553806305  seconds.
----- ITERATION 9/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 51.501625061035156 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(5,20)_none_pNone_gNone took 13.03304386138916 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_semi_pNone_gNone took 13.114956378936768 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 12.927769184112549 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_full_pNone_gNone took 13.031506538391113 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_tennis_pNone_gNone took 13.022432088851929 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0004821883 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.923e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.30077e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.04066e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.103e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.38443e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 34.64118313789368
Epoch 1/9
	 Logging train Loss: 1.06189e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.564e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.88552e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 9.7371e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.846e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.06294e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 36.258880615234375
Epoch 2/9
	 Logging train Loss: 7.9196e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.55e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.09991e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 5.4534e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.008e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.19125e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 34.42173194885254
Epoch 3/9
	 Logging train Loss: 7.2971e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.624e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.1513e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 5.6851e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.119e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.24725e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 36.59423279762268
Epoch 4/9
	 Logging train Loss: 5.9916e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.187e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 6.0193e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.9044e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.93e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 6.2556e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 33.97734498977661
Epoch 5/9
	 Logging train Loss: 5.5618e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.266e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.14949e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.04588e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.784e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.50271e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 35.86472749710083
Epoch 6/9
	 Logging train Loss: 4.5488e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.25e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 4.7083e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.2837e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 9.68e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.965e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 34.78156352043152
Epoch 7/9
	 Logging train Loss: 3.6765e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.808e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 5.7578e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.7443e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.567e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 6.2745e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 36.065486431121826
Epoch 8/9
	 Logging train Loss: 3.1449e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.65e-08 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.6872e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.2845e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.15e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.8536e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 35.63145041465759
Epoch 9/9
	 Logging train Loss: 2.4633e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.695e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 4.4269e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.1954e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.567e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 5.022e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 35.354140758514404
Saved model in  trained_models/gru/data_t(0,0)_r(5,20)_combi_pNone_gNone/'quat_1'_'False'.pth
It took  482.1491448879242  seconds.
----- ITERATION 10/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 50.73869204521179 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(5,20)_none_pNone_gNone took 12.904096126556396 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_semi_pNone_gNone took 12.861932039260864 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 12.708108186721802 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_full_pNone_gNone took 12.788901329040527 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_tennis_pNone_gNone took 12.84718370437622 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0004393883 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.2604e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 6.07437e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.57841e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.1912e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 7.40824e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 34.79702019691467
Epoch 1/9
	 Logging train Loss: 9.9598e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.145e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.00759e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.09758e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone █▃▁▂▁▂▃▁▁▁
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone █▃▁▁▁▂▃▁▁▁
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone █▃▁▁▁▂▃▁▁▁
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone █▃▂▂▁▂▃▁▁▁
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone █▃▁▂▁▂▃▁▁▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone 0.0
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: 🚀 View run worthy-spaceship-729 at: https://wandb.ai/nreints/ThesisFinal2/runs/kxc1ckdm
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_150036-kxc1ckdm/logs
	 Logging test loss: 5.461e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.382e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 34.79929184913635
Epoch 2/9
	 Logging train Loss: 8.1045e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.599e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 7.8459e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.9182e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 9.48e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 8.4501e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 34.85383582115173
Epoch 3/9
	 Logging train Loss: 7.0378e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.065e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 9.5629e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.9647e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.546e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.0889e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 35.145007371902466
Epoch 4/9
	 Logging train Loss: 6.424e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.028e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 6.0574e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.0197e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.57e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 6.6199e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 34.185941219329834
Epoch 5/9
	 Logging train Loss: 5.1609e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.766e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.10148e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 5.8518e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.436e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.29302e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 35.75662302970886
Epoch 6/9
	 Logging train Loss: 4.2767e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.481e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.29667e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 1.24435e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.32e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.77118e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 34.02028560638428
Epoch 7/9
	 Logging train Loss: 3.5359e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.201e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 7.7129e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 4.1283e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.036e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 9.2286e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 35.74572443962097
Epoch 8/9
	 Logging train Loss: 2.9571e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.83e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 6.4652e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 3.5063e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.687e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 7.733e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 33.64680790901184
Epoch 9/9
	 Logging train Loss: 2.3744e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.705e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.7469e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 2.0147e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.599e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.35e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
		--> Epoch time; 34.83199429512024
Saved model in  trained_models/gru/data_t(0,0)_r(5,20)_combi_pNone_gNone/'quat_1'_'False'.pth
It took  474.9435131549835  seconds.

JOB STATISTICS
==============
Job ID: 3037314
Array Job ID: 3037308_24
Cluster: snellius
User/Group: nreints/nreints
State: COMPLETED (exit code 0)
Nodes: 1
Cores per node: 18
CPU Utilized: 01:29:09
CPU Efficiency: 6.13% of 1-00:14:42 core-walltime
Job Wall-clock time: 01:20:49
Memory Utilized: 7.98 GB
Memory Efficiency: 0.00% of 0.00 MB
