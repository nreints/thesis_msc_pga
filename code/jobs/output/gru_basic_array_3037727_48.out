wandb: Currently logged in as: nreints. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_165458-wb3kallf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hopeful-yogurt-762
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/wb3kallf
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue â–ˆâ–‚â–â–…â–â–â–â–â–†â–
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue â–ˆâ–‚â–â–‚â–â–â–â–â–â–
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue â–†â–â–â–‡â–â–â–â–â–ˆâ–
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue â–†â–â–â–‡â–â–â–â–â–ˆâ–
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue 0.0
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue 0.0
wandb:                                 Train loss 0.0
wandb: 
wandb: ðŸš€ View run hopeful-yogurt-762 at: https://wandb.ai/nreints/ThesisFinal2/runs/wb3kallf
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_165458-wb3kallf/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_170232-u1amk21o
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run proud-sound-775
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/u1amk21o
Training on dataset: data_t(0,0)_r(0,0)_combi_pNone_gTrue
Testing on 4 datasets: ['data_t(0,0)_r(0,0)_full_pNone_gTrue', 'data_t(0,0)_r(0,0)_semi_pNone_gTrue', 'data_t(0,0)_r(0,0)_tennis_pNone_gTrue', 'data_t(0,0)_r(0,0)_combi_pNone_gTrue']
Focussing on identity: True
Using extra input: False
Using fr-fr as reference point.
----- ITERATION 1/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 52.36735558509827 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_full_pNone_gTrue took 13.096404075622559 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pNone_gTrue took 13.089478731155396 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pNone_gTrue took 13.150514125823975 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 13.578998565673828 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0002551146 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.3954e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 4.6415e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 4.6743e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 4.5171e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 34.85738921165466
Epoch 1/9
	 Logging train Loss: 1.941e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.234e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 4.652e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 4.684e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 4.44e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 33.287890911102295
Epoch 2/9
	 Logging train Loss: 3.156e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.564e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 3.057e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.78e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 33.14478516578674
Epoch 3/9
	 Logging train Loss: 1.424e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.144e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 5.4525e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 5.6526e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.7847e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 33.024373292922974
Epoch 4/9
	 Logging train Loss: 1.7195e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.57e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.905e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 4e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.787e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 33.10687565803528
Epoch 5/9
	 Logging train Loss: 1.927e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 9.88e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.214e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.228e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.107e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 33.29134654998779
Epoch 6/9
	 Logging train Loss: 1.4274e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.07e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.317e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.358e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 9.74e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 32.98468899726868
Epoch 7/9
	 Logging train Loss: 1.4674e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.86e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.05e-08 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 3.06e-08 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.95e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 33.05772805213928
Epoch 8/9
	 Logging train Loss: 1.0886e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.923e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 6.8042e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 6.6572e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.3141e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 33.02152991294861
Epoch 9/9
	 Logging train Loss: 1.0643e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.1e-09 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 9.65e-08 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.034e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 5.54e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 33.066566467285156
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'dual_quat_1'_'False'.pth
It took  455.24784779548645  seconds.
----- ITERATION 2/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 47.570167779922485 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_full_pNone_gTrue took 12.192314863204956 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pNone_gTrue took 12.243364334106445 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pNone_gTrue took 12.24388337135315 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 12.032264947891235 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.000102364 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.27e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 8.731e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 8.787e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 8.519e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 33.32351279258728
Epoch 1/9
	 Logging train Loss: 1.1862e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.245e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.406e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.424e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.331e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 33.31807899475098
Epoch 2/9
	 Logging train Loss: 1.0881e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.8464e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.04913e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.26592e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.13127e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 33.35788702964783
Epoch 3/9
	 Logging train Loss: 1.7562e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.2e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.646e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.658e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.12e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 33.48858404159546
Epoch 4/9
	 Logging train Loss: 1.2169e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.202e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue â–‚â–â–ˆâ–â–‚â–â–ˆâ–‚â–â–
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue â–„â–‚â–‡â–â–â–â–ˆâ–â–â–
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue â–â–â–ˆâ–â–‚â–â–ˆâ–‚â–â–
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue â–â–â–ˆâ–â–‚â–â–ˆâ–‚â–â–
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue 0.0
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue 0.0
wandb:                                 Train loss 0.0
wandb: 
wandb: ðŸš€ View run proud-sound-775 at: https://wandb.ai/nreints/ThesisFinal2/runs/u1amk21o
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_170232-u1amk21o/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_170954-tv6648ow
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ruby-snowflake-790
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/tv6648ow
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue â–ˆâ–ƒâ–â–â–„â–â–‚â–â–â–
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue â–ˆâ–ƒâ–â–â–‚â–â–â–â–â–
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue â–ˆâ–ƒâ–â–â–†â–â–‚â–â–â–
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue â–ˆâ–ƒâ–â–â–†â–â–‚â–â–â–
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue 0.0
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue 0.0
wandb:                                 Train loss 0.0
wandb: 
wandb: ðŸš€ View run ruby-snowflake-790 at: https://wandb.ai/nreints/ThesisFinal2/runs/tv6648ow
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_170954-tv6648ow/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_171712-51wsk4zv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ethereal-lake-805
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/51wsk4zv
	 Logging test loss: 3.7523e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 3.8795e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.8538e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 33.41932153701782
Epoch 5/9
	 Logging train Loss: 1.1857e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.6e-09 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 9.5e-09 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 9.9e-09 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 7.1e-09 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 33.43477511405945
Epoch 6/9
	 Logging train Loss: 1.0013e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.0938e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.16261e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.15961e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.13491e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 33.2896728515625
Epoch 7/9
	 Logging train Loss: 6.85e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.421e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.8351e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 3.1042e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.5373e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 33.415207624435425
Epoch 8/9
	 Logging train Loss: 6.69e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5e-10 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1e-09 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.1e-09 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 8e-10 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 33.36695218086243
Epoch 9/9
	 Logging train Loss: 4.971e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 9e-10 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3e-09 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 3.2e-09 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2e-09 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 33.396130323410034
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'dual_quat_1'_'False'.pth
It took  441.97691655158997  seconds.
----- ITERATION 3/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 45.83153486251831 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_full_pNone_gTrue took 12.071827173233032 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pNone_gTrue took 12.04473876953125 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pNone_gTrue took 12.077040910720825 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 11.808381080627441 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0004174781 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.0461e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 6.4288e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 6.4513e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 6.2172e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 33.45331001281738
Epoch 1/9
	 Logging train Loss: 3.7507e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.4899e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.801e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.8187e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.6269e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 33.45268726348877
Epoch 2/9
	 Logging train Loss: 1.023e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.909e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 4.614e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 4.662e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 4.214e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 33.22218322753906
Epoch 3/9
	 Logging train Loss: 1.9006e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.19e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.328e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 3.339e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.252e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 33.165754079818726
Epoch 4/9
	 Logging train Loss: 2.0274e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.2141e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 4.1791e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 4.2915e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.5499e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 32.97322630882263
Epoch 5/9
	 Logging train Loss: 1.6812e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.987e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.04e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.043e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.011e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 33.14683389663696
Epoch 6/9
	 Logging train Loss: 1.5679e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.445e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.0707e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.1612e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 5.97e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 33.4053316116333
Epoch 7/9
	 Logging train Loss: 2.1408e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 9.26e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 9.61e-08 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 9.63e-08 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 9.42e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 33.11607313156128
Epoch 8/9
	 Logging train Loss: 1.1828e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.24e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 5.52e-08 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 5.54e-08 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 5.37e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 33.22803831100464
Epoch 9/9
	 Logging train Loss: 8.319e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.87e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.31e-08 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 3.33e-08 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.08e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 33.24388790130615
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'dual_quat_1'_'False'.pth
It took  437.8759217262268  seconds.
----- ITERATION 4/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 46.30118441581726 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_full_pNone_gTrue took 12.082435131072998 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pNone_gTrue took 12.05625295639038 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pNone_gTrue took 12.074751138687134 seconds.
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue â–ˆâ–ƒâ–‚â–â–â–â–â–‚â–â–‚
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue â–ˆâ–ƒâ–â–â–â–â–â–â–â–
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue â–ˆâ–ƒâ–‚â–â–â–â–â–ƒâ–â–‚
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue â–ˆâ–ƒâ–‚â–â–â–â–â–ƒâ–â–‚
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue 0.0
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue 0.0
wandb:                                 Train loss 0.0
wandb: 
wandb: ðŸš€ View run ethereal-lake-805 at: https://wandb.ai/nreints/ThesisFinal2/runs/51wsk4zv
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_171712-51wsk4zv/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_172433-0qys07ao
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run crimson-bush-822
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/0qys07ao
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 11.889333248138428 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0003789075 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.3677e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 6.4425e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 6.4432e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 6.4066e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 33.525967836380005
Epoch 1/9
	 Logging train Loss: 4.0054e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.8391e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.9233e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.9316e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.8839e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 33.267582654953
Epoch 2/9
	 Logging train Loss: 1.0233e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.129e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 8.488e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 8.645e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 6.357e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 33.36325812339783
Epoch 3/9
	 Logging train Loss: 7.521e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.07e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.135e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 3.139e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.104e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 33.58347821235657
Epoch 4/9
	 Logging train Loss: 1.3812e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.528e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.584e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.588e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.557e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 33.3789644241333
Epoch 5/9
	 Logging train Loss: 2.5357e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.98e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.033e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.038e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.009e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 33.42859721183777
Epoch 6/9
	 Logging train Loss: 8.352e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.541e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.03e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.063e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.798e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 33.479393005371094
Epoch 7/9
	 Logging train Loss: 7.975e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.564e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.8629e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.9834e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.143e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 33.57981896400452
Epoch 8/9
	 Logging train Loss: 1.3989e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.72e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 5.24e-08 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 5.28e-08 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 5e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 33.46876239776611
Epoch 9/9
	 Logging train Loss: 7.842e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.485e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.3419e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.3965e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 8.119e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 33.63779973983765
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'dual_quat_1'_'False'.pth
It took  441.3987445831299  seconds.
----- ITERATION 5/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 46.131322383880615 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_full_pNone_gTrue took 12.063534021377563 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pNone_gTrue took 12.04018783569336 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pNone_gTrue took 12.028947353363037 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 11.796363830566406 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0003661149 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.6443e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 5.9584e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 5.9869e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 5.7987e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 33.5679395198822
Epoch 1/9
	 Logging train Loss: 2.8492e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.228e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 8.756e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 8.88e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 7.972e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 33.28579616546631
Epoch 2/9
	 Logging train Loss: 4.599e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.388e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.541e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 3.556e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.465e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 33.354623794555664
Epoch 3/9
	 Logging train Loss: 9.505e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.045e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 5.718e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 5.913e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 4.483e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 33.248788833618164
Epoch 4/9
	 Logging train Loss: 1.2025e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.616e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.666e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.669e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.643e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 33.514803886413574
Epoch 5/9
	 Logging train Loss: 1.3255e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.96e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.082e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.082e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 9.91e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 33.585097551345825
Epoch 6/9
	 Logging train Loss: 1.439e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.0467e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue â–ˆâ–‚â–â–‚â–â–â–„â–â–â–
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue â–ˆâ–‚â–â–â–â–â–‚â–â–â–
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue â–ˆâ–‚â–â–‚â–â–â–†â–â–â–
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue â–ˆâ–‚â–â–‚â–â–â–†â–â–â–
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue 0.0
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue 0.0
wandb:                                 Train loss 0.0
wandb: 
wandb: ðŸš€ View run crimson-bush-822 at: https://wandb.ai/nreints/ThesisFinal2/runs/0qys07ao
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_172433-0qys07ao/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_173154-8lvyzr79
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hardy-waterfall-843
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/8lvyzr79
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue â–ˆâ–‚â–‚â–â–‚â–â–‚â–â–ƒâ–
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue â–ˆâ–‚â–â–â–â–â–â–â–ƒâ–
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue â–ˆâ–‚â–‚â–â–‚â–â–‚â–‚â–„â–
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue â–ˆâ–‚â–‚â–â–‚â–â–‚â–‚â–„â–
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue 0.0
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue 0.0
wandb:                                 Train loss 0.0
wandb: 
wandb: ðŸš€ View run hardy-waterfall-843 at: https://wandb.ai/nreints/ThesisFinal2/runs/8lvyzr79
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_173154-8lvyzr79/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_173916-rquzxoqb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run devoted-puddle-858
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/rquzxoqb
	 Logging test loss: 4.3037e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 4.3339e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.7487e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 33.35255527496338
Epoch 7/9
	 Logging train Loss: 1.6565e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.29e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.46e-08 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.47e-08 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.38e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 33.686301946640015
Epoch 8/9
	 Logging train Loss: 6.63e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.54e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.507e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.588e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.184e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 33.12987804412842
Epoch 9/9
	 Logging train Loss: 1.1228e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.1e-09 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.9e-09 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.9e-09 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.5e-09 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 33.40415024757385
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'dual_quat_1'_'False'.pth
It took  440.9191925525665  seconds.
----- ITERATION 6/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 47.90914607048035 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_full_pNone_gTrue took 12.098369359970093 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pNone_gTrue took 12.174880981445312 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pNone_gTrue took 12.129791021347046 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 12.002138614654541 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0003239461 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.2214e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 4.412e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 4.4455e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 4.323e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 33.139638900756836
Epoch 1/9
	 Logging train Loss: 1.6456e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.859e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 4.113e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 4.176e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 4.002e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 33.777968406677246
Epoch 2/9
	 Logging train Loss: 3.782e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.897e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.609e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 3.774e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.284e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 33.50608706474304
Epoch 3/9
	 Logging train Loss: 6.75e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.664e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.768e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.8e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.723e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 33.264944314956665
Epoch 4/9
	 Logging train Loss: 1.3305e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.523e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 5.453e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 6.353e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.634e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 33.23434352874756
Epoch 5/9
	 Logging train Loss: 1.0215e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.03e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 8.99e-08 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 9.5e-08 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 8.11e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 33.43539333343506
Epoch 6/9
	 Logging train Loss: 9.335e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.571e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 5.417e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 6.337e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.649e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 33.27551984786987
Epoch 7/9
	 Logging train Loss: 1.2838e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.02e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.775e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 4.157e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.045e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 33.47980046272278
Epoch 8/9
	 Logging train Loss: 8.109e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.0709e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.6912e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.8883e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.4237e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 33.403857707977295
Epoch 9/9
	 Logging train Loss: 8.637e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.6e-09 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 4.4e-09 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 4.5e-09 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 4e-09 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 33.31550645828247
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'dual_quat_1'_'False'.pth
It took  442.0017547607422  seconds.
----- ITERATION 7/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 45.83184361457825 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_full_pNone_gTrue took 11.99499249458313 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pNone_gTrue took 11.943753480911255 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pNone_gTrue took 11.936770915985107 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 11.636464357376099 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0003392664 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.282e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 5.5052e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 5.5414e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 5.4057e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 33.321253061294556
Epoch 1/9
	 Logging train Loss: 2.8481e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue â–ƒâ–â–â–â–â–â–â–ˆâ–â–
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue â–ˆâ–‚â–â–â–â–â–â–„â–â–
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue â–‚â–â–â–â–â–â–â–ˆâ–â–
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue â–‚â–â–â–â–â–â–â–ˆâ–â–
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue 0.0
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue 0.0
wandb:                                 Train loss 0.0
wandb: 
wandb: ðŸš€ View run devoted-puddle-858 at: https://wandb.ai/nreints/ThesisFinal2/runs/rquzxoqb
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_173916-rquzxoqb/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_174636-bfczcu74
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run swift-lion-879
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/bfczcu74
	 Logging test loss: 8.894e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 9.952e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.0162e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 9.486e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 33.82986330986023
Epoch 2/9
	 Logging train Loss: 6.266e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.548e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 7.873e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 8.343e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 5.697e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 33.340293407440186
Epoch 3/9
	 Logging train Loss: 1.2162e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.317e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.846e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.926e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.593e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 33.27878975868225
Epoch 4/9
	 Logging train Loss: 9.93e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.759e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.856e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.87e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.809e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 33.38546323776245
Epoch 5/9
	 Logging train Loss: 1.7409e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.292e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.4e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.415e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.348e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 33.3453266620636
Epoch 6/9
	 Logging train Loss: 1.8469e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.022e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.9644e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.216e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.1112e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 33.22175145149231
Epoch 7/9
	 Logging train Loss: 1.3993e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.566e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.41954e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 4.2482e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.15928e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 33.7250862121582
Epoch 8/9
	 Logging train Loss: 1.2861e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.78e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.98e-08 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 3.01e-08 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.89e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 33.25268268585205
Epoch 9/9
	 Logging train Loss: 1.0676e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.39e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.7e-08 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.74e-08 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.55e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 33.335522413253784
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'dual_quat_1'_'False'.pth
It took  440.1980199813843  seconds.
----- ITERATION 8/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 47.78967595100403 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_full_pNone_gTrue took 12.09746241569519 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pNone_gTrue took 12.116176128387451 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pNone_gTrue took 12.068195581436157 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 12.000866413116455 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0003634347 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.882e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 4.9848e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 4.9924e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 4.9294e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 33.00141739845276
Epoch 1/9
	 Logging train Loss: 2.4083e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.751e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 7.279e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 7.32e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 6.999e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 33.36533546447754
Epoch 2/9
	 Logging train Loss: 3.845e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.662e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.852e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.868e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.751e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 33.17523217201233
Epoch 3/9
	 Logging train Loss: 7.632e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.617e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 5.4965e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 5.8709e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.7709e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 33.389461040496826
Epoch 4/9
	 Logging train Loss: 1.6691e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.737e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.866e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 3.029e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.312e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 33.15587306022644
Epoch 5/9
	 Logging train Loss: 2.2487e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.194e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.421e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.44e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.3e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 33.22385382652283
Epoch 6/9
	 Logging train Loss: 1.5522e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.43e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.056e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.079e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 8.87e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 33.333831787109375
Epoch 7/9
	 Logging train Loss: 1.5698e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.671e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 7.47e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 8.116e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 4.556e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 33.26830172538757
Epoch 8/9
	 Logging train Loss: 1.3549e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue â–ˆâ–‚â–â–…â–â–â–â–‚â–â–
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue â–ˆâ–‚â–â–‚â–â–â–â–â–â–
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue â–‡â–‚â–â–ˆâ–â–â–â–‚â–â–‚
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue â–‡â–‚â–â–ˆâ–â–â–â–‚â–â–‚
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue 0.0
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue 0.0
wandb:                                 Train loss 0.0
wandb: 
wandb: ðŸš€ View run swift-lion-879 at: https://wandb.ai/nreints/ThesisFinal2/runs/bfczcu74
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_174636-bfczcu74/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_175356-5wlgi80f
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run azure-deluge-902
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/5wlgi80f
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue â–„â–ƒâ–â–â–ˆâ–â–â–â–â–
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue â–ˆâ–„â–‚â–â–‚â–â–â–â–â–
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue â–ƒâ–‚â–â–â–ˆâ–â–â–â–â–
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue â–ƒâ–‚â–â–â–ˆâ–â–â–â–â–
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue 0.0
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue 0.0
wandb:                                 Train loss 0.0
wandb: 
wandb: ðŸš€ View run azure-deluge-902 at: https://wandb.ai/nreints/ThesisFinal2/runs/5wlgi80f
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_175356-5wlgi80f/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_180110-vqsj0anz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run likely-pyramid-918
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/vqsj0anz
	 Logging test loss: 2.58e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.646e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.773e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 9.04e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 33.26132774353027
Epoch 9/9
	 Logging train Loss: 1.0295e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.97e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 8.061e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 8.638e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 4.109e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 33.115967988967896
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'dual_quat_1'_'False'.pth
It took  439.97427010536194  seconds.
----- ITERATION 9/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 45.96036505699158 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_full_pNone_gTrue took 11.948761463165283 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pNone_gTrue took 11.97846531867981 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pNone_gTrue took 11.931889057159424 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 11.733662366867065 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0007436908 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.6167e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 8.1108e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 8.1203e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 7.8863e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 33.090720653533936
Epoch 1/9
	 Logging train Loss: 5.721e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.6415e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.754e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 3.7545e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.702e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 33.340983390808105
Epoch 2/9
	 Logging train Loss: 2.1353e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 9.094e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 9.854e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 9.853e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 9.507e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 32.977179288864136
Epoch 3/9
	 Logging train Loss: 5.05e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.844e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.36e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 3.362e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.129e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 33.03738045692444
Epoch 4/9
	 Logging train Loss: 1.1893e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.2752e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.82624e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.78313e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.58274e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 32.89669060707092
Epoch 5/9
	 Logging train Loss: 2.2469e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.015e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.488e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.481e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.269e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 32.77359485626221
Epoch 6/9
	 Logging train Loss: 1.7088e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.737e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 4.917e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 4.829e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.44e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 32.42011260986328
Epoch 7/9
	 Logging train Loss: 2.4481e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.253e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.339e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.339e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.3e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 32.58017945289612
Epoch 8/9
	 Logging train Loss: 1.4093e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.181e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.574e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 3.553e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.437e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 32.72550082206726
Epoch 9/9
	 Logging train Loss: 1.383e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.86e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 6.35e-08 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 6.35e-08 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 6.13e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 32.63975763320923
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'dual_quat_1'_'False'.pth
It took  434.0436646938324  seconds.
----- ITERATION 10/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 47.792473793029785 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_full_pNone_gTrue took 12.0649573802948 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pNone_gTrue took 12.089205265045166 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pNone_gTrue took 12.093457698822021 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 12.047832489013672 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0002491541 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.1085e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 5.356e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 5.3954e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 5.2399e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 32.49570345878601
Epoch 1/9
	 Logging train Loss: 3.1246e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.3329e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.4657e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.4839e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.4015e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 32.72750115394592
Epoch 2/9
	 Logging train Loss: 6.814e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.238e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.508e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 3.548e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.379e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 32.687403202056885
Epoch 3/9
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue â–‡â–ƒâ–â–ˆâ–â–â–â–â–â–
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue â–ˆâ–ƒâ–â–‚â–â–â–â–â–â–
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue â–„â–‚â–â–ˆâ–â–â–â–â–â–
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue â–„â–‚â–â–ˆâ–â–â–â–â–â–
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue 0.0
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue 0.0
wandb:                                 Train loss 0.0
wandb: 
wandb: ðŸš€ View run likely-pyramid-918 at: https://wandb.ai/nreints/ThesisFinal2/runs/vqsj0anz
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_180110-vqsj0anz/logs
	 Logging train Loss: 2.3429e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.754e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.11038e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.23807e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 6.0749e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 32.58034014701843
Epoch 4/9
	 Logging train Loss: 2.1079e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.097e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.149e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.158e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.124e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 32.452741861343384
Epoch 5/9
	 Logging train Loss: 1.3787e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.651e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.789e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.808e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.724e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 32.60694360733032
Epoch 6/9
	 Logging train Loss: 1.6982e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.411e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.824e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 3.913e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.579e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 32.689502477645874
Epoch 7/9
	 Logging train Loss: 1.3057e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.68e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 7.96e-08 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 8e-08 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 7.83e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 32.489484786987305
Epoch 8/9
	 Logging train Loss: 1.15e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.05e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 4.2e-08 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 4.22e-08 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 4.13e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 32.84069347381592
Epoch 9/9
	 Logging train Loss: 7.754e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.67e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.897e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.072e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.094e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
		--> Epoch time; 32.86091423034668
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'dual_quat_1'_'False'.pth
It took  433.85684847831726  seconds.
