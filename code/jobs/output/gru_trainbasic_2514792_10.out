wandb: Currently logged in as: nreints. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230329_133617-v51y4mhs
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run logical-oath-503
wandb: ⭐️ View project at https://wandb.ai/nreints/test
wandb: 🚀 View run at https://wandb.ai/nreints/test/runs/v51y4mhs
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.031 MB of 0.078 MB uploaded (0.000 MB deduped)wandb: \ 0.078 MB of 0.078 MB uploaded (0.000 MB deduped)wandb: | 0.078 MB of 0.078 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:                                                    Epoch ▁▂▃▃▄▅▆▆▇█
wandb: Test loss t(5, 20)_r(0, 0)_tennis_pNone_gNone, MSELoss() █▃▂▁▁▁▁▁▁▁▁
wandb:                                               Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                                    Epoch 9
wandb: Test loss t(5, 20)_r(0, 0)_tennis_pNone_gNone, MSELoss() 0.00217
wandb:                                               Train loss 0.00338
wandb: 
wandb: 🚀 View run logical-oath-503 at: https://wandb.ai/nreints/test/runs/v51y4mhs
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230329_133617-v51y4mhs/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230329_134418-ngq2l7fu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vibrant-sun-522
wandb: ⭐️ View project at https://wandb.ai/nreints/test
wandb: 🚀 View run at https://wandb.ai/nreints/test/runs/ngq2l7fu
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.031 MB of 0.079 MB uploaded (0.000 MB deduped)wandb: \ 0.031 MB of 0.079 MB uploaded (0.000 MB deduped)wandb: | 0.031 MB of 0.079 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:                                                    Epoch ▁▂▃▃▄▅▆▆▇█
wandb: Test loss t(5, 20)_r(0, 0)_tennis_pNone_gNone, MSELoss() █▃▂▁▁▁▁▁▁▁▁
wandb:                                               Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                                    Epoch 9
wandb: Test loss t(5, 20)_r(0, 0)_tennis_pNone_gNone, MSELoss() 0.00259
wandb:                                               Train loss 0.00419
wandb: 
wandb: 🚀 View run vibrant-sun-522 at: https://wandb.ai/nreints/test/runs/ngq2l7fu
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230329_134418-ngq2l7fu/logs
Running for data type: quat
----- ITERATION 1/2 ------
Number of train simulations: 1600
Number of test simulations: 400
-- Finished Train Dataloader --
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
-- Started Training --
Epoch 0
	 Logging train Loss: 8.408217467 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss: 0.519639253616333 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 43.73825216293335
Epoch 1
	 Logging train Loss: 0.2590617446 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss: 0.12673930823802948 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 41.40725660324097
Epoch 2
	 Logging train Loss: 0.0791661832 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss: 0.04838848486542702 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 41.45509362220764
Epoch 3
	 Logging train Loss: 0.0343168765 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss: 0.02280925214290619 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 41.28992247581482
Epoch 4
	 Logging train Loss: 0.0182414914 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss: 0.01197260245680809 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 41.26476716995239
Epoch 5
	 Logging train Loss: 0.0119225384 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss: 0.007090782281011343 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 41.77793478965759
Epoch 6
	 Logging train Loss: 0.0081010425 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss: 0.010043827816843987 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 41.36476540565491
Epoch 7
	 Logging train Loss: 0.0065087241 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss: 0.004100465215742588 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 41.24439811706543
Epoch 8
	 Logging train Loss: 0.0064288752 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss: 0.00281338719651103 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 41.09341859817505
Epoch 9
	 Logging train Loss: 0.0033795694 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss: 0.002169917104765773 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 41.290170431137085
	 Logging test loss: 0.002167605794966221 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
It took  482.6826241016388  seconds.
----- ITERATION 2/2 ------
Number of train simulations: 1600
Number of test simulations: 400
-- Finished Train Dataloader --
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
-- Started Training --
Epoch 0
	 Logging train Loss: 14.9750891814 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss: 0.6736936569213867 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 41.47161054611206
Epoch 1
	 Logging train Loss: 0.3269056211 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss: 0.1661747843027115 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 41.601696729660034
Epoch 2
	 Logging train Loss: 0.1038144447 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss: 0.06824184954166412 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 41.38000464439392
Epoch 3
	 Logging train Loss: 0.0469517829 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss: 0.03417575731873512 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 41.477975368499756
Epoch 4
	 Logging train Loss: 0.0241414874 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss: 0.017841458320617676 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 46.237234115600586
Epoch 5
	 Logging train Loss: 0.0131563816 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss: 0.009277286939322948 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 43.447405099868774
Epoch 6
	 Logging train Loss: 0.0081384707 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss: 0.005713562946766615 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 45.792205810546875
Epoch 7
	 Logging train Loss: 0.0061424393 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss: 0.004549952689558268 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 41.390621185302734
Epoch 8
	 Logging train Loss: 0.0060674594 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss: 0.003506738692522049 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 41.79863214492798
Epoch 9
	 Logging train Loss: 0.0041866551 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss: 0.0025890818797051907 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 41.565316915512085
	 Logging test loss: 0.0025939769111573696 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
It took  488.6105489730835  seconds.

JOB STATISTICS
==============
Job ID: 2514802
Array Job ID: 2514792_10
Cluster: snellius
User/Group: nreints/nreints
State: COMPLETED (exit code 0)
Nodes: 1
Cores per node: 18
CPU Utilized: 03:19:40
CPU Efficiency: 67.71% of 04:54:54 core-walltime
Job Wall-clock time: 00:16:23
Memory Utilized: 25.01 GB
Memory Efficiency: 80.05% of 31.25 GB
