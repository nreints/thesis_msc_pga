wandb: Currently logged in as: nreints. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230629_112031-da8a07zz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run apricot-serenity-30
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/da8a07zz
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone █▂▁▁▁▁▂▁▁▁
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone █▂▁▁▃▁▂▁▁▁
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone █▂▁▁▃▁▂▁▁▁
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone █▂▁▁▁▁▂▁▁▁
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone █▂▁▁▁▁▂▁▁▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone 1e-05
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone 1e-05
wandb:                                  Train loss 0.0
wandb: 
wandb: 🚀 View run apricot-serenity-30 at: https://wandb.ai/nreints/ThesisFinal2/runs/da8a07zz
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230629_112031-da8a07zz/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230629_112915-ouha8kd0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run light-sea-44
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/ouha8kd0
Training on dataset: data_t(0,0)_r(5,20)_combi_pNone_gNone
Testing on 5 datasets: ['data_t(0,0)_r(5,20)_full_pNone_gNone', 'data_t(0,0)_r(5,20)_tennis_pNone_gNone', 'data_t(0,0)_r(5,20)_none_pNone_gNone', 'data_t(0,0)_r(5,20)_combi_pNone_gNone', 'data_t(0,0)_r(5,20)_semi_pNone_gNone']
Focussing on identity: False
Using extra input: False
Using fr-fr as reference point.
----- ITERATION 1/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 52.21932339668274 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(5,20)_full_pNone_gNone took 12.935790777206421 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_tennis_pNone_gNone took 13.147229194641113 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_none_pNone_gNone took 13.289992809295654 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 12.734482049942017 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_semi_pNone_gNone took 12.296088218688965 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(6, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=6, bias=True)
)
Datatype: log_dualQ_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0007796301 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.9141e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 6.24837e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.1557e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.29326e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.61277e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 40.047871589660645
Epoch 1/9
	 Logging train Loss: 1.29406e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.607e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 9.8279e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.272e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 5.4723e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 9.3314e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 39.01051306724548
Epoch 2/9
	 Logging train Loss: 4.2319e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.34e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 6.727e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.815e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.786e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.4997e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 38.75605225563049
Epoch 3/9
	 Logging train Loss: 3.9825e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.424e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 6.5969e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.834e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.6985e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.3902e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 39.08392381668091
Epoch 4/9
	 Logging train Loss: 4.0742e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.051e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 7.7069e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 7.451e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 4.533e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.4572e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 39.06649136543274
Epoch 5/9
	 Logging train Loss: 4.0716e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.02e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 5.3516e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.056e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.9436e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.2183e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 39.02301621437073
Epoch 6/9
	 Logging train Loss: 3.9941e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.488e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.27744e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.824e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 6.8427e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.19756e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 39.238311529159546
Epoch 7/9
	 Logging train Loss: 4.0029e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.602e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 6.8336e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.93e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.7041e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.5199e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 39.56093239784241
Epoch 8/9
	 Logging train Loss: 3.4184e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.67e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.3293e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.041e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.4175e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.1944e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 38.846391677856445
Epoch 9/9
	 Logging train Loss: 3.2877e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.684e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 7.1181e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.937e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.8506e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.7121e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 39.054720878601074
Saved model in  trained_models/gru/data_t(0,0)_r(5,20)_combi_pNone_gNone/'log_dualQ_1'_'False'.pth
It took  525.3143844604492  seconds.
----- ITERATION 2/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 45.48805499076843 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(5,20)_full_pNone_gNone took 12.21005654335022 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_tennis_pNone_gNone took 11.31376576423645 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_none_pNone_gNone took 12.264623880386353 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 11.356215715408325 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_semi_pNone_gNone took 11.352983951568604 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(6, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=6, bias=True)
)
Datatype: log_dualQ_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0006042341 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.987e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.68026e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.1142e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.92563e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.35854e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 39.129478931427
Epoch 1/9
	 Logging train Loss: 1.17386e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.445e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 8.5323e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone █▂▂▁▁▂▁▂▁▁
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone █▂▂▁▁▂▁▃▁▁
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone █▂▂▁▁▂▁▃▁▁
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone █▂▂▂▁▂▁▂▁▁
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone █▂▂▁▁▂▁▂▁▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone 0.0
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: 🚀 View run light-sea-44 at: https://wandb.ai/nreints/ThesisFinal2/runs/ouha8kd0
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230629_112915-ouha8kd0/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230629_113743-6u5p64td
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run peachy-feather-62
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/6u5p64td
	 Logging test loss: 5.146e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 5.3196e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.4124e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 38.94073438644409
Epoch 2/9
	 Logging train Loss: 5.0418e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.24e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 8.9211e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.652e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 4.5806e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.5619e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 39.15877556800842
Epoch 3/9
	 Logging train Loss: 4.8123e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.489e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 6.6047e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.873e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.4131e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.4499e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 39.00614833831787
Epoch 4/9
	 Logging train Loss: 4.6788e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.051e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 6.4484e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.381e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.2975e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.3228e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 39.29268836975098
Epoch 5/9
	 Logging train Loss: 4.4928e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.396e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 8.019e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.692e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 4.114e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.6854e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 39.02809023857117
Epoch 6/9
	 Logging train Loss: 4.2176e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.73e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.7338e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 8.51e-08 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.4331e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.691e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 39.02954030036926
Epoch 7/9
	 Logging train Loss: 4.0967e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.007e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.26647e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 6.152e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 6.1857e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.16581e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 39.10021615028381
Epoch 8/9
	 Logging train Loss: 3.3259e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.125e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 5.8131e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.325e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.8706e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.5922e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 39.13398861885071
Epoch 9/9
	 Logging train Loss: 3.1929e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.68e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.6212e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.044e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.8407e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.5558e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 39.125049114227295
Saved model in  trained_models/gru/data_t(0,0)_r(5,20)_combi_pNone_gNone/'log_dualQ_1'_'False'.pth
It took  507.9822201728821  seconds.
----- ITERATION 3/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 45.716270446777344 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(5,20)_full_pNone_gNone took 11.272088766098022 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_tennis_pNone_gNone took 11.282799005508423 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_none_pNone_gNone took 11.306164264678955 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 11.293897151947021 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_semi_pNone_gNone took 11.332930326461792 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(6, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=6, bias=True)
)
Datatype: log_dualQ_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0007578828 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.0323e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 5.29869e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.0767e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.3183e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.28347e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 38.96974563598633
Epoch 1/9
	 Logging train Loss: 1.23784e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.245e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 8.5943e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.637e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 5.447e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.8397e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 39.277854919433594
Epoch 2/9
	 Logging train Loss: 4.5824e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.538e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.18494e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.839e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 6.4536e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.14864e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 39.069963693618774
Epoch 3/9
	 Logging train Loss: 4.388e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.288e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 8.1558e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.628e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 4.5527e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.18e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 38.890708208084106
Epoch 4/9
	 Logging train Loss: 4.5306e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.266e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.56145e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.476e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 8.1283e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.4724e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 39.260366916656494
Epoch 5/9
	 Logging train Loss: 4.3181e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.64e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 5.2357e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone █▂▂▁▂▁▁▁▁▁
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone █▂▂▁▂▁▁▁▁▁
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone █▂▂▁▂▁▁▁▁▁
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone █▂▂▁▂▁▁▁▁▁
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone █▂▂▁▃▁▁▁▁▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone 1e-05
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone 1e-05
wandb:                                  Train loss 0.0
wandb: 
wandb: 🚀 View run peachy-feather-62 at: https://wandb.ai/nreints/ThesisFinal2/runs/6u5p64td
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230629_113743-6u5p64td/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230629_114609-wsop5rwz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run balmy-frog-79
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/wsop5rwz
	 Logging test loss: 7.8e-08 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.983e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.5113e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 39.35824179649353
Epoch 6/9
	 Logging train Loss: 4.0281e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.704e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 6.3344e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.978e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.5582e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.4701e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 39.3238582611084
Epoch 7/9
	 Logging train Loss: 3.7236e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.326e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 7.7285e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.564e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 4.1248e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.5783e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 38.93074417114258
Epoch 8/9
	 Logging train Loss: 3.5912e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.147e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 5.0702e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.363e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.8028e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.1879e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 39.11789155006409
Epoch 9/9
	 Logging train Loss: 3.0635e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.23e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 5.0924e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.416e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.7907e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.1089e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 38.93428039550781
Saved model in  trained_models/gru/data_t(0,0)_r(5,20)_combi_pNone_gNone/'log_dualQ_1'_'False'.pth
It took  505.98959946632385  seconds.
----- ITERATION 4/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 46.0815966129303 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(5,20)_full_pNone_gNone took 11.293898344039917 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_tennis_pNone_gNone took 11.2985680103302 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_none_pNone_gNone took 11.292100191116333 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 11.306629419326782 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_semi_pNone_gNone took 11.38627290725708 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(6, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=6, bias=True)
)
Datatype: log_dualQ_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0007943711 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.959e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 5.72039e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.1762e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.25021e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.78838e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 38.74708366394043
Epoch 1/9
	 Logging train Loss: 1.31847e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.624e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 7.1612e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.15e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 4.3221e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.571e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 39.22317361831665
Epoch 2/9
	 Logging train Loss: 4.1662e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.082e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 5.7236e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.5e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.0005e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.134e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 38.8176326751709
Epoch 3/9
	 Logging train Loss: 4.131e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.201e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 7.2899e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.623e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.5971e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.5664e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 38.70699858665466
Epoch 4/9
	 Logging train Loss: 4.0841e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.76e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 6.5082e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.269e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.1805e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.737e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 38.84085154533386
Epoch 5/9
	 Logging train Loss: 4.2131e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.416e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 7.244e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.802e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.5074e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.3921e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 39.41974902153015
Epoch 6/9
	 Logging train Loss: 4.1315e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.98e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 5.098e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 9.2e-08 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.4927e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.3658e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 39.163772106170654
Epoch 7/9
	 Logging train Loss: 3.9779e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.249e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 6.1692e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.563e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.9385e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.3301e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 39.012826919555664
Epoch 8/9
	 Logging train Loss: 3.5713e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 9.89e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.101e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.255e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.0162e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.3088e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 39.200973987579346
Epoch 9/9
	 Logging train Loss: 3.1724e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.1e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 5.6376e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone █▂▁▁▁▁▁▁▁▁
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone █▂▁▁▁▁▁▁▁▂
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone █▂▁▁▁▁▁▁▁▁
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone █▁▁▁▁▁▁▁▁▁
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone █▁▁▁▁▁▁▁▁▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone 1e-05
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone 1e-05
wandb:                                  Train loss 0.0
wandb: 
wandb: 🚀 View run balmy-frog-79 at: https://wandb.ai/nreints/ThesisFinal2/runs/wsop5rwz
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230629_114609-wsop5rwz/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230629_115436-ucciqmb6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dauntless-river-96
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/ucciqmb6
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone █▂▂▂▁▂▁▂▁▁
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone █▂▁▁▁▂▁▂▁▁
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone █▂▁▁▁▂▁▂▁▁
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone █▂▂▂▂▂▂▃▁▁
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone █▂▂▂▂▂▂▃▁▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone 0.0
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: 🚀 View run dauntless-river-96 at: https://wandb.ai/nreints/ThesisFinal2/runs/ucciqmb6
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230629_115436-ucciqmb6/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230629_120300-alpxls4p
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stilted-lion-114
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/alpxls4p
	 Logging test loss: 2.376e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.7317e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.7436e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 39.09112882614136
Saved model in  trained_models/gru/data_t(0,0)_r(5,20)_combi_pNone_gNone/'log_dualQ_1'_'False'.pth
It took  507.0003287792206  seconds.
----- ITERATION 5/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 46.03795051574707 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(5,20)_full_pNone_gNone took 11.303976774215698 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_tennis_pNone_gNone took 11.295616626739502 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_none_pNone_gNone took 11.291964292526245 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 11.314131259918213 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_semi_pNone_gNone took 11.501802682876587 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(6, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=6, bias=True)
)
Datatype: log_dualQ_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.000482749 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.1279e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 2.69813e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.169e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.59636e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.55953e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 38.8441960811615
Epoch 1/9
	 Logging train Loss: 7.0924e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.573e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 6.3312e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.993e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.346e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.5637e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 38.95769500732422
Epoch 2/9
	 Logging train Loss: 4.3324e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.5e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 6.289e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.264e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.1212e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.5181e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 39.53003144264221
Epoch 3/9
	 Logging train Loss: 4.6837e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.2e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 6.3588e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.214e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.1168e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.4925e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 39.12085747718811
Epoch 4/9
	 Logging train Loss: 4.3643e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.49e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 5.548e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.023e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.701e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.6794e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 38.78866195678711
Epoch 5/9
	 Logging train Loss: 4.2594e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.515e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 8.2057e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.865e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.8622e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.186e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 39.048864126205444
Epoch 6/9
	 Logging train Loss: 3.8835e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.199e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 5.8767e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.515e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.8192e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.9301e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 38.89228630065918
Epoch 7/9
	 Logging train Loss: 3.5386e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.615e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.03822e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.885e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 4.8259e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 9.9816e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 38.41497087478638
Epoch 8/9
	 Logging train Loss: 3.2282e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.21e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.4559e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 9.55e-08 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.0829e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.4905e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 38.68736481666565
Epoch 9/9
	 Logging train Loss: 2.9165e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.077e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.8515e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.29e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.838e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.8638e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 38.19722104072571
Saved model in  trained_models/gru/data_t(0,0)_r(5,20)_combi_pNone_gNone/'log_dualQ_1'_'False'.pth
It took  504.11244773864746  seconds.
----- ITERATION 6/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 46.2309935092926 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(5,20)_full_pNone_gNone took 11.292876243591309 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_tennis_pNone_gNone took 11.371415376663208 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_none_pNone_gNone took 11.252661943435669 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 11.426230430603027 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_semi_pNone_gNone took 11.749165058135986 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(6, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=6, bias=True)
)
Datatype: log_dualQ_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0007777864 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.1866e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 5.15154e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.3849e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.58294e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.73949e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 38.14122247695923
Epoch 1/9
	 Logging train Loss: 1.20414e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.769e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 7.7784e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone █▂▁▁▂▂▁▂▂▁
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone █▂▁▁▂▁▁▂▂▃
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone █▂▁▁▂▁▁▂▂▂
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone █▂▁▁▂▂▁▂▂▁
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone █▂▁▁▂▂▁▂▂▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone 0.0
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: 🚀 View run stilted-lion-114 at: https://wandb.ai/nreints/ThesisFinal2/runs/alpxls4p
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230629_120300-alpxls4p/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230629_121119-dxyta44q
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run spring-glitter-131
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/dxyta44q
	 Logging test loss: 4.356e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 5.6203e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.1998e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 38.32522964477539
Epoch 2/9
	 Logging train Loss: 4.3927e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.531e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 7.2736e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.047e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 4.6885e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.7234e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 38.049431562423706
Epoch 3/9
	 Logging train Loss: 4.0661e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.02e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 6.0296e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.26e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.8564e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.5752e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 38.07106900215149
Epoch 4/9
	 Logging train Loss: 4.1366e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.434e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.22509e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.959e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 7.1535e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.08328e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 38.1184515953064
Epoch 5/9
	 Logging train Loss: 4.1509e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.001e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 9.9515e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.473e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 5.8833e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.9481e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 38.30296516418457
Epoch 6/9
	 Logging train Loss: 3.9447e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.61e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 5.1091e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.02e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.2019e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.7281e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 38.20154595375061
Epoch 7/9
	 Logging train Loss: 3.6581e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.23e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.33712e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.71e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 7.8804e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.18933e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 38.21468758583069
Epoch 8/9
	 Logging train Loss: 3.3471e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.935e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.2846e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.4e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 7.1967e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.11333e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 38.34244918823242
Epoch 9/9
	 Logging train Loss: 3.1054e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.223e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.366e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 5.48e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.904e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.0739e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 38.153523206710815
Saved model in  trained_models/gru/data_t(0,0)_r(5,20)_combi_pNone_gNone/'log_dualQ_1'_'False'.pth
It took  499.0154809951782  seconds.
----- ITERATION 7/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 46.38207387924194 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(5,20)_full_pNone_gNone took 11.309297323226929 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_tennis_pNone_gNone took 11.317986488342285 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_none_pNone_gNone took 11.287795782089233 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 11.33816146850586 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_semi_pNone_gNone took 11.709672212600708 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(6, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=6, bias=True)
)
Datatype: log_dualQ_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0003821967 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.798e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.66447e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 8.765e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.29947e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.51576e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 37.81724190711975
Epoch 1/9
	 Logging train Loss: 7.3436e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.743e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.33629e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.207e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 7.2272e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.22307e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 38.96643614768982
Epoch 2/9
	 Logging train Loss: 5.8139e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.828e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 7.6216e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.2e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 4.0931e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.1098e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 37.96634793281555
Epoch 3/9
	 Logging train Loss: 4.8536e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.27e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 8.1242e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.583e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 4.2457e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.6308e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 37.949342012405396
Epoch 4/9
	 Logging train Loss: 4.7223e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.262e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 8.0758e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.551e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 4.1825e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.5835e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 38.042059659957886
Epoch 5/9
	 Logging train Loss: 4.4165e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.629e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 6.9352e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone █▄▂▂▂▂▃▃▁▂
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone █▄▂▁▁▂▄▂▃▂
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone █▄▂▁▁▂▃▂▃▂
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone █▆▃▃▃▂▅▅▁▄
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone █▆▃▃▃▂▅▄▁▄
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone 1e-05
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone 1e-05
wandb:                                  Train loss 0.0
wandb: 
wandb: 🚀 View run spring-glitter-131 at: https://wandb.ai/nreints/ThesisFinal2/runs/dxyta44q
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230629_121119-dxyta44q/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230629_121937-plvi38qc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vibrant-brook-146
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/plvi38qc
	 Logging test loss: 2.905e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.6697e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.5358e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 38.244481563568115
Epoch 6/9
	 Logging train Loss: 3.8437e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.613e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.18346e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.841e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 5.8004e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.05728e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 38.007519483566284
Epoch 7/9
	 Logging train Loss: 3.5068e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.143e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.05475e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.311e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 5.193e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 9.8182e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 37.92837929725647
Epoch 8/9
	 Logging train Loss: 3.3307e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.923e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.5346e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.118e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.4304e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.2653e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 38.03010058403015
Epoch 9/9
	 Logging train Loss: 2.8234e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.143e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 9.0636e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.251e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 4.4002e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.1575e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 38.0178906917572
Saved model in  trained_models/gru/data_t(0,0)_r(5,20)_combi_pNone_gNone/'log_dualQ_1'_'False'.pth
It took  497.9723825454712  seconds.
----- ITERATION 8/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 46.40776777267456 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(5,20)_full_pNone_gNone took 11.323642015457153 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_tennis_pNone_gNone took 11.34797477722168 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_none_pNone_gNone took 11.304113388061523 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 11.375311851501465 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_semi_pNone_gNone took 11.701351404190063 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(6, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=6, bias=True)
)
Datatype: log_dualQ_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0005159811 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.3581e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.01576e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.5187e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.97029e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.47793e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 38.03844881057739
Epoch 1/9
	 Logging train Loss: 8.4489e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.987e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 7.8982e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.48e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.9804e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.597e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 38.208022594451904
Epoch 2/9
	 Logging train Loss: 4.2722e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.19e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 5.9544e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.217e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.9709e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.9804e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 37.953782081604004
Epoch 3/9
	 Logging train Loss: 4.4791e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.281e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 8.9888e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.718e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 4.2265e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.53e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 38.12129092216492
Epoch 4/9
	 Logging train Loss: 4.4285e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.066e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 7.1299e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.447e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.4255e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.903e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 37.863008975982666
Epoch 5/9
	 Logging train Loss: 4.143e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.002e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 7.3102e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.364e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.5832e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.9135e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 38.148011684417725
Epoch 6/9
	 Logging train Loss: 3.8444e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.275e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 5.9199e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 5.585e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.0769e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.8047e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 38.30665063858032
Epoch 7/9
	 Logging train Loss: 3.6387e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.181e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 6.8992e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.496e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.3271e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.472e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 38.02383375167847
Epoch 8/9
	 Logging train Loss: 3.3461e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.618e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 8.1377e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.931e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.8705e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.4521e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 37.97088980674744
Epoch 9/9
	 Logging train Loss: 2.8456e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.374e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 6.7788e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone █▁▁▂▁▁▁▁▁▁
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone █▂▁▁▂▂▃▂▂▁
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone █▂▁▁▂▂▃▂▂▁
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone █▁▁▂▁▁▁▁▁▁
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone █▁▁▂▁▁▁▁▁▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone 1e-05
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone 1e-05
wandb:                                  Train loss 0.0
wandb: 
wandb: 🚀 View run vibrant-brook-146 at: https://wandb.ai/nreints/ThesisFinal2/runs/plvi38qc
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230629_121937-plvi38qc/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230629_122754-lxzp1v8b
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dutiful-smoke-164
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/lxzp1v8b
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone █▂▁▁▁▁▂▁▁▁
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone █▂▁▁▁▁▂▁▁▂
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone █▂▁▁▁▁▂▁▁▂
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone █▁▁▁▁▁▂▁▁▁
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone █▁▁▁▁▁▂▁▁▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone 0.0
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone 1e-05
wandb:                                  Train loss 0.0
wandb: 
wandb: 🚀 View run dutiful-smoke-164 at: https://wandb.ai/nreints/ThesisFinal2/runs/lxzp1v8b
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230629_122754-lxzp1v8b/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230629_123612-r3hndyb3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dulcet-eon-175
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/r3hndyb3
	 Logging test loss: 1.641e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.1597e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.1457e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 38.09954619407654
Saved model in  trained_models/gru/data_t(0,0)_r(5,20)_combi_pNone_gNone/'log_dualQ_1'_'False'.pth
It took  497.1260681152344  seconds.
----- ITERATION 9/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 46.353185415267944 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(5,20)_full_pNone_gNone took 11.33847975730896 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_tennis_pNone_gNone took 11.379194498062134 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_none_pNone_gNone took 11.33156418800354 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 11.449899673461914 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_semi_pNone_gNone took 11.695656061172485 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(6, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=6, bias=True)
)
Datatype: log_dualQ_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0009779846 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.2444e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 6.958e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.4738e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.63461e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.26307e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 38.231260776519775
Epoch 1/9
	 Logging train Loss: 1.66248e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.285e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 8.6208e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.834e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 4.965e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.1626e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 38.21240758895874
Epoch 2/9
	 Logging train Loss: 4.3153e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.478e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 5.9225e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.905e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.0253e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.7741e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 38.00671458244324
Epoch 3/9
	 Logging train Loss: 3.6814e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.176e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 5.8447e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.568e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.8827e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.7087e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 37.857420206069946
Epoch 4/9
	 Logging train Loss: 4.1547e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.047e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 6.8822e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.426e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.1954e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.5729e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 37.9796199798584
Epoch 5/9
	 Logging train Loss: 4.3206e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.312e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 7.3174e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.671e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.3417e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.7406e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 38.38629937171936
Epoch 6/9
	 Logging train Loss: 4.3148e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.745e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.15763e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.136e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 5.1825e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.03382e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 38.11215949058533
Epoch 7/9
	 Logging train Loss: 4.0878e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.426e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 7.0612e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.74e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.135e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.6136e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 38.19336724281311
Epoch 8/9
	 Logging train Loss: 3.6716e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.076e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.6324e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.343e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.1141e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.4294e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 38.079243183135986
Epoch 9/9
	 Logging train Loss: 3.2799e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.841e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 5.2689e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.075e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.4008e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.8034e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 38.132877826690674
Saved model in  trained_models/gru/data_t(0,0)_r(5,20)_combi_pNone_gNone/'log_dualQ_1'_'False'.pth
It took  497.2387821674347  seconds.
----- ITERATION 10/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 46.83028030395508 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(5,20)_full_pNone_gNone took 11.458607196807861 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_tennis_pNone_gNone took 11.45171046257019 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_none_pNone_gNone took 11.39612627029419 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_combi_pNone_gNone took 11.468711853027344 seconds.
The dataloader for data/data_t(0,0)_r(5,20)_semi_pNone_gNone took 11.80286979675293 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(6, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=6, bias=True)
)
Datatype: log_dualQ_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0010020728 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.2389e-06 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 6.5096e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.565e-06 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.55519e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.60424e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 37.840041160583496
Epoch 1/9
	 Logging train Loss: 1.43914e-05 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.273e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 8.0125e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                       Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone █▂▁▁▁▂▂▁▁▁
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone █▂▁▁▁▁▂▁▁▁
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone █▂▁▁▁▁▂▁▁▁
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone █▁▁▁▁▂▂▁▁▁
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone █▁▁▁▁▂▂▁▁▁
wandb:                                  Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                       Epoch 9
wandb:  Test loss t(0,0)_r(5,20)_combi_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(0,0)_r(5,20)_semi_pNone_gNone 0.0
wandb: Test loss t(0,0)_r(5,20)_tennis_pNone_gNone 0.0
wandb:                                  Train loss 0.0
wandb: 
wandb: 🚀 View run dulcet-eon-175 at: https://wandb.ai/nreints/ThesisFinal2/runs/r3hndyb3
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230629_123612-r3hndyb3/logs
	 Logging test loss: 5.34e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 4.6033e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.4907e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 38.10792279243469
Epoch 2/9
	 Logging train Loss: 3.8891e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.397e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 7.3428e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.938e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.5263e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.7312e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 38.117509841918945
Epoch 3/9
	 Logging train Loss: 3.3116e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.35e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 5.9128e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.093e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.7756e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.5059e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 38.155664682388306
Epoch 4/9
	 Logging train Loss: 3.5292e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.2e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 5.6828e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 9.18e-08 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.6154e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 5.2041e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 38.048768758773804
Epoch 5/9
	 Logging train Loss: 3.9338e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.867e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 9.6104e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 2.209e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 4.3476e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.3628e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 37.991222858428955
Epoch 6/9
	 Logging train Loss: 4.0071e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.434e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.7195e-05 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.697e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 7.8267e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.44679e-05 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 37.99665021896362
Epoch 7/9
	 Logging train Loss: 3.5962e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.547e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 7.8978e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.839e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.597e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.9548e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 38.03264832496643
Epoch 8/9
	 Logging train Loss: 3.5347e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.575e-07 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 5.076e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.854e-07 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 2.3437e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.5595e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 38.16717553138733
Epoch 9/9
	 Logging train Loss: 3.097e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.2e-08 [MSELoss(): t(0,0)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.1966e-06 [MSELoss(): t(0,0)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 8.6e-08 [MSELoss(): t(0,0)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.8984e-06 [MSELoss(): t(0,0)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 3.7669e-06 [MSELoss(): t(0,0)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 38.09746551513672
Saved model in  trained_models/gru/data_t(0,0)_r(5,20)_combi_pNone_gNone/'log_dualQ_1'_'False'.pth
It took  498.01619696617126  seconds.

JOB STATISTICS
==============
Job ID: 2986706
Array Job ID: 2986645_12
Cluster: snellius
User/Group: nreints/nreints
State: RUNNING
Nodes: 1
Cores per node: 18
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 1-01:17:24 core-walltime
Job Wall-clock time: 01:24:18
Memory Utilized: 0.00 MB (estimated maximum)
Memory Efficiency: 0.00% of 0.00 MB (0.00 MB/node)
WARNING: Efficiency statistics may be misleading for RUNNING jobs.
