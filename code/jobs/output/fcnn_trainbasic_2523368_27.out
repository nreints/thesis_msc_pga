wandb: Currently logged in as: nreints. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home/nreints/.netrc
/gpfs/home2/nreints/MScThesis/code/fcnn.py:566: DeprecationWarning: Sampling from a set deprecated
since Python 3.9 and will be removed in a subsequent version.
  train_sims = set(random.sample(sims_train, int(0.8 * n_sims_train)))
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230330_123650-ocrathua
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run expert-planet-566
wandb: â­ï¸ View project at https://wandb.ai/nreints/test
wandb: ðŸš€ View run at https://wandb.ai/nreints/test/runs/ocrathua
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.029 MB of 0.029 MB uploaded (0.000 MB deduped)wandb: \ 0.029 MB of 0.078 MB uploaded (0.000 MB deduped)wandb: | 0.029 MB of 0.078 MB uploaded (0.000 MB deduped)wandb: / 0.029 MB of 0.078 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  Test loss t(5, 20)_r(0, 0)_tennis L1Loss() â–ƒâ–„â–‚â–„â–‚â–†â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–‚â–‚â–â–‚â–‚
wandb: Test loss t(5, 20)_r(0, 0)_tennis MSELoss() â–‚â–ƒâ–â–‚â–â–…â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:     Train loss data_t(5, 20)_r(0, 0)_tennis â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:  Test loss t(5, 20)_r(0, 0)_tennis L1Loss() 0.08757
wandb: Test loss t(5, 20)_r(0, 0)_tennis MSELoss() 0.01809
wandb:     Train loss data_t(5, 20)_r(0, 0)_tennis 0.02707
wandb: 
wandb: ðŸš€ View run expert-planet-566 at: https://wandb.ai/nreints/test/runs/ocrathua
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230330_123650-ocrathua/logs
/gpfs/home2/nreints/MScThesis/code/fcnn.py:566: DeprecationWarning: Sampling from a set deprecated
since Python 3.9 and will be removed in a subsequent version.
  train_sims = set(random.sample(sims_train, int(0.8 * n_sims_train)))
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230330_124931-n8dbdbi8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pleasant-lake-637
wandb: â­ï¸ View project at https://wandb.ai/nreints/test
wandb: ðŸš€ View run at https://wandb.ai/nreints/test/runs/n8dbdbi8
Training on dataset: data/data_t(5, 20)_r(0, 0)_tennis_pNone_gNone
Testing on datasets: ['data_t(5, 20)_r(0, 0)_tennis_pNone_gNone']
----- ITERATION 1/2 ------
Number of train simulations: 1600
Number of test simulations: 400
The dataloader took 59.32333755493164 seconds.
-- Finished Train Dataloader --
The dataloader took 14.505283117294312 seconds.
-- Finished Test Dataloader(s) --
Datatype: log_dualQ
--- Started Training ---
Epoch 0
	 Logging train Loss: 13.3147288603 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.05957476422190666 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.17142504453659058 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 34.92651438713074
Epoch 1
	 Logging train Loss: 0.0748325672 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.15089872479438782 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.2566697895526886 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 34.477641344070435
Epoch 2
	 Logging train Loss: 0.0720118105 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.020986931398510933 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.10073866695165634 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 34.053364992141724
Epoch 3
	 Logging train Loss: 0.0571674671 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.10339599847793579 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.20889191329479218 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 33.9911835193634
Epoch 4
	 Logging train Loss: 0.060847912 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.020977329462766647 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.10109769552946091 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 34.12505912780762
Epoch 5
	 Logging train Loss: 0.0506011414 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.27508509159088135 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.32346484065055847 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 34.35002160072327
Epoch 6
	 Logging train Loss: 0.0513316285 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.5352379083633423 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.4791173040866852 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 34.13084387779236
Epoch 7
	 Logging train Loss: 0.0696714763 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.030937759205698967 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.11618432402610779 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 34.04101777076721
Epoch 8
	 Logging train Loss: 0.0426020504 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.014237799681723118 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.08101681619882584 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 34.38247776031494
Epoch 9
	 Logging train Loss: 0.045520219 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.0099012590944767 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.06719321757555008 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 32.632723569869995
Epoch 10
	 Logging train Loss: 0.0390887541 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.004076315090060234 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.04345548152923584 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 32.47701358795166
Epoch 11
	 Logging train Loss: 0.0399936352 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.006085991393774748 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.05326832830905914 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 32.732956647872925
Epoch 12
	 Logging train Loss: 0.0420842688 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.007012549787759781 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.05730397254228592 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 32.652899503707886
Epoch 13
	 Logging train Loss: 0.038150194 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.004957121796905994 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.048682842403650284 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 34.28906512260437
Epoch 14
	 Logging train Loss: 0.0340453179 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.004649715963751078 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.04674902185797691 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 32.76166558265686
Epoch 15
	 Logging train Loss: 0.0312982846 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.010283408686518669 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.06715377420186996 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 32.71375584602356
Epoch 16
	 Logging train Loss: 0.0361784243 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.013774262741208076 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.07276501506567001 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 32.39543080329895
Epoch 17
	 Logging train Loss: 0.035093664 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.0385676734149456 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.13303688168525696 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 33.152106523513794
Epoch 18
	 Logging train Loss: 0.0274315204 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.003275252878665924 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.039741963148117065 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 32.95942544937134
Epoch 19
	 Logging train Loss: 0.0270719291 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.018089773133397102 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.08758146315813065 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 34.36614370346069
	 Logging test loss 0.018091494217514992 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.087574802339077 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
It took 761.3078780174255 seconds to train & eval the model.
----- ITERATION 2/2 ------
Number of train simulations: 1600
Number of test simulations: 400
The dataloader took 52.337291955947876 seconds.
-- Finished Train Dataloader --
The dataloader took 13.136469602584839 seconds.
-- Finished Test Dataloader(s) --
Datatype: log_dualQ
--- Started Training ---
Epoch 0
	 Logging train Loss: 17.6126136132 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.05372011661529541 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.15748821198940277 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 34.9572479724884
Epoch 1
	 Logging train Loss: 0.0709096073 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.06584872305393219 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.16632592678070068 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 32.772403955459595
Epoch 2
	 Logging train Loss: 0.0675622379 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.02394014783203602 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.10864993184804916 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 32.731910705566406
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.029 MB of 0.029 MB uploaded (0.000 MB deduped)wandb: \ 0.029 MB of 0.029 MB uploaded (0.000 MB deduped)wandb: | 0.029 MB of 0.029 MB uploaded (0.000 MB deduped)wandb: / 0.029 MB of 0.029 MB uploaded (0.000 MB deduped)wandb: - 0.029 MB of 0.029 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  Test loss t(5, 20)_r(0, 0)_tennis L1Loss() â–…â–…â–ƒâ–„â–„â–„â–ƒâ–ƒâ–ˆâ–ƒâ–„â–…â–…â–‚â–â–â–â–ƒâ–‚â–ƒâ–ƒ
wandb: Test loss t(5, 20)_r(0, 0)_tennis MSELoss() â–„â–„â–‚â–ƒâ–ƒâ–ƒâ–‚â–‚â–ˆâ–‚â–ƒâ–„â–„â–â–â–â–â–‚â–â–‚â–‚
wandb:     Train loss data_t(5, 20)_r(0, 0)_tennis â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:  Test loss t(5, 20)_r(0, 0)_tennis L1Loss() 0.08477
wandb: Test loss t(5, 20)_r(0, 0)_tennis MSELoss() 0.01712
wandb:     Train loss data_t(5, 20)_r(0, 0)_tennis 0.03214
wandb: 
wandb: ðŸš€ View run pleasant-lake-637 at: https://wandb.ai/nreints/test/runs/n8dbdbi8
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230330_124931-n8dbdbi8/logs
Epoch 3
	 Logging train Loss: 0.0614250931 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.0336068794131279 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.12614847719669342 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 32.16856837272644
Epoch 4
	 Logging train Loss: 0.0592695897 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.033525142818689346 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.12479756027460098 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 34.28787541389465
Epoch 5
	 Logging train Loss: 0.0559317944 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.035388268530368805 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.12875230610370636 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 34.001895904541016
Epoch 6
	 Logging train Loss: 0.0543480917 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.01930290088057518 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.09599452465772629 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 34.09842491149902
Epoch 7
	 Logging train Loss: 0.0508583966 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.016868118196725845 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.08915261924266815 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 32.86662197113037
Epoch 8
	 Logging train Loss: 0.0550722209 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.14271454513072968 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.23831523954868317 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 32.763787508010864
Epoch 9
	 Logging train Loss: 0.0518993702 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.022923734039068222 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.10224524140357971 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 32.98368549346924
Epoch 10
	 Logging train Loss: 0.0435204849 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.03692157566547394 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.11600144952535629 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 32.61392855644226
Epoch 11
	 Logging train Loss: 0.0418803845 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.05957134813070297 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.15679794549942017 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 34.51538348197937
Epoch 12
	 Logging train Loss: 0.0400588615 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.053559739142656326 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.14227843284606934 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 32.64303946495056
Epoch 13
	 Logging train Loss: 0.0398626789 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.008344082161784172 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.060396235436201096 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 32.87861227989197
Epoch 14
	 Logging train Loss: 0.0429880878 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.004045183304697275 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.04174138233065605 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 32.83727836608887
Epoch 15
	 Logging train Loss: 0.0358831318 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.004681863822042942 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.04441248998045921 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 32.50891709327698
Epoch 16
	 Logging train Loss: 0.03374926 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.0035401962231844664 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.03909451141953468 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 35.065696477890015
Epoch 17
	 Logging train Loss: 0.0329657686 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.017806190997362137 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.08697222173213959 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 34.92399287223816
Epoch 18
	 Logging train Loss: 0.0334942537 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.012343176640570164 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.07216235250234604 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 34.57488203048706
Epoch 19
	 Logging train Loss: 0.0321428286 (MSELoss(): data_t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.01712062954902649 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.08477703481912613 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
     --> Epoch time; 32.62287402153015
	 Logging test loss 0.017120758071541786 (MSELoss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
	 Logging test loss 0.08477240055799484 (L1Loss(): t(5, 20)_r(0, 0)_tennis_pNone_gNone)
It took 750.992152929306 seconds to train & eval the model.

JOB STATISTICS
==============
Job ID: 2523395
Array Job ID: 2523368_27
Cluster: snellius
User/Group: nreints/nreints
State: COMPLETED (exit code 0)
Nodes: 1
Cores per node: 18
CPU Utilized: 04:03:29
CPU Efficiency: 53.08% of 07:38:42 core-walltime
Job Wall-clock time: 00:25:29
Memory Utilized: 3.42 GB
Memory Efficiency: 11.68% of 29.30 GB
