wandb: Currently logged in as: nreints. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_231702-4nku7bf8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run mild-bee-1149
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/4nku7bf8
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue â–ˆâ–„â–‚â–â–ƒâ–â–â–â–â–
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue â–ˆâ–„â–‚â–â–â–â–â–â–â–
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue â–ˆâ–„â–‚â–â–ƒâ–â–â–‚â–â–
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue â–ˆâ–„â–‚â–â–ƒâ–â–â–‚â–â–
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue 0.0
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue 0.0
wandb:                                 Train loss 2e-05
wandb: 
wandb: ðŸš€ View run mild-bee-1149 at: https://wandb.ai/nreints/ThesisFinal2/runs/4nku7bf8
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_231702-4nku7bf8/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_232449-rm38a6h0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dulcet-darkness-1156
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/rm38a6h0
Training on dataset: data_t(0,0)_r(0,0)_combi_pNone_gTrue
Testing on 4 datasets: ['data_t(0,0)_r(0,0)_semi_pNone_gTrue', 'data_t(0,0)_r(0,0)_combi_pNone_gTrue', 'data_t(0,0)_r(0,0)_full_pNone_gTrue', 'data_t(0,0)_r(0,0)_tennis_pNone_gTrue']
Focussing on identity: False
Using extra input: False
Using start-fr as reference point.
----- ITERATION 1/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 78.74169898033142 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_semi_pNone_gTrue took 19.69335126876831 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 19.85442543029785 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pNone_gTrue took 19.99190926551819 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pNone_gTrue took 19.911847591400146 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: log_quat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0434788503 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.45303e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 4.89569e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.27143e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 5.57553e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 30.878122329711914
Epoch 1/9
	 Logging train Loss: 5.06808e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.11216e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.04244e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.96755e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.12427e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 29.18829107284546
Epoch 2/9
	 Logging train Loss: 4.88e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 9.6933e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 9.3064e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.8968e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 9.7469e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 29.273209810256958
Epoch 3/9
	 Logging train Loss: 2.83529e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.2741e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 3.8758e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.4443e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 4.3294e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 29.117143154144287
Epoch 4/9
	 Logging train Loss: 2.62288e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.91831e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.1424e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.5439e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.00099e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 29.17486596107483
Epoch 5/9
	 Logging train Loss: 3.16114e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.1959e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.1005e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.0037e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.213e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 29.45243787765503
Epoch 6/9
	 Logging train Loss: 2.57934e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.2656e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 9.75e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.51e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.2928e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 29.133314609527588
Epoch 7/9
	 Logging train Loss: 1.96315e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.6074e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 3.292e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.387e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 6.3647e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 29.150068759918213
Epoch 8/9
	 Logging train Loss: 2.19018e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.2467e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 8.306e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.272e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.3766e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 29.375336170196533
Epoch 9/9
	 Logging train Loss: 1.93793e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.8738e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.7433e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.25e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.1148e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 29.823535680770874
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'log_quat'_'False'.pth
It took  468.0094337463379  seconds.
----- ITERATION 2/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 72.57166767120361 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_semi_pNone_gTrue took 18.28965711593628 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 18.19625496864319 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pNone_gTrue took 18.337071895599365 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pNone_gTrue took 18.324921131134033 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: log_quat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0369195677 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.57394e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 3.13035e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.71065e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.62683e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 29.673956394195557
Epoch 1/9
	 Logging train Loss: 4.23941e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.87672e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.42151e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 9.5848e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.93405e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 29.60524320602417
Epoch 2/9
	 Logging train Loss: 3.63044e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.8013e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 5.9407e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.0345e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 6.9123e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 29.410240411758423
Epoch 3/9
	 Logging train Loss: 3.0619e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.3131e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.9933e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.6536e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.3551e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 29.526862144470215
Epoch 4/9
	 Logging train Loss: 3.13631e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue â–…â–ƒâ–‚â–â–â–â–ƒâ–ˆâ–â–‚
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue â–ˆâ–ƒâ–‚â–‚â–â–â–â–‚â–â–
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue â–„â–‚â–â–â–â–â–ƒâ–ˆâ–â–‚
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue â–ƒâ–‚â–â–â–â–â–ƒâ–ˆâ–â–‚
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue 1e-05
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue 1e-05
wandb:                                 Train loss 2e-05
wandb: 
wandb: ðŸš€ View run dulcet-darkness-1156 at: https://wandb.ai/nreints/ThesisFinal2/runs/rm38a6h0
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_232449-rm38a6h0/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_233222-wpvm2xgx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run logical-dust-1167
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/wpvm2xgx
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue â–ƒâ–‚â–‚â–ƒâ–â–â–â–ˆâ–â–
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue â–ˆâ–…â–„â–ƒâ–‚â–‚â–‚â–„â–â–
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue â–ƒâ–‚â–â–ƒâ–â–â–â–ˆâ–â–
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue â–ƒâ–‚â–â–„â–â–â–â–ˆâ–â–
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue 0.0
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue 0.0
wandb:                                 Train loss 3e-05
wandb: 
wandb: ðŸš€ View run logical-dust-1167 at: https://wandb.ai/nreints/ThesisFinal2/runs/wpvm2xgx
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_233222-wpvm2xgx/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_233955-a2k04og3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wobbly-donkey-1175
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/a2k04og3
	 Logging test loss: 1.8111e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.5832e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.3458e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.8395e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 29.559087991714478
Epoch 5/9
	 Logging train Loss: 3.40536e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.0734e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 9.459e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.132e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.089e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 29.483094930648804
Epoch 6/9
	 Logging train Loss: 1.83832e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.26385e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.74946e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.1482e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.36542e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 29.44477868080139
Epoch 7/9
	 Logging train Loss: 2.83966e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 9.59191e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 5.16673e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.7779e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 0.0001034971 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 29.574693202972412
Epoch 8/9
	 Logging train Loss: 1.99128e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.258e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 5.794e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.283e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 6.341e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 29.28201699256897
Epoch 9/9
	 Logging train Loss: 1.73635e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.9695e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 4.5481e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.1329e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 8.5161e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 29.52855682373047
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'log_quat'_'False'.pth
It took  452.8961944580078  seconds.
----- ITERATION 3/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 72.26208758354187 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_semi_pNone_gTrue took 18.30007314682007 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 18.145607471466064 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pNone_gTrue took 18.273987770080566 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pNone_gTrue took 18.288861513137817 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: log_quat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0376879163 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.79305e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 5.19355e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.27906e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 8.08684e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 29.40293288230896
Epoch 1/9
	 Logging train Loss: 3.56891e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.28352e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.58929e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.00708e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.37438e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 29.56123971939087
Epoch 2/9
	 Logging train Loss: 4.59406e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.43416e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.34774e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.28219e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.44507e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 29.49497127532959
Epoch 3/9
	 Logging train Loss: 3.46612e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0001137496 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 5.64044e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.20207e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 0.0001214743 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 29.40191650390625
Epoch 4/9
	 Logging train Loss: 3.35269e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.3093e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 7.0954e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.9315e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 7.3275e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 29.262070894241333
Epoch 5/9
	 Logging train Loss: 3.10159e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.8471e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 5.7369e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.6505e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 5.8639e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 29.577943801879883
Epoch 6/9
	 Logging train Loss: 2.65226e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.7749e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 6.3218e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.4873e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 9.0386e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 29.642736434936523
Epoch 7/9
	 Logging train Loss: 4.30718e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0003258192 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 0.0001600237 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.6737e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 0.0003325286 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 29.53189706802368
Epoch 8/9
	 Logging train Loss: 1.52823e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.4415e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.3473e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.2766e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.4559e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 29.767152309417725
Epoch 9/9
	 Logging train Loss: 3.26307e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.5617e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.4938e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.4393e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.572e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 30.33538269996643
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'log_quat'_'False'.pth
It took  453.1613132953644  seconds.
----- ITERATION 4/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 72.24066591262817 seconds.
-- Finished Train Dataloader --
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue â–ˆâ–…â–‚â–‚â–â–„â–â–â–â–
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue â–ˆâ–†â–‚â–ƒâ–â–†â–â–â–â–
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue â–ˆâ–‡â–‚â–ƒâ–â–‡â–â–â–â–
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue 0.0
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue 0.0
wandb:                                 Train loss 1e-05
wandb: 
wandb: ðŸš€ View run wobbly-donkey-1175 at: https://wandb.ai/nreints/ThesisFinal2/runs/a2k04og3
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_233955-a2k04og3/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_234727-p4kw4pwm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glad-sponge-1185
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/p4kw4pwm
The dataloader for data/data_t(0,0)_r(0,0)_semi_pNone_gTrue took 18.25818109512329 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 18.16521906852722 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pNone_gTrue took 18.26313090324402 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pNone_gTrue took 18.239420413970947 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: log_quat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0473829173 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.19672e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 4.82136e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.40125e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 5.24193e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 29.598883390426636
Epoch 1/9
	 Logging train Loss: 3.50874e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.06336e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.87674e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.41518e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 4.26889e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 29.378110647201538
Epoch 2/9
	 Logging train Loss: 1.95329e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.3582e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 5.023e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.6684e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 5.3937e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 29.692099809646606
Epoch 3/9
	 Logging train Loss: 2.76208e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.2425e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 7.6334e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.6476e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.30407e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 29.36848759651184
Epoch 4/9
	 Logging train Loss: 3.045e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.6468e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.4766e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.2881e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.6665e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 29.354546546936035
Epoch 5/9
	 Logging train Loss: 4.13394e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.9778e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.29982e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.5074e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 4.24071e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 29.406490325927734
Epoch 6/9
	 Logging train Loss: 6.5706e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.428e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 7.363e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.192e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 8.546e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 29.388198375701904
Epoch 7/9
	 Logging train Loss: 3.89035e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.0627e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 8.227e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.835e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.0821e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 29.6615047454834
Epoch 8/9
	 Logging train Loss: 3.17565e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.433e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 6.53e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.576e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 7.529e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 29.552307605743408
Epoch 9/9
	 Logging train Loss: 1.1464e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.653e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 6.315e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.714e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 7.837e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 29.31597113609314
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'log_quat'_'False'.pth
It took  452.3937335014343  seconds.
----- ITERATION 5/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 72.38765382766724 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_semi_pNone_gTrue took 18.227376222610474 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 18.149677753448486 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pNone_gTrue took 18.249500513076782 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pNone_gTrue took 18.233518838882446 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: log_quat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0326697715 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.69692e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 5.39945e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.08383e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 5.75182e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 29.759516954421997
Epoch 1/9
	 Logging train Loss: 4.08092e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.95275e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.84366e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.72751e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.97315e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 29.297517776489258
Epoch 2/9
	 Logging train Loss: 3.90449e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.65869e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.15378e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.65923e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.65735e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 29.451526880264282
Epoch 3/9
	 Logging train Loss: 3.3727e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0001145346 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 6.73582e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.23999e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 0.0001212184 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 29.190343856811523
Epoch 4/9
	 Logging train Loss: 3.43042e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.7151e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 7.7318e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.7068e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 8.8855e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 29.297648668289185
Epoch 5/9
	 Logging train Loss: 3.61358e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0003114825 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue â–ƒâ–‚â–‚â–„â–â–ˆâ–â–â–â–
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue â–ˆâ–…â–ƒâ–‚â–‚â–ƒâ–â–â–â–
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue â–‚â–‚â–‚â–„â–â–ˆâ–â–â–â–
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue â–‚â–‚â–‚â–„â–â–ˆâ–â–â–â–
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue 1e-05
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue 1e-05
wandb:                                 Train loss 1e-05
wandb: 
wandb: ðŸš€ View run glad-sponge-1185 at: https://wandb.ai/nreints/ThesisFinal2/runs/p4kw4pwm
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_234727-p4kw4pwm/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_235458-t25vqjkg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lemon-fog-1195
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/t25vqjkg
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue â–…â–ƒâ–‚â–‡â–â–‚â–â–‚â–â–ˆ
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue â–ˆâ–„â–‚â–ƒâ–â–â–â–â–â–‚
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue â–ƒâ–‚â–â–†â–â–‚â–â–‚â–â–ˆ
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue â–ƒâ–‚â–â–†â–â–‚â–â–‚â–â–ˆ
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 8e-05
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue 1e-05
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue 0.00014
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue 0.00018
wandb:                                 Train loss 2e-05
wandb: 
wandb: ðŸš€ View run lemon-fog-1195 at: https://wandb.ai/nreints/ThesisFinal2/runs/t25vqjkg
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_235458-t25vqjkg/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230710_000231-vdfc9dwb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dulcet-pine-1203
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/vdfc9dwb
	 Logging test loss: 0.0001682587 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.39742e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 0.000312551 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 29.49710178375244
Epoch 6/9
	 Logging train Loss: 2.36912e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.7117e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 4.6235e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.5303e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 4.7179e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 29.38062572479248
Epoch 7/9
	 Logging train Loss: 2.01666e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.04351e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 7.0919e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.7359e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.10753e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 29.32019281387329
Epoch 8/9
	 Logging train Loss: 1.85242e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.8021e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.71e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.6131e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.806e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 29.224855422973633
Epoch 9/9
	 Logging train Loss: 1.43694e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.8261e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 4.5032e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.9542e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 7.0087e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 29.903188705444336
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'log_quat'_'False'.pth
It took  450.9160990715027  seconds.
----- ITERATION 6/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 72.29173350334167 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_semi_pNone_gTrue took 18.37983226776123 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 18.25796151161194 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pNone_gTrue took 18.265761375427246 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pNone_gTrue took 18.282724380493164 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: log_quat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0383896455 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.6108e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 4.203e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.70557e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 4.82417e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 29.368977546691895
Epoch 1/9
	 Logging train Loss: 3.13509e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.55593e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.03029e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.45947e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.72975e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 29.56141448020935
Epoch 2/9
	 Logging train Loss: 4.37437e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.2156e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 7.5857e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.8489e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 8.4686e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 29.489384651184082
Epoch 3/9
	 Logging train Loss: 2.24465e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.00011209 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 6.46754e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.07311e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 0.0001301381 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 29.497921228408813
Epoch 4/9
	 Logging train Loss: 3.24836e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.6103e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.2031e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.7411e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.7596e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 29.343250513076782
Epoch 5/9
	 Logging train Loss: 2.60812e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.95099e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.11453e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.6235e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.3869e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 29.505945205688477
Epoch 6/9
	 Logging train Loss: 2.02038e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.0581e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 4.3587e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 9.872e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 8.7744e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 29.18117928504944
Epoch 7/9
	 Logging train Loss: 2.74967e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.52303e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 8.7557e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 9.115e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.82696e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 29.596249103546143
Epoch 8/9
	 Logging train Loss: 1.68557e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.31e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 5.235e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.09e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 6.599e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 29.713950872421265
Epoch 9/9
	 Logging train Loss: 1.85123e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0001442867 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 7.95621e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.1107e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 0.0001764063 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 29.512929677963257
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'log_quat'_'False'.pth
It took  452.9224498271942  seconds.
----- ITERATION 7/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 72.17554521560669 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_semi_pNone_gTrue took 18.15973949432373 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 18.08731484413147 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pNone_gTrue took 18.148144245147705 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pNone_gTrue took 18.16538643836975 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: log_quat
-- Started Training --
Epoch 0/9
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue â–ˆâ–„â–ƒâ–‚â–‚â–â–‚â–ƒâ–â–…
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue â–ˆâ–„â–ƒâ–‚â–‚â–â–â–â–â–‚
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue â–ˆâ–„â–ƒâ–‚â–‚â–â–‚â–„â–â–ˆ
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue â–‡â–„â–ƒâ–‚â–â–â–‚â–„â–â–ˆ
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 2e-05
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue 4e-05
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue 5e-05
wandb:                                 Train loss 2e-05
wandb: 
wandb: ðŸš€ View run dulcet-pine-1203 at: https://wandb.ai/nreints/ThesisFinal2/runs/vdfc9dwb
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230710_000231-vdfc9dwb/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230710_000957-1wgbotcr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rare-aardvark-1213
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/1wgbotcr
	 Logging train Loss: 0.0413136184 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.9675e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 3.63003e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.30456e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 4.0326e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 28.944185972213745
Epoch 1/9
	 Logging train Loss: 3.92819e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.79746e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.67897e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.55207e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.82643e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 29.021700143814087
Epoch 2/9
	 Logging train Loss: 3.98711e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.38479e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.15971e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 9.202e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.45076e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 28.971438884735107
Epoch 3/9
	 Logging train Loss: 3.44431e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.8283e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 5.6671e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.4869e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 5.8756e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 29.008618116378784
Epoch 4/9
	 Logging train Loss: 4.42009e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.8841e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 3.7677e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.6428e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.9183e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 28.728588342666626
Epoch 5/9
	 Logging train Loss: 2.89576e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.6238e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.506e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.3853e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.6531e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 29.218254804611206
Epoch 6/9
	 Logging train Loss: 1.86504e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.5387e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 3.8179e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.7772e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 6.2131e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 29.10979700088501
Epoch 7/9
	 Logging train Loss: 2.24535e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.66929e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 9.1732e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.3317e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.83982e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 29.282885313034058
Epoch 8/9
	 Logging train Loss: 2.25608e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.0371e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 8.512e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.64e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.0801e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 28.94560980796814
Epoch 9/9
	 Logging train Loss: 2.25638e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.01603e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.33273e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.0071e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 4.63059e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 29.15022921562195
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'log_quat'_'False'.pth
It took  445.99565839767456  seconds.
----- ITERATION 8/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 72.03235816955566 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_semi_pNone_gTrue took 18.190349578857422 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 18.106194734573364 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pNone_gTrue took 18.199994802474976 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pNone_gTrue took 18.161890506744385 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: log_quat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0351691097 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.28774e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 3.94939e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.64856e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 4.34513e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 28.97559905052185
Epoch 1/9
	 Logging train Loss: 4.66539e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.01908e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.91624e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.81865e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.04133e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 28.986408472061157
Epoch 2/9
	 Logging train Loss: 3.79773e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.41548e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.26159e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.12224e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.44202e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 28.803911209106445
Epoch 3/9
	 Logging train Loss: 4.90574e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 9.4097e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 8.5448e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.7881e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 9.5393e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 28.76226830482483
Epoch 4/9
	 Logging train Loss: 2.45919e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.24319e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 9.266e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.4071e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.3192e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 28.799097537994385
Epoch 5/9
	 Logging train Loss: 3.63549e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.0647e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 7.6953e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.9935e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.11151e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 29.179535627365112
Epoch 6/9
	 Logging train Loss: 3.56507e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.4254e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 3.3491e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.284e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue â–â–â–â–â–â–â–â–â–‚â–ˆ
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue â–ˆâ–„â–ƒâ–‚â–‚â–‚â–â–â–‚â–‡
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue â–â–â–â–â–â–â–â–â–‚â–ˆ
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue â–â–â–â–â–â–â–â–â–‚â–ˆ
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 0.00057
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue 3e-05
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue 0.00117
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue 0.00126
wandb:                                 Train loss 2e-05
wandb: 
wandb: ðŸš€ View run rare-aardvark-1213 at: https://wandb.ai/nreints/ThesisFinal2/runs/1wgbotcr
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230710_000957-1wgbotcr/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230710_001730-p2uvn4ei
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run chocolate-shape-1220
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/p2uvn4ei
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue â–ƒâ–‚â–‚â–â–ƒâ–â–â–â–†â–ˆ
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue â–ˆâ–…â–ƒâ–‚â–‚â–â–â–â–‚â–ƒ
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue â–‚â–‚â–â–â–ƒâ–â–â–â–†â–ˆ
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue â–‚â–‚â–â–â–ƒâ–â–â–â–†â–ˆ
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 0.00021
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue 2e-05
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue 0.00037
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue 0.00036
wandb:                                 Train loss 2e-05
wandb: 
wandb: ðŸš€ View run chocolate-shape-1220 at: https://wandb.ai/nreints/ThesisFinal2/runs/p2uvn4ei
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230710_001730-p2uvn4ei/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230710_002456-3jo93pv5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run elated-paper-1229
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/3jo93pv5
	 Logging test loss: 3.4386e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 28.927231550216675
Epoch 7/9
	 Logging train Loss: 2.0887e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.9495e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.8045e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.6711e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.985e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 28.66994071006775
Epoch 8/9
	 Logging train Loss: 2.33543e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0002249257 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 0.0001084542 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.6128e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 0.0002403545 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 28.655073642730713
Epoch 9/9
	 Logging train Loss: 1.60316e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0011726682 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 0.000565331 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.38199e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 0.0012607418 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 28.874573707580566
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'log_quat'_'False'.pth
It took  453.02137875556946  seconds.
----- ITERATION 9/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 71.97370505332947 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_semi_pNone_gTrue took 18.151623487472534 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 18.132375955581665 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pNone_gTrue took 18.187302112579346 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pNone_gTrue took 18.21621561050415 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: log_quat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0473116003 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.59297e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 5.93327e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.18689e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 6.57822e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 28.699138641357422
Epoch 1/9
	 Logging train Loss: 4.36693e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.53536e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 3.35552e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.15332e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.52677e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 29.05495023727417
Epoch 2/9
	 Logging train Loss: 3.59098e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.13473e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.08068e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.01805e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.13264e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 28.908020496368408
Epoch 3/9
	 Logging train Loss: 4.56263e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.28248e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.81025e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.27833e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.29706e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 28.88005805015564
Epoch 4/9
	 Logging train Loss: 3.06369e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0001291461 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 7.63373e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.22874e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 0.0001318086 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 28.932971477508545
Epoch 5/9
	 Logging train Loss: 5.59407e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.9281e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 7.6683e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.3752e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 7.9172e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 29.061479330062866
Epoch 6/9
	 Logging train Loss: 1.24099e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.6116e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 6.5329e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.4451e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 6.6086e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 28.754786014556885
Epoch 7/9
	 Logging train Loss: 2.73613e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.6468e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 5.5877e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.5213e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 5.6396e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 28.921379327774048
Epoch 8/9
	 Logging train Loss: 2.26605e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0002421889 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 0.0001380831 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.24771e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 0.0002469085 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 28.851306915283203
Epoch 9/9
	 Logging train Loss: 1.56966e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0003683821 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 0.0002114945 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.63543e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 0.0003629904 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 28.85294818878174
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'log_quat'_'False'.pth
It took  445.89239144325256  seconds.
----- ITERATION 10/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 72.10048651695251 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_semi_pNone_gTrue took 18.199629306793213 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 18.172597646713257 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pNone_gTrue took 18.203417539596558 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pNone_gTrue took 18.218331813812256 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: log_quat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0431211367 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.2395e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 3.99726e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.75941e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 4.2706e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 28.90271759033203
Epoch 1/9
	 Logging train Loss: 3.69588e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue â–â–ˆâ–â–â–â–â–‚â–â–â–
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue â–ƒâ–ˆâ–â–â–â–â–‚â–â–â–
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue â–â–ˆâ–â–â–â–â–‚â–â–â–
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue â–â–ˆâ–â–â–â–â–‚â–â–â–
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 1e-05
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue 2e-05
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue 2e-05
wandb:                                 Train loss 1e-05
wandb: 
wandb: ðŸš€ View run elated-paper-1229 at: https://wandb.ai/nreints/ThesisFinal2/runs/3jo93pv5
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230710_002456-3jo93pv5/logs
	 Logging test loss: 0.0039115842 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 0.0020312103 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.000124392 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 0.0042442731 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 29.07232689857483
Epoch 2/9
	 Logging train Loss: 4.41301e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.4756e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 7.176e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.8838e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 7.5267e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 28.92325258255005
Epoch 3/9
	 Logging train Loss: 2.05878e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.75367e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.06844e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.9286e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.88348e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 28.979299068450928
Epoch 4/9
	 Logging train Loss: 3.59333e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.9628e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 4.417e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.8015e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 7.2288e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 28.734710693359375
Epoch 5/9
	 Logging train Loss: 2.02034e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.3516e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.3053e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.2105e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.5959e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 28.8670392036438
Epoch 6/9
	 Logging train Loss: 2.20495e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0004680612 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 0.0002436801 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.59557e-05 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 0.000512913 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 28.87355065345764
Epoch 7/9
	 Logging train Loss: 2.68228e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 9.6546e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 5.3118e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 9.878e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.05678e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 29.03076410293579
Epoch 8/9
	 Logging train Loss: 1.6149e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.139e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 6.297e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.567e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 8.351e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 29.19132161140442
Epoch 9/9
	 Logging train Loss: 1.40634e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.56133e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 8.3715e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 9.095e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.73593e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 29.329312562942505
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'log_quat'_'False'.pth
It took  445.882732629776  seconds.

JOB STATISTICS
==============
Job ID: 3039255
Array Job ID: 3039249_30
Cluster: snellius
User/Group: nreints/nreints
State: COMPLETED (exit code 0)
Nodes: 1
Cores per node: 18
CPU Utilized: 01:21:28
CPU Efficiency: 5.99% of 22:41:06 core-walltime
Job Wall-clock time: 01:15:37
Memory Utilized: 7.69 GB
Memory Efficiency: 0.00% of 0.00 MB
