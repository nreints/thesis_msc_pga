wandb: Currently logged in as: nreints. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_180950-06ifqerd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glowing-disco-941
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/06ifqerd
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue █▆▂▂▂▁▁▁▁▁
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue ▄▁▁▂▆▅▆█▇█
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue █▇▆▆▅▄▂▃▁▁
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue █▆▆▅▄▃▂▂▁▁
wandb:                                 Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 0.00409
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.09279
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.18971
wandb:                                 Train loss 2e-05
wandb: 
wandb: 🚀 View run glowing-disco-941 at: https://wandb.ai/nreints/ThesisFinal2/runs/06ifqerd
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_180950-06ifqerd/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_181808-jx7uivgr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run splendid-paper-962
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/jx7uivgr
Training on dataset: data_t(0,0)_r(0,0)_combi_pNone_gTrue
Testing on 4 datasets: ['data_t(0,0)_r(0,0)_tennis_pTrue_gTrue', 'data_t(0,0)_r(0,0)_combi_pNone_gTrue', 'data_t(0,0)_r(0,0)_semi_pTrue_gTrue', 'data_t(0,0)_r(0,0)_full_pTrue_gTrue']
Focussing on identity: False
Using extra input: True
Using start-fr as reference point.
----- ITERATION 1/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 86.34504914283752 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 21.70493745803833 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 21.86703610420227 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 21.83483362197876 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 21.80499505996704 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (pre_hidden_lin_layer): Sequential(
    (0): Linear(in_features=3, out_features=96, bias=True)
    (1): ReLU()
    (2): Linear(in_features=96, out_features=96, bias=True)
    (3): ReLU()
  )
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: log_quat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0368262865 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.2025585771 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 8.77203e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0966178998 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0040695542 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 32.27401423454285
Epoch 1/9
	 Logging train Loss: 4.68844e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1992252618 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 5.87074e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0959130526 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0040606954 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 31.23897361755371
Epoch 2/9
	 Logging train Loss: 3.9408e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1993479878 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.06556e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0954944417 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0040589706 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 30.98242712020874
Epoch 3/9
	 Logging train Loss: 4.55635e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1966887712 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.20785e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0954054445 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0040642405 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 30.90685486793518
Epoch 4/9
	 Logging train Loss: 5.39849e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1955798864 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 8.8133e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0948760509 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0040767826 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 30.9142324924469
Epoch 5/9
	 Logging train Loss: 2.3061e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.193924427 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.7934e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0945401862 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0040739849 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 30.724632740020752
Epoch 6/9
	 Logging train Loss: 4.52665e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1921245009 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.2628e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0935818106 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0040787272 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 30.942238807678223
Epoch 7/9
	 Logging train Loss: 2.28882e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1909541041 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.5716e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0938386694 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.004084642 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 30.98692560195923
Epoch 8/9
	 Logging train Loss: 2.11751e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1897390485 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 7.919e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0929997414 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0040829666 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 30.868727445602417
Epoch 9/9
	 Logging train Loss: 2.35761e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1897107065 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.1719e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0927906185 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0040856823 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 30.96856141090393
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'log_quat'_'True'.pth
It took  498.9880359172821  seconds.
----- ITERATION 2/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 78.88369679450989 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 20.055186986923218 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 19.867668867111206 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 20.063403606414795 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 20.09049916267395 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (pre_hidden_lin_layer): Sequential(
    (0): Linear(in_features=3, out_features=96, bias=True)
    (1): ReLU()
    (2): Linear(in_features=96, out_features=96, bias=True)
    (3): ReLU()
  )
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: log_quat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0296439268 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.2756589353 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 9.54264e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1086042225 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0041272035 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 31.21461272239685
Epoch 1/9
	 Logging train Loss: 5.99862e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.2743372619 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.94877e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1074754521 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.004092711 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 31.286895751953125
Epoch 2/9
	 Logging train Loss: 4.2225e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.2690548003 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 7.4296e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1062168479 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0040704622 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 31.15815496444702
Epoch 3/9
	 Logging train Loss: 3.40812e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue ▅▂▁█▃▁▃▃▆▁
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue █▆▄▄▃▃▃▂▂▁
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue █▇▆▅▄▄▃▃▂▁
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue █▇▄▃▃▂▂▂▂▁
wandb:                                 Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 0.00402
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.10176
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.26392
wandb:                                 Train loss 2e-05
wandb: 
wandb: 🚀 View run splendid-paper-962 at: https://wandb.ai/nreints/ThesisFinal2/runs/jx7uivgr
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_181808-jx7uivgr/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_182611-yw936vfc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fluent-sound-982
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/yw936vfc
	 Logging test loss: 0.2677769959 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0001872302 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1053834334 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0040693381 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 30.973854541778564
Epoch 4/9
	 Logging train Loss: 3.66086e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.2669348121 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 5.20924e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1050806269 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0040596589 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 31.20539402961731
Epoch 5/9
	 Logging train Loss: 2.40325e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.2656825185 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 5.3843e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1043561623 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0040543042 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 31.204278707504272
Epoch 6/9
	 Logging train Loss: 3.86081e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.2651107609 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 5.10838e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.103560105 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0040455996 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 31.254735469818115
Epoch 7/9
	 Logging train Loss: 1.83363e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.2664157152 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 4.78206e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.103234075 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0040402259 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 31.159565448760986
Epoch 8/9
	 Logging train Loss: 3.02542e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.2655827403 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0001433906 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1027834639 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0040408624 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 31.221805572509766
Epoch 9/9
	 Logging train Loss: 1.72416e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.2639189959 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.3009e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1017563865 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0040227389 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 31.26430892944336
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'log_quat'_'True'.pth
It took  483.2284891605377  seconds.
----- ITERATION 3/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 80.293785572052 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 20.17021942138672 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 20.1801495552063 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 20.106385231018066 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 20.14217472076416 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (pre_hidden_lin_layer): Sequential(
    (0): Linear(in_features=3, out_features=96, bias=True)
    (1): ReLU()
    (2): Linear(in_features=96, out_features=96, bias=True)
    (3): ReLU()
  )
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: log_quat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0440387353 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.3022771478 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 6.75735e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.3131347895 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0041305856 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 31.371186017990112
Epoch 1/9
	 Logging train Loss: 3.52042e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.3012718558 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.54463e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.3142482638 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0041024061 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 31.435312032699585
Epoch 2/9
	 Logging train Loss: 3.34794e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.3028896153 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 9.4487e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.314353466 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0041162213 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 31.40367293357849
Epoch 3/9
	 Logging train Loss: 4.54775e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.3020511866 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.28896e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.3136766255 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0041283695 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 31.189210653305054
Epoch 4/9
	 Logging train Loss: 2.56002e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.3010285497 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 3.7194e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.3093238771 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0041376948 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 31.02836585044861
Epoch 5/9
	 Logging train Loss: 4.10543e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.2958340645 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.1142e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.3088816702 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0041419608 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 31.05817151069641
Epoch 6/9
	 Logging train Loss: 2.62791e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.2932509184 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.3646e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.3035313487 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0041491273 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 31.421530961990356
Epoch 7/9
	 Logging train Loss: 3.27016e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.288056463 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.0826e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.2997947633 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0041576298 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 31.065734386444092
Epoch 8/9
	 Logging train Loss: 1.83523e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.2864889503 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.05634e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.2975539863 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0041769785 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 31.263566970825195
Epoch 9/9
	 Logging train Loss: 1.88516e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue █▄▂▂▁▁▁▁▂▁
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue ▃▁▂▃▄▄▅▆▇█
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue ▇███▆▆▃▂▁▂
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue █▇██▇▅▄▂▂▁
wandb:                                 Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 0.00419
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.29897
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.28484
wandb:                                 Train loss 2e-05
wandb: 
wandb: 🚀 View run fluent-sound-982 at: https://wandb.ai/nreints/ThesisFinal2/runs/yw936vfc
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_182611-yw936vfc/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_183416-ou4zkllj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run resilient-serenity-1005
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/ou4zkllj
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue ▄▂▇▃▁▁▂▂▁█
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue █▆▅▄▄▃▂▂▂▁
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue █▇▆▅▄▄▃▂▁▁
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue █▆▅▃▂▂▁▁▁▁
wandb:                                 Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 0.00012
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 0.00346
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.17414
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.15025
wandb:                                 Train loss 2e-05
wandb: 
wandb: 🚀 View run resilient-serenity-1005 at: https://wandb.ai/nreints/ThesisFinal2/runs/ou4zkllj
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_183416-ou4zkllj/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_184227-pw8o2acg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run trim-feather-1024
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/pw8o2acg
	 Logging test loss: 0.2848415971 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 5.848e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.2989745438 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0041863555 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 31.115849018096924
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'log_quat'_'True'.pth
It took  484.91225934028625  seconds.
----- ITERATION 4/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 79.65053915977478 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 20.0247585773468 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 20.153214693069458 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 20.028295278549194 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 20.120699644088745 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (pre_hidden_lin_layer): Sequential(
    (0): Linear(in_features=3, out_features=96, bias=True)
    (1): ReLU()
    (2): Linear(in_features=96, out_features=96, bias=True)
    (3): ReLU()
  )
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: log_quat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0334785953 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1651039273 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 5.79868e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1938869804 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0035121317 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 31.404364585876465
Epoch 1/9
	 Logging train Loss: 5.62118e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.161906451 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.14746e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1917650998 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0034942771 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 30.896156072616577
Epoch 2/9
	 Logging train Loss: 5.65587e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1582740843 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 9.69939e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1888888925 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0034854175 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 31.261475324630737
Epoch 3/9
	 Logging train Loss: 4.33666e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1551673263 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 3.58121e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1858820319 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0034826722 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 30.91896414756775
Epoch 4/9
	 Logging train Loss: 3.42232e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.15324983 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 5.1924e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1832437217 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0034791925 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 31.462075233459473
Epoch 5/9
	 Logging train Loss: 3.27273e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1519304514 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 4.8874e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1813908815 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0034736604 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 31.48674249649048
Epoch 6/9
	 Logging train Loss: 3.26496e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1511366069 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.14669e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1803131551 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0034667144 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 31.301077604293823
Epoch 7/9
	 Logging train Loss: 3.07161e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1509980112 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.44769e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1779372692 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0034649144 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 31.21256446838379
Epoch 8/9
	 Logging train Loss: 1.81819e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1502141654 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.1033e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1755331755 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0034628122 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 31.125668048858643
Epoch 9/9
	 Logging train Loss: 2.113e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1502474099 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.000121575 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1741409749 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0034574869 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 31.355793952941895
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'log_quat'_'True'.pth
It took  490.42438769340515  seconds.
----- ITERATION 5/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 79.62686538696289 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 20.115482091903687 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 20.027597427368164 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 20.04103994369507 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 20.10776948928833 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (pre_hidden_lin_layer): Sequential(
    (0): Linear(in_features=3, out_features=96, bias=True)
    (1): ReLU()
    (2): Linear(in_features=96, out_features=96, bias=True)
    (3): ReLU()
  )
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: log_quat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0355042443 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1463983506 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 5.57926e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.2754889131 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0033961209 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 31.12615704536438
Epoch 1/9
	 Logging train Loss: 5.41714e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1436491311 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.63211e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.2724460363 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0033667772 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 31.444480419158936
Epoch 2/9
	 Logging train Loss: 4.55187e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.141140148 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.46954e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.2699839473 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue ▅▂▂▁█▁▁▁▁▁
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue █▄▃▂▃▁▂▂▂▁
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue █▇▆▆▅▄▃▃▂▁
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue █▆▅▅▄▃▃▃▂▁
wandb:                                 Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 1e-05
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 0.00334
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.25368
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.13376
wandb:                                 Train loss 2e-05
wandb: 
wandb: 🚀 View run trim-feather-1024 at: https://wandb.ai/nreints/ThesisFinal2/runs/pw8o2acg
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_184227-pw8o2acg/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_185031-a808d2q4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run exalted-water-1042
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/a808d2q4
	 Logging test loss: 0.0033593713 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 31.260730743408203
Epoch 3/9
	 Logging train Loss: 4.73942e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1402509212 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 5.5066e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.2692583203 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0033478492 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 31.09989070892334
Epoch 4/9
	 Logging train Loss: 5.52556e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1400058419 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 9.40311e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.2673294842 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0033592968 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 30.95320153236389
Epoch 5/9
	 Logging train Loss: 3.18586e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.138233602 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 3.3423e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.2634889185 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0033435689 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 31.290749549865723
Epoch 6/9
	 Logging train Loss: 3.58608e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1371089667 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 3.6763e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.261099726 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0033499091 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 31.058094024658203
Epoch 7/9
	 Logging train Loss: 3.60853e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1365585178 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.3302e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.2605419457 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0033505945 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 31.05577802658081
Epoch 8/9
	 Logging train Loss: 1.56019e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1351947635 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.4949e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.2563416958 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0033506195 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 31.18054175376892
Epoch 9/9
	 Logging train Loss: 2.37841e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1337570846 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 6.9376e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.2536803484 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0033410597 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 31.364766120910645
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'log_quat'_'True'.pth
It took  484.09763765335083  seconds.
----- ITERATION 6/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 80.4206051826477 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 20.15598964691162 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 20.198161602020264 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 20.087641954421997 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 20.160735368728638 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (pre_hidden_lin_layer): Sequential(
    (0): Linear(in_features=3, out_features=96, bias=True)
    (1): ReLU()
    (2): Linear(in_features=96, out_features=96, bias=True)
    (3): ReLU()
  )
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: log_quat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0306910407 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1913703382 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 6.71356e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1973627508 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0035992167 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 31.085153579711914
Epoch 1/9
	 Logging train Loss: 4.79038e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1874141842 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.03019e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1901569813 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0035637841 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 31.252822399139404
Epoch 2/9
	 Logging train Loss: 4.28851e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.185203433 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0003091139 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1865616292 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0035655268 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 31.14043116569519
Epoch 3/9
	 Logging train Loss: 3.63454e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1830692589 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 4.71177e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1834922135 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0035672381 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 31.381933450698853
Epoch 4/9
	 Logging train Loss: 3.29713e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1808986813 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.8486e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.179888472 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0035564199 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 31.35011386871338
Epoch 5/9
	 Logging train Loss: 2.95552e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1802300364 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0002278335 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1783652902 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.003563564 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 31.356163263320923
Epoch 6/9
	 Logging train Loss: 2.75659e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1778356731 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.5837e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1759880036 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0035478114 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 31.466240406036377
Epoch 7/9
	 Logging train Loss: 2.44991e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1774587333 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.3063e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1735366136 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0035420426 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 31.188809394836426
Epoch 8/9
	 Logging train Loss: 2.52206e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.175943777 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 7.09542e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1720552146 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue ▂▁█▂▁▆▁▁▃▁
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue █▅▅▅▄▅▃▃▂▁
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue █▆▅▅▄▃▃▂▂▁
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue █▆▆▅▄▄▃▃▂▁
wandb:                                 Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 0.00352
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.16894
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.17337
wandb:                                 Train loss 2e-05
wandb: 
wandb: 🚀 View run exalted-water-1042 at: https://wandb.ai/nreints/ThesisFinal2/runs/a808d2q4
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_185031-a808d2q4/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_185838-khdma0ks
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ethereal-lion-1061
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/khdma0ks
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue █▃▅▂▁▁▂▁▁▁
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue ▃▁▃▂▄▄▄▅▇█
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue █▇█▇▇▇▆▄▃▁
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue █▄▂▂▁▁▁▂▂▃
wandb:                                 Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 1e-05
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 0.00349
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.22511
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.09644
wandb:                                 Train loss 1e-05
wandb: 
wandb: 🚀 View run ethereal-lion-1061 at: https://wandb.ai/nreints/ThesisFinal2/runs/khdma0ks
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_185838-khdma0ks/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_190640-wkdyo2xj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hardy-lake-1079
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/wkdyo2xj
	 Logging test loss: 0.0035349454 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 31.385807037353516
Epoch 9/9
	 Logging train Loss: 1.63698e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1733704209 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.1685e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1689382046 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0035244776 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 31.29896831512451
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'log_quat'_'True'.pth
It took  486.75108075141907  seconds.
----- ITERATION 7/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 78.83321118354797 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 20.058382034301758 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 19.879189252853394 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 20.169952392578125 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 20.123095750808716 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (pre_hidden_lin_layer): Sequential(
    (0): Linear(in_features=3, out_features=96, bias=True)
    (1): ReLU()
    (2): Linear(in_features=96, out_features=96, bias=True)
    (3): ReLU()
  )
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: log_quat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0277382229 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0985375047 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 7.37673e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.2370844632 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0034586284 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 31.11058020591736
Epoch 1/9
	 Logging train Loss: 4.12939e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0968556926 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.09889e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.2363285124 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0034441811 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 31.34096336364746
Epoch 2/9
	 Logging train Loss: 4.21789e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0962349996 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 4.74324e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.2372631431 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0034565357 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 31.073354482650757
Epoch 3/9
	 Logging train Loss: 4.74304e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0961071998 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 9.8499e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.2362068743 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0034501932 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 30.94843363761902
Epoch 4/9
	 Logging train Loss: 3.56846e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0959560126 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 6.7002e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.2361610234 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0034615705 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 30.87202501296997
Epoch 5/9
	 Logging train Loss: 3.17205e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0959775224 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 4.7976e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.2361809313 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0034666322 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 31.22136902809143
Epoch 6/9
	 Logging train Loss: 2.37509e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0958362669 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 8.8396e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.2332951874 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0034667221 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 31.208874225616455
Epoch 7/9
	 Logging train Loss: 2.6069e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0961061493 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 5.259e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.230558604 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.003473524 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 31.060962677001953
Epoch 8/9
	 Logging train Loss: 3.73641e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0963922143 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.1015e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.2285606861 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0034832431 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 31.04919981956482
Epoch 9/9
	 Logging train Loss: 9.3068e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.0964433104 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 5.3077e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.225111559 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0034902196 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 30.987955331802368
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'log_quat'_'True'.pth
It took  482.11813974380493  seconds.
----- ITERATION 8/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 80.65922713279724 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 20.10818314552307 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 20.190298557281494 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 19.5942120552063 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 20.047192335128784 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (pre_hidden_lin_layer): Sequential(
    (0): Linear(in_features=3, out_features=96, bias=True)
    (1): ReLU()
    (2): Linear(in_features=96, out_features=96, bias=True)
    (3): ReLU()
  )
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: log_quat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0337953977 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.2580584884 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0001304953 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1920597255 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0036642537 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 30.9493145942688
Epoch 1/9
	 Logging train Loss: 6.03032e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.2578980625 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.05348e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1915949732 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0036590328 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 31.106276273727417
Epoch 2/9
	 Logging train Loss: 5.25892e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.2558825314 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue █▂▂▄▁▁▁▁▁▃
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue ▆▅▆█▅▆▄▂▁▂
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue ███▆▆▅▄▃▂▁
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue ██▇▇▅▅▃▂▂▁
wandb:                                 Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 3e-05
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 0.00364
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.17539
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.23655
wandb:                                 Train loss 3e-05
wandb: 
wandb: 🚀 View run hardy-lake-1079 at: https://wandb.ai/nreints/ThesisFinal2/runs/wkdyo2xj
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_190640-wkdyo2xj/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_191444-mvmwcntg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ethereal-deluge-1094
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/mvmwcntg
	 Logging test loss: 1.04353e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1919816732 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0036654926 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 30.94999122619629
Epoch 3/9
	 Logging train Loss: 4.6139e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.2541281879 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 5.96619e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1883838773 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0036749432 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 31.12168288230896
Epoch 4/9
	 Logging train Loss: 5.7035e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.2502868176 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 4.1235e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1876211613 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0036611308 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 31.134821891784668
Epoch 5/9
	 Logging train Loss: 1.92076e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.2477141768 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 5.4679e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1841588169 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0036627143 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 31.162199020385742
Epoch 6/9
	 Logging train Loss: 3.90678e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.2432561964 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.7162e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1823544502 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0036551422 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 31.23025107383728
Epoch 7/9
	 Logging train Loss: 2.98704e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.2402956188 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.4753e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1790078729 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0036461058 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 31.13437819480896
Epoch 8/9
	 Logging train Loss: 1.48869e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.2388654649 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 7.679e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1773435771 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.00364003 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 31.249393463134766
Epoch 9/9
	 Logging train Loss: 2.52517e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.2365539819 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 3.49771e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.1753919721 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.003642696 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 31.293703079223633
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'log_quat'_'True'.pth
It took  484.14357686042786  seconds.
----- ITERATION 9/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 79.80273985862732 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 20.09921622276306 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 20.203231811523438 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 19.576740264892578 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 20.0982027053833 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (pre_hidden_lin_layer): Sequential(
    (0): Linear(in_features=3, out_features=96, bias=True)
    (1): ReLU()
    (2): Linear(in_features=96, out_features=96, bias=True)
    (3): ReLU()
  )
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: log_quat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0428443775 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.3494096696 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 5.05812e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.3551730216 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0036525035 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 31.122426986694336
Epoch 1/9
	 Logging train Loss: 5.21936e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.3436818123 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.57078e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.3478999138 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0036485794 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 31.242002725601196
Epoch 2/9
	 Logging train Loss: 4.22414e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.3397316933 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.20009e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.347417146 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0036512662 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 31.023613929748535
Epoch 3/9
	 Logging train Loss: 3.7421e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.3352635801 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.07526e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.3414576352 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0036408319 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 31.13344383239746
Epoch 4/9
	 Logging train Loss: 3.88606e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.331882745 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.35252e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.3376153111 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.003630629 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 30.980282306671143
Epoch 5/9
	 Logging train Loss: 3.07477e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.3278679252 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 6.04973e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.3336567283 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0036338661 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 30.903745889663696
Epoch 6/9
	 Logging train Loss: 2.63779e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.3240976036 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.4112e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.328630656 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0036215226 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 30.52886652946472
Epoch 7/9
	 Logging train Loss: 2.48638e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.3201052845 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.29713e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.3240148127 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0036172254 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 30.55285906791687
Epoch 8/9
	 Logging train Loss: 3.02154e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.3172386885 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.1846e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue ▇▄▂▂▂█▁▂▂▁
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue █▇█▆▅▅▃▃▂▁
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue █▇▇▆▅▄▃▃▂▁
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue █▇▆▅▅▄▃▂▂▁
wandb:                                 Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 0.00361
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.31512
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.31216
wandb:                                 Train loss 1e-05
wandb: 
wandb: 🚀 View run ethereal-deluge-1094 at: https://wandb.ai/nreints/ThesisFinal2/runs/mvmwcntg
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_191444-mvmwcntg/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_192245-wq976dgt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run misunderstood-silence-1107
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/wq976dgt
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue ▄█▁█▁▁▅▁▁▁
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue █▅▃▃▁▁▃▂▂▃
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue █▆▆▇▅▅▄▃▂▁
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue █▇▇▆▆▇▄▃▂▁
wandb:                                 Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pTrue_gTrue 0.00354
wandb:   Test loss t(0,0)_r(0,0)_semi_pTrue_gTrue 0.26159
wandb: Test loss t(0,0)_r(0,0)_tennis_pTrue_gTrue 0.39646
wandb:                                 Train loss 2e-05
wandb: 
wandb: 🚀 View run misunderstood-silence-1107 at: https://wandb.ai/nreints/ThesisFinal2/runs/wq976dgt
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_192245-wq976dgt/logs
	 Logging test loss: 0.3204960227 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0036121754 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 30.519954681396484
Epoch 9/9
	 Logging train Loss: 1.01037e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.3121573925 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.8427e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.3151234686 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0036055439 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 30.414408206939697
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'log_quat'_'True'.pth
It took  480.61201190948486  seconds.
----- ITERATION 10/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 78.42470002174377 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pTrue_gTrue took 20.063830852508545 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 19.767571687698364 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pTrue_gTrue took 20.080682039260864 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pTrue_gTrue took 20.00753927230835 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(7, 96, batch_first=True)
  (pre_hidden_lin_layer): Sequential(
    (0): Linear(in_features=3, out_features=96, bias=True)
    (1): ReLU()
    (2): Linear(in_features=96, out_features=96, bias=True)
    (3): ReLU()
  )
  (fc): Linear(in_features=96, out_features=7, bias=True)
)
Datatype: log_quat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0272188894 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.4207344353 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 5.86191e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.2800956666 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0035753569 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 30.441206216812134
Epoch 1/9
	 Logging train Loss: 4.81353e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.4179340005 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0001476873 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.2753667831 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0035575971 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 30.38022494316101
Epoch 2/9
	 Logging train Loss: 5.53797e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.4175276756 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 8.2396e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.2761002481 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0035480326 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 30.623267889022827
Epoch 3/9
	 Logging train Loss: 2.38531e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.4151515365 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 0.0001467135 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.2771846056 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0035481141 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 30.458926677703857
Epoch 4/9
	 Logging train Loss: 4.5132e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.4138317704 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 3.7075e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.2726530433 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0035350961 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 30.45212721824646
Epoch 5/9
	 Logging train Loss: 3.10577e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.4162638187 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 2.4943e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.2711436152 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0035335917 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 30.57798981666565
Epoch 6/9
	 Logging train Loss: 3.08328e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.4085151553 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 9.21589e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.2686703801 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0035432649 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 30.460673570632935
Epoch 7/9
	 Logging train Loss: 3.9594e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.4045632184 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.2995e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.2665258646 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0035418712 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 30.444364309310913
Epoch 8/9
	 Logging train Loss: 1.43685e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.4012278318 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.0185e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.2634370923 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0035402286 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 30.350879430770874
Epoch 9/9
	 Logging train Loss: 2.29088e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.3964559734 [MSELoss(): t(0,0)_r(0,0)_tennis_pTrue_gTrue]
	 Logging test loss: 1.8737e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 0.261585474 [MSELoss(): t(0,0)_r(0,0)_semi_pTrue_gTrue]
	 Logging test loss: 0.0035431667 [MSELoss(): t(0,0)_r(0,0)_full_pTrue_gTrue]
		--> Epoch time; 30.61139178276062
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'log_quat'_'True'.pth
It took  475.1586320400238  seconds.

JOB STATISTICS
==============
Job ID: 3038001
Array Job ID: 3037875_37
Cluster: snellius
User/Group: nreints/nreints
State: COMPLETED (exit code 0)
Nodes: 1
Cores per node: 18
CPU Utilized: 01:28:03
CPU Efficiency: 6.02% of 1-00:21:36 core-walltime
Job Wall-clock time: 01:21:12
Memory Utilized: 7.42 GB
Memory Efficiency: 0.00% of 0.00 MB
