wandb: Currently logged in as: nreints. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home/nreints/.netrc
/gpfs/home2/nreints/MScThesis/code/fcnn.py:566: DeprecationWarning: Sampling from a set deprecated
since Python 3.9 and will be removed in a subsequent version.
  train_sims = set(random.sample(sims_train, int(0.8 * n_sims_train)))
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230330_123649-0eauiujf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run magic-flower-558
wandb: ⭐️ View project at https://wandb.ai/nreints/test
wandb: 🚀 View run at https://wandb.ai/nreints/test/runs/0eauiujf
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:  Test loss t(5, 20)_r(0, 0)_semi L1Loss() ▆▆██▃▃▃▄▂▂▁▁▃▂▁▁▁▁▄▃▃
wandb: Test loss t(5, 20)_r(0, 0)_semi MSELoss() ▅▄██▂▂▂▃▁▁▁▁▂▁▁▁▁▁▃▂▂
wandb:     Train loss data_t(5, 20)_r(0, 0)_semi █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:  Test loss t(5, 20)_r(0, 0)_semi L1Loss() 0.10816
wandb: Test loss t(5, 20)_r(0, 0)_semi MSELoss() 0.03054
wandb:     Train loss data_t(5, 20)_r(0, 0)_semi 0.02254
wandb: 
wandb: 🚀 View run magic-flower-558 at: https://wandb.ai/nreints/test/runs/0eauiujf
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230330_123649-0eauiujf/logs
/gpfs/home2/nreints/MScThesis/code/fcnn.py:566: DeprecationWarning: Sampling from a set deprecated
since Python 3.9 and will be removed in a subsequent version.
  train_sims = set(random.sample(sims_train, int(0.8 * n_sims_train)))
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230330_124734-jhfybm2v
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run happy-oath-614
wandb: ⭐️ View project at https://wandb.ai/nreints/test
wandb: 🚀 View run at https://wandb.ai/nreints/test/runs/jhfybm2v
Training on dataset: data/data_t(5, 20)_r(0, 0)_semi_pNone_gNone
Testing on datasets: ['data_t(5, 20)_r(0, 0)_semi_pNone_gNone']
----- ITERATION 1/2 ------
Number of train simulations: 1600
Number of test simulations: 400
The dataloader took 61.984896659851074 seconds.
-- Finished Train Dataloader --
The dataloader took 15.454864263534546 seconds.
-- Finished Test Dataloader(s) --
Datatype: eucl_motion
--- Started Training ---
Epoch 0
	 Logging train Loss: 26.8296109069 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.11574308574199677 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.2263476401567459 (L1Loss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 26.369739532470703
Epoch 1
	 Logging train Loss: 0.0702519884 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.1008610874414444 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.2085391879081726 (L1Loss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 28.121761560440063
Epoch 2
	 Logging train Loss: 0.0563822777 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.20106017589569092 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.29971715807914734 (L1Loss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 28.330138683319092
Epoch 3
	 Logging train Loss: 0.0579251308 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.18998894095420837 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.2898983955383301 (L1Loss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 28.49655270576477
Epoch 4
	 Logging train Loss: 0.0474519917 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.023240430280566216 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.10104698687791824 (L1Loss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 28.449342489242554
Epoch 5
	 Logging train Loss: 0.0493744495 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.025326212868094444 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.10536998510360718 (L1Loss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 28.130268812179565
Epoch 6
	 Logging train Loss: 0.0426486096 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.0280612725764513 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.11331605166196823 (L1Loss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 28.09403896331787
Epoch 7
	 Logging train Loss: 0.0409063726 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.06259504705667496 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.15464995801448822 (L1Loss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 27.964146375656128
Epoch 8
	 Logging train Loss: 0.0491600136 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.011253423988819122 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.06160673499107361 (L1Loss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 28.261346340179443
Epoch 9
	 Logging train Loss: 0.0346889296 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.013953601941466331 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.0743434801697731 (L1Loss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 28.595272541046143
Epoch 10
	 Logging train Loss: 0.0475662481 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.010544991120696068 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.0566972941160202 (L1Loss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 28.091898918151855
Epoch 11
	 Logging train Loss: 0.0269317403 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.009614652954041958 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.05731483921408653 (L1Loss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 28.228941917419434
Epoch 12
	 Logging train Loss: 0.0372330335 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.028876813128590584 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.1140964925289154 (L1Loss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 26.718645334243774
Epoch 13
	 Logging train Loss: 0.0310016757 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.015097511000931263 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.07610833644866943 (L1Loss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 26.655418634414673
Epoch 14
	 Logging train Loss: 0.0303251079 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.008132481016218662 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.0505206435918808 (L1Loss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 26.632075786590576
Epoch 15
	 Logging train Loss: 0.0378360673 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.007879173383116722 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.0497891940176487 (L1Loss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 26.620275259017944
Epoch 16
	 Logging train Loss: 0.0291636074 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.00662546930834651 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.04253258928656578 (L1Loss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 28.285447597503662
Epoch 17
	 Logging train Loss: 0.0267157536 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.006809678860008717 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.04416109621524811 (L1Loss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 26.90164613723755
Epoch 18
	 Logging train Loss: 0.0292461769 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.04870738089084625 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.14599934220314026 (L1Loss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 26.893980979919434
Epoch 19
	 Logging train Loss: 0.0225378398 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.030540557578206062 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.10818400979042053 (L1Loss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 26.60565710067749
	 Logging test loss 0.030542364344000816 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.10815969854593277 (L1Loss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
It took 645.6395466327667 seconds to train & eval the model.
----- ITERATION 2/2 ------
Number of train simulations: 1600
Number of test simulations: 400
The dataloader took 56.5979380607605 seconds.
-- Finished Train Dataloader --
The dataloader took 14.039251804351807 seconds.
-- Finished Test Dataloader(s) --
Datatype: eucl_motion
--- Started Training ---
Epoch 0
	 Logging train Loss: 21.1996183109 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.05793822929263115 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.15866594016551971 (L1Loss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 28.55846333503723
Epoch 1
	 Logging train Loss: 0.0535687665 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.03227393329143524 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.12317389249801636 (L1Loss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 27.204143524169922
Epoch 2
	 Logging train Loss: 0.0482770334 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.04409269988536835 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.14222800731658936 (L1Loss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 26.587696313858032
Epoch 3
	 Logging train Loss: 0.0513909483 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:  Test loss t(5, 20)_r(0, 0)_semi L1Loss() ▇▅▆▃▃▅▃▆▂▂▂▁▂▁▄▇█▁▂▁▁
wandb: Test loss t(5, 20)_r(0, 0)_semi MSELoss() █▄▆▂▂▃▂▆▁▁▂▁▁▁▃▇█▁▁▁▁
wandb:     Train loss data_t(5, 20)_r(0, 0)_semi █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:  Test loss t(5, 20)_r(0, 0)_semi L1Loss() 0.04968
wandb: Test loss t(5, 20)_r(0, 0)_semi MSELoss() 0.00552
wandb:     Train loss data_t(5, 20)_r(0, 0)_semi 0.02705
wandb: 
wandb: 🚀 View run happy-oath-614 at: https://wandb.ai/nreints/test/runs/jhfybm2v
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230330_124734-jhfybm2v/logs
	 Logging test loss 0.01583864912390709 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.08424224704504013 (L1Loss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 26.300017595291138
Epoch 4
	 Logging train Loss: 0.0478140289 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.015757521614432335 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.08552693575620651 (L1Loss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 28.479581117630005
Epoch 5
	 Logging train Loss: 0.0520807553 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.02316591888666153 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.1077660322189331 (L1Loss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 28.301507711410522
Epoch 6
	 Logging train Loss: 0.0394723207 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.0150674507021904 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.08479315042495728 (L1Loss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 28.43670153617859
Epoch 7
	 Logging train Loss: 0.0445567362 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.04419148340821266 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.13967570662498474 (L1Loss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 26.900201559066772
Epoch 8
	 Logging train Loss: 0.0488558451 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.008225036785006523 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.057714447379112244 (L1Loss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 26.9206702709198
Epoch 9
	 Logging train Loss: 0.0371342104 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.008321552537381649 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.0576951764523983 (L1Loss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 26.603436946868896
Epoch 10
	 Logging train Loss: 0.0354632957 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.00906266551464796 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.06306014955043793 (L1Loss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 26.42751169204712
Epoch 11
	 Logging train Loss: 0.0398619733 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.007272157818078995 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.052641551941633224 (L1Loss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 28.235507249832153
Epoch 12
	 Logging train Loss: 0.0354918411 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.0075315204448997974 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.05561639368534088 (L1Loss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 26.832791090011597
Epoch 13
	 Logging train Loss: 0.0357080921 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.006208960898220539 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.0488257110118866 (L1Loss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 26.73046040534973
Epoch 14
	 Logging train Loss: 0.0407844095 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.02137145586311817 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.10184957087039948 (L1Loss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 26.79306983947754
Epoch 15
	 Logging train Loss: 0.0235125224 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.05731157958507538 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.1618398129940033 (L1Loss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 26.298827171325684
Epoch 16
	 Logging train Loss: 0.0340157577 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.06136530265212059 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.17123447358608246 (L1Loss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 28.67862296104431
Epoch 17
	 Logging train Loss: 0.0300716001 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.004620577674359083 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.04364714398980141 (L1Loss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 28.35614252090454
Epoch 18
	 Logging train Loss: 0.0278142917 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.006392214447259903 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.05434398725628853 (L1Loss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 28.24762511253357
Epoch 19
	 Logging train Loss: 0.0270450393 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.005518588237464428 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.04968351870775223 (L1Loss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 26.887083768844604
	 Logging test loss 0.005519350990653038 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.04968253895640373 (L1Loss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
It took 634.309604883194 seconds to train & eval the model.

JOB STATISTICS
==============
Job ID: 2523377
Array Job ID: 2523368_9
Cluster: snellius
User/Group: nreints/nreints
State: RUNNING
Nodes: 1
Cores per node: 18
CPU Utilized: 03:09:55
CPU Efficiency: 48.85% of 06:28:48 core-walltime
Job Wall-clock time: 00:21:36
Memory Utilized: 5.71 GB
Memory Efficiency: 19.49% of 29.30 GB
WARNING: Efficiency statistics may be misleading for RUNNING jobs.
