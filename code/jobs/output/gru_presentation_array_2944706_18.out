wandb: Currently logged in as: nreints. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230620_141159-q8tgxecw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run still-frog-274
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal/runs/q8tgxecw
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone â–ˆâ–„â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone â–ˆâ–„â–‚â–ƒâ–‚â–ƒâ–â–‚â–‚â–
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone â–ˆâ–„â–‚â–ƒâ–‚â–‚â–â–‚â–‚â–
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone â–ˆâ–„â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone â–ˆâ–„â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–
wandb:                                   Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone 0.0056
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 0.00154
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone 0.00174
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 0.00859
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 0.00909
wandb:                                   Train loss 0.00954
wandb: 
wandb: ðŸš€ View run still-frog-274 at: https://wandb.ai/nreints/ThesisFinal/runs/q8tgxecw
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230620_141159-q8tgxecw/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230620_142115-85ao4cqf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run easy-morning-306
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal/runs/85ao4cqf
Training on dataset: data_t(5,20)_r(5,20)_combi_pNone_gNone
Testing on 5 datasets: ['data_t(5,20)_r(5,20)_combi_pNone_gNone', 'data_t(5,20)_r(5,20)_tennis_pNone_gNone', 'data_t(5,20)_r(5,20)_none_pNone_gNone', 'data_t(5,20)_r(5,20)_semi_pNone_gNone', 'data_t(5,20)_r(5,20)_full_pNone_gNone']
Focussing on identity: False
Using extra input: None
Using start-fr as reference point.
----- ITERATION 1/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 77.86538505554199 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 19.617388248443604 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 19.84261965751648 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_none_pNone_gNone took 20.085609674453735 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 20.040594577789307 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 20.018298149108887 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 2.5014457703 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0538227856 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0727107078 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0343465693 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0690596849 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0338785574 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 37.664350748062134
Epoch 1/9
	 Logging train Loss: 0.0304881223 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0279093552 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.038635727 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0172064509 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.036913313 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0157893077 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 35.830029249191284
Epoch 2/9
	 Logging train Loss: 0.0201747436 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0160351209 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0240791645 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0073100468 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0228985045 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0065834853 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 35.7221736907959
Epoch 3/9
	 Logging train Loss: 0.0175656155 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0197381657 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0268656146 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0118391756 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0264890213 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0103937211 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 35.53873610496521
Epoch 4/9
	 Logging train Loss: 0.0172919165 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0149724409 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0211014301 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0076501411 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0199294742 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0084471041 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 35.59596586227417
Epoch 5/9
	 Logging train Loss: 0.0135290744 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0150435297 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.020638112 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0087208115 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0196709409 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0086267218 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 35.76816725730896
Epoch 6/9
	 Logging train Loss: 0.0131228492 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0091610244 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0143078538 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0036080235 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0136160422 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0031696763 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 35.88625931739807
Epoch 7/9
	 Logging train Loss: 0.0106366845 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0105256317 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0153645864 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0054496829 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0143485321 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.005132114 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 35.72114443778992
Epoch 8/9
	 Logging train Loss: 0.0095017022 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0118924826 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0163721181 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0076875654 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0156433936 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0066016517 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 35.73298501968384
Epoch 9/9
	 Logging train Loss: 0.0095426133 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0055993861 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0090881968 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0017370482 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0085906675 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0015415186 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 35.9872682094574
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gNone/'dual_quat'_'None'.pth
It took  557.3343722820282  seconds.
----- ITERATION 2/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 72.69435858726501 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 18.253772735595703 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 18.461480617523193 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_none_pNone_gNone took 18.376718759536743 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 18.364980220794678 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 18.337136030197144 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 2.3506174088 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0508551598 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0722475797 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0350493528 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: ERROR Error while calling W&B API: An internal error occurred. Please contact support. (<Response [500]>)
wandb: 
wandb: Run history:
wandb:                                        Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone â–ˆâ–„â–†â–ƒâ–‚â–‚â–‚â–â–â–‚
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone â–ˆâ–„â–‡â–„â–‚â–‚â–‚â–â–‚â–ƒ
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone â–ˆâ–„â–‡â–ƒâ–‚â–‚â–‚â–â–‚â–‚
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone â–ˆâ–„â–†â–ƒâ–‚â–‚â–‚â–â–â–
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone â–ˆâ–„â–†â–ƒâ–‚â–‚â–‚â–â–â–
wandb:                                   Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone 0.01136
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 0.00905
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone 0.00734
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 0.01442
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 0.01548
wandb:                                   Train loss 0.00918
wandb: 
wandb: ðŸš€ View run easy-morning-306 at: https://wandb.ai/nreints/ThesisFinal/runs/85ao4cqf
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230620_142115-85ao4cqf/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230620_143016-h98enjwk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run faithful-fog-326
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal/runs/h98enjwk
	 Logging test loss: 0.0687475428 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0321834832 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 37.94759941101074
Epoch 1/9
	 Logging train Loss: 0.0337844305 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0238743685 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0356762893 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.014452287 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.033784464 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0135400137 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 36.13359475135803
Epoch 2/9
	 Logging train Loss: 0.0225968286 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0393914171 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0518414862 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0303467568 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0516787767 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0269610509 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 36.1806697845459
Epoch 3/9
	 Logging train Loss: 0.0192177817 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0204923805 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0293991566 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.013313666 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.027239766 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0134900259 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 35.98521399497986
Epoch 4/9
	 Logging train Loss: 0.0173940491 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0152037404 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0228371378 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0092563191 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0216959789 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0083487164 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 35.922735929489136
Epoch 5/9
	 Logging train Loss: 0.0159523971 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.014761108 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0220848098 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0089816833 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0213651005 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0080850022 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 35.660369634628296
Epoch 6/9
	 Logging train Loss: 0.0131406719 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0107250111 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0169630256 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0056739282 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0155205103 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0055653998 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 35.72620105743408
Epoch 7/9
	 Logging train Loss: 0.0110326288 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0071068197 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0125367297 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0025765679 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0111418031 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0025076477 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 35.90638089179993
Epoch 8/9
	 Logging train Loss: 0.0108951097 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0101381214 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0153830182 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0058692317 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0144185927 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0053047584 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 36.222668409347534
Epoch 9/9
	 Logging train Loss: 0.009180231 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0113591347 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0154849254 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0073356219 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0144170923 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0090482077 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 36.00883340835571
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gNone/'dual_quat'_'None'.pth
It took  541.3446650505066  seconds.
----- ITERATION 3/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 71.9634370803833 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 18.120800495147705 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 18.446016550064087 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_none_pNone_gNone took 18.383923292160034 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 18.3869845867157 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 18.40125823020935 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 3.1339421272 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0496565215 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0674549863 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0326159485 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0676051378 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0311501455 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 36.204166412353516
Epoch 1/9
	 Logging train Loss: 0.0328978263 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0298071653 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0407343134 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0195794273 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0411415733 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0187888294 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 35.85756969451904
Epoch 2/9
	 Logging train Loss: 0.0220232401 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0186162684 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0268583652 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0102823619 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.028023975 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0102255614 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 36.01728868484497
Epoch 3/9
	 Logging train Loss: 0.0188125409 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0224244781 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0301191099 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.014842201 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0294513628 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0165505428 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone â–ˆâ–…â–ƒâ–„â–‚â–â–â–‚â–â–
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone â–ˆâ–…â–ƒâ–„â–â–â–â–ƒâ–â–‚
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone â–ˆâ–…â–ƒâ–„â–â–â–â–‚â–â–‚
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone â–ˆâ–…â–ƒâ–ƒâ–‚â–â–â–‚â–â–
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone â–ˆâ–…â–ƒâ–ƒâ–‚â–â–â–‚â–â–
wandb:                                   Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone 0.00888
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 0.00546
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone 0.00519
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 0.01258
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 0.01234
wandb:                                   Train loss 0.00852
wandb: 
wandb: ðŸš€ View run faithful-fog-326 at: https://wandb.ai/nreints/ThesisFinal/runs/h98enjwk
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230620_143016-h98enjwk/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230620_143924-eqzaavff
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fiery-wildflower-343
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal/runs/eqzaavff
		--> Epoch time; 36.2327675819397
Epoch 4/9
	 Logging train Loss: 0.01657979 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0103159146 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0162645504 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0039572837 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0172572192 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0037802518 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 35.57745027542114
Epoch 5/9
	 Logging train Loss: 0.0160195269 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0083221095 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0136872334 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0026384941 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0146826766 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0023240319 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 36.227949380874634
Epoch 6/9
	 Logging train Loss: 0.0120483879 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0078924689 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.012680023 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0027181101 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0134122372 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0028180073 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 36.1541748046875
Epoch 7/9
	 Logging train Loss: 0.0112529341 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0125450836 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0170376878 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.007950997 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0171397068 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0089060375 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 36.18921160697937
Epoch 8/9
	 Logging train Loss: 0.01095853 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.006904101 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0108550545 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0028925794 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.011563736 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0025330717 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 36.23737287521362
Epoch 9/9
	 Logging train Loss: 0.0085153449 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.008875764 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0123362252 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0051949099 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0125801163 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0054611298 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 36.156418800354004
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gNone/'dual_quat'_'None'.pth
It took  548.0449092388153  seconds.
----- ITERATION 4/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 71.78556203842163 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 17.975160360336304 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 18.214043617248535 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_none_pNone_gNone took 18.19733238220215 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 18.21983289718628 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 18.352906465530396 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 4.7211995125 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0873496234 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.1253657788 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.053933572 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.1253088713 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0523513407 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 35.95725750923157
Epoch 1/9
	 Logging train Loss: 0.0455373637 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0256947894 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0389011987 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0143026644 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0369106568 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0138600674 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 36.151894092559814
Epoch 2/9
	 Logging train Loss: 0.0213175137 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.016116662 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0252491571 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0076740035 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0237594042 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0070808521 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 36.021687746047974
Epoch 3/9
	 Logging train Loss: 0.0180460233 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0139477095 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0216856059 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0069530657 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0206821114 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0064264894 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 35.66234493255615
Epoch 4/9
	 Logging train Loss: 0.0165615603 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0096475855 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.016155947 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0031833516 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0149528943 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0031122915 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 36.01156568527222
Epoch 5/9
	 Logging train Loss: 0.0135852238 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0109271677 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0170630906 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0054280083 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0155125689 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0060413461 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 36.11853075027466
Epoch 6/9
	 Logging train Loss: 0.0125819864 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0099984622 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0153197385 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0050065522 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0143946791 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0044079823 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 36.155227184295654
Epoch 7/9
	 Logging train Loss: 0.011164546 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone â–ˆâ–ƒâ–‚â–‚â–â–‚â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–
wandb:                                   Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone 0.00603
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 0.00254
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone 0.00261
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 0.00896
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 0.00955
wandb:                                   Train loss 0.00828
wandb: 
wandb: ðŸš€ View run fiery-wildflower-343 at: https://wandb.ai/nreints/ThesisFinal/runs/eqzaavff
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230620_143924-eqzaavff/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230620_144821-rsj2kcpb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vocal-shape-361
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal/runs/rsj2kcpb
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone â–ˆâ–„â–ƒâ–ƒâ–‚â–‚â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone â–ˆâ–„â–ƒâ–‚â–‚â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone â–ˆâ–„â–‚â–‚â–‚â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone â–ˆâ–„â–ƒâ–ƒâ–‚â–‚â–â–â–â–
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone â–ˆâ–„â–ƒâ–ƒâ–‚â–‚â–‚â–â–â–
wandb:                                   Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone 0.00583
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 0.00208
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone 0.00212
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 0.00852
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 0.00947
wandb:                                   Train loss 0.00982
wandb: 
wandb: ðŸš€ View run vocal-shape-361 at: https://wandb.ai/nreints/ThesisFinal/runs/rsj2kcpb
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230620_144821-rsj2kcpb/logs
	 Logging test loss: 0.0065721078 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0111116413 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0020799753 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0102606155 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0020764307 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 36.37144446372986
Epoch 8/9
	 Logging train Loss: 0.0101455292 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0063224956 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0103832791 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0024493614 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0096762897 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0023162737 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 36.78251814842224
Epoch 9/9
	 Logging train Loss: 0.0082833888 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0060345908 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0095495656 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.002610961 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0089618517 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.002539024 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 36.28046274185181
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gNone/'dual_quat'_'None'.pth
It took  536.3741438388824  seconds.
----- ITERATION 5/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 71.74958419799805 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 18.025078773498535 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 18.213597536087036 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_none_pNone_gNone took 18.16977095603943 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 18.171050310134888 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 18.200300455093384 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 2.1997711658 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0509431846 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0693676472 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0354827791 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0665605292 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0308490954 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 35.64097809791565
Epoch 1/9
	 Logging train Loss: 0.0319193266 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0247623585 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0353571363 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0148702059 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0334773809 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0131355906 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 36.15445137023926
Epoch 2/9
	 Logging train Loss: 0.0233096816 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.016971834 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0254964866 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0086918939 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0239430536 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0081865489 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 36.387794971466064
Epoch 3/9
	 Logging train Loss: 0.0179664213 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0155443652 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0231884848 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0081589753 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0215916988 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0074558947 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 35.99115967750549
Epoch 4/9
	 Logging train Loss: 0.0167677924 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0122501375 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0192721393 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0056853266 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0176217258 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0048963916 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 36.11753463745117
Epoch 5/9
	 Logging train Loss: 0.0145259518 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0099963685 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0160451084 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0039159749 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0148308566 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0034484151 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 36.04149627685547
Epoch 6/9
	 Logging train Loss: 0.0121085308 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0085096285 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0137478411 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0030162123 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0126585579 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0027965494 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 36.22979974746704
Epoch 7/9
	 Logging train Loss: 0.0118198954 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0078036617 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0125184413 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0030383598 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0114282267 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0026837795 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 37.95358395576477
Epoch 8/9
	 Logging train Loss: 0.0099429209 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0059737056 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0100734262 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0016072036 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.009038005 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0014389819 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 36.3145751953125
Epoch 9/9
	 Logging train Loss: 0.0098165274 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0058304295 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0094657056 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0021246532 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0085191121 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0020771769 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 36.315587282180786
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gNone/'dual_quat'_'None'.pth
It took  538.4713115692139  seconds.
----- ITERATION 6/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230620_145719-clwxjdmd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run spring-snowflake-380
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal/runs/clwxjdmd
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone â–ˆâ–„â–ƒâ–ƒâ–ƒâ–‚â–â–„â–â–‚
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone â–ˆâ–ƒâ–‚â–ƒâ–ƒâ–‚â–â–†â–‚â–‚
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone â–ˆâ–„â–ƒâ–‚â–ƒâ–‚â–â–…â–‚â–ƒ
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone â–ˆâ–„â–ƒâ–‚â–‚â–‚â–â–ƒâ–â–‚
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone â–ˆâ–„â–ƒâ–‚â–‚â–‚â–â–ƒâ–â–‚
wandb:                                   Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone 0.01415
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 0.0089
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone 0.01137
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 0.01807
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 0.01811
wandb:                                   Train loss 0.01009
wandb: 
wandb: ðŸš€ View run spring-snowflake-380 at: https://wandb.ai/nreints/ThesisFinal/runs/clwxjdmd
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230620_145719-clwxjdmd/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230620_150615-fhr45c9r
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run iconic-bush-396
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal/runs/fhr45c9r
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 72.03686738014221 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 18.06259536743164 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 18.175001621246338 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_none_pNone_gNone took 18.201627016067505 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 18.20593786239624 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 18.19675087928772 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 2.1188578606 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.049007345 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0640023425 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0366236269 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.062820293 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.032697577 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 36.06877636909485
Epoch 1/9
	 Logging train Loss: 0.0326480754 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0237427969 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0339003801 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0151072061 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0331503823 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0131019717 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 36.21224927902222
Epoch 2/9
	 Logging train Loss: 0.0222661477 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0182114933 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0269519538 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0103448024 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0263122059 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0090165082 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 36.12671995162964
Epoch 3/9
	 Logging train Loss: 0.0188326966 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0168158375 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0238975342 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0095620584 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0223773867 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0115521839 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 36.0765655040741
Epoch 4/9
	 Logging train Loss: 0.0173565056 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0167717934 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0240839254 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0107830856 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0229401626 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0109019792 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 36.18471312522888
Epoch 5/9
	 Logging train Loss: 0.0154558159 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0120958211 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0182384383 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0065235849 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0179344695 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0058331196 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 36.10334396362305
Epoch 6/9
	 Logging train Loss: 0.0150496708 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0079249693 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0133310817 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0028763544 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0128005743 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0028006251 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 35.806137800216675
Epoch 7/9
	 Logging train Loss: 0.011168004 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0264406856 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0313318036 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0217945632 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0293436609 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0241828281 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 35.87149453163147
Epoch 8/9
	 Logging train Loss: 0.0114309778 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0104117002 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0146300178 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0060396893 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0140099069 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0068846764 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 36.33039093017578
Epoch 9/9
	 Logging train Loss: 0.0100896424 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0141542628 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0181117356 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.011370454 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0180669911 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0089034736 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 36.004077672958374
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gNone/'dual_quat'_'None'.pth
It took  536.1610457897186  seconds.
----- ITERATION 7/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 71.9419355392456 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 18.079431295394897 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 18.229488611221313 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_none_pNone_gNone took 18.211042642593384 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 18.173299551010132 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 18.20084023475647 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 1.9428527355 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.044860851 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0602412745 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0287639759 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0571483448 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0259831473 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 35.80416202545166
Epoch 1/9
	 Logging train Loss: 0.0307269357 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0304346755 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0399412736 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0203306675 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone â–ˆâ–…â–„â–ˆâ–ƒâ–‚â–ƒâ–„â–â–ƒ
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone â–…â–…â–ƒâ–ˆâ–ƒâ–‚â–ƒâ–„â–â–ƒ
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone â–†â–…â–ƒâ–ˆâ–‚â–‚â–ƒâ–„â–â–ƒ
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone â–ˆâ–…â–„â–‡â–‚â–‚â–ƒâ–„â–â–‚
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone â–ˆâ–…â–„â–‡â–ƒâ–‚â–ƒâ–„â–â–‚
wandb:                                   Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone 0.01547
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 0.01412
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone 0.01198
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 0.01729
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 0.01841
wandb:                                   Train loss 0.0081
wandb: 
wandb: ðŸš€ View run iconic-bush-396 at: https://wandb.ai/nreints/ThesisFinal/runs/fhr45c9r
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230620_150615-fhr45c9r/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230620_151514-xf8cjs2o
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run still-paper-414
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal/runs/xf8cjs2o
	 Logging test loss: 0.0380379297 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0218376759 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 35.991238832473755
Epoch 2/9
	 Logging train Loss: 0.0221350808 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0217910726 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0293442644 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0130581362 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0273200944 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0124188326 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 36.116193771362305
Epoch 3/9
	 Logging train Loss: 0.0214324407 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0448724516 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0517747179 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0369605795 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0493669137 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0401303507 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 35.73371434211731
Epoch 4/9
	 Logging train Loss: 0.0145782335 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0163684729 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0222698506 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0093212007 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0202198401 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0109529551 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 37.78201723098755
Epoch 5/9
	 Logging train Loss: 0.013949017 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0136907622 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0190135352 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0073906053 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0175065827 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0079220589 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 36.72066640853882
Epoch 6/9
	 Logging train Loss: 0.0129880896 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0176350176 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0219633989 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0115284836 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0213932227 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0123558203 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 36.048847913742065
Epoch 7/9
	 Logging train Loss: 0.0104201129 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0247419309 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0292892288 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0194740854 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0275932513 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0208003893 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 36.49977231025696
Epoch 8/9
	 Logging train Loss: 0.0090887249 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0070593138 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0107970349 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0029366144 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0102298567 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0024719026 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 36.08978629112244
Epoch 9/9
	 Logging train Loss: 0.0081005944 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.015474231 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.01840505 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0119834142 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0172869377 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0141174849 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 36.23179221153259
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gNone/'dual_quat'_'None'.pth
It took  538.5876560211182  seconds.
----- ITERATION 8/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 72.53795766830444 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 18.12747550010681 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 18.2887544631958 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_none_pNone_gNone took 18.259796142578125 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 18.2274329662323 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 18.236260414123535 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 3.4235851765 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0519957095 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0780878291 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0329155363 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0738698691 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0296153147 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 35.90246224403381
Epoch 1/9
	 Logging train Loss: 0.0312133245 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.024496533 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0355414823 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0160647891 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0332600139 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0150020327 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 35.903019428253174
Epoch 2/9
	 Logging train Loss: 0.0212186705 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0209449138 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0297014229 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0139409136 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.02806939 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0139514431 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 35.86604619026184
Epoch 3/9
	 Logging train Loss: 0.0181062333 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0100754295 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0182164796 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0041398276 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0164099745 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0039061585 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 35.64996409416199
Epoch 4/9
	 Logging train Loss: 0.0155330226 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0116013773 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0188254956 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0062969131 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0170589127 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0060009584 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone â–ˆâ–„â–ƒâ–‚â–‚â–ƒâ–ƒâ–â–â–‚
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone â–ˆâ–„â–„â–â–‚â–„â–ƒâ–â–‚â–„
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone â–ˆâ–„â–„â–â–‚â–ƒâ–ƒâ–â–â–ƒ
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone â–ˆâ–„â–ƒâ–‚â–‚â–‚â–‚â–â–â–‚
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone â–ˆâ–„â–ƒâ–‚â–‚â–‚â–‚â–â–â–‚
wandb:                                   Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone 0.01407
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 0.01367
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone 0.01165
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 0.01556
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 0.01766
wandb:                                   Train loss 0.0085
wandb: 
wandb: ðŸš€ View run still-paper-414 at: https://wandb.ai/nreints/ThesisFinal/runs/xf8cjs2o
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230620_151514-xf8cjs2o/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230620_152409-6j0pp1xn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run usual-blaze-431
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal/runs/6j0pp1xn
		--> Epoch time; 35.80687665939331
Epoch 5/9
	 Logging train Loss: 0.0136238551 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0168321095 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.023157686 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.012096134 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0214466639 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0120232934 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 36.082284688949585
Epoch 6/9
	 Logging train Loss: 0.0124197016 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0165259484 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0227404144 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0124142319 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0212951582 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0117374472 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 36.258902072906494
Epoch 7/9
	 Logging train Loss: 0.0110153379 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.005900804 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0110309487 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0023274471 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0098493323 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0021624223 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 36.237022399902344
Epoch 8/9
	 Logging train Loss: 0.0088099279 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0074900263 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0118095055 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0043670125 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0103956331 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0049208771 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 36.42263984680176
Epoch 9/9
	 Logging train Loss: 0.0085044373 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0140659502 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0176614653 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0116537688 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0155615453 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0136680724 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 35.92452096939087
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gNone/'dual_quat'_'None'.pth
It took  535.325553894043  seconds.
----- ITERATION 9/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 71.89551210403442 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 18.00864005088806 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 18.244932174682617 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_none_pNone_gNone took 18.19800853729248 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 18.209372758865356 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 18.269630193710327 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 2.107010603 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0417600498 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0571055859 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0265628379 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0569078624 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0248969514 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 37.47203469276428
Epoch 1/9
	 Logging train Loss: 0.0290541705 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0281227771 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0379181243 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0182198174 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0372520797 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0191651136 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 37.54978156089783
Epoch 2/9
	 Logging train Loss: 0.021468427 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0186467357 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0263283849 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0103816772 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.02581493 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0109462133 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 35.91171717643738
Epoch 3/9
	 Logging train Loss: 0.0180768389 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0172662567 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0238290001 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0098890522 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0228459444 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.012795547 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 36.259135484695435
Epoch 4/9
	 Logging train Loss: 0.0158761814 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0127553102 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0186344441 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0062677762 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0186935198 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0066707041 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 36.41655373573303
Epoch 5/9
	 Logging train Loss: 0.0147295855 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0107339351 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0165942833 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0051044947 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0167118832 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0042865542 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 36.658021450042725
Epoch 6/9
	 Logging train Loss: 0.0122687444 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0076162801 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0123317698 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0024841602 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.012360068 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0027131969 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 36.55067729949951
Epoch 7/9
	 Logging train Loss: 0.0110340817 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0099925147 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0144963907 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0053152996 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0145904692 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0051817684 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 36.013482332229614
Epoch 8/9
	 Logging train Loss: 0.0103784064 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone â–ˆâ–…â–ƒâ–ƒâ–‚â–‚â–â–‚â–â–‚
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone â–ˆâ–†â–„â–„â–‚â–‚â–â–‚â–â–ƒ
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone â–ˆâ–†â–ƒâ–ƒâ–‚â–‚â–â–‚â–â–‚
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone â–ˆâ–…â–ƒâ–ƒâ–‚â–‚â–â–‚â–â–
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone â–ˆâ–…â–ƒâ–ƒâ–‚â–‚â–â–‚â–â–‚
wandb:                                   Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone 0.01073
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 0.00866
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone 0.00679
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 0.01317
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 0.01404
wandb:                                   Train loss 0.00881
wandb: 
wandb: ðŸš€ View run usual-blaze-431 at: https://wandb.ai/nreints/ThesisFinal/runs/6j0pp1xn
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230620_152409-6j0pp1xn/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230620_153310-nri0v2g6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pleasant-sunset-449
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal/runs/nri0v2g6
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone â–ˆâ–„â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone â–ˆâ–„â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–ƒâ–
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone â–ˆâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone â–ˆâ–„â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone â–ˆâ–„â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–
wandb:                                   Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone 0.00573
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 0.00211
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone 0.00199
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 0.00803
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 0.00874
wandb:                                   Train loss 0.00932
wandb: 
wandb: ðŸš€ View run pleasant-sunset-449 at: https://wandb.ai/nreints/ThesisFinal/runs/nri0v2g6
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230620_153310-nri0v2g6/logs
	 Logging test loss: 0.0064515248 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0102701448 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0023693463 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0102695813 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0024213959 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 36.131749391555786
Epoch 9/9
	 Logging train Loss: 0.008812842 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0107307788 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0140411556 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0067947386 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0131674875 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0086607449 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 35.929248571395874
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gNone/'dual_quat'_'None'.pth
It took  540.3139960765839  seconds.
----- ITERATION 10/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 71.85413551330566 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 18.00824785232544 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 18.214458465576172 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_none_pNone_gNone took 18.11855411529541 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 18.11468195915222 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 18.154998540878296 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(8, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=8, bias=True)
)
Datatype: dual_quat
-- Started Training --
Epoch 0/9
	 Logging train Loss: 2.8066730499 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0540572219 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0709694847 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0316757932 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0668542385 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0312299654 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 36.163005352020264
Epoch 1/9
	 Logging train Loss: 0.0323498361 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0240605529 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0335813612 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.012430652 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0309844241 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.012686858 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 36.115864753723145
Epoch 2/9
	 Logging train Loss: 0.0218683071 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0182564221 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.025497172 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0086055966 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0235630609 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0099991411 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 36.20378804206848
Epoch 3/9
	 Logging train Loss: 0.0181344207 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0195450243 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.026037246 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0105678774 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0242562238 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0110723134 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 36.01699614524841
Epoch 4/9
	 Logging train Loss: 0.0165986586 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0133878551 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0191797148 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0062871375 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0182234459 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0060087177 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 36.463441133499146
Epoch 5/9
	 Logging train Loss: 0.0132231237 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0120321997 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.017105449 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0055711027 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0161165278 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0058635231 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 36.13011169433594
Epoch 6/9
	 Logging train Loss: 0.012440417 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0109808175 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0154222697 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0051118182 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0141028045 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0056403321 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 36.34658241271973
Epoch 7/9
	 Logging train Loss: 0.0108047063 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0110816611 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0145944012 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0055115386 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0132799158 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0076284362 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 36.03124189376831
Epoch 8/9
	 Logging train Loss: 0.0091881724 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0124331005 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0153963184 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0070617432 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0145499213 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0096553639 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 35.94779920578003
Epoch 9/9
	 Logging train Loss: 0.0093183443 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0057303659 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.0087442724 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 0.0019946818 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 0.0080342954 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
	 Logging test loss: 0.0021070614 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
		--> Epoch time; 35.757543325424194
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gNone/'dual_quat'_'None'.pth
It took  536.1933989524841  seconds.

JOB STATISTICS
==============
Job ID: 2944787
Array Job ID: 2944706_18
Cluster: snellius
User/Group: nreints/nreints
State: RUNNING
Nodes: 1
Cores per node: 18
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 1-03:06:18 core-walltime
Job Wall-clock time: 01:30:21
Memory Utilized: 0.00 MB (estimated maximum)
Memory Efficiency: 0.00% of 0.00 MB (0.00 MB/node)
WARNING: Efficiency statistics may be misleading for RUNNING jobs.
