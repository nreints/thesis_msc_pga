wandb: Currently logged in as: nreints. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230620_120349-v9s7f1sr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run proud-leaf-121
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal
wandb: ğŸš€ View run at https://wandb.ai/nreints/ThesisFinal/runs/v9s7f1sr
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone â–ˆâ–„â–‚â–â–â–‚â–‚â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone â–ˆâ–†â–ƒâ–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone â–ˆâ–†â–ƒâ–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone â–ˆâ–„â–ƒâ–â–â–ƒâ–‚â–â–â–
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone â–ˆâ–ƒâ–‚â–â–â–‚â–‚â–â–â–
wandb:                                   Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone 1e-05
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 1e-05
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 1e-05
wandb:                                   Train loss 1e-05
wandb: 
wandb: ğŸš€ View run proud-leaf-121 at: https://wandb.ai/nreints/ThesisFinal/runs/v9s7f1sr
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230620_120349-v9s7f1sr/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230620_122932-aruo0r7u
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sandy-salad-156
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal
wandb: ğŸš€ View run at https://wandb.ai/nreints/ThesisFinal/runs/aruo0r7u
Training on dataset: data_t(5,20)_r(5,20)_combi_pNone_gNone
Testing on 5 datasets: ['data_t(5,20)_r(5,20)_combi_pNone_gNone', 'data_t(5,20)_r(5,20)_tennis_pNone_gNone', 'data_t(5,20)_r(5,20)_none_pNone_gNone', 'data_t(5,20)_r(5,20)_full_pNone_gNone', 'data_t(5,20)_r(5,20)_semi_pNone_gNone']
Focussing on identity: False
Using extra input: inertia_body
Using fr-fr as reference point.
----- ITERATION 1/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 61.94987773895264 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 15.37703275680542 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 15.531039953231812 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_none_pNone_gNone took 15.56246542930603 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 15.594115257263184 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 15.585648775100708 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (pre_hidden_lin_layer): Sequential(
    (0): Linear(in_features=3, out_features=96, bias=True)
    (1): ReLU()
    (2): Linear(in_features=96, out_features=96, bias=True)
    (3): ReLU()
  )
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0130779659 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.000134254 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 0.000257055 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 6.50478e-05 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 6.68177e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 0.0001376824 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 139.31458854675293
Epoch 1/9
	 Logging train Loss: 8.72369e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.18566e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.2784e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 4.44473e-05 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 4.56177e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 7.19595e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 142.84192514419556
Epoch 2/9
	 Logging train Loss: 4.41399e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.96685e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.0823e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.92325e-05 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.96336e-05 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.77848e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 139.03584170341492
Epoch 3/9
	 Logging train Loss: 1.96054e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.24884e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.08171e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 5.1967e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 5.2255e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.93128e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 139.24822664260864
Epoch 4/9
	 Logging train Loss: 1.04598e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 9.8859e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.7617e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.3948e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.3655e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.56165e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 138.71554970741272
Epoch 5/9
	 Logging train Loss: 1.17212e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.46508e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.95594e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.6405e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.6152e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 4.08608e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 138.33757519721985
Epoch 6/9
	 Logging train Loss: 1.20495e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 2.06442e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 4.03913e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 3.0486e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 3.0252e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 3.64418e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 137.4804859161377
Epoch 7/9
	 Logging train Loss: 1.00856e-05 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 8.1294e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.62028e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.2547e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.2246e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.43717e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 137.77001690864563
Epoch 8/9
	 Logging train Loss: 9.5834e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 6.2426e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.15936e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.5731e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.5326e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.02354e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 140.99950456619263
Epoch 9/9
	 Logging train Loss: 9.1808e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 7.4097e-06 [MSELoss(): t(5,20)_r(5,20)_combi_pNone_gNone]
	 Logging test loss: 1.39775e-05 [MSELoss(): t(5,20)_r(5,20)_tennis_pNone_gNone]
	 Logging test loss: 1.7361e-06 [MSELoss(): t(5,20)_r(5,20)_none_pNone_gNone]
	 Logging test loss: 1.7082e-06 [MSELoss(): t(5,20)_r(5,20)_full_pNone_gNone]
	 Logging test loss: 1.23501e-05 [MSELoss(): t(5,20)_r(5,20)_semi_pNone_gNone]
		--> Epoch time; 137.68578600883484
Saved model in  trained_models/gru/data_t(5,20)_r(5,20)_combi_pNone_gNone/'rot_mat_1'_'inertia_body'.pth
It took  1544.4300184249878  seconds.
----- ITERATION 2/10 ------
Total number of simulations in train dir:  2400
Checked number of simulations in each data directory.
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 58.36994981765747 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(5,20)_r(5,20)_combi_pNone_gNone took 14.562608003616333 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_tennis_pNone_gNone took 14.888625383377075 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_none_pNone_gNone took 14.583393573760986 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_full_pNone_gNone took 14.684720754623413 seconds.
The dataloader for data/data_t(5,20)_r(5,20)_semi_pNone_gNone took 14.53913164138794 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (pre_hidden_lin_layer): Sequential(
    (0): Linear(in_features=3, out_features=96, bias=True)
    (1): ReLU()
    (2): Linear(in_features=96, out_features=96, bias=True)
    (3): ReLU()
  )
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat_1
-- Started Training --
Epoch 0/9
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                        Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone â–ˆâ–…â–ƒâ–‚â–â–‚â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone â–ˆâ–†â–ƒâ–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone â–ˆâ–†â–ƒâ–â–â–â–â–â–â–
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone â–ˆâ–…â–ƒâ–‚â–‚â–‚â–â–â–â–
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone â–ˆâ–„â–‚â–‚â–â–‚â–â–â–â–
wandb:                                   Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                        Epoch 9
wandb:  Test loss t(5,20)_r(5,20)_combi_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(5,20)_full_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(5,20)_none_pNone_gNone 0.0
wandb:   Test loss t(5,20)_r(5,20)_semi_pNone_gNone 1e-05
wandb: Test loss t(5,20)_r(5,20)_tennis_pNone_gNone 1e-05
wandb:                                   Train loss 1e-05
wandb: 
wandb: ğŸš€ View run sandy-salad-156 at: https://wandb.ai/nreints/ThesisFinal/runs/aruo0r7u
wandb: Synced 7 W&B file(s), 0 media file(s), 4 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230620_122932-aruo0r7u/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230620_125528-abmifgrm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run misunderstood-microwave-177
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal
wandb: ğŸš€ View run at https://wandb.ai/nreints/ThesisFinal/runs/abmifgrm
slurmstepd: error: *** JOB 2943917 ON gcn40 CANCELLED AT 2023-06-20T13:04:07 ***
slurmstepd: error: *** STEP 2943917.0 ON gcn40 CANCELLED AT 2023-06-20T13:04:07 ***

JOB STATISTICS
==============
Job ID: 2943917
Array Job ID: 2943913_2
Cluster: snellius
User/Group: nreints/nreints
State: CANCELLED (exit code 0)
Nodes: 1
Cores per node: 18
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 18:09:00 core-walltime
Job Wall-clock time: 01:00:30
Memory Utilized: 7.00 MB
Memory Efficiency: 0.00% of 0.00 MB
