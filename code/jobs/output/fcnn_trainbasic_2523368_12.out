wandb: Currently logged in as: nreints. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /home/nreints/.netrc
/gpfs/home2/nreints/MScThesis/code/fcnn.py:566: DeprecationWarning: Sampling from a set deprecated
since Python 3.9 and will be removed in a subsequent version.
  train_sims = set(random.sample(sims_train, int(0.8 * n_sims_train)))
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230330_123650-wpubg0t0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rural-universe-581
wandb: â­ï¸ View project at https://wandb.ai/nreints/test
wandb: ðŸš€ View run at https://wandb.ai/nreints/test/runs/wpubg0t0
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.029 MB of 0.078 MB uploaded (0.000 MB deduped)wandb: \ 0.078 MB of 0.078 MB uploaded (0.000 MB deduped)wandb: | 0.078 MB of 0.078 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  Test loss t(5, 20)_r(0, 0)_semi L1Loss() â–ˆâ–…â–…â–…â–„â–…â–ƒâ–„â–…â–‚â–‡â–…â–â–â–â–ƒâ–â–â–„â–â–
wandb: Test loss t(5, 20)_r(0, 0)_semi MSELoss() â–ˆâ–„â–…â–…â–ƒâ–„â–‚â–ƒâ–„â–‚â–‡â–„â–â–â–â–‚â–â–â–ƒâ–â–
wandb:     Train loss data_t(5, 20)_r(0, 0)_semi â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:  Test loss t(5, 20)_r(0, 0)_semi L1Loss() 0.04596
wandb: Test loss t(5, 20)_r(0, 0)_semi MSELoss() 0.0041
wandb:     Train loss data_t(5, 20)_r(0, 0)_semi 0.01013
wandb: 
wandb: ðŸš€ View run rural-universe-581 at: https://wandb.ai/nreints/test/runs/wpubg0t0
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230330_123650-wpubg0t0/logs
/gpfs/home2/nreints/MScThesis/code/fcnn.py:566: DeprecationWarning: Sampling from a set deprecated
since Python 3.9 and will be removed in a subsequent version.
  train_sims = set(random.sample(sims_train, int(0.8 * n_sims_train)))
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230330_124845-hb4oyvth
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run laced-bush-632
wandb: â­ï¸ View project at https://wandb.ai/nreints/test
wandb: ðŸš€ View run at https://wandb.ai/nreints/test/runs/hb4oyvth
Training on dataset: data/data_t(5, 20)_r(0, 0)_semi_pNone_gNone
Testing on datasets: ['data_t(5, 20)_r(0, 0)_semi_pNone_gNone']
----- ITERATION 1/2 ------
Number of train simulations: 1600
Number of test simulations: 400
The dataloader took 60.46178674697876 seconds.
-- Finished Train Dataloader --
The dataloader took 15.150658369064331 seconds.
-- Finished Test Dataloader(s) --
Datatype: dual_quat
--- Started Training ---
Epoch 0
	 Logging train Loss: 12.9983238868 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.046557679772377014 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.1622048169374466 (L1Loss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 29.899940729141235
Epoch 1
	 Logging train Loss: 0.0303711685 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.022207265719771385 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.1112380102276802 (L1Loss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 31.73059892654419
Epoch 2
	 Logging train Loss: 0.0195730147 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.025522254407405853 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.12033238261938095 (L1Loss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 31.968384265899658
Epoch 3
	 Logging train Loss: 0.0187909083 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.025370892137289047 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.11768099665641785 (L1Loss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 32.014259338378906
Epoch 4
	 Logging train Loss: 0.0179873747 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.013825397938489914 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.08780737221240997 (L1Loss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 32.11241436004639
Epoch 5
	 Logging train Loss: 0.0176237219 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.024709288030862808 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.11285838484764099 (L1Loss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 31.770456790924072
Epoch 6
	 Logging train Loss: 0.0166346407 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.012409077025949955 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.08209562301635742 (L1Loss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 31.536611557006836
Epoch 7
	 Logging train Loss: 0.0146331139 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.01666071265935898 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.0936989039182663 (L1Loss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 31.659534454345703
Epoch 8
	 Logging train Loss: 0.014268824 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.024483198300004005 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.10757958143949509 (L1Loss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 32.00434732437134
Epoch 9
	 Logging train Loss: 0.0140858843 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.008831585757434368 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.06836537271738052 (L1Loss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 31.856549501419067
Epoch 10
	 Logging train Loss: 0.01303734 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.04132906720042229 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.14364291727542877 (L1Loss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 31.25303053855896
Epoch 11
	 Logging train Loss: 0.0129605985 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.023489074781537056 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.11266084760427475 (L1Loss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 31.767975091934204
Epoch 12
	 Logging train Loss: 0.0122728036 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.004721108358353376 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.05047503858804703 (L1Loss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 30.209038257598877
Epoch 13
	 Logging train Loss: 0.012237307 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.00525392172858119 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.051847193390131 (L1Loss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 30.289249658584595
Epoch 14
	 Logging train Loss: 0.0113717547 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.005724770482629538 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.05404150113463402 (L1Loss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 30.211247205734253
Epoch 15
	 Logging train Loss: 0.0110494813 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.012057260610163212 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.08066646009683609 (L1Loss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 29.901729583740234
Epoch 16
	 Logging train Loss: 0.0118983213 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.004165759775787592 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.04625117778778076 (L1Loss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 31.77272891998291
Epoch 17
	 Logging train Loss: 0.0103129387 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.004754029214382172 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.049331456422805786 (L1Loss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 30.369155645370483
Epoch 18
	 Logging train Loss: 0.0101757754 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.018375463783740997 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.09679616242647171 (L1Loss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 30.559354782104492
Epoch 19
	 Logging train Loss: 0.0101256109 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.004099338315427303 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.045961834490299225 (L1Loss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 31.173280954360962
	 Logging test loss 0.004098835401237011 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.04596497491002083 (L1Loss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
It took 714.5707454681396 seconds to train & eval the model.
----- ITERATION 2/2 ------
Number of train simulations: 1600
Number of test simulations: 400
The dataloader took 56.155351400375366 seconds.
-- Finished Train Dataloader --
The dataloader took 14.001530885696411 seconds.
-- Finished Test Dataloader(s) --
Datatype: dual_quat
--- Started Training ---
Epoch 0
	 Logging train Loss: 10.9520578023 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.04968918487429619 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.1678813248872757 (L1Loss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 32.43273115158081
Epoch 1
	 Logging train Loss: 0.0275136312 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.01871432736515999 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.1032005175948143 (L1Loss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 30.202751874923706
Epoch 2
	 Logging train Loss: 0.0156805924 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.012644977308809757 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.08447611331939697 (L1Loss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 30.1538143157959
Epoch 3
	 Logging train Loss: 0.0140603782 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.029 MB of 0.029 MB uploaded (0.000 MB deduped)wandb: \ 0.029 MB of 0.029 MB uploaded (0.000 MB deduped)wandb: | 0.029 MB of 0.029 MB uploaded (0.000 MB deduped)wandb: / 0.029 MB of 0.029 MB uploaded (0.000 MB deduped)wandb: - 0.029 MB of 0.029 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:  Test loss t(5, 20)_r(0, 0)_semi L1Loss() â–ˆâ–„â–ƒâ–†â–ƒâ–…â–ƒâ–ƒâ–‚â–ƒâ–…â–‚â–â–ƒâ–â–‚â–‚â–‚â–‚â–‚â–‚
wandb: Test loss t(5, 20)_r(0, 0)_semi MSELoss() â–ˆâ–ƒâ–‚â–…â–‚â–„â–‚â–ƒâ–â–ƒâ–…â–â–â–‚â–â–â–â–‚â–‚â–â–
wandb:     Train loss data_t(5, 20)_r(0, 0)_semi â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:  Test loss t(5, 20)_r(0, 0)_semi L1Loss() 0.05677
wandb: Test loss t(5, 20)_r(0, 0)_semi MSELoss() 0.00602
wandb:     Train loss data_t(5, 20)_r(0, 0)_semi 0.00955
wandb: 
wandb: ðŸš€ View run laced-bush-632 at: https://wandb.ai/nreints/test/runs/hb4oyvth
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230330_124845-hb4oyvth/logs
	 Logging test loss 0.03120557591319084 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.1342235654592514 (L1Loss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 30.073116302490234
Epoch 4
	 Logging train Loss: 0.0150618622 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.011926800012588501 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.08142092078924179 (L1Loss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 32.35611605644226
Epoch 5
	 Logging train Loss: 0.0137794856 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.02159452997148037 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.10867711901664734 (L1Loss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 32.112008571624756
Epoch 6
	 Logging train Loss: 0.013476373 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.010583379305899143 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.07623684406280518 (L1Loss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 32.09024500846863
Epoch 7
	 Logging train Loss: 0.0131904515 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.014024957083165646 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.08365026861429214 (L1Loss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 30.872101306915283
Epoch 8
	 Logging train Loss: 0.0123891968 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.006952878553420305 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.0613519586622715 (L1Loss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 30.39138913154602
Epoch 9
	 Logging train Loss: 0.0120277455 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.013826999813318253 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.08301868289709091 (L1Loss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 30.344332218170166
Epoch 10
	 Logging train Loss: 0.0117508982 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.028190650045871735 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.12316451966762543 (L1Loss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 30.10249376296997
Epoch 11
	 Logging train Loss: 0.0113295649 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.005723231006413698 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.05469334498047829 (L1Loss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 31.89801526069641
Epoch 12
	 Logging train Loss: 0.011044865 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.00514204241335392 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.05180110037326813 (L1Loss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 30.3843514919281
Epoch 13
	 Logging train Loss: 0.0104723425 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.011087681166827679 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.07764419913291931 (L1Loss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 30.623131036758423
Epoch 14
	 Logging train Loss: 0.0106535444 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.0036994849797338247 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.04412635788321495 (L1Loss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 30.4815514087677
Epoch 15
	 Logging train Loss: 0.0103481766 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.006540014408528805 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.05896375700831413 (L1Loss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 29.83816170692444
Epoch 16
	 Logging train Loss: 0.0099265049 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.006214731372892857 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.05796077847480774 (L1Loss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 31.766123294830322
Epoch 17
	 Logging train Loss: 0.0097161792 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.00766452681273222 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.06415233016014099 (L1Loss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 31.604214429855347
Epoch 18
	 Logging train Loss: 0.0097483897 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.008927267044782639 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.06990140676498413 (L1Loss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 31.653759717941284
Epoch 19
	 Logging train Loss: 0.009552485 (MSELoss(): data_t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.006017193663865328 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.05677532032132149 (L1Loss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
     --> Epoch time; 30.46889615058899
	 Logging test loss 0.006017152685672045 (MSELoss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
	 Logging test loss 0.05677178502082825 (L1Loss(): t(5, 20)_r(0, 0)_semi_pNone_gNone)
It took 706.6571626663208 seconds to train & eval the model.

JOB STATISTICS
==============
Job ID: 2523380
Array Job ID: 2523368_12
Cluster: snellius
User/Group: nreints/nreints
State: COMPLETED (exit code 0)
Nodes: 1
Cores per node: 18
CPU Utilized: 03:45:29
CPU Efficiency: 52.27% of 07:11:24 core-walltime
Job Wall-clock time: 00:23:58
Memory Utilized: 3.66 GB
Memory Efficiency: 12.49% of 29.30 GB
