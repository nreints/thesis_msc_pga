wandb: Currently logged in as: nreints. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_165455-a13eqxa5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hearty-flower-760
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/a13eqxa5
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue █▃▁▁▅▁▅▁▁▁
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue █▃▁▁▅▁▅▁▁▁
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue █▃▁▁▅▁▅▁▁▁
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue █▃▁▁▅▁▅▁▁▁
wandb:                                 Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue 0.0
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue 0.0
wandb:                                 Train loss 0.0
wandb: 
wandb: 🚀 View run hearty-flower-760 at: https://wandb.ai/nreints/ThesisFinal2/runs/a13eqxa5
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_165455-a13eqxa5/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_170126-jk8094fy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run clear-butterfly-768
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/jk8094fy
Training on dataset: data_t(0,0)_r(0,0)_combi_pNone_gTrue
Testing on 4 datasets: ['data_t(0,0)_r(0,0)_full_pNone_gTrue', 'data_t(0,0)_r(0,0)_semi_pNone_gTrue', 'data_t(0,0)_r(0,0)_combi_pNone_gTrue', 'data_t(0,0)_r(0,0)_tennis_pNone_gTrue']
Focussing on identity: False
Using extra input: False
Using fr-fr as reference point.
----- ITERATION 1/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 51.50865864753723 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_full_pNone_gTrue took 13.113918542861938 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pNone_gTrue took 13.057069301605225 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 12.288437366485596 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pNone_gTrue took 12.300537824630737 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(24, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=24, bias=True)
)
Datatype: pos_diff_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 2.94802e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.418e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.417e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.417e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.418e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 28.23100233078003
Epoch 1/9
	 Logging train Loss: 1.34e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.8e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 5.79e-08 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 5.79e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.79e-08 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 27.646613836288452
Epoch 2/9
	 Logging train Loss: 2.81e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.11e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.11e-08 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.11e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.11e-08 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 27.249799251556396
Epoch 3/9
	 Logging train Loss: 5.8e-09 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.2e-09 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 4.2e-09 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 4.2e-09 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.2e-09 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 27.364176750183105
Epoch 4/9
	 Logging train Loss: 1.11e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.425e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.425e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.425e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.425e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 27.60245180130005
Epoch 5/9
	 Logging train Loss: 2.38e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5e-10 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 5e-10 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 5e-10 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5e-10 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 27.34255075454712
Epoch 6/9
	 Logging train Loss: 2.82e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.263e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.263e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.263e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.263e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 27.357651948928833
Epoch 7/9
	 Logging train Loss: 3.28e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.19e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.19e-08 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.19e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.19e-08 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 27.30733847618103
Epoch 8/9
	 Logging train Loss: 3.08e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.31e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.31e-08 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.31e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.31e-08 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 27.165963411331177
Epoch 9/9
	 Logging train Loss: 2.98e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6e-10 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 6e-10 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 6e-10 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6e-10 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 27.337499618530273
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'pos_diff_1'_'False'.pth
It took  392.4098515510559  seconds.
----- ITERATION 2/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 50.852680683135986 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_full_pNone_gTrue took 13.109310865402222 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pNone_gTrue took 13.139248371124268 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 12.783880472183228 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pNone_gTrue took 12.963780879974365 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(24, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=24, bias=True)
)
Datatype: pos_diff_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 3.45632e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.906e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.906e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.906e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.905e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 27.525954484939575
Epoch 1/9
	 Logging train Loss: 1.167e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.34e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 6.34e-08 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 6.34e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.34e-08 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 27.534306526184082
Epoch 2/9
	 Logging train Loss: 3.9e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.01e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.01e-08 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.01e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.01e-08 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 27.592926740646362
Epoch 3/9
	 Logging train Loss: 1.58e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.2e-09 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 6.2e-09 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 6.2e-09 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.2e-09 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 27.386327028274536
Epoch 4/9
	 Logging train Loss: 1.92e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.7e-09 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 6.7e-09 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue █▃▂▁▁▄▁▂▁▃
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue █▃▂▁▁▄▁▂▁▃
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue █▃▂▁▁▄▁▂▁▃
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue █▃▂▁▁▄▁▂▁▃
wandb:                                 Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue 0.0
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue 0.0
wandb:                                 Train loss 0.0
wandb: 
wandb: 🚀 View run clear-butterfly-768 at: https://wandb.ai/nreints/ThesisFinal2/runs/jk8094fy
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_170126-jk8094fy/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_170755-brv6dn53
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glamorous-meadow-784
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/brv6dn53
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue █▃▁▂▁▂▁▁▂▂
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue █▃▁▂▁▂▁▁▂▂
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue █▃▁▂▁▂▁▁▂▂
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue █▃▁▂▁▂▁▁▂▂
wandb:                                 Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue 0.0
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue 0.0
wandb:                                 Train loss 0.0
wandb: 
wandb: 🚀 View run glamorous-meadow-784 at: https://wandb.ai/nreints/ThesisFinal2/runs/brv6dn53
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_170755-brv6dn53/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_171422-udn6fbr7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rare-valley-796
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/udn6fbr7
	 Logging test loss: 6.7e-09 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.7e-09 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 27.522475481033325
Epoch 5/9
	 Logging train Loss: 2.61e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.85e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 8.85e-08 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 8.85e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.85e-08 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 27.451392650604248
Epoch 6/9
	 Logging train Loss: 3.27e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.7e-09 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 6.7e-09 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 6.7e-09 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.7e-09 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 27.48474359512329
Epoch 7/9
	 Logging train Loss: 3.28e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.08e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 4.08e-08 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 4.08e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.08e-08 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 27.495155096054077
Epoch 8/9
	 Logging train Loss: 3.09e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6e-10 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 6e-10 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 6e-10 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6e-10 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 27.293134689331055
Epoch 9/9
	 Logging train Loss: 2.82e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.72e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 6.72e-08 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 6.72e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.72e-08 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 27.3884174823761
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'pos_diff_1'_'False'.pth
It took  388.5408082008362  seconds.
----- ITERATION 3/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 48.73321461677551 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_full_pNone_gTrue took 12.92840051651001 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pNone_gTrue took 12.942039728164673 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 12.170162439346313 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pNone_gTrue took 12.883744716644287 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(24, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=24, bias=True)
)
Datatype: pos_diff_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 2.8775e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.312e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.312e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.312e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.312e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 27.53587245941162
Epoch 1/9
	 Logging train Loss: 1.29e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.56e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 5.56e-08 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 5.56e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.55e-08 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 27.493982791900635
Epoch 2/9
	 Logging train Loss: 2.62e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.1e-09 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 8.1e-09 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 8.1e-09 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.1e-09 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 27.578243732452393
Epoch 3/9
	 Logging train Loss: 7.7e-09 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.99e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.99e-08 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.99e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.99e-08 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 27.463842153549194
Epoch 4/9
	 Logging train Loss: 1.04e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.9e-09 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.9e-09 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.9e-09 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.9e-09 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 27.396584033966064
Epoch 5/9
	 Logging train Loss: 2.4e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.61e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.61e-08 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.61e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.61e-08 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 27.535189151763916
Epoch 6/9
	 Logging train Loss: 3.35e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.7e-09 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 7.7e-09 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 7.7e-09 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.7e-09 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 27.50358009338379
Epoch 7/9
	 Logging train Loss: 3.4e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.4e-09 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 7.4e-09 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 7.4e-09 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.4e-09 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 27.68985867500305
Epoch 8/9
	 Logging train Loss: 3.45e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.73e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.73e-08 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.73e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.73e-08 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 27.656002283096313
Epoch 9/9
	 Logging train Loss: 3.14e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.23e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.23e-08 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.23e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.23e-08 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 27.485424280166626
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'pos_diff_1'_'False'.pth
It took  387.202508687973  seconds.
----- ITERATION 4/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 49.3792884349823 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_full_pNone_gTrue took 12.934260129928589 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pNone_gTrue took 12.940544366836548 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 12.541683197021484 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pNone_gTrue took 12.935855388641357 seconds.
-- Finished Test Dataloader(s) --
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue █▃▁▁▂▁▁▁▁▁
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue █▃▁▁▂▁▁▁▁▁
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue █▃▁▁▂▁▁▁▁▁
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue █▃▁▁▂▁▁▁▁▁
wandb:                                 Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue 0.0
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue 0.0
wandb:                                 Train loss 0.0
wandb: 
wandb: 🚀 View run rare-valley-796 at: https://wandb.ai/nreints/ThesisFinal2/runs/udn6fbr7
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_171422-udn6fbr7/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_172050-yn5l6lh0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run efficient-sea-814
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/yn5l6lh0
GRU(
  (rnn): GRU(24, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=24, bias=True)
)
Datatype: pos_diff_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 2.81508e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.313e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.314e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.312e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.314e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 27.404880046844482
Epoch 1/9
	 Logging train Loss: 1.253e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.36e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 5.36e-08 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 5.36e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.36e-08 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 27.135684967041016
Epoch 2/9
	 Logging train Loss: 2.61e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.6e-09 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 8.6e-09 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 8.6e-09 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.6e-09 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 27.527886629104614
Epoch 3/9
	 Logging train Loss: 9.9e-09 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.6e-09 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.6e-09 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.6e-09 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.6e-09 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 27.571800470352173
Epoch 4/9
	 Logging train Loss: 1.57e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.03e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 5.03e-08 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 5.03e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.03e-08 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 27.675141096115112
Epoch 5/9
	 Logging train Loss: 2.59e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.7e-09 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.7e-09 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 3.7e-09 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.7e-09 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 27.358149528503418
Epoch 6/9
	 Logging train Loss: 3.24e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.1e-09 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.1e-09 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.1e-09 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.1e-09 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 27.445305585861206
Epoch 7/9
	 Logging train Loss: 3.26e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.66e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.66e-08 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.66e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.66e-08 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 27.696305513381958
Epoch 8/9
	 Logging train Loss: 3.02e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.9e-09 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 4.9e-09 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 4.9e-09 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.9e-09 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 27.41444420814514
Epoch 9/9
	 Logging train Loss: 2.82e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.9e-09 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 5.9e-09 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 5.9e-09 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.9e-09 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 27.356638431549072
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'pos_diff_1'_'False'.pth
It took  388.0747892856598  seconds.
----- ITERATION 5/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 48.93637204170227 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_full_pNone_gTrue took 12.919702529907227 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pNone_gTrue took 12.893546342849731 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 12.419666290283203 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pNone_gTrue took 12.940021514892578 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(24, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=24, bias=True)
)
Datatype: pos_diff_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 2.62573e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.438e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.437e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.438e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.437e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 27.746273517608643
Epoch 1/9
	 Logging train Loss: 5.66e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.41e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.4e-08 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.4e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.41e-08 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 27.535968542099
Epoch 2/9
	 Logging train Loss: 7.9e-09 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.4e-09 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.4e-09 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.4e-09 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.4e-09 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 27.515947818756104
Epoch 3/9
	 Logging train Loss: 1.61e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.02e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.02e-08 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.02e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.02e-08 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 27.551271438598633
Epoch 4/9
	 Logging train Loss: 2.29e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5e-10 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 5e-10 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 5e-10 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5e-10 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 27.50797200202942
Epoch 5/9
	 Logging train Loss: 3.84e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.19e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.19e-08 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.19e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.19e-08 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 27.68658471107483
Epoch 6/9
	 Logging train Loss: 3.79e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.21e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.21e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.21e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.21e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue ▆▁▁▁▁▂█▃▁▁
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue ▆▁▁▁▁▂█▃▁▁
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue ▆▁▁▁▁▂█▃▁▁
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue ▆▁▁▁▁▂█▃▁▁
wandb:                                 Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue 0.0
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue 0.0
wandb:                                 Train loss 0.0
wandb: 
wandb: 🚀 View run efficient-sea-814 at: https://wandb.ai/nreints/ThesisFinal2/runs/yn5l6lh0
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_172050-yn5l6lh0/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_172717-fwqbwsue
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run honest-cherry-828
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/fwqbwsue
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue █▃▂▁▁▁▁▁▁▁
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue █▃▂▁▁▁▁▁▁▁
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue █▃▂▁▁▁▁▁▁▁
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue █▃▂▁▁▁▁▁▁▁
wandb:                                 Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue 0.0
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue 0.0
wandb:                                 Train loss 0.0
wandb: 
wandb: 🚀 View run honest-cherry-828 at: https://wandb.ai/nreints/ThesisFinal2/runs/fwqbwsue
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_172717-fwqbwsue/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_173345-a578aiqt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run brisk-voice-846
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/a578aiqt
		--> Epoch time; 27.624115228652954
Epoch 7/9
	 Logging train Loss: 4.11e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.38e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 5.38e-08 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 5.38e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.38e-08 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 27.52394437789917
Epoch 8/9
	 Logging train Loss: 3.73e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.8e-09 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.8e-09 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 3.8e-09 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.8e-09 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 27.261905908584595
Epoch 9/9
	 Logging train Loss: 3.53e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.4e-09 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 6.4e-09 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 6.4e-09 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.4e-09 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 27.607189416885376
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'pos_diff_1'_'False'.pth
It took  387.18612718582153  seconds.
----- ITERATION 6/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 48.818575859069824 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_full_pNone_gTrue took 12.760676383972168 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pNone_gTrue took 12.772395610809326 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 12.516846179962158 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pNone_gTrue took 12.88048505783081 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(24, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=24, bias=True)
)
Datatype: pos_diff_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 2.64547e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.47e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.47e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.47e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.469e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 27.50268030166626
Epoch 1/9
	 Logging train Loss: 1.477e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.57e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 7.57e-08 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 7.57e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.57e-08 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 27.636144161224365
Epoch 2/9
	 Logging train Loss: 4.49e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.25e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.25e-08 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.25e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.25e-08 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 27.601596117019653
Epoch 3/9
	 Logging train Loss: 2.45e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.6e-09 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 6.6e-09 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 6.6e-09 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.6e-09 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 27.42001461982727
Epoch 4/9
	 Logging train Loss: 2.36e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.1e-09 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.1e-09 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 3.1e-09 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.1e-09 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 27.558250188827515
Epoch 5/9
	 Logging train Loss: 3.43e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.7e-09 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 6.7e-09 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 6.7e-09 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.7e-09 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 27.407089471817017
Epoch 6/9
	 Logging train Loss: 3.58e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.3e-09 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.3e-09 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.3e-09 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.3e-09 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 27.236429691314697
Epoch 7/9
	 Logging train Loss: 3.87e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 9e-10 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 9e-10 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 9e-10 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 9e-10 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 27.700682878494263
Epoch 8/9
	 Logging train Loss: 3.56e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.1e-09 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.1e-09 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 3.1e-09 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.1e-09 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 27.558026790618896
Epoch 9/9
	 Logging train Loss: 3.46e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.4e-09 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 7.4e-09 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 7.4e-09 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.4e-09 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 27.74194574356079
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'pos_diff_1'_'False'.pth
It took  388.09140825271606  seconds.
----- ITERATION 7/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 49.09360718727112 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_full_pNone_gTrue took 12.729112386703491 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pNone_gTrue took 12.736752033233643 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 12.46652865409851 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pNone_gTrue took 12.827000856399536 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(24, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=24, bias=True)
)
Datatype: pos_diff_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 1.58767e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.451e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.451e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.451e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.451e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 27.621103286743164
Epoch 1/9
	 Logging train Loss: 5.39e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.05e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.05e-08 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.05e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.05e-08 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 27.763113260269165
Epoch 2/9
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue █▁▁▂▂▃▃▂▃▂
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue █▁▁▂▂▃▃▂▃▂
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue █▁▁▂▂▃▃▂▃▂
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue █▁▁▂▂▃▃▂▃▂
wandb:                                 Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue 0.0
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue 0.0
wandb:                                 Train loss 0.0
wandb: 
wandb: 🚀 View run brisk-voice-846 at: https://wandb.ai/nreints/ThesisFinal2/runs/a578aiqt
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_173345-a578aiqt/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_174012-nd6wren5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run zany-blaze-860
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/nd6wren5
	 Logging train Loss: 5.6e-09 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.8e-09 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.8e-09 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.8e-09 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.8e-09 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 27.450639009475708
Epoch 3/9
	 Logging train Loss: 1.09e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.52e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.52e-08 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.52e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.52e-08 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 27.488466262817383
Epoch 4/9
	 Logging train Loss: 2.48e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.42e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.42e-08 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.42e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.42e-08 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 27.446001291275024
Epoch 5/9
	 Logging train Loss: 3.24e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.3e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.3e-08 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 3.3e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.3e-08 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 27.63660192489624
Epoch 6/9
	 Logging train Loss: 3.37e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.75e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.75e-08 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 3.75e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.75e-08 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 27.338061332702637
Epoch 7/9
	 Logging train Loss: 3.09e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.01e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.01e-08 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.01e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.01e-08 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 27.62085771560669
Epoch 8/9
	 Logging train Loss: 3.01e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.92e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 4.92e-08 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 4.92e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.92e-08 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 27.455816745758057
Epoch 9/9
	 Logging train Loss: 2.8e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.68e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.68e-08 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.68e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.68e-08 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 27.541197538375854
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'pos_diff_1'_'False'.pth
It took  387.1596369743347  seconds.
----- ITERATION 8/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 49.01272416114807 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_full_pNone_gTrue took 12.693673133850098 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pNone_gTrue took 12.728758573532104 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 12.255660057067871 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pNone_gTrue took 12.65490436553955 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(24, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=24, bias=True)
)
Datatype: pos_diff_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 2.24414e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.911e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.911e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.91e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.911e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 27.66528081893921
Epoch 1/9
	 Logging train Loss: 9.15e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.98e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.98e-08 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.98e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.98e-08 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 27.73534369468689
Epoch 2/9
	 Logging train Loss: 1.5e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5e-09 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 5e-09 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 5e-09 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5e-09 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 27.767460107803345
Epoch 3/9
	 Logging train Loss: 1.35e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.4e-09 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.4e-09 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.4e-09 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.4e-09 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 27.605199098587036
Epoch 4/9
	 Logging train Loss: 2.45e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7e-10 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 7e-10 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 7e-10 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7e-10 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 27.29641604423523
Epoch 5/9
	 Logging train Loss: 3.58e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6e-10 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 6e-10 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 6e-10 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6e-10 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 27.6165611743927
Epoch 6/9
	 Logging train Loss: 4.12e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 9.7e-09 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 9.7e-09 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 9.7e-09 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 9.7e-09 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 27.5089168548584
Epoch 7/9
	 Logging train Loss: 3.81e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.8e-09 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.8e-09 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.8e-09 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.8e-09 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 27.71358633041382
Epoch 8/9
	 Logging train Loss: 3.74e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.92e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.92e-08 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 3.92e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.92e-08 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 27.63628077507019
Epoch 9/9
	 Logging train Loss: 3.4e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.1e-09 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue █▂▁▁▁▁▁▁▂▁
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue █▂▁▁▁▁▁▁▂▁
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue █▂▁▁▁▁▁▁▂▁
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue █▂▁▁▁▁▁▁▂▁
wandb:                                 Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue 0.0
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue 0.0
wandb:                                 Train loss 0.0
wandb: 
wandb: 🚀 View run zany-blaze-860 at: https://wandb.ai/nreints/ThesisFinal2/runs/nd6wren5
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_174012-nd6wren5/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_174639-9rws9zo2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run worthy-lion-880
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/9rws9zo2
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue █▂▁▁▂▁▂▂▅▁
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue █▂▁▁▂▁▂▂▅▁
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue █▂▁▁▂▁▂▂▅▁
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue █▂▁▁▂▁▂▂▅▁
wandb:                                 Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue 0.0
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue 0.0
wandb:                                 Train loss 0.0
wandb: 
wandb: 🚀 View run worthy-lion-880 at: https://wandb.ai/nreints/ThesisFinal2/runs/9rws9zo2
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_174639-9rws9zo2/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_175308-2bliajjb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ethereal-meadow-897
wandb: ⭐️ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: 🚀 View run at https://wandb.ai/nreints/ThesisFinal2/runs/2bliajjb
	 Logging test loss: 2.1e-09 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.1e-09 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.1e-09 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 27.118014097213745
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'pos_diff_1'_'False'.pth
It took  387.0536651611328  seconds.
----- ITERATION 9/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 49.688270568847656 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_full_pNone_gTrue took 12.722655057907104 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pNone_gTrue took 12.716356992721558 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 12.55164384841919 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pNone_gTrue took 12.711512327194214 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(24, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=24, bias=True)
)
Datatype: pos_diff_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 2.34027e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.38e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.379e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.38e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.379e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 27.245325088500977
Epoch 1/9
	 Logging train Loss: 5.23e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.1e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.1e-08 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.1e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.1e-08 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 27.717910528182983
Epoch 2/9
	 Logging train Loss: 8e-09 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.6e-09 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.6e-09 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.6e-09 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.6e-09 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 27.378671646118164
Epoch 3/9
	 Logging train Loss: 1.06e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7e-10 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 7e-10 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 7e-10 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7e-10 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 27.639984130859375
Epoch 4/9
	 Logging train Loss: 1.89e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.33e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.33e-08 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.33e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.33e-08 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 27.461723566055298
Epoch 5/9
	 Logging train Loss: 2.63e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4e-10 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 4e-10 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 4e-10 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4e-10 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 27.460954189300537
Epoch 6/9
	 Logging train Loss: 2.81e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.39e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.39e-08 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.39e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.39e-08 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 27.359489917755127
Epoch 7/9
	 Logging train Loss: 2.93e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.69e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.69e-08 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.69e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.69e-08 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 27.7309992313385
Epoch 8/9
	 Logging train Loss: 2.66e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.85e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 7.85e-08 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 7.85e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.85e-08 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 27.676830530166626
Epoch 9/9
	 Logging train Loss: 2.61e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.02e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.02e-08 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.02e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.02e-08 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 27.803110599517822
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'pos_diff_1'_'False'.pth
It took  388.313414812088  seconds.
----- ITERATION 10/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 48.895355224609375 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_full_pNone_gTrue took 12.686126232147217 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pNone_gTrue took 12.690990924835205 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 12.531672716140747 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pNone_gTrue took 12.781046628952026 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(24, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=24, bias=True)
)
Datatype: pos_diff_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 2.02815e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.968e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.967e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.967e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.968e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 27.40041947364807
Epoch 1/9
	 Logging train Loss: 1.039e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.12e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 6.12e-08 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 6.12e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.12e-08 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 27.726058959960938
Epoch 2/9
	 Logging train Loss: 2.05e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.9e-09 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 6.9e-09 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 6.9e-09 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.9e-09 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 27.551018953323364
Epoch 3/9
	 Logging train Loss: 7.9e-09 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.14e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 2.14e-08 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.14e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.14e-08 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 27.63149642944336
Epoch 4/9
	 Logging train Loss: 1.65e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.7e-09 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch ▁▂▃▃▄▅▆▆▇█
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue █▃▁▂▁▂▄▂▁▂
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue █▃▁▂▁▂▄▂▁▂
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue █▃▁▂▁▂▄▂▁▂
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue █▃▁▂▁▂▄▂▁▂
wandb:                                 Train loss █▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue 0.0
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue 0.0
wandb:                                 Train loss 0.0
wandb: 
wandb: 🚀 View run ethereal-meadow-897 at: https://wandb.ai/nreints/ThesisFinal2/runs/2bliajjb
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_175308-2bliajjb/logs
	 Logging test loss: 2.7e-09 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.7e-09 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.7e-09 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 27.505753755569458
Epoch 5/9
	 Logging train Loss: 2.82e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.34e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 4.34e-08 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 4.34e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.34e-08 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 27.592309713363647
Epoch 6/9
	 Logging train Loss: 3.26e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.41e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 7.41e-08 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 7.41e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.41e-08 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 27.647494554519653
Epoch 7/9
	 Logging train Loss: 3.02e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.02e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 3.02e-08 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 3.02e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.02e-08 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 27.704195261001587
Epoch 8/9
	 Logging train Loss: 3.08e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.35e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 1.35e-08 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.35e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.35e-08 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 27.492684364318848
Epoch 9/9
	 Logging train Loss: 2.74e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.38e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
	 Logging test loss: 4.38e-08 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 4.38e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.38e-08 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
		--> Epoch time; 27.51017165184021
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'pos_diff_1'_'False'.pth
It took  387.0472660064697  seconds.

JOB STATISTICS
==============
Job ID: 3037747
Array Job ID: 3037727_40
Cluster: snellius
User/Group: nreints/nreints
State: COMPLETED (exit code 0)
Nodes: 1
Cores per node: 18
CPU Utilized: 01:05:31
CPU Efficiency: 5.60% of 19:30:36 core-walltime
Job Wall-clock time: 01:05:02
Memory Utilized: 9.85 GB
Memory Efficiency: 0.00% of 0.00 MB
