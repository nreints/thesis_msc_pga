wandb: Currently logged in as: nreints. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_165449-5qvh8h6w
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run bumbling-vortex-756
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/5qvh8h6w
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue â–†â–‚â–‚â–â–ˆâ–‚â–â–„â–â–
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue â–ˆâ–‚â–‚â–‚â–†â–â–â–…â–â–
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue â–…â–‚â–‚â–â–ˆâ–‚â–â–ƒâ–â–
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue â–…â–‚â–‚â–â–ˆâ–‚â–â–ƒâ–â–
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue 0.0
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue 0.0
wandb:                                 Train loss 0.0
wandb: 
wandb: ðŸš€ View run bumbling-vortex-756 at: https://wandb.ai/nreints/ThesisFinal2/runs/5qvh8h6w
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_165449-5qvh8h6w/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_170604-3hmwmotm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fluent-paper-779
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/3hmwmotm
Training on dataset: data_t(0,0)_r(0,0)_combi_pNone_gTrue
Testing on 4 datasets: ['data_t(0,0)_r(0,0)_combi_pNone_gTrue', 'data_t(0,0)_r(0,0)_tennis_pNone_gTrue', 'data_t(0,0)_r(0,0)_semi_pNone_gTrue', 'data_t(0,0)_r(0,0)_full_pNone_gTrue']
Focussing on identity: True
Using extra input: False
Using fr-fr as reference point.
----- ITERATION 1/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 51.98645305633545 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 12.96839714050293 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pNone_gTrue took 12.966358184814453 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pNone_gTrue took 12.17517638206482 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pNone_gTrue took 12.208836793899536 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0001071784 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.0038e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.2769e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.2225e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.8044e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 56.25409913063049
Epoch 1/9
	 Logging train Loss: 8.228e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.628e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.137e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 4.069e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 3.225e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 56.266398668289185
Epoch 2/9
	 Logging train Loss: 4.244e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.077e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.092e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 5.968e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.388e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 56.36425447463989
Epoch 3/9
	 Logging train Loss: 7.135e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.685e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.936e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.904e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.431e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 56.82451605796814
Epoch 4/9
	 Logging train Loss: 5.527e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.7187e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.2017e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.9176e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.2939e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 57.37638735771179
Epoch 5/9
	 Logging train Loss: 5.351e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.076e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.622e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.45e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 5.17e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 55.843350887298584
Epoch 6/9
	 Logging train Loss: 5.202e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.27e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.413e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.421e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.138e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 55.06316423416138
Epoch 7/9
	 Logging train Loss: 4.606e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.0797e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.127e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.1225e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.0389e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 54.98076033592224
Epoch 8/9
	 Logging train Loss: 3.605e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.85e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.34e-08 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 5.06e-08 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 8.8e-09 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 54.791513204574585
Epoch 9/9
	 Logging train Loss: 3.474e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.9e-09 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.5e-09 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 6.5e-09 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 5.4e-09 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 55.08273482322693
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'rot_mat_1'_'False'.pth
It took  675.1925828456879  seconds.
----- ITERATION 2/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 50.77958345413208 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 12.7449209690094 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pNone_gTrue took 12.79038381576538 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pNone_gTrue took 12.808301448822021 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pNone_gTrue took 12.746519804000854 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 6.08642e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.978e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.42e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 6.353e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 5.586e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 56.396515130996704
Epoch 1/9
	 Logging train Loss: 3.776e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.854e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.881e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.877e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.827e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 56.55860376358032
Epoch 2/9
	 Logging train Loss: 2.867e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.548e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.575e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.572e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.525e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 56.22745943069458
Epoch 3/9
	 Logging train Loss: 5.023e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.85e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.087e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.878e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.761e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 56.19449830055237
Epoch 4/9
	 Logging train Loss: 9.449e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.92e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue â–‚â–‚â–â–‚â–â–â–â–ˆâ–â–„
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue â–ƒâ–‚â–â–‚â–â–â–â–ˆâ–â–…
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue â–‚â–â–â–‚â–â–â–â–ˆâ–â–„
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue â–‚â–â–â–‚â–â–â–â–ˆâ–â–„
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue 0.0
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue 0.0
wandb:                                 Train loss 0.0
wandb: 
wandb: ðŸš€ View run fluent-paper-779 at: https://wandb.ai/nreints/ThesisFinal2/runs/3hmwmotm
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_170604-3hmwmotm/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_171714-zd0iajdt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run expert-sound-806
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/zd0iajdt
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue â–ˆâ–‚â–‚â–â–‚â–ƒâ–â–‚â–â–‚
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue â–ˆâ–‚â–‚â–â–‚â–â–â–â–â–‚
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue â–ˆâ–‚â–â–â–‚â–…â–â–„â–â–‚
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue â–ˆâ–‚â–â–â–‚â–…â–â–„â–â–‚
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue 0.0
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue 0.0
wandb:                                 Train loss 0.0
wandb: 
wandb: ðŸš€ View run expert-sound-806 at: https://wandb.ai/nreints/ThesisFinal2/runs/zd0iajdt
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_171714-zd0iajdt/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_172853-39ko9z8q
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pious-waterfall-834
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/39ko9z8q
	 Logging test loss: 3.02e-08 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3e-08 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.83e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 55.66130971908569
Epoch 5/9
	 Logging train Loss: 4.362e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.39e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.62e-08 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.58e-08 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.2e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 55.449267625808716
Epoch 6/9
	 Logging train Loss: 4.747e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.14e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.62e-08 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 6.21e-08 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.01e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 55.43716096878052
Epoch 7/9
	 Logging train Loss: 4.165e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.3745e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.5199e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 4.2936e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.422e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 55.58605194091797
Epoch 8/9
	 Logging train Loss: 3.549e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5e-10 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6e-10 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 6e-10 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 3e-10 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 55.46906542778015
Epoch 9/9
	 Logging train Loss: 3.22e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.6012e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.7063e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.6897e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.5089e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 55.51662492752075
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'rot_mat_1'_'False'.pth
It took  670.5317323207855  seconds.
----- ITERATION 3/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 50.130728006362915 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 12.626801490783691 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pNone_gTrue took 12.73751974105835 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pNone_gTrue took 12.757547616958618 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pNone_gTrue took 12.737007856369019 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.0001052434 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.5714e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.8996e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.8619e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 3.3598e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 57.40772771835327
Epoch 1/9
	 Logging train Loss: 1.5804e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.588e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.244e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 5.154e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 4.162e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 59.148825883865356
Epoch 2/9
	 Logging train Loss: 3.538e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.578e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.807e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.785e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 3.41e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 60.02623701095581
Epoch 3/9
	 Logging train Loss: 5.854e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.817e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.861e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.858e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.782e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 59.33850455284119
Epoch 4/9
	 Logging train Loss: 5.984e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.299e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.304e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 5.262e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 3.455e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 60.44504976272583
Epoch 5/9
	 Logging train Loss: 5.476e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.1164e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.4262e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.3127e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.169e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 60.233643531799316
Epoch 6/9
	 Logging train Loss: 5.45e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 9.22e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.537e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.459e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 4.33e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 58.546736001968384
Epoch 7/9
	 Logging train Loss: 4.329e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.722e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.5865e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.5284e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 8.34e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 57.6732234954834
Epoch 8/9
	 Logging train Loss: 2.973e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.25e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.535e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.446e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 3.75e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 57.56696271896362
Epoch 9/9
	 Logging train Loss: 2.856e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.948e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.344e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 6.25e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 3.881e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 57.6728892326355
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'rot_mat_1'_'False'.pth
It took  699.0907647609711  seconds.
----- ITERATION 4/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 50.46856665611267 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 12.778999090194702 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pNone_gTrue took 12.7396879196167 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pNone_gTrue took 12.745847940444946 seconds.
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue â–ˆâ–‚â–‚â–‚â–‚â–ƒâ–â–â–‡â–
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue â–ˆâ–‚â–‚â–‚â–‚â–„â–â–â–„â–
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue â–ˆâ–‚â–‚â–â–‚â–ƒâ–â–â–ˆâ–
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue â–‡â–‚â–‚â–â–‚â–ƒâ–â–â–ˆâ–‚
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue 0.0
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue 0.0
wandb:                                 Train loss 0.0
wandb: 
wandb: ðŸš€ View run pious-waterfall-834 at: https://wandb.ai/nreints/ThesisFinal2/runs/39ko9z8q
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_172853-39ko9z8q/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_174032-8a45c8gh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run efficient-jazz-864
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/8a45c8gh
The dataloader for data/data_t(0,0)_r(0,0)_full_pNone_gTrue took 12.800719976425171 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 6.46059e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.7086e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.8585e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.8439e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.5502e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 58.38806891441345
Epoch 1/9
	 Logging train Loss: 6.919e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.401e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.473e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.466e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 3.33e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 57.884732723236084
Epoch 2/9
	 Logging train Loss: 4.409e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.287e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.322e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.319e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.253e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 58.86038851737976
Epoch 3/9
	 Logging train Loss: 9.155e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.474e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.493e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.491e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.453e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 58.62416172027588
Epoch 4/9
	 Logging train Loss: 4.072e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.432e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.185e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 4.075e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.714e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 58.399718284606934
Epoch 5/9
	 Logging train Loss: 6.488e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.014e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.066e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 6.061e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 5.965e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 58.520522356033325
Epoch 6/9
	 Logging train Loss: 6.659e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.31e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.72e-08 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.69e-08 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.92e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 58.4374098777771
Epoch 7/9
	 Logging train Loss: 3.752e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.06e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.54e-08 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 6.51e-08 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 5.51e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 58.44860243797302
Epoch 8/9
	 Logging train Loss: 4.052e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.3687e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.0316e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.9724e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 6.461e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 58.87962365150452
Epoch 9/9
	 Logging train Loss: 3.357e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.096e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.749e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.646e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 4.49e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 58.48239183425903
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'rot_mat_1'_'False'.pth
It took  699.1127164363861  seconds.
----- ITERATION 5/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 49.27870011329651 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 12.435626745223999 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pNone_gTrue took 12.655484199523926 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pNone_gTrue took 12.75415849685669 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pNone_gTrue took 12.733197450637817 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 0.000108242 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.958e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 9.562e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 9.337e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 6.476e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 57.40529203414917
Epoch 1/9
	 Logging train Loss: 4.11e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.941e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.018e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.019e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.858e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 57.05520439147949
Epoch 2/9
	 Logging train Loss: 3.493e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.678e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.72e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.719e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.635e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 57.207812786102295
Epoch 3/9
	 Logging train Loss: 4.836e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.9021e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.41648e-05 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.35618e-05 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.4832e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 57.35877060890198
Epoch 4/9
	 Logging train Loss: 5.842e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.1392e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.4764e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.4152e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.8489e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 57.43157148361206
Epoch 5/9
	 Logging train Loss: 5.605e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.59e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.79e-08 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.77e-08 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.4e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 58.89589524269104
Epoch 6/9
	 Logging train Loss: 4.144e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.16e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue â–‚â–â–â–ˆâ–ƒâ–â–â–â–â–
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue â–ƒâ–‚â–‚â–‡â–ˆâ–â–â–â–â–
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue â–â–â–â–ˆâ–‚â–â–â–â–â–
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue â–â–â–â–ˆâ–‚â–â–â–â–â–
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue 0.0
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue 0.0
wandb:                                 Train loss 0.0
wandb: 
wandb: ðŸš€ View run efficient-jazz-864 at: https://wandb.ai/nreints/ThesisFinal2/runs/8a45c8gh
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_174032-8a45c8gh/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_175204-juk93hut
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run floral-monkey-894
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/juk93hut
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue â–…â–‚â–‚â–ˆâ–‚â–„â–‚â–‚â–â–
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue â–…â–‚â–‚â–ˆâ–‚â–‚â–â–‚â–â–
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue â–…â–‚â–â–ˆâ–‚â–†â–ƒâ–ƒâ–â–
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue â–…â–‚â–â–ˆâ–‚â–†â–ƒâ–ƒâ–â–
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue 0.0
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue 0.0
wandb:                                 Train loss 0.0
wandb: 
wandb: ðŸš€ View run floral-monkey-894 at: https://wandb.ai/nreints/ThesisFinal2/runs/juk93hut
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_175204-juk93hut/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_180325-p94nyrws
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run unique-pyramid-925
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/p94nyrws
	 Logging test loss: 1.37e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.238e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.03e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 58.66919469833374
Epoch 7/9
	 Logging train Loss: 4.133e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.19e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.28e-08 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 7.67e-08 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 8.1e-09 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 59.178675174713135
Epoch 8/9
	 Logging train Loss: 4.105e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8e-10 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.1e-09 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.1e-09 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 5e-10 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 58.548004150390625
Epoch 9/9
	 Logging train Loss: 3.126e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.17e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.05e-08 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 4.04e-08 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2e-09 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 57.924633264541626
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'rot_mat_1'_'False'.pth
It took  692.0396273136139  seconds.
----- ITERATION 6/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 49.250500440597534 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 12.380582094192505 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pNone_gTrue took 12.621389627456665 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pNone_gTrue took 12.664815425872803 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pNone_gTrue took 12.673007488250732 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 3.60263e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.508e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.705e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 4.641e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 4.353e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 57.01401495933533
Epoch 1/9
	 Logging train Loss: 4.378e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.592e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.639e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.624e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.555e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 57.188764572143555
Epoch 2/9
	 Logging train Loss: 5.473e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.11e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.36e-08 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 7.29e-08 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 6.91e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 56.76291084289551
Epoch 3/9
	 Logging train Loss: 5.05e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.621e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.719e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 8.705e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 8.538e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 57.09232950210571
Epoch 4/9
	 Logging train Loss: 5.143e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.201e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.822e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.677e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 6.66e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 57.549525022506714
Epoch 5/9
	 Logging train Loss: 4.483e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.347e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.387e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 6.062e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 6.8e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 56.39260506629944
Epoch 6/9
	 Logging train Loss: 4.03e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.263e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.162e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.073e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 4.82e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 56.32571077346802
Epoch 7/9
	 Logging train Loss: 3.433e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.655e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.358e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.255e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.044e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 57.209078788757324
Epoch 8/9
	 Logging train Loss: 3.074e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.35e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.41e-08 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 6.72e-08 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 3.5e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 57.28683805465698
Epoch 9/9
	 Logging train Loss: 2.52e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.9e-09 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.29e-08 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.24e-08 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 5.5e-09 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 57.20479869842529
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'rot_mat_1'_'False'.pth
It took  680.1827960014343  seconds.
----- ITERATION 7/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 50.13195872306824 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 12.533559322357178 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pNone_gTrue took 12.746143579483032 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pNone_gTrue took 12.744738101959229 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pNone_gTrue took 12.827831506729126 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 5.80073e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.4756e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.6432e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.6078e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.3237e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 57.68615674972534
Epoch 1/9
	 Logging train Loss: 7.291e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.578e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue 0.0
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue 0.0
wandb:                                 Train loss 0.0
wandb: 
wandb: ðŸš€ View run unique-pyramid-925 at: https://wandb.ai/nreints/ThesisFinal2/runs/p94nyrws
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_180325-p94nyrws/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_181454-lrfonslu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run gentle-dawn-954
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/lrfonslu
	 Logging test loss: 3.615e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.606e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 3.543e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 58.20506525039673
Epoch 2/9
	 Logging train Loss: 6.654e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.21e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.229e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.223e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.196e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 57.78292441368103
Epoch 3/9
	 Logging train Loss: 3.211e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.155e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.175e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.171e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.137e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 57.900519609451294
Epoch 4/9
	 Logging train Loss: 7.277e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.09e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.3e-08 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 5.26e-08 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 4.91e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 57.67451071739197
Epoch 5/9
	 Logging train Loss: 4.578e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.4e-08 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.29e-08 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.67e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 57.22601079940796
Epoch 6/9
	 Logging train Loss: 4.349e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5e-09 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.8e-09 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 5.7e-09 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 4.3e-09 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 57.23046660423279
Epoch 7/9
	 Logging train Loss: 3.342e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.003e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.129e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.108e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 8.92e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 57.80426907539368
Epoch 8/9
	 Logging train Loss: 3.44e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.47e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.89e-08 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 6.43e-08 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 5.7e-09 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 58.59422540664673
Epoch 9/9
	 Logging train Loss: 2.627e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3e-09 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.5e-09 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.4e-09 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.6e-09 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 58.53280973434448
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'rot_mat_1'_'False'.pth
It took  689.012035369873  seconds.
----- ITERATION 8/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 50.18979072570801 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 12.539617776870728 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pNone_gTrue took 12.78263807296753 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pNone_gTrue took 12.756150484085083 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pNone_gTrue took 12.792531728744507 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 2.85982e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.1683e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.1956e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.1916e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.1462e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 58.53811573982239
Epoch 1/9
	 Logging train Loss: 4.794e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.918e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.955e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.949e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.891e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 58.91550040245056
Epoch 2/9
	 Logging train Loss: 5.737e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.852e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.878e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.875e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.833e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 58.56423568725586
Epoch 3/9
	 Logging train Loss: 5.841e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.443e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.587e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 5.062e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.744e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 58.75303506851196
Epoch 4/9
	 Logging train Loss: 5.224e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.83e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.9e-08 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 4.89e-08 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 4.77e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 59.6332266330719
Epoch 5/9
	 Logging train Loss: 4.463e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.219e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.475e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.446e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 3.028e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 60.12401866912842
Epoch 6/9
	 Logging train Loss: 3.43e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.7e-09 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.9e-09 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 6.9e-09 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 6.5e-09 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 59.47511029243469
Epoch 7/9
	 Logging train Loss: 3.396e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.395e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.472e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.457e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 3.336e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 59.66385793685913
Epoch 8/9
	 Logging train Loss: 2.704e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.828e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.653e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue â–ˆâ–ƒâ–‚â–ƒâ–â–ƒâ–â–ƒâ–ƒâ–
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue â–ˆâ–ƒâ–‚â–‚â–â–ƒâ–â–ƒâ–ƒâ–
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue â–ˆâ–ƒâ–‚â–„â–â–ƒâ–â–ƒâ–„â–
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue â–ˆâ–ƒâ–‚â–„â–â–ƒâ–â–ƒâ–„â–
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue 0.0
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue 0.0
wandb:                                 Train loss 0.0
wandb: 
wandb: ðŸš€ View run gentle-dawn-954 at: https://wandb.ai/nreints/ThesisFinal2/runs/lrfonslu
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_181454-lrfonslu/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_182638-2ekxal6l
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stoic-bee-985
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/2ekxal6l
wandb: Waiting for W&B process to finish... (success).
wandb: ERROR Error while calling W&B API: An internal error occurred. Please contact support. (<Response [500]>)
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue â–‚â–â–â–â–â–â–â–â–â–ˆ
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue â–‚â–‚â–â–â–â–â–â–â–â–ˆ
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue â–‚â–â–â–â–â–â–â–â–â–ˆ
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue â–‚â–â–â–â–â–â–â–â–â–ˆ
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue 1e-05
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue 1e-05
wandb:                                 Train loss 0.0
wandb: 
wandb: ðŸš€ View run stoic-bee-985 at: https://wandb.ai/nreints/ThesisFinal2/runs/2ekxal6l
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_182638-2ekxal6l/logs
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230709_183801-iol4nf8l
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run trim-bird-1016
wandb: â­ï¸ View project at https://wandb.ai/nreints/ThesisFinal2
wandb: ðŸš€ View run at https://wandb.ai/nreints/ThesisFinal2/runs/iol4nf8l
	 Logging test loss: 4.55e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 3.213e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 59.117918252944946
Epoch 9/9
	 Logging train Loss: 2.06e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.45e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.46e-08 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.34e-08 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.67e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 59.03578758239746
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'rot_mat_1'_'False'.pth
It took  703.968243598938  seconds.
----- ITERATION 9/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 50.29739236831665 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 12.596949815750122 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pNone_gTrue took 12.811030626296997 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pNone_gTrue took 12.764661073684692 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pNone_gTrue took 12.794962406158447 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 4.88247e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.742e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.477e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 6.543e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 4.822e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 57.08942222595215
Epoch 1/9
	 Logging train Loss: 4.484e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.665e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.751e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.756e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.564e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 57.391939640045166
Epoch 2/9
	 Logging train Loss: 5.146e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.538e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.597e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.599e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.469e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 56.866496324539185
Epoch 3/9
	 Logging train Loss: 5.468e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.33e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.53e-08 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 7.54e-08 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 7.08e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 56.95782423019409
Epoch 4/9
	 Logging train Loss: 5.193e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.093e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.182e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.22e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 8.29e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 56.94417858123779
Epoch 5/9
	 Logging train Loss: 4.704e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.58e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.91e-08 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.93e-08 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.19e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 56.86518573760986
Epoch 6/9
	 Logging train Loss: 5.402e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.649e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.799e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.816e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.46e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 56.49481272697449
Epoch 7/9
	 Logging train Loss: 3.943e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 8.03e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.222e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.279e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.64e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 57.11562919616699
Epoch 8/9
	 Logging train Loss: 4.01e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.04e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 3.26e-08 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.35e-08 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 4.1e-09 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 57.34193706512451
Epoch 9/9
	 Logging train Loss: 2.929e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.7193e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.7618e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 5.8996e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 3.3896e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 57.203481674194336
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'rot_mat_1'_'False'.pth
It took  683.0865111351013  seconds.
----- ITERATION 10/10 ------
Number of train simulations:  1920
Number of test simulations:  480
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 49.47953939437866 seconds.
-- Finished Train Dataloader --
The dataloader for data/data_t(0,0)_r(0,0)_combi_pNone_gTrue took 12.482074499130249 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_tennis_pNone_gTrue took 12.781733751296997 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_semi_pNone_gTrue took 12.795608043670654 seconds.
The dataloader for data/data_t(0,0)_r(0,0)_full_pNone_gTrue took 12.797249794006348 seconds.
-- Finished Test Dataloader(s) --
GRU(
  (rnn): GRU(12, 96, batch_first=True)
  (fc): Linear(in_features=96, out_features=12, bias=True)
)
Datatype: rot_mat_1
-- Started Training --
Epoch 0/9
	 Logging train Loss: 3.99431e-05 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.1009e-06 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.4286e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.3767e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.8246e-06 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 58.422255754470825
Epoch 1/9
	 Logging train Loss: 9.531e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 7.187e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.0933e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.0257e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 4.075e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 58.26218056678772
Epoch 2/9
	 Logging train Loss: 6.385e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.495e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.515e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.511e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 2.478e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 58.15880727767944
Epoch 3/9
	 Logging train Loss: 7.66e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 9.364e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                      Epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue â–ˆâ–ƒâ–‚â–„â–â–â–â–â–â–‚
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue â–ˆâ–‚â–‚â–ƒâ–â–â–â–â–â–
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue â–ˆâ–„â–‚â–…â–â–â–â–â–â–‚
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue â–ˆâ–„â–‚â–…â–â–â–â–â–â–‚
wandb:                                 Train loss â–ˆâ–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                                      Epoch 9
wandb:  Test loss t(0,0)_r(0,0)_combi_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_full_pNone_gTrue 0.0
wandb:   Test loss t(0,0)_r(0,0)_semi_pNone_gTrue 0.0
wandb: Test loss t(0,0)_r(0,0)_tennis_pNone_gTrue 0.0
wandb:                                 Train loss 0.0
wandb: 
wandb: ðŸš€ View run trim-bird-1016 at: https://wandb.ai/nreints/ThesisFinal2/runs/iol4nf8l
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230709_183801-iol4nf8l/logs
	 Logging test loss: 1.3201e-06 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 1.2624e-06 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 6.137e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 58.008347034454346
Epoch 4/9
	 Logging train Loss: 5.039e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 9.27e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 9.38e-08 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 9.35e-08 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 9.17e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 57.947657346725464
Epoch 5/9
	 Logging train Loss: 7.283e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 5.27e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.41e-08 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 6.14e-08 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 4.32e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 58.31891202926636
Epoch 6/9
	 Logging train Loss: 2.385e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.13e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.88e-08 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 6.73e-08 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 5.51e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 58.12666630744934
Epoch 7/9
	 Logging train Loss: 2.752e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 1.437e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.272e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 2.098e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 7.51e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 58.08984184265137
Epoch 8/9
	 Logging train Loss: 2.752e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.93e-08 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 6.96e-08 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 6.96e-08 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 6.9e-08 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 58.33519983291626
Epoch 9/9
	 Logging train Loss: 2.419e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 2.631e-07 [MSELoss(): t(0,0)_r(0,0)_combi_pNone_gTrue]
	 Logging test loss: 4.062e-07 [MSELoss(): t(0,0)_r(0,0)_tennis_pNone_gTrue]
	 Logging test loss: 3.735e-07 [MSELoss(): t(0,0)_r(0,0)_semi_pNone_gTrue]
	 Logging test loss: 1.431e-07 [MSELoss(): t(0,0)_r(0,0)_full_pNone_gTrue]
		--> Epoch time; 58.14083456993103
Saved model in  trained_models/gru/data_t(0,0)_r(0,0)_combi_pNone_gTrue/'rot_mat_1'_'False'.pth
It took  692.235757112503  seconds.

JOB STATISTICS
==============
Job ID: 3037753
Array Job ID: 3037727_46
Cluster: snellius
User/Group: nreints/nreints
State: COMPLETED (exit code 0)
Nodes: 1
Cores per node: 18
CPU Utilized: 02:03:30
CPU Efficiency: 5.97% of 1-10:30:00 core-walltime
Job Wall-clock time: 01:55:00
Memory Utilized: 8.48 GB
Memory Efficiency: 0.00% of 0.00 MB
