/gpfs/home2/nreints/MScThesis/code/lstm.py:270: DeprecationWarning: Sampling from a set deprecated
since Python 3.9 and will be removed in a subsequent version.
  train_sims = set(random.sample(sims_train, int(0.8 * n_sims_train)))
wandb: Currently logged in as: nreints. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.13.9 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.8
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230127_064929-l943mkm1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dancing-chrysanthemum-1570
wandb: â­ï¸ View project at https://wandb.ai/nreints/thesis
wandb: ğŸš€ View run at https://wandb.ai/nreints/thesis/runs/l943mkm1
/home/nreints/.conda/envs/thesis/lib/python3.10/site-packages/torch/nn/modules/rnn.py:67: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  warnings.warn("dropout option adds dropout after all but last "
BEFORE ['data_t(0,', '0)_r(-5,', '5)_none']
----- ITERATION 0/10 ------
[<torch.utils.data.dataloader.DataLoader object at 0x1478a4c6e8f0>, <torch.utils.data.dataloader.DataLoader object at 0x14789dd40520>, <torch.utils.data.dataloader.DataLoader object at 0x14789dd40790>, <torch.utils.data.dataloader.DataLoader object at 0x14789dd40640>]
LSTM(
  (lstm): LSTM(7, 96, batch_first=True, dropout=0.2)
  (layers): Sequential(
    (0): Linear(in_features=96, out_features=7, bias=True)
  )
)
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0305427648127079
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.6343937516212463
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.03319443762302399
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.601198673248291
0 1.7892351172 	 0.6011986862
epoch_time;  41.30030941963196
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.01044842042028904
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.2827241122722626
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.01106248889118433
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.2532126307487488
1 0.0219482563 	 0.2532126435
epoch_time;  43.222721338272095
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.00463562086224556
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.16259633004665375
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.005242611281573772
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.14211797714233398
2 0.0094184731 	 0.1421179757
epoch_time;  41.48450303077698
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0061818878166377544
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.11721929907798767
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.006984966341406107
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.10191621631383896
3 0.0062111725 	 0.1019162181
epoch_time;  40.123435497283936
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.002852065023034811
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.08634469658136368
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.003144944552332163
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.0735979974269867
4 0.0042224526 	 0.0735979973
epoch_time;  40.57722496986389
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.004465129226446152
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.06812494993209839
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.006271941587328911
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.06011533737182617
5 0.0036619195 	 0.0601153359
epoch_time;  41.03100347518921
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0010567371500656009
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.05099056288599968
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0015159088652580976
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.04391012340784073
6 0.0030271771 	 0.0439101216
epoch_time;  40.93348836898804
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.002004501409828663
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.041960764676332474
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.002295880112797022
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.03742442652583122
7 0.0025869288 	 0.0374244275
epoch_time;  41.41463565826416
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0027626650407910347
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.1254706233739853
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.003235904034227133
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.11505825072526932
8 0.0184385601 	 0.1150582535
epoch_time;  41.168696880340576
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0014796097530052066
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.08393964171409607
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0022622528485953808
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.07554910331964493
9 0.0024713746 	 0.0755490997
epoch_time;  40.32050442695618
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0012026812182739377
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.06045796722173691
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0016658043023198843
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.054043013602495193
10 0.0021963605 	 0.0540430121
epoch_time;  39.60932898521423
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0011616013944149017
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.049245256930589676
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.001480143517255783
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.04246412217617035
11 0.0020725424 	 0.0424641209
epoch_time;  39.53237271308899
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0008693686104379594
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.04352053254842758
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.00142068846616894
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.0376158282160759
12 0.0018749239 	 0.0376158279
epoch_time;  39.97374176979065
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0010818321024999022
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.039815884083509445
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0013911341084167361
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.03411421179771423
13 0.001751324 	 0.0341142124
epoch_time;  40.322431564331055
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0012273077154532075
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.045155733823776245
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0015261344378814101
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.038218602538108826
14 0.0023217023 	 0.038218602
epoch_time;  39.87926697731018
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0015046802582219243
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.03847204148769379
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.001746016088873148
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.031955111771821976
15 0.0014925678 	 0.0319551111
epoch_time;  39.918148040771484
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0014816568000242114
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.03782210499048233
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0020492132753133774
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.03116801008582115
16 0.0014345874 	 0.0311680099
epoch_time;  39.52694392204285
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.001293879235163331
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.034457188099622726
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0016531572910025716
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.027812868356704712
17 0.0014284041 	 0.0278128684
epoch_time;  39.44428873062134
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0007241611601784825
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.03632211312651634
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0010388176888227463
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.02884426899254322
18 0.0019207457 	 0.0288442687
epoch_time;  40.3201379776001
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0008085734443739057
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.03413832187652588
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0011138039408251643
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.027290165424346924
19 0.0013021697 	 0.0272901656
epoch_time;  39.576409578323364
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0008529101614840329
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.030676500871777534
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0012257116613909602
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.025761207565665245
20 0.001307898 	 0.0257612067
epoch_time;  40.056755781173706
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0018823281861841679
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.033714767545461655
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0019145285477861762
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.02546888403594494
21 0.0012718742 	 0.0254688839
epoch_time;  40.1170220375061
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0005564937018789351
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.047364216297864914
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0009286353015340865
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.03735221549868584
22 0.0021293032 	 0.0373522162
epoch_time;  40.69525766372681
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                              Epoch â–â–â–â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–…â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb: Test loss t(-10, 10)_r(-5, 5)_none â–ˆâ–„â–‚â–‚â–‚â–â–â–â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  Test loss t(-10, 10)_r(0, 0)_none â–ˆâ–„â–ƒâ–‚â–‚â–â–â–â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    Test loss t(0, 0)_r(-5, 5)_none â–ˆâ–ƒâ–‚â–‚â–‚â–‚â–â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:     Test loss t(0, 0)_r(0, 0)_none â–ˆâ–ƒâ–‚â–‚â–‚â–‚â–â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                         Train loss â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                              Epoch 29
wandb: Test loss t(-10, 10)_r(-5, 5)_none 0.02481
wandb:  Test loss t(-10, 10)_r(0, 0)_none 0.03211
wandb:    Test loss t(0, 0)_r(-5, 5)_none 0.00082
wandb:     Test loss t(0, 0)_r(0, 0)_none 0.00051
wandb:                         Train loss 0.00112
wandb: 
wandb: ğŸš€ View run dancing-chrysanthemum-1570 at: https://wandb.ai/nreints/thesis/runs/l943mkm1
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230127_064929-l943mkm1/logs
/gpfs/home2/nreints/MScThesis/code/lstm.py:270: DeprecationWarning: Sampling from a set deprecated
since Python 3.9 and will be removed in a subsequent version.
  train_sims = set(random.sample(sims_train, int(0.8 * n_sims_train)))
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.13.9 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.8
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230127_071103-qcdj561e
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run floating-firecracker-1577
wandb: â­ï¸ View project at https://wandb.ai/nreints/thesis
wandb: ğŸš€ View run at https://wandb.ai/nreints/thesis/runs/qcdj561e
/home/nreints/.conda/envs/thesis/lib/python3.10/site-packages/torch/nn/modules/rnn.py:67: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  warnings.warn("dropout option adds dropout after all but last "
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0009601583587937057
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.03604300692677498
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0011864667758345604
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.02899882383644581
23 0.0009783111 	 0.0289988244
epoch_time;  42.74017834663391
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.000542942900210619
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.03111002966761589
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0008474573260173202
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.025205494835972786
24 0.0011932082 	 0.0252054941
epoch_time;  42.01454973220825
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0014687069924548268
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.032739538699388504
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0019199864473193884
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.02656463533639908
25 0.0011862798 	 0.0265646355
epoch_time;  40.43863344192505
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0007088345591910183
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.03126688301563263
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0010142824612557888
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.025003492832183838
26 0.0011535234 	 0.0250034937
epoch_time;  40.18524503707886
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0007176712970249355
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.030020898208022118
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0010720246937125921
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.024110576137900352
27 0.001151366 	 0.0241105765
epoch_time;  40.287789821624756
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0005587178748100996
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.029092632234096527
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0008961724815890193
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.02373216301202774
28 0.0011451175 	 0.0237321623
epoch_time;  41.350279092788696
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0005124065210111439
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.032078031450510025
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0008212709799408913
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.024795731529593468
29 0.0011229998 	 0.024795731
epoch_time;  42.263880014419556
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0005125967436470091
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.03210543841123581
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0008214369299821556
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.024807117879390717
It took  1294.2107634544373  seconds.
----- ITERATION 1/10 ------
[<torch.utils.data.dataloader.DataLoader object at 0x1478a4c37fa0>, <torch.utils.data.dataloader.DataLoader object at 0x1478a66194b0>, <torch.utils.data.dataloader.DataLoader object at 0x14789dd41d80>, <torch.utils.data.dataloader.DataLoader object at 0x147860c82ad0>]
LSTM(
  (lstm): LSTM(7, 96, batch_first=True, dropout=0.2)
  (layers): Sequential(
    (0): Linear(in_features=96, out_features=7, bias=True)
  )
)
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.031082194298505783
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.48858287930488586
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.033018577843904495
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.5153756737709045
0 2.0639319467 	 0.5153756963
epoch_time;  40.54048490524292
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.010935695841908455
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.2082076221704483
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0120339160785079
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.21632857620716095
1 0.0218663862 	 0.2163285777
epoch_time;  42.75732660293579
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.005480101332068443
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.10785696655511856
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0061123869381845
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.11351644992828369
2 0.0094138109 	 0.1135164474
epoch_time;  39.6131432056427
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0032132891938090324
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.06656607985496521
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.004080653190612793
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.07286126166582108
3 0.0061352872 	 0.0728612652
epoch_time;  39.745997190475464
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.00157508987467736
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.04705480858683586
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.002346490044146776
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.05442607402801514
4 0.0044725022 	 0.0544260722
epoch_time;  39.401461124420166
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.002142893150448799
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.03700616955757141
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0026996168307960033
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.04528376832604408
5 0.0035800526 	 0.0452837699
epoch_time;  40.0993218421936
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0025555549655109644
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.03163764253258705
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.00294883013702929
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.03982425108551979
6 0.0030137236 	 0.0398242495
epoch_time;  39.80833649635315
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.008117735385894775
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.2103111296892166
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.011705996468663216
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.23812006413936615
7 0.0176512035 	 0.2381200646
epoch_time;  40.15953540802002
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0017053047195076942
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.06263658404350281
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.00232503074221313
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.07588363438844681
8 0.0041691728 	 0.0758836349
epoch_time;  39.911309003829956
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.003959018271416426
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.044319916516542435
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.004053309094160795
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.052929628640413284
9 0.0025068649 	 0.0529296276
epoch_time;  39.89573359489441
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0013745140749961138
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.03195175155997276
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0017857433995231986
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.03862043097615242
10 0.0022775208 	 0.0386204302
epoch_time;  40.320128440856934
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0009974101558327675
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.025603050366044044
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0012752274051308632
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.031018324196338654
11 0.0019670309 	 0.0310183234
epoch_time;  39.80720329284668
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0009355790680274367
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.022699706256389618
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.00122823438141495
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.027980415150523186
12 0.0018951021 	 0.0279804155
epoch_time;  39.57921051979065
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0006933873519301414
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.02213301695883274
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0010499764466658235
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.027824195101857185
13 0.0022429315 	 0.0278241944
epoch_time;  40.29099655151367
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0016319731948897243
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.022238606587052345
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.002068267436698079
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.028485262766480446
14 0.0015291522 	 0.0284852636
epoch_time;  42.38049006462097
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0007538509089499712
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                              Epoch â–â–â–â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–…â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb: Test loss t(-10, 10)_r(-5, 5)_none â–ˆâ–„â–‚â–‚â–â–â–â–„â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  Test loss t(-10, 10)_r(0, 0)_none â–ˆâ–„â–‚â–‚â–â–â–â–„â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    Test loss t(0, 0)_r(-5, 5)_none â–ˆâ–ƒâ–‚â–‚â–â–â–â–ƒâ–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–‚â–â–â–â–â–â–â–
wandb:     Test loss t(0, 0)_r(0, 0)_none â–ˆâ–ƒâ–‚â–‚â–â–â–â–ƒâ–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–‚â–â–â–â–â–â–â–
wandb:                         Train loss â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                              Epoch 29
wandb: Test loss t(-10, 10)_r(-5, 5)_none 0.02212
wandb:  Test loss t(-10, 10)_r(0, 0)_none 0.01709
wandb:    Test loss t(0, 0)_r(-5, 5)_none 0.00089
wandb:     Test loss t(0, 0)_r(0, 0)_none 0.00058
wandb:                         Train loss 0.00111
wandb: 
wandb: ğŸš€ View run floating-firecracker-1577 at: https://wandb.ai/nreints/thesis/runs/qcdj561e
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230127_071103-qcdj561e/logs
/gpfs/home2/nreints/MScThesis/code/lstm.py:270: DeprecationWarning: Sampling from a set deprecated
since Python 3.9 and will be removed in a subsequent version.
  train_sims = set(random.sample(sims_train, int(0.8 * n_sims_train)))
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.13.9 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.8
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230127_073224-ga1wsdh8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glittering-peony-1584
wandb: â­ï¸ View project at https://wandb.ai/nreints/thesis
wandb: ğŸš€ View run at https://wandb.ai/nreints/thesis/runs/ga1wsdh8
/home/nreints/.conda/envs/thesis/lib/python3.10/site-packages/torch/nn/modules/rnn.py:67: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  warnings.warn("dropout option adds dropout after all but last "
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.020492995157837868
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.001110135461203754
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.026351159438490868
15 0.0015209089 	 0.0263511594
epoch_time;  40.64152956008911
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0018094079568982124
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.020849067717790604
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0019599779043346643
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.026254506781697273
16 0.0014560262 	 0.026254507
epoch_time;  40.968579053878784
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.000647440436296165
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.019091902300715446
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0009437480475753546
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.023907817900180817
17 0.0014703901 	 0.0239078185
epoch_time;  40.55134701728821
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0014465524582192302
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.019807402044534683
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0018177789170295
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.02413664385676384
18 0.0013618242 	 0.0241366441
epoch_time;  40.66155433654785
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0007588356384076178
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.04797355458140373
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0011952040949836373
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.05645463988184929
19 0.0040128496 	 0.0564546383
epoch_time;  41.61638569831848
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.000607042689807713
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.029230235144495964
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0010050266282632947
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.035513781011104584
20 0.0010777119 	 0.0355137799
epoch_time;  40.16732597351074
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0010706462198868394
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.02508878894150257
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0014027339639142156
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.03184572234749794
21 0.0012468512 	 0.0318457238
epoch_time;  41.1058144569397
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.000720934709534049
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.02234184928238392
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0010304482420906425
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.02915428765118122
22 0.0012549785 	 0.0291542877
epoch_time;  40.45035934448242
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0034579599741846323
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.025328582152724266
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.003824751591309905
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.031217442825436592
23 0.0012640202 	 0.0312174425
epoch_time;  40.55012226104736
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0009809504263103008
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0199500173330307
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0013052135473117232
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.02501881867647171
24 0.0011732039 	 0.0250188188
epoch_time;  40.15644192695618
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0008038001251406968
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.018815942108631134
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0010655818041414022
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.023954737931489944
25 0.001205926 	 0.0239547387
epoch_time;  40.57300782203674
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0007190381293185055
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.018256355077028275
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0010145502164959908
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.023039286956191063
26 0.0011606177 	 0.0230392877
epoch_time;  39.84429216384888
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0007565839914605021
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.017535874620079994
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0009981743060052395
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.022258371114730835
27 0.0011581752 	 0.022258371
epoch_time;  39.27744007110596
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0005742529174312949
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.017987370491027832
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0009400388807989657
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.0227891243994236
28 0.0011417888 	 0.0227891239
epoch_time;  40.00068259239197
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0005784512613900006
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.01707693375647068
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0008924513240344822
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.022109344601631165
29 0.0011083775 	 0.0221093443
epoch_time;  39.83127689361572
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0005784083623439074
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.017092755064368248
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0008918190142139792
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.02211812697350979
It took  1280.922653913498  seconds.
----- ITERATION 2/10 ------
[<torch.utils.data.dataloader.DataLoader object at 0x14789dd41e40>, <torch.utils.data.dataloader.DataLoader object at 0x147860c83010>, <torch.utils.data.dataloader.DataLoader object at 0x147860c802b0>, <torch.utils.data.dataloader.DataLoader object at 0x147860c82680>]
LSTM(
  (lstm): LSTM(7, 96, batch_first=True, dropout=0.2)
  (layers): Sequential(
    (0): Linear(in_features=96, out_features=7, bias=True)
  )
)
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.030410977080464363
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.47987887263298035
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.03720634803175926
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.4866379201412201
0 1.8860687556 	 0.4866379107
epoch_time;  40.24363327026367
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.013054339215159416
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.20077911019325256
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.015196863561868668
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.18914110958576202
1 0.0226883495 	 0.189141115
epoch_time;  39.642364501953125
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.004549975972622633
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.1106080710887909
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.005514506250619888
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.09811940789222717
2 0.0099381346 	 0.0981194073
epoch_time;  39.64810633659363
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.007320203818380833
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.08118857443332672
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0077286409214138985
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.07036448270082474
3 0.0061148709 	 0.0703644825
epoch_time;  39.30614256858826
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.002411412773653865
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.05388092249631882
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0030457796528935432
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.046380240470170975
4 0.0045633619 	 0.046380239
epoch_time;  42.416871070861816
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0018067894270643592
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.04244200140237808
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0023486490827053785
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.038004279136657715
5 0.0035172036 	 0.0380042788
epoch_time;  42.64801907539368
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.002535021398216486
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.03521120920777321
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0031138493213802576
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.0316896066069603
6 0.0029987367 	 0.0316896064
epoch_time;  40.252854108810425
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0020072495099157095
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.09453238546848297
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                              Epoch â–â–â–â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–…â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb: Test loss t(-10, 10)_r(-5, 5)_none â–ˆâ–„â–‚â–‚â–â–â–â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  Test loss t(-10, 10)_r(0, 0)_none â–ˆâ–„â–‚â–‚â–‚â–â–â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    Test loss t(0, 0)_r(-5, 5)_none â–ˆâ–„â–‚â–‚â–â–â–â–â–â–â–â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:     Test loss t(0, 0)_r(0, 0)_none â–ˆâ–„â–‚â–ƒâ–â–â–â–â–â–â–â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                         Train loss â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                              Epoch 29
wandb: Test loss t(-10, 10)_r(-5, 5)_none 0.01361
wandb:  Test loss t(-10, 10)_r(0, 0)_none 0.01635
wandb:    Test loss t(0, 0)_r(-5, 5)_none 0.00155
wandb:     Test loss t(0, 0)_r(0, 0)_none 0.00142
wandb:                         Train loss 0.0011
wandb: 
wandb: ğŸš€ View run glittering-peony-1584 at: https://wandb.ai/nreints/thesis/runs/ga1wsdh8
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230127_073224-ga1wsdh8/logs
/gpfs/home2/nreints/MScThesis/code/lstm.py:270: DeprecationWarning: Sampling from a set deprecated
since Python 3.9 and will be removed in a subsequent version.
  train_sims = set(random.sample(sims_train, int(0.8 * n_sims_train)))
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.13.9 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.8
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230127_075354-wpa3rivz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run twinkling-lantern-1591
wandb: â­ï¸ View project at https://wandb.ai/nreints/thesis
wandb: ğŸš€ View run at https://wandb.ai/nreints/thesis/runs/wpa3rivz
/home/nreints/.conda/envs/thesis/lib/python3.10/site-packages/torch/nn/modules/rnn.py:67: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  warnings.warn("dropout option adds dropout after all but last "
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.002908047754317522
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.08791202306747437
7 0.0147681687 	 0.0879120207
epoch_time;  40.343324422836304
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0024774421472102404
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0593353696167469
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0022779812570661306
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.05324764922261238
8 0.0024407533 	 0.0532476477
epoch_time;  40.982890129089355
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0013338400749489665
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.04203478991985321
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.001993816811591387
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.039456769824028015
9 0.0022616959 	 0.0394567709
epoch_time;  40.7011342048645
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0013788642827421427
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.033467069268226624
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0019983237143605947
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.030396398156881332
10 0.0020968775 	 0.0303963981
epoch_time;  41.56357145309448
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0007216569501906633
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.025386666879057884
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0011517292587086558
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.022762028500437737
11 0.0017505382 	 0.0227620292
epoch_time;  40.560707330703735
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0053671603091061115
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.028261994943022728
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0037502353079617023
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.023150740191340446
12 0.0017754106 	 0.0231507394
epoch_time;  41.56214213371277
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0008516779635101557
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0379633866250515
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0013896678574383259
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.03513498976826668
13 0.0081712707 	 0.0351349897
epoch_time;  40.81494998931885
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.00119008996989578
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.025807397440075874
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0016835167771205306
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.02381654642522335
14 0.0013836114 	 0.0238165466
epoch_time;  40.51372671127319
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0019080695929005742
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.02276736870408058
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0020921886898577213
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.020595479756593704
15 0.0014906747 	 0.0205954799
epoch_time;  40.758206367492676
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0008886682335287333
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.018949022516608238
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0011698894668370485
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.016909733414649963
16 0.0014035637 	 0.0169097333
epoch_time;  40.439860343933105
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0009084287448786199
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.01790744811296463
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0013361090095713735
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.016315368935465813
17 0.001392118 	 0.0163153694
epoch_time;  40.37321996688843
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0009022674639709294
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.016201041638851166
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0013302379520609975
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.014819703996181488
18 0.0013265955 	 0.0148197042
epoch_time;  40.53014087677002
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0007890202687121928
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.02700451761484146
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0012446725741028786
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.024405241012573242
19 0.0034429563 	 0.0244052403
epoch_time;  40.433825969696045
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0010854975553229451
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.02366919443011284
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.001237934804521501
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.022636232897639275
20 0.0011036941 	 0.0226362321
epoch_time;  40.020039081573486
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0007872162968851626
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.020518802106380463
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0011591485235840082
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.019504012539982796
21 0.0012151575 	 0.0195040127
epoch_time;  39.441664934158325
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0012568046804517508
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.019400913268327713
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.001849466236308217
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.018631866201758385
22 0.0012251855 	 0.018631866
epoch_time;  39.83000206947327
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0005939820548519492
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.017234068363904953
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0009502657921984792
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.016230134293437004
23 0.0012207929 	 0.0162301337
epoch_time;  39.70037794113159
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0008319056360051036
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.017033588141202927
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0011218475410714746
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.015432012267410755
24 0.0011815007 	 0.015432012
epoch_time;  40.59314775466919
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0006078442675061524
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.015729816630482674
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0009510169620625675
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.014249266125261784
25 0.001153312 	 0.0142492657
epoch_time;  40.36257553100586
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0008559328853152692
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.016268016770482063
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0011355398455634713
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.014210429042577744
26 0.001182004 	 0.0142104287
epoch_time;  40.91386365890503
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0007232968928292394
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.015629131346940994
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0010469021508470178
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.013645198196172714
27 0.0010960505 	 0.013645198
epoch_time;  44.107903480529785
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0011510319309309125
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.016876019537448883
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0021413902286440134
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.01480494998395443
28 0.0011196815 	 0.0148049496
epoch_time;  40.589877128601074
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0014241726603358984
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.016352351754903793
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0015491292579099536
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.013575981371104717
29 0.0010960371 	 0.0135759818
epoch_time;  40.39982724189758
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0014239794109016657
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.016347462311387062
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0015489020152017474
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.013612981885671616
It took  1290.1986842155457  seconds.
----- ITERATION 3/10 ------
[<torch.utils.data.dataloader.DataLoader object at 0x147860c82aa0>, <torch.utils.data.dataloader.DataLoader object at 0x147860c59390>, <torch.utils.data.dataloader.DataLoader object at 0x147860c5ad70>, <torch.utils.data.dataloader.DataLoader object at 0x147860d131c0>]
LSTM(
  (lstm): LSTM(7, 96, batch_first=True, dropout=0.2)
  (layers): Sequential(
    (0): Linear(in_features=96, out_features=7, bias=True)
  )
)
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.036766719073057175
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.5436521172523499
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.038450006395578384
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.6218434572219849
0 1.8530132978 	 0.621843459
epoch_time;  40.512046098709106
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.010916228406131268
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.22755272686481476
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.011574806645512581
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.24336574971675873
1 0.020348024 	 0.2433657459
epoch_time;  40.75294899940491
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0058530112728476524
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.1379566490650177
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.005973175633698702
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.143638476729393
2 0.0087681271 	 0.1436384841
epoch_time;  41.03262519836426
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0022585687693208456
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0952707976102829
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.003240125020965934
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.09869588911533356
3 0.0054183927 	 0.0986958875
epoch_time;  40.3110990524292
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.003418689826503396
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.07456259429454803
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0036459306720644236
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.07575249671936035
4 0.004125185 	 0.0757524946
epoch_time;  40.172935247421265
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.00223814370110631
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.06139577180147171
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.003153975587338209
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.061897844076156616
5 0.0033284078 	 0.0618978425
epoch_time;  40.023683309555054
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.001222189050167799
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.049392566084861755
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.001890479470603168
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.048048585653305054
6 0.0028509294 	 0.048048587
epoch_time;  40.78251123428345
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0020738139282912016
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.1700090765953064
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0028517607133835554
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.19070932269096375
7 0.0192148424 	 0.1907093244
epoch_time;  40.435126066207886
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.001480143633671105
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.10574904084205627
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0022383956238627434
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.11881045997142792
8 0.0024348262 	 0.1188104635
epoch_time;  39.87090563774109
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.002980536315590143
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.07834336906671524
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.003318639937788248
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.08720275014638901
9 0.0022164313 	 0.0872027521
epoch_time;  40.15155506134033
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0026834760792553425
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.06299188733100891
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0037255084607750177
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.06881648302078247
10 0.0020871774 	 0.0688164818
epoch_time;  40.30641174316406
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0034003527835011482
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.05249854922294617
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0033983266912400723
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.05794917047023773
11 0.0019624526 	 0.0579491699
epoch_time;  40.21669793128967
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0023988797329366207
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0440189391374588
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.002708679996430874
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.04985145106911659
12 0.0017084673 	 0.0498514492
epoch_time;  40.463210105895996
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0007637047674506903
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.039008717983961105
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0010998130310326815
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.044148582965135574
13 0.0016939467 	 0.0441485834
epoch_time;  40.77188801765442
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0011945953592658043
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.03622547909617424
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0013274421216920018
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.040430210530757904
14 0.0015644385 	 0.0404302101
epoch_time;  40.44646596908569
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0015320212114602327
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.03465856611728668
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0018733983160927892
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.038574058562517166
15 0.0015064044 	 0.0385740603
epoch_time;  40.05791401863098
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0018455978715792298
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.10027223080396652
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0026692042592912912
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.1341293305158615
16 0.0172195001 	 0.1341293312
epoch_time;  40.695664167404175
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0010681857820600271
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.059916552156209946
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0017495796782895923
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.08211880177259445
17 0.0020816073 	 0.0821188036
epoch_time;  43.298712730407715
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.00108053139410913
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.04789150133728981
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.001561789307743311
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.06426291912794113
18 0.0016781517 	 0.0642629203
epoch_time;  42.284461975097656
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0008129765628837049
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.03727244585752487
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0011635913979262114
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.05058111250400543
19 0.001512677 	 0.0505811109
epoch_time;  40.514700412750244
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0009906803024932742
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.031551748514175415
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0014723023632541299
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.042676616460084915
20 0.0014030644 	 0.0426766174
epoch_time;  40.23321580886841
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.000677725241985172
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.02937934547662735
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0010433440329506993
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.03878575190901756
21 0.0013694654 	 0.0387857501
epoch_time;  39.83202075958252
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0008006442803889513
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.029759034514427185
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.001379274413920939
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.038024187088012695
22 0.0013098531 	 0.0380241878
epoch_time;  40.48106074333191
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0006206416874192655
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.02512577921152115
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0009405959863215685
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.03451402485370636
23 0.0012596875 	 0.0345140238
epoch_time;  41.87583613395691
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                              Epoch â–â–â–â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–…â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb: Test loss t(-10, 10)_r(-5, 5)_none â–ˆâ–„â–‚â–‚â–‚â–â–â–ƒâ–‚â–‚â–â–â–â–â–â–â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  Test loss t(-10, 10)_r(0, 0)_none â–ˆâ–„â–ƒâ–‚â–‚â–‚â–â–ƒâ–‚â–‚â–‚â–â–â–â–â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    Test loss t(0, 0)_r(-5, 5)_none â–ˆâ–ƒâ–‚â–â–‚â–â–â–â–â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:     Test loss t(0, 0)_r(0, 0)_none â–ˆâ–ƒâ–‚â–â–‚â–â–â–â–â–â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                         Train loss â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                              Epoch 29
wandb: Test loss t(-10, 10)_r(-5, 5)_none 0.0307
wandb:  Test loss t(-10, 10)_r(0, 0)_none 0.02279
wandb:    Test loss t(0, 0)_r(-5, 5)_none 0.00094
wandb:     Test loss t(0, 0)_r(0, 0)_none 0.00061
wandb:                         Train loss 0.00113
wandb: 
wandb: ğŸš€ View run twinkling-lantern-1591 at: https://wandb.ai/nreints/thesis/runs/wpa3rivz
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230127_075354-wpa3rivz/logs
/gpfs/home2/nreints/MScThesis/code/lstm.py:270: DeprecationWarning: Sampling from a set deprecated
since Python 3.9 and will be removed in a subsequent version.
  train_sims = set(random.sample(sims_train, int(0.8 * n_sims_train)))
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.13.9 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.8
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230127_081517-rzwfscro
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sparkling-ox-1600
wandb: â­ï¸ View project at https://wandb.ai/nreints/thesis
wandb: ğŸš€ View run at https://wandb.ai/nreints/thesis/runs/rzwfscro
/home/nreints/.conda/envs/thesis/lib/python3.10/site-packages/torch/nn/modules/rnn.py:67: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  warnings.warn("dropout option adds dropout after all but last "
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0012073784600943327
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.025696396827697754
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0014307142700999975
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.03460231423377991
24 0.0012419768 	 0.034602315
epoch_time;  40.79489517211914
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0007401862530969083
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.023194540292024612
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.001227765460498631
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.0323205441236496
25 0.0012213363 	 0.0323205441
epoch_time;  40.265302896499634
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0005157795967534184
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.03281571716070175
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0008884172420948744
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.04479190707206726
26 0.0018414931 	 0.0447919073
epoch_time;  39.963425636291504
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0007078172639012337
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.02478642389178276
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.001034403219819069
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.03354787081480026
27 0.0009678213 	 0.0335478711
epoch_time;  39.41850972175598
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0006478307768702507
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.023809995502233505
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0011020348174497485
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.031304966658353806
28 0.00112786 	 0.0313049674
epoch_time;  39.800164461135864
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0006143195205368102
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.02289009466767311
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0009376813541166484
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.030698955059051514
29 0.0011338806 	 0.0306989549
epoch_time;  40.38372302055359
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0006139908800832927
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.022787772119045258
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0009379831608384848
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.03070402331650257
It took  1283.022493839264  seconds.
----- ITERATION 4/10 ------
[<torch.utils.data.dataloader.DataLoader object at 0x14789e723fa0>, <torch.utils.data.dataloader.DataLoader object at 0x147860c5aec0>, <torch.utils.data.dataloader.DataLoader object at 0x147860c5add0>, <torch.utils.data.dataloader.DataLoader object at 0x147860d13e50>]
LSTM(
  (lstm): LSTM(7, 96, batch_first=True, dropout=0.2)
  (layers): Sequential(
    (0): Linear(in_features=96, out_features=7, bias=True)
  )
)
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.032030243426561356
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.4087528884410858
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.032041147351264954
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.42101216316223145
0 1.6835371966 	 0.4210121639
epoch_time;  39.870081424713135
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.011271144263446331
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.17422029376029968
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.012096528895199299
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.17443253099918365
1 0.0215412388 	 0.1744325298
epoch_time;  39.974751234054565
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.005279055330902338
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.09184920787811279
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.00601607421413064
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.09163110703229904
2 0.0098718611 	 0.0916311085
epoch_time;  40.48899579048157
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.003719204105436802
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0614946074783802
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.004060712642967701
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.0617891363799572
3 0.0059378517 	 0.0617891352
epoch_time;  40.026158809661865
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0022837426513433456
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0443376861512661
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.003506536828354001
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.04559016600251198
4 0.0045186031 	 0.0455901644
epoch_time;  40.16616082191467
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0017553666839376092
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.03336228057742119
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0020580890122801065
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.03421834856271744
5 0.0037093487 	 0.0342183473
epoch_time;  39.64859390258789
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.005858097691088915
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.03421127423644066
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.005506773479282856
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.03456473723053932
6 0.0029066111 	 0.0345647385
epoch_time;  39.25807428359985
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.00799579732120037
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.2213839441537857
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.011081337928771973
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.24133747816085815
7 0.0253776533 	 0.2413374794
epoch_time;  39.5669424533844
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.002179306000471115
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.06704900413751602
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.002712654648348689
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.07267918437719345
8 0.0046368815 	 0.0726791854
epoch_time;  41.48711323738098
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0021175206638872623
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.045769017189741135
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.002418752294033766
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.048507776111364365
9 0.0025633973 	 0.0485077769
epoch_time;  41.24072813987732
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.000986466882750392
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.034440480172634125
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0013867050874978304
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.03602239489555359
10 0.0023696682 	 0.0360223937
epoch_time;  39.551244020462036
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0013069463893771172
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.028010092675685883
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0015835488447919488
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.02833574451506138
11 0.0020985594 	 0.0283357442
epoch_time;  40.24419045448303
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0011743346694856882
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.023960823193192482
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0014868252910673618
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.02311326563358307
12 0.0019105901 	 0.0231132651
epoch_time;  40.49284839630127
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0011203910689800978
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.02130446769297123
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.001408617477864027
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.020150402560830116
13 0.0017386282 	 0.0201504022
epoch_time;  40.741434812545776
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.000690204615239054
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.019108688458800316
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.001076576765626669
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.017942417412996292
14 0.0017776401 	 0.0179424171
epoch_time;  41.29800629615784
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0010903268121182919
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.018099335953593254
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0014095791848376393
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.016503747552633286
15 0.0015881238 	 0.0165037475
epoch_time;  41.44170808792114
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0014950106851756573
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                              Epoch â–â–â–â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–…â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb: Test loss t(-10, 10)_r(-5, 5)_none â–ˆâ–„â–‚â–‚â–‚â–â–â–…â–‚â–‚â–â–â–â–â–â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  Test loss t(-10, 10)_r(0, 0)_none â–ˆâ–„â–‚â–‚â–‚â–â–â–…â–‚â–‚â–â–â–â–â–â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    Test loss t(0, 0)_r(-5, 5)_none â–ˆâ–„â–‚â–‚â–‚â–â–‚â–ƒâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:     Test loss t(0, 0)_r(0, 0)_none â–ˆâ–ƒâ–‚â–‚â–â–â–‚â–ƒâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                         Train loss â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                              Epoch 29
wandb: Test loss t(-10, 10)_r(-5, 5)_none 0.01301
wandb:  Test loss t(-10, 10)_r(0, 0)_none 0.0141
wandb:    Test loss t(0, 0)_r(-5, 5)_none 0.00141
wandb:     Test loss t(0, 0)_r(0, 0)_none 0.00121
wandb:                         Train loss 0.00116
wandb: 
wandb: ğŸš€ View run sparkling-ox-1600 at: https://wandb.ai/nreints/thesis/runs/rzwfscro
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230127_081517-rzwfscro/logs
/gpfs/home2/nreints/MScThesis/code/lstm.py:270: DeprecationWarning: Sampling from a set deprecated
since Python 3.9 and will be removed in a subsequent version.
  train_sims = set(random.sample(sims_train, int(0.8 * n_sims_train)))
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: wandb version 0.13.9 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.8
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230127_083627-h7luk2uw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run golden-rooster-1607
wandb: â­ï¸ View project at https://wandb.ai/nreints/thesis
wandb: ğŸš€ View run at https://wandb.ai/nreints/thesis/runs/h7luk2uw
/home/nreints/.conda/envs/thesis/lib/python3.10/site-packages/torch/nn/modules/rnn.py:67: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  warnings.warn("dropout option adds dropout after all but last "
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.06485248357057571
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0021663932129740715
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.0620461069047451
16 0.0107140032 	 0.0620461086
epoch_time;  40.53986144065857
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0007912539876997471
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.03106709010899067
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0011683159973472357
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.02944202907383442
17 0.0015818694 	 0.0294420294
epoch_time;  39.57865357398987
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0011750031262636185
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.023452529683709145
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0014640992740169168
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.02169957384467125
18 0.0014131029 	 0.0216995741
epoch_time;  40.01012849807739
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0007213132921606302
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.018257837742567062
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0010318572167307138
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.016935022547841072
19 0.0014185012 	 0.0169350229
epoch_time;  40.115519285202026
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0006444560131058097
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.01599161885678768
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0009498954750597477
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.014957137405872345
20 0.0013790547 	 0.014957137
epoch_time;  39.06214189529419
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0007715248502790928
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.01468734908849001
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0010550727602094412
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.013644542545080185
21 0.0013415503 	 0.0136445426
epoch_time;  39.436302185058594
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0009071306558325887
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.01396112609654665
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.001092883525416255
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.012673304416239262
22 0.0013095992 	 0.0126733045
epoch_time;  40.309751749038696
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0005349775892682374
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.012682843022048473
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0008593061356805265
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.012004191987216473
23 0.0012961803 	 0.0120041918
epoch_time;  39.99612092971802
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0024481001310050488
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.015073161572217941
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0024243921507149935
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.01383969560265541
24 0.0012437019 	 0.0138396957
epoch_time;  39.6879301071167
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0008117537945508957
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.01239044964313507
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.001149666146375239
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.011817941442131996
25 0.0012242149 	 0.0118179415
epoch_time;  40.11980605125427
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0006669387803412974
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.020311500877141953
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0010338793508708477
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.019133351743221283
26 0.0035270695 	 0.0191333517
epoch_time;  39.93387246131897
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0005479131359606981
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.013596315868198872
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0008526646997779608
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.013492705300450325
27 0.0010423731 	 0.0134927052
epoch_time;  40.154618978500366
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0006155663286335766
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.012586836703121662
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0009452260565012693
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.012019909918308258
28 0.0011333215 	 0.0120199101
epoch_time;  39.99956655502319
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0012135811848565936
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.01412283442914486
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0014113542856648564
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.01297203078866005
29 0.001160476 	 0.0129720308
epoch_time;  39.807894468307495
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0012126161018386483
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.014101041480898857
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0014112495118752122
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.01301408652216196
It took  1270.0477719306946  seconds.
----- ITERATION 5/10 ------
[<torch.utils.data.dataloader.DataLoader object at 0x1478a66194b0>, <torch.utils.data.dataloader.DataLoader object at 0x147860d10130>, <torch.utils.data.dataloader.DataLoader object at 0x14789e722ef0>, <torch.utils.data.dataloader.DataLoader object at 0x14789e723f40>]
LSTM(
  (lstm): LSTM(7, 96, batch_first=True, dropout=0.2)
  (layers): Sequential(
    (0): Linear(in_features=96, out_features=7, bias=True)
  )
)
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.029863525182008743
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.4699888229370117
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.03221854567527771
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.5340371131896973
0 1.619283487 	 0.5340371031
epoch_time;  39.89263653755188
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.011242661625146866
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.18678896129131317
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.011634298600256443
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.20799098908901215
1 0.0219721047 	 0.2079909863
epoch_time;  39.802823066711426
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.005077348556369543
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.10269337892532349
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0053650010377168655
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.113549143075943
2 0.0095130125 	 0.1135491432
epoch_time;  39.84258985519409
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.010347485542297363
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.07935730367898941
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.011243061162531376
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.08891307562589645
3 0.005832118 	 0.0889130791
epoch_time;  40.802865982055664
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0021011875942349434
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.05196007713675499
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0027445240411907434
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.05893075093626976
4 0.0043938595 	 0.0589307514
epoch_time;  41.83650803565979
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.001373381819576025
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.04262549802660942
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0025823565665632486
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.049209825694561005
5 0.003593042 	 0.0492098252
epoch_time;  40.4271981716156
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0011791354045271873
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.037095531821250916
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0018089156365022063
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.042096592485904694
6 0.0030944497 	 0.0420965932
epoch_time;  40.65360760688782
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.001375086372718215
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.031208764761686325
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.001940651098266244
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.03537946194410324
7 0.0025908189 	 0.0353794617
epoch_time;  39.99503946304321
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.002512587234377861
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.13275142014026642
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                              Epoch â–â–â–â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–…â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb: Test loss t(-10, 10)_r(-5, 5)_none â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–ƒâ–‚â–‚â–â–â–â–â–â–ƒâ–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  Test loss t(-10, 10)_r(0, 0)_none â–ˆâ–„â–‚â–‚â–â–â–â–â–ƒâ–‚â–‚â–â–â–â–â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    Test loss t(0, 0)_r(-5, 5)_none â–ˆâ–ƒâ–‚â–ƒâ–â–â–â–â–‚â–â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:     Test loss t(0, 0)_r(0, 0)_none â–ˆâ–„â–‚â–ƒâ–â–â–â–â–â–â–‚â–ƒâ–â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                         Train loss â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                              Epoch 29
wandb: Test loss t(-10, 10)_r(-5, 5)_none 0.03556
wandb:  Test loss t(-10, 10)_r(0, 0)_none 0.02662
wandb:    Test loss t(0, 0)_r(-5, 5)_none 0.00092
wandb:     Test loss t(0, 0)_r(0, 0)_none 0.00061
wandb:                         Train loss 0.00104
wandb: 
wandb: ğŸš€ View run golden-rooster-1607 at: https://wandb.ai/nreints/thesis/runs/h7luk2uw
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230127_083627-h7luk2uw/logs
/gpfs/home2/nreints/MScThesis/code/lstm.py:270: DeprecationWarning: Sampling from a set deprecated
since Python 3.9 and will be removed in a subsequent version.
  train_sims = set(random.sample(sims_train, int(0.8 * n_sims_train)))
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.13.9 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.8
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230127_085745-3m9arzei
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run chromatic-kumquat-1614
wandb: â­ï¸ View project at https://wandb.ai/nreints/thesis
wandb: ğŸš€ View run at https://wandb.ai/nreints/thesis/runs/3m9arzei
/home/nreints/.conda/envs/thesis/lib/python3.10/site-packages/torch/nn/modules/rnn.py:67: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  warnings.warn("dropout option adds dropout after all but last "
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.00364843406714499
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.15575258433818817
8 0.0272130627 	 0.1557525911
epoch_time;  40.50061058998108
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0015262484084814787
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.07521536946296692
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.002242312068119645
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.09345231205224991
9 0.0029227815 	 0.0934523153
epoch_time;  39.165090560913086
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0033143949694931507
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.059149980545043945
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0032676169648766518
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.07163216918706894
10 0.0024514343 	 0.0716321663
epoch_time;  39.70310688018799
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.006843270268291235
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.049704913049936295
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.006136700976639986
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.057441551238298416
11 0.0021939332 	 0.0574415501
epoch_time;  39.48617243766785
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.000999304698780179
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.03572395071387291
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0013936212053522468
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.04388291388750076
12 0.001985349 	 0.0438829145
epoch_time;  40.303863763809204
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0012541862670332193
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.030119089409708977
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0016443250933662057
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.037506818771362305
13 0.0018306372 	 0.0375068181
epoch_time;  39.99935555458069
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.002627095440402627
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.029856644570827484
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.002780421171337366
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.03689543902873993
14 0.0016794291 	 0.0368954379
epoch_time;  39.62539720535278
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0010714309755712748
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.024178504943847656
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0014180723810568452
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.030336376279592514
15 0.0015768243 	 0.0303363771
epoch_time;  39.956860065460205
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0020582592114806175
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.11163551360368729
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.003052989486604929
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.1439940184354782
16 0.0072808573 	 0.1439940115
epoch_time;  40.10195708274841
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0007098933565430343
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.038261957466602325
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.001132276258431375
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.05192190036177635
17 0.0015867235 	 0.0519219021
epoch_time;  40.118980407714844
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0008202543831430376
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.029758209362626076
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0012492872774600983
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.040560442954301834
18 0.0013447921 	 0.0405604429
epoch_time;  39.82410264015198
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0007940990617498755
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.027445446699857712
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0011063077254220843
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.03524140641093254
19 0.0013695483 	 0.0352414065
epoch_time;  39.31875491142273
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.001593230408616364
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.02673216164112091
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0016629864694550633
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.03389724716544151
20 0.0013575648 	 0.0338972472
epoch_time;  39.44605875015259
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.000734951754566282
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.023700280115008354
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0011362131917849183
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.030552053824067116
21 0.0012842885 	 0.0305520545
epoch_time;  42.41001319885254
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0009099077433347702
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.02321050874888897
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0011724353535100818
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.02922348864376545
22 0.0012626647 	 0.0292234882
epoch_time;  39.81350588798523
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0005078093963675201
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0274649728089571
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0008497824310325086
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.03538693115115166
23 0.0017235907 	 0.0353869297
epoch_time;  39.89228391647339
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0010574876796454191
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.023724587634205818
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0013044594088569283
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.03025169111788273
24 0.0010895173 	 0.0302516903
epoch_time;  39.73798394203186
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.000815278384834528
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.023207025602459908
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.001114059123210609
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.02876734919846058
25 0.0011763 	 0.0287673495
epoch_time;  40.83067035675049
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0007880147313699126
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.023272627964615822
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0013594323536381125
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.029437914490699768
26 0.0011644672 	 0.0294379151
epoch_time;  39.938313722610474
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0010293733794242144
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.023762879893183708
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0014155588578432798
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.029418613761663437
27 0.0011323906 	 0.029418614
epoch_time;  39.998101234436035
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0006572562269866467
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.027325740084052086
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.00102268869522959
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.034622713923454285
28 0.0014431639 	 0.0346227139
epoch_time;  41.18995404243469
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0006149952532723546
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.026631034910678864
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0009169387631118298
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.035021454095840454
29 0.0010438216 	 0.0350214535
epoch_time;  39.87826704978943
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0006146163213998079
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.026624541729688644
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0009161222260445356
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.03556046634912491
It took  1277.6515443325043  seconds.
----- ITERATION 6/10 ------
[<torch.utils.data.dataloader.DataLoader object at 0x1478a4bddc30>, <torch.utils.data.dataloader.DataLoader object at 0x14789dd405e0>, <torch.utils.data.dataloader.DataLoader object at 0x14789dd407c0>, <torch.utils.data.dataloader.DataLoader object at 0x14789dd428f0>]
LSTM(
  (lstm): LSTM(7, 96, batch_first=True, dropout=0.2)
  (layers): Sequential(
    (0): Linear(in_features=96, out_features=7, bias=True)
  )
)
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.03272630646824837
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.48204177618026733
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.03522828221321106
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.4866422414779663
0 1.7929413974 	 0.486642244
epoch_time;  40.29916214942932
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.00995416659861803
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.2050824612379074
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.010695266537368298
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.205478236079216
1 0.0212543323 	 0.2054782418
epoch_time;  39.85215902328491
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.005439082160592079
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.12178223580121994
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.006254055071622133
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.11784712225198746
2 0.0089796465 	 0.1178471199
epoch_time;  39.768784523010254
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.005431600380688906
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0854077935218811
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.005503278691321611
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.08046908676624298
3 0.0059193991 	 0.0804690854
epoch_time;  40.18733620643616
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.00647390354424715
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.06591875851154327
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.009144570678472519
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.06627590209245682
4 0.004337836 	 0.0662758991
epoch_time;  40.075783252716064
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.00263596442528069
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.047722943127155304
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0030099540017545223
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.04603715240955353
5 0.0035606568 	 0.0460371525
epoch_time;  39.94133973121643
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0015907484339550138
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.03894489258527756
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0020086427684873343
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.03770674392580986
6 0.0028941489 	 0.0377067439
epoch_time;  40.24254751205444
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0018048648489639163
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.036033663898706436
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0024880024138838053
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.03495076298713684
7 0.0026153592 	 0.0349507634
epoch_time;  39.92359256744385
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0015647110994905233
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.07723893225193024
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.002248056698590517
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.0715450868010521
8 0.0125242691 	 0.0715450852
epoch_time;  39.50090217590332
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.001211474183946848
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.052892252802848816
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0017693674890324473
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.0494973324239254
9 0.0021952953 	 0.0494973335
epoch_time;  40.376824617385864
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0014782196376472712
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.04006405174732208
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0016019087051972747
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.03917268291115761
10 0.0020412485 	 0.0391726825
epoch_time;  39.875629901885986
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0009692479507066309
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0339587964117527
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0012806334998458624
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.03487981855869293
11 0.0018876333 	 0.0348798199
epoch_time;  42.25242829322815
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0010202437406405807
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.03162692114710808
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0012672296725213528
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.033046212047338486
12 0.0026855593 	 0.0330462124
epoch_time;  42.25955653190613
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0077464766800403595
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.03482310101389885
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.007142650429159403
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.03560961037874222
13 0.0015550784 	 0.0356096112
epoch_time;  40.12525272369385
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0013254046207293868
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.02835916168987751
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.002391279675066471
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.030934296548366547
14 0.0016205708 	 0.0309342963
epoch_time;  39.88788866996765
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0009506270871497691
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.024736706167459488
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0012408087495714426
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.025983646512031555
15 0.0014973377 	 0.0259836462
epoch_time;  39.236435413360596
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0008816294139251113
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.04675896465778351
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0012519584270194173
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.04507806897163391
16 0.0057991986 	 0.0450780701
epoch_time;  39.497081995010376
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0011674504494294524
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.03360779210925102
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0016827573999762535
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.033078599721193314
17 0.0012957917 	 0.0330785999
epoch_time;  41.41936635971069
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0011277629528194666
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.028723325580358505
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.00149233965203166
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.02810162492096424
18 0.0013701917 	 0.0281016243
epoch_time;  39.980308055877686
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0007486095419153571
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.026416126638650894
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0010692207142710686
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.02614235132932663
19 0.0013840228 	 0.0261423509
epoch_time;  39.7764356136322
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.012439089827239513
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.04076257348060608
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.009890882298350334
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.03789743408560753
20 0.0013682749 	 0.0378974356
epoch_time;  39.92753267288208
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.002436982002109289
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.028449900448322296
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0029919506050646305
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.028698403388261795
21 0.0017440106 	 0.0286984026
epoch_time;  39.33994817733765
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.00237076822668314
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.02790188603103161
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0027178172022104263
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.028448378667235374
22 0.0012522501 	 0.0284483786
epoch_time;  40.312047481536865
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0008229562663473189
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.024952439591288567
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0011017541401088238
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.02555113658308983
23 0.0012273473 	 0.0255511362
epoch_time;  39.20117688179016
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0007063314551487565
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.023955857381224632
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0009804044384509325
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.024367179721593857
24 0.0012224036 	 0.0243671798
epoch_time;  39.09214663505554
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                              Epoch â–â–â–â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–…â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb: Test loss t(-10, 10)_r(-5, 5)_none â–ˆâ–„â–‚â–‚â–‚â–â–â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  Test loss t(-10, 10)_r(0, 0)_none â–ˆâ–„â–‚â–‚â–‚â–â–â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    Test loss t(0, 0)_r(-5, 5)_none â–ˆâ–ƒâ–‚â–‚â–ƒâ–â–â–â–â–â–â–â–â–‚â–â–â–â–â–â–â–ƒâ–â–â–â–â–â–â–â–â–â–
wandb:     Test loss t(0, 0)_r(0, 0)_none â–ˆâ–ƒâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–ƒâ–â–â–â–â–â–â–„â–â–â–â–â–â–â–â–â–â–
wandb:                         Train loss â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                              Epoch 29
wandb: Test loss t(-10, 10)_r(-5, 5)_none 0.02521
wandb:  Test loss t(-10, 10)_r(0, 0)_none 0.02554
wandb:    Test loss t(0, 0)_r(-5, 5)_none 0.00103
wandb:     Test loss t(0, 0)_r(0, 0)_none 0.00071
wandb:                         Train loss 0.00116
wandb: 
wandb: ğŸš€ View run chromatic-kumquat-1614 at: https://wandb.ai/nreints/thesis/runs/3m9arzei
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230127_085745-3m9arzei/logs
/gpfs/home2/nreints/MScThesis/code/lstm.py:270: DeprecationWarning: Sampling from a set deprecated
since Python 3.9 and will be removed in a subsequent version.
  train_sims = set(random.sample(sims_train, int(0.8 * n_sims_train)))
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.13.9 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.8
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230127_091850-ilj8zcgi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run scintillating-wish-1621
wandb: â­ï¸ View project at https://wandb.ai/nreints/thesis
wandb: ğŸš€ View run at https://wandb.ai/nreints/thesis/runs/ilj8zcgi
/home/nreints/.conda/envs/thesis/lib/python3.10/site-packages/torch/nn/modules/rnn.py:67: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  warnings.warn("dropout option adds dropout after all but last "
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0006714863702654839
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.028659762814641
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.001027958351187408
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.02905389852821827
25 0.0014717934 	 0.0290538984
epoch_time;  38.922948360443115
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.000694591028150171
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.026955192908644676
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0010026348754763603
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.02733840048313141
26 0.0011452147 	 0.0273383996
epoch_time;  38.861124753952026
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0007037743926048279
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.02677665650844574
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0009923744946718216
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.02623659186065197
27 0.0011778446 	 0.0262365917
epoch_time;  38.97313976287842
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0007014109869487584
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.025988304987549782
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0010321090230718255
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.02581806480884552
28 0.0011265285 	 0.0258180641
epoch_time;  39.25113296508789
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0007107633864507079
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.025544704869389534
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0010296847904101014
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.025369824841618538
29 0.0011605414 	 0.0253698257
epoch_time;  38.937485218048096
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0007107113488018513
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.02554282732307911
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0010294386884197593
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.025210071355104446
It took  1265.4523866176605  seconds.
----- ITERATION 7/10 ------
[<torch.utils.data.dataloader.DataLoader object at 0x147860c6bb50>, <torch.utils.data.dataloader.DataLoader object at 0x1478a4bde950>, <torch.utils.data.dataloader.DataLoader object at 0x1478a4bdc5b0>, <torch.utils.data.dataloader.DataLoader object at 0x1478a4bddff0>]
LSTM(
  (lstm): LSTM(7, 96, batch_first=True, dropout=0.2)
  (layers): Sequential(
    (0): Linear(in_features=96, out_features=7, bias=True)
  )
)
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.03172549605369568
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.4248517155647278
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.03283536434173584
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.5187373757362366
0 1.6135965444 	 0.5187373781
epoch_time;  38.98444366455078
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.012172732502222061
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.16880068182945251
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.012187330983579159
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.2117815911769867
1 0.0211546376 	 0.2117815968
epoch_time;  38.73211050033569
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.004984859377145767
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.09106910973787308
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.006071419920772314
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.11971795558929443
2 0.0090618141 	 0.1197179581
epoch_time;  42.47460603713989
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0037620363291352987
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.06432344019412994
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.004026392940431833
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.08506245166063309
3 0.0059226182 	 0.0850624534
epoch_time;  40.63597869873047
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.015612521208822727
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0636780858039856
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.015281124040484428
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.08007883280515671
4 0.0042462334 	 0.0800788338
epoch_time;  40.36717367172241
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0018234928138554096
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0394425243139267
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.002267965115606785
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.0530376136302948
5 0.003725201 	 0.0530376146
epoch_time;  39.19751334190369
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0029409267008304596
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.03393044322729111
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0027944620233029127
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.04539618641138077
6 0.0029674551 	 0.0453961854
epoch_time;  39.64074349403381
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0024990220554172993
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.02829960733652115
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.003747496986761689
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.03888796642422676
7 0.0026327077 	 0.0388879661
epoch_time;  40.43204975128174
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0026123609859496355
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.1080508828163147
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.003661820199340582
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.15208669006824493
8 0.0190575114 	 0.1520866901
epoch_time;  41.4229416847229
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0014493409544229507
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.056340236216783524
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.002049126895144582
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.08621688932180405
9 0.0025604681 	 0.0862168891
epoch_time;  40.1302969455719
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.001152092358097434
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.03906680643558502
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0017960077384486794
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.06093405932188034
10 0.0021761397 	 0.060934061
epoch_time;  42.669440269470215
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0012323460541665554
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.030128885060548782
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0016126740956678987
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.04737982153892517
11 0.0020768812 	 0.0473798222
epoch_time;  38.73069667816162
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0016068392433226109
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.02552872709929943
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0020591565407812595
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.04010672867298126
12 0.0019036381 	 0.0401067302
epoch_time;  39.312664270401
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.002894873730838299
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.02416258491575718
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0028170517180114985
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.037867140024900436
13 0.0017856198 	 0.0378671398
epoch_time;  38.73828935623169
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0006088745431043208
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.02207767777144909
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.001010825508274138
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.03674594312906265
14 0.0019624031 	 0.0367459415
epoch_time;  38.49343013763428
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0007254675729200244
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.018225688487291336
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0010099245700985193
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.031527455896139145
15 0.0014072152 	 0.0315274558
epoch_time;  38.49022603034973
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0006975563010200858
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.01734931580722332
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0010395930148661137
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.031196508556604385
16 0.0014934629 	 0.0311965078
epoch_time;  38.33881998062134
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.001417109277099371
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                              Epoch â–â–â–â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–…â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb: Test loss t(-10, 10)_r(-5, 5)_none â–ˆâ–„â–‚â–‚â–‚â–â–â–â–ƒâ–‚â–‚â–â–â–â–â–â–â–â–â–‚â–â–â–â–â–â–â–â–â–â–â–
wandb:  Test loss t(-10, 10)_r(0, 0)_none â–ˆâ–„â–‚â–‚â–‚â–â–â–â–ƒâ–‚â–â–â–â–â–â–â–â–â–â–‚â–â–â–â–â–â–â–â–â–â–â–
wandb:    Test loss t(0, 0)_r(-5, 5)_none â–„â–‚â–‚â–â–ƒâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–
wandb:     Test loss t(0, 0)_r(0, 0)_none â–„â–‚â–â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–
wandb:                         Train loss â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                              Epoch 29
wandb: Test loss t(-10, 10)_r(-5, 5)_none 0.02432
wandb:  Test loss t(-10, 10)_r(0, 0)_none 0.01367
wandb:    Test loss t(0, 0)_r(-5, 5)_none 0.0014
wandb:     Test loss t(0, 0)_r(0, 0)_none 0.00111
wandb:                         Train loss 0.00111
wandb: 
wandb: ğŸš€ View run scintillating-wish-1621 at: https://wandb.ai/nreints/thesis/runs/ilj8zcgi
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230127_091850-ilj8zcgi/logs
/gpfs/home2/nreints/MScThesis/code/lstm.py:270: DeprecationWarning: Sampling from a set deprecated
since Python 3.9 and will be removed in a subsequent version.
  train_sims = set(random.sample(sims_train, int(0.8 * n_sims_train)))
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.13.9 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.8
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230127_093941-1hoyaomn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run virtuous-pig-1628
wandb: â­ï¸ View project at https://wandb.ai/nreints/thesis
wandb: ğŸš€ View run at https://wandb.ai/nreints/thesis/runs/1hoyaomn
/home/nreints/.conda/envs/thesis/lib/python3.10/site-packages/torch/nn/modules/rnn.py:67: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  warnings.warn("dropout option adds dropout after all but last "
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.016948232427239418
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0016021972987800837
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.030428897589445114
17 0.0014695392 	 0.0304288979
epoch_time;  38.68305158615112
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0005762444925494492
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.01701989769935608
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0009030640358105302
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.03039216622710228
18 0.0015500247 	 0.0303921656
epoch_time;  38.494707345962524
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.07315830141305923
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.09760651737451553
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.06595201790332794
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.10502959042787552
19 0.0013992825 	 0.1050295873
epoch_time;  38.65629243850708
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0007807979127392173
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.01798740029335022
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0012274986365810037
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.03271361067891121
20 0.0017894755 	 0.0327136106
epoch_time;  38.17812180519104
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0006294155609793961
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.016081219539046288
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0010069034760817885
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.02990259975194931
21 0.00126283 	 0.0299025994
epoch_time;  38.342888593673706
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0005398345529101789
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.01647639460861683
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0008643206674605608
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.029207956045866013
22 0.0013722047 	 0.0292079557
epoch_time;  38.40979838371277
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0006132879643701017
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.014633027836680412
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.000978721771389246
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.02669657953083515
23 0.0011529357 	 0.0266965797
epoch_time;  38.94273042678833
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0006572084384970367
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.01485661044716835
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0009498861618340015
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.02630455419421196
24 0.001251727 	 0.0263045533
epoch_time;  38.688124656677246
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0005529392510652542
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.01433758158236742
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0009158227476291358
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.02528936229646206
25 0.0011703526 	 0.0252893627
epoch_time;  40.72176694869995
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0008110867929644883
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.013871408998966217
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0013094980968162417
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.02493981271982193
26 0.0011645222 	 0.0249398136
epoch_time;  40.19499731063843
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0005585261969827116
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.013471080921590328
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0008847982971929014
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.02418859489262104
27 0.0011642644 	 0.0241885949
epoch_time;  38.815816164016724
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0007874443545006216
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.013785405084490776
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0010477680480107665
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.024520857259631157
28 0.0011421657 	 0.0245208567
epoch_time;  38.54352927207947
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0011093735229223967
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.013709464110434055
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0013961226213723421
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.024228349328041077
29 0.0011120028 	 0.0242283496
epoch_time;  38.9460825920105
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0011099339462816715
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.013671808876097202
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0013973972527310252
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.02431534044444561
It took  1250.7323052883148  seconds.
----- ITERATION 8/10 ------
[<torch.utils.data.dataloader.DataLoader object at 0x1478a4bde7a0>, <torch.utils.data.dataloader.DataLoader object at 0x14789e6ed3f0>, <torch.utils.data.dataloader.DataLoader object at 0x14789e6eeda0>, <torch.utils.data.dataloader.DataLoader object at 0x14789e6eecb0>]
LSTM(
  (lstm): LSTM(7, 96, batch_first=True, dropout=0.2)
  (layers): Sequential(
    (0): Linear(in_features=96, out_features=7, bias=True)
  )
)
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0323893167078495
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.4515768587589264
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.03438407555222511
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.5110259056091309
0 1.7932858926 	 0.5110259272
epoch_time;  39.68330955505371
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.010420616716146469
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.19272030889987946
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.01021602377295494
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.20576848089694977
1 0.0209578139 	 0.2057684815
epoch_time;  39.84031438827515
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.01213042438030243
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.12168504297733307
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.012360744178295135
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.12432855367660522
2 0.00950111 	 0.1243285557
epoch_time;  39.056811809539795
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0023392990697175264
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0810202807188034
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.002844991395249963
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.08063367009162903
3 0.0058306958 	 0.0806336705
epoch_time;  38.69964337348938
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0017949441680684686
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.06350100040435791
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0024868003092706203
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.06207111105322838
4 0.0042158747 	 0.0620711116
epoch_time;  38.91518473625183
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.004821790382266045
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.054306406527757645
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.004191804677248001
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.052147768437862396
5 0.0034419355 	 0.0521477702
epoch_time;  38.46125864982605
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.000993476714938879
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.041916374117136
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0013249251060187817
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.039985042065382004
6 0.0029931882 	 0.039985043
epoch_time;  38.19832754135132
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0021210159175097942
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.09725766628980637
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.002896364778280258
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.10218846797943115
7 0.0149441069 	 0.1021884676
epoch_time;  38.78328776359558
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.002429140033200383
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.06295961141586304
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.003007593797519803
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.06590740382671356
8 0.0025402707 	 0.0659074063
epoch_time;  38.520448207855225
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.002014759462326765
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.048588018864393234
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                              Epoch â–â–â–â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–…â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb: Test loss t(-10, 10)_r(-5, 5)_none â–ˆâ–„â–‚â–‚â–â–â–â–‚â–‚â–â–â–â–â–ƒâ–‚â–â–â–â–â–‚â–â–â–â–â–â–â–‚â–â–â–â–
wandb:  Test loss t(-10, 10)_r(0, 0)_none â–ˆâ–„â–ƒâ–‚â–‚â–â–â–‚â–‚â–â–â–â–â–ƒâ–‚â–â–â–â–â–‚â–â–â–â–â–â–â–‚â–â–â–â–
wandb:    Test loss t(0, 0)_r(-5, 5)_none â–ˆâ–ƒâ–ƒâ–â–â–‚â–â–â–â–â–â–â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–‚â–â–â–â–â–
wandb:     Test loss t(0, 0)_r(0, 0)_none â–ˆâ–ƒâ–„â–â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–‚â–â–â–â–‚â–â–â–â–â–
wandb:                         Train loss â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                              Epoch 29
wandb: Test loss t(-10, 10)_r(-5, 5)_none 0.03324
wandb:  Test loss t(-10, 10)_r(0, 0)_none 0.02478
wandb:    Test loss t(0, 0)_r(-5, 5)_none 0.00107
wandb:     Test loss t(0, 0)_r(0, 0)_none 0.00072
wandb:                         Train loss 0.00117
wandb: 
wandb: ğŸš€ View run virtuous-pig-1628 at: https://wandb.ai/nreints/thesis/runs/1hoyaomn
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230127_093941-1hoyaomn/logs
/gpfs/home2/nreints/MScThesis/code/lstm.py:270: DeprecationWarning: Sampling from a set deprecated
since Python 3.9 and will be removed in a subsequent version.
  train_sims = set(random.sample(sims_train, int(0.8 * n_sims_train)))
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.13.9 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.8
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230127_100009-xrc8soa9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run abundant-wish-1635
wandb: â­ï¸ View project at https://wandb.ai/nreints/thesis
wandb: ğŸš€ View run at https://wandb.ai/nreints/thesis/runs/xrc8soa9
/home/nreints/.conda/envs/thesis/lib/python3.10/site-packages/torch/nn/modules/rnn.py:67: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  warnings.warn("dropout option adds dropout after all but last "
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.00242609903216362
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.05014587193727493
9 0.0022299618 	 0.0501458724
epoch_time;  38.806251525878906
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0011727545643225312
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.038007207214832306
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.001463696244172752
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.03964425250887871
10 0.0019795312 	 0.0396442529
epoch_time;  38.92693519592285
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0010616863146424294
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.033826835453510284
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0013627567095682025
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.035105619579553604
11 0.0018917715 	 0.0351056188
epoch_time;  38.641656160354614
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0023913593031466007
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0327862948179245
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0030103435274213552
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.03440104052424431
12 0.0017667277 	 0.0344010408
epoch_time;  38.52045679092407
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0024693896993994713
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.1450035572052002
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.003458611899986863
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.15297779440879822
13 0.0079627907 	 0.1529777965
epoch_time;  38.37905812263489
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0007409437675960362
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.062441617250442505
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0011860006488859653
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.06662146747112274
14 0.0017984551 	 0.0666214692
epoch_time;  38.495771169662476
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0007961944211274385
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.049418456852436066
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.00113966956268996
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.052023183554410934
15 0.0015073089 	 0.0520231817
epoch_time;  38.68887948989868
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0006786729791201651
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.04097050428390503
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0009733548504300416
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.043661750853061676
16 0.0015279738 	 0.0436617514
epoch_time;  38.669740438461304
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0007777291466481984
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0345308892428875
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0010278159752488136
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.037856653332710266
17 0.0013805272 	 0.0378566523
epoch_time;  41.871922969818115
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0006745772552676499
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0321962907910347
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0010259562404826283
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.035803940147161484
18 0.0013481219 	 0.0358039389
epoch_time;  38.45576214790344
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0008303165668621659
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0689285397529602
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0012724759289994836
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.08441732078790665
19 0.0028837718 	 0.0844173201
epoch_time;  39.01732063293457
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0005885580321773887
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.03827439621090889
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0008883412228897214
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.04596862196922302
20 0.0010941161 	 0.0459686204
epoch_time;  38.96690535545349
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.002881118096411228
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.03659692034125328
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.002539041917771101
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.041994623839855194
21 0.001208984 	 0.0419946221
epoch_time;  38.88481593132019
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.000662557315081358
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.029701344668865204
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0009865075116977096
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.03464415296912193
22 0.0012290173 	 0.0346441528
epoch_time;  38.829986572265625
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0006641228101216257
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.028889939188957214
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0009288191795349121
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.03306134417653084
23 0.0012714406 	 0.0330613445
epoch_time;  39.355218172073364
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0006302092224359512
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.027024980634450912
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0009607700631022453
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.03050869330763817
24 0.0011538028 	 0.0305086925
epoch_time;  39.06826734542847
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.002979770302772522
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.028618311509490013
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.003290439024567604
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.03203292563557625
25 0.0011626089 	 0.0320329263
epoch_time;  38.75968050956726
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0011988821206614375
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.05775149539113045
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0017663557082414627
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.0774911642074585
26 0.0067169542 	 0.077491161
epoch_time;  38.59035539627075
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0007968179415911436
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.03398982807993889
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0012014189269393682
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.04658348858356476
27 0.001395363 	 0.0465834868
epoch_time;  38.79087996482849
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.001834966940805316
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0285215862095356
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.001901920884847641
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.037852540612220764
28 0.0011969974 	 0.0378525408
epoch_time;  38.72657084465027
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0007245802553370595
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.024771032854914665
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0010742993326857686
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.03324227035045624
29 0.001166583 	 0.0332422689
epoch_time;  38.39833307266235
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.000724600744433701
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.02478235960006714
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0010732922237366438
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.03324289247393608
It took  1228.0582756996155  seconds.
----- ITERATION 9/10 ------
[<torch.utils.data.dataloader.DataLoader object at 0x14789e6eeef0>, <torch.utils.data.dataloader.DataLoader object at 0x14789dd40280>, <torch.utils.data.dataloader.DataLoader object at 0x14789dd408b0>, <torch.utils.data.dataloader.DataLoader object at 0x14789e6ec8b0>]
LSTM(
  (lstm): LSTM(7, 96, batch_first=True, dropout=0.2)
  (layers): Sequential(
    (0): Linear(in_features=96, out_features=7, bias=True)
  )
)
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.03358541429042816
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.45289504528045654
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.035993967205286026
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.5489041209220886
0 1.6487455866 	 0.5489040963
epoch_time;  38.691179513931274
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.010798557661473751
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.19391532242298126
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.011247504502534866
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.2323761284351349
1 0.022740037 	 0.2323761217
epoch_time;  38.52459526062012
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0062950607389211655
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.12172402441501617
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.008152550086379051
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.14291733503341675
2 0.0098071181 	 0.1429173334
epoch_time;  38.25247550010681
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.00495230033993721
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.09248505532741547
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.005512834992259741
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.1058177649974823
3 0.0061171017 	 0.105817766
epoch_time;  38.794233322143555
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.00285594561137259
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.07367141544818878
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0035124653950333595
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.08115611970424652
4 0.0046443914 	 0.081156117
epoch_time;  38.716625928878784
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0017451514722779393
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.058526985347270966
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.002329649170860648
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.06382361054420471
5 0.0036619296 	 0.0638236078
epoch_time;  38.34609866142273
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0176631361246109
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.06562309712171555
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.021693270653486252
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.07323217391967773
6 0.0032461958 	 0.0732321725
epoch_time;  38.69576120376587
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0011898254742845893
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.041644394397735596
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0016195049975067377
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.044984567910432816
7 0.0028009725 	 0.0449845668
epoch_time;  38.86001896858215
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0010121752275153995
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.037419840693473816
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0014720200560986996
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.04071493074297905
8 0.002351543 	 0.0407149295
epoch_time;  40.74946093559265
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.002619534032419324
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.15469186007976532
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0035662157461047173
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.171879380941391
9 0.0250302242 	 0.1718793794
epoch_time;  41.38510799407959
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.002107290318235755
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0924638882279396
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.002577868290245533
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.10357335209846497
10 0.0027587053 	 0.1035733525
epoch_time;  38.829697132110596
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0012427900219336152
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.06592048704624176
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0017917488003149629
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.07446938753128052
11 0.0023123608 	 0.0744693906
epoch_time;  38.86202836036682
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.003620839910581708
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.05868677794933319
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.004100496415048838
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.06559061259031296
12 0.0020726572 	 0.0655906136
epoch_time;  38.765562295913696
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0010414619464427233
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.042978718876838684
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0013219016836956143
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.04889587312936783
13 0.0019015423 	 0.0488958733
epoch_time;  39.10366487503052
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0008774836314842105
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.03600962460041046
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0012964507332071662
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.041426245123147964
14 0.001682991 	 0.0414262466
epoch_time;  40.06570267677307
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0011732811108231544
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.03445611894130707
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0015883613377809525
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.039146795868873596
15 0.001651591 	 0.039146795
epoch_time;  39.09048676490784
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0007215106743387878
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.034145135432481766
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0011176187545061111
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.03859831765294075
16 0.0031153158 	 0.038598317
epoch_time;  38.53538727760315
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.001038856222294271
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.029720118269324303
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0015013599768280983
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.03395643085241318
17 0.0013752643 	 0.0339564297
epoch_time;  38.76046419143677
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0008080894476734102
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.026071367785334587
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0011757120955735445
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.02985917404294014
18 0.0014251822 	 0.0298591741
epoch_time;  38.54270839691162
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.000844070571474731
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.025831734761595726
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0011595302494242787
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.029684150591492653
19 0.0013921749 	 0.0296841503
epoch_time;  38.748525857925415
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0008009971352294087
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.02525980770587921
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.001057767542079091
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.029573552310466766
20 0.0013419847 	 0.0295735529
epoch_time;  38.29851174354553
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0012355003273114562
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.027450846508145332
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.001347810379229486
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.03207853436470032
21 0.0014948955 	 0.0320785355
epoch_time;  38.636921882629395
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0008561532595194876
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.025684157386422157
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0011544390581548214
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.02990660071372986
22 0.0012793764 	 0.0299066013
epoch_time;  38.69895005226135
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0007237446261569858
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.025443371385335922
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0011754410807043314
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.02997770346701145
23 0.0012667356 	 0.0299777034
epoch_time;  38.473222494125366
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0006138247554190457
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.03697929158806801
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0010214855428785086
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.043927617371082306
24 0.0017555742 	 0.0439276162
epoch_time;  38.372509479522705
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0009545916109345853
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.02534583769738674
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0011865193955600262
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.030651401728391647
25 0.000988524 	 0.0306514008
epoch_time;  38.285268783569336
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                              Epoch â–â–â–â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–…â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb: Test loss t(-10, 10)_r(-5, 5)_none â–ˆâ–„â–ƒâ–‚â–‚â–â–‚â–â–â–ƒâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  Test loss t(-10, 10)_r(0, 0)_none â–ˆâ–„â–ƒâ–‚â–‚â–‚â–‚â–â–â–ƒâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    Test loss t(0, 0)_r(-5, 5)_none â–ˆâ–ƒâ–‚â–‚â–‚â–â–…â–â–â–‚â–â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:     Test loss t(0, 0)_r(0, 0)_none â–ˆâ–ƒâ–‚â–‚â–â–â–…â–â–â–â–â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                         Train loss â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:                              Epoch 29
wandb: Test loss t(-10, 10)_r(-5, 5)_none 0.02801
wandb:  Test loss t(-10, 10)_r(0, 0)_none 0.02568
wandb:    Test loss t(0, 0)_r(-5, 5)_none 0.00104
wandb:     Test loss t(0, 0)_r(0, 0)_none 0.0007
wandb:                         Train loss 0.00119
wandb: 
wandb: ğŸš€ View run abundant-wish-1635 at: https://wandb.ai/nreints/thesis/runs/xrc8soa9
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230127_100009-xrc8soa9/logs
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0010924404487013817
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.024923672899603844
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0012620253255590796
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.02872941642999649
26 0.0011787735 	 0.0287294157
epoch_time;  38.72489261627197
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0006807212485000491
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.025058872997760773
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0009882646845653653
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.027598358690738678
27 0.0012038469 	 0.027598358
epoch_time;  38.59237623214722
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.002120820339769125
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.027751976624131203
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0025225833524018526
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.029893333092331886
28 0.0011454727 	 0.0298933335
epoch_time;  38.418139696121216
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0007011754787527025
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.02569262497127056
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.00104036508128047
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.02803192473948002
29 0.0011916421 	 0.0280319254
epoch_time;  38.58444595336914
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0007011223933659494
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.025675194337964058
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0010403753258287907
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.02800917625427246
It took  1226.4194600582123  seconds.

JOB STATISTICS
==============
Job ID: 2142225
Array Job ID: 2141141_17
Cluster: snellius
User/Group: nreints/nreints
State: COMPLETED (exit code 0)
Nodes: 1
Cores per node: 18
CPU Utilized: 19:08:25
CPU Efficiency: 30.17% of 2-15:26:06 core-walltime
Job Wall-clock time: 03:31:27
Memory Utilized: 15.38 GB
Memory Efficiency: 49.22% of 31.25 GB
