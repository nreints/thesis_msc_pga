/gpfs/home2/nreints/MScThesis/code/lstm.py:270: DeprecationWarning: Sampling from a set deprecated
since Python 3.9 and will be removed in a subsequent version.
  train_sims = set(random.sample(sims_train, int(0.8 * n_sims_train)))
wandb: Currently logged in as: nreints. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.13.9 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.8
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230127_072247-fj6sxab8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lunar-monkey-1582
wandb: ⭐️ View project at https://wandb.ai/nreints/thesis
wandb: 🚀 View run at https://wandb.ai/nreints/thesis/runs/fj6sxab8
/home/nreints/.conda/envs/thesis/lib/python3.10/site-packages/torch/nn/modules/rnn.py:67: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  warnings.warn("dropout option adds dropout after all but last "
BEFORE ['data_t(0,', '0)_r(-5,', '5)_none']
----- ITERATION 0/10 ------
[<torch.utils.data.dataloader.DataLoader object at 0x145e7515a8c0>, <torch.utils.data.dataloader.DataLoader object at 0x145e6e42cb50>, <torch.utils.data.dataloader.DataLoader object at 0x145e6e42c400>, <torch.utils.data.dataloader.DataLoader object at 0x145e6e42c670>]
LSTM(
  (lstm): LSTM(8, 96, batch_first=True, dropout=0.2)
  (layers): Sequential(
    (0): Linear(in_features=96, out_features=8, bias=True)
  )
)
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.024659736081957817
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.06060438230633736
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0290551595389843
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.0876942053437233
0 1.3644088064 	 0.0876942027
epoch_time;  41.709084033966064
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.024304863065481186
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.04716913029551506
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.020676005631685257
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.052900854498147964
1 0.021050337 	 0.052900856
epoch_time;  41.49487662315369
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.010227355174720287
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0279250368475914
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.012631049379706383
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.04061480239033699
2 0.0151284526 	 0.0406148023
epoch_time;  41.42920756340027
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0030591499526053667
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.015823829919099808
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0055246842093765736
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.025737229734659195
3 0.0126549203 	 0.0257372294
epoch_time;  41.30741238594055
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.022493917495012283
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.04493681713938713
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.025100529193878174
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.04780252277851105
4 0.0099281806 	 0.0478025246
epoch_time;  41.50941491127014
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0019549138378351927
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.01012769341468811
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.003969656769186258
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.017276063561439514
5 0.0087610139 	 0.0172760638
epoch_time;  41.20535159111023
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0027485855389386415
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.009986627846956253
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.004957710392773151
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.01720133051276207
6 0.007496841 	 0.01720133
epoch_time;  41.23638963699341
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.019090309739112854
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.03164003789424896
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.012563961558043957
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.025099534541368484
7 0.0065813122 	 0.0250995354
epoch_time;  40.9398090839386
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0013970157597213984
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.006447296589612961
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0027592794504016638
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.012105152010917664
8 0.00638712 	 0.0121051523
epoch_time;  40.8082971572876
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.00508554233238101
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.012436018325388432
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.006525092758238316
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.01764245145022869
9 0.0061068387 	 0.0176424519
epoch_time;  40.73131775856018
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0010477734031155705
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.005729831755161285
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0016696002567186952
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.009496483020484447
10 0.004743375 	 0.0094964828
epoch_time;  44.61739730834961
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0032825481612235308
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.009220627136528492
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.004020544234663248
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.012510097585618496
11 0.0048357565 	 0.012510098
epoch_time;  44.03036642074585
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0014337871689349413
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.005822544917464256
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.002130345907062292
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.009276759810745716
12 0.004369774 	 0.0092767596
epoch_time;  41.04950404167175
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0013333720853552222
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.005619514733552933
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.00203891983255744
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.009421235881745815
13 0.0046406294 	 0.0094212355
epoch_time;  41.22797727584839
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0014638274442404509
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.006446123123168945
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.002529558027163148
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.010027294978499413
14 0.0043334264 	 0.0100272948
epoch_time;  40.78405570983887
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0018484621541574597
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.006018848158419132
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.001990121090784669
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.008640069514513016
15 0.0036689699 	 0.0086400696
epoch_time;  40.8170211315155
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0017578061670064926
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.005675556603819132
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.002397349337115884
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.008648189716041088
16 0.0034134083 	 0.0086481895
epoch_time;  40.96307134628296
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0011062072589993477
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.00857294537127018
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0020159233827143908
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.012592141516506672
17 0.0106879573 	 0.0125921414
epoch_time;  41.198633432388306
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.001948047080077231
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.006452810950577259
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.003096022643148899
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.010231140069663525
18 0.0024246893 	 0.0102311398
epoch_time;  41.03558969497681
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0008017633226700127
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.004185475409030914
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0012934693368151784
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.006741035263985395
19 0.0034195393 	 0.0067410354
epoch_time;  40.817023277282715
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0012339483946561813
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.004496952053159475
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.001677494728937745
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.006920676212757826
20 0.0029187775 	 0.0069206762
epoch_time;  40.81423854827881
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.003330316161736846
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0076143573969602585
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.004032668191939592
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.009726776741445065
21 0.0031817737 	 0.0097267772
epoch_time;  41.36970138549805
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0019091643625870347
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.005127232056111097
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0026084298733621836
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.007752075791358948
22 0.0030909159 	 0.0077520757
epoch_time;  41.265116691589355
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                              Epoch ▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇███
wandb: Test loss t(-10, 10)_r(-5, 5)_none █▅▄▃▅▂▂▃▂▂▁▂▁▁▁▁▁▂▁▁▁▁▁▁▁▂▂▁▁▁▁
wandb:  Test loss t(-10, 10)_r(0, 0)_none █▆▄▃▆▂▂▄▁▂▁▂▁▁▁▁▁▂▁▁▁▂▁▁▂▁▂▁▁▁▁
wandb:    Test loss t(0, 0)_r(-5, 5)_none █▆▄▂▇▂▂▄▁▂▁▂▁▁▁▁▁▁▁▁▁▂▁▁▂▂▂▁▁▁▁
wandb:     Test loss t(0, 0)_r(0, 0)_none ██▄▂▇▁▂▆▁▂▁▂▁▁▁▁▁▁▁▁▁▂▁▁▂▂▂▁▁▁▁
wandb:                         Train loss █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                              Epoch 29
wandb: Test loss t(-10, 10)_r(-5, 5)_none 0.00575
wandb:  Test loss t(-10, 10)_r(0, 0)_none 0.00352
wandb:    Test loss t(0, 0)_r(-5, 5)_none 0.00126
wandb:     Test loss t(0, 0)_r(0, 0)_none 0.00074
wandb:                         Train loss 0.00569
wandb: 
wandb: 🚀 View run lunar-monkey-1582 at: https://wandb.ai/nreints/thesis/runs/fj6sxab8
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230127_072247-fj6sxab8/logs
/gpfs/home2/nreints/MScThesis/code/lstm.py:270: DeprecationWarning: Sampling from a set deprecated
since Python 3.9 and will be removed in a subsequent version.
  train_sims = set(random.sample(sims_train, int(0.8 * n_sims_train)))
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.13.9 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.8
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230127_074438-pjsu89r5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run festive-rocket-1589
wandb: ⭐️ View project at https://wandb.ai/nreints/thesis
wandb: 🚀 View run at https://wandb.ai/nreints/thesis/runs/pjsu89r5
/home/nreints/.conda/envs/thesis/lib/python3.10/site-packages/torch/nn/modules/rnn.py:67: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  warnings.warn("dropout option adds dropout after all but last "
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0007357129361480474
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.003158843843266368
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0012102937325835228
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.005527027882635593
23 0.0028763747 	 0.0055270278
epoch_time;  41.17457365989685
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0040605328977108
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.00839085690677166
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0039000753313302994
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.009595664218068123
24 0.0042703789 	 0.0095956642
epoch_time;  41.292173862457275
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.002984217368066311
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.006605793721973896
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.006232742685824633
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.012580565176904202
25 0.00260156 	 0.0125805647
epoch_time;  41.39366888999939
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.005290079861879349
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.009450315497815609
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.005610698368400335
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.01107705570757389
26 0.0027555847 	 0.0110770561
epoch_time;  40.54542136192322
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.000776575761847198
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.002841481938958168
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0011172789381816983
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.004878481384366751
27 0.002937948 	 0.0048784813
epoch_time;  41.09926438331604
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.001466080779209733
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.004145537503063679
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0021570678800344467
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.006256874185055494
28 0.0026075407 	 0.0062568742
epoch_time;  40.9840772151947
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0007359670707955956
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0035174828954041004
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0012576731387525797
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.005738929845392704
29 0.0056852338 	 0.00573893
epoch_time;  41.02602028846741
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.000735799374524504
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0035201602149754763
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0012576562585309148
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.005746426526457071
It took  1311.1857872009277  seconds.
----- ITERATION 1/10 ------
[<torch.utils.data.dataloader.DataLoader object at 0x145e6e42de40>, <torch.utils.data.dataloader.DataLoader object at 0x145e42dc6380>, <torch.utils.data.dataloader.DataLoader object at 0x145e1f0a8070>, <torch.utils.data.dataloader.DataLoader object at 0x145e1f0a8190>]
LSTM(
  (lstm): LSTM(8, 96, batch_first=True, dropout=0.2)
  (layers): Sequential(
    (0): Linear(in_features=96, out_features=8, bias=True)
  )
)
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.026717303320765495
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.06932827085256577
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.026789814233779907
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.09536170214414597
0 1.7601420932 	 0.0953617038
epoch_time;  44.17799663543701
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.03919922932982445
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.07970426231622696
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.04374642297625542
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.09357667714357376
1 0.0191429132 	 0.0935766791
epoch_time;  44.14597725868225
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.015458601526916027
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.035861510783433914
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.014537544921040535
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.044258955866098404
2 0.0147946045 	 0.0442589561
epoch_time;  41.72127723693848
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.003354374086484313
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.019467419013381004
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.005603342782706022
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.028357652947306633
3 0.0126193102 	 0.0283576527
epoch_time;  41.468676805496216
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.003251634771004319
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.017176898196339607
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.005265058949589729
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.02240159921348095
4 0.0099959825 	 0.0224015994
epoch_time;  41.38128995895386
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.007975808344781399
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.028595155104994774
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.009406177327036858
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.028617626056075096
5 0.0088866094 	 0.0286176255
epoch_time;  40.87859106063843
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.02650066465139389
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.04598730430006981
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.03258172795176506
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.056270863860845566
6 0.0075980164 	 0.0562708644
epoch_time;  41.30785512924194
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.004471029620617628
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.014792487025260925
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.004671331495046616
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.016360094770789146
7 0.0069492897 	 0.0163600956
epoch_time;  41.18044948577881
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0038942573592066765
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.013694368302822113
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0070858607068657875
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.01949009671807289
8 0.0058496321 	 0.0194900965
epoch_time;  40.954756021499634
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.005269072484225035
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.014151673763990402
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.007739229127764702
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.018864482641220093
9 0.0059463113 	 0.0188644833
epoch_time;  41.0967915058136
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0014930652687326074
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.008023674599826336
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.002372559392824769
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.010715999640524387
10 0.004689527 	 0.0107159996
epoch_time;  41.10414505004883
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.015204259194433689
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.028309796005487442
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.012646653689444065
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.025290662422776222
11 0.0048445038 	 0.0252906621
epoch_time;  41.00261616706848
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0017786378739401698
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.008388559333980083
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.00227581849321723
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.010035802610218525
12 0.0045846063 	 0.010035803
epoch_time;  41.308515787124634
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.004123570863157511
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.01117070484906435
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.004153850022703409
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.012019517831504345
13 0.0044590858 	 0.0120195176
epoch_time;  41.37271571159363
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.001594263594597578
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.007431202568113804
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.002116998191922903
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.00894705019891262
14 0.0039993733 	 0.0089470497
epoch_time;  40.9708776473999
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0007366498466581106
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                              Epoch ▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇███
wandb: Test loss t(-10, 10)_r(-5, 5)_none ██▄▃▂▃▅▂▂▂▁▃▁▂▁▁▂▁▂▅▁▂▂▁▁▁▁▁▁▁▁
wandb:  Test loss t(-10, 10)_r(0, 0)_none ▇█▄▂▂▃▅▂▂▂▁▃▁▂▁▁▂▁▂▆▁▃▂▁▁▁▁▁▁▁▁
wandb:    Test loss t(0, 0)_r(-5, 5)_none ▅█▃▂▂▂▆▂▂▂▁▃▁▂▁▁▂▁▂▆▁▂▂▁▁▁▁▁▁▁▁
wandb:     Test loss t(0, 0)_r(0, 0)_none ▆█▄▂▁▂▆▂▂▂▁▄▁▂▁▁▂▁▁▇▁▃▂▁▁▁▁▁▁▁▁
wandb:                         Train loss █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                              Epoch 29
wandb: Test loss t(-10, 10)_r(-5, 5)_none 0.00515
wandb:  Test loss t(-10, 10)_r(0, 0)_none 0.00377
wandb:    Test loss t(0, 0)_r(-5, 5)_none 0.00103
wandb:     Test loss t(0, 0)_r(0, 0)_none 0.00059
wandb:                         Train loss 0.00327
wandb: 
wandb: 🚀 View run festive-rocket-1589 at: https://wandb.ai/nreints/thesis/runs/pjsu89r5
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230127_074438-pjsu89r5/logs
/gpfs/home2/nreints/MScThesis/code/lstm.py:270: DeprecationWarning: Sampling from a set deprecated
since Python 3.9 and will be removed in a subsequent version.
  train_sims = set(random.sample(sims_train, int(0.8 * n_sims_train)))
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.13.9 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.8
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230127_080633-dijt1yj8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run luminous-paper-1596
wandb: ⭐️ View project at https://wandb.ai/nreints/thesis
wandb: 🚀 View run at https://wandb.ai/nreints/thesis/runs/dijt1yj8
/home/nreints/.conda/envs/thesis/lib/python3.10/site-packages/torch/nn/modules/rnn.py:67: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  warnings.warn("dropout option adds dropout after all but last "
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.006051331292837858
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.001288337865844369
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.007660096511244774
15 0.0043216058 	 0.0076600965
epoch_time;  40.99427103996277
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.007576394826173782
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.014846393838524818
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.006727093830704689
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.014894034713506699
16 0.0032366955 	 0.0148940346
epoch_time;  41.02836346626282
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.000839429791085422
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.005288487300276756
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0012949275551363826
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.006885460112243891
17 0.0036517857 	 0.0068854601
epoch_time;  41.352039098739624
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.003331773681566119
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.009970271959900856
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.00490918243303895
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.01251921709626913
18 0.003451347 	 0.012519217
epoch_time;  41.088330030441284
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.03521205112338066
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.058260343968868256
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.03147219493985176
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.05176382139325142
19 0.0030866965 	 0.0517638227
epoch_time;  40.989664793014526
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0008635176927782595
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.005158592015504837
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0014227030333131552
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.00654748035594821
20 0.0031936629 	 0.0065474806
epoch_time;  40.87720847129822
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.011971637606620789
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.021280815824866295
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.010080505162477493
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.018408898264169693
21 0.0030694896 	 0.0184088978
epoch_time;  41.111318588256836
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.008664893917739391
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.015660492703318596
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.008796720765531063
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.017313139513134956
22 0.0029862606 	 0.017313139
epoch_time;  44.6603057384491
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0006726617575623095
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.004510934930294752
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0011825573164969683
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.005824495106935501
23 0.0029558071 	 0.0058244953
epoch_time;  43.06734108924866
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0026179058477282524
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.007592340931296349
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.004011527169495821
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.010231301188468933
24 0.0027257037 	 0.0102313011
epoch_time;  41.47865843772888
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0018424715381115675
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.005637096706777811
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0021403769496828318
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.006604179739952087
25 0.0027067261 	 0.0066041795
epoch_time;  41.16318655014038
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0012859331909567118
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.004531617276370525
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0017864624969661236
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.005901207681745291
26 0.0027141421 	 0.0059012077
epoch_time;  41.38709878921509
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0018355458742007613
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0057552712969481945
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.002833465812727809
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.007647440768778324
27 0.0025567187 	 0.0076474409
epoch_time;  40.95052409172058
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0009125522337853909
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0037857098504900932
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0013094182359054685
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.005257927346974611
28 0.0027490877 	 0.0052579274
epoch_time;  41.511295318603516
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0005899881361983716
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0037906195502728224
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0010260627605021
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.00515226274728775
29 0.0032714927 	 0.0051522626
epoch_time;  42.03286385536194
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0005902335396967828
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0037696033250540495
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0010255277156829834
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.005152303725481033
It took  1315.3448777198792  seconds.
----- ITERATION 2/10 ------
[<torch.utils.data.dataloader.DataLoader object at 0x145e6ec0ac20>, <torch.utils.data.dataloader.DataLoader object at 0x145e42dc6500>, <torch.utils.data.dataloader.DataLoader object at 0x145e750d2bc0>, <torch.utils.data.dataloader.DataLoader object at 0x145e750d2da0>]
LSTM(
  (lstm): LSTM(8, 96, batch_first=True, dropout=0.2)
  (layers): Sequential(
    (0): Linear(in_features=96, out_features=8, bias=True)
  )
)
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.011462211608886719
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.03593553602695465
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.01763548143208027
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.0766114816069603
0 1.2483831459 	 0.0766114814
epoch_time;  41.528350591659546
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.004688435234129429
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.01884821057319641
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.00917000975459814
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.04057539254426956
1 0.019773915 	 0.0405753934
epoch_time;  41.01111102104187
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0037247035652399063
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.014924936927855015
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.006505816243588924
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.029828978702425957
2 0.0152129131 	 0.0298289792
epoch_time;  40.9045193195343
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.01622232235968113
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.028874371200799942
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.01229745615273714
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.03314782679080963
3 0.0120031319 	 0.0331478263
epoch_time;  41.50089430809021
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.005669931415468454
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.014663875102996826
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.006277257110923529
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.021784260869026184
4 0.0100924776 	 0.0217842609
epoch_time;  40.75795912742615
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0072123147547245026
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.016775833442807198
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.01350516639649868
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.030726315453648567
5 0.0088725238 	 0.0307263147
epoch_time;  41.09166359901428
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.03699379041790962
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.05717376247048378
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.026830967515707016
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.04786546155810356
6 0.0076387826 	 0.0478654614
epoch_time;  41.095175981521606
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0041633835062384605
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.011143459938466549
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                              Epoch ▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇███
wandb: Test loss t(-10, 10)_r(-5, 5)_none █▄▃▄▃▄▅▂▄▂▂▄▁▂▁▁▁▁▂▂▁▁▁▁▂▁▁▁▇▁▁
wandb:  Test loss t(-10, 10)_r(0, 0)_none ▃▂▂▃▂▂▅▂▃▁▁▃▁▁▁▁▁▁▂▂▁▁▁▁▁▁▁▁█▁▁
wandb:    Test loss t(0, 0)_r(-5, 5)_none ▃▂▂▃▂▃▅▂▃▁▁▃▁▁▁▁▁▁▁▂▁▁▁▁▂▁▁▁█▁▁
wandb:     Test loss t(0, 0)_r(0, 0)_none ▂▁▁▂▁▂▄▁▃▁▁▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁
wandb:                         Train loss █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                              Epoch 29
wandb: Test loss t(-10, 10)_r(-5, 5)_none 0.00458
wandb:  Test loss t(-10, 10)_r(0, 0)_none 0.00259
wandb:    Test loss t(0, 0)_r(-5, 5)_none 0.00108
wandb:     Test loss t(0, 0)_r(0, 0)_none 0.0007
wandb:                         Train loss 0.00275
wandb: 
wandb: 🚀 View run luminous-paper-1596 at: https://wandb.ai/nreints/thesis/runs/dijt1yj8
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230127_080633-dijt1yj8/logs
/gpfs/home2/nreints/MScThesis/code/lstm.py:270: DeprecationWarning: Sampling from a set deprecated
since Python 3.9 and will be removed in a subsequent version.
  train_sims = set(random.sample(sims_train, int(0.8 * n_sims_train)))
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.13.9 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.8
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230127_082824-7l729foi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vermilion-noodles-1603
wandb: ⭐️ View project at https://wandb.ai/nreints/thesis
wandb: 🚀 View run at https://wandb.ai/nreints/thesis/runs/7l729foi
/home/nreints/.conda/envs/thesis/lib/python3.10/site-packages/torch/nn/modules/rnn.py:67: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  warnings.warn("dropout option adds dropout after all but last "
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.005662000272423029
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.017660347744822502
7 0.006994316 	 0.0176603484
epoch_time;  41.198952436447144
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.017322123050689697
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.030775466933846474
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.015201062895357609
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.0322575680911541
8 0.0060984628 	 0.0322575699
epoch_time;  41.6652991771698
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0010818574810400605
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.005305653437972069
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0016078135231509805
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.010094987228512764
9 0.0054719609 	 0.0100949877
epoch_time;  41.63094758987427
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0010433616116642952
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0054477062076330185
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.001642483752220869
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.01023237593472004
10 0.0056121485 	 0.0102323758
epoch_time;  41.496086835861206
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.019105032086372375
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.03071259707212448
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.017489789053797722
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.030710432678461075
11 0.0044956103 	 0.0307104335
epoch_time;  41.744645833969116
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.001007381360977888
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.004734529182314873
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0014535109512507915
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.008852577768266201
12 0.0043643916 	 0.0088525776
epoch_time;  44.43434739112854
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.002156272530555725
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.006320747546851635
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0026940780226141214
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.010250259190797806
13 0.0042205045 	 0.0102502594
epoch_time;  43.19228267669678
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0010857901070266962
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.004661157727241516
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0014370993012562394
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.008117339573800564
14 0.0043934404 	 0.0081173394
epoch_time;  41.018800258636475
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0016600259114056826
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.005271672271192074
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0025765064638108015
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.009411380626261234
15 0.0037009191 	 0.0094113811
epoch_time;  41.1864128112793
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.002286681206896901
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.006101752165704966
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.002793475752696395
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.009593782015144825
16 0.003982775 	 0.0095937821
epoch_time;  41.54117560386658
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0007517671911045909
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0036315477918833494
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.00118324626237154
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.006843857932835817
17 0.0035548705 	 0.0068438579
epoch_time;  41.44221115112305
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0015740026719868183
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.01215235237032175
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0028714467771351337
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.018435874953866005
18 0.0225606163 	 0.0184358744
epoch_time;  41.56126141548157
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.004077194258570671
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.010979000478982925
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.007172612007707357
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.017870092764496803
19 0.0023605585 	 0.017870092
epoch_time;  40.95433688163757
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.001051499042659998
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0045770141296088696
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.001631307415664196
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.007939305156469345
20 0.0031045203 	 0.0079393056
epoch_time;  41.29090881347656
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0019742308650165796
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.005364663433283567
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0021892543882131577
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.008158083073794842
21 0.0033585995 	 0.008158083
epoch_time;  41.32931089401245
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0016107020201161504
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.004463694524019957
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.002311689080670476
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.00748409191146493
22 0.0032498293 	 0.0074840917
epoch_time;  41.25832748413086
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0006979061872698367
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0032030981965363026
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0011854803888127208
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.005884157493710518
23 0.0032931219 	 0.0058841576
epoch_time;  41.35873603820801
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.003283710917457938
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.007508051116019487
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0055230287835001945
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.012492969632148743
24 0.0025973423 	 0.0124929693
epoch_time;  41.38755774497986
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0006812229403294623
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0032540506217628717
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0011273057898506522
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.005706953816115856
25 0.0036084906 	 0.0057069539
epoch_time;  40.871846437454224
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0012423187727108598
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0034518472384661436
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0014813755406066775
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.005566288251429796
26 0.0020541731 	 0.0055662883
epoch_time;  41.238423585891724
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.000564610178116709
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0024347451981157064
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0009896056726574898
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.004679855424910784
27 0.0028513409 	 0.0046798556
epoch_time;  40.927818775177
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.07664024829864502
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.10839131474494934
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.04966691508889198
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.0685114935040474
28 0.0026373988 	 0.0685114961
epoch_time;  41.545032262802124
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0006991234258748591
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.00257527525536716
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0010824549244716763
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.004585915710777044
29 0.0027483706 	 0.0045859158
epoch_time;  41.33866095542908
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0006993337301537395
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0025863749906420708
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0010826552752405405
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.004583880305290222
It took  1311.1965630054474  seconds.
----- ITERATION 3/10 ------
[<torch.utils.data.dataloader.DataLoader object at 0x145e42dc6a40>, <torch.utils.data.dataloader.DataLoader object at 0x145e42e47820>, <torch.utils.data.dataloader.DataLoader object at 0x145e750d2b60>, <torch.utils.data.dataloader.DataLoader object at 0x145e42e3aec0>]
LSTM(
  (lstm): LSTM(8, 96, batch_first=True, dropout=0.2)
  (layers): Sequential(
    (0): Linear(in_features=96, out_features=8, bias=True)
  )
)
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.009090542793273926
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.04398267716169357
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.015301117673516273
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.07478057593107224
0 1.3829269929 	 0.0747805765
epoch_time;  41.459768772125244
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.006162725389003754
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.027754083275794983
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.00878994446247816
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.0402308814227581
1 0.0176947433 	 0.0402308807
epoch_time;  41.448283672332764
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0413985513150692
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.07337123155593872
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.03879765048623085
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.07376552373170853
2 0.0142025222 	 0.0737655213
epoch_time;  44.17348289489746
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0040006134659051895
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.019150523468852043
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.006544142495840788
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.02710667997598648
3 0.0134291725 	 0.0271066798
epoch_time;  42.83647680282593
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.008829792030155659
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.022557472810149193
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.011559933423995972
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.031148003414273262
4 0.0096946799 	 0.0311480029
epoch_time;  40.978909492492676
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.008003567345440388
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.01878109946846962
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.009963219985365868
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.02543894574046135
5 0.0084433538 	 0.0254389455
epoch_time;  41.40446162223816
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0026153235230594873
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.010696952231228352
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.004069597460329533
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.01744871586561203
6 0.0079555035 	 0.0174487163
epoch_time;  41.37427854537964
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.005074950400739908
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0134532880038023
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0056311991065740585
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.01783614233136177
7 0.0064153354 	 0.0178361414
epoch_time;  41.28192734718323
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.00406018178910017
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.011375046335160732
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.006454335991293192
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.0188054870814085
8 0.0065299763 	 0.0188054866
epoch_time;  41.139301776885986
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.008534335531294346
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.017131827771663666
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.009796352125704288
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.02425132691860199
9 0.0059879886 	 0.0242513271
epoch_time;  41.32383346557617
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.01143887359648943
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.024728141725063324
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.01593095064163208
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.03447301313281059
10 0.0049421677 	 0.0344730129
epoch_time;  41.57883286476135
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0009741939720697701
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.006809931248426437
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0016608682926744223
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.011488051153719425
11 0.0053610506 	 0.0114880516
epoch_time;  41.38760447502136
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0011456817155703902
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.00549953943118453
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0016756426775828004
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.010032279416918755
12 0.0039693109 	 0.0100322793
epoch_time;  41.35769248008728
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.023893652483820915
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.03800966963171959
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.017517149448394775
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.03173094242811203
13 0.0042278173 	 0.0317309429
epoch_time;  41.055155992507935
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0013077276526018977
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.005766494199633598
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0019329433562234044
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.009954728186130524
14 0.0041898396 	 0.0099547284
epoch_time;  41.370508909225464
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0007152881007641554
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.004648150410503149
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0012154931901022792
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.008475269190967083
15 0.0044352761 	 0.0084752691
epoch_time;  41.102368116378784
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.000707605155184865
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.004159195348620415
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.001182828564196825
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.007885485887527466
16 0.0036408113 	 0.0078854856
epoch_time;  41.187528133392334
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.002416715258732438
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.006621277891099453
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.002860727021470666
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.010174647904932499
17 0.0035423038 	 0.0101746476
epoch_time;  41.428632974624634
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0015240792417898774
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0052033537067472935
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.002678908873349428
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.010122513398528099
18 0.0034853418 	 0.0101225131
epoch_time;  40.934831619262695
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0023637788835912943
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.005917658098042011
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.002626588800922036
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.009291671216487885
19 0.0032631573 	 0.0092916712
epoch_time;  40.858487367630005
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.004282079637050629
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.00930276233702898
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.003957329783588648
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.011562831699848175
20 0.0034193686 	 0.0115628315
epoch_time;  41.69082951545715
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.000739328155759722
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.004947280045598745
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0013044194784015417
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.009271206334233284
21 0.0062962149 	 0.0092712061
epoch_time;  41.22779726982117
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0006565893418155611
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0036617524456232786
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0010800260351970792
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.006709442939609289
22 0.0023583397 	 0.0067094431
epoch_time;  41.32987308502197
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0021148573141545057
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0055887820199131966
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.002329484559595585
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.008103946223855019
23 0.0026163152 	 0.0081039462
epoch_time;  44.71664023399353
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.022 MB of 0.022 MB uploaded (0.000 MB deduped)wandb: \ 0.022 MB of 0.022 MB uploaded (0.000 MB deduped)wandb: | 0.022 MB of 0.022 MB uploaded (0.000 MB deduped)wandb: / 0.022 MB of 0.022 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:                              Epoch ▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇███
wandb: Test loss t(-10, 10)_r(-5, 5)_none █▄█▃▄▃▂▂▂▃▄▂▁▄▁▁▁▁▁▁▂▁▁▁▁▁▁▁▂▁▁
wandb:  Test loss t(-10, 10)_r(0, 0)_none ▅▃█▃▃▃▂▂▂▂▃▁▁▄▁▁▁▁▁▁▂▁▁▁▁▁▁▁▂▂▂
wandb:    Test loss t(0, 0)_r(-5, 5)_none ▄▂█▂▃▃▂▂▂▃▄▁▁▄▁▁▁▁▁▁▂▁▁▁▁▁▁▁▂▂▂
wandb:     Test loss t(0, 0)_r(0, 0)_none ▂▂█▂▂▂▁▂▂▂▃▁▁▅▁▁▁▁▁▁▂▁▁▁▁▁▁▁▂▂▂
wandb:                         Train loss █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                              Epoch 29
wandb: Test loss t(-10, 10)_r(-5, 5)_none 0.01032
wandb:  Test loss t(-10, 10)_r(0, 0)_none 0.00851
wandb:    Test loss t(0, 0)_r(-5, 5)_none 0.00421
wandb:     Test loss t(0, 0)_r(0, 0)_none 0.0043
wandb:                         Train loss 0.00262
wandb: 
wandb: 🚀 View run vermilion-noodles-1603 at: https://wandb.ai/nreints/thesis/runs/7l729foi
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230127_082824-7l729foi/logs
/gpfs/home2/nreints/MScThesis/code/lstm.py:270: DeprecationWarning: Sampling from a set deprecated
since Python 3.9 and will be removed in a subsequent version.
  train_sims = set(random.sample(sims_train, int(0.8 * n_sims_train)))
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.13.9 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.8
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230127_085019-rnk8mlt9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glistening-laughter-1611
wandb: ⭐️ View project at https://wandb.ai/nreints/thesis
wandb: 🚀 View run at https://wandb.ai/nreints/thesis/runs/rnk8mlt9
/home/nreints/.conda/envs/thesis/lib/python3.10/site-packages/torch/nn/modules/rnn.py:67: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  warnings.warn("dropout option adds dropout after all but last "
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.000892238924279809
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0035724740009754896
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0012879895512014627
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.006307998206466436
24 0.0027590607 	 0.0063079981
epoch_time;  43.04010057449341
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0008786926628090441
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.003490438684821129
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0012483805185183883
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.006117034703493118
25 0.0031802512 	 0.0061170349
epoch_time;  42.605886459350586
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0008546775789000094
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.003274077083915472
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0011486813891679049
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.00589041318744421
26 0.0028357479 	 0.005890413
epoch_time;  40.90523838996887
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0012444212334230542
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.004154641646891832
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0015251594595611095
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.006939724553376436
27 0.003723647 	 0.0069397245
epoch_time;  41.138524293899536
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.007602174300700426
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.013805449940264225
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.00744100334122777
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.015284743160009384
28 0.002466877 	 0.0152847428
epoch_time;  41.011277198791504
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.004297404550015926
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.008510990999639034
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0042137219570577145
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.010315804742276669
29 0.0026244056 	 0.0103158043
epoch_time;  40.685433864593506
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.004296007100492716
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.00850594975054264
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.004213858861476183
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.010316341184079647
It took  1314.1692152023315  seconds.
----- ITERATION 4/10 ------
[<torch.utils.data.dataloader.DataLoader object at 0x145e76b78a90>, <torch.utils.data.dataloader.DataLoader object at 0x145e750d02e0>, <torch.utils.data.dataloader.DataLoader object at 0x145e6e42f160>, <torch.utils.data.dataloader.DataLoader object at 0x145e750d2410>]
LSTM(
  (lstm): LSTM(8, 96, batch_first=True, dropout=0.2)
  (layers): Sequential(
    (0): Linear(in_features=96, out_features=8, bias=True)
  )
)
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.009534605778753757
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.039332129061222076
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.01542472094297409
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.08044847100973129
0 1.2576280546 	 0.0804484733
epoch_time;  41.18436622619629
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.00808718241751194
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.02718198485672474
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.011701068840920925
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.047511324286460876
1 0.0189209302 	 0.0475113226
epoch_time;  41.132676124572754
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.003193486947566271
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.01598677784204483
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0058422875590622425
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.033832043409347534
2 0.0157376462 	 0.033832043
epoch_time;  41.30302691459656
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.00560504337772727
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.017714086920022964
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.006963788997381926
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.029427099972963333
3 0.0125792516 	 0.0294270991
epoch_time;  40.995408058166504
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0027466609608381987
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.012939948588609695
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.004372242838144302
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.023285161703824997
4 0.0099700629 	 0.0232851613
epoch_time;  40.99712824821472
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0044575948268175125
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.013620329089462757
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.006371188908815384
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.02306998148560524
5 0.0090774374 	 0.023069981
epoch_time;  41.16685199737549
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.006834601983428001
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.01595737226307392
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.008118324913084507
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.023340921849012375
6 0.0079716409 	 0.0233409225
epoch_time;  41.29356408119202
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.005408009514212608
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.013060192577540874
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.005174477118998766
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.01888756826519966
7 0.007469344 	 0.0188875674
epoch_time;  41.222806215286255
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0016887254314497113
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.007468432653695345
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0021604530047625303
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.013115606270730495
8 0.006189225 	 0.0131156063
epoch_time;  41.13974928855896
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.011061589233577251
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.020034978166222572
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.01144973561167717
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.025400444865226746
9 0.0051982123 	 0.0254004441
epoch_time;  40.94709396362305
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0015523928450420499
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.006742950528860092
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.002538609318435192
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.01203949749469757
10 0.0051059546 	 0.0120394972
epoch_time;  41.75431275367737
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0008902073604986072
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.005189168732613325
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0014332192949950695
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.009450561366975307
11 0.0047344447 	 0.009450561
epoch_time;  41.02585697174072
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0011572310468181968
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.005239512771368027
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0015543290646746755
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.009083358570933342
12 0.0044359937 	 0.0090833582
epoch_time;  41.2113139629364
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.023185648024082184
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0399332158267498
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.02649141289293766
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.04768935963511467
13 0.0052191986 	 0.0476893601
epoch_time;  41.39312481880188
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.002452836837619543
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.006899174768477678
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0027541618328541517
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.01014524046331644
14 0.0040407863 	 0.0101452407
epoch_time;  43.12840795516968
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.00582731980830431
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.012462307699024677
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.009061058983206749
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.019970685243606567
15 0.0036607604 	 0.019970685
epoch_time;  42.957844972610474
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0016107492847368121
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                              Epoch ▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇███
wandb: Test loss t(-10, 10)_r(-5, 5)_none █▅▄▃▃▃▃▂▂▃▂▁▁▅▁▂▁▅▁▂▂▁▁▂▁▁▂▁▁▁▁
wandb:  Test loss t(-10, 10)_r(0, 0)_none █▅▃▄▃▃▃▃▂▄▂▁▁█▂▃▁█▁▂▆▁▂▃▁▁▂▁▁▁▁
wandb:    Test loss t(0, 0)_r(-5, 5)_none ▅▄▂▃▂▂▃▂▁▄▁▁▁█▁▃▁█▁▁▄▁▂▃▁▁▂▁▁▁▁
wandb:     Test loss t(0, 0)_r(0, 0)_none ▄▃▂▂▂▂▃▂▁▄▁▁▁█▂▃▁█▁▁▆▁▁▃▁▁▂▁▁▁▁
wandb:                         Train loss █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                              Epoch 29
wandb: Test loss t(-10, 10)_r(-5, 5)_none 0.00562
wandb:  Test loss t(-10, 10)_r(0, 0)_none 0.00328
wandb:    Test loss t(0, 0)_r(-5, 5)_none 0.00124
wandb:     Test loss t(0, 0)_r(0, 0)_none 0.00096
wandb:                         Train loss 0.00405
wandb: 
wandb: 🚀 View run glistening-laughter-1611 at: https://wandb.ai/nreints/thesis/runs/rnk8mlt9
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230127_085019-rnk8mlt9/logs
/gpfs/home2/nreints/MScThesis/code/lstm.py:270: DeprecationWarning: Sampling from a set deprecated
since Python 3.9 and will be removed in a subsequent version.
  train_sims = set(random.sample(sims_train, int(0.8 * n_sims_train)))
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.13.9 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.8
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230127_091209-t6ei9msz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run enchanting-lamp-1620
wandb: ⭐️ View project at https://wandb.ai/nreints/thesis
wandb: 🚀 View run at https://wandb.ai/nreints/thesis/runs/t6ei9msz
/home/nreints/.conda/envs/thesis/lib/python3.10/site-packages/torch/nn/modules/rnn.py:67: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  warnings.warn("dropout option adds dropout after all but last "
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.00533114792779088
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.001845449791289866
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.008400826714932919
16 0.0045158944 	 0.0084008263
epoch_time;  41.219701528549194
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.023851552978157997
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.041175685822963715
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.026435520499944687
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.04480431601405144
17 0.0032512443 	 0.0448043166
epoch_time;  41.24401926994324
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.001356663298793137
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.004571111407130957
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.001687750336714089
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.007576923817396164
18 0.0038156102 	 0.0075769237
epoch_time;  41.103185176849365
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0009639344061724842
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.006499770097434521
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0016250894404947758
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.011223696172237396
19 0.0084152936 	 0.0112236958
epoch_time;  41.44105648994446
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.01845819689333439
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.029870765283703804
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.01152533944696188
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.02110685408115387
20 0.0016458462 	 0.0211068539
epoch_time;  41.30232620239258
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0007870299159549177
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0034278929233551025
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0011435706401243806
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.006033751647919416
21 0.0030920814 	 0.0060337515
epoch_time;  41.22170615196228
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.002203994896262884
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.005584242288023233
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0030068776104599237
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.008710574358701706
22 0.0028711167 	 0.0087105745
epoch_time;  41.46824526786804
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.006441934034228325
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.011265725828707218
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.009778284467756748
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.018054544925689697
23 0.0030252033 	 0.0180545444
epoch_time;  41.7897846698761
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0006388120818883181
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0027653889264911413
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0010222602868452668
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.005095584783703089
24 0.0028610592 	 0.0050955849
epoch_time;  41.2198281288147
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0021089366637170315
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.005106639117002487
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.002317173406481743
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.007100178860127926
25 0.0028438909 	 0.0071001788
epoch_time;  41.49897766113281
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.002448560204356909
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.005928552243858576
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0044855475425720215
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.010483783669769764
26 0.0026554879 	 0.0104837835
epoch_time;  41.17587614059448
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0012159800389781594
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0035247323103249073
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.001724145608022809
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.005793737713247538
27 0.002625469 	 0.0057937379
epoch_time;  41.32680583000183
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0007515916367992759
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.002727379323914647
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0012539984891191125
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.00501108868047595
28 0.0025208175 	 0.0050110889
epoch_time;  41.42985248565674
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0009627536637708545
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0032676367554813623
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0012427765177562833
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.005630748346447945
29 0.0040544525 	 0.0056307485
epoch_time;  41.18073606491089
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0009628059924580157
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0032797737512737513
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0012427021283656359
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.005624047014862299
It took  1310.2018258571625  seconds.
----- ITERATION 5/10 ------
[<torch.utils.data.dataloader.DataLoader object at 0x145e75123f70>, <torch.utils.data.dataloader.DataLoader object at 0x145e6ebf5270>, <torch.utils.data.dataloader.DataLoader object at 0x145e6ebf6c50>, <torch.utils.data.dataloader.DataLoader object at 0x145e6ebf6e00>]
LSTM(
  (lstm): LSTM(8, 96, batch_first=True, dropout=0.2)
  (layers): Sequential(
    (0): Linear(in_features=96, out_features=8, bias=True)
  )
)
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.01358985435217619
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.07316102087497711
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.021773843094706535
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.10347123444080353
0 1.818714035 	 0.1034712316
epoch_time;  41.113083362579346
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.013418423943221569
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.051707491278648376
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.016972266137599945
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.06566862761974335
1 0.0194379935 	 0.0656686305
epoch_time;  40.2583646774292
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.027173904702067375
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.06455729156732559
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.028451425954699516
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.06646102666854858
2 0.01401298 	 0.0664610272
epoch_time;  40.2054386138916
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.004398433957248926
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.025254806503653526
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.007101472932845354
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.03261382505297661
3 0.0124186979 	 0.0326138263
epoch_time;  40.90986227989197
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.012021188624203205
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.031522978097200394
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.010935633443295956
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.032831110060214996
4 0.0101177106 	 0.0328311085
epoch_time;  43.37523651123047
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0050728763453662395
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.021189972758293152
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.005395050626248121
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.020887644961476326
5 0.0085748987 	 0.0208876457
epoch_time;  42.05859446525574
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.004502836149185896
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.017754241824150085
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.00642741983756423
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.020984984934329987
6 0.007354675 	 0.0209849853
epoch_time;  40.591012716293335
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.008672710508108139
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.02234111726284027
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.010610193014144897
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.0265212245285511
7 0.0067655843 	 0.0265212246
epoch_time;  40.51256728172302
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.007767622359097004
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.019309362396597862
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                              Epoch ▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇███
wandb: Test loss t(-10, 10)_r(-5, 5)_none █▅▅▃▃▂▂▃▂▂▁▁▁▁▂▁▂▁▁▁▁▁▁▁▁▁▁▂▁▁▁
wandb:  Test loss t(-10, 10)_r(0, 0)_none █▆▇▃▄▃▂▃▃▂▂▁▁▁▂▁▂▁▁▁▁▁▁▁▁▁▁▂▁▁▁
wandb:    Test loss t(0, 0)_r(-5, 5)_none ▆▅█▃▄▂▂▃▃▁▁▁▁▁▂▁▂▁▁▁▁▁▂▂▂▂▁▂▁▁▁
wandb:     Test loss t(0, 0)_r(0, 0)_none ▄▄█▂▄▂▂▃▃▂▁▁▁▁▂▁▂▁▁▁▁▁▂▁▂▂▁▂▁▁▁
wandb:                         Train loss █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                              Epoch 29
wandb: Test loss t(-10, 10)_r(-5, 5)_none 0.00548
wandb:  Test loss t(-10, 10)_r(0, 0)_none 0.0033
wandb:    Test loss t(0, 0)_r(-5, 5)_none 0.00167
wandb:     Test loss t(0, 0)_r(0, 0)_none 0.001
wandb:                         Train loss 0.00229
wandb: 
wandb: 🚀 View run enchanting-lamp-1620 at: https://wandb.ai/nreints/thesis/runs/t6ei9msz
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230127_091209-t6ei9msz/logs
/gpfs/home2/nreints/MScThesis/code/lstm.py:270: DeprecationWarning: Sampling from a set deprecated
since Python 3.9 and will be removed in a subsequent version.
  train_sims = set(random.sample(sims_train, int(0.8 * n_sims_train)))
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.13.9 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.8
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230127_093340-sugfr1dn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run bright-cake-1627
wandb: ⭐️ View project at https://wandb.ai/nreints/thesis
wandb: 🚀 View run at https://wandb.ai/nreints/thesis/runs/sugfr1dn
/home/nreints/.conda/envs/thesis/lib/python3.10/site-packages/torch/nn/modules/rnn.py:67: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  warnings.warn("dropout option adds dropout after all but last "
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.007872809655964375
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.019496187567710876
8 0.005603638 	 0.0194961873
epoch_time;  40.47263741493225
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.00255211372859776
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.010884391143918037
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.00284749292768538
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.011783192865550518
9 0.0053795859 	 0.0117831929
epoch_time;  40.203033685684204
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0010555138578638434
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.007996111176908016
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0017101833363994956
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.009515061043202877
10 0.0052438309 	 0.0095150615
epoch_time;  40.427626848220825
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0011054272763431072
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0069838594645261765
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.001650129328481853
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.008797558024525642
11 0.0043620525 	 0.0087975577
epoch_time;  40.65026640892029
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.001688705524429679
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.007267005275934935
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0023604698944836855
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.009602795355021954
12 0.0044738183 	 0.0096027952
epoch_time;  40.30085492134094
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0015804213471710682
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0067642126232385635
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0019360643345862627
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.008596011437475681
13 0.0040137625 	 0.0085960119
epoch_time;  40.71554636955261
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.004411253146827221
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.01198427565395832
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.006439738441258669
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.01572486199438572
14 0.0040731383 	 0.0157248621
epoch_time;  40.2639262676239
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.00171644426882267
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0061872778460383415
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0019510869169607759
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.008121740072965622
15 0.0038311902 	 0.0081217404
epoch_time;  40.628708839416504
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.004930140450596809
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.010288168676197529
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.00497937947511673
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.011790208518505096
16 0.0035428878 	 0.0117902086
epoch_time;  40.65344595909119
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0014812950976192951
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0052775111980736256
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0016177044017240405
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.00703991437330842
17 0.0035410747 	 0.0070399143
epoch_time;  40.845969915390015
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0007155161001719534
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.004285979084670544
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0012354949722066522
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.006292029749602079
18 0.0033030784 	 0.0062920298
epoch_time;  40.51716089248657
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0016275193775072694
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.007128159515559673
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.002214146079495549
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.009242309257388115
19 0.0045624667 	 0.0092423092
epoch_time;  40.59293174743652
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0009634345187805593
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0044087995775043964
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.00155026582069695
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.006349281407892704
20 0.0020094263 	 0.0063492812
epoch_time;  41.06684851646423
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0009899347787722945
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.004145961720496416
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0016963359666988254
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.0064690918661653996
21 0.0029387927 	 0.006469092
epoch_time;  40.42184281349182
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0026485444977879524
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.006946207955479622
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0048207067884504795
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.010727081447839737
22 0.0029162307 	 0.0107270814
epoch_time;  40.47255539894104
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0021322069223970175
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.006088429130613804
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0032257004640996456
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.009077465161681175
23 0.0031242645 	 0.0090774654
epoch_time;  40.86316251754761
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.003871192457154393
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.007618051953613758
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0046904729679226875
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.009723834693431854
24 0.0025013479 	 0.0097238348
epoch_time;  40.70203971862793
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.003693042090162635
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0078020780347287655
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0037465484347194433
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.008567791432142258
25 0.0024851921 	 0.0085677913
epoch_time;  40.460583209991455
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0008064284920692444
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0032242094166576862
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0011215123813599348
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.0050155725330114365
26 0.0028690666 	 0.0050155728
epoch_time;  43.33222723007202
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.005408501718193293
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.009573140181601048
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.00590845663100481
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.011984732002019882
27 0.0025853122 	 0.0119847322
epoch_time;  41.535945653915405
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0006027290946803987
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0027924899477511644
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0010474632726982236
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.00456059817224741
28 0.002593714 	 0.0045605981
epoch_time;  40.43682074546814
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0009958111913874745
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.003302275203168392
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0016658639069646597
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.005475236102938652
29 0.0022856467 	 0.0054752362
epoch_time;  40.62350869178772
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0009954392444342375
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0033021012786775827
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0016665651928633451
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.005475373473018408
It took  1290.8266258239746  seconds.
----- ITERATION 6/10 ------
[<torch.utils.data.dataloader.DataLoader object at 0x145e42dc6980>, <torch.utils.data.dataloader.DataLoader object at 0x145e42dc5c60>, <torch.utils.data.dataloader.DataLoader object at 0x145e6ebd2c20>, <torch.utils.data.dataloader.DataLoader object at 0x145e6ebd2e00>]
LSTM(
  (lstm): LSTM(8, 96, batch_first=True, dropout=0.2)
  (layers): Sequential(
    (0): Linear(in_features=96, out_features=8, bias=True)
  )
)
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0120754549279809
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.04182438552379608
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.018251892179250717
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.09016435593366623
0 1.358222586 	 0.0901643574
epoch_time;  40.37166142463684
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.005760738626122475
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.022010328248143196
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.009123518131673336
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.044382985681295395
1 0.017594536 	 0.0443829856
epoch_time;  40.248613357543945
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.004108814522624016
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.017216769978404045
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.006544795818626881
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.03580775484442711
2 0.015329348 	 0.0358077565
epoch_time;  40.46277117729187
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.004430004861205816
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.016301607713103294
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0075503066182136536
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.029882904142141342
3 0.0116890417 	 0.0298829035
epoch_time;  40.638246059417725
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0039940509013831615
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.015067956410348415
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0057991910725831985
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.024691907688975334
4 0.0111900708 	 0.0246919073
epoch_time;  40.540120124816895
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.005527015309780836
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.01658775471150875
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.007235366385430098
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.023837188258767128
5 0.0083952961 	 0.0238371889
epoch_time;  40.83673024177551
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.002026735572144389
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.00842203013598919
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.003148949472233653
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.015292526222765446
6 0.0078077042 	 0.0152925264
epoch_time;  40.50279474258423
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0023977195378392935
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.008311053737998009
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0029113630298525095
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.013531357981264591
7 0.0068727633 	 0.0135313579
epoch_time;  40.35151290893555
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0014821598306298256
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0065625817514956
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.002248805947601795
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.011597495526075363
8 0.0060425657 	 0.0115974958
epoch_time;  40.299718618392944
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.001664057606831193
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0066800774075090885
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0023407163098454475
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.01160446461290121
9 0.0060357369 	 0.0116044647
epoch_time;  40.63026022911072
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0030626014340668917
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.008395490236580372
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.005644307006150484
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.01589006558060646
10 0.0045705379 	 0.0158900653
epoch_time;  40.43621563911438
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0014058246742933989
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.010608885437250137
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.002347999718040228
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.018188973888754845
11 0.0111699332 	 0.0181889736
epoch_time;  40.357449769973755
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0008828140562400222
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.005222087725996971
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0015033116796985269
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.00971981417387724
12 0.0028462589 	 0.0097198141
epoch_time;  40.45142865180969
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.002209944184869528
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.00621027173474431
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0024550785310566425
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.010350181721150875
13 0.0039639484 	 0.0103501813
epoch_time;  40.481106758117676
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0008553396328352392
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0047240909188985825
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0014336648164317012
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.008987212553620338
14 0.0047665826 	 0.0089872128
epoch_time;  40.53622007369995
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0012626617681235075
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.004970992915332317
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.002301375148817897
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.009783333167433739
15 0.003300891 	 0.0097833328
epoch_time;  40.363492012023926
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0011051605688408017
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.004822925198823214
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0018574260175228119
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.008763973601162434
16 0.003934474 	 0.0087639738
epoch_time;  45.34131932258606
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.001548037282191217
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.005126921460032463
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.00215127388946712
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.008563201874494553
17 0.0032282987 	 0.0085632023
epoch_time;  42.83025503158569
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0028140104841440916
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.007307947147637606
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.003484197659417987
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.010780277661979198
18 0.0038134324 	 0.0107802776
epoch_time;  41.035022020339966
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.018904300406575203
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.030752338469028473
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.019180409610271454
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.03476458787918091
19 0.0031608344 	 0.0347645866
epoch_time;  40.702924489974976
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.007943407632410526
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.044723961502313614
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.011878293007612228
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.07001250237226486
20 0.0203154129 	 0.0700124988
epoch_time;  40.65180015563965
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0018532361136749387
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.008191796950995922
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0023141251876950264
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.013010546565055847
21 0.0033686899 	 0.0130105465
epoch_time;  40.728087186813354
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.00129286153241992
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.004997955169528723
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0016655276995152235
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.008724164217710495
22 0.0026725732 	 0.0087241644
epoch_time;  40.701213121414185
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0013993184547871351
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.004694968927651644
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.002091835020110011
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.008152627386152744
23 0.0029819012 	 0.0081526275
epoch_time;  40.21892189979553
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.001813333947211504
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.00463731586933136
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.00251266872510314
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.00826234184205532
24 0.0029582131 	 0.0082623418
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                              Epoch ▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇███
wandb: Test loss t(-10, 10)_r(-5, 5)_none █▄▄▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▃▆▂▁▁▁▁▁▂▁▁▁
wandb:  Test loss t(-10, 10)_r(0, 0)_none █▄▃▃▃▃▂▂▂▂▂▂▁▂▁▁▁▁▂▆█▂▁▁▁▁▂▃▁▁▁
wandb:    Test loss t(0, 0)_r(-5, 5)_none █▄▃▄▃▃▂▂▁▁▃▁▁▂▁▁▁▁▂█▅▁▁▁▂▁▂▄▁▁▁
wandb:     Test loss t(0, 0)_r(0, 0)_none ▅▃▂▂▂▃▂▂▁▁▂▁▁▂▁▁▁▁▂█▄▁▁▁▁▁▂▃▁▁▁
wandb:                         Train loss █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                              Epoch 29
wandb: Test loss t(-10, 10)_r(-5, 5)_none 0.00533
wandb:  Test loss t(-10, 10)_r(0, 0)_none 0.00328
wandb:    Test loss t(0, 0)_r(-5, 5)_none 0.00144
wandb:     Test loss t(0, 0)_r(0, 0)_none 0.00116
wandb:                         Train loss 0.00219
wandb: 
wandb: 🚀 View run bright-cake-1627 at: https://wandb.ai/nreints/thesis/runs/sugfr1dn
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230127_093340-sugfr1dn/logs
/gpfs/home2/nreints/MScThesis/code/lstm.py:270: DeprecationWarning: Sampling from a set deprecated
since Python 3.9 and will be removed in a subsequent version.
  train_sims = set(random.sample(sims_train, int(0.8 * n_sims_train)))
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.13.9 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.8
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230127_095510-esv84yc8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glittering-fish-1634
wandb: ⭐️ View project at https://wandb.ai/nreints/thesis
wandb: 🚀 View run at https://wandb.ai/nreints/thesis/runs/esv84yc8
/home/nreints/.conda/envs/thesis/lib/python3.10/site-packages/torch/nn/modules/rnn.py:67: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  warnings.warn("dropout option adds dropout after all but last "
epoch_time;  40.43691039085388
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0013295577373355627
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.004139847122132778
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0017193553503602743
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.00688588060438633
25 0.003064305 	 0.0068858808
epoch_time;  40.94513773918152
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0040462082251906395
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0075378697365522385
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0032351615373045206
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.00836449209600687
26 0.0027722776 	 0.0083644923
epoch_time;  40.666465282440186
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.006705974694341421
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.012997640296816826
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.00846182368695736
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.017895687371492386
27 0.0029291 	 0.017895687
epoch_time;  40.461148262023926
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0005978993722237647
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.002853493671864271
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0010620628017932177
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.005387759301811457
28 0.002861596 	 0.0053877593
epoch_time;  40.535027503967285
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0011565792374312878
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.003289605490863323
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0014363628579303622
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.005327649414539337
29 0.0021911644 	 0.0053276493
epoch_time;  40.184131383895874
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0011566703906282783
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.00328351859934628
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0014357275795191526
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.005328951869159937
It took  1290.2452647686005  seconds.
----- ITERATION 7/10 ------
[<torch.utils.data.dataloader.DataLoader object at 0x145e766c5480>, <torch.utils.data.dataloader.DataLoader object at 0x145e6ebf5870>, <torch.utils.data.dataloader.DataLoader object at 0x145e6ebf4af0>, <torch.utils.data.dataloader.DataLoader object at 0x145e6ebf4ac0>]
LSTM(
  (lstm): LSTM(8, 96, batch_first=True, dropout=0.2)
  (layers): Sequential(
    (0): Linear(in_features=96, out_features=8, bias=True)
  )
)
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.011287440545856953
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.052613455802202225
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.01649969257414341
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.08512555062770844
0 1.58313515 	 0.0851255515
epoch_time;  40.71719932556152
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.01233722921460867
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.04400603100657463
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.017502347007393837
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.05917651578783989
1 0.0181421068 	 0.059176517
epoch_time;  40.427364110946655
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0038263120222836733
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.021935870870947838
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0062057883478701115
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.03422163054347038
2 0.0144974595 	 0.034221629
epoch_time;  40.38157796859741
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.007120579946786165
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.02474679984152317
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.008622231893241405
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.03165127709507942
3 0.0117448385 	 0.0316512779
epoch_time;  40.559845209121704
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.002741853706538677
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.014734800904989243
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.004208827391266823
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.022402053698897362
4 0.0098989986 	 0.0224020546
epoch_time;  40.34935927391052
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.017910344526171684
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.03711507469415665
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.013280940242111683
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.0312977060675621
5 0.0084136202 	 0.0312977068
epoch_time;  40.17675757408142
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0022822520695626736
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.010132155381143093
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.002588815987110138
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.01469173189252615
6 0.0073967334 	 0.0146917317
epoch_time;  40.63714289665222
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.002103836741298437
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.008912515826523304
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0029134450014680624
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.013673785142600536
7 0.0060727829 	 0.0136737852
epoch_time;  43.03803586959839
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0012612815480679274
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0081044752150774
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0018981480970978737
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.012607007287442684
8 0.0072483226 	 0.0126070069
epoch_time;  43.133190870285034
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0017111264169216156
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.007504908833652735
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.002812502207234502
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.012319433502852917
9 0.0039780593 	 0.0123194337
epoch_time;  40.2290472984314
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0011281281476840377
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.005962831899523735
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.001884505501948297
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.00974118709564209
10 0.004795569 	 0.0097411875
epoch_time;  40.40887212753296
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0017164587043225765
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.006835675332695246
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.001932030892930925
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.009617004543542862
11 0.0045253947 	 0.0096170045
epoch_time;  40.459848165512085
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0021754088811576366
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.008151278831064701
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0026283259503543377
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.010980385355651379
12 0.0043121467 	 0.0109803857
epoch_time;  40.47193884849548
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0008061190601438284
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.005919322371482849
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0015335811767727137
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.009974462911486626
13 0.005657539 	 0.0099744631
epoch_time;  40.581316232681274
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.004487140104174614
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.010243401862680912
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.003901588497683406
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.012149715796113014
14 0.0033751725 	 0.0121497157
epoch_time;  40.132349252700806
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0012456695549190044
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.005519911181181669
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.002017492428421974
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.0090522151440382
15 0.0035981865 	 0.0090522154
epoch_time;  40.146648645401
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0008235129644162953
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.004705683793872595
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0013377568684518337
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.007719143759459257
16 0.0036957457 	 0.0077191436
epoch_time;  40.131566762924194
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                              Epoch ▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇███
wandb: Test loss t(-10, 10)_r(-5, 5)_none █▆▄▃▃▃▂▂▂▂▁▁▂▁▂▁▁▁▁▁▁▁▁▂▁▂▁▁▁▃▃
wandb:  Test loss t(-10, 10)_r(0, 0)_none █▇▄▄▃▆▂▂▂▂▁▁▂▁▂▁▁▁▁▁▁▁▁▃▁▂▁▁▁▆▆
wandb:    Test loss t(0, 0)_r(-5, 5)_none ██▃▄▂▆▂▂▁▂▁▁▂▁▂▁▁▁▁▂▁▁▁▃▁▃▁▁▁▇▇
wandb:     Test loss t(0, 0)_r(0, 0)_none ▄▄▂▃▂▆▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▃▁▁▁▁▁██
wandb:                         Train loss █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                              Epoch 29
wandb: Test loss t(-10, 10)_r(-5, 5)_none 0.0237
wandb:  Test loss t(-10, 10)_r(0, 0)_none 0.03909
wandb:    Test loss t(0, 0)_r(-5, 5)_none 0.01451
wandb:     Test loss t(0, 0)_r(0, 0)_none 0.02643
wandb:                         Train loss 0.00238
wandb: 
wandb: 🚀 View run glittering-fish-1634 at: https://wandb.ai/nreints/thesis/runs/esv84yc8
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230127_095510-esv84yc8/logs
/gpfs/home2/nreints/MScThesis/code/lstm.py:270: DeprecationWarning: Sampling from a set deprecated
since Python 3.9 and will be removed in a subsequent version.
  train_sims = set(random.sample(sims_train, int(0.8 * n_sims_train)))
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.13.9 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.8
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230127_101639-8f4n6c2k
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run brilliant-lamp-1641
wandb: ⭐️ View project at https://wandb.ai/nreints/thesis
wandb: 🚀 View run at https://wandb.ai/nreints/thesis/runs/8f4n6c2k
/home/nreints/.conda/envs/thesis/lib/python3.10/site-packages/torch/nn/modules/rnn.py:67: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  warnings.warn("dropout option adds dropout after all but last "
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0006944388733245432
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.004803663119673729
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0011172030353918672
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.007643438875675201
17 0.0039252971 	 0.0076434389
epoch_time;  40.23771333694458
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0010247286409139633
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0044603110291063786
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.001417237683199346
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.0071715558879077435
18 0.0025638677 	 0.0071715559
epoch_time;  40.15723729133606
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.001745380344800651
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.005924394354224205
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.002318486338481307
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.008877926506102085
19 0.0040800176 	 0.0088779264
epoch_time;  40.49080038070679
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0006420307909138501
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.003990986384451389
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0010982785606756806
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.006341088563203812
20 0.002853883 	 0.0063410886
epoch_time;  40.33283233642578
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0007977989735081792
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0042290822602808475
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0013239625841379166
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.006785213481634855
21 0.0030666322 	 0.0067852134
epoch_time;  40.38189482688904
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.000832859193906188
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.004102490842342377
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0013419758761301637
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.006399383768439293
22 0.0028724708 	 0.0063993837
epoch_time;  40.361215591430664
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.00904915388673544
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.01626153290271759
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.006906569004058838
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.01400996558368206
23 0.0027765697 	 0.0140099655
epoch_time;  40.105401277542114
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0016510162968188524
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.004878567066043615
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0016628599260002375
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.006589964497834444
24 0.0027506601 	 0.0065899644
epoch_time;  40.08268189430237
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0024319528602063656
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.007200172170996666
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.005402848590165377
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.012762556783854961
25 0.003080115 	 0.0127625566
epoch_time;  40.4237174987793
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.002043497748672962
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.00500426534563303
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0018981394823640585
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.006592052523046732
26 0.0025064857 	 0.0065920526
epoch_time;  40.765811920166016
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.000980231212452054
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.004137861542403698
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0019255820661783218
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.006748702842742205
27 0.0026579291 	 0.006748703
epoch_time;  40.37762475013733
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0006073618424125016
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0033325478434562683
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.001026130630634725
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.004995248280465603
28 0.0023461264 	 0.0049952481
epoch_time;  40.89615321159363
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.026422375813126564
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.039061903953552246
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.014498216100037098
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.023729749023914337
29 0.0023802803 	 0.0237297493
epoch_time;  43.6849799156189
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.02642866037786007
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.03908858448266983
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.014508360996842384
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.023702260106801987
It took  1288.91086935997  seconds.
----- ITERATION 8/10 ------
[<torch.utils.data.dataloader.DataLoader object at 0x145e6ebe1000>, <torch.utils.data.dataloader.DataLoader object at 0x145e6ebf7a90>, <torch.utils.data.dataloader.DataLoader object at 0x145e42dc4d00>, <torch.utils.data.dataloader.DataLoader object at 0x145e42dc4fa0>]
LSTM(
  (lstm): LSTM(8, 96, batch_first=True, dropout=0.2)
  (layers): Sequential(
    (0): Linear(in_features=96, out_features=8, bias=True)
  )
)
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.018792593851685524
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.05866927281022072
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.021884940564632416
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.08277876675128937
0 1.4873917354 	 0.0827787693
epoch_time;  40.37722659111023
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.009641177952289581
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.03127795085310936
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.01226885337382555
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.045101847499608994
1 0.0190593769 	 0.0451018486
epoch_time;  40.2339243888855
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.006573493592441082
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.022406872361898422
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.01029992289841175
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.036144666373729706
2 0.0145206004 	 0.0361446657
epoch_time;  40.5599091053009
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.04922308400273323
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.07475180923938751
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.034013532102108
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.059722669422626495
3 0.0126952504 	 0.0597226699
epoch_time;  40.408198833465576
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.003376259235665202
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.014687977731227875
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.005665866192430258
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.022273413836956024
4 0.0102582169 	 0.0222734137
epoch_time;  40.56989884376526
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.005093562416732311
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0166280847042799
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.005647911224514246
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.02065723016858101
5 0.0092994198 	 0.0206572311
epoch_time;  40.106791973114014
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.004329897928982973
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.01511659100651741
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.007358229253441095
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.022272799164056778
6 0.0074518025 	 0.0222727986
epoch_time;  39.905529499053955
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.004155699163675308
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.012764748185873032
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.006338175851851702
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.018177855759859085
7 0.0063265029 	 0.0181778551
epoch_time;  40.20450043678284
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0037972109857946634
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.011621681973338127
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.004472370259463787
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.015508351847529411
8 0.0061432516 	 0.0155083521
epoch_time;  40.33772802352905
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0026019830256700516
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.009513448923826218
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                              Epoch ▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇███
wandb: Test loss t(-10, 10)_r(-5, 5)_none █▅▄▆▃▂▃▂▂▂▂▂▁▂▂▂▁▂▁▁▁▂▁▁▁▁▁▂▁▃▃
wandb:  Test loss t(-10, 10)_r(0, 0)_none ▆▄▃█▂▂▂▂▂▂▂▁▁▁▂▂▁▁▁▁▁▁▂▁▁▁▁▂▁▄▄
wandb:    Test loss t(0, 0)_r(-5, 5)_none ▅▃▃█▂▂▂▂▂▁▂▁▁▂▂▂▁▂▁▁▁▂▂▁▁▁▁▂▁▄▄
wandb:     Test loss t(0, 0)_r(0, 0)_none ▄▂▂█▁▂▂▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▂▁▁▁▁▂▁▄▄
wandb:                         Train loss █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                              Epoch 29
wandb: Test loss t(-10, 10)_r(-5, 5)_none 0.02715
wandb:  Test loss t(-10, 10)_r(0, 0)_none 0.03014
wandb:    Test loss t(0, 0)_r(-5, 5)_none 0.01675
wandb:     Test loss t(0, 0)_r(0, 0)_none 0.01956
wandb:                         Train loss 0.00324
wandb: 
wandb: 🚀 View run brilliant-lamp-1641 at: https://wandb.ai/nreints/thesis/runs/8f4n6c2k
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230127_101639-8f4n6c2k/logs
/gpfs/home2/nreints/MScThesis/code/lstm.py:270: DeprecationWarning: Sampling from a set deprecated
since Python 3.9 and will be removed in a subsequent version.
  train_sims = set(random.sample(sims_train, int(0.8 * n_sims_train)))
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.13.9 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.8
wandb: Run data is saved locally in /gpfs/home2/nreints/MScThesis/code/wandb/run-20230127_103801-uahaswrl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run luminous-lamp-1650
wandb: ⭐️ View project at https://wandb.ai/nreints/thesis
wandb: 🚀 View run at https://wandb.ai/nreints/thesis/runs/uahaswrl
/home/nreints/.conda/envs/thesis/lib/python3.10/site-packages/torch/nn/modules/rnn.py:67: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  warnings.warn("dropout option adds dropout after all but last "
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.003328900318592787
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.013201842084527016
9 0.0055021622 	 0.0132018418
epoch_time;  40.154685735702515
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.003705645212903619
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.010045730508863926
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.004735591821372509
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.014357962645590305
10 0.0048829619 	 0.014357963
epoch_time;  39.962377071380615
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.002027666661888361
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0076588792726397514
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0023241834715008736
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.01130524929612875
11 0.0052050649 	 0.0113052493
epoch_time;  40.02279615402222
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0008662014151923358
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.005590213928371668
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0014382096705958247
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.00906591210514307
12 0.0042496262 	 0.0090659126
epoch_time;  42.342020988464355
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0026056438218802214
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.007838882505893707
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.003584290621802211
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.011814984492957592
13 0.0042261962 	 0.0118149847
epoch_time;  39.93433690071106
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0034856179263442755
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.009997147135436535
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0037635057233273983
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.01365763321518898
14 0.0048809329 	 0.0136576333
epoch_time;  40.05128455162048
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.004794837906956673
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.010412964038550854
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0052432287484407425
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.013679897412657738
15 0.0030752315 	 0.0136798977
epoch_time;  40.140713691711426
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0008682046900503337
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0048577007837593555
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0013124555116519332
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.007757075130939484
16 0.0037912673 	 0.0077570752
epoch_time;  39.920538902282715
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.003253120696172118
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.008347725495696068
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.004744942300021648
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.012702264823019505
17 0.0035018044 	 0.0127022648
epoch_time;  40.49422860145569
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0014274375280365348
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.007432326674461365
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0020827457774430513
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.010359199717640877
18 0.0089646404 	 0.0103592001
epoch_time;  40.344948053359985
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0014135009841993451
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.005911471322178841
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0018192058196291327
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.008209171704947948
19 0.0028520668 	 0.0082091716
epoch_time;  43.86044001579285
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0015278107021003962
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.005200245417654514
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0019580493681132793
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.007643973454833031
20 0.002902472 	 0.0076439734
epoch_time;  41.675891399383545
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0035743839107453823
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.008092086762189865
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.005017440766096115
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.011383520439267159
21 0.0029856184 	 0.0113835205
epoch_time;  41.85490679740906
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0052287764847278595
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.009724189527332783
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.004827538505196571
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.010597677901387215
22 0.0030564536 	 0.0105976777
epoch_time;  39.89029669761658
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0007146637071855366
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0038023069500923157
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0011783705558627844
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.006345103494822979
23 0.0035228736 	 0.0063451035
epoch_time;  40.809348821640015
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0014099564868956804
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.004287912975996733
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0016288341721519828
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.005994192324578762
24 0.0023051525 	 0.0059941924
epoch_time;  40.14007091522217
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0023461291566491127
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.005316536873579025
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.00261324574239552
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.007278626784682274
25 0.0026467864 	 0.0072786268
epoch_time;  40.3783392906189
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0008051884942688048
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0034274922218173742
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0011894759954884648
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.00550669664517045
26 0.0032677077 	 0.0055066967
epoch_time;  40.34597969055176
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.005677734035998583
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.010465726256370544
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0066360305063426495
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.012702183797955513
27 0.002114314 	 0.0127021841
epoch_time;  40.05439758300781
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0015622712671756744
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.004087306559085846
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0019646959844976664
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.005982695613056421
28 0.0026191153 	 0.0059826954
epoch_time;  40.12319326400757
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.019570544362068176
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.030151166021823883
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.016755571588873863
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.027178306132555008
29 0.0032409766 	 0.0271783062
epoch_time;  40.76672291755676
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.019564446061849594
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.03013838455080986
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.016748515889048576
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.027154484763741493
It took  1282.209379196167  seconds.
----- ITERATION 9/10 ------
[<torch.utils.data.dataloader.DataLoader object at 0x145e42dc6e00>, <torch.utils.data.dataloader.DataLoader object at 0x145e750d2c50>, <torch.utils.data.dataloader.DataLoader object at 0x145e750d3be0>, <torch.utils.data.dataloader.DataLoader object at 0x145e750d1720>]
LSTM(
  (lstm): LSTM(8, 96, batch_first=True, dropout=0.2)
  (layers): Sequential(
    (0): Linear(in_features=96, out_features=8, bias=True)
  )
)
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.020572489127516747
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.055570170283317566
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.026233036071062088
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.09839897602796555
0 1.4661628671 	 0.098398975
epoch_time;  40.53047204017639
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.015101071447134018
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.03759590536355972
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0166095569729805
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.05409718304872513
1 0.01931441 	 0.0540971842
epoch_time;  40.18658256530762
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.008863692171871662
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.026798728853464127
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.00922448467463255
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.03978778421878815
2 0.015828116 	 0.0397877852
epoch_time;  40.567060470581055
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.005605618469417095
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.019389215856790543
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0073800222016870975
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.031335145235061646
3 0.0123181513 	 0.031335145
epoch_time;  40.113794565200806
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.021708199754357338
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.040477652102708817
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.01790107786655426
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.040584348142147064
4 0.0101415503 	 0.0405843481
epoch_time;  40.49887704849243
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0026156415697187185
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.01323548424988985
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.003678814275190234
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.01969003491103649
5 0.0096298863 	 0.0196900353
epoch_time;  40.612709760665894
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.001654701423831284
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.010271108709275723
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.002900195773690939
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.017289845272898674
6 0.0081197282 	 0.0172898445
epoch_time;  40.7387421131134
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.003480411833152175
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.010887467302381992
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.00741825345903635
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.021587060764431953
7 0.0063404391 	 0.0215870607
epoch_time;  40.57566237449646
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0013155197957530618
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.008217821829020977
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0021956406999379396
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.013825709000229836
8 0.0070390052 	 0.013825709
epoch_time;  40.3245894908905
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.00181787449400872
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.008067783899605274
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0023774332366883755
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.012845776975154877
9 0.0053036525 	 0.012845777
epoch_time;  40.270963191986084
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.004530274774879217
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.011623653583228588
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0050426060333848
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.016285264864563942
10 0.0053170249 	 0.0162852653
epoch_time;  43.149619340896606
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.001376046915538609
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.006878797896206379
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0020493450574576855
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.011327839456498623
11 0.0046706402 	 0.0113278393
epoch_time;  42.178638219833374
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.003239147597923875
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.009902815334498882
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.004243690054863691
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.014488968066871166
12 0.0046169085 	 0.0144889679
epoch_time;  40.67714548110962
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.000892017618753016
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.005253138951957226
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0014009950682520866
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.009414841420948505
13 0.0043063409 	 0.0094148414
epoch_time;  40.28989362716675
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0023822803050279617
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.007417008746415377
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0026420000940561295
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.010587445460259914
14 0.0038830813 	 0.0105874452
epoch_time;  40.61912703514099
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0017941785044968128
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.006271806079894304
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.002432510256767273
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.010002843104302883
15 0.0040020343 	 0.0100028428
epoch_time;  40.35006928443909
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0009204695816151798
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.004798079375177622
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.001494646305218339
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.008389879018068314
16 0.0041576591 	 0.0083898792
epoch_time;  40.455729484558105
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0009255557088181376
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.004873836413025856
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0014192654052749276
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.008127217181026936
17 0.003973575 	 0.0081272168
epoch_time;  40.315380811691284
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0011949955951422453
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.005075362045317888
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0019159718649461865
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.008542360737919807
18 0.0032796181 	 0.0085423605
epoch_time;  40.5348904132843
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0016681255074217916
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.005675779655575752
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0021940642036497593
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.008440469391644001
19 0.0032095126 	 0.0084404693
epoch_time;  40.824273347854614
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0017174893291667104
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.005547212436795235
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.002743564313277602
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.009238187223672867
20 0.0033902335 	 0.0092381869
epoch_time;  40.33313465118408
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0006964896456338465
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0038418506737798452
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.001194465672597289
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.0067658619955182076
21 0.0032204037 	 0.0067658619
epoch_time;  40.504385471343994
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0013847621157765388
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.004712593741714954
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0017933171475306153
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.007332961540669203
22 0.0029062521 	 0.0073329617
epoch_time;  40.76076292991638
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0007554091280326247
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0038560985121876
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.001239810953848064
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.006442462559789419
23 0.0031526069 	 0.0064424626
epoch_time;  40.28572750091553
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0009161718189716339
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0036755180917680264
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0014151710784062743
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.006222252268344164
24 0.0026793586 	 0.0062222524
epoch_time;  40.16949462890625
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0005888157174922526
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.003800938604399562
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0011105508310720325
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.006485729943960905
25 0.0047015122 	 0.0064857301
epoch_time;  40.44651174545288
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                              Epoch ▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇███
wandb: Test loss t(-10, 10)_r(-5, 5)_none █▅▄▃▄▂▂▂▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂
wandb:  Test loss t(-10, 10)_r(0, 0)_none █▆▄▃▆▂▂▂▂▂▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▃▃
wandb:    Test loss t(0, 0)_r(-5, 5)_none █▅▃▃▆▂▂▃▁▁▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▃▃
wandb:     Test loss t(0, 0)_r(0, 0)_none █▆▄▃█▂▁▂▁▁▂▁▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▂▁▄▄
wandb:                         Train loss █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:                              Epoch 29
wandb: Test loss t(-10, 10)_r(-5, 5)_none 0.01687
wandb:  Test loss t(-10, 10)_r(0, 0)_none 0.0159
wandb:    Test loss t(0, 0)_r(-5, 5)_none 0.00923
wandb:     Test loss t(0, 0)_r(0, 0)_none 0.00976
wandb:                         Train loss 0.00278
wandb: 
wandb: 🚀 View run luminous-lamp-1650 at: https://wandb.ai/nreints/thesis/runs/uahaswrl
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20230127_103801-uahaswrl/logs
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0007714229286648333
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.0035212195944041014
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0012393726501613855
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.005707626696676016
26 0.002177764 	 0.0057076266
epoch_time;  40.77893400192261
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.0029328842647373676
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.006704419851303101
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.003584276419132948
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.008956030942499638
27 0.0026440249 	 0.0089560311
epoch_time;  40.485846757888794
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.000624090782366693
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.003007208462804556
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.0010894362349063158
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.005293738096952438
28 0.0028182834 	 0.0052937381
epoch_time;  40.43197226524353
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.009767947718501091
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.015889788046479225
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.009224962443113327
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.016857756301760674
29 0.002777481 	 0.0168577566
epoch_time;  40.35414457321167
	 Logging test loss: t(0, 0)_r(0, 0)_none => 0.00975956954061985
	 Logging test loss: t(-10, 10)_r(0, 0)_none => 0.015898356214165688
	 Logging test loss: t(0, 0)_r(-5, 5)_none => 0.00922845583409071
	 Logging test loss: t(-10, 10)_r(-5, 5)_none => 0.01687227003276348
It took  1287.036123752594  seconds.

JOB STATISTICS
==============
Job ID: 2142308
Array Job ID: 2141141_19
Cluster: snellius
User/Group: nreints/nreints
State: RUNNING
Nodes: 1
Cores per node: 18
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 2-17:04:48 core-walltime
Job Wall-clock time: 03:36:56
Memory Utilized: 0.00 MB (estimated maximum)
Memory Efficiency: 0.00% of 31.25 GB (31.25 GB/node)
WARNING: Efficiency statistics may be misleading for RUNNING jobs.
