diff --git a/code/convert.py b/code/convert.py
index fb08a1f..9ad5b22 100644
--- a/code/convert.py
+++ b/code/convert.py
@@ -140,7 +140,7 @@ def log_quat2pos(log_quat, start_pos):
         scalar = (magn * torch.cos(v_norm))[:, :, None]
 
         quat = torch.cat((scalar, vector), dim=2)
-        
+
         # Stack translation to quaternion
         full_quat = torch.cat((quat, log_quat[:, :, 4:]), dim=2)
 
@@ -158,12 +158,14 @@ def diff_pos_start2pos(true_preds, start_pos):
         Converted difference to current position
 
     """
+    start_pos = start_pos.reshape(start_pos.shape[0], 8, 3)
     if len(true_preds.shape) == 2:
         true_preds = true_preds[:, None, :]
         start_pos = start_pos[:, None, :]
 
     start_pos = start_pos.reshape(-1, 1, true_preds.shape[2]).expand(-1, true_preds.shape[1], -1)
-    return start_pos + true_preds
+    result = start_pos + true_preds
+    return result.reshape(result.shape[0], 8, 3)
 
 
 
@@ -180,7 +182,7 @@ def convert(true_preds, start_pos, data_type):
 
     """
     if data_type == "pos" or data_type == "pos_norm":
-        return true_preds
+        return true_preds.reshape(true_preds.shape[0], 8,3)
     elif data_type == "eucl_motion":
         return eucl2pos(true_preds, start_pos)
     elif data_type == "quat":
diff --git a/code/plot_data.py b/code/plot_data.py
index 9520062..5917bad 100644
--- a/code/plot_data.py
+++ b/code/plot_data.py
@@ -5,93 +5,136 @@ import matplotlib.pyplot as plt
 from torch_nn import Network
 import pickle
 from random import randint
-
+import numpy as np
 import matplotlib.pyplot as plt
 import matplotlib.animation as animation
+from convert import *
 
-# model = torch.load(f"models/pos_fcnn.pickle")
-# print(model)
 
-data_type = "pos"
-architecture = "fcnn"
+def load_model(data_type, architecture):
+    # Load model
+    model_dict = torch.load(f"models/{data_type}_{architecture}.pickle")
+    config = model_dict['config']
+    ndata_dict = model_dict['data_dict']
+    model = Network(ndata_dict[config['data_type']], config)
+    model.load_state_dict(model_dict['model'])
+    model.eval()
+    print("Current model: \n", model)
+    return model
 
-model_dict = torch.load(f"models/{data_type}_{architecture}.pickle")
-config = model_dict['config']
-ndata_dict = model_dict['data_dict']
-model = Network(ndata_dict[config['data_type']], config)
-model.load_state_dict(model_dict['model'])
-model.eval()
-print(model)
-# exit()
+def get_random_sim_data():
+    # Select random simulation
+    i = randint(0, 749)
 
-i = randint(0, 749)
-print(i)
-with open(f'data/sim_{i}.pickle', 'rb') as f:
-    data = torch.FloatTensor(pickle.load(f)["data"][data_type])
+    print("Using simulation number ", i)
+    with open(f'data/sim_{i}.pickle', 'rb') as f:
+        file = pickle.load(f)
+        start_pos = torch.tensor(file["data"]["pos"][0], dtype=torch.float32)
+        start_pos = start_pos[None, :].repeat(225, 1, 1)
 
-result = torch.zeros_like(data)
-for frame_id in range(20, data.shape[0]):
-    # Get 20 frames (1, 480)
-    input_data = data[frame_id - 20 : frame_id]
-    input_data = input_data.flatten()[None, :]
+        data_tensor = torch.tensor(file["data"][data_type], dtype=torch.float32)
+        original_data = data_tensor.flatten(start_dim=1)
 
-    # Save the prediction in result
-    print(input_data)
-    with torch.no_grad(): # Deactivate gradients for the following code
-        result[frame_id] = model(input_data).reshape(8, 3)
+        plot_data = convert(data_tensor.flatten(start_dim=1), start_pos, data_type).reshape(225, 8, 3)
 
-# result = result.detach(
-print("data_shape ", data.shape)
-print("result_shape ", result.shape)
+    return plot_data, original_data
 
+def get_prediction(data, data_type, original_data):
+    # Collect prediction of model given simulation
+    result = torch.zeros_like(original_data)
+    start_pos = original_data[0][None, :]
 
-fig = plt.figure()
-ax = fig.add_subplot(111, projection='3d')
+    for frame_id in range(20, data.shape[0]):
+        # Get 20 frames shape: (1, 480)
+        input_data = data[frame_id - 20 : frame_id]
+        input_data = input_data.flatten()[None, :]
 
+        # Save the prediction in result
+        with torch.no_grad(): # Deactivate gradients for the following code
+            prediction = model(input_data)
+            result[frame_id] = convert(prediction, start_pos, data_type)
 
-first_cube = data[0]
-cube_result = result[0]
-X, Y, Z = first_cube[:, 0], first_cube[:, 1], first_cube[:, 2]
-X_result, Y_result, Z_result = cube_result[:, 0], cube_result[:, 1], cube_result[:, 2]
-# print(X)
-# print(Y)
-# print(Z)
-# exit()
-# print(X.shape, Y.shape, Z.shape)
 
-# Set the axis limits
-ax.set_xlim3d(-15, 15)
-ax.set_ylim(-15, 15)
-ax.set_zlim(0, 50)
+    return result
 
-# Begin plotting.
-ax.scatter(X, Y, Z, color='b', linewidth=0.5)
-ax.scatter(X_result, Y_result, Z_result, color='r', linewidth=0.5)
+def plot_3D_animation(data, result):
+    data = data.numpy()
+    result = result.numpy()
 
-ax.set_xlabel('$X$', fontsize=20)
-ax.set_ylabel('$Y$')
+    # Open figure
+    fig = plt.figure()
+    ax = fig.add_subplot(111, projection='3d')
+    # Set the axis limits
+    ax.set_xlim3d(-15, 15)
+    ax.set_ylim(-15, 15)
+    ax.set_zlim(0, 50)
+    ax.set_xlabel('$X$')
+    ax.set_ylabel('$Y$')
+    ax.set_xlabel('$Z$')
 
-# plt.show()
+    # Initial plot
+    first_cube = data[0]
+    first_cube = first_cube[np.array([0, 1, 2, 3, 4, 5, 6, 7]), :][np.array([0,1,3,2,6,7,5,4]), :]
+    cube_result = result[0]
+    cube_result = cube_result[np.array([0, 1, 2, 3, 4, 5, 6, 7]), :][np.array([0,1,3,2,6,7,5,4]), :]
+    X, Y, Z = first_cube[:, 0], first_cube[:, 1], first_cube[:, 2]
+    X_pred, Y_pred, Z_pred = cube_result[:, 0], cube_result[:, 1], cube_result[:, 2]
+
+    # Begin plotting.
+    ax.scatter(X, Y, Z, linewidth=0.5, color='b')
+    ax.scatter(X_pred, Y_pred, Z_pred, color='r', linewidth=0.5)
+    ax.plot(X, Y, Z)
+    ax.plot(X_pred, Y_pred, Z_pred, c="r")
+
+
+    def update(idx):
+        ax.set_xlabel('$X$')
+        ax.set_ylabel('$Y$')
+        ax.set_xlabel('$Z$')
+
+        ax.set_xlim3d(-15, 15)
+        ax.set_ylim3d(-15, 15)
+        ax.set_zlim3d(0, 50)
+
+
+        # Remove the previous scatter plot
+        if idx != 0:
+            ax.cla()
+
+        # Get original cube data
+        cube = data[idx]
+        cube = cube[np.array([0, 1, 2, 3, 4, 5, 6, 7]), :][np.array([0,1,3,2,6,7,5,4]), :]
+
+        # Get predicted cube date
+        predicted_cube = result[idx]
+        predicted_cube = predicted_cube[np.array([0, 1, 2, 3, 4, 5, 6, 7]), :][np.array([0,1,3,2,6,7,5,4]), :]
+
+
+        # Scatter original data
+        ax.scatter(cube[:, 0], cube[:, 1], cube[:, 2], color='b', linewidth=0.5)
+
+        # Scatter prediction data
+        ax.scatter(predicted_cube[:, 0], predicted_cube[:, 1], predicted_cube[:, 2], color='r', linewidth=0.5)
+
+        ax.plot(cube[:, 0], cube[:, 1], cube[:, 2])
+        ax.plot(predicted_cube[:, 0], predicted_cube[:, 1], predicted_cube[:, 2], c="r")
+
+
+    # Interval : Delay between frames in milliseconds.
+    ani = animation.FuncAnimation(fig, update, 225, interval=100, repeat=False)
+
+    plt.show()
+
+
+if __name__ == "__main__":
+    data_type = "quat"
+    architecture = "fcnn"
+
+    model = load_model(data_type, architecture)
+
+    plot_data, data = get_random_sim_data()
+
+    prediction = get_prediction(data, data_type, plot_data)
+
+    plot_3D_animation(plot_data, prediction)
 
-def update(idx):
-    # Set the axis limits
-    print(idx)
-    # Remove the previous scatter plot
-    if idx != 0:
-        ax.cla()
-
-    # Plot the new wireframe and pause briefly before continuing.
-    cube = data[idx]
-    result_cube = result[idx]
-    print(f'prediction: {result_cube[:,0]}')
-    print(f'true: {cube[:,0]}')
-    ax.scatter(cube[:, 0], cube[:, 1], cube[:, 2], color='b', linewidth=0.5)
-    ax.scatter(result_cube[:, 0], result_cube[:, 1], result_cube[:, 2], color='r', linewidth=0.5)
-    if idx == 224:
-        print(torch.min(result_cube[:, 2]))
-
-# Interval : Delay between frames in milliseconds.
-
-ani = animation.FuncAnimation(fig, update, 225, interval=100, repeat=False)
-
-plt.show()
\ No newline at end of file
diff --git a/code/torch_nn.py b/code/torch_nn.py
index db0b44b..a98b9a8 100644
--- a/code/torch_nn.py
+++ b/code/torch_nn.py
@@ -182,7 +182,6 @@ def eval_model(model, data_loader, loss_module):
             data_inputs, data_labels = data_inputs.to(device), data_labels.to(device)
             preds = model(data_inputs)
             preds = preds.squeeze(dim=1)
-            print(preds[0])
 
             alt_preds = convert(preds.detach().cpu(), start_pos, data_loader.dataset.data_type)
             alt_labels = convert(data_labels.detach().cpu(), start_pos, data_loader.dataset.data_type)
@@ -250,7 +249,7 @@ if __name__ == "__main__":
         loss_type = "L1",
         loss_reduction_type = "mean",
         optimizer = "Adam",
-        data_type = "pos",
+        data_type = "log_quat",
         architecture = "fcnn",
         train_sims = list(train_sims),
         test_sims = list(test_sims),
diff --git a/code/wandb/latest-run b/code/wandb/latest-run
index 0a7bc9c..f7bb01d 120000
--- a/code/wandb/latest-run
+++ b/code/wandb/latest-run
@@ -1 +1 @@
-run-20220920_133124-1633qjkf
\ No newline at end of file
+run-20220927_165240-ckvzsl8e
\ No newline at end of file
